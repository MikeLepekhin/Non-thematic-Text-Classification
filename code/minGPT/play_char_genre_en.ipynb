{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a character-level GPT on some text data\n",
    "\n",
    "The inputs here are simple text files, which we chop up to individual characters and then train GPT on. So you could say this is a char-transformer instead of a char-rnn. Doesn't quite roll off the tongue as well. In this example we will feed it some Shakespeare, which we'll get it to predict character-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join as pathjoin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "# make deterministic\n",
    "from mingpt.utils import sample, set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt_generator(train_text_file, state_dict_file, n_layer=8, n_head=8, n_embd=512,\n",
    "                        max_epochs=2, batch_size=512):\n",
    "    text = open(train_text_file, 'r').read()\n",
    "    train_dataset = CharDataset(text, block_size) \n",
    "    mconf = GPTConfig(\n",
    "        train_dataset.vocab_size, train_dataset.block_size,\n",
    "        n_layer=n_layer, n_head=n_head, n_embd=n_embd\n",
    "    )\n",
    "    model = GPT(mconf)\n",
    "    tconf = TrainerConfig(\n",
    "        max_epochs=max_epochs, batch_size=batch_size, learning_rate=6e-4,\n",
    "        lr_decay=True, warmup_tokens=batch_size*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "    trainer = Trainer(model, train_dataset, None, tconf)\n",
    "    trainer.train()\n",
    "    torch.save(model.state_dict(), state_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_DATA_DIR = '/home/mlepekhin/data/genre'\n",
    "GPT_MODELS_DIR = '/home/mlepekhin/models/mini_gpt/'\n",
    "LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 807353 characters, 95 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1577 [00:00<?, ?it/s]\u001b[A/home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "epoch 1 iter 0: train loss 4.64142. lr 5.999999e-04:   0%|          | 0/1577 [00:07<?, ?it/s]\u001b[A\n",
      "epoch 1 iter 0: train loss 4.64142. lr 5.999999e-04:   0%|          | 1/1577 [00:07<3:18:55,  7.57s/it]\u001b[A\n",
      "epoch 1 iter 1: train loss 3.70626. lr 5.999995e-04:   0%|          | 1/1577 [00:07<3:18:55,  7.57s/it]\u001b[A\n",
      "epoch 1 iter 1: train loss 3.70626. lr 5.999995e-04:   0%|          | 2/1577 [00:07<2:21:53,  5.41s/it]\u001b[A\n",
      "epoch 1 iter 2: train loss 5.45379. lr 5.999988e-04:   0%|          | 2/1577 [00:08<2:21:53,  5.41s/it]\u001b[A\n",
      "epoch 1 iter 2: train loss 5.45379. lr 5.999988e-04:   0%|          | 3/1577 [00:08<1:41:46,  3.88s/it]\u001b[A\n",
      "epoch 1 iter 3: train loss 4.12409. lr 5.999978e-04:   0%|          | 3/1577 [00:08<1:41:46,  3.88s/it]\u001b[A\n",
      "epoch 1 iter 3: train loss 4.12409. lr 5.999978e-04:   0%|          | 4/1577 [00:08<1:14:14,  2.83s/it]\u001b[A\n",
      "epoch 1 iter 4: train loss 3.62736. lr 5.999965e-04:   0%|          | 4/1577 [00:08<1:14:14,  2.83s/it]\u001b[A\n",
      "epoch 1 iter 4: train loss 3.62736. lr 5.999965e-04:   0%|          | 5/1577 [00:08<54:27,  2.08s/it]  \u001b[A\n",
      "epoch 1 iter 5: train loss 3.31480. lr 5.999949e-04:   0%|          | 5/1577 [00:09<54:27,  2.08s/it]\u001b[A\n",
      "epoch 1 iter 5: train loss 3.31480. lr 5.999949e-04:   0%|          | 6/1577 [00:09<40:36,  1.55s/it]\u001b[A\n",
      "epoch 1 iter 6: train loss 3.10141. lr 5.999930e-04:   0%|          | 6/1577 [00:09<40:36,  1.55s/it]\u001b[A\n",
      "epoch 1 iter 6: train loss 3.10141. lr 5.999930e-04:   0%|          | 7/1577 [00:09<30:54,  1.18s/it]\u001b[A\n",
      "epoch 1 iter 7: train loss 3.19409. lr 5.999908e-04:   0%|          | 7/1577 [00:09<30:54,  1.18s/it]\u001b[A\n",
      "epoch 1 iter 7: train loss 3.19409. lr 5.999908e-04:   1%|          | 8/1577 [00:09<24:07,  1.08it/s]\u001b[A\n",
      "epoch 1 iter 8: train loss 3.27862. lr 5.999884e-04:   1%|          | 8/1577 [00:10<24:07,  1.08it/s]\u001b[A\n",
      "epoch 1 iter 8: train loss 3.27862. lr 5.999884e-04:   1%|          | 9/1577 [00:10<19:23,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 9: train loss 3.21591. lr 5.999856e-04:   1%|          | 9/1577 [00:10<19:23,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 9: train loss 3.21591. lr 5.999856e-04:   1%|          | 10/1577 [00:10<16:04,  1.63it/s]\u001b[A\n",
      "epoch 1 iter 10: train loss 3.10434. lr 5.999825e-04:   1%|          | 10/1577 [00:10<16:04,  1.63it/s]\u001b[A\n",
      "epoch 1 iter 10: train loss 3.10434. lr 5.999825e-04:   1%|          | 11/1577 [00:10<13:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11: train loss 3.05906. lr 5.999791e-04:   1%|          | 11/1577 [00:11<13:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11: train loss 3.05906. lr 5.999791e-04:   1%|          | 12/1577 [00:11<12:07,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 12: train loss 3.04058. lr 5.999754e-04:   1%|          | 12/1577 [00:11<12:07,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 12: train loss 3.04058. lr 5.999754e-04:   1%|          | 13/1577 [00:11<10:59,  2.37it/s]\u001b[A\n",
      "epoch 1 iter 13: train loss 3.04710. lr 5.999715e-04:   1%|          | 13/1577 [00:11<10:59,  2.37it/s]\u001b[A\n",
      "epoch 1 iter 13: train loss 3.04710. lr 5.999715e-04:   1%|          | 14/1577 [00:11<10:11,  2.56it/s]\u001b[A\n",
      "epoch 1 iter 14: train loss 3.04445. lr 5.999672e-04:   1%|          | 14/1577 [00:12<10:11,  2.56it/s]\u001b[A\n",
      "epoch 1 iter 14: train loss 3.04445. lr 5.999672e-04:   1%|          | 15/1577 [00:12<09:37,  2.70it/s]\u001b[A\n",
      "epoch 1 iter 15: train loss 3.03814. lr 5.999626e-04:   1%|          | 15/1577 [00:12<09:37,  2.70it/s]\u001b[A\n",
      "epoch 1 iter 15: train loss 3.03814. lr 5.999626e-04:   1%|          | 16/1577 [00:12<09:14,  2.81it/s]\u001b[A\n",
      "epoch 1 iter 16: train loss 3.01440. lr 5.999578e-04:   1%|          | 16/1577 [00:12<09:14,  2.81it/s]\u001b[A\n",
      "epoch 1 iter 16: train loss 3.01440. lr 5.999578e-04:   1%|          | 17/1577 [00:12<08:57,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 17: train loss 2.99301. lr 5.999526e-04:   1%|          | 17/1577 [00:13<08:57,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 17: train loss 2.99301. lr 5.999526e-04:   1%|          | 18/1577 [00:13<08:45,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 18: train loss 3.01746. lr 5.999471e-04:   1%|          | 18/1577 [00:13<08:45,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 18: train loss 3.01746. lr 5.999471e-04:   1%|          | 19/1577 [00:13<08:53,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 19: train loss 2.97306. lr 5.999414e-04:   1%|          | 19/1577 [00:13<08:53,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 19: train loss 2.97306. lr 5.999414e-04:   1%|▏         | 20/1577 [00:13<08:42,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 20: train loss 2.97078. lr 5.999353e-04:   1%|▏         | 20/1577 [00:14<08:42,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 20: train loss 2.97078. lr 5.999353e-04:   1%|▏         | 21/1577 [00:14<08:36,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 21: train loss 2.93837. lr 5.999290e-04:   1%|▏         | 21/1577 [00:14<08:36,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 21: train loss 2.93837. lr 5.999290e-04:   1%|▏         | 22/1577 [00:14<08:30,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 22: train loss 2.90395. lr 5.999223e-04:   1%|▏         | 22/1577 [00:14<08:30,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 22: train loss 2.90395. lr 5.999223e-04:   1%|▏         | 23/1577 [00:14<08:34,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 23: train loss 2.86656. lr 5.999153e-04:   1%|▏         | 23/1577 [00:15<08:34,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 23: train loss 2.86656. lr 5.999153e-04:   2%|▏         | 24/1577 [00:15<08:32,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 24: train loss 2.85309. lr 5.999081e-04:   2%|▏         | 24/1577 [00:15<08:32,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 24: train loss 2.85309. lr 5.999081e-04:   2%|▏         | 25/1577 [00:15<08:27,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 25: train loss 2.81614. lr 5.999005e-04:   2%|▏         | 25/1577 [00:15<08:27,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 25: train loss 2.81614. lr 5.999005e-04:   2%|▏         | 26/1577 [00:15<08:23,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 26: train loss 2.80352. lr 5.998927e-04:   2%|▏         | 26/1577 [00:16<08:23,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 26: train loss 2.80352. lr 5.998927e-04:   2%|▏         | 27/1577 [00:16<08:30,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 27: train loss 2.76151. lr 5.998846e-04:   2%|▏         | 27/1577 [00:16<08:30,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 27: train loss 2.76151. lr 5.998846e-04:   2%|▏         | 28/1577 [00:16<08:32,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 28: train loss 2.72506. lr 5.998761e-04:   2%|▏         | 28/1577 [00:16<08:32,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 28: train loss 2.72506. lr 5.998761e-04:   2%|▏         | 29/1577 [00:16<08:28,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 29: train loss 2.69505. lr 5.998674e-04:   2%|▏         | 29/1577 [00:17<08:28,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 29: train loss 2.69505. lr 5.998674e-04:   2%|▏         | 30/1577 [00:17<08:24,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 30: train loss 2.67100. lr 5.998583e-04:   2%|▏         | 30/1577 [00:17<08:24,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 30: train loss 2.67100. lr 5.998583e-04:   2%|▏         | 31/1577 [00:17<08:29,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 31: train loss 2.63602. lr 5.998490e-04:   2%|▏         | 31/1577 [00:17<08:29,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 31: train loss 2.63602. lr 5.998490e-04:   2%|▏         | 32/1577 [00:17<08:27,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 32: train loss 2.63642. lr 5.998394e-04:   2%|▏         | 32/1577 [00:18<08:27,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 32: train loss 2.63642. lr 5.998394e-04:   2%|▏         | 33/1577 [00:18<08:24,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 33: train loss 2.61745. lr 5.998295e-04:   2%|▏         | 33/1577 [00:18<08:24,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 33: train loss 2.61745. lr 5.998295e-04:   2%|▏         | 34/1577 [00:18<08:46,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 34: train loss 2.59825. lr 5.998192e-04:   2%|▏         | 34/1577 [00:18<08:46,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 34: train loss 2.59825. lr 5.998192e-04:   2%|▏         | 35/1577 [00:18<08:40,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 35: train loss 2.58583. lr 5.998087e-04:   2%|▏         | 35/1577 [00:19<08:40,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 35: train loss 2.58583. lr 5.998087e-04:   2%|▏         | 36/1577 [00:19<08:35,  2.99it/s]\u001b[A\n",
      "epoch 1 iter 36: train loss 2.57910. lr 5.997979e-04:   2%|▏         | 36/1577 [00:19<08:35,  2.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 36: train loss 2.57910. lr 5.997979e-04:   2%|▏         | 37/1577 [00:19<08:33,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 37: train loss 2.58006. lr 5.997868e-04:   2%|▏         | 37/1577 [00:19<08:33,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 37: train loss 2.58006. lr 5.997868e-04:   2%|▏         | 38/1577 [00:19<08:31,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 38: train loss 2.57380. lr 5.997753e-04:   2%|▏         | 38/1577 [00:20<08:31,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 38: train loss 2.57380. lr 5.997753e-04:   2%|▏         | 39/1577 [00:20<08:30,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 39: train loss 2.56470. lr 5.997636e-04:   2%|▏         | 39/1577 [00:20<08:30,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 39: train loss 2.56470. lr 5.997636e-04:   3%|▎         | 40/1577 [00:20<08:30,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 40: train loss 2.54831. lr 5.997516e-04:   3%|▎         | 40/1577 [00:20<08:30,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 40: train loss 2.54831. lr 5.997516e-04:   3%|▎         | 41/1577 [00:20<08:28,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 41: train loss 2.55179. lr 5.997393e-04:   3%|▎         | 41/1577 [00:21<08:28,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 41: train loss 2.55179. lr 5.997393e-04:   3%|▎         | 42/1577 [00:21<08:28,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 42: train loss 2.53752. lr 5.997267e-04:   3%|▎         | 42/1577 [00:21<08:28,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 42: train loss 2.53752. lr 5.997267e-04:   3%|▎         | 43/1577 [00:21<08:27,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 43: train loss 2.52669. lr 5.997138e-04:   3%|▎         | 43/1577 [00:21<08:27,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 43: train loss 2.52669. lr 5.997138e-04:   3%|▎         | 44/1577 [00:21<08:26,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 44: train loss 2.51552. lr 5.997006e-04:   3%|▎         | 44/1577 [00:22<08:26,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 44: train loss 2.51552. lr 5.997006e-04:   3%|▎         | 45/1577 [00:22<08:22,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 45: train loss 2.52084. lr 5.996871e-04:   3%|▎         | 45/1577 [00:22<08:22,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 45: train loss 2.52084. lr 5.996871e-04:   3%|▎         | 46/1577 [00:22<08:18,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 46: train loss 2.51638. lr 5.996733e-04:   3%|▎         | 46/1577 [00:22<08:18,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 46: train loss 2.51638. lr 5.996733e-04:   3%|▎         | 47/1577 [00:22<08:15,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 47: train loss 2.52019. lr 5.996592e-04:   3%|▎         | 47/1577 [00:22<08:15,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 47: train loss 2.52019. lr 5.996592e-04:   3%|▎         | 48/1577 [00:22<08:13,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 48: train loss 2.50359. lr 5.996448e-04:   3%|▎         | 48/1577 [00:23<08:13,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 48: train loss 2.50359. lr 5.996448e-04:   3%|▎         | 49/1577 [00:23<08:29,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 49: train loss 2.49339. lr 5.996301e-04:   3%|▎         | 49/1577 [00:23<08:29,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 49: train loss 2.49339. lr 5.996301e-04:   3%|▎         | 50/1577 [00:23<08:23,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 50: train loss 2.48365. lr 5.996151e-04:   3%|▎         | 50/1577 [00:23<08:23,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 50: train loss 2.48365. lr 5.996151e-04:   3%|▎         | 51/1577 [00:23<08:18,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 51: train loss 2.48117. lr 5.995999e-04:   3%|▎         | 51/1577 [00:24<08:18,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 51: train loss 2.48117. lr 5.995999e-04:   3%|▎         | 52/1577 [00:24<08:15,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 52: train loss 2.47668. lr 5.995843e-04:   3%|▎         | 52/1577 [00:24<08:15,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 52: train loss 2.47668. lr 5.995843e-04:   3%|▎         | 53/1577 [00:24<08:12,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 53: train loss 2.47923. lr 5.995684e-04:   3%|▎         | 53/1577 [00:24<08:12,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 53: train loss 2.47923. lr 5.995684e-04:   3%|▎         | 54/1577 [00:24<08:11,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 54: train loss 2.45520. lr 5.995522e-04:   3%|▎         | 54/1577 [00:25<08:11,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 54: train loss 2.45520. lr 5.995522e-04:   3%|▎         | 55/1577 [00:25<08:10,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 55: train loss 2.44940. lr 5.995357e-04:   3%|▎         | 55/1577 [00:25<08:10,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 55: train loss 2.44940. lr 5.995357e-04:   4%|▎         | 56/1577 [00:25<08:09,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 56: train loss 2.45892. lr 5.995190e-04:   4%|▎         | 56/1577 [00:25<08:09,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 56: train loss 2.45892. lr 5.995190e-04:   4%|▎         | 57/1577 [00:25<08:09,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 57: train loss 2.44893. lr 5.995019e-04:   4%|▎         | 57/1577 [00:26<08:09,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 57: train loss 2.44893. lr 5.995019e-04:   4%|▎         | 58/1577 [00:26<08:08,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 58: train loss 2.45877. lr 5.994845e-04:   4%|▎         | 58/1577 [00:26<08:08,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 58: train loss 2.45877. lr 5.994845e-04:   4%|▎         | 59/1577 [00:26<08:07,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 59: train loss 2.44400. lr 5.994669e-04:   4%|▎         | 59/1577 [00:26<08:07,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 59: train loss 2.44400. lr 5.994669e-04:   4%|▍         | 60/1577 [00:26<08:07,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 60: train loss 2.44493. lr 5.994489e-04:   4%|▍         | 60/1577 [00:27<08:07,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 60: train loss 2.44493. lr 5.994489e-04:   4%|▍         | 61/1577 [00:27<08:06,  3.12it/s]\u001b[A\n",
      "epoch 1 iter 61: train loss 2.44253. lr 5.994307e-04:   4%|▍         | 61/1577 [00:27<08:06,  3.12it/s]\u001b[A\n",
      "epoch 1 iter 61: train loss 2.44253. lr 5.994307e-04:   4%|▍         | 62/1577 [00:27<08:06,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 62: train loss 2.43038. lr 5.994121e-04:   4%|▍         | 62/1577 [00:27<08:06,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 62: train loss 2.43038. lr 5.994121e-04:   4%|▍         | 63/1577 [00:27<08:20,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 63: train loss 2.44139. lr 5.993932e-04:   4%|▍         | 63/1577 [00:28<08:20,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 63: train loss 2.44139. lr 5.993932e-04:   4%|▍         | 64/1577 [00:28<08:16,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 64: train loss 2.43622. lr 5.993741e-04:   4%|▍         | 64/1577 [00:28<08:16,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 64: train loss 2.43622. lr 5.993741e-04:   4%|▍         | 65/1577 [00:28<08:13,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 65: train loss 2.43819. lr 5.993546e-04:   4%|▍         | 65/1577 [00:28<08:13,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 65: train loss 2.43819. lr 5.993546e-04:   4%|▍         | 66/1577 [00:28<08:10,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 66: train loss 2.42154. lr 5.993349e-04:   4%|▍         | 66/1577 [00:29<08:10,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 66: train loss 2.42154. lr 5.993349e-04:   4%|▍         | 67/1577 [00:29<08:09,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 67: train loss 2.43774. lr 5.993149e-04:   4%|▍         | 67/1577 [00:29<08:09,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 67: train loss 2.43774. lr 5.993149e-04:   4%|▍         | 68/1577 [00:29<08:08,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 68: train loss 2.42709. lr 5.992945e-04:   4%|▍         | 68/1577 [00:29<08:08,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 68: train loss 2.42709. lr 5.992945e-04:   4%|▍         | 69/1577 [00:29<08:07,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 69: train loss 2.42808. lr 5.992739e-04:   4%|▍         | 69/1577 [00:30<08:07,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 69: train loss 2.42808. lr 5.992739e-04:   4%|▍         | 70/1577 [00:30<08:06,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 70: train loss 2.42339. lr 5.992530e-04:   4%|▍         | 70/1577 [00:30<08:06,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 70: train loss 2.42339. lr 5.992530e-04:   5%|▍         | 71/1577 [00:30<08:05,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 71: train loss 2.41644. lr 5.992317e-04:   5%|▍         | 71/1577 [00:30<08:05,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 71: train loss 2.41644. lr 5.992317e-04:   5%|▍         | 72/1577 [00:30<08:04,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 72: train loss 2.42667. lr 5.992102e-04:   5%|▍         | 72/1577 [00:31<08:04,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 72: train loss 2.42667. lr 5.992102e-04:   5%|▍         | 73/1577 [00:31<08:04,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 73: train loss 2.40738. lr 5.991884e-04:   5%|▍         | 73/1577 [00:31<08:04,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 73: train loss 2.40738. lr 5.991884e-04:   5%|▍         | 74/1577 [00:31<08:03,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 74: train loss 2.42002. lr 5.991663e-04:   5%|▍         | 74/1577 [00:31<08:03,  3.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 74: train loss 2.42002. lr 5.991663e-04:   5%|▍         | 75/1577 [00:31<08:03,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 75: train loss 2.41512. lr 5.991438e-04:   5%|▍         | 75/1577 [00:32<08:03,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 75: train loss 2.41512. lr 5.991438e-04:   5%|▍         | 76/1577 [00:32<08:03,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 76: train loss 2.39270. lr 5.991211e-04:   5%|▍         | 76/1577 [00:32<08:03,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 76: train loss 2.39270. lr 5.991211e-04:   5%|▍         | 77/1577 [00:32<08:03,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 77: train loss 2.39834. lr 5.990981e-04:   5%|▍         | 77/1577 [00:32<08:03,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 77: train loss 2.39834. lr 5.990981e-04:   5%|▍         | 78/1577 [00:32<08:16,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 78: train loss 2.40575. lr 5.990748e-04:   5%|▍         | 78/1577 [00:33<08:16,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 78: train loss 2.40575. lr 5.990748e-04:   5%|▌         | 79/1577 [00:33<08:12,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 79: train loss 2.40202. lr 5.990512e-04:   5%|▌         | 79/1577 [00:33<08:12,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 79: train loss 2.40202. lr 5.990512e-04:   5%|▌         | 80/1577 [00:33<08:10,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 80: train loss 2.40501. lr 5.990273e-04:   5%|▌         | 80/1577 [00:33<08:10,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 80: train loss 2.40501. lr 5.990273e-04:   5%|▌         | 81/1577 [00:33<08:07,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 81: train loss 2.39432. lr 5.990031e-04:   5%|▌         | 81/1577 [00:34<08:07,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 81: train loss 2.39432. lr 5.990031e-04:   5%|▌         | 82/1577 [00:34<08:05,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 82: train loss 2.39258. lr 5.989786e-04:   5%|▌         | 82/1577 [00:34<08:05,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 82: train loss 2.39258. lr 5.989786e-04:   5%|▌         | 83/1577 [00:34<08:03,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 83: train loss 2.40785. lr 5.989538e-04:   5%|▌         | 83/1577 [00:34<08:03,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 83: train loss 2.40785. lr 5.989538e-04:   5%|▌         | 84/1577 [00:34<08:02,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 84: train loss 2.38552. lr 5.989287e-04:   5%|▌         | 84/1577 [00:34<08:02,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 84: train loss 2.38552. lr 5.989287e-04:   5%|▌         | 85/1577 [00:34<08:00,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 85: train loss 2.40150. lr 5.989033e-04:   5%|▌         | 85/1577 [00:35<08:00,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 85: train loss 2.40150. lr 5.989033e-04:   5%|▌         | 86/1577 [00:35<07:59,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 86: train loss 2.38079. lr 5.988776e-04:   5%|▌         | 86/1577 [00:35<07:59,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 86: train loss 2.38079. lr 5.988776e-04:   6%|▌         | 87/1577 [00:35<07:58,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 87: train loss 2.38531. lr 5.988517e-04:   6%|▌         | 87/1577 [00:35<07:58,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 87: train loss 2.38531. lr 5.988517e-04:   6%|▌         | 88/1577 [00:35<07:59,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 88: train loss 2.37633. lr 5.988254e-04:   6%|▌         | 88/1577 [00:36<07:59,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 88: train loss 2.37633. lr 5.988254e-04:   6%|▌         | 89/1577 [00:36<07:59,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 89: train loss 2.38438. lr 5.987988e-04:   6%|▌         | 89/1577 [00:36<07:59,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 89: train loss 2.38438. lr 5.987988e-04:   6%|▌         | 90/1577 [00:36<07:58,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 90: train loss 2.38827. lr 5.987719e-04:   6%|▌         | 90/1577 [00:36<07:58,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 90: train loss 2.38827. lr 5.987719e-04:   6%|▌         | 91/1577 [00:36<07:57,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 91: train loss 2.37144. lr 5.987448e-04:   6%|▌         | 91/1577 [00:37<07:57,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 91: train loss 2.37144. lr 5.987448e-04:   6%|▌         | 92/1577 [00:37<07:57,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 92: train loss 2.38999. lr 5.987173e-04:   6%|▌         | 92/1577 [00:37<07:57,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 92: train loss 2.38999. lr 5.987173e-04:   6%|▌         | 93/1577 [00:37<08:12,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 93: train loss 2.37697. lr 5.986896e-04:   6%|▌         | 93/1577 [00:37<08:12,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 93: train loss 2.37697. lr 5.986896e-04:   6%|▌         | 94/1577 [00:37<08:07,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 94: train loss 2.37488. lr 5.986615e-04:   6%|▌         | 94/1577 [00:38<08:07,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 94: train loss 2.37488. lr 5.986615e-04:   6%|▌         | 95/1577 [00:38<08:03,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 95: train loss 2.37211. lr 5.986331e-04:   6%|▌         | 95/1577 [00:38<08:03,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 95: train loss 2.37211. lr 5.986331e-04:   6%|▌         | 96/1577 [00:38<08:01,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 96: train loss 2.38149. lr 5.986045e-04:   6%|▌         | 96/1577 [00:38<08:01,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 96: train loss 2.38149. lr 5.986045e-04:   6%|▌         | 97/1577 [00:38<07:59,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 97: train loss 2.37899. lr 5.985756e-04:   6%|▌         | 97/1577 [00:39<07:59,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 97: train loss 2.37899. lr 5.985756e-04:   6%|▌         | 98/1577 [00:39<07:58,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 98: train loss 2.41084. lr 5.985463e-04:   6%|▌         | 98/1577 [00:39<07:58,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 98: train loss 2.41084. lr 5.985463e-04:   6%|▋         | 99/1577 [00:39<07:57,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 99: train loss 2.39313. lr 5.985168e-04:   6%|▋         | 99/1577 [00:39<07:57,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 99: train loss 2.39313. lr 5.985168e-04:   6%|▋         | 100/1577 [00:39<07:56,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 100: train loss 2.37312. lr 5.984869e-04:   6%|▋         | 100/1577 [00:40<07:56,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 100: train loss 2.37312. lr 5.984869e-04:   6%|▋         | 101/1577 [00:40<07:55,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 101: train loss 2.38807. lr 5.984568e-04:   6%|▋         | 101/1577 [00:40<07:55,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 101: train loss 2.38807. lr 5.984568e-04:   6%|▋         | 102/1577 [00:40<07:54,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 102: train loss 2.37653. lr 5.984264e-04:   6%|▋         | 102/1577 [00:40<07:54,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 102: train loss 2.37653. lr 5.984264e-04:   7%|▋         | 103/1577 [00:40<07:54,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 103: train loss 2.37331. lr 5.983957e-04:   7%|▋         | 103/1577 [00:41<07:54,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 103: train loss 2.37331. lr 5.983957e-04:   7%|▋         | 104/1577 [00:41<07:53,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 104: train loss 2.37704. lr 5.983646e-04:   7%|▋         | 104/1577 [00:41<07:53,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 104: train loss 2.37704. lr 5.983646e-04:   7%|▋         | 105/1577 [00:41<07:53,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 105: train loss 2.36518. lr 5.983333e-04:   7%|▋         | 105/1577 [00:41<07:53,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 105: train loss 2.36518. lr 5.983333e-04:   7%|▋         | 106/1577 [00:41<07:53,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 106: train loss 2.36747. lr 5.983017e-04:   7%|▋         | 106/1577 [00:42<07:53,  3.11it/s]\u001b[A\n",
      "epoch 1 iter 106: train loss 2.36747. lr 5.983017e-04:   7%|▋         | 107/1577 [00:42<07:53,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 107: train loss 2.36383. lr 5.982698e-04:   7%|▋         | 107/1577 [00:42<07:53,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 107: train loss 2.36383. lr 5.982698e-04:   7%|▋         | 108/1577 [00:42<08:06,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 108: train loss 2.37334. lr 5.982376e-04:   7%|▋         | 108/1577 [00:42<08:06,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 108: train loss 2.37334. lr 5.982376e-04:   7%|▋         | 109/1577 [00:42<08:01,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 109: train loss 2.36590. lr 5.982051e-04:   7%|▋         | 109/1577 [00:43<08:01,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 109: train loss 2.36590. lr 5.982051e-04:   7%|▋         | 110/1577 [00:43<07:59,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 110: train loss 2.35806. lr 5.981723e-04:   7%|▋         | 110/1577 [00:43<07:59,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 110: train loss 2.35806. lr 5.981723e-04:   7%|▋         | 111/1577 [00:43<07:57,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 111: train loss 2.35714. lr 5.981392e-04:   7%|▋         | 111/1577 [00:43<07:57,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 111: train loss 2.35714. lr 5.981392e-04:   7%|▋         | 112/1577 [00:43<07:55,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 112: train loss 2.35460. lr 5.981058e-04:   7%|▋         | 112/1577 [00:44<07:55,  3.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 112: train loss 2.35460. lr 5.981058e-04:   7%|▋         | 113/1577 [00:44<07:54,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 113: train loss 2.36220. lr 5.980721e-04:   7%|▋         | 113/1577 [00:44<07:54,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 113: train loss 2.36220. lr 5.980721e-04:   7%|▋         | 114/1577 [00:44<07:54,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 114: train loss 2.36341. lr 5.980382e-04:   7%|▋         | 114/1577 [00:44<07:54,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 114: train loss 2.36341. lr 5.980382e-04:   7%|▋         | 115/1577 [00:44<07:53,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 115: train loss 2.36236. lr 5.980039e-04:   7%|▋         | 115/1577 [00:45<07:53,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 115: train loss 2.36236. lr 5.980039e-04:   7%|▋         | 116/1577 [00:45<07:51,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 116: train loss 2.35596. lr 5.979693e-04:   7%|▋         | 116/1577 [00:45<07:51,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 116: train loss 2.35596. lr 5.979693e-04:   7%|▋         | 117/1577 [00:45<07:51,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 117: train loss 2.35772. lr 5.979344e-04:   7%|▋         | 117/1577 [00:45<07:51,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 117: train loss 2.35772. lr 5.979344e-04:   7%|▋         | 118/1577 [00:45<07:50,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 118: train loss 2.34587. lr 5.978993e-04:   7%|▋         | 118/1577 [00:45<07:50,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 118: train loss 2.34587. lr 5.978993e-04:   8%|▊         | 119/1577 [00:46<07:50,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 119: train loss 2.36901. lr 5.978638e-04:   8%|▊         | 119/1577 [00:46<07:50,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 119: train loss 2.36901. lr 5.978638e-04:   8%|▊         | 120/1577 [00:46<07:50,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 120: train loss 2.34394. lr 5.978281e-04:   8%|▊         | 120/1577 [00:46<07:50,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 120: train loss 2.34394. lr 5.978281e-04:   8%|▊         | 121/1577 [00:46<07:49,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 121: train loss 2.33915. lr 5.977920e-04:   8%|▊         | 121/1577 [00:46<07:49,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 121: train loss 2.33915. lr 5.977920e-04:   8%|▊         | 122/1577 [00:46<08:01,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 122: train loss 2.35220. lr 5.977557e-04:   8%|▊         | 122/1577 [00:47<08:01,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 122: train loss 2.35220. lr 5.977557e-04:   8%|▊         | 123/1577 [00:47<07:56,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 123: train loss 2.34712. lr 5.977190e-04:   8%|▊         | 123/1577 [00:47<07:56,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 123: train loss 2.34712. lr 5.977190e-04:   8%|▊         | 124/1577 [00:47<07:54,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 124: train loss 2.35126. lr 5.976821e-04:   8%|▊         | 124/1577 [00:47<07:54,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 124: train loss 2.35126. lr 5.976821e-04:   8%|▊         | 125/1577 [00:47<07:52,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 125: train loss 2.34505. lr 5.976448e-04:   8%|▊         | 125/1577 [00:48<07:52,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 125: train loss 2.34505. lr 5.976448e-04:   8%|▊         | 126/1577 [00:48<07:50,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 2.33808. lr 5.976073e-04:   8%|▊         | 126/1577 [00:48<07:50,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 2.33808. lr 5.976073e-04:   8%|▊         | 127/1577 [00:48<07:49,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 2.34428. lr 5.975695e-04:   8%|▊         | 127/1577 [00:48<07:49,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 2.34428. lr 5.975695e-04:   8%|▊         | 128/1577 [00:48<07:49,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 2.33593. lr 5.975314e-04:   8%|▊         | 128/1577 [00:49<07:49,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 2.33593. lr 5.975314e-04:   8%|▊         | 129/1577 [00:49<07:48,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 2.34159. lr 5.974930e-04:   8%|▊         | 129/1577 [00:49<07:48,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 2.34159. lr 5.974930e-04:   8%|▊         | 130/1577 [00:49<07:47,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 2.34028. lr 5.974543e-04:   8%|▊         | 130/1577 [00:49<07:47,  3.10it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 2.34028. lr 5.974543e-04:   8%|▊         | 131/1577 [00:49<07:47,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 2.33025. lr 5.974152e-04:   8%|▊         | 131/1577 [00:50<07:47,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 2.33025. lr 5.974152e-04:   8%|▊         | 132/1577 [00:50<07:47,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 2.32761. lr 5.973759e-04:   8%|▊         | 132/1577 [00:50<07:47,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 2.32761. lr 5.973759e-04:   8%|▊         | 133/1577 [00:50<07:47,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 2.33621. lr 5.973363e-04:   8%|▊         | 133/1577 [00:50<07:47,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 2.33621. lr 5.973363e-04:   8%|▊         | 134/1577 [00:50<07:46,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 2.32317. lr 5.972965e-04:   8%|▊         | 134/1577 [00:51<07:46,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 2.32317. lr 5.972965e-04:   9%|▊         | 135/1577 [00:51<07:47,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 2.32833. lr 5.972563e-04:   9%|▊         | 135/1577 [00:51<07:47,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 2.32833. lr 5.972563e-04:   9%|▊         | 136/1577 [00:51<07:49,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 2.32818. lr 5.972158e-04:   9%|▊         | 136/1577 [00:51<07:49,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 2.32818. lr 5.972158e-04:   9%|▊         | 137/1577 [00:51<08:03,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 2.30012. lr 5.971750e-04:   9%|▊         | 137/1577 [00:52<08:03,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 2.30012. lr 5.971750e-04:   9%|▉         | 138/1577 [00:52<07:58,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 2.32709. lr 5.971339e-04:   9%|▉         | 138/1577 [00:52<07:58,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 2.32709. lr 5.971339e-04:   9%|▉         | 139/1577 [00:52<07:54,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 2.31540. lr 5.970926e-04:   9%|▉         | 139/1577 [00:52<07:54,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 2.31540. lr 5.970926e-04:   9%|▉         | 140/1577 [00:52<07:51,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 2.33511. lr 5.970509e-04:   9%|▉         | 140/1577 [00:53<07:51,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 2.33511. lr 5.970509e-04:   9%|▉         | 141/1577 [00:53<07:49,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 2.31549. lr 5.970090e-04:   9%|▉         | 141/1577 [00:53<07:49,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 2.31549. lr 5.970090e-04:   9%|▉         | 142/1577 [00:53<07:47,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 2.31424. lr 5.969667e-04:   9%|▉         | 142/1577 [00:53<07:47,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 2.31424. lr 5.969667e-04:   9%|▉         | 143/1577 [00:53<07:46,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 2.32207. lr 5.969242e-04:   9%|▉         | 143/1577 [00:54<07:46,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 2.32207. lr 5.969242e-04:   9%|▉         | 144/1577 [00:54<07:46,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 2.30123. lr 5.968813e-04:   9%|▉         | 144/1577 [00:54<07:46,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 2.30123. lr 5.968813e-04:   9%|▉         | 145/1577 [00:54<07:45,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 2.31823. lr 5.968382e-04:   9%|▉         | 145/1577 [00:54<07:45,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 2.31823. lr 5.968382e-04:   9%|▉         | 146/1577 [00:54<07:45,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 2.30577. lr 5.967948e-04:   9%|▉         | 146/1577 [00:55<07:45,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 2.30577. lr 5.967948e-04:   9%|▉         | 147/1577 [00:55<07:44,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 2.30125. lr 5.967510e-04:   9%|▉         | 147/1577 [00:55<07:44,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 2.30125. lr 5.967510e-04:   9%|▉         | 148/1577 [00:55<07:43,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 2.29735. lr 5.967070e-04:   9%|▉         | 148/1577 [00:55<07:43,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 2.29735. lr 5.967070e-04:   9%|▉         | 149/1577 [00:55<07:43,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 2.29806. lr 5.966627e-04:   9%|▉         | 149/1577 [00:56<07:43,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 2.29806. lr 5.966627e-04:  10%|▉         | 150/1577 [00:56<07:42,  3.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 150: train loss 2.29992. lr 5.966181e-04:  10%|▉         | 150/1577 [00:56<07:42,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 150: train loss 2.29992. lr 5.966181e-04:  10%|▉         | 151/1577 [00:56<07:42,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 2.29312. lr 5.965732e-04:  10%|▉         | 151/1577 [00:56<07:42,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 2.29312. lr 5.965732e-04:  10%|▉         | 152/1577 [00:56<07:55,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 2.30017. lr 5.965280e-04:  10%|▉         | 152/1577 [00:57<07:55,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 2.30017. lr 5.965280e-04:  10%|▉         | 153/1577 [00:57<07:51,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 2.29256. lr 5.964825e-04:  10%|▉         | 153/1577 [00:57<07:51,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 2.29256. lr 5.964825e-04:  10%|▉         | 154/1577 [00:57<07:47,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 2.29124. lr 5.964367e-04:  10%|▉         | 154/1577 [00:57<07:47,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 2.29124. lr 5.964367e-04:  10%|▉         | 155/1577 [00:57<07:45,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 2.29552. lr 5.963906e-04:  10%|▉         | 155/1577 [00:58<07:45,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 2.29552. lr 5.963906e-04:  10%|▉         | 156/1577 [00:58<07:43,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 2.29138. lr 5.963443e-04:  10%|▉         | 156/1577 [00:58<07:43,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 2.29138. lr 5.963443e-04:  10%|▉         | 157/1577 [00:58<07:42,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 2.29855. lr 5.962976e-04:  10%|▉         | 157/1577 [00:58<07:42,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 2.29855. lr 5.962976e-04:  10%|█         | 158/1577 [00:58<07:41,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 2.29627. lr 5.962506e-04:  10%|█         | 158/1577 [00:59<07:41,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 2.29627. lr 5.962506e-04:  10%|█         | 159/1577 [00:59<07:41,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 2.28675. lr 5.962034e-04:  10%|█         | 159/1577 [00:59<07:41,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 2.28675. lr 5.962034e-04:  10%|█         | 160/1577 [00:59<07:40,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 2.28028. lr 5.961558e-04:  10%|█         | 160/1577 [00:59<07:40,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 2.28028. lr 5.961558e-04:  10%|█         | 161/1577 [00:59<07:39,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 2.30013. lr 5.961080e-04:  10%|█         | 161/1577 [01:00<07:39,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 2.30013. lr 5.961080e-04:  10%|█         | 162/1577 [01:00<07:39,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 2.29136. lr 5.960598e-04:  10%|█         | 162/1577 [01:00<07:39,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 2.29136. lr 5.960598e-04:  10%|█         | 163/1577 [01:00<07:38,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 2.27322. lr 5.960114e-04:  10%|█         | 163/1577 [01:00<07:38,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 2.27322. lr 5.960114e-04:  10%|█         | 164/1577 [01:00<07:38,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 2.26536. lr 5.959627e-04:  10%|█         | 164/1577 [01:00<07:38,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 2.26536. lr 5.959627e-04:  10%|█         | 165/1577 [01:00<07:37,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 2.28151. lr 5.959137e-04:  10%|█         | 165/1577 [01:01<07:37,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 2.28151. lr 5.959137e-04:  11%|█         | 166/1577 [01:01<07:37,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 2.27489. lr 5.958643e-04:  11%|█         | 166/1577 [01:01<07:37,  3.09it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 2.27489. lr 5.958643e-04:  11%|█         | 167/1577 [01:01<07:50,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 2.26970. lr 5.958147e-04:  11%|█         | 167/1577 [01:01<07:50,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 2.26970. lr 5.958147e-04:  11%|█         | 168/1577 [01:01<07:46,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 2.27191. lr 5.957648e-04:  11%|█         | 168/1577 [01:02<07:46,  3.02it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 2.27191. lr 5.957648e-04:  11%|█         | 169/1577 [01:02<07:42,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 2.26447. lr 5.957146e-04:  11%|█         | 169/1577 [01:02<07:42,  3.04it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 2.26447. lr 5.957146e-04:  11%|█         | 170/1577 [01:02<07:40,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 2.26692. lr 5.956642e-04:  11%|█         | 170/1577 [01:02<07:40,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 2.26692. lr 5.956642e-04:  11%|█         | 171/1577 [01:02<07:38,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 2.25677. lr 5.956134e-04:  11%|█         | 171/1577 [01:03<07:38,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 2.25677. lr 5.956134e-04:  11%|█         | 172/1577 [01:03<07:37,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 2.24877. lr 5.955623e-04:  11%|█         | 172/1577 [01:03<07:37,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 2.24877. lr 5.955623e-04:  11%|█         | 173/1577 [01:03<07:36,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 2.26548. lr 5.955109e-04:  11%|█         | 173/1577 [01:03<07:36,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 2.26548. lr 5.955109e-04:  11%|█         | 174/1577 [01:03<07:35,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 2.25485. lr 5.954593e-04:  11%|█         | 174/1577 [01:04<07:35,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 2.25485. lr 5.954593e-04:  11%|█         | 175/1577 [01:04<07:34,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 2.28238. lr 5.954073e-04:  11%|█         | 175/1577 [01:04<07:34,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 2.28238. lr 5.954073e-04:  11%|█         | 176/1577 [01:04<07:34,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 2.26589. lr 5.953551e-04:  11%|█         | 176/1577 [01:04<07:34,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 2.26589. lr 5.953551e-04:  11%|█         | 177/1577 [01:04<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 2.26913. lr 5.953025e-04:  11%|█         | 177/1577 [01:05<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 2.26913. lr 5.953025e-04:  11%|█▏        | 178/1577 [01:05<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 2.24185. lr 5.952497e-04:  11%|█▏        | 178/1577 [01:05<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 2.24185. lr 5.952497e-04:  11%|█▏        | 179/1577 [01:05<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 2.25993. lr 5.951966e-04:  11%|█▏        | 179/1577 [01:05<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 2.25993. lr 5.951966e-04:  11%|█▏        | 180/1577 [01:05<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 2.24100. lr 5.951431e-04:  11%|█▏        | 180/1577 [01:06<07:33,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 2.24100. lr 5.951431e-04:  11%|█▏        | 181/1577 [01:06<07:45,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 2.24032. lr 5.950894e-04:  11%|█▏        | 181/1577 [01:06<07:45,  3.00it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 2.24032. lr 5.950894e-04:  12%|█▏        | 182/1577 [01:06<07:42,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 2.24306. lr 5.950354e-04:  12%|█▏        | 182/1577 [01:06<07:42,  3.01it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 2.24306. lr 5.950354e-04:  12%|█▏        | 183/1577 [01:06<07:39,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 2.23460. lr 5.949811e-04:  12%|█▏        | 183/1577 [01:07<07:39,  3.03it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 2.23460. lr 5.949811e-04:  12%|█▏        | 184/1577 [01:07<07:36,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 2.23720. lr 5.949265e-04:  12%|█▏        | 184/1577 [01:07<07:36,  3.05it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 2.23720. lr 5.949265e-04:  12%|█▏        | 185/1577 [01:07<07:35,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 2.23185. lr 5.948716e-04:  12%|█▏        | 185/1577 [01:07<07:35,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 2.23185. lr 5.948716e-04:  12%|█▏        | 186/1577 [01:07<07:34,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 2.22691. lr 5.948165e-04:  12%|█▏        | 186/1577 [01:08<07:34,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 2.22691. lr 5.948165e-04:  12%|█▏        | 187/1577 [01:08<07:33,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 187: train loss 2.23489. lr 5.947610e-04:  12%|█▏        | 187/1577 [01:08<07:33,  3.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 187: train loss 2.23489. lr 5.947610e-04:  12%|█▏        | 188/1577 [01:08<07:33,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 2.22899. lr 5.947052e-04:  12%|█▏        | 188/1577 [01:08<07:33,  3.06it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 2.22899. lr 5.947052e-04:  12%|█▏        | 189/1577 [01:08<07:32,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 2.23048. lr 5.946492e-04:  12%|█▏        | 189/1577 [01:09<07:32,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 2.23048. lr 5.946492e-04:  12%|█▏        | 190/1577 [01:09<07:31,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 2.23484. lr 5.945928e-04:  12%|█▏        | 190/1577 [01:09<07:31,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 2.23484. lr 5.945928e-04:  12%|█▏        | 191/1577 [01:09<07:31,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 2.22491. lr 5.945362e-04:  12%|█▏        | 191/1577 [01:09<07:31,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 2.22491. lr 5.945362e-04:  12%|█▏        | 192/1577 [01:09<07:30,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 2.22820. lr 5.944792e-04:  12%|█▏        | 192/1577 [01:10<07:30,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 2.22820. lr 5.944792e-04:  12%|█▏        | 193/1577 [01:10<07:29,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 2.23544. lr 5.944220e-04:  12%|█▏        | 193/1577 [01:10<07:29,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 2.23544. lr 5.944220e-04:  12%|█▏        | 194/1577 [01:10<07:30,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 2.21403. lr 5.943645e-04:  12%|█▏        | 194/1577 [01:10<07:30,  3.07it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 2.21403. lr 5.943645e-04:  12%|█▏        | 195/1577 [01:10<07:29,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 2.22692. lr 5.943067e-04:  12%|█▏        | 195/1577 [01:11<07:29,  3.08it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 2.22692. lr 5.943067e-04:  12%|█▏        | 196/1577 [01:11<07:44,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 2.19914. lr 5.942486e-04:  12%|█▏        | 196/1577 [01:11<07:44,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 2.19914. lr 5.942486e-04:  12%|█▏        | 197/1577 [01:11<07:41,  2.99it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 2.20991. lr 5.941902e-04:  12%|█▏        | 197/1577 [01:11<07:41,  2.99it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 2.20991. lr 5.941902e-04:  13%|█▎        | 198/1577 [01:11<07:42,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 2.18590. lr 5.941315e-04:  13%|█▎        | 198/1577 [01:12<07:42,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 2.18590. lr 5.941315e-04:  13%|█▎        | 199/1577 [01:12<07:42,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 2.20179. lr 5.940725e-04:  13%|█▎        | 199/1577 [01:12<07:42,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 2.20179. lr 5.940725e-04:  13%|█▎        | 200/1577 [01:12<07:41,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 2.19966. lr 5.940132e-04:  13%|█▎        | 200/1577 [01:12<07:41,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 2.19966. lr 5.940132e-04:  13%|█▎        | 201/1577 [01:12<07:41,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 2.18479. lr 5.939537e-04:  13%|█▎        | 201/1577 [01:13<07:41,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 2.18479. lr 5.939537e-04:  13%|█▎        | 202/1577 [01:13<07:40,  2.99it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 2.18859. lr 5.938938e-04:  13%|█▎        | 202/1577 [01:13<07:40,  2.99it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 2.18859. lr 5.938938e-04:  13%|█▎        | 203/1577 [01:13<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 2.18075. lr 5.938337e-04:  13%|█▎        | 203/1577 [01:13<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 2.18075. lr 5.938337e-04:  13%|█▎        | 204/1577 [01:13<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 2.18751. lr 5.937732e-04:  13%|█▎        | 204/1577 [01:14<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 2.18751. lr 5.937732e-04:  13%|█▎        | 205/1577 [01:14<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 2.17205. lr 5.937125e-04:  13%|█▎        | 205/1577 [01:14<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 2.17205. lr 5.937125e-04:  13%|█▎        | 206/1577 [01:14<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 2.19219. lr 5.936515e-04:  13%|█▎        | 206/1577 [01:14<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 2.19219. lr 5.936515e-04:  13%|█▎        | 207/1577 [01:14<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 2.16737. lr 5.935902e-04:  13%|█▎        | 207/1577 [01:15<07:40,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 2.16737. lr 5.935902e-04:  13%|█▎        | 208/1577 [01:15<07:40,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 2.18619. lr 5.935286e-04:  13%|█▎        | 208/1577 [01:15<07:40,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 2.18619. lr 5.935286e-04:  13%|█▎        | 209/1577 [01:15<07:39,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 2.17908. lr 5.934667e-04:  13%|█▎        | 209/1577 [01:15<07:39,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 2.17908. lr 5.934667e-04:  13%|█▎        | 210/1577 [01:15<07:39,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 2.15141. lr 5.934045e-04:  13%|█▎        | 210/1577 [01:16<07:39,  2.98it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 2.15141. lr 5.934045e-04:  13%|█▎        | 211/1577 [01:16<07:53,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 2.17588. lr 5.933420e-04:  13%|█▎        | 211/1577 [01:16<07:53,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 2.17588. lr 5.933420e-04:  13%|█▎        | 212/1577 [01:16<07:49,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 2.15903. lr 5.932792e-04:  13%|█▎        | 212/1577 [01:16<07:49,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 2.15903. lr 5.932792e-04:  14%|█▎        | 213/1577 [01:16<07:46,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 2.14332. lr 5.932162e-04:  14%|█▎        | 213/1577 [01:17<07:46,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 2.14332. lr 5.932162e-04:  14%|█▎        | 214/1577 [01:17<07:43,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 2.14400. lr 5.931528e-04:  14%|█▎        | 214/1577 [01:17<07:43,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 2.14400. lr 5.931528e-04:  14%|█▎        | 215/1577 [01:17<07:40,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 2.15132. lr 5.930892e-04:  14%|█▎        | 215/1577 [01:17<07:40,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 2.15132. lr 5.930892e-04:  14%|█▎        | 216/1577 [01:17<07:39,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 2.14504. lr 5.930253e-04:  14%|█▎        | 216/1577 [01:18<07:39,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 2.14504. lr 5.930253e-04:  14%|█▍        | 217/1577 [01:18<07:39,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 2.14382. lr 5.929610e-04:  14%|█▍        | 217/1577 [01:18<07:39,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 2.14382. lr 5.929610e-04:  14%|█▍        | 218/1577 [01:18<07:38,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 2.12757. lr 5.928965e-04:  14%|█▍        | 218/1577 [01:18<07:38,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 2.12757. lr 5.928965e-04:  14%|█▍        | 219/1577 [01:18<07:37,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 2.12443. lr 5.928317e-04:  14%|█▍        | 219/1577 [01:19<07:37,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 2.12443. lr 5.928317e-04:  14%|█▍        | 220/1577 [01:19<07:36,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 2.12977. lr 5.927666e-04:  14%|█▍        | 220/1577 [01:19<07:36,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 2.12977. lr 5.927666e-04:  14%|█▍        | 221/1577 [01:19<07:36,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 2.13332. lr 5.927012e-04:  14%|█▍        | 221/1577 [01:19<07:36,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 2.13332. lr 5.927012e-04:  14%|█▍        | 222/1577 [01:19<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 2.11244. lr 5.926355e-04:  14%|█▍        | 222/1577 [01:20<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 2.11244. lr 5.926355e-04:  14%|█▍        | 223/1577 [01:20<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 2.12394. lr 5.925696e-04:  14%|█▍        | 223/1577 [01:20<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 2.12394. lr 5.925696e-04:  14%|█▍        | 224/1577 [01:20<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 2.12809. lr 5.925033e-04:  14%|█▍        | 224/1577 [01:20<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 2.12809. lr 5.925033e-04:  14%|█▍        | 225/1577 [01:20<07:35,  2.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 225: train loss 2.10997. lr 5.924368e-04:  14%|█▍        | 225/1577 [01:21<07:35,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 225: train loss 2.10997. lr 5.924368e-04:  14%|█▍        | 226/1577 [01:21<07:49,  2.88it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 2.12034. lr 5.923699e-04:  14%|█▍        | 226/1577 [01:21<07:49,  2.88it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 2.12034. lr 5.923699e-04:  14%|█▍        | 227/1577 [01:21<07:44,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 2.10756. lr 5.923028e-04:  14%|█▍        | 227/1577 [01:21<07:44,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 2.10756. lr 5.923028e-04:  14%|█▍        | 228/1577 [01:21<07:40,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 2.11758. lr 5.922354e-04:  14%|█▍        | 228/1577 [01:22<07:40,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 2.11758. lr 5.922354e-04:  15%|█▍        | 229/1577 [01:22<07:38,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 2.09640. lr 5.921677e-04:  15%|█▍        | 229/1577 [01:22<07:38,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 2.09640. lr 5.921677e-04:  15%|█▍        | 230/1577 [01:22<07:35,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 2.11140. lr 5.920997e-04:  15%|█▍        | 230/1577 [01:22<07:35,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 2.11140. lr 5.920997e-04:  15%|█▍        | 231/1577 [01:22<07:34,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 2.09122. lr 5.920314e-04:  15%|█▍        | 231/1577 [01:23<07:34,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 2.09122. lr 5.920314e-04:  15%|█▍        | 232/1577 [01:23<07:33,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 2.09054. lr 5.919628e-04:  15%|█▍        | 232/1577 [01:23<07:33,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 2.09054. lr 5.919628e-04:  15%|█▍        | 233/1577 [01:23<07:32,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 2.09262. lr 5.918939e-04:  15%|█▍        | 233/1577 [01:23<07:32,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 2.09262. lr 5.918939e-04:  15%|█▍        | 234/1577 [01:23<07:32,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 2.09330. lr 5.918248e-04:  15%|█▍        | 234/1577 [01:24<07:32,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 2.09330. lr 5.918248e-04:  15%|█▍        | 235/1577 [01:24<07:32,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 2.11547. lr 5.917553e-04:  15%|█▍        | 235/1577 [01:24<07:32,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 2.11547. lr 5.917553e-04:  15%|█▍        | 236/1577 [01:24<07:32,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 2.10442. lr 5.916856e-04:  15%|█▍        | 236/1577 [01:25<07:32,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 2.10442. lr 5.916856e-04:  15%|█▌        | 237/1577 [01:25<07:31,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 2.08560. lr 5.916155e-04:  15%|█▌        | 237/1577 [01:25<07:31,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 2.08560. lr 5.916155e-04:  15%|█▌        | 238/1577 [01:25<07:31,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 2.08221. lr 5.915452e-04:  15%|█▌        | 238/1577 [01:25<07:31,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 2.08221. lr 5.915452e-04:  15%|█▌        | 239/1577 [01:25<07:31,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 2.08434. lr 5.914746e-04:  15%|█▌        | 239/1577 [01:26<07:31,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 2.08434. lr 5.914746e-04:  15%|█▌        | 240/1577 [01:26<07:45,  2.87it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 2.07179. lr 5.914037e-04:  15%|█▌        | 240/1577 [01:26<07:45,  2.87it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 2.07179. lr 5.914037e-04:  15%|█▌        | 241/1577 [01:26<07:40,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 2.08172. lr 5.913325e-04:  15%|█▌        | 241/1577 [01:26<07:40,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 2.08172. lr 5.913325e-04:  15%|█▌        | 242/1577 [01:26<07:38,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 2.06548. lr 5.912611e-04:  15%|█▌        | 242/1577 [01:27<07:38,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 2.06548. lr 5.912611e-04:  15%|█▌        | 243/1577 [01:27<07:36,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 2.05528. lr 5.911893e-04:  15%|█▌        | 243/1577 [01:27<07:36,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 2.05528. lr 5.911893e-04:  15%|█▌        | 244/1577 [01:27<07:33,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 2.06471. lr 5.911172e-04:  15%|█▌        | 244/1577 [01:27<07:33,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 2.06471. lr 5.911172e-04:  16%|█▌        | 245/1577 [01:27<07:31,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 2.04836. lr 5.910449e-04:  16%|█▌        | 245/1577 [01:28<07:31,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 2.04836. lr 5.910449e-04:  16%|█▌        | 246/1577 [01:28<07:29,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 2.04940. lr 5.909723e-04:  16%|█▌        | 246/1577 [01:28<07:29,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 2.04940. lr 5.909723e-04:  16%|█▌        | 247/1577 [01:28<07:28,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 2.06840. lr 5.908993e-04:  16%|█▌        | 247/1577 [01:28<07:28,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 2.06840. lr 5.908993e-04:  16%|█▌        | 248/1577 [01:28<07:28,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 2.06218. lr 5.908261e-04:  16%|█▌        | 248/1577 [01:29<07:28,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 2.06218. lr 5.908261e-04:  16%|█▌        | 249/1577 [01:29<07:28,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 2.04641. lr 5.907526e-04:  16%|█▌        | 249/1577 [01:29<07:28,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 2.04641. lr 5.907526e-04:  16%|█▌        | 250/1577 [01:29<07:27,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 2.04740. lr 5.906789e-04:  16%|█▌        | 250/1577 [01:29<07:27,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 2.04740. lr 5.906789e-04:  16%|█▌        | 251/1577 [01:29<07:26,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 2.03543. lr 5.906048e-04:  16%|█▌        | 251/1577 [01:30<07:26,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 2.03543. lr 5.906048e-04:  16%|█▌        | 252/1577 [01:30<07:25,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 2.05211. lr 5.905304e-04:  16%|█▌        | 252/1577 [01:30<07:25,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 2.05211. lr 5.905304e-04:  16%|█▌        | 253/1577 [01:30<07:26,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 2.03558. lr 5.904558e-04:  16%|█▌        | 253/1577 [01:30<07:26,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 2.03558. lr 5.904558e-04:  16%|█▌        | 254/1577 [01:30<07:26,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 2.03561. lr 5.903808e-04:  16%|█▌        | 254/1577 [01:31<07:26,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 2.03561. lr 5.903808e-04:  16%|█▌        | 255/1577 [01:31<07:40,  2.87it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 2.04079. lr 5.903056e-04:  16%|█▌        | 255/1577 [01:31<07:40,  2.87it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 2.04079. lr 5.903056e-04:  16%|█▌        | 256/1577 [01:31<07:35,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 2.01130. lr 5.902301e-04:  16%|█▌        | 256/1577 [01:31<07:35,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 2.01130. lr 5.902301e-04:  16%|█▋        | 257/1577 [01:31<07:31,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 2.00606. lr 5.901543e-04:  16%|█▋        | 257/1577 [01:32<07:31,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 2.00606. lr 5.901543e-04:  16%|█▋        | 258/1577 [01:32<07:29,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 2.00321. lr 5.900782e-04:  16%|█▋        | 258/1577 [01:32<07:29,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 2.00321. lr 5.900782e-04:  16%|█▋        | 259/1577 [01:32<07:28,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 2.01337. lr 5.900018e-04:  16%|█▋        | 259/1577 [01:32<07:28,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 2.01337. lr 5.900018e-04:  16%|█▋        | 260/1577 [01:32<07:26,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 1.99766. lr 5.899251e-04:  16%|█▋        | 260/1577 [01:33<07:26,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 1.99766. lr 5.899251e-04:  17%|█▋        | 261/1577 [01:33<07:25,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 2.02360. lr 5.898482e-04:  17%|█▋        | 261/1577 [01:33<07:25,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 2.02360. lr 5.898482e-04:  17%|█▋        | 262/1577 [01:33<07:24,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 262: train loss 2.00852. lr 5.897709e-04:  17%|█▋        | 262/1577 [01:33<07:24,  2.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 262: train loss 2.00852. lr 5.897709e-04:  17%|█▋        | 263/1577 [01:33<07:24,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 2.01187. lr 5.896934e-04:  17%|█▋        | 263/1577 [01:34<07:24,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 2.01187. lr 5.896934e-04:  17%|█▋        | 264/1577 [01:34<07:23,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 2.00984. lr 5.896156e-04:  17%|█▋        | 264/1577 [01:34<07:23,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 2.00984. lr 5.896156e-04:  17%|█▋        | 265/1577 [01:34<07:22,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 2.00567. lr 5.895375e-04:  17%|█▋        | 265/1577 [01:34<07:22,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 2.00567. lr 5.895375e-04:  17%|█▋        | 266/1577 [01:34<07:23,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 1.99145. lr 5.894591e-04:  17%|█▋        | 266/1577 [01:35<07:23,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 1.99145. lr 5.894591e-04:  17%|█▋        | 267/1577 [01:35<07:22,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 1.99895. lr 5.893804e-04:  17%|█▋        | 267/1577 [01:35<07:22,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 1.99895. lr 5.893804e-04:  17%|█▋        | 268/1577 [01:35<07:22,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 1.98798. lr 5.893014e-04:  17%|█▋        | 268/1577 [01:35<07:22,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 1.98798. lr 5.893014e-04:  17%|█▋        | 269/1577 [01:35<07:21,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 1.98196. lr 5.892222e-04:  17%|█▋        | 269/1577 [01:36<07:21,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 1.98196. lr 5.892222e-04:  17%|█▋        | 270/1577 [01:36<07:35,  2.87it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 1.98024. lr 5.891426e-04:  17%|█▋        | 270/1577 [01:36<07:35,  2.87it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 1.98024. lr 5.891426e-04:  17%|█▋        | 271/1577 [01:36<07:31,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 1.99172. lr 5.890628e-04:  17%|█▋        | 271/1577 [01:36<07:31,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 1.99172. lr 5.890628e-04:  17%|█▋        | 272/1577 [01:36<07:27,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 1.97587. lr 5.889827e-04:  17%|█▋        | 272/1577 [01:37<07:27,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 1.97587. lr 5.889827e-04:  17%|█▋        | 273/1577 [01:37<07:26,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 1.98506. lr 5.889023e-04:  17%|█▋        | 273/1577 [01:37<07:26,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 1.98506. lr 5.889023e-04:  17%|█▋        | 274/1577 [01:37<07:24,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 1.97769. lr 5.888216e-04:  17%|█▋        | 274/1577 [01:37<07:24,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 1.97769. lr 5.888216e-04:  17%|█▋        | 275/1577 [01:37<07:22,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 1.97250. lr 5.887406e-04:  17%|█▋        | 275/1577 [01:38<07:22,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 1.97250. lr 5.887406e-04:  18%|█▊        | 276/1577 [01:38<07:21,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 1.96443. lr 5.886593e-04:  18%|█▊        | 276/1577 [01:38<07:21,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 1.96443. lr 5.886593e-04:  18%|█▊        | 277/1577 [01:38<07:20,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 1.97209. lr 5.885778e-04:  18%|█▊        | 277/1577 [01:38<07:20,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 1.97209. lr 5.885778e-04:  18%|█▊        | 278/1577 [01:38<07:19,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 1.98007. lr 5.884959e-04:  18%|█▊        | 278/1577 [01:39<07:19,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 1.98007. lr 5.884959e-04:  18%|█▊        | 279/1577 [01:39<07:18,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 1.94954. lr 5.884138e-04:  18%|█▊        | 279/1577 [01:39<07:18,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 1.94954. lr 5.884138e-04:  18%|█▊        | 280/1577 [01:39<07:17,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 1.95423. lr 5.883314e-04:  18%|█▊        | 280/1577 [01:39<07:17,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 1.95423. lr 5.883314e-04:  18%|█▊        | 281/1577 [01:39<07:16,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 1.95459. lr 5.882487e-04:  18%|█▊        | 281/1577 [01:40<07:16,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 1.95459. lr 5.882487e-04:  18%|█▊        | 282/1577 [01:40<07:16,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 1.94212. lr 5.881657e-04:  18%|█▊        | 282/1577 [01:40<07:16,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 1.94212. lr 5.881657e-04:  18%|█▊        | 283/1577 [01:40<07:16,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 1.93690. lr 5.880825e-04:  18%|█▊        | 283/1577 [01:40<07:16,  2.97it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 1.93690. lr 5.880825e-04:  18%|█▊        | 284/1577 [01:40<07:16,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 1.93439. lr 5.879989e-04:  18%|█▊        | 284/1577 [01:41<07:16,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 1.93439. lr 5.879989e-04:  18%|█▊        | 285/1577 [01:41<07:33,  2.85it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 1.93786. lr 5.879151e-04:  18%|█▊        | 285/1577 [01:41<07:33,  2.85it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 1.93786. lr 5.879151e-04:  18%|█▊        | 286/1577 [01:41<07:27,  2.88it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 1.92806. lr 5.878309e-04:  18%|█▊        | 286/1577 [01:42<07:27,  2.88it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 1.92806. lr 5.878309e-04:  18%|█▊        | 287/1577 [01:42<07:24,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 1.91990. lr 5.877465e-04:  18%|█▊        | 287/1577 [01:42<07:24,  2.90it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 1.91990. lr 5.877465e-04:  18%|█▊        | 288/1577 [01:42<07:21,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 1.94610. lr 5.876618e-04:  18%|█▊        | 288/1577 [01:42<07:21,  2.92it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 1.94610. lr 5.876618e-04:  18%|█▊        | 289/1577 [01:42<07:19,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 1.92234. lr 5.875768e-04:  18%|█▊        | 289/1577 [01:43<07:19,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 1.92234. lr 5.875768e-04:  18%|█▊        | 290/1577 [01:43<07:18,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 1.93260. lr 5.874916e-04:  18%|█▊        | 290/1577 [01:43<07:18,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 1.93260. lr 5.874916e-04:  18%|█▊        | 291/1577 [01:43<07:17,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 1.91336. lr 5.874060e-04:  18%|█▊        | 291/1577 [01:43<07:17,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 1.91336. lr 5.874060e-04:  19%|█▊        | 292/1577 [01:43<07:16,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 1.91926. lr 5.873202e-04:  19%|█▊        | 292/1577 [01:44<07:16,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 1.91926. lr 5.873202e-04:  19%|█▊        | 293/1577 [01:44<07:14,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 1.90383. lr 5.872340e-04:  19%|█▊        | 293/1577 [01:44<07:14,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 1.90383. lr 5.872340e-04:  19%|█▊        | 294/1577 [01:44<07:14,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 1.91470. lr 5.871476e-04:  19%|█▊        | 294/1577 [01:44<07:14,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 1.91470. lr 5.871476e-04:  19%|█▊        | 295/1577 [01:44<07:13,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 1.90837. lr 5.870609e-04:  19%|█▊        | 295/1577 [01:45<07:13,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 1.90837. lr 5.870609e-04:  19%|█▉        | 296/1577 [01:45<07:12,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 1.89258. lr 5.869740e-04:  19%|█▉        | 296/1577 [01:45<07:12,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 1.89258. lr 5.869740e-04:  19%|█▉        | 297/1577 [01:45<07:12,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 1.90536. lr 5.868867e-04:  19%|█▉        | 297/1577 [01:45<07:12,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 1.90536. lr 5.868867e-04:  19%|█▉        | 298/1577 [01:45<07:12,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 1.90578. lr 5.867991e-04:  19%|█▉        | 298/1577 [01:46<07:12,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 1.90578. lr 5.867991e-04:  19%|█▉        | 299/1577 [01:46<07:26,  2.86it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 1.88870. lr 5.867113e-04:  19%|█▉        | 299/1577 [01:46<07:26,  2.86it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 1.88870. lr 5.867113e-04:  19%|█▉        | 300/1577 [01:46<07:21,  2.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 300: train loss 1.89722. lr 5.866232e-04:  19%|█▉        | 300/1577 [01:46<07:21,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 300: train loss 1.89722. lr 5.866232e-04:  19%|█▉        | 301/1577 [01:46<07:17,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 1.89727. lr 5.865348e-04:  19%|█▉        | 301/1577 [01:47<07:17,  2.91it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 1.89727. lr 5.865348e-04:  19%|█▉        | 302/1577 [01:47<07:15,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 1.90420. lr 5.864461e-04:  19%|█▉        | 302/1577 [01:47<07:15,  2.93it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 1.90420. lr 5.864461e-04:  19%|█▉        | 303/1577 [01:47<07:13,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 1.88084. lr 5.863571e-04:  19%|█▉        | 303/1577 [01:47<07:13,  2.94it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 1.88084. lr 5.863571e-04:  19%|█▉        | 304/1577 [01:47<07:12,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 1.88391. lr 5.862679e-04:  19%|█▉        | 304/1577 [01:48<07:12,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 1.88391. lr 5.862679e-04:  19%|█▉        | 305/1577 [01:48<07:11,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 1.88399. lr 5.861783e-04:  19%|█▉        | 305/1577 [01:48<07:11,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 1.88399. lr 5.861783e-04:  19%|█▉        | 306/1577 [01:48<07:10,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 1.87787. lr 5.860885e-04:  19%|█▉        | 306/1577 [01:48<07:10,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 1.87787. lr 5.860885e-04:  19%|█▉        | 307/1577 [01:48<07:10,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 1.88798. lr 5.859984e-04:  19%|█▉        | 307/1577 [01:49<07:10,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 1.88798. lr 5.859984e-04:  20%|█▉        | 308/1577 [01:49<07:09,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 1.87734. lr 5.859080e-04:  20%|█▉        | 308/1577 [01:49<07:09,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 1.87734. lr 5.859080e-04:  20%|█▉        | 309/1577 [01:49<07:08,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 1.89233. lr 5.858173e-04:  20%|█▉        | 309/1577 [01:49<07:08,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 1.89233. lr 5.858173e-04:  20%|█▉        | 310/1577 [01:49<07:08,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 1.86688. lr 5.857264e-04:  20%|█▉        | 310/1577 [01:50<07:08,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 1.86688. lr 5.857264e-04:  20%|█▉        | 311/1577 [01:50<07:08,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 1.86530. lr 5.856351e-04:  20%|█▉        | 311/1577 [01:50<07:08,  2.95it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 1.86530. lr 5.856351e-04:  20%|█▉        | 312/1577 [01:50<07:07,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 1.85741. lr 5.855436e-04:  20%|█▉        | 312/1577 [01:50<07:07,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 1.85741. lr 5.855436e-04:  20%|█▉        | 313/1577 [01:50<07:07,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 1.85514. lr 5.854518e-04:  20%|█▉        | 313/1577 [01:51<07:07,  2.96it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 1.85514. lr 5.854518e-04:  20%|█▉        | 314/1577 [01:51<07:21,  2.86it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 1.86902. lr 5.853597e-04:  20%|█▉        | 314/1577 [01:51<07:21,  2.86it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 1.86902. lr 5.853597e-04:  20%|█▉        | 315/1577 [01:51<07:17,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 1.85733. lr 5.852673e-04:  20%|█▉        | 315/1577 [01:51<07:17,  2.89it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 1.85733. lr 5.852673e-04:  20%|██        | 316/1577 [01:51<07:13,  2.91it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for train_text_file in tqdm.tqdm(listdir(pathjoin(GENRE_DATA_DIR, LANG))):\n",
    "    label = train_text_file[:-4]\n",
    "    train_gpt_generator(\n",
    "        pathjoin(GENRE_DATA_DIR, LANG, train_text_file),\n",
    "        pathjoin(GPT_MODELS_DIR, LANG, label)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
