## Experiment Results

### BERT Results

Without POS tagging.

|    | 0%   | 10%  | 25%  | 50%  | 100% |
|----|------|------|------|------|------|
| ru | 0.81 | 0.73 | 0.66 | 0.53 | 0.08 |
| en | 0.71 | 0.48 | 0.41 | 0.32 | 0.13 |

Key point -- even slight replacement of keywords in the test dataset results in significant degradation of model accuracy.

With taking into account the part of speech of every replaced token:


|            | 0%   | 2%   | 5%   | 10%  | 25%  | 50%  | 100% |
|------------|------|------|------|------|------|------|------|
| ru         | 0.8  | 0.51 | 0.5  | 0.47 | 0.4  | 0.26 | 0.09 |
| ru_natasha | 0.8  | 0.5  | 0.48 | 0.46 | 0.39 | 0.31 | 0.07 |
| en         | 0.7  | 0.41 | 0.39 | 0.36 | 0.31 | 0.2  | 0.12 |


### XLM-Roberta Results


|            | 0%   | 2%   | 5%   | 10%  | 25%  | 50%  | 100% |
|------------|------|------|------|------|------|------|------|
| ru         | 0.85  | 0.68 | 0.66  | 0.64 | 0.55  | 0.40 | 0.12 |
| ru_natasha | 0.85  | 0.66  | 0.63 | 0.63 | 0.54 | 0.37 | 0.14 |
| en         | 0.67  | 0.37 | 0.35 | 0.34 | 0.30 | 0.22  | 0.13 |


### Adversarial XLM-Roberta Results

alpha = 0.01

|            | 0%   | 2%   | 5%   | 10%  | 25%  | 50%  | 100% |
|------------|------|------|------|------|------|------|------|
| ru         | 0.78  | 0.7 | 0.69  | 0.67 | 0.6  | 0.48 | 0.16 |
| ru_natasha | 0.78  | 0.69  | 0.66 | 0.66 | 0.59 | 0.43 | 0.14 |
| en         | 0.67  | 0.46 | 0.44 | 0.38 | 0.33 | 0.26 | 0.13 |

alpha = 0.05

|            | 0%   | 2%   | 5%   | 10%  | 25%  | 50%  | 100% |
|------------|------|------|------|------|------|------|------|
| ru         | 0.78  | 0.62 | 0.61  | 0.59 | 0.5  | 0.37 | 0.17 |
| ru_natasha | 0.78  | 0.63  | 0.61 | 0.61 | 0.53 | 0.38 | 0.16 |
| en         | 0.59  | 0.45 | 0.43 | 0.42 | 0.34 | 0.27 | 0.09 |
