{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prepare_dataset_with_substitution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffd3FyUVHcHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cec41bf-47a5-47c3-9bf2-d39de2e46b54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeasuK4lOaw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UL9OsSjXmdJ",
        "colab_type": "text"
      },
      "source": [
        "Reading of the test datasets -- in English, and in Russian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtgDZ6zFgInc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_en_test = pd.read_csv('/content/drive/My Drive/abbyy/en_test')\n",
        "df_ru_test = pd.read_csv('/content/drive/My Drive/abbyy/ru_test')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmUMjrrwsiR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b09f78e4-f9db-4d95-d84c-dec5bd018379"
      },
      "source": [
        "df_en_test.values.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTi9KRXMkl9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_ru, y_test_ru =  df_ru_test['text'].values, df_ru_test['target'].values\n",
        "X_test_en, y_test_en = df_en_test['text'].values, df_en_test['target'].values"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSyxytaqX2Qw",
        "colab_type": "text"
      },
      "source": [
        "Reading of the extracted keywords for both languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS5PAAp-5W21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keywords_ru = pd.read_csv('/content/drive/My Drive/abbyy/keywords_ru.csv')\n",
        "keywords_en = pd.read_csv('/content/drive/My Drive/abbyy/keywords_en.csv')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mex0k2DWkde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_keywords_by_topic(keywords_df):\n",
        "  result = dict()\n",
        "\n",
        "  for keyword, topic in zip(keywords_df['keyword'].values, keywords_df['topic'].values):\n",
        "    if topic not in result:\n",
        "      result[topic] = set()\n",
        "    result[topic].add(keyword)\n",
        "  return result"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCcRZKSbSnzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ru_keywords_by_topic = get_keywords_by_topic(keywords_ru)\n",
        "en_keywords_by_topic = get_keywords_by_topic(keywords_en)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhjNmeOblPoT",
        "colab_type": "text"
      },
      "source": [
        "Reading of the most frequent words for both languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13kg_2HZljdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_list_from_file(filename):\n",
        "  result_list = []\n",
        "  with open(filename, 'r') as fin:\n",
        "    for line in fin:\n",
        "      result_list.append(line.strip())\n",
        "  return result_list"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv_hUKqXlQCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frequent_words_ru = read_list_from_file('/content/drive/My Drive/abbyy/frequent_words_ru')\n",
        "frequent_words_en = read_list_from_file('/content/drive/My Drive/abbyy/frequent_words_en')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxKVC0Bpm3Pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "e4fb42fa-843c-4605-8037-6e4a3a219528"
      },
      "source": [
        "!cat '/content/drive/My Drive/abbyy/frequent_words_en'"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one\n",
            "may\n",
            "would\n",
            "also\n",
            "time\n",
            "â€“\n",
            "shall\n",
            "said\n",
            "new\n",
            "work\n",
            "like\n",
            "people\n",
            "first\n",
            "use\n",
            "nt\n",
            "could\n",
            "system\n",
            "information\n",
            "two\n",
            "see\n",
            "well\n",
            "made\n",
            "state\n",
            "make\n",
            "article\n",
            "many\n",
            "us\n",
            "doc\n",
            "united\n",
            "military\n",
            "order\n",
            "international\n",
            "even\n",
            "police\n",
            "states\n",
            "must\n",
            "need\n",
            "way\n",
            "data\n",
            "c\n",
            "children\n",
            "take\n",
            "world\n",
            "get\n",
            "used\n",
            "years\n",
            "court\n",
            "good\n",
            "case\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrVbF-NBYXdj",
        "colab_type": "text"
      },
      "source": [
        "Creation of datasets with substituted keywords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcA4MrlZS1ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_word(word):\n",
        "  return word.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
        "\n",
        "def modify_sentence(sentence, keywords_set, frequent_list, substitution_prob):\n",
        "  found_keywords = 0\n",
        "  substituted_keywords = 0\n",
        "  mod_sentence = []\n",
        "\n",
        "  for word in sentence.split():\n",
        "    mod_word = normalize_word(word)\n",
        "    if mod_word in keywords_set:\n",
        "      found_keywords += 1\n",
        "      rand = np.random.uniform()\n",
        "      if rand <= substitution_prob:\n",
        "        substituted_keywords += 1\n",
        "        mod_sentence.append(np.random.choice(frequent_list))\n",
        "      else:\n",
        "        mod_sentence.append(word)\n",
        "  return found_keywords, substituted_keywords, ' '.join(mod_sentence)\n",
        "\n",
        "\n",
        "def make_dataset_with_substitution(X, y, keywords_dict, frequent_list, substitution_prob):\n",
        "  result_df = pd.DataFrame()\n",
        "  found_keywords = 0\n",
        "  substituted_keywords = 0\n",
        "\n",
        "  for sentence, topic in zip(X, y):\n",
        "    found, substituted, mod_sentence = modify_sentence(\n",
        "        sentence, keywords_dict[topic], frequent_list, substitution_prob\n",
        "    )\n",
        "    result_df = result_df.append({'text': mod_sentence, 'target': topic}, ignore_index=True)\n",
        "    found_keywords += found\n",
        "    substituted_keywords += substituted\n",
        "  \n",
        "  print(\"found keywords: {}, substituted keywords: {}\".format(found_keywords, substituted_keywords))\n",
        "  return result_df"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GygxdNJMZKA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8211b429-06c5-49fb-8d4a-c01f594f867f"
      },
      "source": [
        "en_substituted_100 = make_dataset_with_substitution(X_test_en, y_test_en, en_keywords_by_topic, frequent_words_en, 1.0)\n",
        "en_substituted_50 = make_dataset_with_substitution(X_test_en, y_test_en, en_keywords_by_topic, frequent_words_en, 0.5)\n",
        "en_substituted_25 = make_dataset_with_substitution(X_test_en, y_test_en, en_keywords_by_topic, frequent_words_en, 0.25)\n",
        "en_substituted_10 = make_dataset_with_substitution(X_test_en, y_test_en, en_keywords_by_topic, frequent_words_en, 0.1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found keywords: 13247, substituted keywords: 13247\n",
            "found keywords: 13247, substituted keywords: 6603\n",
            "found keywords: 13247, substituted keywords: 3418\n",
            "found keywords: 13247, substituted keywords: 1347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pc1EflsoA2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_substituted_100.to_csv('/content/drive/My Drive/abbyy/en_test_substitution100')\n",
        "en_substituted_50.to_csv('/content/drive/My Drive/abbyy/en_test_substitution50')\n",
        "en_substituted_25.to_csv('/content/drive/My Drive/abbyy/en_test_substitution25')\n",
        "en_substituted_10.to_csv('/content/drive/My Drive/abbyy/en_test_substitution10')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwbu4aweZxap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7a0073ef-833d-4992-b075-92c4151ea036"
      },
      "source": [
        "ru_substituted_100 = make_dataset_with_substitution(X_test_ru, y_test_ru, ru_keywords_by_topic, frequent_words_ru, 1.0)\n",
        "ru_substituted_50 = make_dataset_with_substitution(X_test_ru, y_test_ru, ru_keywords_by_topic, frequent_words_ru, 0.5)\n",
        "ru_substituted_25 = make_dataset_with_substitution(X_test_ru, y_test_ru, ru_keywords_by_topic, frequent_words_ru, 0.25)\n",
        "ru_substituted_10 = make_dataset_with_substitution(X_test_ru, y_test_ru, ru_keywords_by_topic, frequent_words_ru, 0.1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found keywords: 12255, substituted keywords: 12255\n",
            "found keywords: 12255, substituted keywords: 6041\n",
            "found keywords: 12255, substituted keywords: 3100\n",
            "found keywords: 12255, substituted keywords: 1194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz-lEhQeo5M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ru_substituted_100.to_csv('/content/drive/My Drive/abbyy/ru_test_substitution100')\n",
        "ru_substituted_50.to_csv('/content/drive/My Drive/abbyy/ru_test_substitution50')\n",
        "ru_substituted_25.to_csv('/content/drive/My Drive/abbyy/ru_test_substitution25')\n",
        "ru_substituted_10.to_csv('/content/drive/My Drive/abbyy/ru_test_substitution10')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PspxgewEpJ-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "bd0e7f20-5265-4ee3-fcf4-c331d538f347"
      },
      "source": [
        "!head '/content/drive/My Drive/abbyy/en_test_substitution100'"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",target,text\n",
            "0,A22,see need\n",
            "1,A7,article may make information use well â€“ good must military nt may even make people united one â€“ information take international may must people doc must world time\n",
            "2,A1,good also children well make\n",
            "3,A12,made â€“ one\n",
            "4,A1,order need military world c one get make states order two well doc may state people system one court children article also get children international would also nt also state years system made system see even shall use article two could good may used article\n",
            "5,A9,good first state â€“ even well get\n",
            "6,A4,united would many court military c take court used work years made states police need states system may must children case c order police military would first would made people information two see military work even united take state world article also doc court see make information one need world united time see use new people united like n must states get two may case system must world use data use system could must said would years time n many way doc state take one need case world need case years doc international work good first like get need n article must also\n",
            "7,A12,children united even work\n",
            "8,A12,police order well made also\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIU1aEekpOUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}