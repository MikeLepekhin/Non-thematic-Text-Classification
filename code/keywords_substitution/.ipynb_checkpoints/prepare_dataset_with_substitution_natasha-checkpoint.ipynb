{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeasuK4lOaw6"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from os.path import join as pathjoin\n",
    "import tqdm\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import Doc, Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5UL9OsSjXmdJ"
   },
   "source": [
    "Reading of the test datasets -- in English, and in Russian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtgDZ6zFgInc"
   },
   "outputs": [],
   "source": [
    "df_ru_test = pd.read_csv(pathjoin(DATA_DIR, 'ru_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NmUMjrrwsiR9",
    "outputId": "b09f78e4-f9db-4d95-d84c-dec5bd018379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en_test.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTi9KRXMkl9m"
   },
   "outputs": [],
   "source": [
    "X_test_ru, y_test_ru =  df_ru_test['text'].values, df_ru_test['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSyxytaqX2Qw"
   },
   "source": [
    "Reading of the extracted keywords for both languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JS5PAAp-5W21"
   },
   "outputs": [],
   "source": [
    "keywords_ru_noun = pd.read_csv(pathjoin(DATA_DIR, 'natasha_keywords_ru_noun.csv'))\n",
    "keywords_ru_adj = pd.read_csv(pathjoin(DATA_DIR, 'natasha_keywords_ru_adj.csv'))\n",
    "keywords_ru_adv = pd.read_csv(pathjoin(DATA_DIR, 'natasha_keywords_ru_adv.csv'))\n",
    "keywords_ru_verb = pd.read_csv(pathjoin(DATA_DIR, 'natasha_keywords_ru_verb.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mex0k2DWkde"
   },
   "outputs": [],
   "source": [
    "def get_keywords_by_topic_and_pos(keywords_df, tag, result_dict):\n",
    "    for keyword, topic in zip(keywords_df['keyword'].values, keywords_df['topic'].values):\n",
    "        if (topic, tag) not in result_dict:\n",
    "            result_dict[(topic, tag)] = list()\n",
    "        result_dict[(topic, tag)].append(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = {'ADV', 'ADJ', 'NOUN', 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCcRZKSbSnzG"
   },
   "outputs": [],
   "source": [
    "ru_keywords_by_topic_pos = dict()\n",
    "for pos in pos_set:\n",
    "    get_keywords_by_topic_and_pos(keywords_ru_noun, pos, ru_keywords_by_topic_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_replace_dict(keywords_by_topic_pos):\n",
    "    replace_dict = dict()\n",
    "    \n",
    "    for key, word_list in keywords_by_topic_pos.items():\n",
    "        replace_dict[key] = []\n",
    "        for another_key, another_word_list in keywords_by_topic_pos.items():\n",
    "            if key != another_key:\n",
    "                replace_dict[key] += another_word_list\n",
    "    return replace_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_replace_dict = make_replace_dict(ru_keywords_by_topic_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrVbF-NBYXdj"
   },
   "source": [
    "Creation of datasets with substituted keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcA4MrlZS1ua"
   },
   "outputs": [],
   "source": [
    "def modify_sentence(sentence, keywords_dict, replace_dict, substitution_prob, topic):\n",
    "    found_keywords = 0\n",
    "    substituted_keywords = 0\n",
    "    mod_sentence = []\n",
    "    doc = Doc(sentence)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "\n",
    "    for word in doc.tokens:\n",
    "        if word.pos in pos_set and word.text in keywords_dict[(topic, word.pos)]:\n",
    "            found_keywords += 1\n",
    "            rand = np.random.uniform()\n",
    "            if rand <= substitution_prob:\n",
    "                substituted_keywords += 1\n",
    "                mod_sentence.append(np.random.choice(replace_dict[(topic, word.pos)]))\n",
    "            else:\n",
    "                mod_sentence.append(word.text)\n",
    "    return found_keywords, substituted_keywords, ' '.join(mod_sentence)\n",
    "\n",
    "\n",
    "def make_dataset_with_substitution(X, y, keywords_dict, replace_dict, substitution_prob):\n",
    "    result_df = pd.DataFrame()\n",
    "    found_keywords = 0\n",
    "    substituted_keywords = 0\n",
    "\n",
    "    for sentence, topic in tqdm.tqdm(zip(X, y)):\n",
    "        found, substituted, mod_sentence = modify_sentence(\n",
    "            sentence, keywords_dict, replace_dict, substitution_prob, topic\n",
    "        )\n",
    "        result_df = result_df.append({'text': mod_sentence, 'target': topic}, ignore_index=True)\n",
    "        found_keywords += found\n",
    "        substituted_keywords += substituted\n",
    "  \n",
    "    print(\"found keywords: {}, substituted keywords: {}\".format(found_keywords, substituted_keywords))\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Vwbu4aweZxap",
    "outputId": "7a0073ef-833d-4992-b075-92c4151ea036"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [00:45, 10.55it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found keywords: 5966, substituted keywords: 5966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [00:46, 10.43it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found keywords: 5966, substituted keywords: 3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [00:46, 10.45it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found keywords: 5966, substituted keywords: 1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [00:46, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found keywords: 5966, substituted keywords: 594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ru_substituted_100 = make_dataset_with_substitution(\n",
    "    X_test_ru, y_test_ru, ru_keywords_by_topic_pos, ru_replace_dict, 1.0\n",
    ")\n",
    "ru_substituted_50 = make_dataset_with_substitution(\n",
    "    X_test_ru, y_test_ru, ru_keywords_by_topic_pos, ru_replace_dict, 0.5\n",
    ")\n",
    "ru_substituted_25 = make_dataset_with_substitution(\n",
    "    X_test_ru, y_test_ru, ru_keywords_by_topic_pos, ru_replace_dict, 0.25\n",
    ")\n",
    "ru_substituted_10 = make_dataset_with_substitution(\n",
    "    X_test_ru, y_test_ru, ru_keywords_by_topic_pos, ru_replace_dict, 0.1\n",
    ")\n",
    "ru_substituted_5 = make_dataset_with_substitution(\n",
    "    X_test_ru, y_test_ru, ru_keywords_by_topic_pos, ru_replace_dict, 0.05\n",
    ")\n",
    "ru_substituted_2 = make_dataset_with_substitution(\n",
    "    X_test_ru, y_test_ru, ru_keywords_by_topic_pos, ru_replace_dict, 0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iz-lEhQeo5M9"
   },
   "outputs": [],
   "source": [
    "ru_substituted_100.to_csv(pathjoin(DATA_DIR, 'natasha_ru_test_substitution100'))\n",
    "ru_substituted_50.to_csv(pathjoin(DATA_DIR, 'natasha_ru_test_substitution50'))\n",
    "ru_substituted_25.to_csv(pathjoin(DATA_DIR, 'natasha_ru_test_substitution25'))\n",
    "ru_substituted_10.to_csv(pathjoin(DATA_DIR, 'natasha_ru_test_substitution10'))\n",
    "ru_substituted_5.to_csv(pathjoin(DATA_DIR, 'natasha_ru_test_substitution5'))\n",
    "ru_substituted_2.to_csv(pathjoin(DATA_DIR, 'natasha_ru_test_substitution2'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prepare_dataset_with_substitution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
