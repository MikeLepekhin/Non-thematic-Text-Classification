{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a character-level GPT on some text data\n",
    "\n",
    "The inputs here are simple text files, which we chop up to individual characters and then train GPT on. So you could say this is a char-transformer instead of a char-rnn. Doesn't quite roll off the tongue as well. In this example we will feed it some Shakespeare, which we'll get it to predict character-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import TokenIndexer, PretrainedTransformerIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, PretrainedTransformerTokenizer\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join as pathjoin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "from minGPT.mingpt.model import GPT, GPTConfig\n",
    "from minGPT.mingpt.trainer import Trainer, TrainerConfig\n",
    "# make deterministic\n",
    "from minGPT.mingpt.utils import sample, set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data/big'\n",
    "#MODELS_DIR = '/home/mlepekhin/models/big'\n",
    "transformer_model = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def detokenize(tokens):\n",
    "    return ' '.join([str(x) for x in tokens[1:-1]]).replace(' ##', '')\n",
    "\n",
    "class BPEDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)\n",
    "#indexer = PretrainedTransformerIndexer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt_generator(train_text_file, state_dict_file, n_layer=8, n_head=8, n_embd=512,\n",
    "                        max_epochs=1, batch_size=256):\n",
    "    text_sentences = nltk.tokenize.sent_tokenize(open(train_text_file, 'r').read())\n",
    "    tokens = np.concatenate([tokenizer.tokenize(sent)[1:-1] for sent in text_sentences])\n",
    "    tokens = [str(token) for token in tokens]\n",
    "    train_dataset = BPEDataset(tokens, block_size) \n",
    "    \n",
    "    mconf = GPTConfig(\n",
    "        train_dataset.vocab_size, train_dataset.block_size,\n",
    "        n_layer=n_layer, n_head=n_head, n_embd=n_embd\n",
    "    )\n",
    "    model = GPT(mconf)\n",
    "    tconf = TrainerConfig(\n",
    "        max_epochs=max_epochs, batch_size=batch_size, learning_rate=6e-4,\n",
    "        lr_decay=True, warmup_tokens=batch_size*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "    trainer = Trainer(model, train_dataset, None, tconf)\n",
    "    trainer.train()\n",
    "    torch.save(model.state_dict(), state_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_DATA_DIR = '/home/mlepekhin/data/big/genre'\n",
    "GPT_MODELS_DIR = '/home/mlepekhin/models/mini_gpt_big_bpe/'\n",
    "LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_gpt_generator(\n",
    "#        pathjoin(GENRE_DATA_DIR, LANG, 'A1.txt'),\n",
    "#        pathjoin(GPT_MODELS_DIR, LANG, 'A1')\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1353356 characters, 22161 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5287 [00:00<?, ?it/s]\u001b[A/home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "epoch 1 iter 0: train loss 10.11153. lr 6.000000e-04:   0%|          | 0/5287 [00:07<?, ?it/s]\u001b[A\n",
      "epoch 1 iter 0: train loss 10.11153. lr 6.000000e-04:   0%|          | 1/5287 [00:07<10:59:54,  7.49s/it]\u001b[A\n",
      "epoch 1 iter 1: train loss 9.40282. lr 6.000000e-04:   0%|          | 1/5287 [00:07<10:59:54,  7.49s/it] \u001b[A\n",
      "epoch 1 iter 1: train loss 9.40282. lr 6.000000e-04:   0%|          | 2/5287 [00:07<7:54:05,  5.38s/it] \u001b[A\n",
      "epoch 1 iter 2: train loss 8.94643. lr 5.999999e-04:   0%|          | 2/5287 [00:08<7:54:05,  5.38s/it]\u001b[A\n",
      "epoch 1 iter 2: train loss 8.94643. lr 5.999999e-04:   0%|          | 3/5287 [00:08<5:43:39,  3.90s/it]\u001b[A\n",
      "epoch 1 iter 3: train loss 8.67606. lr 5.999998e-04:   0%|          | 3/5287 [00:08<5:43:39,  3.90s/it]\u001b[A\n",
      "epoch 1 iter 3: train loss 8.67606. lr 5.999998e-04:   0%|          | 4/5287 [00:08<4:12:24,  2.87s/it]\u001b[A\n",
      "epoch 1 iter 4: train loss 8.40319. lr 5.999997e-04:   0%|          | 4/5287 [00:09<4:12:24,  2.87s/it]\u001b[A\n",
      "epoch 1 iter 4: train loss 8.40319. lr 5.999997e-04:   0%|          | 5/5287 [00:09<3:08:33,  2.14s/it]\u001b[A\n",
      "epoch 1 iter 5: train loss 8.16373. lr 5.999995e-04:   0%|          | 5/5287 [00:09<3:08:33,  2.14s/it]\u001b[A\n",
      "epoch 1 iter 5: train loss 8.16373. lr 5.999995e-04:   0%|          | 6/5287 [00:09<2:23:50,  1.63s/it]\u001b[A\n",
      "epoch 1 iter 6: train loss 7.90603. lr 5.999994e-04:   0%|          | 6/5287 [00:10<2:23:50,  1.63s/it]\u001b[A\n",
      "epoch 1 iter 6: train loss 7.90603. lr 5.999994e-04:   0%|          | 7/5287 [00:10<1:57:21,  1.33s/it]\u001b[A\n",
      "epoch 1 iter 7: train loss 7.72430. lr 5.999992e-04:   0%|          | 7/5287 [00:10<1:57:21,  1.33s/it]\u001b[A\n",
      "epoch 1 iter 7: train loss 7.72430. lr 5.999992e-04:   0%|          | 8/5287 [00:10<1:34:07,  1.07s/it]\u001b[A\n",
      "epoch 1 iter 8: train loss 7.51483. lr 5.999990e-04:   0%|          | 8/5287 [00:11<1:34:07,  1.07s/it]\u001b[A\n",
      "epoch 1 iter 8: train loss 7.51483. lr 5.999990e-04:   0%|          | 9/5287 [00:11<1:17:51,  1.13it/s]\u001b[A\n",
      "epoch 1 iter 9: train loss 7.36883. lr 5.999987e-04:   0%|          | 9/5287 [00:11<1:17:51,  1.13it/s]\u001b[A\n",
      "epoch 1 iter 9: train loss 7.36883. lr 5.999987e-04:   0%|          | 10/5287 [00:11<1:06:29,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 10: train loss 7.25056. lr 5.999984e-04:   0%|          | 10/5287 [00:12<1:06:29,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 10: train loss 7.25056. lr 5.999984e-04:   0%|          | 11/5287 [00:12<58:30,  1.50it/s]  \u001b[A\n",
      "epoch 1 iter 11: train loss 7.16073. lr 5.999981e-04:   0%|          | 11/5287 [00:12<58:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 11: train loss 7.16073. lr 5.999981e-04:   0%|          | 12/5287 [00:12<52:55,  1.66it/s]\u001b[A\n",
      "epoch 1 iter 12: train loss 7.11280. lr 5.999978e-04:   0%|          | 12/5287 [00:13<52:55,  1.66it/s]\u001b[A\n",
      "epoch 1 iter 12: train loss 7.11280. lr 5.999978e-04:   0%|          | 13/5287 [00:13<49:00,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13: train loss 7.02271. lr 5.999975e-04:   0%|          | 13/5287 [00:13<49:00,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13: train loss 7.02271. lr 5.999975e-04:   0%|          | 14/5287 [00:13<46:15,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14: train loss 7.07545. lr 5.999971e-04:   0%|          | 14/5287 [00:14<46:15,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14: train loss 7.07545. lr 5.999971e-04:   0%|          | 15/5287 [00:14<44:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 15: train loss 6.98601. lr 5.999967e-04:   0%|          | 15/5287 [00:14<44:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 15: train loss 6.98601. lr 5.999967e-04:   0%|          | 16/5287 [00:14<43:01,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 16: train loss 7.01138. lr 5.999962e-04:   0%|          | 16/5287 [00:14<43:01,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 16: train loss 7.01138. lr 5.999962e-04:   0%|          | 17/5287 [00:14<42:05,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 17: train loss 7.01678. lr 5.999958e-04:   0%|          | 17/5287 [00:15<42:05,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 17: train loss 7.01678. lr 5.999958e-04:   0%|          | 18/5287 [00:15<41:26,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 18: train loss 6.99049. lr 5.999953e-04:   0%|          | 18/5287 [00:15<41:26,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 18: train loss 6.99049. lr 5.999953e-04:   0%|          | 19/5287 [00:15<40:59,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 19: train loss 6.97815. lr 5.999948e-04:   0%|          | 19/5287 [00:16<40:59,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 19: train loss 6.97815. lr 5.999948e-04:   0%|          | 20/5287 [00:16<40:39,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 20: train loss 6.96727. lr 5.999942e-04:   0%|          | 20/5287 [00:16<40:39,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 20: train loss 6.96727. lr 5.999942e-04:   0%|          | 21/5287 [00:16<40:23,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 21: train loss 6.89632. lr 5.999937e-04:   0%|          | 21/5287 [00:17<40:23,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 21: train loss 6.89632. lr 5.999937e-04:   0%|          | 22/5287 [00:17<40:11,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 22: train loss 6.92313. lr 5.999931e-04:   0%|          | 22/5287 [00:17<40:11,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 22: train loss 6.92313. lr 5.999931e-04:   0%|          | 23/5287 [00:17<40:08,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 23: train loss 6.91860. lr 5.999925e-04:   0%|          | 23/5287 [00:18<40:08,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 23: train loss 6.91860. lr 5.999925e-04:   0%|          | 24/5287 [00:18<39:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 24: train loss 6.84377. lr 5.999918e-04:   0%|          | 24/5287 [00:18<39:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 24: train loss 6.84377. lr 5.999918e-04:   0%|          | 25/5287 [00:18<39:55,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 25: train loss 6.81330. lr 5.999912e-04:   0%|          | 25/5287 [00:19<39:55,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 25: train loss 6.81330. lr 5.999912e-04:   0%|          | 26/5287 [00:19<39:49,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 26: train loss 6.84439. lr 5.999905e-04:   0%|          | 26/5287 [00:19<39:49,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 26: train loss 6.84439. lr 5.999905e-04:   1%|          | 27/5287 [00:19<39:48,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 27: train loss 6.88074. lr 5.999897e-04:   1%|          | 27/5287 [00:19<39:48,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 27: train loss 6.88074. lr 5.999897e-04:   1%|          | 28/5287 [00:19<39:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 28: train loss 6.83205. lr 5.999890e-04:   1%|          | 28/5287 [00:20<39:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 28: train loss 6.83205. lr 5.999890e-04:   1%|          | 29/5287 [00:20<39:43,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 29: train loss 6.79689. lr 5.999882e-04:   1%|          | 29/5287 [00:20<39:43,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 29: train loss 6.79689. lr 5.999882e-04:   1%|          | 30/5287 [00:20<39:42,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 30: train loss 6.79358. lr 5.999874e-04:   1%|          | 30/5287 [00:21<39:42,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 30: train loss 6.79358. lr 5.999874e-04:   1%|          | 31/5287 [00:21<39:42,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 31: train loss 6.78880. lr 5.999866e-04:   1%|          | 31/5287 [00:21<39:42,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 31: train loss 6.78880. lr 5.999866e-04:   1%|          | 32/5287 [00:21<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 32: train loss 6.76003. lr 5.999857e-04:   1%|          | 32/5287 [00:22<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 32: train loss 6.76003. lr 5.999857e-04:   1%|          | 33/5287 [00:22<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 33: train loss 6.71058. lr 5.999848e-04:   1%|          | 33/5287 [00:22<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 33: train loss 6.71058. lr 5.999848e-04:   1%|          | 34/5287 [00:22<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 34: train loss 6.71127. lr 5.999839e-04:   1%|          | 34/5287 [00:23<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 34: train loss 6.71127. lr 5.999839e-04:   1%|          | 35/5287 [00:23<39:40,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 35: train loss 6.63881. lr 5.999830e-04:   1%|          | 35/5287 [00:23<39:40,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 35: train loss 6.63881. lr 5.999830e-04:   1%|          | 36/5287 [00:23<39:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 36: train loss 6.62182. lr 5.999820e-04:   1%|          | 36/5287 [00:23<39:39,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 36: train loss 6.62182. lr 5.999820e-04:   1%|          | 37/5287 [00:23<39:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 37: train loss 6.65813. lr 5.999810e-04:   1%|          | 37/5287 [00:24<39:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 37: train loss 6.65813. lr 5.999810e-04:   1%|          | 38/5287 [00:24<39:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 38: train loss 6.71436. lr 5.999800e-04:   1%|          | 38/5287 [00:24<39:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 38: train loss 6.71436. lr 5.999800e-04:   1%|          | 39/5287 [00:24<39:38,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 39: train loss 6.61231. lr 5.999790e-04:   1%|          | 39/5287 [00:25<39:38,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 39: train loss 6.61231. lr 5.999790e-04:   1%|          | 40/5287 [00:25<39:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 40: train loss 6.63065. lr 5.999779e-04:   1%|          | 40/5287 [00:25<39:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 40: train loss 6.63065. lr 5.999779e-04:   1%|          | 41/5287 [00:25<39:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 41: train loss 6.59261. lr 5.999768e-04:   1%|          | 41/5287 [00:26<39:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 41: train loss 6.59261. lr 5.999768e-04:   1%|          | 42/5287 [00:26<43:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 42: train loss 6.60977. lr 5.999757e-04:   1%|          | 42/5287 [00:26<43:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 42: train loss 6.60977. lr 5.999757e-04:   1%|          | 43/5287 [00:26<42:11,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 43: train loss 6.58294. lr 5.999745e-04:   1%|          | 43/5287 [00:27<42:11,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 43: train loss 6.58294. lr 5.999745e-04:   1%|          | 44/5287 [00:27<41:26,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 44: train loss 6.55742. lr 5.999734e-04:   1%|          | 44/5287 [00:27<41:26,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 44: train loss 6.55742. lr 5.999734e-04:   1%|          | 45/5287 [00:27<40:50,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 45: train loss 6.57133. lr 5.999722e-04:   1%|          | 45/5287 [00:28<40:50,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 45: train loss 6.57133. lr 5.999722e-04:   1%|          | 46/5287 [00:28<40:28,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 46: train loss 6.52615. lr 5.999709e-04:   1%|          | 46/5287 [00:28<40:28,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 46: train loss 6.52615. lr 5.999709e-04:   1%|          | 47/5287 [00:28<40:12,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 47: train loss 6.53993. lr 5.999697e-04:   1%|          | 47/5287 [00:29<40:12,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 47: train loss 6.53993. lr 5.999697e-04:   1%|          | 48/5287 [00:29<39:59,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 48: train loss 6.49189. lr 5.999684e-04:   1%|          | 48/5287 [00:29<39:59,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 48: train loss 6.49189. lr 5.999684e-04:   1%|          | 49/5287 [00:29<39:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 49: train loss 6.51471. lr 5.999671e-04:   1%|          | 49/5287 [00:30<39:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 49: train loss 6.51471. lr 5.999671e-04:   1%|          | 50/5287 [00:30<39:45,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 50: train loss 6.46585. lr 5.999658e-04:   1%|          | 50/5287 [00:30<39:45,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 50: train loss 6.46585. lr 5.999658e-04:   1%|          | 51/5287 [00:30<39:43,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 51: train loss 6.48924. lr 5.999644e-04:   1%|          | 51/5287 [00:30<39:43,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 51: train loss 6.48924. lr 5.999644e-04:   1%|          | 52/5287 [00:30<39:38,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 52: train loss 6.44187. lr 5.999630e-04:   1%|          | 52/5287 [00:31<39:38,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 52: train loss 6.44187. lr 5.999630e-04:   1%|          | 53/5287 [00:31<39:35,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 53: train loss 6.37956. lr 5.999616e-04:   1%|          | 53/5287 [00:31<39:35,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 53: train loss 6.37956. lr 5.999616e-04:   1%|          | 54/5287 [00:31<39:36,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 54: train loss 6.45423. lr 5.999602e-04:   1%|          | 54/5287 [00:32<39:36,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 54: train loss 6.45423. lr 5.999602e-04:   1%|          | 55/5287 [00:32<39:34,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 55: train loss 6.44026. lr 5.999587e-04:   1%|          | 55/5287 [00:32<39:34,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 55: train loss 6.44026. lr 5.999587e-04:   1%|          | 56/5287 [00:32<39:33,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 56: train loss 6.41014. lr 5.999572e-04:   1%|          | 56/5287 [00:33<39:33,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 56: train loss 6.41014. lr 5.999572e-04:   1%|          | 57/5287 [00:33<39:31,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 57: train loss 6.38728. lr 5.999557e-04:   1%|          | 57/5287 [00:33<39:31,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 57: train loss 6.38728. lr 5.999557e-04:   1%|          | 58/5287 [00:33<39:30,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 58: train loss 6.35988. lr 5.999541e-04:   1%|          | 58/5287 [00:34<39:30,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 58: train loss 6.35988. lr 5.999541e-04:   1%|          | 59/5287 [00:34<39:31,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 59: train loss 6.42529. lr 5.999526e-04:   1%|          | 59/5287 [00:34<39:31,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 59: train loss 6.42529. lr 5.999526e-04:   1%|          | 60/5287 [00:34<39:30,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 60: train loss 6.34889. lr 5.999510e-04:   1%|          | 60/5287 [00:35<39:30,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 60: train loss 6.34889. lr 5.999510e-04:   1%|          | 61/5287 [00:35<39:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 61: train loss 6.38495. lr 5.999493e-04:   1%|          | 61/5287 [00:35<39:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 61: train loss 6.38495. lr 5.999493e-04:   1%|          | 62/5287 [00:35<39:29,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 62: train loss 6.36000. lr 5.999477e-04:   1%|          | 62/5287 [00:35<39:29,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 62: train loss 6.36000. lr 5.999477e-04:   1%|          | 63/5287 [00:35<39:29,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 63: train loss 6.33770. lr 5.999460e-04:   1%|          | 63/5287 [00:36<39:29,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 63: train loss 6.33770. lr 5.999460e-04:   1%|          | 64/5287 [00:36<39:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 64: train loss 6.31265. lr 5.999443e-04:   1%|          | 64/5287 [00:36<39:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 64: train loss 6.31265. lr 5.999443e-04:   1%|          | 65/5287 [00:36<39:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 65: train loss 6.29390. lr 5.999426e-04:   1%|          | 65/5287 [00:37<39:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 65: train loss 6.29390. lr 5.999426e-04:   1%|          | 66/5287 [00:37<39:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 66: train loss 6.29125. lr 5.999408e-04:   1%|          | 66/5287 [00:37<39:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 66: train loss 6.29125. lr 5.999408e-04:   1%|▏         | 67/5287 [00:37<39:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 67: train loss 6.26847. lr 5.999390e-04:   1%|▏         | 67/5287 [00:38<39:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 67: train loss 6.26847. lr 5.999390e-04:   1%|▏         | 68/5287 [00:38<39:25,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 68: train loss 6.28435. lr 5.999372e-04:   1%|▏         | 68/5287 [00:38<39:25,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 68: train loss 6.28435. lr 5.999372e-04:   1%|▏         | 69/5287 [00:38<43:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 69: train loss 6.21998. lr 5.999354e-04:   1%|▏         | 69/5287 [00:39<43:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 69: train loss 6.21998. lr 5.999354e-04:   1%|▏         | 70/5287 [00:39<41:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 70: train loss 6.29678. lr 5.999335e-04:   1%|▏         | 70/5287 [00:39<41:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 70: train loss 6.29678. lr 5.999335e-04:   1%|▏         | 71/5287 [00:39<41:10,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 71: train loss 6.25474. lr 5.999316e-04:   1%|▏         | 71/5287 [00:40<41:10,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 71: train loss 6.25474. lr 5.999316e-04:   1%|▏         | 72/5287 [00:40<40:39,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 72: train loss 6.25453. lr 5.999297e-04:   1%|▏         | 72/5287 [00:40<40:39,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 72: train loss 6.25453. lr 5.999297e-04:   1%|▏         | 73/5287 [00:40<40:14,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 73: train loss 6.33109. lr 5.999278e-04:   1%|▏         | 73/5287 [00:41<40:14,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 73: train loss 6.33109. lr 5.999278e-04:   1%|▏         | 74/5287 [00:41<39:57,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 74: train loss 6.22153. lr 5.999258e-04:   1%|▏         | 74/5287 [00:41<39:57,  2.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 74: train loss 6.22153. lr 5.999258e-04:   1%|▏         | 75/5287 [00:41<39:48,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 75: train loss 6.25726. lr 5.999238e-04:   1%|▏         | 75/5287 [00:41<39:48,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 75: train loss 6.25726. lr 5.999238e-04:   1%|▏         | 76/5287 [00:41<39:38,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 76: train loss 6.22580. lr 5.999218e-04:   1%|▏         | 76/5287 [00:42<39:38,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 76: train loss 6.22580. lr 5.999218e-04:   1%|▏         | 77/5287 [00:42<39:33,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 77: train loss 6.19895. lr 5.999197e-04:   1%|▏         | 77/5287 [00:42<39:33,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 77: train loss 6.19895. lr 5.999197e-04:   1%|▏         | 78/5287 [00:42<39:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 78: train loss 6.17545. lr 5.999177e-04:   1%|▏         | 78/5287 [00:43<39:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 78: train loss 6.17545. lr 5.999177e-04:   1%|▏         | 79/5287 [00:43<39:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 79: train loss 6.24111. lr 5.999156e-04:   1%|▏         | 79/5287 [00:43<39:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 79: train loss 6.24111. lr 5.999156e-04:   2%|▏         | 80/5287 [00:43<39:25,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 80: train loss 6.26076. lr 5.999134e-04:   2%|▏         | 80/5287 [00:44<39:25,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 80: train loss 6.26076. lr 5.999134e-04:   2%|▏         | 81/5287 [00:44<39:23,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 81: train loss 6.20308. lr 5.999113e-04:   2%|▏         | 81/5287 [00:44<39:23,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 81: train loss 6.20308. lr 5.999113e-04:   2%|▏         | 82/5287 [00:44<39:23,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 82: train loss 6.18613. lr 5.999091e-04:   2%|▏         | 82/5287 [00:45<39:23,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 82: train loss 6.18613. lr 5.999091e-04:   2%|▏         | 83/5287 [00:45<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 83: train loss 6.15051. lr 5.999069e-04:   2%|▏         | 83/5287 [00:45<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 83: train loss 6.15051. lr 5.999069e-04:   2%|▏         | 84/5287 [00:45<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 84: train loss 6.14368. lr 5.999047e-04:   2%|▏         | 84/5287 [00:46<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 84: train loss 6.14368. lr 5.999047e-04:   2%|▏         | 85/5287 [00:46<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 85: train loss 6.12943. lr 5.999024e-04:   2%|▏         | 85/5287 [00:46<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 85: train loss 6.12943. lr 5.999024e-04:   2%|▏         | 86/5287 [00:46<39:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 86: train loss 6.16804. lr 5.999001e-04:   2%|▏         | 86/5287 [00:46<39:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 86: train loss 6.16804. lr 5.999001e-04:   2%|▏         | 87/5287 [00:46<39:22,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 87: train loss 6.15359. lr 5.998978e-04:   2%|▏         | 87/5287 [00:47<39:22,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 87: train loss 6.15359. lr 5.998978e-04:   2%|▏         | 88/5287 [00:47<39:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 88: train loss 6.11411. lr 5.998955e-04:   2%|▏         | 88/5287 [00:47<39:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 88: train loss 6.11411. lr 5.998955e-04:   2%|▏         | 89/5287 [00:47<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 89: train loss 6.12962. lr 5.998931e-04:   2%|▏         | 89/5287 [00:48<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 89: train loss 6.12962. lr 5.998931e-04:   2%|▏         | 90/5287 [00:48<39:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 90: train loss 6.17650. lr 5.998907e-04:   2%|▏         | 90/5287 [00:48<39:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 90: train loss 6.17650. lr 5.998907e-04:   2%|▏         | 91/5287 [00:48<39:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 91: train loss 6.08245. lr 5.998883e-04:   2%|▏         | 91/5287 [00:49<39:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 91: train loss 6.08245. lr 5.998883e-04:   2%|▏         | 92/5287 [00:49<39:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 92: train loss 6.08025. lr 5.998858e-04:   2%|▏         | 92/5287 [00:49<39:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 92: train loss 6.08025. lr 5.998858e-04:   2%|▏         | 93/5287 [00:49<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 93: train loss 6.10454. lr 5.998834e-04:   2%|▏         | 93/5287 [00:50<39:21,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 93: train loss 6.10454. lr 5.998834e-04:   2%|▏         | 94/5287 [00:50<39:18,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 94: train loss 6.05973. lr 5.998809e-04:   2%|▏         | 94/5287 [00:50<39:18,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 94: train loss 6.05973. lr 5.998809e-04:   2%|▏         | 95/5287 [00:50<39:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 95: train loss 6.04062. lr 5.998783e-04:   2%|▏         | 95/5287 [00:51<39:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 95: train loss 6.04062. lr 5.998783e-04:   2%|▏         | 96/5287 [00:51<39:05,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 96: train loss 6.03410. lr 5.998758e-04:   2%|▏         | 96/5287 [00:51<39:05,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 96: train loss 6.03410. lr 5.998758e-04:   2%|▏         | 97/5287 [00:51<39:02,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 97: train loss 5.97836. lr 5.998732e-04:   2%|▏         | 97/5287 [00:51<39:02,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 97: train loss 5.97836. lr 5.998732e-04:   2%|▏         | 98/5287 [00:51<38:57,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 98: train loss 6.01845. lr 5.998706e-04:   2%|▏         | 98/5287 [00:52<38:57,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 98: train loss 6.01845. lr 5.998706e-04:   2%|▏         | 99/5287 [00:52<38:56,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 99: train loss 5.98762. lr 5.998680e-04:   2%|▏         | 99/5287 [00:52<38:56,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 99: train loss 5.98762. lr 5.998680e-04:   2%|▏         | 100/5287 [00:52<38:53,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 100: train loss 6.02082. lr 5.998653e-04:   2%|▏         | 100/5287 [00:53<38:53,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 100: train loss 6.02082. lr 5.998653e-04:   2%|▏         | 101/5287 [00:53<38:52,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 101: train loss 6.00048. lr 5.998626e-04:   2%|▏         | 101/5287 [00:53<38:52,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 101: train loss 6.00048. lr 5.998626e-04:   2%|▏         | 102/5287 [00:53<38:50,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 102: train loss 6.06343. lr 5.998599e-04:   2%|▏         | 102/5287 [00:54<38:50,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 102: train loss 6.06343. lr 5.998599e-04:   2%|▏         | 103/5287 [00:54<38:48,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 103: train loss 5.98201. lr 5.998572e-04:   2%|▏         | 103/5287 [00:54<38:48,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 103: train loss 5.98201. lr 5.998572e-04:   2%|▏         | 104/5287 [00:54<38:47,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 104: train loss 5.96922. lr 5.998544e-04:   2%|▏         | 104/5287 [00:55<38:47,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 104: train loss 5.96922. lr 5.998544e-04:   2%|▏         | 105/5287 [00:55<38:49,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 105: train loss 6.03873. lr 5.998516e-04:   2%|▏         | 105/5287 [00:55<38:49,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 105: train loss 6.03873. lr 5.998516e-04:   2%|▏         | 106/5287 [00:55<38:50,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 106: train loss 5.97411. lr 5.998488e-04:   2%|▏         | 106/5287 [00:55<38:50,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 106: train loss 5.97411. lr 5.998488e-04:   2%|▏         | 107/5287 [00:55<38:47,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 107: train loss 5.92265. lr 5.998460e-04:   2%|▏         | 107/5287 [00:56<38:47,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 107: train loss 5.92265. lr 5.998460e-04:   2%|▏         | 108/5287 [00:56<38:45,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 108: train loss 5.95341. lr 5.998431e-04:   2%|▏         | 108/5287 [00:57<38:45,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 108: train loss 5.95341. lr 5.998431e-04:   2%|▏         | 109/5287 [00:57<42:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 109: train loss 5.97169. lr 5.998402e-04:   2%|▏         | 109/5287 [00:57<42:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 109: train loss 5.97169. lr 5.998402e-04:   2%|▏         | 110/5287 [00:57<41:20,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 110: train loss 5.97178. lr 5.998373e-04:   2%|▏         | 110/5287 [00:57<41:20,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 110: train loss 5.97178. lr 5.998373e-04:   2%|▏         | 111/5287 [00:57<40:32,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 111: train loss 5.92733. lr 5.998343e-04:   2%|▏         | 111/5287 [00:58<40:32,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 111: train loss 5.92733. lr 5.998343e-04:   2%|▏         | 112/5287 [00:58<39:59,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 112: train loss 5.96703. lr 5.998313e-04:   2%|▏         | 112/5287 [00:58<39:59,  2.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 112: train loss 5.96703. lr 5.998313e-04:   2%|▏         | 113/5287 [00:58<39:36,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 113: train loss 5.93330. lr 5.998283e-04:   2%|▏         | 113/5287 [00:59<39:36,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 113: train loss 5.93330. lr 5.998283e-04:   2%|▏         | 114/5287 [00:59<39:20,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 114: train loss 5.92517. lr 5.998253e-04:   2%|▏         | 114/5287 [00:59<39:20,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 114: train loss 5.92517. lr 5.998253e-04:   2%|▏         | 115/5287 [00:59<39:10,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 115: train loss 5.96815. lr 5.998223e-04:   2%|▏         | 115/5287 [01:00<39:10,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 115: train loss 5.96815. lr 5.998223e-04:   2%|▏         | 116/5287 [01:00<39:01,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 116: train loss 5.92616. lr 5.998192e-04:   2%|▏         | 116/5287 [01:00<39:01,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 116: train loss 5.92616. lr 5.998192e-04:   2%|▏         | 117/5287 [01:00<38:53,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 117: train loss 5.80130. lr 5.998161e-04:   2%|▏         | 117/5287 [01:01<38:53,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 117: train loss 5.80130. lr 5.998161e-04:   2%|▏         | 118/5287 [01:01<38:48,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 118: train loss 5.88810. lr 5.998129e-04:   2%|▏         | 118/5287 [01:01<38:48,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 118: train loss 5.88810. lr 5.998129e-04:   2%|▏         | 119/5287 [01:01<38:47,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 119: train loss 5.88022. lr 5.998098e-04:   2%|▏         | 119/5287 [01:01<38:47,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 119: train loss 5.88022. lr 5.998098e-04:   2%|▏         | 120/5287 [01:01<38:47,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 120: train loss 5.88010. lr 5.998066e-04:   2%|▏         | 120/5287 [01:02<38:47,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 120: train loss 5.88010. lr 5.998066e-04:   2%|▏         | 121/5287 [01:02<38:44,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 121: train loss 5.87314. lr 5.998034e-04:   2%|▏         | 121/5287 [01:02<38:44,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 121: train loss 5.87314. lr 5.998034e-04:   2%|▏         | 122/5287 [01:02<38:41,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 122: train loss 5.87306. lr 5.998001e-04:   2%|▏         | 122/5287 [01:03<38:41,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 122: train loss 5.87306. lr 5.998001e-04:   2%|▏         | 123/5287 [01:03<38:40,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 123: train loss 5.82810. lr 5.997969e-04:   2%|▏         | 123/5287 [01:03<38:40,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 123: train loss 5.82810. lr 5.997969e-04:   2%|▏         | 124/5287 [01:03<38:41,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 124: train loss 5.90064. lr 5.997936e-04:   2%|▏         | 124/5287 [01:04<38:41,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 124: train loss 5.90064. lr 5.997936e-04:   2%|▏         | 125/5287 [01:04<38:41,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 125: train loss 5.76476. lr 5.997903e-04:   2%|▏         | 125/5287 [01:04<38:41,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 125: train loss 5.76476. lr 5.997903e-04:   2%|▏         | 126/5287 [01:04<38:38,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 5.88136. lr 5.997869e-04:   2%|▏         | 126/5287 [01:05<38:38,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 5.88136. lr 5.997869e-04:   2%|▏         | 127/5287 [01:05<38:37,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 5.89028. lr 5.997835e-04:   2%|▏         | 127/5287 [01:05<38:37,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 5.89028. lr 5.997835e-04:   2%|▏         | 128/5287 [01:05<38:38,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 5.82621. lr 5.997801e-04:   2%|▏         | 128/5287 [01:05<38:38,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 5.82621. lr 5.997801e-04:   2%|▏         | 129/5287 [01:05<38:39,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 5.78109. lr 5.997767e-04:   2%|▏         | 129/5287 [01:06<38:39,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 5.78109. lr 5.997767e-04:   2%|▏         | 130/5287 [01:06<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 5.85366. lr 5.997733e-04:   2%|▏         | 130/5287 [01:06<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 5.85366. lr 5.997733e-04:   2%|▏         | 131/5287 [01:06<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 5.83844. lr 5.997698e-04:   2%|▏         | 131/5287 [01:07<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 5.83844. lr 5.997698e-04:   2%|▏         | 132/5287 [01:07<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 5.75497. lr 5.997663e-04:   2%|▏         | 132/5287 [01:07<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 5.75497. lr 5.997663e-04:   3%|▎         | 133/5287 [01:07<38:37,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 5.90669. lr 5.997627e-04:   3%|▎         | 133/5287 [01:08<38:37,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 5.90669. lr 5.997627e-04:   3%|▎         | 134/5287 [01:08<38:37,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 5.78701. lr 5.997592e-04:   3%|▎         | 134/5287 [01:08<38:37,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 5.78701. lr 5.997592e-04:   3%|▎         | 135/5287 [01:08<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 5.83481. lr 5.997556e-04:   3%|▎         | 135/5287 [01:09<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 5.83481. lr 5.997556e-04:   3%|▎         | 136/5287 [01:09<38:34,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 5.74340. lr 5.997520e-04:   3%|▎         | 136/5287 [01:09<38:34,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 5.74340. lr 5.997520e-04:   3%|▎         | 137/5287 [01:09<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 5.81059. lr 5.997484e-04:   3%|▎         | 137/5287 [01:10<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 5.81059. lr 5.997484e-04:   3%|▎         | 138/5287 [01:10<38:36,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 5.74101. lr 5.997447e-04:   3%|▎         | 138/5287 [01:10<38:36,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 5.74101. lr 5.997447e-04:   3%|▎         | 139/5287 [01:10<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 5.77926. lr 5.997410e-04:   3%|▎         | 139/5287 [01:10<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 5.77926. lr 5.997410e-04:   3%|▎         | 140/5287 [01:10<38:33,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 5.83112. lr 5.997373e-04:   3%|▎         | 140/5287 [01:11<38:33,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 5.83112. lr 5.997373e-04:   3%|▎         | 141/5287 [01:11<38:31,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 5.70958. lr 5.997335e-04:   3%|▎         | 141/5287 [01:11<38:31,  2.23it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 5.70958. lr 5.997335e-04:   3%|▎         | 142/5287 [01:11<41:46,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 5.78387. lr 5.997298e-04:   3%|▎         | 142/5287 [01:12<41:46,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 5.78387. lr 5.997298e-04:   3%|▎         | 143/5287 [01:12<40:47,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 5.74969. lr 5.997260e-04:   3%|▎         | 143/5287 [01:12<40:47,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 5.74969. lr 5.997260e-04:   3%|▎         | 144/5287 [01:12<40:05,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 5.79060. lr 5.997221e-04:   3%|▎         | 144/5287 [01:13<40:05,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 5.79060. lr 5.997221e-04:   3%|▎         | 145/5287 [01:13<39:36,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 5.74941. lr 5.997183e-04:   3%|▎         | 145/5287 [01:13<39:36,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 5.74941. lr 5.997183e-04:   3%|▎         | 146/5287 [01:13<39:18,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 5.75507. lr 5.997144e-04:   3%|▎         | 146/5287 [01:14<39:18,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 5.75507. lr 5.997144e-04:   3%|▎         | 147/5287 [01:14<39:04,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 5.72399. lr 5.997105e-04:   3%|▎         | 147/5287 [01:14<39:04,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 5.72399. lr 5.997105e-04:   3%|▎         | 148/5287 [01:14<38:54,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 5.76001. lr 5.997066e-04:   3%|▎         | 148/5287 [01:15<38:54,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 5.76001. lr 5.997066e-04:   3%|▎         | 149/5287 [01:15<38:44,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 5.68494. lr 5.997026e-04:   3%|▎         | 149/5287 [01:15<38:44,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 5.68494. lr 5.997026e-04:   3%|▎         | 150/5287 [01:15<38:39,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 150: train loss 5.76490. lr 5.996987e-04:   3%|▎         | 150/5287 [01:16<38:39,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 150: train loss 5.76490. lr 5.996987e-04:   3%|▎         | 151/5287 [01:16<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 5.73633. lr 5.996946e-04:   3%|▎         | 151/5287 [01:16<38:38,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 5.73633. lr 5.996946e-04:   3%|▎         | 152/5287 [01:16<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 5.69355. lr 5.996906e-04:   3%|▎         | 152/5287 [01:16<38:35,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 5.69355. lr 5.996906e-04:   3%|▎         | 153/5287 [01:16<38:32,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 5.69661. lr 5.996866e-04:   3%|▎         | 153/5287 [01:17<38:32,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 5.69661. lr 5.996866e-04:   3%|▎         | 154/5287 [01:17<38:29,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 5.72832. lr 5.996825e-04:   3%|▎         | 154/5287 [01:17<38:29,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 5.72832. lr 5.996825e-04:   3%|▎         | 155/5287 [01:17<38:29,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 5.68745. lr 5.996784e-04:   3%|▎         | 155/5287 [01:18<38:29,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 5.68745. lr 5.996784e-04:   3%|▎         | 156/5287 [01:18<38:31,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 5.68436. lr 5.996742e-04:   3%|▎         | 156/5287 [01:18<38:31,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 5.68436. lr 5.996742e-04:   3%|▎         | 157/5287 [01:18<38:29,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 5.65087. lr 5.996700e-04:   3%|▎         | 157/5287 [01:19<38:29,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 5.65087. lr 5.996700e-04:   3%|▎         | 158/5287 [01:19<38:27,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 5.70153. lr 5.996659e-04:   3%|▎         | 158/5287 [01:19<38:27,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 5.70153. lr 5.996659e-04:   3%|▎         | 159/5287 [01:19<38:27,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 5.64606. lr 5.996616e-04:   3%|▎         | 159/5287 [01:20<38:27,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 5.64606. lr 5.996616e-04:   3%|▎         | 160/5287 [01:20<38:28,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 5.67058. lr 5.996574e-04:   3%|▎         | 160/5287 [01:20<38:28,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 5.67058. lr 5.996574e-04:   3%|▎         | 161/5287 [01:20<38:28,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 5.66682. lr 5.996531e-04:   3%|▎         | 161/5287 [01:20<38:28,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 5.66682. lr 5.996531e-04:   3%|▎         | 162/5287 [01:20<38:25,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 5.65229. lr 5.996488e-04:   3%|▎         | 162/5287 [01:21<38:25,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 5.65229. lr 5.996488e-04:   3%|▎         | 163/5287 [01:21<38:25,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 5.67943. lr 5.996445e-04:   3%|▎         | 163/5287 [01:21<38:25,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 5.67943. lr 5.996445e-04:   3%|▎         | 164/5287 [01:21<38:28,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 5.62060. lr 5.996401e-04:   3%|▎         | 164/5287 [01:22<38:28,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 5.62060. lr 5.996401e-04:   3%|▎         | 165/5287 [01:22<38:26,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 5.72999. lr 5.996358e-04:   3%|▎         | 165/5287 [01:22<38:26,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 5.72999. lr 5.996358e-04:   3%|▎         | 166/5287 [01:22<38:23,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 5.61890. lr 5.996314e-04:   3%|▎         | 166/5287 [01:23<38:23,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 5.61890. lr 5.996314e-04:   3%|▎         | 167/5287 [01:23<38:21,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 5.55566. lr 5.996269e-04:   3%|▎         | 167/5287 [01:23<38:21,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 5.55566. lr 5.996269e-04:   3%|▎         | 168/5287 [01:23<38:22,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 5.69010. lr 5.996225e-04:   3%|▎         | 168/5287 [01:24<38:22,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 5.69010. lr 5.996225e-04:   3%|▎         | 169/5287 [01:24<38:23,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 5.70344. lr 5.996180e-04:   3%|▎         | 169/5287 [01:24<38:23,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 5.70344. lr 5.996180e-04:   3%|▎         | 170/5287 [01:24<41:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 5.59176. lr 5.996135e-04:   3%|▎         | 170/5287 [01:25<41:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 5.59176. lr 5.996135e-04:   3%|▎         | 171/5287 [01:25<40:26,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 5.63644. lr 5.996089e-04:   3%|▎         | 171/5287 [01:25<40:26,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 5.63644. lr 5.996089e-04:   3%|▎         | 172/5287 [01:25<39:46,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 5.59977. lr 5.996044e-04:   3%|▎         | 172/5287 [01:26<39:46,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 5.59977. lr 5.996044e-04:   3%|▎         | 173/5287 [01:26<39:20,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 5.66114. lr 5.995998e-04:   3%|▎         | 173/5287 [01:26<39:20,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 5.66114. lr 5.995998e-04:   3%|▎         | 174/5287 [01:26<39:04,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 5.59431. lr 5.995952e-04:   3%|▎         | 174/5287 [01:26<39:04,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 5.59431. lr 5.995952e-04:   3%|▎         | 175/5287 [01:26<38:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 5.65249. lr 5.995905e-04:   3%|▎         | 175/5287 [01:27<38:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 5.65249. lr 5.995905e-04:   3%|▎         | 176/5287 [01:27<38:40,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 5.60360. lr 5.995858e-04:   3%|▎         | 176/5287 [01:27<38:40,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 5.60360. lr 5.995858e-04:   3%|▎         | 177/5287 [01:27<38:33,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 5.60542. lr 5.995812e-04:   3%|▎         | 177/5287 [01:28<38:33,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 5.60542. lr 5.995812e-04:   3%|▎         | 178/5287 [01:28<38:30,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 5.58971. lr 5.995764e-04:   3%|▎         | 178/5287 [01:28<38:30,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 5.58971. lr 5.995764e-04:   3%|▎         | 179/5287 [01:28<38:27,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 5.57796. lr 5.995717e-04:   3%|▎         | 179/5287 [01:29<38:27,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 5.57796. lr 5.995717e-04:   3%|▎         | 180/5287 [01:29<38:22,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 5.63302. lr 5.995669e-04:   3%|▎         | 180/5287 [01:29<38:22,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 5.63302. lr 5.995669e-04:   3%|▎         | 181/5287 [01:29<38:20,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 5.63819. lr 5.995621e-04:   3%|▎         | 181/5287 [01:30<38:20,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 5.63819. lr 5.995621e-04:   3%|▎         | 182/5287 [01:30<38:22,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 5.55134. lr 5.995573e-04:   3%|▎         | 182/5287 [01:30<38:22,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 5.55134. lr 5.995573e-04:   3%|▎         | 183/5287 [01:30<38:20,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 5.57727. lr 5.995524e-04:   3%|▎         | 183/5287 [01:30<38:20,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 5.57727. lr 5.995524e-04:   3%|▎         | 184/5287 [01:30<38:17,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 5.67776. lr 5.995475e-04:   3%|▎         | 184/5287 [01:31<38:17,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 5.67776. lr 5.995475e-04:   3%|▎         | 185/5287 [01:31<38:17,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 5.61054. lr 5.995426e-04:   3%|▎         | 185/5287 [01:31<38:17,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 5.61054. lr 5.995426e-04:   4%|▎         | 186/5287 [01:31<38:18,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 5.56866. lr 5.995377e-04:   4%|▎         | 186/5287 [01:32<38:18,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 5.56866. lr 5.995377e-04:   4%|▎         | 187/5287 [01:32<38:18,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 187: train loss 5.52859. lr 5.995327e-04:   4%|▎         | 187/5287 [01:32<38:18,  2.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 187: train loss 5.52859. lr 5.995327e-04:   4%|▎         | 188/5287 [01:32<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 5.63372. lr 5.995277e-04:   4%|▎         | 188/5287 [01:33<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 5.63372. lr 5.995277e-04:   4%|▎         | 189/5287 [01:33<38:13,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 5.57798. lr 5.995227e-04:   4%|▎         | 189/5287 [01:33<38:13,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 5.57798. lr 5.995227e-04:   4%|▎         | 190/5287 [01:33<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 5.54303. lr 5.995177e-04:   4%|▎         | 190/5287 [01:34<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 5.54303. lr 5.995177e-04:   4%|▎         | 191/5287 [01:34<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 5.58530. lr 5.995126e-04:   4%|▎         | 191/5287 [01:34<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 5.58530. lr 5.995126e-04:   4%|▎         | 192/5287 [01:34<38:14,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 5.52834. lr 5.995075e-04:   4%|▎         | 192/5287 [01:35<38:14,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 5.52834. lr 5.995075e-04:   4%|▎         | 193/5287 [01:35<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 5.55047. lr 5.995024e-04:   4%|▎         | 193/5287 [01:35<38:15,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 5.55047. lr 5.995024e-04:   4%|▎         | 194/5287 [01:35<38:14,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 5.54789. lr 5.994973e-04:   4%|▎         | 194/5287 [01:35<38:14,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 5.54789. lr 5.994973e-04:   4%|▎         | 195/5287 [01:35<38:14,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 5.50904. lr 5.994921e-04:   4%|▎         | 195/5287 [01:36<38:14,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 5.50904. lr 5.994921e-04:   4%|▎         | 196/5287 [01:36<38:13,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 5.55344. lr 5.994869e-04:   4%|▎         | 196/5287 [01:36<38:13,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 5.55344. lr 5.994869e-04:   4%|▎         | 197/5287 [01:36<38:13,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 5.54456. lr 5.994817e-04:   4%|▎         | 197/5287 [01:37<38:13,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 5.54456. lr 5.994817e-04:   4%|▎         | 198/5287 [01:37<41:08,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 5.60342. lr 5.994764e-04:   4%|▎         | 198/5287 [01:37<41:08,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 5.60342. lr 5.994764e-04:   4%|▍         | 199/5287 [01:37<40:15,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 5.55313. lr 5.994711e-04:   4%|▍         | 199/5287 [01:38<40:15,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 5.55313. lr 5.994711e-04:   4%|▍         | 200/5287 [01:38<39:37,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 5.58008. lr 5.994658e-04:   4%|▍         | 200/5287 [01:38<39:37,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 5.58008. lr 5.994658e-04:   4%|▍         | 201/5287 [01:38<39:11,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 5.54268. lr 5.994605e-04:   4%|▍         | 201/5287 [01:39<39:11,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 5.54268. lr 5.994605e-04:   4%|▍         | 202/5287 [01:39<38:54,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 5.59749. lr 5.994552e-04:   4%|▍         | 202/5287 [01:39<38:54,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 5.59749. lr 5.994552e-04:   4%|▍         | 203/5287 [01:39<38:41,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 5.47033. lr 5.994498e-04:   4%|▍         | 203/5287 [01:40<38:41,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 5.47033. lr 5.994498e-04:   4%|▍         | 204/5287 [01:40<38:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 5.50543. lr 5.994444e-04:   4%|▍         | 204/5287 [01:40<38:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 5.50543. lr 5.994444e-04:   4%|▍         | 205/5287 [01:40<38:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 5.45509. lr 5.994389e-04:   4%|▍         | 205/5287 [01:41<38:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 5.45509. lr 5.994389e-04:   4%|▍         | 206/5287 [01:41<38:21,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 5.53315. lr 5.994335e-04:   4%|▍         | 206/5287 [01:41<38:21,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 5.53315. lr 5.994335e-04:   4%|▍         | 207/5287 [01:41<38:17,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 5.51718. lr 5.994280e-04:   4%|▍         | 207/5287 [01:41<38:17,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 5.51718. lr 5.994280e-04:   4%|▍         | 208/5287 [01:41<38:14,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 5.51812. lr 5.994225e-04:   4%|▍         | 208/5287 [01:42<38:14,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 5.51812. lr 5.994225e-04:   4%|▍         | 209/5287 [01:42<38:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 5.47641. lr 5.994169e-04:   4%|▍         | 209/5287 [01:42<38:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 5.47641. lr 5.994169e-04:   4%|▍         | 210/5287 [01:42<38:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 5.55214. lr 5.994113e-04:   4%|▍         | 210/5287 [01:43<38:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 5.55214. lr 5.994113e-04:   4%|▍         | 211/5287 [01:43<38:10,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 5.51132. lr 5.994057e-04:   4%|▍         | 211/5287 [01:43<38:10,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 5.51132. lr 5.994057e-04:   4%|▍         | 212/5287 [01:43<38:09,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 5.47312. lr 5.994001e-04:   4%|▍         | 212/5287 [01:44<38:09,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 5.47312. lr 5.994001e-04:   4%|▍         | 213/5287 [01:44<38:09,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 5.47026. lr 5.993945e-04:   4%|▍         | 213/5287 [01:44<38:09,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 5.47026. lr 5.993945e-04:   4%|▍         | 214/5287 [01:44<38:08,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 5.49708. lr 5.993888e-04:   4%|▍         | 214/5287 [01:45<38:08,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 5.49708. lr 5.993888e-04:   4%|▍         | 215/5287 [01:45<38:06,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 5.40187. lr 5.993831e-04:   4%|▍         | 215/5287 [01:45<38:06,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 5.40187. lr 5.993831e-04:   4%|▍         | 216/5287 [01:45<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 5.49559. lr 5.993774e-04:   4%|▍         | 216/5287 [01:45<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 5.49559. lr 5.993774e-04:   4%|▍         | 217/5287 [01:45<38:07,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 5.47285. lr 5.993716e-04:   4%|▍         | 217/5287 [01:46<38:07,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 5.47285. lr 5.993716e-04:   4%|▍         | 218/5287 [01:46<38:06,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 5.49239. lr 5.993658e-04:   4%|▍         | 218/5287 [01:46<38:06,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 5.49239. lr 5.993658e-04:   4%|▍         | 219/5287 [01:46<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 5.44147. lr 5.993600e-04:   4%|▍         | 219/5287 [01:47<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 5.44147. lr 5.993600e-04:   4%|▍         | 220/5287 [01:47<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 5.42841. lr 5.993542e-04:   4%|▍         | 220/5287 [01:47<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 5.42841. lr 5.993542e-04:   4%|▍         | 221/5287 [01:47<38:06,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 5.44798. lr 5.993483e-04:   4%|▍         | 221/5287 [01:48<38:06,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 5.44798. lr 5.993483e-04:   4%|▍         | 222/5287 [01:48<38:04,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 5.46121. lr 5.993425e-04:   4%|▍         | 222/5287 [01:48<38:04,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 5.46121. lr 5.993425e-04:   4%|▍         | 223/5287 [01:48<38:03,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 5.37683. lr 5.993365e-04:   4%|▍         | 223/5287 [01:49<38:03,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 5.37683. lr 5.993365e-04:   4%|▍         | 224/5287 [01:49<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 5.36756. lr 5.993306e-04:   4%|▍         | 224/5287 [01:49<38:05,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 5.36756. lr 5.993306e-04:   4%|▍         | 225/5287 [01:49<38:03,  2.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 225: train loss 5.44333. lr 5.993246e-04:   4%|▍         | 225/5287 [01:50<38:03,  2.22it/s]\u001b[A\n",
      "epoch 1 iter 225: train loss 5.44333. lr 5.993246e-04:   4%|▍         | 226/5287 [01:50<41:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 5.52502. lr 5.993186e-04:   4%|▍         | 226/5287 [01:50<41:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 5.52502. lr 5.993186e-04:   4%|▍         | 227/5287 [01:50<40:26,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 5.38235. lr 5.993126e-04:   4%|▍         | 227/5287 [01:51<40:26,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 5.38235. lr 5.993126e-04:   4%|▍         | 228/5287 [01:51<39:44,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 5.40222. lr 5.993066e-04:   4%|▍         | 228/5287 [01:51<39:44,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 5.40222. lr 5.993066e-04:   4%|▍         | 229/5287 [01:51<39:13,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 5.54319. lr 5.993005e-04:   4%|▍         | 229/5287 [01:51<39:13,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 5.54319. lr 5.993005e-04:   4%|▍         | 230/5287 [01:51<38:50,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 5.42584. lr 5.992944e-04:   4%|▍         | 230/5287 [01:52<38:50,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 5.42584. lr 5.992944e-04:   4%|▍         | 231/5287 [01:52<38:35,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 5.43211. lr 5.992883e-04:   4%|▍         | 231/5287 [01:52<38:35,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 5.43211. lr 5.992883e-04:   4%|▍         | 232/5287 [01:52<38:27,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 5.42168. lr 5.992821e-04:   4%|▍         | 232/5287 [01:53<38:27,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 5.42168. lr 5.992821e-04:   4%|▍         | 233/5287 [01:53<38:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 5.39657. lr 5.992760e-04:   4%|▍         | 233/5287 [01:53<38:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 5.39657. lr 5.992760e-04:   4%|▍         | 234/5287 [01:53<38:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 5.42763. lr 5.992698e-04:   4%|▍         | 234/5287 [01:54<38:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 5.42763. lr 5.992698e-04:   4%|▍         | 235/5287 [01:54<38:13,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 5.45498. lr 5.992635e-04:   4%|▍         | 235/5287 [01:54<38:13,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 5.45498. lr 5.992635e-04:   4%|▍         | 236/5287 [01:54<38:07,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 5.45466. lr 5.992573e-04:   4%|▍         | 236/5287 [01:55<38:07,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 5.45466. lr 5.992573e-04:   4%|▍         | 237/5287 [01:55<38:06,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 5.38446. lr 5.992510e-04:   4%|▍         | 237/5287 [01:55<38:06,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 5.38446. lr 5.992510e-04:   5%|▍         | 238/5287 [01:55<38:04,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 5.41584. lr 5.992447e-04:   5%|▍         | 238/5287 [01:56<38:04,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 5.41584. lr 5.992447e-04:   5%|▍         | 239/5287 [01:56<38:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 5.39510. lr 5.992384e-04:   5%|▍         | 239/5287 [01:56<38:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 5.39510. lr 5.992384e-04:   5%|▍         | 240/5287 [01:56<38:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 5.34925. lr 5.992320e-04:   5%|▍         | 240/5287 [01:56<38:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 5.34925. lr 5.992320e-04:   5%|▍         | 241/5287 [01:56<38:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 5.38215. lr 5.992256e-04:   5%|▍         | 241/5287 [01:57<38:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 5.38215. lr 5.992256e-04:   5%|▍         | 242/5287 [01:57<37:59,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 5.27956. lr 5.992192e-04:   5%|▍         | 242/5287 [01:57<37:59,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 5.27956. lr 5.992192e-04:   5%|▍         | 243/5287 [01:57<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 5.39091. lr 5.992127e-04:   5%|▍         | 243/5287 [01:58<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 5.39091. lr 5.992127e-04:   5%|▍         | 244/5287 [01:58<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 5.37402. lr 5.992063e-04:   5%|▍         | 244/5287 [01:58<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 5.37402. lr 5.992063e-04:   5%|▍         | 245/5287 [01:58<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 5.42614. lr 5.991998e-04:   5%|▍         | 245/5287 [01:59<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 5.42614. lr 5.991998e-04:   5%|▍         | 246/5287 [01:59<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 5.34203. lr 5.991933e-04:   5%|▍         | 246/5287 [01:59<37:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 5.34203. lr 5.991933e-04:   5%|▍         | 247/5287 [01:59<37:57,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 5.32851. lr 5.991867e-04:   5%|▍         | 247/5287 [02:00<37:57,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 5.32851. lr 5.991867e-04:   5%|▍         | 248/5287 [02:00<37:57,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 5.39259. lr 5.991801e-04:   5%|▍         | 248/5287 [02:00<37:57,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 5.39259. lr 5.991801e-04:   5%|▍         | 249/5287 [02:00<37:55,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 5.38262. lr 5.991735e-04:   5%|▍         | 249/5287 [02:00<37:55,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 5.38262. lr 5.991735e-04:   5%|▍         | 250/5287 [02:00<37:55,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 5.29956. lr 5.991669e-04:   5%|▍         | 250/5287 [02:01<37:55,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 5.29956. lr 5.991669e-04:   5%|▍         | 251/5287 [02:01<37:54,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 5.37523. lr 5.991603e-04:   5%|▍         | 251/5287 [02:01<37:54,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 5.37523. lr 5.991603e-04:   5%|▍         | 252/5287 [02:01<37:54,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 5.35232. lr 5.991536e-04:   5%|▍         | 252/5287 [02:02<37:54,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 5.35232. lr 5.991536e-04:   5%|▍         | 253/5287 [02:02<37:55,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 5.39981. lr 5.991469e-04:   5%|▍         | 253/5287 [02:02<37:55,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 5.39981. lr 5.991469e-04:   5%|▍         | 254/5287 [02:02<40:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 5.33974. lr 5.991402e-04:   5%|▍         | 254/5287 [02:03<40:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 5.33974. lr 5.991402e-04:   5%|▍         | 255/5287 [02:03<39:56,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 5.34190. lr 5.991334e-04:   5%|▍         | 255/5287 [02:03<39:56,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 5.34190. lr 5.991334e-04:   5%|▍         | 256/5287 [02:03<39:18,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 5.37079. lr 5.991266e-04:   5%|▍         | 256/5287 [02:04<39:18,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 5.37079. lr 5.991266e-04:   5%|▍         | 257/5287 [02:04<38:53,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 5.33275. lr 5.991198e-04:   5%|▍         | 257/5287 [02:04<38:53,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 5.33275. lr 5.991198e-04:   5%|▍         | 258/5287 [02:04<38:35,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 5.31755. lr 5.991130e-04:   5%|▍         | 258/5287 [02:05<38:35,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 5.31755. lr 5.991130e-04:   5%|▍         | 259/5287 [02:05<38:21,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 5.25718. lr 5.991061e-04:   5%|▍         | 259/5287 [02:05<38:21,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 5.25718. lr 5.991061e-04:   5%|▍         | 260/5287 [02:05<38:14,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 5.32687. lr 5.990992e-04:   5%|▍         | 260/5287 [02:06<38:14,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 5.32687. lr 5.990992e-04:   5%|▍         | 261/5287 [02:06<38:06,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 5.25156. lr 5.990923e-04:   5%|▍         | 261/5287 [02:06<38:06,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 5.25156. lr 5.990923e-04:   5%|▍         | 262/5287 [02:06<37:59,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 262: train loss 5.30430. lr 5.990853e-04:   5%|▍         | 262/5287 [02:06<37:59,  2.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 262: train loss 5.30430. lr 5.990853e-04:   5%|▍         | 263/5287 [02:06<37:57,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 5.33477. lr 5.990784e-04:   5%|▍         | 263/5287 [02:07<37:57,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 5.33477. lr 5.990784e-04:   5%|▍         | 264/5287 [02:07<37:56,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 5.32661. lr 5.990714e-04:   5%|▍         | 264/5287 [02:07<37:56,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 5.32661. lr 5.990714e-04:   5%|▌         | 265/5287 [02:07<37:52,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 5.28413. lr 5.990644e-04:   5%|▌         | 265/5287 [02:08<37:52,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 5.28413. lr 5.990644e-04:   5%|▌         | 266/5287 [02:08<37:52,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 5.30251. lr 5.990573e-04:   5%|▌         | 266/5287 [02:08<37:52,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 5.30251. lr 5.990573e-04:   5%|▌         | 267/5287 [02:08<37:51,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 5.33229. lr 5.990502e-04:   5%|▌         | 267/5287 [02:09<37:51,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 5.33229. lr 5.990502e-04:   5%|▌         | 268/5287 [02:09<37:49,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 5.33105. lr 5.990431e-04:   5%|▌         | 268/5287 [02:09<37:49,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 5.33105. lr 5.990431e-04:   5%|▌         | 269/5287 [02:09<37:49,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 5.25880. lr 5.990360e-04:   5%|▌         | 269/5287 [02:10<37:49,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 5.25880. lr 5.990360e-04:   5%|▌         | 270/5287 [02:10<37:48,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 5.27692. lr 5.990289e-04:   5%|▌         | 270/5287 [02:10<37:48,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 5.27692. lr 5.990289e-04:   5%|▌         | 271/5287 [02:10<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 5.31912. lr 5.990217e-04:   5%|▌         | 271/5287 [02:11<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 5.31912. lr 5.990217e-04:   5%|▌         | 272/5287 [02:11<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 5.28172. lr 5.990145e-04:   5%|▌         | 272/5287 [02:11<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 5.28172. lr 5.990145e-04:   5%|▌         | 273/5287 [02:11<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 5.21522. lr 5.990072e-04:   5%|▌         | 273/5287 [02:11<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 5.21522. lr 5.990072e-04:   5%|▌         | 274/5287 [02:11<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 5.29460. lr 5.990000e-04:   5%|▌         | 274/5287 [02:12<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 5.29460. lr 5.990000e-04:   5%|▌         | 275/5287 [02:12<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 5.22611. lr 5.989927e-04:   5%|▌         | 275/5287 [02:12<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 5.22611. lr 5.989927e-04:   5%|▌         | 276/5287 [02:12<37:47,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 5.26423. lr 5.989854e-04:   5%|▌         | 276/5287 [02:13<37:47,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 5.26423. lr 5.989854e-04:   5%|▌         | 277/5287 [02:13<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 5.37017. lr 5.989780e-04:   5%|▌         | 277/5287 [02:13<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 5.37017. lr 5.989780e-04:   5%|▌         | 278/5287 [02:13<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 5.25296. lr 5.989707e-04:   5%|▌         | 278/5287 [02:14<37:46,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 5.25296. lr 5.989707e-04:   5%|▌         | 279/5287 [02:14<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 5.28270. lr 5.989633e-04:   5%|▌         | 279/5287 [02:14<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 5.28270. lr 5.989633e-04:   5%|▌         | 280/5287 [02:14<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 5.20856. lr 5.989559e-04:   5%|▌         | 280/5287 [02:15<37:45,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 5.20856. lr 5.989559e-04:   5%|▌         | 281/5287 [02:15<37:44,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 5.27066. lr 5.989484e-04:   5%|▌         | 281/5287 [02:15<37:44,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 5.27066. lr 5.989484e-04:   5%|▌         | 282/5287 [02:15<40:37,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 5.26919. lr 5.989409e-04:   5%|▌         | 282/5287 [02:16<40:37,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 5.26919. lr 5.989409e-04:   5%|▌         | 283/5287 [02:16<39:45,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 5.28870. lr 5.989334e-04:   5%|▌         | 283/5287 [02:16<39:45,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 5.28870. lr 5.989334e-04:   5%|▌         | 284/5287 [02:16<39:09,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 5.22821. lr 5.989259e-04:   5%|▌         | 284/5287 [02:17<39:09,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 5.22821. lr 5.989259e-04:   5%|▌         | 285/5287 [02:17<38:42,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 5.21035. lr 5.989184e-04:   5%|▌         | 285/5287 [02:17<38:42,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 5.21035. lr 5.989184e-04:   5%|▌         | 286/5287 [02:17<38:24,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 5.23747. lr 5.989108e-04:   5%|▌         | 286/5287 [02:17<38:24,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 5.23747. lr 5.989108e-04:   5%|▌         | 287/5287 [02:17<38:11,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 5.25019. lr 5.989032e-04:   5%|▌         | 287/5287 [02:18<38:11,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 5.25019. lr 5.989032e-04:   5%|▌         | 288/5287 [02:18<38:02,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 5.21752. lr 5.988956e-04:   5%|▌         | 288/5287 [02:18<38:02,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 5.21752. lr 5.988956e-04:   5%|▌         | 289/5287 [02:18<37:55,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 5.23279. lr 5.988879e-04:   5%|▌         | 289/5287 [02:19<37:55,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 5.23279. lr 5.988879e-04:   5%|▌         | 290/5287 [02:19<37:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 5.23099. lr 5.988802e-04:   5%|▌         | 290/5287 [02:19<37:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 5.23099. lr 5.988802e-04:   6%|▌         | 291/5287 [02:19<37:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 5.20694. lr 5.988725e-04:   6%|▌         | 291/5287 [02:20<37:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 5.20694. lr 5.988725e-04:   6%|▌         | 292/5287 [02:20<37:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 5.22176. lr 5.988648e-04:   6%|▌         | 292/5287 [02:20<37:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 5.22176. lr 5.988648e-04:   6%|▌         | 293/5287 [02:20<37:43,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 5.19538. lr 5.988570e-04:   6%|▌         | 293/5287 [02:21<37:43,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 5.19538. lr 5.988570e-04:   6%|▌         | 294/5287 [02:21<37:42,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 5.19428. lr 5.988492e-04:   6%|▌         | 294/5287 [02:21<37:42,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 5.19428. lr 5.988492e-04:   6%|▌         | 295/5287 [02:21<37:41,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 5.21406. lr 5.988414e-04:   6%|▌         | 295/5287 [02:22<37:41,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 5.21406. lr 5.988414e-04:   6%|▌         | 296/5287 [02:22<37:38,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 5.26148. lr 5.988336e-04:   6%|▌         | 296/5287 [02:22<37:38,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 5.26148. lr 5.988336e-04:   6%|▌         | 297/5287 [02:22<37:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 5.15215. lr 5.988257e-04:   6%|▌         | 297/5287 [02:22<37:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 5.15215. lr 5.988257e-04:   6%|▌         | 298/5287 [02:22<37:38,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 5.19988. lr 5.988178e-04:   6%|▌         | 298/5287 [02:23<37:38,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 5.19988. lr 5.988178e-04:   6%|▌         | 299/5287 [02:23<37:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 5.19229. lr 5.988099e-04:   6%|▌         | 299/5287 [02:23<37:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 5.19229. lr 5.988099e-04:   6%|▌         | 300/5287 [02:23<37:36,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 300: train loss 5.20376. lr 5.988020e-04:   6%|▌         | 300/5287 [02:24<37:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 300: train loss 5.20376. lr 5.988020e-04:   6%|▌         | 301/5287 [02:24<37:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 5.19037. lr 5.987940e-04:   6%|▌         | 301/5287 [02:24<37:37,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 5.19037. lr 5.987940e-04:   6%|▌         | 302/5287 [02:24<37:35,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 5.16235. lr 5.987860e-04:   6%|▌         | 302/5287 [02:25<37:35,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 5.16235. lr 5.987860e-04:   6%|▌         | 303/5287 [02:25<37:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 5.22714. lr 5.987780e-04:   6%|▌         | 303/5287 [02:25<37:36,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 5.22714. lr 5.987780e-04:   6%|▌         | 304/5287 [02:25<37:34,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 5.15341. lr 5.987699e-04:   6%|▌         | 304/5287 [02:26<37:34,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 5.15341. lr 5.987699e-04:   6%|▌         | 305/5287 [02:26<37:33,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 5.25109. lr 5.987618e-04:   6%|▌         | 305/5287 [02:26<37:33,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 5.25109. lr 5.987618e-04:   6%|▌         | 306/5287 [02:26<37:34,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 5.17755. lr 5.987537e-04:   6%|▌         | 306/5287 [02:27<37:34,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 5.17755. lr 5.987537e-04:   6%|▌         | 307/5287 [02:27<37:31,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 5.08993. lr 5.987456e-04:   6%|▌         | 307/5287 [02:27<37:31,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 5.08993. lr 5.987456e-04:   6%|▌         | 308/5287 [02:27<37:31,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 5.17254. lr 5.987374e-04:   6%|▌         | 308/5287 [02:27<37:31,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 5.17254. lr 5.987374e-04:   6%|▌         | 309/5287 [02:27<37:34,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 5.18964. lr 5.987292e-04:   6%|▌         | 309/5287 [02:28<37:34,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 5.18964. lr 5.987292e-04:   6%|▌         | 310/5287 [02:28<40:20,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 5.13158. lr 5.987210e-04:   6%|▌         | 310/5287 [02:28<40:20,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 5.13158. lr 5.987210e-04:   6%|▌         | 311/5287 [02:28<39:28,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 5.15587. lr 5.987128e-04:   6%|▌         | 311/5287 [02:29<39:28,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 5.15587. lr 5.987128e-04:   6%|▌         | 312/5287 [02:29<38:52,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 5.08629. lr 5.987045e-04:   6%|▌         | 312/5287 [02:29<38:52,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 5.08629. lr 5.987045e-04:   6%|▌         | 313/5287 [02:29<38:29,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 5.19166. lr 5.986963e-04:   6%|▌         | 313/5287 [02:30<38:29,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 5.19166. lr 5.986963e-04:   6%|▌         | 314/5287 [02:30<38:10,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 5.15645. lr 5.986879e-04:   6%|▌         | 314/5287 [02:30<38:10,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 5.15645. lr 5.986879e-04:   6%|▌         | 315/5287 [02:30<37:59,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 5.16549. lr 5.986796e-04:   6%|▌         | 315/5287 [02:31<37:59,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 5.16549. lr 5.986796e-04:   6%|▌         | 316/5287 [02:31<37:50,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 316: train loss 5.12053. lr 5.986712e-04:   6%|▌         | 316/5287 [02:31<37:50,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 316: train loss 5.12053. lr 5.986712e-04:   6%|▌         | 317/5287 [02:31<37:41,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 317: train loss 5.07391. lr 5.986628e-04:   6%|▌         | 317/5287 [02:32<37:41,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 317: train loss 5.07391. lr 5.986628e-04:   6%|▌         | 318/5287 [02:32<37:38,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 318: train loss 5.12403. lr 5.986544e-04:   6%|▌         | 318/5287 [02:32<37:38,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 318: train loss 5.12403. lr 5.986544e-04:   6%|▌         | 319/5287 [02:32<37:34,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 319: train loss 5.09157. lr 5.986460e-04:   6%|▌         | 319/5287 [02:33<37:34,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 319: train loss 5.09157. lr 5.986460e-04:   6%|▌         | 320/5287 [02:33<37:32,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 320: train loss 5.11501. lr 5.986375e-04:   6%|▌         | 320/5287 [02:33<37:32,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 320: train loss 5.11501. lr 5.986375e-04:   6%|▌         | 321/5287 [02:33<37:32,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 321: train loss 5.08110. lr 5.986290e-04:   6%|▌         | 321/5287 [02:33<37:32,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 321: train loss 5.08110. lr 5.986290e-04:   6%|▌         | 322/5287 [02:33<37:29,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 322: train loss 5.07360. lr 5.986205e-04:   6%|▌         | 322/5287 [02:34<37:29,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 322: train loss 5.07360. lr 5.986205e-04:   6%|▌         | 323/5287 [02:34<37:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 323: train loss 5.13502. lr 5.986119e-04:   6%|▌         | 323/5287 [02:34<37:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 323: train loss 5.13502. lr 5.986119e-04:   6%|▌         | 324/5287 [02:34<37:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 324: train loss 5.06249. lr 5.986033e-04:   6%|▌         | 324/5287 [02:35<37:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 324: train loss 5.06249. lr 5.986033e-04:   6%|▌         | 325/5287 [02:35<37:27,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 325: train loss 5.13400. lr 5.985947e-04:   6%|▌         | 325/5287 [02:35<37:27,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 325: train loss 5.13400. lr 5.985947e-04:   6%|▌         | 326/5287 [02:35<37:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 326: train loss 5.11158. lr 5.985861e-04:   6%|▌         | 326/5287 [02:36<37:28,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 326: train loss 5.11158. lr 5.985861e-04:   6%|▌         | 327/5287 [02:36<37:26,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 327: train loss 5.05486. lr 5.985774e-04:   6%|▌         | 327/5287 [02:36<37:26,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 327: train loss 5.05486. lr 5.985774e-04:   6%|▌         | 328/5287 [02:36<37:25,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 328: train loss 5.05885. lr 5.985688e-04:   6%|▌         | 328/5287 [02:37<37:25,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 328: train loss 5.05885. lr 5.985688e-04:   6%|▌         | 329/5287 [02:37<37:26,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 329: train loss 5.12941. lr 5.985600e-04:   6%|▌         | 329/5287 [02:37<37:26,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 329: train loss 5.12941. lr 5.985600e-04:   6%|▌         | 330/5287 [02:37<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 330: train loss 5.17385. lr 5.985513e-04:   6%|▌         | 330/5287 [02:37<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 330: train loss 5.17385. lr 5.985513e-04:   6%|▋         | 331/5287 [02:37<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 331: train loss 5.08731. lr 5.985425e-04:   6%|▋         | 331/5287 [02:38<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 331: train loss 5.08731. lr 5.985425e-04:   6%|▋         | 332/5287 [02:38<37:25,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 332: train loss 5.03056. lr 5.985337e-04:   6%|▋         | 332/5287 [02:38<37:25,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 332: train loss 5.03056. lr 5.985337e-04:   6%|▋         | 333/5287 [02:38<37:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 333: train loss 5.01863. lr 5.985249e-04:   6%|▋         | 333/5287 [02:39<37:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 333: train loss 5.01863. lr 5.985249e-04:   6%|▋         | 334/5287 [02:39<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 334: train loss 5.06252. lr 5.985161e-04:   6%|▋         | 334/5287 [02:39<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 334: train loss 5.06252. lr 5.985161e-04:   6%|▋         | 335/5287 [02:39<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 335: train loss 5.10462. lr 5.985072e-04:   6%|▋         | 335/5287 [02:40<37:24,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 335: train loss 5.10462. lr 5.985072e-04:   6%|▋         | 336/5287 [02:40<37:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 336: train loss 5.09407. lr 5.984983e-04:   6%|▋         | 336/5287 [02:40<37:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 336: train loss 5.09407. lr 5.984983e-04:   6%|▋         | 337/5287 [02:40<37:23,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 337: train loss 4.99684. lr 5.984894e-04:   6%|▋         | 337/5287 [02:41<37:23,  2.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 337: train loss 4.99684. lr 5.984894e-04:   6%|▋         | 338/5287 [02:41<40:11,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 338: train loss 5.03805. lr 5.984805e-04:   6%|▋         | 338/5287 [02:41<40:11,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 338: train loss 5.03805. lr 5.984805e-04:   6%|▋         | 339/5287 [02:41<39:19,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 339: train loss 5.09300. lr 5.984715e-04:   6%|▋         | 339/5287 [02:42<39:19,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 339: train loss 5.09300. lr 5.984715e-04:   6%|▋         | 340/5287 [02:42<38:45,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 340: train loss 5.18588. lr 5.984625e-04:   6%|▋         | 340/5287 [02:42<38:45,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 340: train loss 5.18588. lr 5.984625e-04:   6%|▋         | 341/5287 [02:42<38:18,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 341: train loss 5.05860. lr 5.984535e-04:   6%|▋         | 341/5287 [02:43<38:18,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 341: train loss 5.05860. lr 5.984535e-04:   6%|▋         | 342/5287 [02:43<38:00,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 342: train loss 5.03054. lr 5.984444e-04:   6%|▋         | 342/5287 [02:43<38:00,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 342: train loss 5.03054. lr 5.984444e-04:   6%|▋         | 343/5287 [02:43<37:50,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 343: train loss 5.05043. lr 5.984353e-04:   6%|▋         | 343/5287 [02:43<37:50,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 343: train loss 5.05043. lr 5.984353e-04:   7%|▋         | 344/5287 [02:43<37:38,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 344: train loss 5.00172. lr 5.984262e-04:   7%|▋         | 344/5287 [02:44<37:38,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 344: train loss 5.00172. lr 5.984262e-04:   7%|▋         | 345/5287 [02:44<37:32,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 345: train loss 5.05082. lr 5.984171e-04:   7%|▋         | 345/5287 [02:44<37:32,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 345: train loss 5.05082. lr 5.984171e-04:   7%|▋         | 346/5287 [02:44<37:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 346: train loss 5.06698. lr 5.984079e-04:   7%|▋         | 346/5287 [02:45<37:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 346: train loss 5.06698. lr 5.984079e-04:   7%|▋         | 347/5287 [02:45<37:24,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 347: train loss 5.01041. lr 5.983987e-04:   7%|▋         | 347/5287 [02:45<37:24,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 347: train loss 5.01041. lr 5.983987e-04:   7%|▋         | 348/5287 [02:45<37:22,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 348: train loss 5.01862. lr 5.983895e-04:   7%|▋         | 348/5287 [02:46<37:22,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 348: train loss 5.01862. lr 5.983895e-04:   7%|▋         | 349/5287 [02:46<37:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 349: train loss 5.07677. lr 5.983803e-04:   7%|▋         | 349/5287 [02:46<37:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 349: train loss 5.07677. lr 5.983803e-04:   7%|▋         | 350/5287 [02:46<37:18,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 350: train loss 5.01425. lr 5.983710e-04:   7%|▋         | 350/5287 [02:47<37:18,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 350: train loss 5.01425. lr 5.983710e-04:   7%|▋         | 351/5287 [02:47<37:18,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 351: train loss 4.99625. lr 5.983617e-04:   7%|▋         | 351/5287 [02:47<37:18,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 351: train loss 4.99625. lr 5.983617e-04:   7%|▋         | 352/5287 [02:47<37:16,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 352: train loss 5.04888. lr 5.983524e-04:   7%|▋         | 352/5287 [02:48<37:16,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 352: train loss 5.04888. lr 5.983524e-04:   7%|▋         | 353/5287 [02:48<37:15,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 353: train loss 4.99498. lr 5.983431e-04:   7%|▋         | 353/5287 [02:48<37:15,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 353: train loss 4.99498. lr 5.983431e-04:   7%|▋         | 354/5287 [02:48<37:15,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 354: train loss 4.98007. lr 5.983337e-04:   7%|▋         | 354/5287 [02:48<37:15,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 354: train loss 4.98007. lr 5.983337e-04:   7%|▋         | 355/5287 [02:48<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 355: train loss 5.05829. lr 5.983243e-04:   7%|▋         | 355/5287 [02:49<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 355: train loss 5.05829. lr 5.983243e-04:   7%|▋         | 356/5287 [02:49<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 356: train loss 4.97495. lr 5.983149e-04:   7%|▋         | 356/5287 [02:49<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 356: train loss 4.97495. lr 5.983149e-04:   7%|▋         | 357/5287 [02:49<37:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 357: train loss 5.03360. lr 5.983054e-04:   7%|▋         | 357/5287 [02:50<37:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 357: train loss 5.03360. lr 5.983054e-04:   7%|▋         | 358/5287 [02:50<37:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 358: train loss 5.09254. lr 5.982960e-04:   7%|▋         | 358/5287 [02:50<37:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 358: train loss 5.09254. lr 5.982960e-04:   7%|▋         | 359/5287 [02:50<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 359: train loss 5.00025. lr 5.982865e-04:   7%|▋         | 359/5287 [02:51<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 359: train loss 5.00025. lr 5.982865e-04:   7%|▋         | 360/5287 [02:51<37:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 360: train loss 5.00610. lr 5.982769e-04:   7%|▋         | 360/5287 [02:51<37:13,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 360: train loss 5.00610. lr 5.982769e-04:   7%|▋         | 361/5287 [02:51<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 361: train loss 4.96786. lr 5.982674e-04:   7%|▋         | 361/5287 [02:52<37:12,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 361: train loss 4.96786. lr 5.982674e-04:   7%|▋         | 362/5287 [02:52<37:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 362: train loss 5.02259. lr 5.982578e-04:   7%|▋         | 362/5287 [02:52<37:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 362: train loss 5.02259. lr 5.982578e-04:   7%|▋         | 363/5287 [02:52<37:10,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 363: train loss 4.95470. lr 5.982482e-04:   7%|▋         | 363/5287 [02:53<37:10,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 363: train loss 4.95470. lr 5.982482e-04:   7%|▋         | 364/5287 [02:53<37:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 364: train loss 5.02465. lr 5.982386e-04:   7%|▋         | 364/5287 [02:53<37:11,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 364: train loss 5.02465. lr 5.982386e-04:   7%|▋         | 365/5287 [02:53<37:12,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 365: train loss 4.96112. lr 5.982289e-04:   7%|▋         | 365/5287 [02:54<37:12,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 365: train loss 4.96112. lr 5.982289e-04:   7%|▋         | 366/5287 [02:54<40:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 366: train loss 4.99977. lr 5.982192e-04:   7%|▋         | 366/5287 [02:54<40:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 366: train loss 4.99977. lr 5.982192e-04:   7%|▋         | 367/5287 [02:54<39:25,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 367: train loss 4.93402. lr 5.982095e-04:   7%|▋         | 367/5287 [02:54<39:25,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 367: train loss 4.93402. lr 5.982095e-04:   7%|▋         | 368/5287 [02:54<38:43,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 368: train loss 4.95284. lr 5.981998e-04:   7%|▋         | 368/5287 [02:55<38:43,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 368: train loss 4.95284. lr 5.981998e-04:   7%|▋         | 369/5287 [02:55<38:16,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 369: train loss 5.00131. lr 5.981900e-04:   7%|▋         | 369/5287 [02:55<38:16,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 369: train loss 5.00131. lr 5.981900e-04:   7%|▋         | 370/5287 [02:55<37:57,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 370: train loss 4.98729. lr 5.981802e-04:   7%|▋         | 370/5287 [02:56<37:57,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 370: train loss 4.98729. lr 5.981802e-04:   7%|▋         | 371/5287 [02:56<37:43,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 371: train loss 4.97334. lr 5.981704e-04:   7%|▋         | 371/5287 [02:56<37:43,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 371: train loss 4.97334. lr 5.981704e-04:   7%|▋         | 372/5287 [02:56<37:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 372: train loss 4.95340. lr 5.981605e-04:   7%|▋         | 372/5287 [02:57<37:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 372: train loss 4.95340. lr 5.981605e-04:   7%|▋         | 373/5287 [02:57<37:24,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 373: train loss 4.93261. lr 5.981507e-04:   7%|▋         | 373/5287 [02:57<37:24,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 373: train loss 4.93261. lr 5.981507e-04:   7%|▋         | 374/5287 [02:57<37:21,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 374: train loss 5.02312. lr 5.981408e-04:   7%|▋         | 374/5287 [02:58<37:21,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 374: train loss 5.02312. lr 5.981408e-04:   7%|▋         | 375/5287 [02:58<37:16,  2.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 375: train loss 4.93490. lr 5.981308e-04:   7%|▋         | 375/5287 [02:58<37:16,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 375: train loss 4.93490. lr 5.981308e-04:   7%|▋         | 376/5287 [02:58<37:13,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 376: train loss 4.96161. lr 5.981209e-04:   7%|▋         | 376/5287 [02:59<37:13,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 376: train loss 4.96161. lr 5.981209e-04:   7%|▋         | 377/5287 [02:59<37:11,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 377: train loss 5.01270. lr 5.981109e-04:   7%|▋         | 377/5287 [02:59<37:11,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 377: train loss 5.01270. lr 5.981109e-04:   7%|▋         | 378/5287 [02:59<37:08,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 378: train loss 4.94878. lr 5.981009e-04:   7%|▋         | 378/5287 [02:59<37:08,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 378: train loss 4.94878. lr 5.981009e-04:   7%|▋         | 379/5287 [02:59<37:07,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 379: train loss 4.97201. lr 5.980909e-04:   7%|▋         | 379/5287 [03:00<37:07,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 379: train loss 4.97201. lr 5.980909e-04:   7%|▋         | 380/5287 [03:00<37:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 380: train loss 4.96144. lr 5.980808e-04:   7%|▋         | 380/5287 [03:00<37:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 380: train loss 4.96144. lr 5.980808e-04:   7%|▋         | 381/5287 [03:00<37:04,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 381: train loss 4.92300. lr 5.980708e-04:   7%|▋         | 381/5287 [03:01<37:04,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 381: train loss 4.92300. lr 5.980708e-04:   7%|▋         | 382/5287 [03:01<37:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 382: train loss 4.92253. lr 5.980606e-04:   7%|▋         | 382/5287 [03:01<37:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 382: train loss 4.92253. lr 5.980606e-04:   7%|▋         | 383/5287 [03:01<37:03,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 383: train loss 4.93367. lr 5.980505e-04:   7%|▋         | 383/5287 [03:02<37:03,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 383: train loss 4.93367. lr 5.980505e-04:   7%|▋         | 384/5287 [03:02<37:06,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 384: train loss 4.94984. lr 5.980404e-04:   7%|▋         | 384/5287 [03:02<37:06,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 384: train loss 4.94984. lr 5.980404e-04:   7%|▋         | 385/5287 [03:02<37:03,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 385: train loss 4.87519. lr 5.980302e-04:   7%|▋         | 385/5287 [03:03<37:03,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 385: train loss 4.87519. lr 5.980302e-04:   7%|▋         | 386/5287 [03:03<37:04,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 386: train loss 4.93065. lr 5.980200e-04:   7%|▋         | 386/5287 [03:03<37:04,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 386: train loss 4.93065. lr 5.980200e-04:   7%|▋         | 387/5287 [03:03<37:03,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 387: train loss 4.79646. lr 5.980097e-04:   7%|▋         | 387/5287 [03:04<37:03,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 387: train loss 4.79646. lr 5.980097e-04:   7%|▋         | 388/5287 [03:04<37:02,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 388: train loss 4.83356. lr 5.979995e-04:   7%|▋         | 388/5287 [03:04<37:02,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 388: train loss 4.83356. lr 5.979995e-04:   7%|▋         | 389/5287 [03:04<37:02,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 389: train loss 4.87717. lr 5.979892e-04:   7%|▋         | 389/5287 [03:04<37:02,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 389: train loss 4.87717. lr 5.979892e-04:   7%|▋         | 390/5287 [03:04<37:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 390: train loss 4.90934. lr 5.979788e-04:   7%|▋         | 390/5287 [03:05<37:00,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 390: train loss 4.90934. lr 5.979788e-04:   7%|▋         | 391/5287 [03:05<37:01,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 391: train loss 4.92643. lr 5.979685e-04:   7%|▋         | 391/5287 [03:05<37:01,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 391: train loss 4.92643. lr 5.979685e-04:   7%|▋         | 392/5287 [03:05<37:00,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 392: train loss 4.87840. lr 5.979581e-04:   7%|▋         | 392/5287 [03:06<37:00,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 392: train loss 4.87840. lr 5.979581e-04:   7%|▋         | 393/5287 [03:06<36:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 393: train loss 4.83461. lr 5.979477e-04:   7%|▋         | 393/5287 [03:06<36:58,  2.21it/s]\u001b[A\n",
      "epoch 1 iter 393: train loss 4.83461. lr 5.979477e-04:   7%|▋         | 394/5287 [03:06<40:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 394: train loss 4.87098. lr 5.979373e-04:   7%|▋         | 394/5287 [03:07<40:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 394: train loss 4.87098. lr 5.979373e-04:   7%|▋         | 395/5287 [03:07<39:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 395: train loss 4.88287. lr 5.979269e-04:   7%|▋         | 395/5287 [03:07<39:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 395: train loss 4.88287. lr 5.979269e-04:   7%|▋         | 396/5287 [03:07<38:34,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 396: train loss 4.85752. lr 5.979164e-04:   7%|▋         | 396/5287 [03:08<38:34,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 396: train loss 4.85752. lr 5.979164e-04:   8%|▊         | 397/5287 [03:08<38:06,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 397: train loss 4.87988. lr 5.979059e-04:   8%|▊         | 397/5287 [03:08<38:06,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 397: train loss 4.87988. lr 5.979059e-04:   8%|▊         | 398/5287 [03:08<37:44,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 398: train loss 4.95505. lr 5.978954e-04:   8%|▊         | 398/5287 [03:09<37:44,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 398: train loss 4.95505. lr 5.978954e-04:   8%|▊         | 399/5287 [03:09<37:31,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 399: train loss 4.81826. lr 5.978848e-04:   8%|▊         | 399/5287 [03:09<37:31,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 399: train loss 4.81826. lr 5.978848e-04:   8%|▊         | 400/5287 [03:09<37:22,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 400: train loss 4.92254. lr 5.978742e-04:   8%|▊         | 400/5287 [03:10<37:22,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 400: train loss 4.92254. lr 5.978742e-04:   8%|▊         | 401/5287 [03:10<37:15,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 401: train loss 4.87022. lr 5.978636e-04:   8%|▊         | 401/5287 [03:10<37:15,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 401: train loss 4.87022. lr 5.978636e-04:   8%|▊         | 402/5287 [03:10<37:11,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 402: train loss 4.91771. lr 5.978530e-04:   8%|▊         | 402/5287 [03:11<37:11,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 402: train loss 4.91771. lr 5.978530e-04:   8%|▊         | 403/5287 [03:11<37:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 403: train loss 4.80215. lr 5.978423e-04:   8%|▊         | 403/5287 [03:11<37:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 403: train loss 4.80215. lr 5.978423e-04:   8%|▊         | 404/5287 [03:11<37:06,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 404: train loss 4.90144. lr 5.978316e-04:   8%|▊         | 404/5287 [03:11<37:06,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 404: train loss 4.90144. lr 5.978316e-04:   8%|▊         | 405/5287 [03:11<37:03,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 405: train loss 4.92553. lr 5.978209e-04:   8%|▊         | 405/5287 [03:12<37:03,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 405: train loss 4.92553. lr 5.978209e-04:   8%|▊         | 406/5287 [03:12<37:02,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 406: train loss 4.90153. lr 5.978102e-04:   8%|▊         | 406/5287 [03:12<37:02,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 406: train loss 4.90153. lr 5.978102e-04:   8%|▊         | 407/5287 [03:12<36:58,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 407: train loss 4.79353. lr 5.977994e-04:   8%|▊         | 407/5287 [03:13<36:58,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 407: train loss 4.79353. lr 5.977994e-04:   8%|▊         | 408/5287 [03:13<36:59,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 408: train loss 4.90860. lr 5.977886e-04:   8%|▊         | 408/5287 [03:13<36:59,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 408: train loss 4.90860. lr 5.977886e-04:   8%|▊         | 409/5287 [03:13<36:56,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 409: train loss 4.91139. lr 5.977778e-04:   8%|▊         | 409/5287 [03:14<36:56,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 409: train loss 4.91139. lr 5.977778e-04:   8%|▊         | 410/5287 [03:14<36:56,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 410: train loss 4.78518. lr 5.977670e-04:   8%|▊         | 410/5287 [03:14<36:56,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 410: train loss 4.78518. lr 5.977670e-04:   8%|▊         | 411/5287 [03:14<36:55,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 411: train loss 4.82334. lr 5.977561e-04:   8%|▊         | 411/5287 [03:15<36:55,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 411: train loss 4.82334. lr 5.977561e-04:   8%|▊         | 412/5287 [03:15<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 412: train loss 4.81565. lr 5.977452e-04:   8%|▊         | 412/5287 [03:15<36:52,  2.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 412: train loss 4.81565. lr 5.977452e-04:   8%|▊         | 413/5287 [03:15<36:54,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 413: train loss 4.85149. lr 5.977343e-04:   8%|▊         | 413/5287 [03:16<36:54,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 413: train loss 4.85149. lr 5.977343e-04:   8%|▊         | 414/5287 [03:16<36:53,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 414: train loss 4.86658. lr 5.977233e-04:   8%|▊         | 414/5287 [03:16<36:53,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 414: train loss 4.86658. lr 5.977233e-04:   8%|▊         | 415/5287 [03:16<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 415: train loss 4.79973. lr 5.977124e-04:   8%|▊         | 415/5287 [03:16<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 415: train loss 4.79973. lr 5.977124e-04:   8%|▊         | 416/5287 [03:16<36:53,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 416: train loss 4.79440. lr 5.977013e-04:   8%|▊         | 416/5287 [03:17<36:53,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 416: train loss 4.79440. lr 5.977013e-04:   8%|▊         | 417/5287 [03:17<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 417: train loss 4.83994. lr 5.976903e-04:   8%|▊         | 417/5287 [03:17<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 417: train loss 4.83994. lr 5.976903e-04:   8%|▊         | 418/5287 [03:17<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 418: train loss 4.80307. lr 5.976793e-04:   8%|▊         | 418/5287 [03:18<36:52,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 418: train loss 4.80307. lr 5.976793e-04:   8%|▊         | 419/5287 [03:18<36:51,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 419: train loss 4.77560. lr 5.976682e-04:   8%|▊         | 419/5287 [03:18<36:51,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 419: train loss 4.77560. lr 5.976682e-04:   8%|▊         | 420/5287 [03:18<36:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 420: train loss 4.82446. lr 5.976571e-04:   8%|▊         | 420/5287 [03:19<36:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 420: train loss 4.82446. lr 5.976571e-04:   8%|▊         | 421/5287 [03:19<36:51,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 421: train loss 4.81098. lr 5.976459e-04:   8%|▊         | 421/5287 [03:19<36:51,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 421: train loss 4.81098. lr 5.976459e-04:   8%|▊         | 422/5287 [03:19<39:37,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 422: train loss 4.87983. lr 5.976348e-04:   8%|▊         | 422/5287 [03:20<39:37,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 422: train loss 4.87983. lr 5.976348e-04:   8%|▊         | 423/5287 [03:20<38:46,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 423: train loss 4.82559. lr 5.976236e-04:   8%|▊         | 423/5287 [03:20<38:46,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 423: train loss 4.82559. lr 5.976236e-04:   8%|▊         | 424/5287 [03:20<38:11,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 424: train loss 4.82443. lr 5.976124e-04:   8%|▊         | 424/5287 [03:21<38:11,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 424: train loss 4.82443. lr 5.976124e-04:   8%|▊         | 425/5287 [03:21<37:47,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 425: train loss 4.73514. lr 5.976012e-04:   8%|▊         | 425/5287 [03:21<37:47,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 425: train loss 4.73514. lr 5.976012e-04:   8%|▊         | 426/5287 [03:21<37:28,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 426: train loss 4.81906. lr 5.975899e-04:   8%|▊         | 426/5287 [03:22<37:28,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 426: train loss 4.81906. lr 5.975899e-04:   8%|▊         | 427/5287 [03:22<37:15,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 427: train loss 4.79990. lr 5.975786e-04:   8%|▊         | 427/5287 [03:22<37:15,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 427: train loss 4.79990. lr 5.975786e-04:   8%|▊         | 428/5287 [03:22<37:07,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 428: train loss 4.78307. lr 5.975673e-04:   8%|▊         | 428/5287 [03:22<37:07,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 428: train loss 4.78307. lr 5.975673e-04:   8%|▊         | 429/5287 [03:22<37:01,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 429: train loss 4.77276. lr 5.975559e-04:   8%|▊         | 429/5287 [03:23<37:01,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 429: train loss 4.77276. lr 5.975559e-04:   8%|▊         | 430/5287 [03:23<36:56,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 430: train loss 4.79826. lr 5.975446e-04:   8%|▊         | 430/5287 [03:23<36:56,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 430: train loss 4.79826. lr 5.975446e-04:   8%|▊         | 431/5287 [03:23<36:53,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 431: train loss 4.77824. lr 5.975332e-04:   8%|▊         | 431/5287 [03:24<36:53,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 431: train loss 4.77824. lr 5.975332e-04:   8%|▊         | 432/5287 [03:24<36:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 432: train loss 4.80305. lr 5.975217e-04:   8%|▊         | 432/5287 [03:24<36:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 432: train loss 4.80305. lr 5.975217e-04:   8%|▊         | 433/5287 [03:24<36:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 433: train loss 4.70214. lr 5.975103e-04:   8%|▊         | 433/5287 [03:25<36:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 433: train loss 4.70214. lr 5.975103e-04:   8%|▊         | 434/5287 [03:25<36:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 434: train loss 4.75074. lr 5.974988e-04:   8%|▊         | 434/5287 [03:25<36:50,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 434: train loss 4.75074. lr 5.974988e-04:   8%|▊         | 435/5287 [03:25<36:49,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 435: train loss 4.77390. lr 5.974873e-04:   8%|▊         | 435/5287 [03:26<36:49,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 435: train loss 4.77390. lr 5.974873e-04:   8%|▊         | 436/5287 [03:26<36:48,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 436: train loss 4.76783. lr 5.974758e-04:   8%|▊         | 436/5287 [03:26<36:48,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 436: train loss 4.76783. lr 5.974758e-04:   8%|▊         | 437/5287 [03:26<36:48,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 437: train loss 4.77150. lr 5.974642e-04:   8%|▊         | 437/5287 [03:27<36:48,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 437: train loss 4.77150. lr 5.974642e-04:   8%|▊         | 438/5287 [03:27<36:47,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 438: train loss 4.74238. lr 5.974527e-04:   8%|▊         | 438/5287 [03:27<36:47,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 438: train loss 4.74238. lr 5.974527e-04:   8%|▊         | 439/5287 [03:27<36:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 439: train loss 4.82063. lr 5.974411e-04:   8%|▊         | 439/5287 [03:27<36:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 439: train loss 4.82063. lr 5.974411e-04:   8%|▊         | 440/5287 [03:27<36:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 440: train loss 4.76559. lr 5.974294e-04:   8%|▊         | 440/5287 [03:28<36:46,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 440: train loss 4.76559. lr 5.974294e-04:   8%|▊         | 441/5287 [03:28<36:44,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 441: train loss 4.77070. lr 5.974178e-04:   8%|▊         | 441/5287 [03:28<36:44,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 441: train loss 4.77070. lr 5.974178e-04:   8%|▊         | 442/5287 [03:28<36:45,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 442: train loss 4.76486. lr 5.974061e-04:   8%|▊         | 442/5287 [03:29<36:45,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 442: train loss 4.76486. lr 5.974061e-04:   8%|▊         | 443/5287 [03:29<36:44,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 443: train loss 4.81732. lr 5.973944e-04:   8%|▊         | 443/5287 [03:29<36:44,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 443: train loss 4.81732. lr 5.973944e-04:   8%|▊         | 444/5287 [03:29<36:44,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 444: train loss 4.67063. lr 5.973826e-04:   8%|▊         | 444/5287 [03:30<36:44,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 444: train loss 4.67063. lr 5.973826e-04:   8%|▊         | 445/5287 [03:30<36:43,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 445: train loss 4.68450. lr 5.973709e-04:   8%|▊         | 445/5287 [03:30<36:43,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 445: train loss 4.68450. lr 5.973709e-04:   8%|▊         | 446/5287 [03:30<36:42,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 446: train loss 4.74347. lr 5.973591e-04:   8%|▊         | 446/5287 [03:31<36:42,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 446: train loss 4.74347. lr 5.973591e-04:   8%|▊         | 447/5287 [03:31<36:42,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 447: train loss 4.80696. lr 5.973473e-04:   8%|▊         | 447/5287 [03:31<36:42,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 447: train loss 4.80696. lr 5.973473e-04:   8%|▊         | 448/5287 [03:31<36:41,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 448: train loss 4.75823. lr 5.973354e-04:   8%|▊         | 448/5287 [03:32<36:41,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 448: train loss 4.75823. lr 5.973354e-04:   8%|▊         | 449/5287 [03:32<36:41,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 449: train loss 4.76545. lr 5.973236e-04:   8%|▊         | 449/5287 [03:32<36:41,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 449: train loss 4.76545. lr 5.973236e-04:   9%|▊         | 450/5287 [03:32<39:28,  2.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 450: train loss 4.78544. lr 5.973117e-04:   9%|▊         | 450/5287 [03:33<39:28,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 450: train loss 4.78544. lr 5.973117e-04:   9%|▊         | 451/5287 [03:33<38:37,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 451: train loss 4.74743. lr 5.972997e-04:   9%|▊         | 451/5287 [03:33<38:37,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 451: train loss 4.74743. lr 5.972997e-04:   9%|▊         | 452/5287 [03:33<38:02,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 452: train loss 4.83584. lr 5.972878e-04:   9%|▊         | 452/5287 [03:33<38:02,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 452: train loss 4.83584. lr 5.972878e-04:   9%|▊         | 453/5287 [03:33<37:36,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 453: train loss 4.78356. lr 5.972758e-04:   9%|▊         | 453/5287 [03:34<37:36,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 453: train loss 4.78356. lr 5.972758e-04:   9%|▊         | 454/5287 [03:34<37:20,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 454: train loss 4.76739. lr 5.972638e-04:   9%|▊         | 454/5287 [03:34<37:20,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 454: train loss 4.76739. lr 5.972638e-04:   9%|▊         | 455/5287 [03:34<37:07,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 455: train loss 4.73588. lr 5.972518e-04:   9%|▊         | 455/5287 [03:35<37:07,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 455: train loss 4.73588. lr 5.972518e-04:   9%|▊         | 456/5287 [03:35<36:58,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 456: train loss 4.71909. lr 5.972397e-04:   9%|▊         | 456/5287 [03:35<36:58,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 456: train loss 4.71909. lr 5.972397e-04:   9%|▊         | 457/5287 [03:35<36:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 457: train loss 4.70914. lr 5.972277e-04:   9%|▊         | 457/5287 [03:36<36:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 457: train loss 4.70914. lr 5.972277e-04:   9%|▊         | 458/5287 [03:36<36:45,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 458: train loss 4.70500. lr 5.972156e-04:   9%|▊         | 458/5287 [03:36<36:45,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 458: train loss 4.70500. lr 5.972156e-04:   9%|▊         | 459/5287 [03:36<36:42,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 459: train loss 4.73419. lr 5.972034e-04:   9%|▊         | 459/5287 [03:37<36:42,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 459: train loss 4.73419. lr 5.972034e-04:   9%|▊         | 460/5287 [03:37<36:39,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 460: train loss 4.68527. lr 5.971913e-04:   9%|▊         | 460/5287 [03:37<36:39,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 460: train loss 4.68527. lr 5.971913e-04:   9%|▊         | 461/5287 [03:37<36:37,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 461: train loss 4.65774. lr 5.971791e-04:   9%|▊         | 461/5287 [03:38<36:37,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 461: train loss 4.65774. lr 5.971791e-04:   9%|▊         | 462/5287 [03:38<36:35,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 462: train loss 4.72420. lr 5.971669e-04:   9%|▊         | 462/5287 [03:38<36:35,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 462: train loss 4.72420. lr 5.971669e-04:   9%|▉         | 463/5287 [03:38<36:34,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 463: train loss 4.78540. lr 5.971546e-04:   9%|▉         | 463/5287 [03:38<36:34,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 463: train loss 4.78540. lr 5.971546e-04:   9%|▉         | 464/5287 [03:38<36:33,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 464: train loss 4.69461. lr 5.971424e-04:   9%|▉         | 464/5287 [03:39<36:33,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 464: train loss 4.69461. lr 5.971424e-04:   9%|▉         | 465/5287 [03:39<36:32,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 465: train loss 4.70711. lr 5.971301e-04:   9%|▉         | 465/5287 [03:39<36:32,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 465: train loss 4.70711. lr 5.971301e-04:   9%|▉         | 466/5287 [03:39<36:32,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 466: train loss 4.68966. lr 5.971178e-04:   9%|▉         | 466/5287 [03:40<36:32,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 466: train loss 4.68966. lr 5.971178e-04:   9%|▉         | 467/5287 [03:40<36:31,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 467: train loss 4.64730. lr 5.971054e-04:   9%|▉         | 467/5287 [03:40<36:31,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 467: train loss 4.64730. lr 5.971054e-04:   9%|▉         | 468/5287 [03:40<36:31,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 468: train loss 4.69962. lr 5.970931e-04:   9%|▉         | 468/5287 [03:41<36:31,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 468: train loss 4.69962. lr 5.970931e-04:   9%|▉         | 469/5287 [03:41<36:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 469: train loss 4.64212. lr 5.970807e-04:   9%|▉         | 469/5287 [03:41<36:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 469: train loss 4.64212. lr 5.970807e-04:   9%|▉         | 470/5287 [03:41<36:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 470: train loss 4.79923. lr 5.970683e-04:   9%|▉         | 470/5287 [03:42<36:30,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 470: train loss 4.79923. lr 5.970683e-04:   9%|▉         | 471/5287 [03:42<36:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 471: train loss 4.73671. lr 5.970558e-04:   9%|▉         | 471/5287 [03:42<36:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 471: train loss 4.73671. lr 5.970558e-04:   9%|▉         | 472/5287 [03:42<36:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 472: train loss 4.64992. lr 5.970433e-04:   9%|▉         | 472/5287 [03:43<36:28,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 472: train loss 4.64992. lr 5.970433e-04:   9%|▉         | 473/5287 [03:43<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 473: train loss 4.74644. lr 5.970308e-04:   9%|▉         | 473/5287 [03:43<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 473: train loss 4.74644. lr 5.970308e-04:   9%|▉         | 474/5287 [03:43<36:26,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 474: train loss 4.65629. lr 5.970183e-04:   9%|▉         | 474/5287 [03:43<36:26,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 474: train loss 4.65629. lr 5.970183e-04:   9%|▉         | 475/5287 [03:43<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 475: train loss 4.69683. lr 5.970058e-04:   9%|▉         | 475/5287 [03:44<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 475: train loss 4.69683. lr 5.970058e-04:   9%|▉         | 476/5287 [03:44<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 476: train loss 4.61510. lr 5.969932e-04:   9%|▉         | 476/5287 [03:44<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 476: train loss 4.61510. lr 5.969932e-04:   9%|▉         | 477/5287 [03:44<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 477: train loss 4.62245. lr 5.969806e-04:   9%|▉         | 477/5287 [03:45<36:27,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 477: train loss 4.62245. lr 5.969806e-04:   9%|▉         | 478/5287 [03:45<39:12,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 478: train loss 4.66092. lr 5.969679e-04:   9%|▉         | 478/5287 [03:45<39:12,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 478: train loss 4.66092. lr 5.969679e-04:   9%|▉         | 479/5287 [03:45<38:23,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 479: train loss 4.62508. lr 5.969553e-04:   9%|▉         | 479/5287 [03:46<38:23,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 479: train loss 4.62508. lr 5.969553e-04:   9%|▉         | 480/5287 [03:46<37:47,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 480: train loss 4.66896. lr 5.969426e-04:   9%|▉         | 480/5287 [03:46<37:47,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 480: train loss 4.66896. lr 5.969426e-04:   9%|▉         | 481/5287 [03:46<37:24,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 481: train loss 4.70069. lr 5.969299e-04:   9%|▉         | 481/5287 [03:47<37:24,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 481: train loss 4.70069. lr 5.969299e-04:   9%|▉         | 482/5287 [03:47<37:05,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 482: train loss 4.62512. lr 5.969172e-04:   9%|▉         | 482/5287 [03:47<37:05,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 482: train loss 4.62512. lr 5.969172e-04:   9%|▉         | 483/5287 [03:47<36:53,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 483: train loss 4.75249. lr 5.969044e-04:   9%|▉         | 483/5287 [03:48<36:53,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 483: train loss 4.75249. lr 5.969044e-04:   9%|▉         | 484/5287 [03:48<36:44,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 484: train loss 4.67522. lr 5.968916e-04:   9%|▉         | 484/5287 [03:48<36:44,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 484: train loss 4.67522. lr 5.968916e-04:   9%|▉         | 485/5287 [03:48<36:37,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 485: train loss 4.61051. lr 5.968788e-04:   9%|▉         | 485/5287 [03:49<36:37,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 485: train loss 4.61051. lr 5.968788e-04:   9%|▉         | 486/5287 [03:49<36:33,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 486: train loss 4.63490. lr 5.968660e-04:   9%|▉         | 486/5287 [03:49<36:33,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 486: train loss 4.63490. lr 5.968660e-04:   9%|▉         | 487/5287 [03:49<36:29,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 487: train loss 4.66203. lr 5.968531e-04:   9%|▉         | 487/5287 [03:50<36:29,  2.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 487: train loss 4.66203. lr 5.968531e-04:   9%|▉         | 488/5287 [03:50<36:28,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 488: train loss 4.68233. lr 5.968402e-04:   9%|▉         | 488/5287 [03:50<36:28,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 488: train loss 4.68233. lr 5.968402e-04:   9%|▉         | 489/5287 [03:50<36:25,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 489: train loss 4.62380. lr 5.968273e-04:   9%|▉         | 489/5287 [03:50<36:25,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 489: train loss 4.62380. lr 5.968273e-04:   9%|▉         | 490/5287 [03:50<36:25,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 490: train loss 4.61471. lr 5.968143e-04:   9%|▉         | 490/5287 [03:51<36:25,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 490: train loss 4.61471. lr 5.968143e-04:   9%|▉         | 491/5287 [03:51<36:22,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 491: train loss 4.63968. lr 5.968014e-04:   9%|▉         | 491/5287 [03:51<36:22,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 491: train loss 4.63968. lr 5.968014e-04:   9%|▉         | 492/5287 [03:51<36:23,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 492: train loss 4.64331. lr 5.967884e-04:   9%|▉         | 492/5287 [03:52<36:23,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 492: train loss 4.64331. lr 5.967884e-04:   9%|▉         | 493/5287 [03:52<36:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 493: train loss 4.69171. lr 5.967754e-04:   9%|▉         | 493/5287 [03:52<36:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 493: train loss 4.69171. lr 5.967754e-04:   9%|▉         | 494/5287 [03:52<36:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 494: train loss 4.71169. lr 5.967623e-04:   9%|▉         | 494/5287 [03:53<36:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 494: train loss 4.71169. lr 5.967623e-04:   9%|▉         | 495/5287 [03:53<36:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 495: train loss 4.62606. lr 5.967492e-04:   9%|▉         | 495/5287 [03:53<36:20,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 495: train loss 4.62606. lr 5.967492e-04:   9%|▉         | 496/5287 [03:53<36:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 496: train loss 4.56811. lr 5.967361e-04:   9%|▉         | 496/5287 [03:54<36:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 496: train loss 4.56811. lr 5.967361e-04:   9%|▉         | 497/5287 [03:54<36:18,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 497: train loss 4.54525. lr 5.967230e-04:   9%|▉         | 497/5287 [03:54<36:18,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 497: train loss 4.54525. lr 5.967230e-04:   9%|▉         | 498/5287 [03:54<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 498: train loss 4.61818. lr 5.967099e-04:   9%|▉         | 498/5287 [03:55<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 498: train loss 4.61818. lr 5.967099e-04:   9%|▉         | 499/5287 [03:55<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 499: train loss 4.65609. lr 5.966967e-04:   9%|▉         | 499/5287 [03:55<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 499: train loss 4.65609. lr 5.966967e-04:   9%|▉         | 500/5287 [03:55<36:16,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 500: train loss 4.55787. lr 5.966835e-04:   9%|▉         | 500/5287 [03:55<36:16,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 500: train loss 4.55787. lr 5.966835e-04:   9%|▉         | 501/5287 [03:55<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 501: train loss 4.61519. lr 5.966702e-04:   9%|▉         | 501/5287 [03:56<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 501: train loss 4.61519. lr 5.966702e-04:   9%|▉         | 502/5287 [03:56<36:16,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 502: train loss 4.54992. lr 5.966570e-04:   9%|▉         | 502/5287 [03:56<36:16,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 502: train loss 4.54992. lr 5.966570e-04:  10%|▉         | 503/5287 [03:56<36:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 503: train loss 4.62963. lr 5.966437e-04:  10%|▉         | 503/5287 [03:57<36:19,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 503: train loss 4.62963. lr 5.966437e-04:  10%|▉         | 504/5287 [03:57<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 504: train loss 4.56047. lr 5.966304e-04:  10%|▉         | 504/5287 [03:57<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 504: train loss 4.56047. lr 5.966304e-04:  10%|▉         | 505/5287 [03:57<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 505: train loss 4.54172. lr 5.966170e-04:  10%|▉         | 505/5287 [03:58<36:17,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 505: train loss 4.54172. lr 5.966170e-04:  10%|▉         | 506/5287 [03:58<38:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 506: train loss 4.65029. lr 5.966037e-04:  10%|▉         | 506/5287 [03:58<38:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 506: train loss 4.65029. lr 5.966037e-04:  10%|▉         | 507/5287 [03:58<38:10,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 507: train loss 4.59977. lr 5.965903e-04:  10%|▉         | 507/5287 [03:59<38:10,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 507: train loss 4.59977. lr 5.965903e-04:  10%|▉         | 508/5287 [03:59<37:35,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 508: train loss 4.58123. lr 5.965769e-04:  10%|▉         | 508/5287 [03:59<37:35,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 508: train loss 4.58123. lr 5.965769e-04:  10%|▉         | 509/5287 [03:59<37:09,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 509: train loss 4.57535. lr 5.965634e-04:  10%|▉         | 509/5287 [04:00<37:09,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 509: train loss 4.57535. lr 5.965634e-04:  10%|▉         | 510/5287 [04:00<36:53,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 510: train loss 4.55465. lr 5.965500e-04:  10%|▉         | 510/5287 [04:00<36:53,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 510: train loss 4.55465. lr 5.965500e-04:  10%|▉         | 511/5287 [04:00<36:40,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 511: train loss 4.58850. lr 5.965365e-04:  10%|▉         | 511/5287 [04:01<36:40,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 511: train loss 4.58850. lr 5.965365e-04:  10%|▉         | 512/5287 [04:01<36:32,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 512: train loss 4.56503. lr 5.965229e-04:  10%|▉         | 512/5287 [04:01<36:32,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 512: train loss 4.56503. lr 5.965229e-04:  10%|▉         | 513/5287 [04:01<36:30,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 513: train loss 4.65340. lr 5.965094e-04:  10%|▉         | 513/5287 [04:01<36:30,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 513: train loss 4.65340. lr 5.965094e-04:  10%|▉         | 514/5287 [04:01<36:26,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 514: train loss 4.54666. lr 5.964958e-04:  10%|▉         | 514/5287 [04:02<36:26,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 514: train loss 4.54666. lr 5.964958e-04:  10%|▉         | 515/5287 [04:02<36:20,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 515: train loss 4.57147. lr 5.964822e-04:  10%|▉         | 515/5287 [04:02<36:20,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 515: train loss 4.57147. lr 5.964822e-04:  10%|▉         | 516/5287 [04:02<36:18,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 516: train loss 4.57541. lr 5.964686e-04:  10%|▉         | 516/5287 [04:03<36:18,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 516: train loss 4.57541. lr 5.964686e-04:  10%|▉         | 517/5287 [04:03<36:14,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 517: train loss 4.52725. lr 5.964550e-04:  10%|▉         | 517/5287 [04:03<36:14,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 517: train loss 4.52725. lr 5.964550e-04:  10%|▉         | 518/5287 [04:03<36:15,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 518: train loss 4.58938. lr 5.964413e-04:  10%|▉         | 518/5287 [04:04<36:15,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 518: train loss 4.58938. lr 5.964413e-04:  10%|▉         | 519/5287 [04:04<36:12,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 519: train loss 4.62968. lr 5.964276e-04:  10%|▉         | 519/5287 [04:04<36:12,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 519: train loss 4.62968. lr 5.964276e-04:  10%|▉         | 520/5287 [04:04<36:13,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 520: train loss 4.54376. lr 5.964138e-04:  10%|▉         | 520/5287 [04:05<36:13,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 520: train loss 4.54376. lr 5.964138e-04:  10%|▉         | 521/5287 [04:05<36:12,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 521: train loss 4.54025. lr 5.964001e-04:  10%|▉         | 521/5287 [04:05<36:12,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 521: train loss 4.54025. lr 5.964001e-04:  10%|▉         | 522/5287 [04:05<36:12,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 522: train loss 4.56919. lr 5.963863e-04:  10%|▉         | 522/5287 [04:06<36:12,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 522: train loss 4.56919. lr 5.963863e-04:  10%|▉         | 523/5287 [04:06<36:11,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 523: train loss 4.52916. lr 5.963725e-04:  10%|▉         | 523/5287 [04:06<36:11,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 523: train loss 4.52916. lr 5.963725e-04:  10%|▉         | 524/5287 [04:06<36:10,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 524: train loss 4.53977. lr 5.963587e-04:  10%|▉         | 524/5287 [04:06<36:10,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 524: train loss 4.53977. lr 5.963587e-04:  10%|▉         | 525/5287 [04:06<36:08,  2.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 525: train loss 4.58922. lr 5.963448e-04:  10%|▉         | 525/5287 [04:07<36:08,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 525: train loss 4.58922. lr 5.963448e-04:  10%|▉         | 526/5287 [04:07<36:09,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 526: train loss 4.50002. lr 5.963309e-04:  10%|▉         | 526/5287 [04:07<36:09,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 526: train loss 4.50002. lr 5.963309e-04:  10%|▉         | 527/5287 [04:07<36:07,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 527: train loss 4.51494. lr 5.963170e-04:  10%|▉         | 527/5287 [04:08<36:07,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 527: train loss 4.51494. lr 5.963170e-04:  10%|▉         | 528/5287 [04:08<36:08,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 528: train loss 4.46901. lr 5.963031e-04:  10%|▉         | 528/5287 [04:08<36:08,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 528: train loss 4.46901. lr 5.963031e-04:  10%|█         | 529/5287 [04:08<36:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 529: train loss 4.59929. lr 5.962891e-04:  10%|█         | 529/5287 [04:09<36:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 529: train loss 4.59929. lr 5.962891e-04:  10%|█         | 530/5287 [04:09<36:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 530: train loss 4.55633. lr 5.962751e-04:  10%|█         | 530/5287 [04:09<36:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 530: train loss 4.55633. lr 5.962751e-04:  10%|█         | 531/5287 [04:09<36:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 531: train loss 4.47085. lr 5.962611e-04:  10%|█         | 531/5287 [04:10<36:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 531: train loss 4.47085. lr 5.962611e-04:  10%|█         | 532/5287 [04:10<36:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 532: train loss 4.53780. lr 5.962470e-04:  10%|█         | 532/5287 [04:10<36:05,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 532: train loss 4.53780. lr 5.962470e-04:  10%|█         | 533/5287 [04:10<36:04,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 533: train loss 4.48068. lr 5.962330e-04:  10%|█         | 533/5287 [04:11<36:04,  2.20it/s]\u001b[A\n",
      "epoch 1 iter 533: train loss 4.48068. lr 5.962330e-04:  10%|█         | 534/5287 [04:11<38:48,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 534: train loss 4.54224. lr 5.962189e-04:  10%|█         | 534/5287 [04:11<38:48,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 534: train loss 4.54224. lr 5.962189e-04:  10%|█         | 535/5287 [04:11<37:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 535: train loss 4.47051. lr 5.962048e-04:  10%|█         | 535/5287 [04:12<37:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 535: train loss 4.47051. lr 5.962048e-04:  10%|█         | 536/5287 [04:12<37:24,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 536: train loss 4.51086. lr 5.961906e-04:  10%|█         | 536/5287 [04:12<37:24,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 536: train loss 4.51086. lr 5.961906e-04:  10%|█         | 537/5287 [04:12<37:01,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 537: train loss 4.44592. lr 5.961764e-04:  10%|█         | 537/5287 [04:13<37:01,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 537: train loss 4.44592. lr 5.961764e-04:  10%|█         | 538/5287 [04:13<36:45,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 538: train loss 4.52755. lr 5.961622e-04:  10%|█         | 538/5287 [04:13<36:45,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 538: train loss 4.52755. lr 5.961622e-04:  10%|█         | 539/5287 [04:13<36:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 539: train loss 4.49055. lr 5.961480e-04:  10%|█         | 539/5287 [04:13<36:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 539: train loss 4.49055. lr 5.961480e-04:  10%|█         | 540/5287 [04:13<36:22,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 540: train loss 4.59832. lr 5.961337e-04:  10%|█         | 540/5287 [04:14<36:22,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 540: train loss 4.59832. lr 5.961337e-04:  10%|█         | 541/5287 [04:14<36:16,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 541: train loss 4.50493. lr 5.961195e-04:  10%|█         | 541/5287 [04:14<36:16,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 541: train loss 4.50493. lr 5.961195e-04:  10%|█         | 542/5287 [04:14<36:12,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 542: train loss 4.54755. lr 5.961052e-04:  10%|█         | 542/5287 [04:15<36:12,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 542: train loss 4.54755. lr 5.961052e-04:  10%|█         | 543/5287 [04:15<36:10,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 543: train loss 4.57854. lr 5.960908e-04:  10%|█         | 543/5287 [04:15<36:10,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 543: train loss 4.57854. lr 5.960908e-04:  10%|█         | 544/5287 [04:15<36:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 544: train loss 4.49759. lr 5.960765e-04:  10%|█         | 544/5287 [04:16<36:07,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 544: train loss 4.49759. lr 5.960765e-04:  10%|█         | 545/5287 [04:16<36:04,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 545: train loss 4.47227. lr 5.960621e-04:  10%|█         | 545/5287 [04:16<36:04,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 545: train loss 4.47227. lr 5.960621e-04:  10%|█         | 546/5287 [04:16<36:04,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 546: train loss 4.48581. lr 5.960477e-04:  10%|█         | 546/5287 [04:17<36:04,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 546: train loss 4.48581. lr 5.960477e-04:  10%|█         | 547/5287 [04:17<36:03,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 547: train loss 4.44672. lr 5.960332e-04:  10%|█         | 547/5287 [04:17<36:03,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 547: train loss 4.44672. lr 5.960332e-04:  10%|█         | 548/5287 [04:17<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 548: train loss 4.44827. lr 5.960188e-04:  10%|█         | 548/5287 [04:18<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 548: train loss 4.44827. lr 5.960188e-04:  10%|█         | 549/5287 [04:18<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 549: train loss 4.52309. lr 5.960043e-04:  10%|█         | 549/5287 [04:18<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 549: train loss 4.52309. lr 5.960043e-04:  10%|█         | 550/5287 [04:18<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 550: train loss 4.45854. lr 5.959898e-04:  10%|█         | 550/5287 [04:18<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 550: train loss 4.45854. lr 5.959898e-04:  10%|█         | 551/5287 [04:18<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 551: train loss 4.49738. lr 5.959752e-04:  10%|█         | 551/5287 [04:19<36:00,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 551: train loss 4.49738. lr 5.959752e-04:  10%|█         | 552/5287 [04:19<35:59,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 552: train loss 4.48089. lr 5.959607e-04:  10%|█         | 552/5287 [04:19<35:59,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 552: train loss 4.48089. lr 5.959607e-04:  10%|█         | 553/5287 [04:19<35:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 553: train loss 4.48099. lr 5.959461e-04:  10%|█         | 553/5287 [04:20<35:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 553: train loss 4.48099. lr 5.959461e-04:  10%|█         | 554/5287 [04:20<35:59,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 554: train loss 4.42789. lr 5.959315e-04:  10%|█         | 554/5287 [04:20<35:59,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 554: train loss 4.42789. lr 5.959315e-04:  10%|█         | 555/5287 [04:20<35:57,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 555: train loss 4.52166. lr 5.959168e-04:  10%|█         | 555/5287 [04:21<35:57,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 555: train loss 4.52166. lr 5.959168e-04:  11%|█         | 556/5287 [04:21<35:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 556: train loss 4.47987. lr 5.959021e-04:  11%|█         | 556/5287 [04:21<35:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 556: train loss 4.47987. lr 5.959021e-04:  11%|█         | 557/5287 [04:21<35:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 557: train loss 4.49701. lr 5.958874e-04:  11%|█         | 557/5287 [04:22<35:58,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 557: train loss 4.49701. lr 5.958874e-04:  11%|█         | 558/5287 [04:22<35:57,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 558: train loss 4.45920. lr 5.958727e-04:  11%|█         | 558/5287 [04:22<35:57,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 558: train loss 4.45920. lr 5.958727e-04:  11%|█         | 559/5287 [04:22<35:56,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 559: train loss 4.50766. lr 5.958580e-04:  11%|█         | 559/5287 [04:23<35:56,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 559: train loss 4.50766. lr 5.958580e-04:  11%|█         | 560/5287 [04:23<35:55,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 560: train loss 4.41667. lr 5.958432e-04:  11%|█         | 560/5287 [04:23<35:55,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 560: train loss 4.41667. lr 5.958432e-04:  11%|█         | 561/5287 [04:23<35:55,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 561: train loss 4.49076. lr 5.958284e-04:  11%|█         | 561/5287 [04:24<35:55,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 561: train loss 4.49076. lr 5.958284e-04:  11%|█         | 562/5287 [04:24<39:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 562: train loss 4.35763. lr 5.958136e-04:  11%|█         | 562/5287 [04:24<39:11,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 562: train loss 4.35763. lr 5.958136e-04:  11%|█         | 563/5287 [04:24<38:12,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 563: train loss 4.42583. lr 5.957987e-04:  11%|█         | 563/5287 [04:25<38:12,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 563: train loss 4.42583. lr 5.957987e-04:  11%|█         | 564/5287 [04:25<37:31,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 564: train loss 4.49346. lr 5.957838e-04:  11%|█         | 564/5287 [04:25<37:31,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 564: train loss 4.49346. lr 5.957838e-04:  11%|█         | 565/5287 [04:25<37:00,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 565: train loss 4.37661. lr 5.957689e-04:  11%|█         | 565/5287 [04:25<37:00,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 565: train loss 4.37661. lr 5.957689e-04:  11%|█         | 566/5287 [04:25<36:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 566: train loss 4.40064. lr 5.957540e-04:  11%|█         | 566/5287 [04:26<36:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 566: train loss 4.40064. lr 5.957540e-04:  11%|█         | 567/5287 [04:26<36:26,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 567: train loss 4.38706. lr 5.957390e-04:  11%|█         | 567/5287 [04:26<36:26,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 567: train loss 4.38706. lr 5.957390e-04:  11%|█         | 568/5287 [04:26<36:15,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 568: train loss 4.42351. lr 5.957240e-04:  11%|█         | 568/5287 [04:27<36:15,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 568: train loss 4.42351. lr 5.957240e-04:  11%|█         | 569/5287 [04:27<36:10,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 569: train loss 4.36681. lr 5.957090e-04:  11%|█         | 569/5287 [04:27<36:10,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 569: train loss 4.36681. lr 5.957090e-04:  11%|█         | 570/5287 [04:27<36:05,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 570: train loss 4.43001. lr 5.956940e-04:  11%|█         | 570/5287 [04:28<36:05,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 570: train loss 4.43001. lr 5.956940e-04:  11%|█         | 571/5287 [04:28<36:02,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 571: train loss 4.42276. lr 5.956789e-04:  11%|█         | 571/5287 [04:28<36:02,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 571: train loss 4.42276. lr 5.956789e-04:  11%|█         | 572/5287 [04:28<35:58,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 572: train loss 4.42960. lr 5.956638e-04:  11%|█         | 572/5287 [04:29<35:58,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 572: train loss 4.42960. lr 5.956638e-04:  11%|█         | 573/5287 [04:29<35:56,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 573: train loss 4.40067. lr 5.956487e-04:  11%|█         | 573/5287 [04:29<35:56,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 573: train loss 4.40067. lr 5.956487e-04:  11%|█         | 574/5287 [04:29<35:55,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 574: train loss 4.45256. lr 5.956336e-04:  11%|█         | 574/5287 [04:30<35:55,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 574: train loss 4.45256. lr 5.956336e-04:  11%|█         | 575/5287 [04:30<35:54,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 575: train loss 4.34797. lr 5.956184e-04:  11%|█         | 575/5287 [04:30<35:54,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 575: train loss 4.34797. lr 5.956184e-04:  11%|█         | 576/5287 [04:30<35:54,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 576: train loss 4.41828. lr 5.956032e-04:  11%|█         | 576/5287 [04:30<35:54,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 576: train loss 4.41828. lr 5.956032e-04:  11%|█         | 577/5287 [04:30<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 577: train loss 4.39460. lr 5.955880e-04:  11%|█         | 577/5287 [04:31<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 577: train loss 4.39460. lr 5.955880e-04:  11%|█         | 578/5287 [04:31<35:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 578: train loss 4.42237. lr 5.955728e-04:  11%|█         | 578/5287 [04:31<35:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 578: train loss 4.42237. lr 5.955728e-04:  11%|█         | 579/5287 [04:31<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 579: train loss 4.45967. lr 5.955575e-04:  11%|█         | 579/5287 [04:32<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 579: train loss 4.45967. lr 5.955575e-04:  11%|█         | 580/5287 [04:32<35:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 580: train loss 4.42397. lr 5.955422e-04:  11%|█         | 580/5287 [04:32<35:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 580: train loss 4.42397. lr 5.955422e-04:  11%|█         | 581/5287 [04:32<35:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 581: train loss 4.43586. lr 5.955269e-04:  11%|█         | 581/5287 [04:33<35:51,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 581: train loss 4.43586. lr 5.955269e-04:  11%|█         | 582/5287 [04:33<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 582: train loss 4.36558. lr 5.955115e-04:  11%|█         | 582/5287 [04:33<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 582: train loss 4.36558. lr 5.955115e-04:  11%|█         | 583/5287 [04:33<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 583: train loss 4.32139. lr 5.954961e-04:  11%|█         | 583/5287 [04:34<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 583: train loss 4.32139. lr 5.954961e-04:  11%|█         | 584/5287 [04:34<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 584: train loss 4.35601. lr 5.954807e-04:  11%|█         | 584/5287 [04:34<35:52,  2.19it/s]\u001b[A\n",
      "epoch 1 iter 584: train loss 4.35601. lr 5.954807e-04:  11%|█         | 585/5287 [04:34<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 585: train loss 4.39979. lr 5.954653e-04:  11%|█         | 585/5287 [04:35<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 585: train loss 4.39979. lr 5.954653e-04:  11%|█         | 586/5287 [04:35<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 586: train loss 4.35789. lr 5.954498e-04:  11%|█         | 586/5287 [04:35<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 586: train loss 4.35789. lr 5.954498e-04:  11%|█         | 587/5287 [04:35<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 587: train loss 4.41941. lr 5.954344e-04:  11%|█         | 587/5287 [04:35<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 587: train loss 4.41941. lr 5.954344e-04:  11%|█         | 588/5287 [04:35<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 588: train loss 4.33542. lr 5.954189e-04:  11%|█         | 588/5287 [04:36<35:51,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 588: train loss 4.33542. lr 5.954189e-04:  11%|█         | 589/5287 [04:36<35:50,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 589: train loss 4.38828. lr 5.954033e-04:  11%|█         | 589/5287 [04:37<35:50,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 589: train loss 4.38828. lr 5.954033e-04:  11%|█         | 590/5287 [04:37<38:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 590: train loss 4.48532. lr 5.953878e-04:  11%|█         | 590/5287 [04:37<38:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 590: train loss 4.48532. lr 5.953878e-04:  11%|█         | 591/5287 [04:37<37:44,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 591: train loss 4.41336. lr 5.953722e-04:  11%|█         | 591/5287 [04:37<37:44,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 591: train loss 4.41336. lr 5.953722e-04:  11%|█         | 592/5287 [04:37<37:08,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 592: train loss 4.35596. lr 5.953566e-04:  11%|█         | 592/5287 [04:38<37:08,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 592: train loss 4.35596. lr 5.953566e-04:  11%|█         | 593/5287 [04:38<36:46,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 593: train loss 4.30857. lr 5.953409e-04:  11%|█         | 593/5287 [04:38<36:46,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 593: train loss 4.30857. lr 5.953409e-04:  11%|█         | 594/5287 [04:38<36:28,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 594: train loss 4.36357. lr 5.953253e-04:  11%|█         | 594/5287 [04:39<36:28,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 594: train loss 4.36357. lr 5.953253e-04:  11%|█▏        | 595/5287 [04:39<36:13,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 595: train loss 4.40009. lr 5.953096e-04:  11%|█▏        | 595/5287 [04:39<36:13,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 595: train loss 4.40009. lr 5.953096e-04:  11%|█▏        | 596/5287 [04:39<36:05,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 596: train loss 4.32488. lr 5.952939e-04:  11%|█▏        | 596/5287 [04:40<36:05,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 596: train loss 4.32488. lr 5.952939e-04:  11%|█▏        | 597/5287 [04:40<35:58,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 597: train loss 4.40556. lr 5.952781e-04:  11%|█▏        | 597/5287 [04:40<35:58,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 597: train loss 4.40556. lr 5.952781e-04:  11%|█▏        | 598/5287 [04:40<35:56,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 598: train loss 4.33846. lr 5.952624e-04:  11%|█▏        | 598/5287 [04:41<35:56,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 598: train loss 4.33846. lr 5.952624e-04:  11%|█▏        | 599/5287 [04:41<35:50,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 599: train loss 4.33145. lr 5.952466e-04:  11%|█▏        | 599/5287 [04:41<35:50,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 599: train loss 4.33145. lr 5.952466e-04:  11%|█▏        | 600/5287 [04:41<35:49,  2.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 600: train loss 4.35584. lr 5.952307e-04:  11%|█▏        | 600/5287 [04:42<35:49,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 600: train loss 4.35584. lr 5.952307e-04:  11%|█▏        | 601/5287 [04:42<35:49,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 601: train loss 4.33293. lr 5.952149e-04:  11%|█▏        | 601/5287 [04:42<35:49,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 601: train loss 4.33293. lr 5.952149e-04:  11%|█▏        | 602/5287 [04:42<35:49,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 602: train loss 4.36625. lr 5.951990e-04:  11%|█▏        | 602/5287 [04:42<35:49,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 602: train loss 4.36625. lr 5.951990e-04:  11%|█▏        | 603/5287 [04:42<35:48,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 603: train loss 4.28696. lr 5.951831e-04:  11%|█▏        | 603/5287 [04:43<35:48,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 603: train loss 4.28696. lr 5.951831e-04:  11%|█▏        | 604/5287 [04:43<35:46,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 604: train loss 4.31854. lr 5.951672e-04:  11%|█▏        | 604/5287 [04:43<35:46,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 604: train loss 4.31854. lr 5.951672e-04:  11%|█▏        | 605/5287 [04:43<35:45,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 605: train loss 4.35929. lr 5.951513e-04:  11%|█▏        | 605/5287 [04:44<35:45,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 605: train loss 4.35929. lr 5.951513e-04:  11%|█▏        | 606/5287 [04:44<35:48,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 606: train loss 4.33706. lr 5.951353e-04:  11%|█▏        | 606/5287 [04:44<35:48,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 606: train loss 4.33706. lr 5.951353e-04:  11%|█▏        | 607/5287 [04:44<35:47,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 607: train loss 4.28726. lr 5.951193e-04:  11%|█▏        | 607/5287 [04:45<35:47,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 607: train loss 4.28726. lr 5.951193e-04:  11%|█▏        | 608/5287 [04:45<35:44,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 608: train loss 4.33417. lr 5.951032e-04:  11%|█▏        | 608/5287 [04:45<35:44,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 608: train loss 4.33417. lr 5.951032e-04:  12%|█▏        | 609/5287 [04:45<35:46,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 609: train loss 4.30506. lr 5.950872e-04:  12%|█▏        | 609/5287 [04:46<35:46,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 609: train loss 4.30506. lr 5.950872e-04:  12%|█▏        | 610/5287 [04:46<35:47,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 610: train loss 4.29716. lr 5.950711e-04:  12%|█▏        | 610/5287 [04:46<35:47,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 610: train loss 4.29716. lr 5.950711e-04:  12%|█▏        | 611/5287 [04:46<35:45,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 611: train loss 4.30032. lr 5.950550e-04:  12%|█▏        | 611/5287 [04:47<35:45,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 611: train loss 4.30032. lr 5.950550e-04:  12%|█▏        | 612/5287 [04:47<35:47,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 612: train loss 4.31103. lr 5.950389e-04:  12%|█▏        | 612/5287 [04:47<35:47,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 612: train loss 4.31103. lr 5.950389e-04:  12%|█▏        | 613/5287 [04:47<35:46,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 613: train loss 4.41009. lr 5.950227e-04:  12%|█▏        | 613/5287 [04:48<35:46,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 613: train loss 4.41009. lr 5.950227e-04:  12%|█▏        | 614/5287 [04:48<35:45,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 614: train loss 4.28187. lr 5.950065e-04:  12%|█▏        | 614/5287 [04:48<35:45,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 614: train loss 4.28187. lr 5.950065e-04:  12%|█▏        | 615/5287 [04:48<35:44,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 615: train loss 4.35092. lr 5.949903e-04:  12%|█▏        | 615/5287 [04:48<35:44,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 615: train loss 4.35092. lr 5.949903e-04:  12%|█▏        | 616/5287 [04:48<35:43,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 616: train loss 4.35250. lr 5.949741e-04:  12%|█▏        | 616/5287 [04:49<35:43,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 616: train loss 4.35250. lr 5.949741e-04:  12%|█▏        | 617/5287 [04:49<35:41,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 617: train loss 4.33246. lr 5.949578e-04:  12%|█▏        | 617/5287 [04:49<35:41,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 617: train loss 4.33246. lr 5.949578e-04:  12%|█▏        | 618/5287 [04:49<38:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 618: train loss 4.30293. lr 5.949415e-04:  12%|█▏        | 618/5287 [04:50<38:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 618: train loss 4.30293. lr 5.949415e-04:  12%|█▏        | 619/5287 [04:50<37:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 619: train loss 4.32024. lr 5.949252e-04:  12%|█▏        | 619/5287 [04:50<37:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 619: train loss 4.32024. lr 5.949252e-04:  12%|█▏        | 620/5287 [04:50<37:01,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 620: train loss 4.23735. lr 5.949089e-04:  12%|█▏        | 620/5287 [04:51<37:01,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 620: train loss 4.23735. lr 5.949089e-04:  12%|█▏        | 621/5287 [04:51<36:35,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 621: train loss 4.29275. lr 5.948925e-04:  12%|█▏        | 621/5287 [04:51<36:35,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 621: train loss 4.29275. lr 5.948925e-04:  12%|█▏        | 622/5287 [04:51<36:29,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 622: train loss 4.27048. lr 5.948761e-04:  12%|█▏        | 622/5287 [04:52<36:29,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 622: train loss 4.27048. lr 5.948761e-04:  12%|█▏        | 623/5287 [04:52<36:15,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 623: train loss 4.24785. lr 5.948597e-04:  12%|█▏        | 623/5287 [04:52<36:15,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 623: train loss 4.24785. lr 5.948597e-04:  12%|█▏        | 624/5287 [04:52<36:07,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 624: train loss 4.27805. lr 5.948432e-04:  12%|█▏        | 624/5287 [04:53<36:07,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 624: train loss 4.27805. lr 5.948432e-04:  12%|█▏        | 625/5287 [04:53<35:57,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 625: train loss 4.29151. lr 5.948268e-04:  12%|█▏        | 625/5287 [04:53<35:57,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 625: train loss 4.29151. lr 5.948268e-04:  12%|█▏        | 626/5287 [04:53<35:50,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 626: train loss 4.33408. lr 5.948103e-04:  12%|█▏        | 626/5287 [04:54<35:50,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 626: train loss 4.33408. lr 5.948103e-04:  12%|█▏        | 627/5287 [04:54<35:47,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 627: train loss 4.29940. lr 5.947938e-04:  12%|█▏        | 627/5287 [04:54<35:47,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 627: train loss 4.29940. lr 5.947938e-04:  12%|█▏        | 628/5287 [04:54<35:43,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 628: train loss 4.31070. lr 5.947772e-04:  12%|█▏        | 628/5287 [04:55<35:43,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 628: train loss 4.31070. lr 5.947772e-04:  12%|█▏        | 629/5287 [04:55<35:40,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 629: train loss 4.25989. lr 5.947606e-04:  12%|█▏        | 629/5287 [04:55<35:40,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 629: train loss 4.25989. lr 5.947606e-04:  12%|█▏        | 630/5287 [04:55<35:39,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 630: train loss 4.26220. lr 5.947440e-04:  12%|█▏        | 630/5287 [04:55<35:39,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 630: train loss 4.26220. lr 5.947440e-04:  12%|█▏        | 631/5287 [04:55<35:36,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 631: train loss 4.28675. lr 5.947274e-04:  12%|█▏        | 631/5287 [04:56<35:36,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 631: train loss 4.28675. lr 5.947274e-04:  12%|█▏        | 632/5287 [04:56<35:36,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 632: train loss 4.31768. lr 5.947107e-04:  12%|█▏        | 632/5287 [04:56<35:36,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 632: train loss 4.31768. lr 5.947107e-04:  12%|█▏        | 633/5287 [04:56<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 633: train loss 4.32187. lr 5.946941e-04:  12%|█▏        | 633/5287 [04:57<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 633: train loss 4.32187. lr 5.946941e-04:  12%|█▏        | 634/5287 [04:57<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 634: train loss 4.30484. lr 5.946774e-04:  12%|█▏        | 634/5287 [04:57<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 634: train loss 4.30484. lr 5.946774e-04:  12%|█▏        | 635/5287 [04:57<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 635: train loss 4.30621. lr 5.946606e-04:  12%|█▏        | 635/5287 [04:58<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 635: train loss 4.30621. lr 5.946606e-04:  12%|█▏        | 636/5287 [04:58<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 636: train loss 4.23116. lr 5.946439e-04:  12%|█▏        | 636/5287 [04:58<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 636: train loss 4.23116. lr 5.946439e-04:  12%|█▏        | 637/5287 [04:58<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 637: train loss 4.19622. lr 5.946271e-04:  12%|█▏        | 637/5287 [04:59<35:34,  2.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 637: train loss 4.19622. lr 5.946271e-04:  12%|█▏        | 638/5287 [04:59<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 638: train loss 4.27482. lr 5.946103e-04:  12%|█▏        | 638/5287 [04:59<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 638: train loss 4.27482. lr 5.946103e-04:  12%|█▏        | 639/5287 [04:59<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 639: train loss 4.25141. lr 5.945934e-04:  12%|█▏        | 639/5287 [05:00<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 639: train loss 4.25141. lr 5.945934e-04:  12%|█▏        | 640/5287 [05:00<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 640: train loss 4.23167. lr 5.945766e-04:  12%|█▏        | 640/5287 [05:00<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 640: train loss 4.23167. lr 5.945766e-04:  12%|█▏        | 641/5287 [05:00<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 641: train loss 4.20963. lr 5.945597e-04:  12%|█▏        | 641/5287 [05:00<35:34,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 641: train loss 4.20963. lr 5.945597e-04:  12%|█▏        | 642/5287 [05:00<35:35,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 642: train loss 4.25132. lr 5.945428e-04:  12%|█▏        | 642/5287 [05:01<35:35,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 642: train loss 4.25132. lr 5.945428e-04:  12%|█▏        | 643/5287 [05:01<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 643: train loss 4.23204. lr 5.945258e-04:  12%|█▏        | 643/5287 [05:01<35:33,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 643: train loss 4.23204. lr 5.945258e-04:  12%|█▏        | 644/5287 [05:01<35:32,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 644: train loss 4.22113. lr 5.945089e-04:  12%|█▏        | 644/5287 [05:02<35:32,  2.18it/s]\u001b[A\n",
      "epoch 1 iter 644: train loss 4.22113. lr 5.945089e-04:  12%|█▏        | 645/5287 [05:02<35:35,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 645: train loss 4.18907. lr 5.944919e-04:  12%|█▏        | 645/5287 [05:02<35:35,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 645: train loss 4.18907. lr 5.944919e-04:  12%|█▏        | 646/5287 [05:02<38:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 646: train loss 4.24981. lr 5.944749e-04:  12%|█▏        | 646/5287 [05:03<38:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 646: train loss 4.24981. lr 5.944749e-04:  12%|█▏        | 647/5287 [05:03<37:54,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 647: train loss 4.25884. lr 5.944578e-04:  12%|█▏        | 647/5287 [05:03<37:54,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 647: train loss 4.25884. lr 5.944578e-04:  12%|█▏        | 648/5287 [05:03<37:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 648: train loss 4.20190. lr 5.944408e-04:  12%|█▏        | 648/5287 [05:04<37:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 648: train loss 4.20190. lr 5.944408e-04:  12%|█▏        | 649/5287 [05:04<36:40,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 649: train loss 4.17797. lr 5.944237e-04:  12%|█▏        | 649/5287 [05:04<36:40,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 649: train loss 4.17797. lr 5.944237e-04:  12%|█▏        | 650/5287 [05:04<36:19,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 650: train loss 4.19525. lr 5.944065e-04:  12%|█▏        | 650/5287 [05:05<36:19,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 650: train loss 4.19525. lr 5.944065e-04:  12%|█▏        | 651/5287 [05:05<36:03,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 651: train loss 4.16999. lr 5.943894e-04:  12%|█▏        | 651/5287 [05:05<36:03,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 651: train loss 4.16999. lr 5.943894e-04:  12%|█▏        | 652/5287 [05:05<35:52,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 652: train loss 4.19974. lr 5.943722e-04:  12%|█▏        | 652/5287 [05:06<35:52,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 652: train loss 4.19974. lr 5.943722e-04:  12%|█▏        | 653/5287 [05:06<35:46,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 653: train loss 4.24465. lr 5.943550e-04:  12%|█▏        | 653/5287 [05:06<35:46,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 653: train loss 4.24465. lr 5.943550e-04:  12%|█▏        | 654/5287 [05:06<35:41,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 654: train loss 4.18769. lr 5.943378e-04:  12%|█▏        | 654/5287 [05:07<35:41,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 654: train loss 4.18769. lr 5.943378e-04:  12%|█▏        | 655/5287 [05:07<35:37,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 655: train loss 4.21498. lr 5.943205e-04:  12%|█▏        | 655/5287 [05:07<35:37,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 655: train loss 4.21498. lr 5.943205e-04:  12%|█▏        | 656/5287 [05:07<35:36,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 656: train loss 4.18926. lr 5.943033e-04:  12%|█▏        | 656/5287 [05:08<35:36,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 656: train loss 4.18926. lr 5.943033e-04:  12%|█▏        | 657/5287 [05:08<35:36,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 657: train loss 4.16269. lr 5.942860e-04:  12%|█▏        | 657/5287 [05:08<35:36,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 657: train loss 4.16269. lr 5.942860e-04:  12%|█▏        | 658/5287 [05:08<35:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 658: train loss 4.19548. lr 5.942686e-04:  12%|█▏        | 658/5287 [05:08<35:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 658: train loss 4.19548. lr 5.942686e-04:  12%|█▏        | 659/5287 [05:08<35:34,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 659: train loss 4.17914. lr 5.942513e-04:  12%|█▏        | 659/5287 [05:09<35:34,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 659: train loss 4.17914. lr 5.942513e-04:  12%|█▏        | 660/5287 [05:09<35:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 660: train loss 4.21370. lr 5.942339e-04:  12%|█▏        | 660/5287 [05:09<35:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 660: train loss 4.21370. lr 5.942339e-04:  13%|█▎        | 661/5287 [05:09<35:34,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 661: train loss 4.16861. lr 5.942165e-04:  13%|█▎        | 661/5287 [05:10<35:34,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 661: train loss 4.16861. lr 5.942165e-04:  13%|█▎        | 662/5287 [05:10<35:30,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 662: train loss 4.19852. lr 5.941990e-04:  13%|█▎        | 662/5287 [05:10<35:30,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 662: train loss 4.19852. lr 5.941990e-04:  13%|█▎        | 663/5287 [05:10<35:33,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 663: train loss 4.19887. lr 5.941816e-04:  13%|█▎        | 663/5287 [05:11<35:33,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 663: train loss 4.19887. lr 5.941816e-04:  13%|█▎        | 664/5287 [05:11<35:31,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 664: train loss 4.21440. lr 5.941641e-04:  13%|█▎        | 664/5287 [05:11<35:31,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 664: train loss 4.21440. lr 5.941641e-04:  13%|█▎        | 665/5287 [05:11<35:31,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 665: train loss 4.13758. lr 5.941466e-04:  13%|█▎        | 665/5287 [05:12<35:31,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 665: train loss 4.13758. lr 5.941466e-04:  13%|█▎        | 666/5287 [05:12<35:34,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 666: train loss 4.15055. lr 5.941291e-04:  13%|█▎        | 666/5287 [05:12<35:34,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 666: train loss 4.15055. lr 5.941291e-04:  13%|█▎        | 667/5287 [05:12<35:33,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 667: train loss 4.20689. lr 5.941115e-04:  13%|█▎        | 667/5287 [05:13<35:33,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 667: train loss 4.20689. lr 5.941115e-04:  13%|█▎        | 668/5287 [05:13<35:30,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 668: train loss 4.24406. lr 5.940939e-04:  13%|█▎        | 668/5287 [05:13<35:30,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 668: train loss 4.24406. lr 5.940939e-04:  13%|█▎        | 669/5287 [05:13<35:28,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 669: train loss 4.12567. lr 5.940763e-04:  13%|█▎        | 669/5287 [05:14<35:28,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 669: train loss 4.12567. lr 5.940763e-04:  13%|█▎        | 670/5287 [05:14<35:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 670: train loss 4.10648. lr 5.940586e-04:  13%|█▎        | 670/5287 [05:14<35:32,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 670: train loss 4.10648. lr 5.940586e-04:  13%|█▎        | 671/5287 [05:14<35:32,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 671: train loss 4.18709. lr 5.940410e-04:  13%|█▎        | 671/5287 [05:14<35:32,  2.16it/s]\u001b[A\n",
      "epoch 1 iter 671: train loss 4.18709. lr 5.940410e-04:  13%|█▎        | 672/5287 [05:14<35:28,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 672: train loss 4.22198. lr 5.940233e-04:  13%|█▎        | 672/5287 [05:15<35:28,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 672: train loss 4.22198. lr 5.940233e-04:  13%|█▎        | 673/5287 [05:15<35:25,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 673: train loss 4.10654. lr 5.940056e-04:  13%|█▎        | 673/5287 [05:15<35:25,  2.17it/s]\u001b[A\n",
      "epoch 1 iter 673: train loss 4.10654. lr 5.940056e-04:  13%|█▎        | 674/5287 [05:15<38:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 674: train loss 4.11471. lr 5.939878e-04:  13%|█▎        | 674/5287 [05:16<38:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 674: train loss 4.11471. lr 5.939878e-04:  13%|█▎        | 675/5287 [05:16<37:20,  2.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 675: train loss 4.20004. lr 5.939700e-04:  13%|█▎        | 675/5287 [05:16<37:20,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 675: train loss 4.20004. lr 5.939700e-04:  13%|█▎        | 676/5287 [05:16<36:47,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 676: train loss 4.08225. lr 5.939522e-04:  13%|█▎        | 676/5287 [05:17<36:47,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 676: train loss 4.08225. lr 5.939522e-04:  13%|█▎        | 677/5287 [05:17<36:20,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 677: train loss 4.23752. lr 5.939344e-04:  13%|█▎        | 677/5287 [05:17<36:20,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 677: train loss 4.23752. lr 5.939344e-04:  13%|█▎        | 678/5287 [05:17<36:02,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 678: train loss 4.14352. lr 5.939166e-04:  13%|█▎        | 678/5287 [05:18<36:02,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 678: train loss 4.14352. lr 5.939166e-04:  13%|█▎        | 679/5287 [05:18<35:54,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 679: train loss 4.11594. lr 5.938987e-04:  13%|█▎        | 679/5287 [05:18<35:54,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 679: train loss 4.11594. lr 5.938987e-04:  13%|█▎        | 680/5287 [05:18<35:55,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 680: train loss 4.09429. lr 5.938808e-04:  13%|█▎        | 680/5287 [05:19<35:55,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 680: train loss 4.09429. lr 5.938808e-04:  13%|█▎        | 681/5287 [05:19<35:49,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 681: train loss 4.08311. lr 5.938629e-04:  13%|█▎        | 681/5287 [05:19<35:49,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 681: train loss 4.08311. lr 5.938629e-04:  13%|█▎        | 682/5287 [05:19<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 682: train loss 4.15923. lr 5.938449e-04:  13%|█▎        | 682/5287 [05:20<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 682: train loss 4.15923. lr 5.938449e-04:  13%|█▎        | 683/5287 [05:20<35:41,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 683: train loss 4.09256. lr 5.938269e-04:  13%|█▎        | 683/5287 [05:20<35:41,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 683: train loss 4.09256. lr 5.938269e-04:  13%|█▎        | 684/5287 [05:20<35:43,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 684: train loss 4.07238. lr 5.938089e-04:  13%|█▎        | 684/5287 [05:21<35:43,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 684: train loss 4.07238. lr 5.938089e-04:  13%|█▎        | 685/5287 [05:21<35:38,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 685: train loss 4.19750. lr 5.937909e-04:  13%|█▎        | 685/5287 [05:21<35:38,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 685: train loss 4.19750. lr 5.937909e-04:  13%|█▎        | 686/5287 [05:21<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 686: train loss 4.12766. lr 5.937728e-04:  13%|█▎        | 686/5287 [05:22<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 686: train loss 4.12766. lr 5.937728e-04:  13%|█▎        | 687/5287 [05:22<35:43,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 687: train loss 4.12835. lr 5.937548e-04:  13%|█▎        | 687/5287 [05:22<35:43,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 687: train loss 4.12835. lr 5.937548e-04:  13%|█▎        | 688/5287 [05:22<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 688: train loss 4.12652. lr 5.937367e-04:  13%|█▎        | 688/5287 [05:22<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 688: train loss 4.12652. lr 5.937367e-04:  13%|█▎        | 689/5287 [05:22<35:39,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 689: train loss 4.10163. lr 5.937185e-04:  13%|█▎        | 689/5287 [05:23<35:39,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 689: train loss 4.10163. lr 5.937185e-04:  13%|█▎        | 690/5287 [05:23<35:34,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 690: train loss 4.13719. lr 5.937004e-04:  13%|█▎        | 690/5287 [05:23<35:34,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 690: train loss 4.13719. lr 5.937004e-04:  13%|█▎        | 691/5287 [05:23<35:36,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 691: train loss 4.12656. lr 5.936822e-04:  13%|█▎        | 691/5287 [05:24<35:36,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 691: train loss 4.12656. lr 5.936822e-04:  13%|█▎        | 692/5287 [05:24<35:44,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 692: train loss 4.09628. lr 5.936640e-04:  13%|█▎        | 692/5287 [05:24<35:44,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 692: train loss 4.09628. lr 5.936640e-04:  13%|█▎        | 693/5287 [05:24<35:50,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 693: train loss 4.03658. lr 5.936457e-04:  13%|█▎        | 693/5287 [05:25<35:50,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 693: train loss 4.03658. lr 5.936457e-04:  13%|█▎        | 694/5287 [05:25<35:50,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 694: train loss 4.12766. lr 5.936275e-04:  13%|█▎        | 694/5287 [05:25<35:50,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 694: train loss 4.12766. lr 5.936275e-04:  13%|█▎        | 695/5287 [05:25<35:48,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 695: train loss 4.08683. lr 5.936092e-04:  13%|█▎        | 695/5287 [05:26<35:48,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 695: train loss 4.08683. lr 5.936092e-04:  13%|█▎        | 696/5287 [05:26<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 696: train loss 4.08531. lr 5.935909e-04:  13%|█▎        | 696/5287 [05:26<35:40,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 696: train loss 4.08531. lr 5.935909e-04:  13%|█▎        | 697/5287 [05:26<35:34,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 697: train loss 4.11465. lr 5.935725e-04:  13%|█▎        | 697/5287 [05:27<35:34,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 697: train loss 4.11465. lr 5.935725e-04:  13%|█▎        | 698/5287 [05:27<35:35,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 698: train loss 4.09103. lr 5.935541e-04:  13%|█▎        | 698/5287 [05:27<35:35,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 698: train loss 4.09103. lr 5.935541e-04:  13%|█▎        | 699/5287 [05:27<35:32,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 699: train loss 4.07842. lr 5.935357e-04:  13%|█▎        | 699/5287 [05:28<35:32,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 699: train loss 4.07842. lr 5.935357e-04:  13%|█▎        | 700/5287 [05:28<35:33,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 700: train loss 4.09248. lr 5.935173e-04:  13%|█▎        | 700/5287 [05:28<35:33,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 700: train loss 4.09248. lr 5.935173e-04:  13%|█▎        | 701/5287 [05:28<35:34,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 701: train loss 4.07498. lr 5.934989e-04:  13%|█▎        | 701/5287 [05:29<35:34,  2.15it/s]\u001b[A\n",
      "epoch 1 iter 701: train loss 4.07498. lr 5.934989e-04:  13%|█▎        | 702/5287 [05:29<38:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 702: train loss 4.09672. lr 5.934804e-04:  13%|█▎        | 702/5287 [05:29<38:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 702: train loss 4.09672. lr 5.934804e-04:  13%|█▎        | 703/5287 [05:29<37:28,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 703: train loss 4.19032. lr 5.934619e-04:  13%|█▎        | 703/5287 [05:30<37:28,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 703: train loss 4.19032. lr 5.934619e-04:  13%|█▎        | 704/5287 [05:30<36:59,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 704: train loss 4.06985. lr 5.934434e-04:  13%|█▎        | 704/5287 [05:30<36:59,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 704: train loss 4.06985. lr 5.934434e-04:  13%|█▎        | 705/5287 [05:30<36:30,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 705: train loss 4.04295. lr 5.934248e-04:  13%|█▎        | 705/5287 [05:30<36:30,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 705: train loss 4.04295. lr 5.934248e-04:  13%|█▎        | 706/5287 [05:30<36:12,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 706: train loss 4.05449. lr 5.934063e-04:  13%|█▎        | 706/5287 [05:31<36:12,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 706: train loss 4.05449. lr 5.934063e-04:  13%|█▎        | 707/5287 [05:31<36:08,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 707: train loss 3.98770. lr 5.933877e-04:  13%|█▎        | 707/5287 [05:31<36:08,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 707: train loss 3.98770. lr 5.933877e-04:  13%|█▎        | 708/5287 [05:31<36:09,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 708: train loss 4.03810. lr 5.933690e-04:  13%|█▎        | 708/5287 [05:32<36:09,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 708: train loss 4.03810. lr 5.933690e-04:  13%|█▎        | 709/5287 [05:32<36:05,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 709: train loss 4.04707. lr 5.933504e-04:  13%|█▎        | 709/5287 [05:32<36:05,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 709: train loss 4.04707. lr 5.933504e-04:  13%|█▎        | 710/5287 [05:32<35:59,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 710: train loss 4.06232. lr 5.933317e-04:  13%|█▎        | 710/5287 [05:33<35:59,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 710: train loss 4.06232. lr 5.933317e-04:  13%|█▎        | 711/5287 [05:33<35:47,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 711: train loss 4.06411. lr 5.933130e-04:  13%|█▎        | 711/5287 [05:33<35:47,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 711: train loss 4.06411. lr 5.933130e-04:  13%|█▎        | 712/5287 [05:33<35:45,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 712: train loss 4.02191. lr 5.932943e-04:  13%|█▎        | 712/5287 [05:34<35:45,  2.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 712: train loss 4.02191. lr 5.932943e-04:  13%|█▎        | 713/5287 [05:34<35:38,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 713: train loss 4.02851. lr 5.932755e-04:  13%|█▎        | 713/5287 [05:34<35:38,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 713: train loss 4.02851. lr 5.932755e-04:  14%|█▎        | 714/5287 [05:34<35:48,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 714: train loss 4.09541. lr 5.932567e-04:  14%|█▎        | 714/5287 [05:35<35:48,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 714: train loss 4.09541. lr 5.932567e-04:  14%|█▎        | 715/5287 [05:35<35:58,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 715: train loss 4.02275. lr 5.932379e-04:  14%|█▎        | 715/5287 [05:35<35:58,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 715: train loss 4.02275. lr 5.932379e-04:  14%|█▎        | 716/5287 [05:35<35:44,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 716: train loss 4.06448. lr 5.932191e-04:  14%|█▎        | 716/5287 [05:36<35:44,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 716: train loss 4.06448. lr 5.932191e-04:  14%|█▎        | 717/5287 [05:36<35:46,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 717: train loss 4.12965. lr 5.932002e-04:  14%|█▎        | 717/5287 [05:36<35:46,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 717: train loss 4.12965. lr 5.932002e-04:  14%|█▎        | 718/5287 [05:36<35:40,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 718: train loss 4.09118. lr 5.931813e-04:  14%|█▎        | 718/5287 [05:37<35:40,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 718: train loss 4.09118. lr 5.931813e-04:  14%|█▎        | 719/5287 [05:37<35:36,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 719: train loss 4.07176. lr 5.931624e-04:  14%|█▎        | 719/5287 [05:37<35:36,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 719: train loss 4.07176. lr 5.931624e-04:  14%|█▎        | 720/5287 [05:37<35:37,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 720: train loss 4.04874. lr 5.931435e-04:  14%|█▎        | 720/5287 [05:38<35:37,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 720: train loss 4.04874. lr 5.931435e-04:  14%|█▎        | 721/5287 [05:38<35:45,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 721: train loss 4.06910. lr 5.931245e-04:  14%|█▎        | 721/5287 [05:38<35:45,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 721: train loss 4.06910. lr 5.931245e-04:  14%|█▎        | 722/5287 [05:38<35:43,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 722: train loss 4.08453. lr 5.931055e-04:  14%|█▎        | 722/5287 [05:38<35:43,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 722: train loss 4.08453. lr 5.931055e-04:  14%|█▎        | 723/5287 [05:38<35:37,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 723: train loss 4.02389. lr 5.930865e-04:  14%|█▎        | 723/5287 [05:39<35:37,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 723: train loss 4.02389. lr 5.930865e-04:  14%|█▎        | 724/5287 [05:39<35:43,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 724: train loss 4.03316. lr 5.930675e-04:  14%|█▎        | 724/5287 [05:39<35:43,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 724: train loss 4.03316. lr 5.930675e-04:  14%|█▎        | 725/5287 [05:39<35:37,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 725: train loss 4.11455. lr 5.930484e-04:  14%|█▎        | 725/5287 [05:40<35:37,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 725: train loss 4.11455. lr 5.930484e-04:  14%|█▎        | 726/5287 [05:40<35:35,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 726: train loss 4.01033. lr 5.930293e-04:  14%|█▎        | 726/5287 [05:40<35:35,  2.14it/s]\u001b[A\n",
      "epoch 1 iter 726: train loss 4.01033. lr 5.930293e-04:  14%|█▍        | 727/5287 [05:40<35:39,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 727: train loss 4.07583. lr 5.930102e-04:  14%|█▍        | 727/5287 [05:41<35:39,  2.13it/s]\u001b[A\n",
      "epoch 1 iter 727: train loss 4.07583. lr 5.930102e-04:  14%|█▍        | 728/5287 [05:41<35:49,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 728: train loss 4.01010. lr 5.929911e-04:  14%|█▍        | 728/5287 [05:41<35:49,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 728: train loss 4.01010. lr 5.929911e-04:  14%|█▍        | 729/5287 [05:41<35:48,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 729: train loss 3.99689. lr 5.929719e-04:  14%|█▍        | 729/5287 [05:42<35:48,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 729: train loss 3.99689. lr 5.929719e-04:  14%|█▍        | 730/5287 [05:42<39:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 730: train loss 4.02823. lr 5.929527e-04:  14%|█▍        | 730/5287 [05:42<39:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 730: train loss 4.02823. lr 5.929527e-04:  14%|█▍        | 731/5287 [05:42<38:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 731: train loss 4.03931. lr 5.929335e-04:  14%|█▍        | 731/5287 [05:43<38:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 731: train loss 4.03931. lr 5.929335e-04:  14%|█▍        | 732/5287 [05:43<37:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 732: train loss 3.97536. lr 5.929142e-04:  14%|█▍        | 732/5287 [05:43<37:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 732: train loss 3.97536. lr 5.929142e-04:  14%|█▍        | 733/5287 [05:43<37:02,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 733: train loss 3.95034. lr 5.928949e-04:  14%|█▍        | 733/5287 [05:44<37:02,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 733: train loss 3.95034. lr 5.928949e-04:  14%|█▍        | 734/5287 [05:44<36:31,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 734: train loss 3.99813. lr 5.928756e-04:  14%|█▍        | 734/5287 [05:44<36:31,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 734: train loss 3.99813. lr 5.928756e-04:  14%|█▍        | 735/5287 [05:44<36:18,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 735: train loss 4.00296. lr 5.928563e-04:  14%|█▍        | 735/5287 [05:45<36:18,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 735: train loss 4.00296. lr 5.928563e-04:  14%|█▍        | 736/5287 [05:45<35:59,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 736: train loss 4.05384. lr 5.928370e-04:  14%|█▍        | 736/5287 [05:45<35:59,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 736: train loss 4.05384. lr 5.928370e-04:  14%|█▍        | 737/5287 [05:45<35:52,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 737: train loss 4.04895. lr 5.928176e-04:  14%|█▍        | 737/5287 [05:46<35:52,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 737: train loss 4.04895. lr 5.928176e-04:  14%|█▍        | 738/5287 [05:46<35:56,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 738: train loss 3.94301. lr 5.927982e-04:  14%|█▍        | 738/5287 [05:46<35:56,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 738: train loss 3.94301. lr 5.927982e-04:  14%|█▍        | 739/5287 [05:46<36:00,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 739: train loss 3.90549. lr 5.927788e-04:  14%|█▍        | 739/5287 [05:47<36:00,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 739: train loss 3.90549. lr 5.927788e-04:  14%|█▍        | 740/5287 [05:47<35:57,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 740: train loss 3.96667. lr 5.927593e-04:  14%|█▍        | 740/5287 [05:47<35:57,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 740: train loss 3.96667. lr 5.927593e-04:  14%|█▍        | 741/5287 [05:47<35:52,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 741: train loss 3.97170. lr 5.927398e-04:  14%|█▍        | 741/5287 [05:48<35:52,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 741: train loss 3.97170. lr 5.927398e-04:  14%|█▍        | 742/5287 [05:48<36:33,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 742: train loss 4.00667. lr 5.927203e-04:  14%|█▍        | 742/5287 [05:48<36:33,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 742: train loss 4.00667. lr 5.927203e-04:  14%|█▍        | 743/5287 [05:48<36:56,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 743: train loss 3.98509. lr 5.927008e-04:  14%|█▍        | 743/5287 [05:49<36:56,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 743: train loss 3.98509. lr 5.927008e-04:  14%|█▍        | 744/5287 [05:49<37:09,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 744: train loss 4.01791. lr 5.926812e-04:  14%|█▍        | 744/5287 [05:49<37:09,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 744: train loss 4.01791. lr 5.926812e-04:  14%|█▍        | 745/5287 [05:49<37:00,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 745: train loss 3.93849. lr 5.926616e-04:  14%|█▍        | 745/5287 [05:50<37:00,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 745: train loss 3.93849. lr 5.926616e-04:  14%|█▍        | 746/5287 [05:50<36:52,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 746: train loss 4.00108. lr 5.926420e-04:  14%|█▍        | 746/5287 [05:50<36:52,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 746: train loss 4.00108. lr 5.926420e-04:  14%|█▍        | 747/5287 [05:50<36:35,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 747: train loss 3.98911. lr 5.926224e-04:  14%|█▍        | 747/5287 [05:51<36:35,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 747: train loss 3.98911. lr 5.926224e-04:  14%|█▍        | 748/5287 [05:51<36:16,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 748: train loss 4.01019. lr 5.926027e-04:  14%|█▍        | 748/5287 [05:51<36:16,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 748: train loss 4.01019. lr 5.926027e-04:  14%|█▍        | 749/5287 [05:51<36:11,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 749: train loss 3.96170. lr 5.925830e-04:  14%|█▍        | 749/5287 [05:52<36:11,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 749: train loss 3.96170. lr 5.925830e-04:  14%|█▍        | 750/5287 [05:52<37:12,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 750: train loss 3.96098. lr 5.925633e-04:  14%|█▍        | 750/5287 [05:52<37:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 750: train loss 3.96098. lr 5.925633e-04:  14%|█▍        | 751/5287 [05:52<37:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 751: train loss 4.03009. lr 5.925436e-04:  14%|█▍        | 751/5287 [05:53<37:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 751: train loss 4.03009. lr 5.925436e-04:  14%|█▍        | 752/5287 [05:53<37:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 752: train loss 3.99150. lr 5.925238e-04:  14%|█▍        | 752/5287 [05:53<37:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 752: train loss 3.99150. lr 5.925238e-04:  14%|█▍        | 753/5287 [05:53<37:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 753: train loss 3.95966. lr 5.925040e-04:  14%|█▍        | 753/5287 [05:53<37:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 753: train loss 3.95966. lr 5.925040e-04:  14%|█▍        | 754/5287 [05:53<37:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 754: train loss 4.01132. lr 5.924842e-04:  14%|█▍        | 754/5287 [05:54<37:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 754: train loss 4.01132. lr 5.924842e-04:  14%|█▍        | 755/5287 [05:54<36:50,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 755: train loss 3.94933. lr 5.924644e-04:  14%|█▍        | 755/5287 [05:54<36:50,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 755: train loss 3.94933. lr 5.924644e-04:  14%|█▍        | 756/5287 [05:54<36:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 756: train loss 3.91246. lr 5.924445e-04:  14%|█▍        | 756/5287 [05:55<36:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 756: train loss 3.91246. lr 5.924445e-04:  14%|█▍        | 757/5287 [05:55<36:22,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 757: train loss 3.97184. lr 5.924246e-04:  14%|█▍        | 757/5287 [05:56<36:22,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 757: train loss 3.97184. lr 5.924246e-04:  14%|█▍        | 758/5287 [05:56<38:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 758: train loss 3.96697. lr 5.924047e-04:  14%|█▍        | 758/5287 [05:56<38:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 758: train loss 3.96697. lr 5.924047e-04:  14%|█▍        | 759/5287 [05:56<37:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 759: train loss 3.94682. lr 5.923847e-04:  14%|█▍        | 759/5287 [05:56<37:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 759: train loss 3.94682. lr 5.923847e-04:  14%|█▍        | 760/5287 [05:56<37:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 760: train loss 3.98919. lr 5.923648e-04:  14%|█▍        | 760/5287 [05:57<37:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 760: train loss 3.98919. lr 5.923648e-04:  14%|█▍        | 761/5287 [05:57<36:41,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 761: train loss 3.97246. lr 5.923448e-04:  14%|█▍        | 761/5287 [05:57<36:41,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 761: train loss 3.97246. lr 5.923448e-04:  14%|█▍        | 762/5287 [05:57<36:28,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 762: train loss 3.94090. lr 5.923248e-04:  14%|█▍        | 762/5287 [05:58<36:28,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 762: train loss 3.94090. lr 5.923248e-04:  14%|█▍        | 763/5287 [05:58<36:13,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 763: train loss 3.87170. lr 5.923047e-04:  14%|█▍        | 763/5287 [05:58<36:13,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 763: train loss 3.87170. lr 5.923047e-04:  14%|█▍        | 764/5287 [05:58<35:59,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 764: train loss 3.96951. lr 5.922846e-04:  14%|█▍        | 764/5287 [05:59<35:59,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 764: train loss 3.96951. lr 5.922846e-04:  14%|█▍        | 765/5287 [05:59<35:53,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 765: train loss 3.92937. lr 5.922645e-04:  14%|█▍        | 765/5287 [05:59<35:53,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 765: train loss 3.92937. lr 5.922645e-04:  14%|█▍        | 766/5287 [05:59<35:53,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 766: train loss 3.93854. lr 5.922444e-04:  14%|█▍        | 766/5287 [06:00<35:53,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 766: train loss 3.93854. lr 5.922444e-04:  15%|█▍        | 767/5287 [06:00<35:40,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 767: train loss 3.96891. lr 5.922242e-04:  15%|█▍        | 767/5287 [06:00<35:40,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 767: train loss 3.96891. lr 5.922242e-04:  15%|█▍        | 768/5287 [06:00<35:43,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 768: train loss 3.86327. lr 5.922041e-04:  15%|█▍        | 768/5287 [06:01<35:43,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 768: train loss 3.86327. lr 5.922041e-04:  15%|█▍        | 769/5287 [06:01<35:33,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 769: train loss 3.97556. lr 5.921839e-04:  15%|█▍        | 769/5287 [06:01<35:33,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 769: train loss 3.97556. lr 5.921839e-04:  15%|█▍        | 770/5287 [06:01<35:33,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 770: train loss 3.89941. lr 5.921636e-04:  15%|█▍        | 770/5287 [06:02<35:33,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 770: train loss 3.89941. lr 5.921636e-04:  15%|█▍        | 771/5287 [06:02<35:42,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 771: train loss 3.90381. lr 5.921434e-04:  15%|█▍        | 771/5287 [06:02<35:42,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 771: train loss 3.90381. lr 5.921434e-04:  15%|█▍        | 772/5287 [06:02<35:30,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 772: train loss 3.88679. lr 5.921231e-04:  15%|█▍        | 772/5287 [06:03<35:30,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 772: train loss 3.88679. lr 5.921231e-04:  15%|█▍        | 773/5287 [06:03<35:30,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 773: train loss 3.92146. lr 5.921028e-04:  15%|█▍        | 773/5287 [06:03<35:30,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 773: train loss 3.92146. lr 5.921028e-04:  15%|█▍        | 774/5287 [06:03<35:34,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 774: train loss 3.90026. lr 5.920825e-04:  15%|█▍        | 774/5287 [06:04<35:34,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 774: train loss 3.90026. lr 5.920825e-04:  15%|█▍        | 775/5287 [06:04<35:38,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 775: train loss 3.89488. lr 5.920621e-04:  15%|█▍        | 775/5287 [06:04<35:38,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 775: train loss 3.89488. lr 5.920621e-04:  15%|█▍        | 776/5287 [06:04<35:36,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 776: train loss 3.79544. lr 5.920417e-04:  15%|█▍        | 776/5287 [06:04<35:36,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 776: train loss 3.79544. lr 5.920417e-04:  15%|█▍        | 777/5287 [06:04<35:29,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 777: train loss 3.82873. lr 5.920213e-04:  15%|█▍        | 777/5287 [06:05<35:29,  2.12it/s]\u001b[A\n",
      "epoch 1 iter 777: train loss 3.82873. lr 5.920213e-04:  15%|█▍        | 778/5287 [06:05<35:35,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 778: train loss 3.88245. lr 5.920009e-04:  15%|█▍        | 778/5287 [06:05<35:35,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 778: train loss 3.88245. lr 5.920009e-04:  15%|█▍        | 779/5287 [06:05<35:40,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 779: train loss 3.89782. lr 5.919804e-04:  15%|█▍        | 779/5287 [06:06<35:40,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 779: train loss 3.89782. lr 5.919804e-04:  15%|█▍        | 780/5287 [06:06<35:37,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 780: train loss 3.78743. lr 5.919599e-04:  15%|█▍        | 780/5287 [06:06<35:37,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 780: train loss 3.78743. lr 5.919599e-04:  15%|█▍        | 781/5287 [06:06<35:39,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 781: train loss 3.86636. lr 5.919394e-04:  15%|█▍        | 781/5287 [06:07<35:39,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 781: train loss 3.86636. lr 5.919394e-04:  15%|█▍        | 782/5287 [06:07<35:43,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 782: train loss 3.87847. lr 5.919189e-04:  15%|█▍        | 782/5287 [06:07<35:43,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 782: train loss 3.87847. lr 5.919189e-04:  15%|█▍        | 783/5287 [06:07<35:31,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 783: train loss 3.87055. lr 5.918983e-04:  15%|█▍        | 783/5287 [06:08<35:31,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 783: train loss 3.87055. lr 5.918983e-04:  15%|█▍        | 784/5287 [06:08<35:43,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 784: train loss 3.93182. lr 5.918777e-04:  15%|█▍        | 784/5287 [06:08<35:43,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 784: train loss 3.93182. lr 5.918777e-04:  15%|█▍        | 785/5287 [06:08<37:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 785: train loss 3.90674. lr 5.918571e-04:  15%|█▍        | 785/5287 [06:09<37:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 785: train loss 3.90674. lr 5.918571e-04:  15%|█▍        | 786/5287 [06:09<41:21,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 786: train loss 3.90900. lr 5.918364e-04:  15%|█▍        | 786/5287 [06:10<41:21,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 786: train loss 3.90900. lr 5.918364e-04:  15%|█▍        | 787/5287 [06:10<40:33,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 787: train loss 3.86319. lr 5.918158e-04:  15%|█▍        | 787/5287 [06:10<40:33,  1.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 787: train loss 3.86319. lr 5.918158e-04:  15%|█▍        | 788/5287 [06:10<39:47,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 788: train loss 3.89382. lr 5.917951e-04:  15%|█▍        | 788/5287 [06:11<39:47,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 788: train loss 3.89382. lr 5.917951e-04:  15%|█▍        | 789/5287 [06:11<39:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 789: train loss 3.83381. lr 5.917744e-04:  15%|█▍        | 789/5287 [06:11<39:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 789: train loss 3.83381. lr 5.917744e-04:  15%|█▍        | 790/5287 [06:11<38:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 790: train loss 3.84320. lr 5.917536e-04:  15%|█▍        | 790/5287 [06:12<38:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 790: train loss 3.84320. lr 5.917536e-04:  15%|█▍        | 791/5287 [06:12<37:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 791: train loss 3.80391. lr 5.917328e-04:  15%|█▍        | 791/5287 [06:12<37:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 791: train loss 3.80391. lr 5.917328e-04:  15%|█▍        | 792/5287 [06:12<37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 792: train loss 3.83309. lr 5.917120e-04:  15%|█▍        | 792/5287 [06:12<37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 792: train loss 3.83309. lr 5.917120e-04:  15%|█▍        | 793/5287 [06:12<36:38,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 793: train loss 3.84327. lr 5.916912e-04:  15%|█▍        | 793/5287 [06:13<36:38,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 793: train loss 3.84327. lr 5.916912e-04:  15%|█▌        | 794/5287 [06:13<36:19,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 794: train loss 3.86116. lr 5.916704e-04:  15%|█▌        | 794/5287 [06:13<36:19,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 794: train loss 3.86116. lr 5.916704e-04:  15%|█▌        | 795/5287 [06:13<36:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 795: train loss 3.81805. lr 5.916495e-04:  15%|█▌        | 795/5287 [06:14<36:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 795: train loss 3.81805. lr 5.916495e-04:  15%|█▌        | 796/5287 [06:14<35:56,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 796: train loss 3.83550. lr 5.916286e-04:  15%|█▌        | 796/5287 [06:14<35:56,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 796: train loss 3.83550. lr 5.916286e-04:  15%|█▌        | 797/5287 [06:14<35:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 797: train loss 3.83764. lr 5.916077e-04:  15%|█▌        | 797/5287 [06:15<35:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 797: train loss 3.83764. lr 5.916077e-04:  15%|█▌        | 798/5287 [06:15<35:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 798: train loss 3.76814. lr 5.915867e-04:  15%|█▌        | 798/5287 [06:15<35:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 798: train loss 3.76814. lr 5.915867e-04:  15%|█▌        | 799/5287 [06:15<35:42,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 799: train loss 3.76256. lr 5.915657e-04:  15%|█▌        | 799/5287 [06:16<35:42,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 799: train loss 3.76256. lr 5.915657e-04:  15%|█▌        | 800/5287 [06:16<35:39,  2.10it/s]\u001b[AIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "epoch 1 iter 2815: train loss 0.83266. lr 5.009603e-04:  53%|█████▎    | 2816/5287 [22:55<19:42,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2816: train loss 0.82463. lr 5.008941e-04:  53%|█████▎    | 2816/5287 [22:55<19:42,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2816: train loss 0.82463. lr 5.008941e-04:  53%|█████▎    | 2817/5287 [22:55<19:40,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2817: train loss 0.81557. lr 5.008279e-04:  53%|█████▎    | 2817/5287 [22:56<19:40,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2817: train loss 0.81557. lr 5.008279e-04:  53%|█████▎    | 2818/5287 [22:56<19:45,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2818: train loss 0.82350. lr 5.007617e-04:  53%|█████▎    | 2818/5287 [22:56<19:45,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2818: train loss 0.82350. lr 5.007617e-04:  53%|█████▎    | 2819/5287 [22:56<20:02,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2819: train loss 0.81363. lr 5.006954e-04:  53%|█████▎    | 2819/5287 [22:57<20:02,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2819: train loss 0.81363. lr 5.006954e-04:  53%|█████▎    | 2820/5287 [22:57<20:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2820: train loss 0.84311. lr 5.006292e-04:  53%|█████▎    | 2820/5287 [22:57<20:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2820: train loss 0.84311. lr 5.006292e-04:  53%|█████▎    | 2821/5287 [22:57<20:11,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2821: train loss 0.82751. lr 5.005629e-04:  53%|█████▎    | 2821/5287 [22:58<20:11,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2821: train loss 0.82751. lr 5.005629e-04:  53%|█████▎    | 2822/5287 [22:58<20:02,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2822: train loss 0.83183. lr 5.004966e-04:  53%|█████▎    | 2822/5287 [22:58<20:02,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2822: train loss 0.83183. lr 5.004966e-04:  53%|█████▎    | 2823/5287 [22:58<19:58,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2823: train loss 0.83607. lr 5.004302e-04:  53%|█████▎    | 2823/5287 [22:59<19:58,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2823: train loss 0.83607. lr 5.004302e-04:  53%|█████▎    | 2824/5287 [22:59<19:46,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2824: train loss 0.80121. lr 5.003639e-04:  53%|█████▎    | 2824/5287 [22:59<19:46,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2824: train loss 0.80121. lr 5.003639e-04:  53%|█████▎    | 2825/5287 [22:59<19:42,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2825: train loss 0.81870. lr 5.002975e-04:  53%|█████▎    | 2825/5287 [23:00<19:42,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2825: train loss 0.81870. lr 5.002975e-04:  53%|█████▎    | 2826/5287 [23:00<19:49,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2826: train loss 0.81050. lr 5.002312e-04:  53%|█████▎    | 2826/5287 [23:00<19:49,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2826: train loss 0.81050. lr 5.002312e-04:  53%|█████▎    | 2827/5287 [23:00<20:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2827: train loss 0.81212. lr 5.001648e-04:  53%|█████▎    | 2827/5287 [23:01<20:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2827: train loss 0.81212. lr 5.001648e-04:  53%|█████▎    | 2828/5287 [23:01<21:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2828: train loss 0.83817. lr 5.000983e-04:  53%|█████▎    | 2828/5287 [23:01<21:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2828: train loss 0.83817. lr 5.000983e-04:  54%|█████▎    | 2829/5287 [23:01<21:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2829: train loss 0.84618. lr 5.000319e-04:  54%|█████▎    | 2829/5287 [23:02<21:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2829: train loss 0.84618. lr 5.000319e-04:  54%|█████▎    | 2830/5287 [23:02<22:41,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2830: train loss 0.81203. lr 4.999655e-04:  54%|█████▎    | 2830/5287 [23:02<22:41,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2830: train loss 0.81203. lr 4.999655e-04:  54%|█████▎    | 2831/5287 [23:02<22:06,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 2831: train loss 0.82622. lr 4.998990e-04:  54%|█████▎    | 2831/5287 [23:03<22:06,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 2831: train loss 0.82622. lr 4.998990e-04:  54%|█████▎    | 2832/5287 [23:03<21:36,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2832: train loss 0.84424. lr 4.998325e-04:  54%|█████▎    | 2832/5287 [23:03<21:36,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2832: train loss 0.84424. lr 4.998325e-04:  54%|█████▎    | 2833/5287 [23:03<21:29,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 2833: train loss 0.82623. lr 4.997660e-04:  54%|█████▎    | 2833/5287 [23:04<21:29,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 2833: train loss 0.82623. lr 4.997660e-04:  54%|█████▎    | 2834/5287 [23:04<21:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2834: train loss 0.80967. lr 4.996995e-04:  54%|█████▎    | 2834/5287 [23:04<21:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2834: train loss 0.80967. lr 4.996995e-04:  54%|█████▎    | 2835/5287 [23:04<21:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2835: train loss 0.81779. lr 4.996330e-04:  54%|█████▎    | 2835/5287 [23:05<21:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2835: train loss 0.81779. lr 4.996330e-04:  54%|█████▎    | 2836/5287 [23:05<20:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2836: train loss 0.83639. lr 4.995664e-04:  54%|█████▎    | 2836/5287 [23:05<20:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2836: train loss 0.83639. lr 4.995664e-04:  54%|█████▎    | 2837/5287 [23:05<20:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2837: train loss 0.82263. lr 4.994998e-04:  54%|█████▎    | 2837/5287 [23:06<20:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2837: train loss 0.82263. lr 4.994998e-04:  54%|█████▎    | 2838/5287 [23:06<20:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2838: train loss 0.83192. lr 4.994332e-04:  54%|█████▎    | 2838/5287 [23:06<20:11,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2838: train loss 0.83192. lr 4.994332e-04:  54%|█████▎    | 2839/5287 [23:06<20:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2839: train loss 0.82014. lr 4.993666e-04:  54%|█████▎    | 2839/5287 [23:07<20:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2839: train loss 0.82014. lr 4.993666e-04:  54%|█████▎    | 2840/5287 [23:07<19:48,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2840: train loss 0.82374. lr 4.993000e-04:  54%|█████▎    | 2840/5287 [23:07<19:48,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2840: train loss 0.82374. lr 4.993000e-04:  54%|█████▎    | 2841/5287 [23:07<19:42,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2841: train loss 0.82007. lr 4.992334e-04:  54%|█████▎    | 2841/5287 [23:08<19:42,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2841: train loss 0.82007. lr 4.992334e-04:  54%|█████▍    | 2842/5287 [23:08<19:43,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2842: train loss 0.84401. lr 4.991667e-04:  54%|█████▍    | 2842/5287 [23:08<19:43,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2842: train loss 0.84401. lr 4.991667e-04:  54%|█████▍    | 2843/5287 [23:08<19:33,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2843: train loss 0.83288. lr 4.991000e-04:  54%|█████▍    | 2843/5287 [23:09<19:33,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2843: train loss 0.83288. lr 4.991000e-04:  54%|█████▍    | 2844/5287 [23:09<19:32,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2844: train loss 0.80748. lr 4.990333e-04:  54%|█████▍    | 2844/5287 [23:09<19:32,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2844: train loss 0.80748. lr 4.990333e-04:  54%|█████▍    | 2845/5287 [23:09<19:35,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2845: train loss 0.80283. lr 4.989666e-04:  54%|█████▍    | 2845/5287 [23:10<19:35,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2845: train loss 0.80283. lr 4.989666e-04:  54%|█████▍    | 2846/5287 [23:10<19:27,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2846: train loss 0.83399. lr 4.988999e-04:  54%|█████▍    | 2846/5287 [23:10<19:27,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2846: train loss 0.83399. lr 4.988999e-04:  54%|█████▍    | 2847/5287 [23:10<19:26,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2847: train loss 0.83758. lr 4.988332e-04:  54%|█████▍    | 2847/5287 [23:11<19:26,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2847: train loss 0.83758. lr 4.988332e-04:  54%|█████▍    | 2848/5287 [23:11<19:30,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2848: train loss 0.83218. lr 4.987664e-04:  54%|█████▍    | 2848/5287 [23:11<19:30,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2848: train loss 0.83218. lr 4.987664e-04:  54%|█████▍    | 2849/5287 [23:11<19:24,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2849: train loss 0.82351. lr 4.986996e-04:  54%|█████▍    | 2849/5287 [23:12<19:24,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2849: train loss 0.82351. lr 4.986996e-04:  54%|█████▍    | 2850/5287 [23:12<19:24,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2850: train loss 0.80989. lr 4.986328e-04:  54%|█████▍    | 2850/5287 [23:12<19:24,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2850: train loss 0.80989. lr 4.986328e-04:  54%|█████▍    | 2851/5287 [23:12<19:30,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2851: train loss 0.79553. lr 4.985660e-04:  54%|█████▍    | 2851/5287 [23:12<19:30,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2851: train loss 0.79553. lr 4.985660e-04:  54%|█████▍    | 2852/5287 [23:12<19:24,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2852: train loss 0.82831. lr 4.984992e-04:  54%|█████▍    | 2852/5287 [23:13<19:24,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2852: train loss 0.82831. lr 4.984992e-04:  54%|█████▍    | 2853/5287 [23:13<19:22,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2853: train loss 0.82827. lr 4.984323e-04:  54%|█████▍    | 2853/5287 [23:13<19:22,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2853: train loss 0.82827. lr 4.984323e-04:  54%|█████▍    | 2854/5287 [23:13<19:30,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2854: train loss 0.83431. lr 4.983654e-04:  54%|█████▍    | 2854/5287 [23:14<19:30,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2854: train loss 0.83431. lr 4.983654e-04:  54%|█████▍    | 2855/5287 [23:14<20:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2855: train loss 0.82309. lr 4.982985e-04:  54%|█████▍    | 2855/5287 [23:15<20:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2855: train loss 0.82309. lr 4.982985e-04:  54%|█████▍    | 2856/5287 [23:15<21:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2856: train loss 0.81905. lr 4.982316e-04:  54%|█████▍    | 2856/5287 [23:15<21:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2856: train loss 0.81905. lr 4.982316e-04:  54%|█████▍    | 2857/5287 [23:15<21:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2857: train loss 0.81236. lr 4.981647e-04:  54%|█████▍    | 2857/5287 [23:16<21:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2857: train loss 0.81236. lr 4.981647e-04:  54%|█████▍    | 2858/5287 [23:16<22:52,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 2858: train loss 0.83333. lr 4.980978e-04:  54%|█████▍    | 2858/5287 [23:16<22:52,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 2858: train loss 0.83333. lr 4.980978e-04:  54%|█████▍    | 2859/5287 [23:16<22:04,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2859: train loss 0.83060. lr 4.980308e-04:  54%|█████▍    | 2859/5287 [23:17<22:04,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2859: train loss 0.83060. lr 4.980308e-04:  54%|█████▍    | 2860/5287 [23:17<21:26,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2860: train loss 0.78335. lr 4.979638e-04:  54%|█████▍    | 2860/5287 [23:17<21:26,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2860: train loss 0.78335. lr 4.979638e-04:  54%|█████▍    | 2861/5287 [23:17<20:55,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2861: train loss 0.82007. lr 4.978968e-04:  54%|█████▍    | 2861/5287 [23:18<20:55,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2861: train loss 0.82007. lr 4.978968e-04:  54%|█████▍    | 2862/5287 [23:18<20:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2862: train loss 0.82686. lr 4.978298e-04:  54%|█████▍    | 2862/5287 [23:18<20:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2862: train loss 0.82686. lr 4.978298e-04:  54%|█████▍    | 2863/5287 [23:18<20:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2863: train loss 0.78806. lr 4.977628e-04:  54%|█████▍    | 2863/5287 [23:19<20:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2863: train loss 0.78806. lr 4.977628e-04:  54%|█████▍    | 2864/5287 [23:19<19:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2864: train loss 0.84864. lr 4.976958e-04:  54%|█████▍    | 2864/5287 [23:19<19:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2864: train loss 0.84864. lr 4.976958e-04:  54%|█████▍    | 2865/5287 [23:19<19:38,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2865: train loss 0.80951. lr 4.976287e-04:  54%|█████▍    | 2865/5287 [23:20<19:38,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2865: train loss 0.80951. lr 4.976287e-04:  54%|█████▍    | 2866/5287 [23:20<19:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2866: train loss 0.82521. lr 4.975616e-04:  54%|█████▍    | 2866/5287 [23:20<19:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2866: train loss 0.82521. lr 4.975616e-04:  54%|█████▍    | 2867/5287 [23:20<19:22,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2867: train loss 0.82149. lr 4.974945e-04:  54%|█████▍    | 2867/5287 [23:21<19:22,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2867: train loss 0.82149. lr 4.974945e-04:  54%|█████▍    | 2868/5287 [23:21<19:14,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2868: train loss 0.80151. lr 4.974274e-04:  54%|█████▍    | 2868/5287 [23:21<19:14,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2868: train loss 0.80151. lr 4.974274e-04:  54%|█████▍    | 2869/5287 [23:21<19:15,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2869: train loss 0.81991. lr 4.973603e-04:  54%|█████▍    | 2869/5287 [23:22<19:15,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2869: train loss 0.81991. lr 4.973603e-04:  54%|█████▍    | 2870/5287 [23:22<19:16,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2870: train loss 0.81893. lr 4.972931e-04:  54%|█████▍    | 2870/5287 [23:22<19:16,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2870: train loss 0.81893. lr 4.972931e-04:  54%|█████▍    | 2871/5287 [23:22<19:17,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2871: train loss 0.81535. lr 4.972260e-04:  54%|█████▍    | 2871/5287 [23:22<19:17,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2871: train loss 0.81535. lr 4.972260e-04:  54%|█████▍    | 2872/5287 [23:22<19:17,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2872: train loss 0.79025. lr 4.971588e-04:  54%|█████▍    | 2872/5287 [23:23<19:17,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2872: train loss 0.79025. lr 4.971588e-04:  54%|█████▍    | 2873/5287 [23:23<19:15,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2873: train loss 0.82897. lr 4.970916e-04:  54%|█████▍    | 2873/5287 [23:23<19:15,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2873: train loss 0.82897. lr 4.970916e-04:  54%|█████▍    | 2874/5287 [23:23<19:12,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2874: train loss 0.81541. lr 4.970244e-04:  54%|█████▍    | 2874/5287 [23:24<19:12,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2874: train loss 0.81541. lr 4.970244e-04:  54%|█████▍    | 2875/5287 [23:24<19:12,  2.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2875: train loss 0.81366. lr 4.969571e-04:  54%|█████▍    | 2875/5287 [23:24<19:12,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2875: train loss 0.81366. lr 4.969571e-04:  54%|█████▍    | 2876/5287 [23:24<19:11,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2876: train loss 0.78705. lr 4.968899e-04:  54%|█████▍    | 2876/5287 [23:25<19:11,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2876: train loss 0.78705. lr 4.968899e-04:  54%|█████▍    | 2877/5287 [23:25<19:07,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2877: train loss 0.82800. lr 4.968226e-04:  54%|█████▍    | 2877/5287 [23:25<19:07,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2877: train loss 0.82800. lr 4.968226e-04:  54%|█████▍    | 2878/5287 [23:25<19:09,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2878: train loss 0.82660. lr 4.967553e-04:  54%|█████▍    | 2878/5287 [23:26<19:09,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2878: train loss 0.82660. lr 4.967553e-04:  54%|█████▍    | 2879/5287 [23:26<19:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2879: train loss 0.80983. lr 4.966880e-04:  54%|█████▍    | 2879/5287 [23:26<19:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2879: train loss 0.80983. lr 4.966880e-04:  54%|█████▍    | 2880/5287 [23:26<19:29,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2880: train loss 0.80854. lr 4.966207e-04:  54%|█████▍    | 2880/5287 [23:27<19:29,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2880: train loss 0.80854. lr 4.966207e-04:  54%|█████▍    | 2881/5287 [23:27<19:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2881: train loss 0.78947. lr 4.965533e-04:  54%|█████▍    | 2881/5287 [23:27<19:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2881: train loss 0.78947. lr 4.965533e-04:  55%|█████▍    | 2882/5287 [23:27<19:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2882: train loss 0.78450. lr 4.964860e-04:  55%|█████▍    | 2882/5287 [23:28<19:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2882: train loss 0.78450. lr 4.964860e-04:  55%|█████▍    | 2883/5287 [23:28<19:18,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2883: train loss 0.79604. lr 4.964186e-04:  55%|█████▍    | 2883/5287 [23:28<19:18,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2883: train loss 0.79604. lr 4.964186e-04:  55%|█████▍    | 2884/5287 [23:28<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2884: train loss 0.80186. lr 4.963512e-04:  55%|█████▍    | 2884/5287 [23:29<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2884: train loss 0.80186. lr 4.963512e-04:  55%|█████▍    | 2885/5287 [23:29<20:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2885: train loss 0.79396. lr 4.962838e-04:  55%|█████▍    | 2885/5287 [23:29<20:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2885: train loss 0.79396. lr 4.962838e-04:  55%|█████▍    | 2886/5287 [23:29<22:00,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2886: train loss 0.83706. lr 4.962164e-04:  55%|█████▍    | 2886/5287 [23:30<22:00,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2886: train loss 0.83706. lr 4.962164e-04:  55%|█████▍    | 2887/5287 [23:30<21:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2887: train loss 0.80804. lr 4.961489e-04:  55%|█████▍    | 2887/5287 [23:30<21:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2887: train loss 0.80804. lr 4.961489e-04:  55%|█████▍    | 2888/5287 [23:30<20:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2888: train loss 0.80643. lr 4.960815e-04:  55%|█████▍    | 2888/5287 [23:31<20:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2888: train loss 0.80643. lr 4.960815e-04:  55%|█████▍    | 2889/5287 [23:31<20:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2889: train loss 0.82465. lr 4.960140e-04:  55%|█████▍    | 2889/5287 [23:31<20:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2889: train loss 0.82465. lr 4.960140e-04:  55%|█████▍    | 2890/5287 [23:31<20:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2890: train loss 0.79415. lr 4.959465e-04:  55%|█████▍    | 2890/5287 [23:32<20:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2890: train loss 0.79415. lr 4.959465e-04:  55%|█████▍    | 2891/5287 [23:32<19:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2891: train loss 0.80727. lr 4.958790e-04:  55%|█████▍    | 2891/5287 [23:32<19:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2891: train loss 0.80727. lr 4.958790e-04:  55%|█████▍    | 2892/5287 [23:32<19:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2892: train loss 0.79836. lr 4.958114e-04:  55%|█████▍    | 2892/5287 [23:33<19:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2892: train loss 0.79836. lr 4.958114e-04:  55%|█████▍    | 2893/5287 [23:33<19:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2893: train loss 0.81233. lr 4.957439e-04:  55%|█████▍    | 2893/5287 [23:33<19:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2893: train loss 0.81233. lr 4.957439e-04:  55%|█████▍    | 2894/5287 [23:33<19:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2894: train loss 0.81219. lr 4.956763e-04:  55%|█████▍    | 2894/5287 [23:34<19:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2894: train loss 0.81219. lr 4.956763e-04:  55%|█████▍    | 2895/5287 [23:34<19:06,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2895: train loss 0.82159. lr 4.956087e-04:  55%|█████▍    | 2895/5287 [23:34<19:06,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2895: train loss 0.82159. lr 4.956087e-04:  55%|█████▍    | 2896/5287 [23:34<18:59,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2896: train loss 0.82186. lr 4.955411e-04:  55%|█████▍    | 2896/5287 [23:35<18:59,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2896: train loss 0.82186. lr 4.955411e-04:  55%|█████▍    | 2897/5287 [23:35<19:01,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2897: train loss 0.80615. lr 4.954735e-04:  55%|█████▍    | 2897/5287 [23:35<19:01,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2897: train loss 0.80615. lr 4.954735e-04:  55%|█████▍    | 2898/5287 [23:35<19:00,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2898: train loss 0.80280. lr 4.954059e-04:  55%|█████▍    | 2898/5287 [23:36<19:00,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2898: train loss 0.80280. lr 4.954059e-04:  55%|█████▍    | 2899/5287 [23:36<18:55,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2899: train loss 0.81443. lr 4.953382e-04:  55%|█████▍    | 2899/5287 [23:36<18:55,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2899: train loss 0.81443. lr 4.953382e-04:  55%|█████▍    | 2900/5287 [23:36<18:56,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2900: train loss 0.80296. lr 4.952706e-04:  55%|█████▍    | 2900/5287 [23:37<18:56,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2900: train loss 0.80296. lr 4.952706e-04:  55%|█████▍    | 2901/5287 [23:37<18:58,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2901: train loss 0.79590. lr 4.952029e-04:  55%|█████▍    | 2901/5287 [23:37<18:58,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2901: train loss 0.79590. lr 4.952029e-04:  55%|█████▍    | 2902/5287 [23:37<18:51,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 2902: train loss 0.77526. lr 4.951352e-04:  55%|█████▍    | 2902/5287 [23:38<18:51,  2.11it/s]\u001b[A\n",
      "epoch 1 iter 2902: train loss 0.77526. lr 4.951352e-04:  55%|█████▍    | 2903/5287 [23:38<18:56,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2903: train loss 0.79820. lr 4.950674e-04:  55%|█████▍    | 2903/5287 [23:38<18:56,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2903: train loss 0.79820. lr 4.950674e-04:  55%|█████▍    | 2904/5287 [23:38<18:57,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2904: train loss 0.80841. lr 4.949997e-04:  55%|█████▍    | 2904/5287 [23:39<18:57,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2904: train loss 0.80841. lr 4.949997e-04:  55%|█████▍    | 2905/5287 [23:39<18:51,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2905: train loss 0.79901. lr 4.949319e-04:  55%|█████▍    | 2905/5287 [23:39<18:51,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2905: train loss 0.79901. lr 4.949319e-04:  55%|█████▍    | 2906/5287 [23:39<18:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2906: train loss 0.83204. lr 4.948642e-04:  55%|█████▍    | 2906/5287 [23:40<18:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2906: train loss 0.83204. lr 4.948642e-04:  55%|█████▍    | 2907/5287 [23:40<19:01,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2907: train loss 0.80044. lr 4.947964e-04:  55%|█████▍    | 2907/5287 [23:40<19:01,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2907: train loss 0.80044. lr 4.947964e-04:  55%|█████▌    | 2908/5287 [23:40<19:01,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2908: train loss 0.80236. lr 4.947286e-04:  55%|█████▌    | 2908/5287 [23:40<19:01,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2908: train loss 0.80236. lr 4.947286e-04:  55%|█████▌    | 2909/5287 [23:40<19:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2909: train loss 0.78991. lr 4.946608e-04:  55%|█████▌    | 2909/5287 [23:41<19:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2909: train loss 0.78991. lr 4.946608e-04:  55%|█████▌    | 2910/5287 [23:41<19:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2910: train loss 0.76622. lr 4.945929e-04:  55%|█████▌    | 2910/5287 [23:41<19:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2910: train loss 0.76622. lr 4.945929e-04:  55%|█████▌    | 2911/5287 [23:41<18:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2911: train loss 0.79577. lr 4.945251e-04:  55%|█████▌    | 2911/5287 [23:42<18:57,  2.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2911: train loss 0.79577. lr 4.945251e-04:  55%|█████▌    | 2912/5287 [23:42<18:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2912: train loss 0.79250. lr 4.944572e-04:  55%|█████▌    | 2912/5287 [23:42<18:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2912: train loss 0.79250. lr 4.944572e-04:  55%|█████▌    | 2913/5287 [23:42<19:00,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2913: train loss 0.76896. lr 4.943893e-04:  55%|█████▌    | 2913/5287 [23:43<19:00,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2913: train loss 0.76896. lr 4.943893e-04:  55%|█████▌    | 2914/5287 [23:43<20:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2914: train loss 0.80323. lr 4.943214e-04:  55%|█████▌    | 2914/5287 [23:43<20:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2914: train loss 0.80323. lr 4.943214e-04:  55%|█████▌    | 2915/5287 [23:43<19:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2915: train loss 0.81762. lr 4.942534e-04:  55%|█████▌    | 2915/5287 [23:44<19:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2915: train loss 0.81762. lr 4.942534e-04:  55%|█████▌    | 2916/5287 [23:44<19:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2916: train loss 0.77861. lr 4.941855e-04:  55%|█████▌    | 2916/5287 [23:44<19:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2916: train loss 0.77861. lr 4.941855e-04:  55%|█████▌    | 2917/5287 [23:44<19:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2917: train loss 0.80307. lr 4.941175e-04:  55%|█████▌    | 2917/5287 [23:45<19:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2917: train loss 0.80307. lr 4.941175e-04:  55%|█████▌    | 2918/5287 [23:45<19:10,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2918: train loss 0.77363. lr 4.940496e-04:  55%|█████▌    | 2918/5287 [23:45<19:10,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2918: train loss 0.77363. lr 4.940496e-04:  55%|█████▌    | 2919/5287 [23:45<19:05,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2919: train loss 0.80946. lr 4.939816e-04:  55%|█████▌    | 2919/5287 [23:46<19:05,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2919: train loss 0.80946. lr 4.939816e-04:  55%|█████▌    | 2920/5287 [23:46<19:00,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2920: train loss 0.76354. lr 4.939135e-04:  55%|█████▌    | 2920/5287 [23:46<19:00,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2920: train loss 0.76354. lr 4.939135e-04:  55%|█████▌    | 2921/5287 [23:46<18:51,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2921: train loss 0.79940. lr 4.938455e-04:  55%|█████▌    | 2921/5287 [23:47<18:51,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2921: train loss 0.79940. lr 4.938455e-04:  55%|█████▌    | 2922/5287 [23:47<18:53,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2922: train loss 0.80826. lr 4.937775e-04:  55%|█████▌    | 2922/5287 [23:47<18:53,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2922: train loss 0.80826. lr 4.937775e-04:  55%|█████▌    | 2923/5287 [23:47<18:49,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2923: train loss 0.80154. lr 4.937094e-04:  55%|█████▌    | 2923/5287 [23:48<18:49,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2923: train loss 0.80154. lr 4.937094e-04:  55%|█████▌    | 2924/5287 [23:48<18:48,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2924: train loss 0.81812. lr 4.936413e-04:  55%|█████▌    | 2924/5287 [23:48<18:48,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2924: train loss 0.81812. lr 4.936413e-04:  55%|█████▌    | 2925/5287 [23:48<18:51,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2925: train loss 0.81107. lr 4.935732e-04:  55%|█████▌    | 2925/5287 [23:49<18:51,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2925: train loss 0.81107. lr 4.935732e-04:  55%|█████▌    | 2926/5287 [23:49<18:56,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2926: train loss 0.79530. lr 4.935051e-04:  55%|█████▌    | 2926/5287 [23:49<18:56,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2926: train loss 0.79530. lr 4.935051e-04:  55%|█████▌    | 2927/5287 [23:49<18:55,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2927: train loss 0.81124. lr 4.934370e-04:  55%|█████▌    | 2927/5287 [23:50<18:55,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2927: train loss 0.81124. lr 4.934370e-04:  55%|█████▌    | 2928/5287 [23:50<18:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2928: train loss 0.81285. lr 4.933688e-04:  55%|█████▌    | 2928/5287 [23:50<18:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2928: train loss 0.81285. lr 4.933688e-04:  55%|█████▌    | 2929/5287 [23:50<18:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2929: train loss 0.77862. lr 4.933007e-04:  55%|█████▌    | 2929/5287 [23:51<18:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2929: train loss 0.77862. lr 4.933007e-04:  55%|█████▌    | 2930/5287 [23:51<18:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2930: train loss 0.80628. lr 4.932325e-04:  55%|█████▌    | 2930/5287 [23:51<18:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2930: train loss 0.80628. lr 4.932325e-04:  55%|█████▌    | 2931/5287 [23:51<18:53,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2931: train loss 0.77137. lr 4.931643e-04:  55%|█████▌    | 2931/5287 [23:52<18:53,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2931: train loss 0.77137. lr 4.931643e-04:  55%|█████▌    | 2932/5287 [23:52<19:05,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2932: train loss 0.78683. lr 4.930960e-04:  55%|█████▌    | 2932/5287 [23:52<19:05,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2932: train loss 0.78683. lr 4.930960e-04:  55%|█████▌    | 2933/5287 [23:52<19:11,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2933: train loss 0.79323. lr 4.930278e-04:  55%|█████▌    | 2933/5287 [23:53<19:11,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2933: train loss 0.79323. lr 4.930278e-04:  55%|█████▌    | 2934/5287 [23:53<19:08,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2934: train loss 0.80964. lr 4.929596e-04:  55%|█████▌    | 2934/5287 [23:53<19:08,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2934: train loss 0.80964. lr 4.929596e-04:  56%|█████▌    | 2935/5287 [23:53<19:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2935: train loss 0.77604. lr 4.928913e-04:  56%|█████▌    | 2935/5287 [23:54<19:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2935: train loss 0.77604. lr 4.928913e-04:  56%|█████▌    | 2936/5287 [23:54<18:59,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2936: train loss 0.77443. lr 4.928230e-04:  56%|█████▌    | 2936/5287 [23:54<18:59,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2936: train loss 0.77443. lr 4.928230e-04:  56%|█████▌    | 2937/5287 [23:54<18:52,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2937: train loss 0.78733. lr 4.927547e-04:  56%|█████▌    | 2937/5287 [23:55<18:52,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2937: train loss 0.78733. lr 4.927547e-04:  56%|█████▌    | 2938/5287 [23:55<18:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2938: train loss 0.78663. lr 4.926864e-04:  56%|█████▌    | 2938/5287 [23:55<18:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2938: train loss 0.78663. lr 4.926864e-04:  56%|█████▌    | 2939/5287 [23:55<18:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2939: train loss 0.78112. lr 4.926180e-04:  56%|█████▌    | 2939/5287 [23:56<18:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2939: train loss 0.78112. lr 4.926180e-04:  56%|█████▌    | 2940/5287 [23:56<18:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2940: train loss 0.80171. lr 4.925497e-04:  56%|█████▌    | 2940/5287 [23:56<18:43,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2940: train loss 0.80171. lr 4.925497e-04:  56%|█████▌    | 2941/5287 [23:56<18:35,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2941: train loss 0.80028. lr 4.924813e-04:  56%|█████▌    | 2941/5287 [23:57<18:35,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2941: train loss 0.80028. lr 4.924813e-04:  56%|█████▌    | 2942/5287 [23:57<20:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2942: train loss 0.79507. lr 4.924129e-04:  56%|█████▌    | 2942/5287 [23:57<20:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2942: train loss 0.79507. lr 4.924129e-04:  56%|█████▌    | 2943/5287 [23:57<19:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2943: train loss 0.79083. lr 4.923445e-04:  56%|█████▌    | 2943/5287 [23:58<19:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2943: train loss 0.79083. lr 4.923445e-04:  56%|█████▌    | 2944/5287 [23:58<19:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2944: train loss 0.80872. lr 4.922761e-04:  56%|█████▌    | 2944/5287 [23:58<19:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2944: train loss 0.80872. lr 4.922761e-04:  56%|█████▌    | 2945/5287 [23:58<19:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2945: train loss 0.78744. lr 4.922077e-04:  56%|█████▌    | 2945/5287 [23:59<19:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2945: train loss 0.78744. lr 4.922077e-04:  56%|█████▌    | 2946/5287 [23:59<19:08,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2946: train loss 0.78865. lr 4.921392e-04:  56%|█████▌    | 2946/5287 [23:59<19:08,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2946: train loss 0.78865. lr 4.921392e-04:  56%|█████▌    | 2947/5287 [23:59<19:06,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2947: train loss 0.79524. lr 4.920707e-04:  56%|█████▌    | 2947/5287 [23:59<19:06,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2947: train loss 0.79524. lr 4.920707e-04:  56%|█████▌    | 2948/5287 [24:00<19:03,  2.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2948: train loss 0.79920. lr 4.920022e-04:  56%|█████▌    | 2948/5287 [24:00<19:03,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2948: train loss 0.79920. lr 4.920022e-04:  56%|█████▌    | 2949/5287 [24:00<19:00,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2949: train loss 0.78817. lr 4.919337e-04:  56%|█████▌    | 2949/5287 [24:00<19:00,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2949: train loss 0.78817. lr 4.919337e-04:  56%|█████▌    | 2950/5287 [24:00<18:53,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2950: train loss 0.77142. lr 4.918652e-04:  56%|█████▌    | 2950/5287 [24:01<18:53,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2950: train loss 0.77142. lr 4.918652e-04:  56%|█████▌    | 2951/5287 [24:01<18:52,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2951: train loss 0.77789. lr 4.917967e-04:  56%|█████▌    | 2951/5287 [24:01<18:52,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2951: train loss 0.77789. lr 4.917967e-04:  56%|█████▌    | 2952/5287 [24:01<18:48,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2952: train loss 0.77372. lr 4.917281e-04:  56%|█████▌    | 2952/5287 [24:02<18:48,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2952: train loss 0.77372. lr 4.917281e-04:  56%|█████▌    | 2953/5287 [24:02<18:43,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2953: train loss 0.77699. lr 4.916595e-04:  56%|█████▌    | 2953/5287 [24:02<18:43,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2953: train loss 0.77699. lr 4.916595e-04:  56%|█████▌    | 2954/5287 [24:02<18:43,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2954: train loss 0.78161. lr 4.915909e-04:  56%|█████▌    | 2954/5287 [24:03<18:43,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2954: train loss 0.78161. lr 4.915909e-04:  56%|█████▌    | 2955/5287 [24:03<18:37,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2955: train loss 0.76874. lr 4.915223e-04:  56%|█████▌    | 2955/5287 [24:03<18:37,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2955: train loss 0.76874. lr 4.915223e-04:  56%|█████▌    | 2956/5287 [24:03<18:34,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2956: train loss 0.78638. lr 4.914537e-04:  56%|█████▌    | 2956/5287 [24:04<18:34,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2956: train loss 0.78638. lr 4.914537e-04:  56%|█████▌    | 2957/5287 [24:04<18:42,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2957: train loss 0.80354. lr 4.913851e-04:  56%|█████▌    | 2957/5287 [24:04<18:42,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2957: train loss 0.80354. lr 4.913851e-04:  56%|█████▌    | 2958/5287 [24:04<18:41,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2958: train loss 0.77636. lr 4.913164e-04:  56%|█████▌    | 2958/5287 [24:05<18:41,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2958: train loss 0.77636. lr 4.913164e-04:  56%|█████▌    | 2959/5287 [24:05<18:39,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2959: train loss 0.78664. lr 4.912477e-04:  56%|█████▌    | 2959/5287 [24:05<18:39,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2959: train loss 0.78664. lr 4.912477e-04:  56%|█████▌    | 2960/5287 [24:05<18:39,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2960: train loss 0.79026. lr 4.911790e-04:  56%|█████▌    | 2960/5287 [24:06<18:39,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2960: train loss 0.79026. lr 4.911790e-04:  56%|█████▌    | 2961/5287 [24:06<18:40,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2961: train loss 0.78177. lr 4.911103e-04:  56%|█████▌    | 2961/5287 [24:06<18:40,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2961: train loss 0.78177. lr 4.911103e-04:  56%|█████▌    | 2962/5287 [24:06<18:34,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2962: train loss 0.79186. lr 4.910416e-04:  56%|█████▌    | 2962/5287 [24:07<18:34,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2962: train loss 0.79186. lr 4.910416e-04:  56%|█████▌    | 2963/5287 [24:07<18:34,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2963: train loss 0.78424. lr 4.909728e-04:  56%|█████▌    | 2963/5287 [24:07<18:34,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2963: train loss 0.78424. lr 4.909728e-04:  56%|█████▌    | 2964/5287 [24:07<18:35,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2964: train loss 0.76272. lr 4.909041e-04:  56%|█████▌    | 2964/5287 [24:08<18:35,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2964: train loss 0.76272. lr 4.909041e-04:  56%|█████▌    | 2965/5287 [24:08<18:28,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2965: train loss 0.79433. lr 4.908353e-04:  56%|█████▌    | 2965/5287 [24:08<18:28,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2965: train loss 0.79433. lr 4.908353e-04:  56%|█████▌    | 2966/5287 [24:08<18:28,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2966: train loss 0.79471. lr 4.907665e-04:  56%|█████▌    | 2966/5287 [24:09<18:28,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2966: train loss 0.79471. lr 4.907665e-04:  56%|█████▌    | 2967/5287 [24:09<18:28,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2967: train loss 0.77133. lr 4.906977e-04:  56%|█████▌    | 2967/5287 [24:09<18:28,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2967: train loss 0.77133. lr 4.906977e-04:  56%|█████▌    | 2968/5287 [24:09<18:22,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2968: train loss 0.78639. lr 4.906289e-04:  56%|█████▌    | 2968/5287 [24:10<18:22,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2968: train loss 0.78639. lr 4.906289e-04:  56%|█████▌    | 2969/5287 [24:10<18:23,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2969: train loss 0.79005. lr 4.905600e-04:  56%|█████▌    | 2969/5287 [24:10<18:23,  2.10it/s]\u001b[A\n",
      "epoch 1 iter 2969: train loss 0.79005. lr 4.905600e-04:  56%|█████▌    | 2970/5287 [24:10<20:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2970: train loss 0.76316. lr 4.904912e-04:  56%|█████▌    | 2970/5287 [24:11<20:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2970: train loss 0.76316. lr 4.904912e-04:  56%|█████▌    | 2971/5287 [24:11<19:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2971: train loss 0.78359. lr 4.904223e-04:  56%|█████▌    | 2971/5287 [24:11<19:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2971: train loss 0.78359. lr 4.904223e-04:  56%|█████▌    | 2972/5287 [24:11<19:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2972: train loss 0.76122. lr 4.903534e-04:  56%|█████▌    | 2972/5287 [24:12<19:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2972: train loss 0.76122. lr 4.903534e-04:  56%|█████▌    | 2973/5287 [24:12<18:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2973: train loss 0.78372. lr 4.902845e-04:  56%|█████▌    | 2973/5287 [24:12<18:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2973: train loss 0.78372. lr 4.902845e-04:  56%|█████▋    | 2974/5287 [24:12<18:53,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2974: train loss 0.75001. lr 4.902155e-04:  56%|█████▋    | 2974/5287 [24:13<18:53,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2974: train loss 0.75001. lr 4.902155e-04:  56%|█████▋    | 2975/5287 [24:13<18:47,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2975: train loss 0.77194. lr 4.901466e-04:  56%|█████▋    | 2975/5287 [24:13<18:47,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 2975: train loss 0.77194. lr 4.901466e-04:  56%|█████▋    | 2976/5287 [24:13<18:44,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2976: train loss 0.75891. lr 4.900776e-04:  56%|█████▋    | 2976/5287 [24:14<18:44,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2976: train loss 0.75891. lr 4.900776e-04:  56%|█████▋    | 2977/5287 [24:14<18:38,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2977: train loss 0.77347. lr 4.900086e-04:  56%|█████▋    | 2977/5287 [24:14<18:38,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2977: train loss 0.77347. lr 4.900086e-04:  56%|█████▋    | 2978/5287 [24:14<18:35,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2978: train loss 0.79347. lr 4.899397e-04:  56%|█████▋    | 2978/5287 [24:15<18:35,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2978: train loss 0.79347. lr 4.899397e-04:  56%|█████▋    | 2979/5287 [24:15<18:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2979: train loss 0.77483. lr 4.898706e-04:  56%|█████▋    | 2979/5287 [24:15<18:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2979: train loss 0.77483. lr 4.898706e-04:  56%|█████▋    | 2980/5287 [24:15<18:28,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2980: train loss 0.77597. lr 4.898016e-04:  56%|█████▋    | 2980/5287 [24:15<18:28,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2980: train loss 0.77597. lr 4.898016e-04:  56%|█████▋    | 2981/5287 [24:15<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2981: train loss 0.77206. lr 4.897326e-04:  56%|█████▋    | 2981/5287 [24:16<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2981: train loss 0.77206. lr 4.897326e-04:  56%|█████▋    | 2982/5287 [24:16<18:26,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2982: train loss 0.77277. lr 4.896635e-04:  56%|█████▋    | 2982/5287 [24:16<18:26,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2982: train loss 0.77277. lr 4.896635e-04:  56%|█████▋    | 2983/5287 [24:16<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2983: train loss 0.76537. lr 4.895944e-04:  56%|█████▋    | 2983/5287 [24:17<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2983: train loss 0.76537. lr 4.895944e-04:  56%|█████▋    | 2984/5287 [24:17<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2984: train loss 0.78298. lr 4.895253e-04:  56%|█████▋    | 2984/5287 [24:17<18:27,  2.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2984: train loss 0.78298. lr 4.895253e-04:  56%|█████▋    | 2985/5287 [24:17<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2985: train loss 0.77616. lr 4.894562e-04:  56%|█████▋    | 2985/5287 [24:18<18:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2985: train loss 0.77616. lr 4.894562e-04:  56%|█████▋    | 2986/5287 [24:18<18:23,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2986: train loss 0.76166. lr 4.893871e-04:  56%|█████▋    | 2986/5287 [24:18<18:23,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2986: train loss 0.76166. lr 4.893871e-04:  56%|█████▋    | 2987/5287 [24:18<18:20,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2987: train loss 0.75971. lr 4.893179e-04:  56%|█████▋    | 2987/5287 [24:19<18:20,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2987: train loss 0.75971. lr 4.893179e-04:  57%|█████▋    | 2988/5287 [24:19<18:20,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2988: train loss 0.79153. lr 4.892488e-04:  57%|█████▋    | 2988/5287 [24:19<18:20,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2988: train loss 0.79153. lr 4.892488e-04:  57%|█████▋    | 2989/5287 [24:19<18:21,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2989: train loss 0.78356. lr 4.891796e-04:  57%|█████▋    | 2989/5287 [24:20<18:21,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 2989: train loss 0.78356. lr 4.891796e-04:  57%|█████▋    | 2990/5287 [24:20<18:26,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2990: train loss 0.76353. lr 4.891104e-04:  57%|█████▋    | 2990/5287 [24:20<18:26,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2990: train loss 0.76353. lr 4.891104e-04:  57%|█████▋    | 2991/5287 [24:20<18:24,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2991: train loss 0.76859. lr 4.890412e-04:  57%|█████▋    | 2991/5287 [24:21<18:24,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2991: train loss 0.76859. lr 4.890412e-04:  57%|█████▋    | 2992/5287 [24:21<18:25,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2992: train loss 0.78376. lr 4.889719e-04:  57%|█████▋    | 2992/5287 [24:21<18:25,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 2992: train loss 0.78376. lr 4.889719e-04:  57%|█████▋    | 2993/5287 [24:21<18:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2993: train loss 0.78482. lr 4.889027e-04:  57%|█████▋    | 2993/5287 [24:22<18:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2993: train loss 0.78482. lr 4.889027e-04:  57%|█████▋    | 2994/5287 [24:22<18:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2994: train loss 0.78513. lr 4.888334e-04:  57%|█████▋    | 2994/5287 [24:22<18:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2994: train loss 0.78513. lr 4.888334e-04:  57%|█████▋    | 2995/5287 [24:22<18:31,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2995: train loss 0.77337. lr 4.887641e-04:  57%|█████▋    | 2995/5287 [24:23<18:31,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2995: train loss 0.77337. lr 4.887641e-04:  57%|█████▋    | 2996/5287 [24:23<18:32,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2996: train loss 0.76839. lr 4.886948e-04:  57%|█████▋    | 2996/5287 [24:23<18:32,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 2996: train loss 0.76839. lr 4.886948e-04:  57%|█████▋    | 2997/5287 [24:23<18:28,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2997: train loss 0.78708. lr 4.886255e-04:  57%|█████▋    | 2997/5287 [24:24<18:28,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 2997: train loss 0.78708. lr 4.886255e-04:  57%|█████▋    | 2998/5287 [24:24<19:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2998: train loss 0.77236. lr 4.885562e-04:  57%|█████▋    | 2998/5287 [24:24<19:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2998: train loss 0.77236. lr 4.885562e-04:  57%|█████▋    | 2999/5287 [24:24<19:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2999: train loss 0.78784. lr 4.884869e-04:  57%|█████▋    | 2999/5287 [24:25<19:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2999: train loss 0.78784. lr 4.884869e-04:  57%|█████▋    | 3000/5287 [24:25<19:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3000: train loss 0.77028. lr 4.884175e-04:  57%|█████▋    | 3000/5287 [24:25<19:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3000: train loss 0.77028. lr 4.884175e-04:  57%|█████▋    | 3001/5287 [24:25<18:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3001: train loss 0.77090. lr 4.883481e-04:  57%|█████▋    | 3001/5287 [24:26<18:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3001: train loss 0.77090. lr 4.883481e-04:  57%|█████▋    | 3002/5287 [24:26<18:39,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3002: train loss 0.76997. lr 4.882787e-04:  57%|█████▋    | 3002/5287 [24:26<18:39,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3002: train loss 0.76997. lr 4.882787e-04:  57%|█████▋    | 3003/5287 [24:26<18:35,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3003: train loss 0.77493. lr 4.882093e-04:  57%|█████▋    | 3003/5287 [24:27<18:35,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3003: train loss 0.77493. lr 4.882093e-04:  57%|█████▋    | 3004/5287 [24:27<18:30,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3004: train loss 0.76784. lr 4.881399e-04:  57%|█████▋    | 3004/5287 [24:27<18:30,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3004: train loss 0.76784. lr 4.881399e-04:  57%|█████▋    | 3005/5287 [24:27<18:24,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3005: train loss 0.77512. lr 4.880704e-04:  57%|█████▋    | 3005/5287 [24:28<18:24,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3005: train loss 0.77512. lr 4.880704e-04:  57%|█████▋    | 3006/5287 [24:28<18:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3006: train loss 0.75764. lr 4.880010e-04:  57%|█████▋    | 3006/5287 [24:28<18:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3006: train loss 0.75764. lr 4.880010e-04:  57%|█████▋    | 3007/5287 [24:28<18:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3007: train loss 0.79325. lr 4.879315e-04:  57%|█████▋    | 3007/5287 [24:29<18:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3007: train loss 0.79325. lr 4.879315e-04:  57%|█████▋    | 3008/5287 [24:29<18:24,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3008: train loss 0.77130. lr 4.878620e-04:  57%|█████▋    | 3008/5287 [24:29<18:24,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3008: train loss 0.77130. lr 4.878620e-04:  57%|█████▋    | 3009/5287 [24:29<18:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3009: train loss 0.76040. lr 4.877925e-04:  57%|█████▋    | 3009/5287 [24:30<18:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3009: train loss 0.76040. lr 4.877925e-04:  57%|█████▋    | 3010/5287 [24:30<18:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3010: train loss 0.76271. lr 4.877229e-04:  57%|█████▋    | 3010/5287 [24:30<18:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3010: train loss 0.76271. lr 4.877229e-04:  57%|█████▋    | 3011/5287 [24:30<19:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3011: train loss 0.77613. lr 4.876534e-04:  57%|█████▋    | 3011/5287 [24:31<19:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3011: train loss 0.77613. lr 4.876534e-04:  57%|█████▋    | 3012/5287 [24:31<19:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3012: train loss 0.75351. lr 4.875838e-04:  57%|█████▋    | 3012/5287 [24:31<19:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3012: train loss 0.75351. lr 4.875838e-04:  57%|█████▋    | 3013/5287 [24:31<18:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3013: train loss 0.77817. lr 4.875142e-04:  57%|█████▋    | 3013/5287 [24:32<18:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3013: train loss 0.77817. lr 4.875142e-04:  57%|█████▋    | 3014/5287 [24:32<18:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3014: train loss 0.79960. lr 4.874446e-04:  57%|█████▋    | 3014/5287 [24:32<18:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3014: train loss 0.79960. lr 4.874446e-04:  57%|█████▋    | 3015/5287 [24:32<18:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3015: train loss 0.75450. lr 4.873750e-04:  57%|█████▋    | 3015/5287 [24:33<18:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3015: train loss 0.75450. lr 4.873750e-04:  57%|█████▋    | 3016/5287 [24:33<18:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3016: train loss 0.75937. lr 4.873054e-04:  57%|█████▋    | 3016/5287 [24:33<18:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3016: train loss 0.75937. lr 4.873054e-04:  57%|█████▋    | 3017/5287 [24:33<18:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3017: train loss 0.76648. lr 4.872358e-04:  57%|█████▋    | 3017/5287 [24:34<18:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3017: train loss 0.76648. lr 4.872358e-04:  57%|█████▋    | 3018/5287 [24:34<18:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3018: train loss 0.76798. lr 4.871661e-04:  57%|█████▋    | 3018/5287 [24:34<18:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3018: train loss 0.76798. lr 4.871661e-04:  57%|█████▋    | 3019/5287 [24:34<18:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3019: train loss 0.76411. lr 4.870964e-04:  57%|█████▋    | 3019/5287 [24:35<18:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3019: train loss 0.76411. lr 4.870964e-04:  57%|█████▋    | 3020/5287 [24:35<18:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3020: train loss 0.78834. lr 4.870267e-04:  57%|█████▋    | 3020/5287 [24:35<18:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3020: train loss 0.78834. lr 4.870267e-04:  57%|█████▋    | 3021/5287 [24:35<18:35,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3021: train loss 0.74665. lr 4.869570e-04:  57%|█████▋    | 3021/5287 [24:36<18:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3021: train loss 0.74665. lr 4.869570e-04:  57%|█████▋    | 3022/5287 [24:36<18:29,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3022: train loss 0.75588. lr 4.868873e-04:  57%|█████▋    | 3022/5287 [24:36<18:29,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3022: train loss 0.75588. lr 4.868873e-04:  57%|█████▋    | 3023/5287 [24:36<18:24,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3023: train loss 0.76026. lr 4.868175e-04:  57%|█████▋    | 3023/5287 [24:37<18:24,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3023: train loss 0.76026. lr 4.868175e-04:  57%|█████▋    | 3024/5287 [24:37<18:19,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3024: train loss 0.78027. lr 4.867478e-04:  57%|█████▋    | 3024/5287 [24:37<18:19,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3024: train loss 0.78027. lr 4.867478e-04:  57%|█████▋    | 3025/5287 [24:37<18:18,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3025: train loss 0.78150. lr 4.866780e-04:  57%|█████▋    | 3025/5287 [24:38<18:18,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3025: train loss 0.78150. lr 4.866780e-04:  57%|█████▋    | 3026/5287 [24:38<20:30,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3026: train loss 0.79123. lr 4.866082e-04:  57%|█████▋    | 3026/5287 [24:38<20:30,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3026: train loss 0.79123. lr 4.866082e-04:  57%|█████▋    | 3027/5287 [24:38<19:49,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3027: train loss 0.75125. lr 4.865384e-04:  57%|█████▋    | 3027/5287 [24:39<19:49,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3027: train loss 0.75125. lr 4.865384e-04:  57%|█████▋    | 3028/5287 [24:39<19:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3028: train loss 0.76748. lr 4.864686e-04:  57%|█████▋    | 3028/5287 [24:39<19:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3028: train loss 0.76748. lr 4.864686e-04:  57%|█████▋    | 3029/5287 [24:39<19:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3029: train loss 0.76205. lr 4.863987e-04:  57%|█████▋    | 3029/5287 [24:40<19:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3029: train loss 0.76205. lr 4.863987e-04:  57%|█████▋    | 3030/5287 [24:40<18:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3030: train loss 0.77318. lr 4.863288e-04:  57%|█████▋    | 3030/5287 [24:40<18:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3030: train loss 0.77318. lr 4.863288e-04:  57%|█████▋    | 3031/5287 [24:40<18:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3031: train loss 0.75379. lr 4.862590e-04:  57%|█████▋    | 3031/5287 [24:41<18:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3031: train loss 0.75379. lr 4.862590e-04:  57%|█████▋    | 3032/5287 [24:41<18:27,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3032: train loss 0.75723. lr 4.861891e-04:  57%|█████▋    | 3032/5287 [24:41<18:27,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3032: train loss 0.75723. lr 4.861891e-04:  57%|█████▋    | 3033/5287 [24:41<18:20,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3033: train loss 0.79062. lr 4.861192e-04:  57%|█████▋    | 3033/5287 [24:42<18:20,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3033: train loss 0.79062. lr 4.861192e-04:  57%|█████▋    | 3034/5287 [24:42<18:17,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3034: train loss 0.74110. lr 4.860492e-04:  57%|█████▋    | 3034/5287 [24:42<18:17,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3034: train loss 0.74110. lr 4.860492e-04:  57%|█████▋    | 3035/5287 [24:42<18:13,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3035: train loss 0.76165. lr 4.859793e-04:  57%|█████▋    | 3035/5287 [24:43<18:13,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3035: train loss 0.76165. lr 4.859793e-04:  57%|█████▋    | 3036/5287 [24:43<18:13,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3036: train loss 0.75349. lr 4.859093e-04:  57%|█████▋    | 3036/5287 [24:43<18:13,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3036: train loss 0.75349. lr 4.859093e-04:  57%|█████▋    | 3037/5287 [24:43<18:07,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3037: train loss 0.75293. lr 4.858394e-04:  57%|█████▋    | 3037/5287 [24:44<18:07,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3037: train loss 0.75293. lr 4.858394e-04:  57%|█████▋    | 3038/5287 [24:44<18:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3038: train loss 0.74743. lr 4.857694e-04:  57%|█████▋    | 3038/5287 [24:44<18:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3038: train loss 0.74743. lr 4.857694e-04:  57%|█████▋    | 3039/5287 [24:44<19:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3039: train loss 0.75089. lr 4.856994e-04:  57%|█████▋    | 3039/5287 [24:45<19:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3039: train loss 0.75089. lr 4.856994e-04:  57%|█████▋    | 3040/5287 [24:45<19:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3040: train loss 0.76894. lr 4.856293e-04:  57%|█████▋    | 3040/5287 [24:45<19:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3040: train loss 0.76894. lr 4.856293e-04:  58%|█████▊    | 3041/5287 [24:45<19:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3041: train loss 0.76092. lr 4.855593e-04:  58%|█████▊    | 3041/5287 [24:46<19:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3041: train loss 0.76092. lr 4.855593e-04:  58%|█████▊    | 3042/5287 [24:46<18:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3042: train loss 0.75143. lr 4.854892e-04:  58%|█████▊    | 3042/5287 [24:46<18:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3042: train loss 0.75143. lr 4.854892e-04:  58%|█████▊    | 3043/5287 [24:46<18:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3043: train loss 0.75741. lr 4.854192e-04:  58%|█████▊    | 3043/5287 [24:47<18:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3043: train loss 0.75741. lr 4.854192e-04:  58%|█████▊    | 3044/5287 [24:47<18:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3044: train loss 0.76345. lr 4.853491e-04:  58%|█████▊    | 3044/5287 [24:47<18:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3044: train loss 0.76345. lr 4.853491e-04:  58%|█████▊    | 3045/5287 [24:47<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3045: train loss 0.74610. lr 4.852790e-04:  58%|█████▊    | 3045/5287 [24:48<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3045: train loss 0.74610. lr 4.852790e-04:  58%|█████▊    | 3046/5287 [24:48<18:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3046: train loss 0.73096. lr 4.852088e-04:  58%|█████▊    | 3046/5287 [24:48<18:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3046: train loss 0.73096. lr 4.852088e-04:  58%|█████▊    | 3047/5287 [24:48<18:17,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3047: train loss 0.75914. lr 4.851387e-04:  58%|█████▊    | 3047/5287 [24:49<18:17,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3047: train loss 0.75914. lr 4.851387e-04:  58%|█████▊    | 3048/5287 [24:49<18:09,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3048: train loss 0.75282. lr 4.850685e-04:  58%|█████▊    | 3048/5287 [24:49<18:09,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3048: train loss 0.75282. lr 4.850685e-04:  58%|█████▊    | 3049/5287 [24:49<18:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3049: train loss 0.76152. lr 4.849984e-04:  58%|█████▊    | 3049/5287 [24:49<18:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3049: train loss 0.76152. lr 4.849984e-04:  58%|█████▊    | 3050/5287 [24:49<18:06,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3050: train loss 0.74517. lr 4.849282e-04:  58%|█████▊    | 3050/5287 [24:50<18:06,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3050: train loss 0.74517. lr 4.849282e-04:  58%|█████▊    | 3051/5287 [24:50<18:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3051: train loss 0.75586. lr 4.848580e-04:  58%|█████▊    | 3051/5287 [24:51<18:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3051: train loss 0.75586. lr 4.848580e-04:  58%|█████▊    | 3052/5287 [24:51<19:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3052: train loss 0.77419. lr 4.847878e-04:  58%|█████▊    | 3052/5287 [24:51<19:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3052: train loss 0.77419. lr 4.847878e-04:  58%|█████▊    | 3053/5287 [24:51<19:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3053: train loss 0.74812. lr 4.847175e-04:  58%|█████▊    | 3053/5287 [24:52<19:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3053: train loss 0.74812. lr 4.847175e-04:  58%|█████▊    | 3054/5287 [24:52<21:14,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 3054: train loss 0.76137. lr 4.846473e-04:  58%|█████▊    | 3054/5287 [24:52<21:14,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 3054: train loss 0.76137. lr 4.846473e-04:  58%|█████▊    | 3055/5287 [24:52<20:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3055: train loss 0.71662. lr 4.845770e-04:  58%|█████▊    | 3055/5287 [24:53<20:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3055: train loss 0.71662. lr 4.845770e-04:  58%|█████▊    | 3056/5287 [24:53<19:50,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3056: train loss 0.75028. lr 4.845067e-04:  58%|█████▊    | 3056/5287 [24:53<19:50,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3056: train loss 0.75028. lr 4.845067e-04:  58%|█████▊    | 3057/5287 [24:53<19:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3057: train loss 0.75640. lr 4.844364e-04:  58%|█████▊    | 3057/5287 [24:54<19:20,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3057: train loss 0.75640. lr 4.844364e-04:  58%|█████▊    | 3058/5287 [24:54<18:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3058: train loss 0.76309. lr 4.843661e-04:  58%|█████▊    | 3058/5287 [24:54<18:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3058: train loss 0.76309. lr 4.843661e-04:  58%|█████▊    | 3059/5287 [24:54<18:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3059: train loss 0.75055. lr 4.842957e-04:  58%|█████▊    | 3059/5287 [24:55<18:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3059: train loss 0.75055. lr 4.842957e-04:  58%|█████▊    | 3060/5287 [24:55<18:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3060: train loss 0.75862. lr 4.842254e-04:  58%|█████▊    | 3060/5287 [24:55<18:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3060: train loss 0.75862. lr 4.842254e-04:  58%|█████▊    | 3061/5287 [24:55<18:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3061: train loss 0.75193. lr 4.841550e-04:  58%|█████▊    | 3061/5287 [24:56<18:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3061: train loss 0.75193. lr 4.841550e-04:  58%|█████▊    | 3062/5287 [24:56<18:02,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3062: train loss 0.73205. lr 4.840846e-04:  58%|█████▊    | 3062/5287 [24:56<18:02,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3062: train loss 0.73205. lr 4.840846e-04:  58%|█████▊    | 3063/5287 [24:56<17:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3063: train loss 0.74858. lr 4.840142e-04:  58%|█████▊    | 3063/5287 [24:57<17:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3063: train loss 0.74858. lr 4.840142e-04:  58%|█████▊    | 3064/5287 [24:57<17:56,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3064: train loss 0.75085. lr 4.839438e-04:  58%|█████▊    | 3064/5287 [24:57<17:56,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3064: train loss 0.75085. lr 4.839438e-04:  58%|█████▊    | 3065/5287 [24:57<18:10,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3065: train loss 0.75809. lr 4.838734e-04:  58%|█████▊    | 3065/5287 [24:58<18:10,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3065: train loss 0.75809. lr 4.838734e-04:  58%|█████▊    | 3066/5287 [24:58<18:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3066: train loss 0.76341. lr 4.838029e-04:  58%|█████▊    | 3066/5287 [24:58<18:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3066: train loss 0.76341. lr 4.838029e-04:  58%|█████▊    | 3067/5287 [24:58<18:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3067: train loss 0.74069. lr 4.837325e-04:  58%|█████▊    | 3067/5287 [24:59<18:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3067: train loss 0.74069. lr 4.837325e-04:  58%|█████▊    | 3068/5287 [24:59<18:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3068: train loss 0.75223. lr 4.836620e-04:  58%|█████▊    | 3068/5287 [24:59<18:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3068: train loss 0.75223. lr 4.836620e-04:  58%|█████▊    | 3069/5287 [24:59<18:05,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3069: train loss 0.77115. lr 4.835915e-04:  58%|█████▊    | 3069/5287 [25:00<18:05,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3069: train loss 0.77115. lr 4.835915e-04:  58%|█████▊    | 3070/5287 [25:00<18:01,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3070: train loss 0.76008. lr 4.835210e-04:  58%|█████▊    | 3070/5287 [25:00<18:01,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3070: train loss 0.76008. lr 4.835210e-04:  58%|█████▊    | 3071/5287 [25:00<17:56,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3071: train loss 0.73880. lr 4.834505e-04:  58%|█████▊    | 3071/5287 [25:01<17:56,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3071: train loss 0.73880. lr 4.834505e-04:  58%|█████▊    | 3072/5287 [25:01<17:55,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3072: train loss 0.76809. lr 4.833799e-04:  58%|█████▊    | 3072/5287 [25:01<17:55,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3072: train loss 0.76809. lr 4.833799e-04:  58%|█████▊    | 3073/5287 [25:01<18:03,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3073: train loss 0.74981. lr 4.833093e-04:  58%|█████▊    | 3073/5287 [25:02<18:03,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3073: train loss 0.74981. lr 4.833093e-04:  58%|█████▊    | 3074/5287 [25:02<18:07,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3074: train loss 0.73681. lr 4.832388e-04:  58%|█████▊    | 3074/5287 [25:02<18:07,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3074: train loss 0.73681. lr 4.832388e-04:  58%|█████▊    | 3075/5287 [25:02<18:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3075: train loss 0.73026. lr 4.831682e-04:  58%|█████▊    | 3075/5287 [25:03<18:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3075: train loss 0.73026. lr 4.831682e-04:  58%|█████▊    | 3076/5287 [25:03<18:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3076: train loss 0.76535. lr 4.830976e-04:  58%|█████▊    | 3076/5287 [25:03<18:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3076: train loss 0.76535. lr 4.830976e-04:  58%|█████▊    | 3077/5287 [25:03<18:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3077: train loss 0.73668. lr 4.830269e-04:  58%|█████▊    | 3077/5287 [25:04<18:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3077: train loss 0.73668. lr 4.830269e-04:  58%|█████▊    | 3078/5287 [25:04<18:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3078: train loss 0.74576. lr 4.829563e-04:  58%|█████▊    | 3078/5287 [25:04<18:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3078: train loss 0.74576. lr 4.829563e-04:  58%|█████▊    | 3079/5287 [25:04<18:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3079: train loss 0.73959. lr 4.828856e-04:  58%|█████▊    | 3079/5287 [25:05<18:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3079: train loss 0.73959. lr 4.828856e-04:  58%|█████▊    | 3080/5287 [25:05<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3080: train loss 0.75475. lr 4.828150e-04:  58%|█████▊    | 3080/5287 [25:05<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3080: train loss 0.75475. lr 4.828150e-04:  58%|█████▊    | 3081/5287 [25:05<18:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3081: train loss 0.75120. lr 4.827443e-04:  58%|█████▊    | 3081/5287 [25:06<18:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3081: train loss 0.75120. lr 4.827443e-04:  58%|█████▊    | 3082/5287 [25:06<19:18,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3082: train loss 0.73537. lr 4.826736e-04:  58%|█████▊    | 3082/5287 [25:06<19:18,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3082: train loss 0.73537. lr 4.826736e-04:  58%|█████▊    | 3083/5287 [25:06<18:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3083: train loss 0.72512. lr 4.826028e-04:  58%|█████▊    | 3083/5287 [25:07<18:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3083: train loss 0.72512. lr 4.826028e-04:  58%|█████▊    | 3084/5287 [25:07<18:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3084: train loss 0.73974. lr 4.825321e-04:  58%|█████▊    | 3084/5287 [25:07<18:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3084: train loss 0.73974. lr 4.825321e-04:  58%|█████▊    | 3085/5287 [25:07<18:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3085: train loss 0.75211. lr 4.824613e-04:  58%|█████▊    | 3085/5287 [25:08<18:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3085: train loss 0.75211. lr 4.824613e-04:  58%|█████▊    | 3086/5287 [25:08<18:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3086: train loss 0.74203. lr 4.823906e-04:  58%|█████▊    | 3086/5287 [25:08<18:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3086: train loss 0.74203. lr 4.823906e-04:  58%|█████▊    | 3087/5287 [25:08<17:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3087: train loss 0.75276. lr 4.823198e-04:  58%|█████▊    | 3087/5287 [25:09<17:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3087: train loss 0.75276. lr 4.823198e-04:  58%|█████▊    | 3088/5287 [25:09<17:53,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3088: train loss 0.74566. lr 4.822490e-04:  58%|█████▊    | 3088/5287 [25:09<17:53,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3088: train loss 0.74566. lr 4.822490e-04:  58%|█████▊    | 3089/5287 [25:09<17:53,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3089: train loss 0.75171. lr 4.821781e-04:  58%|█████▊    | 3089/5287 [25:10<17:53,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3089: train loss 0.75171. lr 4.821781e-04:  58%|█████▊    | 3090/5287 [25:10<17:52,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3090: train loss 0.73644. lr 4.821073e-04:  58%|█████▊    | 3090/5287 [25:10<17:52,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3090: train loss 0.73644. lr 4.821073e-04:  58%|█████▊    | 3091/5287 [25:10<17:51,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3091: train loss 0.75156. lr 4.820365e-04:  58%|█████▊    | 3091/5287 [25:11<17:51,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3091: train loss 0.75156. lr 4.820365e-04:  58%|█████▊    | 3092/5287 [25:11<17:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3092: train loss 0.75636. lr 4.819656e-04:  58%|█████▊    | 3092/5287 [25:11<17:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3092: train loss 0.75636. lr 4.819656e-04:  59%|█████▊    | 3093/5287 [25:11<17:46,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3093: train loss 0.71626. lr 4.818947e-04:  59%|█████▊    | 3093/5287 [25:12<17:46,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3093: train loss 0.71626. lr 4.818947e-04:  59%|█████▊    | 3094/5287 [25:12<17:42,  2.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3094: train loss 0.74700. lr 4.818238e-04:  59%|█████▊    | 3094/5287 [25:12<17:42,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3094: train loss 0.74700. lr 4.818238e-04:  59%|█████▊    | 3095/5287 [25:12<17:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3095: train loss 0.73268. lr 4.817529e-04:  59%|█████▊    | 3095/5287 [25:12<17:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3095: train loss 0.73268. lr 4.817529e-04:  59%|█████▊    | 3096/5287 [25:12<17:37,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3096: train loss 0.73495. lr 4.816819e-04:  59%|█████▊    | 3096/5287 [25:13<17:37,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3096: train loss 0.73495. lr 4.816819e-04:  59%|█████▊    | 3097/5287 [25:13<17:41,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3097: train loss 0.75677. lr 4.816110e-04:  59%|█████▊    | 3097/5287 [25:13<17:41,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3097: train loss 0.75677. lr 4.816110e-04:  59%|█████▊    | 3098/5287 [25:13<17:45,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3098: train loss 0.73957. lr 4.815400e-04:  59%|█████▊    | 3098/5287 [25:14<17:45,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3098: train loss 0.73957. lr 4.815400e-04:  59%|█████▊    | 3099/5287 [25:14<17:47,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3099: train loss 0.75785. lr 4.814690e-04:  59%|█████▊    | 3099/5287 [25:14<17:47,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3099: train loss 0.75785. lr 4.814690e-04:  59%|█████▊    | 3100/5287 [25:14<17:44,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3100: train loss 0.73090. lr 4.813980e-04:  59%|█████▊    | 3100/5287 [25:15<17:44,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3100: train loss 0.73090. lr 4.813980e-04:  59%|█████▊    | 3101/5287 [25:15<17:42,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3101: train loss 0.73380. lr 4.813270e-04:  59%|█████▊    | 3101/5287 [25:15<17:42,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3101: train loss 0.73380. lr 4.813270e-04:  59%|█████▊    | 3102/5287 [25:15<17:38,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3102: train loss 0.74643. lr 4.812560e-04:  59%|█████▊    | 3102/5287 [25:16<17:38,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3102: train loss 0.74643. lr 4.812560e-04:  59%|█████▊    | 3103/5287 [25:16<17:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3103: train loss 0.74451. lr 4.811850e-04:  59%|█████▊    | 3103/5287 [25:16<17:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3103: train loss 0.74451. lr 4.811850e-04:  59%|█████▊    | 3104/5287 [25:16<17:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3104: train loss 0.74700. lr 4.811139e-04:  59%|█████▊    | 3104/5287 [25:17<17:32,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3104: train loss 0.74700. lr 4.811139e-04:  59%|█████▊    | 3105/5287 [25:17<17:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3105: train loss 0.72715. lr 4.810428e-04:  59%|█████▊    | 3105/5287 [25:17<17:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3105: train loss 0.72715. lr 4.810428e-04:  59%|█████▊    | 3106/5287 [25:17<17:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3106: train loss 0.73190. lr 4.809717e-04:  59%|█████▊    | 3106/5287 [25:18<17:34,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3106: train loss 0.73190. lr 4.809717e-04:  59%|█████▉    | 3107/5287 [25:18<17:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3107: train loss 0.75424. lr 4.809006e-04:  59%|█████▉    | 3107/5287 [25:18<17:27,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3107: train loss 0.75424. lr 4.809006e-04:  59%|█████▉    | 3108/5287 [25:18<17:36,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3108: train loss 0.74237. lr 4.808295e-04:  59%|█████▉    | 3108/5287 [25:19<17:36,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3108: train loss 0.74237. lr 4.808295e-04:  59%|█████▉    | 3109/5287 [25:19<17:42,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3109: train loss 0.74229. lr 4.807583e-04:  59%|█████▉    | 3109/5287 [25:19<17:42,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3109: train loss 0.74229. lr 4.807583e-04:  59%|█████▉    | 3110/5287 [25:19<19:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3110: train loss 0.73694. lr 4.806872e-04:  59%|█████▉    | 3110/5287 [25:20<19:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3110: train loss 0.73694. lr 4.806872e-04:  59%|█████▉    | 3111/5287 [25:20<18:51,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3111: train loss 0.74126. lr 4.806160e-04:  59%|█████▉    | 3111/5287 [25:20<18:51,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3111: train loss 0.74126. lr 4.806160e-04:  59%|█████▉    | 3112/5287 [25:20<18:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3112: train loss 0.73871. lr 4.805448e-04:  59%|█████▉    | 3112/5287 [25:21<18:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3112: train loss 0.73871. lr 4.805448e-04:  59%|█████▉    | 3113/5287 [25:21<18:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3113: train loss 0.74801. lr 4.804736e-04:  59%|█████▉    | 3113/5287 [25:21<18:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3113: train loss 0.74801. lr 4.804736e-04:  59%|█████▉    | 3114/5287 [25:21<18:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3114: train loss 0.74898. lr 4.804024e-04:  59%|█████▉    | 3114/5287 [25:22<18:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3114: train loss 0.74898. lr 4.804024e-04:  59%|█████▉    | 3115/5287 [25:22<18:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3115: train loss 0.73863. lr 4.803312e-04:  59%|█████▉    | 3115/5287 [25:22<18:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3115: train loss 0.73863. lr 4.803312e-04:  59%|█████▉    | 3116/5287 [25:22<18:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3116: train loss 0.73948. lr 4.802599e-04:  59%|█████▉    | 3116/5287 [25:23<18:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3116: train loss 0.73948. lr 4.802599e-04:  59%|█████▉    | 3117/5287 [25:23<18:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3117: train loss 0.74205. lr 4.801886e-04:  59%|█████▉    | 3117/5287 [25:23<18:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3117: train loss 0.74205. lr 4.801886e-04:  59%|█████▉    | 3118/5287 [25:23<18:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3118: train loss 0.72871. lr 4.801174e-04:  59%|█████▉    | 3118/5287 [25:24<18:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3118: train loss 0.72871. lr 4.801174e-04:  59%|█████▉    | 3119/5287 [25:24<18:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3119: train loss 0.73386. lr 4.800461e-04:  59%|█████▉    | 3119/5287 [25:24<18:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3119: train loss 0.73386. lr 4.800461e-04:  59%|█████▉    | 3120/5287 [25:24<18:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3120: train loss 0.74014. lr 4.799747e-04:  59%|█████▉    | 3120/5287 [25:25<18:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3120: train loss 0.74014. lr 4.799747e-04:  59%|█████▉    | 3121/5287 [25:25<17:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3121: train loss 0.72334. lr 4.799034e-04:  59%|█████▉    | 3121/5287 [25:25<17:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3121: train loss 0.72334. lr 4.799034e-04:  59%|█████▉    | 3122/5287 [25:25<17:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3122: train loss 0.72203. lr 4.798321e-04:  59%|█████▉    | 3122/5287 [25:26<17:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3122: train loss 0.72203. lr 4.798321e-04:  59%|█████▉    | 3123/5287 [25:26<17:36,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3123: train loss 0.73521. lr 4.797607e-04:  59%|█████▉    | 3123/5287 [25:26<17:36,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3123: train loss 0.73521. lr 4.797607e-04:  59%|█████▉    | 3124/5287 [25:26<17:35,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3124: train loss 0.73816. lr 4.796893e-04:  59%|█████▉    | 3124/5287 [25:27<17:35,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3124: train loss 0.73816. lr 4.796893e-04:  59%|█████▉    | 3125/5287 [25:27<17:28,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3125: train loss 0.73900. lr 4.796179e-04:  59%|█████▉    | 3125/5287 [25:27<17:28,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3125: train loss 0.73900. lr 4.796179e-04:  59%|█████▉    | 3126/5287 [25:27<17:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3126: train loss 0.73288. lr 4.795465e-04:  59%|█████▉    | 3126/5287 [25:28<17:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3126: train loss 0.73288. lr 4.795465e-04:  59%|█████▉    | 3127/5287 [25:28<17:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3127: train loss 0.73850. lr 4.794751e-04:  59%|█████▉    | 3127/5287 [25:28<17:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3127: train loss 0.73850. lr 4.794751e-04:  59%|█████▉    | 3128/5287 [25:28<17:24,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3128: train loss 0.71991. lr 4.794036e-04:  59%|█████▉    | 3128/5287 [25:29<17:24,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3128: train loss 0.71991. lr 4.794036e-04:  59%|█████▉    | 3129/5287 [25:29<17:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3129: train loss 0.75447. lr 4.793322e-04:  59%|█████▉    | 3129/5287 [25:29<17:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3129: train loss 0.75447. lr 4.793322e-04:  59%|█████▉    | 3130/5287 [25:29<17:21,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3130: train loss 0.70386. lr 4.792607e-04:  59%|█████▉    | 3130/5287 [25:30<17:21,  2.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3130: train loss 0.70386. lr 4.792607e-04:  59%|█████▉    | 3131/5287 [25:30<17:21,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3131: train loss 0.72526. lr 4.791892e-04:  59%|█████▉    | 3131/5287 [25:30<17:21,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3131: train loss 0.72526. lr 4.791892e-04:  59%|█████▉    | 3132/5287 [25:30<17:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3132: train loss 0.73836. lr 4.791177e-04:  59%|█████▉    | 3132/5287 [25:31<17:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3132: train loss 0.73836. lr 4.791177e-04:  59%|█████▉    | 3133/5287 [25:31<17:16,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3133: train loss 0.74184. lr 4.790462e-04:  59%|█████▉    | 3133/5287 [25:31<17:16,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3133: train loss 0.74184. lr 4.790462e-04:  59%|█████▉    | 3134/5287 [25:31<17:15,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3134: train loss 0.72942. lr 4.789746e-04:  59%|█████▉    | 3134/5287 [25:32<17:15,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3134: train loss 0.72942. lr 4.789746e-04:  59%|█████▉    | 3135/5287 [25:32<17:21,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3135: train loss 0.73047. lr 4.789031e-04:  59%|█████▉    | 3135/5287 [25:32<17:21,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3135: train loss 0.73047. lr 4.789031e-04:  59%|█████▉    | 3136/5287 [25:32<18:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3136: train loss 0.71608. lr 4.788315e-04:  59%|█████▉    | 3136/5287 [25:33<18:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3136: train loss 0.71608. lr 4.788315e-04:  59%|█████▉    | 3137/5287 [25:33<18:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3137: train loss 0.73011. lr 4.787599e-04:  59%|█████▉    | 3137/5287 [25:33<18:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3137: train loss 0.73011. lr 4.787599e-04:  59%|█████▉    | 3138/5287 [25:33<20:07,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 3138: train loss 0.73840. lr 4.786883e-04:  59%|█████▉    | 3138/5287 [25:34<20:07,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 3138: train loss 0.73840. lr 4.786883e-04:  59%|█████▉    | 3139/5287 [25:34<19:35,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3139: train loss 0.72467. lr 4.786167e-04:  59%|█████▉    | 3139/5287 [25:34<19:35,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3139: train loss 0.72467. lr 4.786167e-04:  59%|█████▉    | 3140/5287 [25:34<19:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3140: train loss 0.71182. lr 4.785451e-04:  59%|█████▉    | 3140/5287 [25:35<19:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3140: train loss 0.71182. lr 4.785451e-04:  59%|█████▉    | 3141/5287 [25:35<18:42,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3141: train loss 0.72489. lr 4.784734e-04:  59%|█████▉    | 3141/5287 [25:35<18:42,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3141: train loss 0.72489. lr 4.784734e-04:  59%|█████▉    | 3142/5287 [25:35<18:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3142: train loss 0.72873. lr 4.784018e-04:  59%|█████▉    | 3142/5287 [25:36<18:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3142: train loss 0.72873. lr 4.784018e-04:  59%|█████▉    | 3143/5287 [25:36<18:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3143: train loss 0.71249. lr 4.783301e-04:  59%|█████▉    | 3143/5287 [25:36<18:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3143: train loss 0.71249. lr 4.783301e-04:  59%|█████▉    | 3144/5287 [25:36<17:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3144: train loss 0.72898. lr 4.782584e-04:  59%|█████▉    | 3144/5287 [25:37<17:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3144: train loss 0.72898. lr 4.782584e-04:  59%|█████▉    | 3145/5287 [25:37<17:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3145: train loss 0.74716. lr 4.781867e-04:  59%|█████▉    | 3145/5287 [25:37<17:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3145: train loss 0.74716. lr 4.781867e-04:  60%|█████▉    | 3146/5287 [25:37<17:31,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3146: train loss 0.71914. lr 4.781149e-04:  60%|█████▉    | 3146/5287 [25:38<17:31,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3146: train loss 0.71914. lr 4.781149e-04:  60%|█████▉    | 3147/5287 [25:38<17:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3147: train loss 0.72534. lr 4.780432e-04:  60%|█████▉    | 3147/5287 [25:38<17:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3147: train loss 0.72534. lr 4.780432e-04:  60%|█████▉    | 3148/5287 [25:38<17:17,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3148: train loss 0.72311. lr 4.779714e-04:  60%|█████▉    | 3148/5287 [25:39<17:17,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3148: train loss 0.72311. lr 4.779714e-04:  60%|█████▉    | 3149/5287 [25:39<17:20,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3149: train loss 0.73613. lr 4.778997e-04:  60%|█████▉    | 3149/5287 [25:39<17:20,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3149: train loss 0.73613. lr 4.778997e-04:  60%|█████▉    | 3150/5287 [25:39<17:18,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3150: train loss 0.73354. lr 4.778279e-04:  60%|█████▉    | 3150/5287 [25:40<17:18,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3150: train loss 0.73354. lr 4.778279e-04:  60%|█████▉    | 3151/5287 [25:40<17:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3151: train loss 0.70223. lr 4.777561e-04:  60%|█████▉    | 3151/5287 [25:40<17:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3151: train loss 0.70223. lr 4.777561e-04:  60%|█████▉    | 3152/5287 [25:40<17:14,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3152: train loss 0.73782. lr 4.776842e-04:  60%|█████▉    | 3152/5287 [25:41<17:14,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3152: train loss 0.73782. lr 4.776842e-04:  60%|█████▉    | 3153/5287 [25:41<17:11,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3153: train loss 0.72852. lr 4.776124e-04:  60%|█████▉    | 3153/5287 [25:41<17:11,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3153: train loss 0.72852. lr 4.776124e-04:  60%|█████▉    | 3154/5287 [25:41<17:08,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3154: train loss 0.72108. lr 4.775405e-04:  60%|█████▉    | 3154/5287 [25:42<17:08,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3154: train loss 0.72108. lr 4.775405e-04:  60%|█████▉    | 3155/5287 [25:42<17:10,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3155: train loss 0.72304. lr 4.774687e-04:  60%|█████▉    | 3155/5287 [25:42<17:10,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3155: train loss 0.72304. lr 4.774687e-04:  60%|█████▉    | 3156/5287 [25:42<17:10,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3156: train loss 0.71482. lr 4.773968e-04:  60%|█████▉    | 3156/5287 [25:43<17:10,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3156: train loss 0.71482. lr 4.773968e-04:  60%|█████▉    | 3157/5287 [25:43<17:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3157: train loss 0.72191. lr 4.773249e-04:  60%|█████▉    | 3157/5287 [25:43<17:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3157: train loss 0.72191. lr 4.773249e-04:  60%|█████▉    | 3158/5287 [25:43<17:21,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3158: train loss 0.72117. lr 4.772530e-04:  60%|█████▉    | 3158/5287 [25:44<17:21,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3158: train loss 0.72117. lr 4.772530e-04:  60%|█████▉    | 3159/5287 [25:44<17:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3159: train loss 0.72413. lr 4.771810e-04:  60%|█████▉    | 3159/5287 [25:44<17:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3159: train loss 0.72413. lr 4.771810e-04:  60%|█████▉    | 3160/5287 [25:44<17:22,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3160: train loss 0.71074. lr 4.771091e-04:  60%|█████▉    | 3160/5287 [25:45<17:22,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3160: train loss 0.71074. lr 4.771091e-04:  60%|█████▉    | 3161/5287 [25:45<17:16,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3161: train loss 0.70619. lr 4.770371e-04:  60%|█████▉    | 3161/5287 [25:45<17:16,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3161: train loss 0.70619. lr 4.770371e-04:  60%|█████▉    | 3162/5287 [25:45<17:09,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3162: train loss 0.74023. lr 4.769652e-04:  60%|█████▉    | 3162/5287 [25:46<17:09,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3162: train loss 0.74023. lr 4.769652e-04:  60%|█████▉    | 3163/5287 [25:46<17:10,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3163: train loss 0.74311. lr 4.768932e-04:  60%|█████▉    | 3163/5287 [25:46<17:10,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3163: train loss 0.74311. lr 4.768932e-04:  60%|█████▉    | 3164/5287 [25:46<17:12,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3164: train loss 0.73423. lr 4.768212e-04:  60%|█████▉    | 3164/5287 [25:47<17:12,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3164: train loss 0.73423. lr 4.768212e-04:  60%|█████▉    | 3165/5287 [25:47<17:14,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3165: train loss 0.72999. lr 4.767491e-04:  60%|█████▉    | 3165/5287 [25:47<17:14,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3165: train loss 0.72999. lr 4.767491e-04:  60%|█████▉    | 3166/5287 [25:47<18:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3166: train loss 0.74434. lr 4.766771e-04:  60%|█████▉    | 3166/5287 [25:48<18:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3166: train loss 0.74434. lr 4.766771e-04:  60%|█████▉    | 3167/5287 [25:48<18:14,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3167: train loss 0.73988. lr 4.766050e-04:  60%|█████▉    | 3167/5287 [25:48<18:14,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3167: train loss 0.73988. lr 4.766050e-04:  60%|█████▉    | 3168/5287 [25:48<17:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3168: train loss 0.73029. lr 4.765330e-04:  60%|█████▉    | 3168/5287 [25:49<17:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3168: train loss 0.73029. lr 4.765330e-04:  60%|█████▉    | 3169/5287 [25:49<17:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3169: train loss 0.71829. lr 4.764609e-04:  60%|█████▉    | 3169/5287 [25:49<17:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3169: train loss 0.71829. lr 4.764609e-04:  60%|█████▉    | 3170/5287 [25:49<17:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3170: train loss 0.72497. lr 4.763888e-04:  60%|█████▉    | 3170/5287 [25:50<17:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3170: train loss 0.72497. lr 4.763888e-04:  60%|█████▉    | 3171/5287 [25:50<17:16,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3171: train loss 0.72548. lr 4.763166e-04:  60%|█████▉    | 3171/5287 [25:50<17:16,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3171: train loss 0.72548. lr 4.763166e-04:  60%|█████▉    | 3172/5287 [25:50<17:13,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3172: train loss 0.70439. lr 4.762445e-04:  60%|█████▉    | 3172/5287 [25:51<17:13,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3172: train loss 0.70439. lr 4.762445e-04:  60%|██████    | 3173/5287 [25:51<17:10,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3173: train loss 0.72197. lr 4.761724e-04:  60%|██████    | 3173/5287 [25:51<17:10,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3173: train loss 0.72197. lr 4.761724e-04:  60%|██████    | 3174/5287 [25:51<17:07,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3174: train loss 0.74044. lr 4.761002e-04:  60%|██████    | 3174/5287 [25:52<17:07,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3174: train loss 0.74044. lr 4.761002e-04:  60%|██████    | 3175/5287 [25:52<17:07,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3175: train loss 0.70437. lr 4.760280e-04:  60%|██████    | 3175/5287 [25:52<17:07,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3175: train loss 0.70437. lr 4.760280e-04:  60%|██████    | 3176/5287 [25:52<17:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3176: train loss 0.71917. lr 4.759558e-04:  60%|██████    | 3176/5287 [25:53<17:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3176: train loss 0.71917. lr 4.759558e-04:  60%|██████    | 3177/5287 [25:53<17:06,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3177: train loss 0.72685. lr 4.758836e-04:  60%|██████    | 3177/5287 [25:53<17:06,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3177: train loss 0.72685. lr 4.758836e-04:  60%|██████    | 3178/5287 [25:53<17:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3178: train loss 0.72434. lr 4.758114e-04:  60%|██████    | 3178/5287 [25:54<17:04,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3178: train loss 0.72434. lr 4.758114e-04:  60%|██████    | 3179/5287 [25:54<16:58,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3179: train loss 0.69891. lr 4.757391e-04:  60%|██████    | 3179/5287 [25:54<16:58,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3179: train loss 0.69891. lr 4.757391e-04:  60%|██████    | 3180/5287 [25:54<16:59,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3180: train loss 0.72718. lr 4.756669e-04:  60%|██████    | 3180/5287 [25:55<16:59,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3180: train loss 0.72718. lr 4.756669e-04:  60%|██████    | 3181/5287 [25:55<16:58,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3181: train loss 0.72114. lr 4.755946e-04:  60%|██████    | 3181/5287 [25:55<16:58,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3181: train loss 0.72114. lr 4.755946e-04:  60%|██████    | 3182/5287 [25:55<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3182: train loss 0.73441. lr 4.755223e-04:  60%|██████    | 3182/5287 [25:55<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3182: train loss 0.73441. lr 4.755223e-04:  60%|██████    | 3183/5287 [25:55<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3183: train loss 0.71440. lr 4.754500e-04:  60%|██████    | 3183/5287 [25:56<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3183: train loss 0.71440. lr 4.754500e-04:  60%|██████    | 3184/5287 [25:56<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3184: train loss 0.73635. lr 4.753777e-04:  60%|██████    | 3184/5287 [25:56<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3184: train loss 0.73635. lr 4.753777e-04:  60%|██████    | 3185/5287 [25:56<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3185: train loss 0.72599. lr 4.753053e-04:  60%|██████    | 3185/5287 [25:57<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3185: train loss 0.72599. lr 4.753053e-04:  60%|██████    | 3186/5287 [25:57<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3186: train loss 0.72065. lr 4.752330e-04:  60%|██████    | 3186/5287 [25:57<16:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3186: train loss 0.72065. lr 4.752330e-04:  60%|██████    | 3187/5287 [25:57<16:55,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3187: train loss 0.72388. lr 4.751606e-04:  60%|██████    | 3187/5287 [25:58<16:55,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3187: train loss 0.72388. lr 4.751606e-04:  60%|██████    | 3188/5287 [25:58<16:55,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3188: train loss 0.69481. lr 4.750882e-04:  60%|██████    | 3188/5287 [25:58<16:55,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3188: train loss 0.69481. lr 4.750882e-04:  60%|██████    | 3189/5287 [25:58<16:50,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3189: train loss 0.72891. lr 4.750158e-04:  60%|██████    | 3189/5287 [25:59<16:50,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3189: train loss 0.72891. lr 4.750158e-04:  60%|██████    | 3190/5287 [25:59<16:50,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3190: train loss 0.70588. lr 4.749434e-04:  60%|██████    | 3190/5287 [25:59<16:50,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3190: train loss 0.70588. lr 4.749434e-04:  60%|██████    | 3191/5287 [25:59<16:54,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3191: train loss 0.70462. lr 4.748710e-04:  60%|██████    | 3191/5287 [26:00<16:54,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3191: train loss 0.70462. lr 4.748710e-04:  60%|██████    | 3192/5287 [26:00<16:52,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3192: train loss 0.71482. lr 4.747985e-04:  60%|██████    | 3192/5287 [26:00<16:52,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3192: train loss 0.71482. lr 4.747985e-04:  60%|██████    | 3193/5287 [26:00<16:47,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3193: train loss 0.70818. lr 4.747261e-04:  60%|██████    | 3193/5287 [26:01<16:47,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3193: train loss 0.70818. lr 4.747261e-04:  60%|██████    | 3194/5287 [26:01<18:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3194: train loss 0.70868. lr 4.746536e-04:  60%|██████    | 3194/5287 [26:01<18:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3194: train loss 0.70868. lr 4.746536e-04:  60%|██████    | 3195/5287 [26:01<17:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3195: train loss 0.71041. lr 4.745811e-04:  60%|██████    | 3195/5287 [26:02<17:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3195: train loss 0.71041. lr 4.745811e-04:  60%|██████    | 3196/5287 [26:02<17:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3196: train loss 0.71985. lr 4.745086e-04:  60%|██████    | 3196/5287 [26:02<17:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3196: train loss 0.71985. lr 4.745086e-04:  60%|██████    | 3197/5287 [26:02<17:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3197: train loss 0.72584. lr 4.744361e-04:  60%|██████    | 3197/5287 [26:03<17:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3197: train loss 0.72584. lr 4.744361e-04:  60%|██████    | 3198/5287 [26:03<17:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3198: train loss 0.71695. lr 4.743636e-04:  60%|██████    | 3198/5287 [26:03<17:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3198: train loss 0.71695. lr 4.743636e-04:  61%|██████    | 3199/5287 [26:03<17:02,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3199: train loss 0.70257. lr 4.742910e-04:  61%|██████    | 3199/5287 [26:04<17:02,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3199: train loss 0.70257. lr 4.742910e-04:  61%|██████    | 3200/5287 [26:04<17:00,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3200: train loss 0.72866. lr 4.742184e-04:  61%|██████    | 3200/5287 [26:04<17:00,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3200: train loss 0.72866. lr 4.742184e-04:  61%|██████    | 3201/5287 [26:04<16:55,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3201: train loss 0.70572. lr 4.741459e-04:  61%|██████    | 3201/5287 [26:05<16:55,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3201: train loss 0.70572. lr 4.741459e-04:  61%|██████    | 3202/5287 [26:05<16:53,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3202: train loss 0.70455. lr 4.740733e-04:  61%|██████    | 3202/5287 [26:05<16:53,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3202: train loss 0.70455. lr 4.740733e-04:  61%|██████    | 3203/5287 [26:05<16:54,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3203: train loss 0.68704. lr 4.740006e-04:  61%|██████    | 3203/5287 [26:06<16:54,  2.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3203: train loss 0.68704. lr 4.740006e-04:  61%|██████    | 3204/5287 [26:06<16:58,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3204: train loss 0.70927. lr 4.739280e-04:  61%|██████    | 3204/5287 [26:06<16:58,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3204: train loss 0.70927. lr 4.739280e-04:  61%|██████    | 3205/5287 [26:06<16:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3205: train loss 0.72553. lr 4.738554e-04:  61%|██████    | 3205/5287 [26:07<16:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3205: train loss 0.72553. lr 4.738554e-04:  61%|██████    | 3206/5287 [26:07<16:58,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3206: train loss 0.70146. lr 4.737827e-04:  61%|██████    | 3206/5287 [26:07<16:58,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3206: train loss 0.70146. lr 4.737827e-04:  61%|██████    | 3207/5287 [26:07<16:51,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3207: train loss 0.72371. lr 4.737100e-04:  61%|██████    | 3207/5287 [26:08<16:51,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3207: train loss 0.72371. lr 4.737100e-04:  61%|██████    | 3208/5287 [26:08<16:50,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3208: train loss 0.72064. lr 4.736373e-04:  61%|██████    | 3208/5287 [26:08<16:50,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3208: train loss 0.72064. lr 4.736373e-04:  61%|██████    | 3209/5287 [26:08<16:48,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3209: train loss 0.71013. lr 4.735646e-04:  61%|██████    | 3209/5287 [26:09<16:48,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3209: train loss 0.71013. lr 4.735646e-04:  61%|██████    | 3210/5287 [26:09<16:47,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3210: train loss 0.72156. lr 4.734919e-04:  61%|██████    | 3210/5287 [26:09<16:47,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3210: train loss 0.72156. lr 4.734919e-04:  61%|██████    | 3211/5287 [26:09<16:50,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3211: train loss 0.72089. lr 4.734192e-04:  61%|██████    | 3211/5287 [26:10<16:50,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3211: train loss 0.72089. lr 4.734192e-04:  61%|██████    | 3212/5287 [26:10<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3212: train loss 0.69576. lr 4.733464e-04:  61%|██████    | 3212/5287 [26:10<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3212: train loss 0.69576. lr 4.733464e-04:  61%|██████    | 3213/5287 [26:10<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3213: train loss 0.72180. lr 4.732736e-04:  61%|██████    | 3213/5287 [26:11<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3213: train loss 0.72180. lr 4.732736e-04:  61%|██████    | 3214/5287 [26:11<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3214: train loss 0.70830. lr 4.732009e-04:  61%|██████    | 3214/5287 [26:11<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3214: train loss 0.70830. lr 4.732009e-04:  61%|██████    | 3215/5287 [26:11<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3215: train loss 0.70351. lr 4.731281e-04:  61%|██████    | 3215/5287 [26:12<16:49,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3215: train loss 0.70351. lr 4.731281e-04:  61%|██████    | 3216/5287 [26:12<16:48,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3216: train loss 0.71955. lr 4.730553e-04:  61%|██████    | 3216/5287 [26:12<16:48,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3216: train loss 0.71955. lr 4.730553e-04:  61%|██████    | 3217/5287 [26:12<16:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3217: train loss 0.69035. lr 4.729824e-04:  61%|██████    | 3217/5287 [26:13<16:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3217: train loss 0.69035. lr 4.729824e-04:  61%|██████    | 3218/5287 [26:13<16:41,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3218: train loss 0.71812. lr 4.729096e-04:  61%|██████    | 3218/5287 [26:13<16:41,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3218: train loss 0.71812. lr 4.729096e-04:  61%|██████    | 3219/5287 [26:13<16:45,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3219: train loss 0.72482. lr 4.728367e-04:  61%|██████    | 3219/5287 [26:14<16:45,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3219: train loss 0.72482. lr 4.728367e-04:  61%|██████    | 3220/5287 [26:14<16:47,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3220: train loss 0.71501. lr 4.727638e-04:  61%|██████    | 3220/5287 [26:14<16:47,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3220: train loss 0.71501. lr 4.727638e-04:  61%|██████    | 3221/5287 [26:14<16:48,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3221: train loss 0.70255. lr 4.726910e-04:  61%|██████    | 3221/5287 [26:15<16:48,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3221: train loss 0.70255. lr 4.726910e-04:  61%|██████    | 3222/5287 [26:15<18:30,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3222: train loss 0.72140. lr 4.726181e-04:  61%|██████    | 3222/5287 [26:15<18:30,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3222: train loss 0.72140. lr 4.726181e-04:  61%|██████    | 3223/5287 [26:15<18:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3223: train loss 0.68532. lr 4.725451e-04:  61%|██████    | 3223/5287 [26:16<18:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3223: train loss 0.68532. lr 4.725451e-04:  61%|██████    | 3224/5287 [26:16<18:00,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3224: train loss 0.71047. lr 4.724722e-04:  61%|██████    | 3224/5287 [26:16<18:00,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3224: train loss 0.71047. lr 4.724722e-04:  61%|██████    | 3225/5287 [26:16<17:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3225: train loss 0.72609. lr 4.723992e-04:  61%|██████    | 3225/5287 [26:17<17:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3225: train loss 0.72609. lr 4.723992e-04:  61%|██████    | 3226/5287 [26:17<17:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3226: train loss 0.73102. lr 4.723263e-04:  61%|██████    | 3226/5287 [26:17<17:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3226: train loss 0.73102. lr 4.723263e-04:  61%|██████    | 3227/5287 [26:17<17:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3227: train loss 0.70085. lr 4.722533e-04:  61%|██████    | 3227/5287 [26:18<17:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3227: train loss 0.70085. lr 4.722533e-04:  61%|██████    | 3228/5287 [26:18<17:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3228: train loss 0.69627. lr 4.721803e-04:  61%|██████    | 3228/5287 [26:18<17:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3228: train loss 0.69627. lr 4.721803e-04:  61%|██████    | 3229/5287 [26:18<16:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3229: train loss 0.72833. lr 4.721073e-04:  61%|██████    | 3229/5287 [26:19<16:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3229: train loss 0.72833. lr 4.721073e-04:  61%|██████    | 3230/5287 [26:19<16:50,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3230: train loss 0.69450. lr 4.720343e-04:  61%|██████    | 3230/5287 [26:19<16:50,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3230: train loss 0.69450. lr 4.720343e-04:  61%|██████    | 3231/5287 [26:19<17:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3231: train loss 0.71624. lr 4.719612e-04:  61%|██████    | 3231/5287 [26:20<17:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3231: train loss 0.71624. lr 4.719612e-04:  61%|██████    | 3232/5287 [26:20<17:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3232: train loss 0.68432. lr 4.718882e-04:  61%|██████    | 3232/5287 [26:20<17:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3232: train loss 0.68432. lr 4.718882e-04:  61%|██████    | 3233/5287 [26:20<17:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3233: train loss 0.71626. lr 4.718151e-04:  61%|██████    | 3233/5287 [26:21<17:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3233: train loss 0.71626. lr 4.718151e-04:  61%|██████    | 3234/5287 [26:21<17:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3234: train loss 0.72558. lr 4.717420e-04:  61%|██████    | 3234/5287 [26:21<17:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3234: train loss 0.72558. lr 4.717420e-04:  61%|██████    | 3235/5287 [26:21<17:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3235: train loss 0.71665. lr 4.716689e-04:  61%|██████    | 3235/5287 [26:22<17:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3235: train loss 0.71665. lr 4.716689e-04:  61%|██████    | 3236/5287 [26:22<17:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3236: train loss 0.70066. lr 4.715958e-04:  61%|██████    | 3236/5287 [26:22<17:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3236: train loss 0.70066. lr 4.715958e-04:  61%|██████    | 3237/5287 [26:22<16:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3237: train loss 0.69616. lr 4.715226e-04:  61%|██████    | 3237/5287 [26:23<16:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3237: train loss 0.69616. lr 4.715226e-04:  61%|██████    | 3238/5287 [26:23<16:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3238: train loss 0.67868. lr 4.714495e-04:  61%|██████    | 3238/5287 [26:23<16:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3238: train loss 0.67868. lr 4.714495e-04:  61%|██████▏   | 3239/5287 [26:23<16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3239: train loss 0.71292. lr 4.713763e-04:  61%|██████▏   | 3239/5287 [26:24<16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3239: train loss 0.71292. lr 4.713763e-04:  61%|██████▏   | 3240/5287 [26:24<17:03,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3240: train loss 0.70363. lr 4.713032e-04:  61%|██████▏   | 3240/5287 [26:24<17:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3240: train loss 0.70363. lr 4.713032e-04:  61%|██████▏   | 3241/5287 [26:24<16:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3241: train loss 0.69668. lr 4.712300e-04:  61%|██████▏   | 3241/5287 [26:25<16:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3241: train loss 0.69668. lr 4.712300e-04:  61%|██████▏   | 3242/5287 [26:25<16:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3242: train loss 0.69021. lr 4.711568e-04:  61%|██████▏   | 3242/5287 [26:25<16:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3242: train loss 0.69021. lr 4.711568e-04:  61%|██████▏   | 3243/5287 [26:25<16:42,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3243: train loss 0.69328. lr 4.710835e-04:  61%|██████▏   | 3243/5287 [26:26<16:42,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3243: train loss 0.69328. lr 4.710835e-04:  61%|██████▏   | 3244/5287 [26:26<16:40,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3244: train loss 0.69310. lr 4.710103e-04:  61%|██████▏   | 3244/5287 [26:26<16:40,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3244: train loss 0.69310. lr 4.710103e-04:  61%|██████▏   | 3245/5287 [26:26<16:38,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3245: train loss 0.71056. lr 4.709370e-04:  61%|██████▏   | 3245/5287 [26:27<16:38,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3245: train loss 0.71056. lr 4.709370e-04:  61%|██████▏   | 3246/5287 [26:27<17:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3246: train loss 0.72528. lr 4.708638e-04:  61%|██████▏   | 3246/5287 [26:27<17:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3246: train loss 0.72528. lr 4.708638e-04:  61%|██████▏   | 3247/5287 [26:27<17:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3247: train loss 0.69312. lr 4.707905e-04:  61%|██████▏   | 3247/5287 [26:28<17:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3247: train loss 0.69312. lr 4.707905e-04:  61%|██████▏   | 3248/5287 [26:28<17:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3248: train loss 0.71140. lr 4.707172e-04:  61%|██████▏   | 3248/5287 [26:28<17:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3248: train loss 0.71140. lr 4.707172e-04:  61%|██████▏   | 3249/5287 [26:28<17:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3249: train loss 0.70004. lr 4.706439e-04:  61%|██████▏   | 3249/5287 [26:29<17:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3249: train loss 0.70004. lr 4.706439e-04:  61%|██████▏   | 3250/5287 [26:29<18:24,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3250: train loss 0.68882. lr 4.705705e-04:  61%|██████▏   | 3250/5287 [26:29<18:24,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3250: train loss 0.68882. lr 4.705705e-04:  61%|██████▏   | 3251/5287 [26:29<17:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3251: train loss 0.71752. lr 4.704972e-04:  61%|██████▏   | 3251/5287 [26:30<17:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3251: train loss 0.71752. lr 4.704972e-04:  62%|██████▏   | 3252/5287 [26:30<17:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3252: train loss 0.70573. lr 4.704238e-04:  62%|██████▏   | 3252/5287 [26:30<17:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3252: train loss 0.70573. lr 4.704238e-04:  62%|██████▏   | 3253/5287 [26:30<17:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3253: train loss 0.68931. lr 4.703505e-04:  62%|██████▏   | 3253/5287 [26:31<17:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3253: train loss 0.68931. lr 4.703505e-04:  62%|██████▏   | 3254/5287 [26:31<16:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3254: train loss 0.70631. lr 4.702771e-04:  62%|██████▏   | 3254/5287 [26:31<16:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3254: train loss 0.70631. lr 4.702771e-04:  62%|██████▏   | 3255/5287 [26:31<16:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3255: train loss 0.71010. lr 4.702037e-04:  62%|██████▏   | 3255/5287 [26:32<16:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3255: train loss 0.71010. lr 4.702037e-04:  62%|██████▏   | 3256/5287 [26:32<16:35,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3256: train loss 0.71080. lr 4.701302e-04:  62%|██████▏   | 3256/5287 [26:32<16:35,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3256: train loss 0.71080. lr 4.701302e-04:  62%|██████▏   | 3257/5287 [26:32<16:31,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3257: train loss 0.67824. lr 4.700568e-04:  62%|██████▏   | 3257/5287 [26:33<16:31,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3257: train loss 0.67824. lr 4.700568e-04:  62%|██████▏   | 3258/5287 [26:33<16:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3258: train loss 0.70250. lr 4.699834e-04:  62%|██████▏   | 3258/5287 [26:33<16:25,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3258: train loss 0.70250. lr 4.699834e-04:  62%|██████▏   | 3259/5287 [26:33<16:24,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3259: train loss 0.70985. lr 4.699099e-04:  62%|██████▏   | 3259/5287 [26:34<16:24,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3259: train loss 0.70985. lr 4.699099e-04:  62%|██████▏   | 3260/5287 [26:34<16:21,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3260: train loss 0.72246. lr 4.698364e-04:  62%|██████▏   | 3260/5287 [26:34<16:21,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3260: train loss 0.72246. lr 4.698364e-04:  62%|██████▏   | 3261/5287 [26:34<16:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3261: train loss 0.70063. lr 4.697629e-04:  62%|██████▏   | 3261/5287 [26:35<16:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3261: train loss 0.70063. lr 4.697629e-04:  62%|██████▏   | 3262/5287 [26:35<16:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3262: train loss 0.71616. lr 4.696894e-04:  62%|██████▏   | 3262/5287 [26:35<16:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3262: train loss 0.71616. lr 4.696894e-04:  62%|██████▏   | 3263/5287 [26:35<16:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3263: train loss 0.69283. lr 4.696159e-04:  62%|██████▏   | 3263/5287 [26:36<16:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3263: train loss 0.69283. lr 4.696159e-04:  62%|██████▏   | 3264/5287 [26:36<16:14,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3264: train loss 0.69769. lr 4.695423e-04:  62%|██████▏   | 3264/5287 [26:36<16:14,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3264: train loss 0.69769. lr 4.695423e-04:  62%|██████▏   | 3265/5287 [26:36<16:15,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3265: train loss 0.69440. lr 4.694688e-04:  62%|██████▏   | 3265/5287 [26:37<16:15,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3265: train loss 0.69440. lr 4.694688e-04:  62%|██████▏   | 3266/5287 [26:37<16:14,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3266: train loss 0.70323. lr 4.693952e-04:  62%|██████▏   | 3266/5287 [26:37<16:14,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3266: train loss 0.70323. lr 4.693952e-04:  62%|██████▏   | 3267/5287 [26:37<16:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3267: train loss 0.70236. lr 4.693216e-04:  62%|██████▏   | 3267/5287 [26:37<16:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3267: train loss 0.70236. lr 4.693216e-04:  62%|██████▏   | 3268/5287 [26:37<16:09,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3268: train loss 0.72594. lr 4.692480e-04:  62%|██████▏   | 3268/5287 [26:38<16:09,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3268: train loss 0.72594. lr 4.692480e-04:  62%|██████▏   | 3269/5287 [26:38<16:08,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3269: train loss 0.70803. lr 4.691744e-04:  62%|██████▏   | 3269/5287 [26:38<16:08,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3269: train loss 0.70803. lr 4.691744e-04:  62%|██████▏   | 3270/5287 [26:38<16:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3270: train loss 0.69912. lr 4.691008e-04:  62%|██████▏   | 3270/5287 [26:39<16:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3270: train loss 0.69912. lr 4.691008e-04:  62%|██████▏   | 3271/5287 [26:39<16:27,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3271: train loss 0.71070. lr 4.690271e-04:  62%|██████▏   | 3271/5287 [26:39<16:27,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3271: train loss 0.71070. lr 4.690271e-04:  62%|██████▏   | 3272/5287 [26:39<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3272: train loss 0.72759. lr 4.689535e-04:  62%|██████▏   | 3272/5287 [26:40<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3272: train loss 0.72759. lr 4.689535e-04:  62%|██████▏   | 3273/5287 [26:40<16:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3273: train loss 0.68421. lr 4.688798e-04:  62%|██████▏   | 3273/5287 [26:40<16:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3273: train loss 0.68421. lr 4.688798e-04:  62%|██████▏   | 3274/5287 [26:40<16:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3274: train loss 0.68982. lr 4.688061e-04:  62%|██████▏   | 3274/5287 [26:41<16:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3274: train loss 0.68982. lr 4.688061e-04:  62%|██████▏   | 3275/5287 [26:41<17:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3275: train loss 0.69319. lr 4.687324e-04:  62%|██████▏   | 3275/5287 [26:42<17:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3275: train loss 0.69319. lr 4.687324e-04:  62%|██████▏   | 3276/5287 [26:42<17:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3276: train loss 0.70169. lr 4.686587e-04:  62%|██████▏   | 3276/5287 [26:42<17:12,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3276: train loss 0.70169. lr 4.686587e-04:  62%|██████▏   | 3277/5287 [26:42<17:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3277: train loss 0.69454. lr 4.685850e-04:  62%|██████▏   | 3277/5287 [26:43<17:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3277: train loss 0.69454. lr 4.685850e-04:  62%|██████▏   | 3278/5287 [26:43<18:15,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3278: train loss 0.70085. lr 4.685112e-04:  62%|██████▏   | 3278/5287 [26:43<18:15,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3278: train loss 0.70085. lr 4.685112e-04:  62%|██████▏   | 3279/5287 [26:43<17:44,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3279: train loss 0.69684. lr 4.684375e-04:  62%|██████▏   | 3279/5287 [26:44<17:44,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3279: train loss 0.69684. lr 4.684375e-04:  62%|██████▏   | 3280/5287 [26:44<17:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3280: train loss 0.67485. lr 4.683637e-04:  62%|██████▏   | 3280/5287 [26:44<17:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3280: train loss 0.67485. lr 4.683637e-04:  62%|██████▏   | 3281/5287 [26:44<17:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3281: train loss 0.69355. lr 4.682899e-04:  62%|██████▏   | 3281/5287 [26:45<17:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3281: train loss 0.69355. lr 4.682899e-04:  62%|██████▏   | 3282/5287 [26:45<16:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3282: train loss 0.69994. lr 4.682161e-04:  62%|██████▏   | 3282/5287 [26:45<16:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3282: train loss 0.69994. lr 4.682161e-04:  62%|██████▏   | 3283/5287 [26:45<16:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3283: train loss 0.72935. lr 4.681422e-04:  62%|██████▏   | 3283/5287 [26:46<16:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3283: train loss 0.72935. lr 4.681422e-04:  62%|██████▏   | 3284/5287 [26:46<16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3284: train loss 0.67712. lr 4.680684e-04:  62%|██████▏   | 3284/5287 [26:46<16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3284: train loss 0.67712. lr 4.680684e-04:  62%|██████▏   | 3285/5287 [26:46<16:22,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3285: train loss 0.67740. lr 4.679946e-04:  62%|██████▏   | 3285/5287 [26:47<16:22,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3285: train loss 0.67740. lr 4.679946e-04:  62%|██████▏   | 3286/5287 [26:47<16:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3286: train loss 0.69434. lr 4.679207e-04:  62%|██████▏   | 3286/5287 [26:47<16:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3286: train loss 0.69434. lr 4.679207e-04:  62%|██████▏   | 3287/5287 [26:47<16:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3287: train loss 0.69952. lr 4.678468e-04:  62%|██████▏   | 3287/5287 [26:48<16:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3287: train loss 0.69952. lr 4.678468e-04:  62%|██████▏   | 3288/5287 [26:48<16:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3288: train loss 0.70070. lr 4.677729e-04:  62%|██████▏   | 3288/5287 [26:48<16:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3288: train loss 0.70070. lr 4.677729e-04:  62%|██████▏   | 3289/5287 [26:48<16:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3289: train loss 0.69654. lr 4.676990e-04:  62%|██████▏   | 3289/5287 [26:49<16:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3289: train loss 0.69654. lr 4.676990e-04:  62%|██████▏   | 3290/5287 [26:49<16:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3290: train loss 0.67442. lr 4.676251e-04:  62%|██████▏   | 3290/5287 [26:49<16:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3290: train loss 0.67442. lr 4.676251e-04:  62%|██████▏   | 3291/5287 [26:49<16:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3291: train loss 0.69741. lr 4.675511e-04:  62%|██████▏   | 3291/5287 [26:50<16:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3291: train loss 0.69741. lr 4.675511e-04:  62%|██████▏   | 3292/5287 [26:50<16:16,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3292: train loss 0.70441. lr 4.674772e-04:  62%|██████▏   | 3292/5287 [26:50<16:16,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3292: train loss 0.70441. lr 4.674772e-04:  62%|██████▏   | 3293/5287 [26:50<16:11,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3293: train loss 0.69131. lr 4.674032e-04:  62%|██████▏   | 3293/5287 [26:51<16:11,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3293: train loss 0.69131. lr 4.674032e-04:  62%|██████▏   | 3294/5287 [26:51<16:10,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3294: train loss 0.69497. lr 4.673292e-04:  62%|██████▏   | 3294/5287 [26:51<16:10,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 3294: train loss 0.69497. lr 4.673292e-04:  62%|██████▏   | 3295/5287 [26:51<16:06,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3295: train loss 0.69613. lr 4.672552e-04:  62%|██████▏   | 3295/5287 [26:51<16:06,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3295: train loss 0.69613. lr 4.672552e-04:  62%|██████▏   | 3296/5287 [26:51<16:02,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3296: train loss 0.68629. lr 4.671812e-04:  62%|██████▏   | 3296/5287 [26:52<16:02,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3296: train loss 0.68629. lr 4.671812e-04:  62%|██████▏   | 3297/5287 [26:52<16:02,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3297: train loss 0.69932. lr 4.671072e-04:  62%|██████▏   | 3297/5287 [26:52<16:02,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3297: train loss 0.69932. lr 4.671072e-04:  62%|██████▏   | 3298/5287 [26:52<16:01,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3298: train loss 0.69639. lr 4.670331e-04:  62%|██████▏   | 3298/5287 [26:53<16:01,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3298: train loss 0.69639. lr 4.670331e-04:  62%|██████▏   | 3299/5287 [26:53<15:56,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3299: train loss 0.68599. lr 4.669591e-04:  62%|██████▏   | 3299/5287 [26:53<15:56,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3299: train loss 0.68599. lr 4.669591e-04:  62%|██████▏   | 3300/5287 [26:53<15:57,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3300: train loss 0.69973. lr 4.668850e-04:  62%|██████▏   | 3300/5287 [26:54<15:57,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3300: train loss 0.69973. lr 4.668850e-04:  62%|██████▏   | 3301/5287 [26:54<15:57,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3301: train loss 0.70307. lr 4.668109e-04:  62%|██████▏   | 3301/5287 [26:54<15:57,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3301: train loss 0.70307. lr 4.668109e-04:  62%|██████▏   | 3302/5287 [26:54<15:54,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3302: train loss 0.69204. lr 4.667368e-04:  62%|██████▏   | 3302/5287 [26:55<15:54,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 3302: train loss 0.69204. lr 4.667368e-04:  62%|██████▏   | 3303/5287 [26:55<15:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3303: train loss 0.70561. lr 4.666627e-04:  62%|██████▏   | 3303/5287 [26:55<15:56,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 3303: train loss 0.70561. lr 4.666627e-04:  62%|██████▏   | 3304/5287 [26:55<16:00,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3304: train loss 0.69803. lr 4.665885e-04:  62%|██████▏   | 3304/5287 [26:56<16:00,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3304: train loss 0.69803. lr 4.665885e-04:  63%|██████▎   | 3305/5287 [26:56<16:02,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3305: train loss 0.69485. lr 4.665144e-04:  63%|██████▎   | 3305/5287 [26:56<16:02,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 3305: train loss 0.69485. lr 4.665144e-04:  63%|██████▎   | 3306/5287 [26:56<17:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3306: train loss 0.67067. lr 4.664402e-04:  63%|██████▎   | 3306/5287 [26:57<17:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3306: train loss 0.67067. lr 4.664402e-04:  63%|██████▎   | 3307/5287 [26:57<16:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3307: train loss 0.69100. lr 4.663660e-04:  63%|██████▎   | 3307/5287 [26:57<16:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3307: train loss 0.69100. lr 4.663660e-04:  63%|██████▎   | 3308/5287 [26:57<16:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3308: train loss 0.68780. lr 4.662919e-04:  63%|██████▎   | 3308/5287 [26:58<16:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3308: train loss 0.68780. lr 4.662919e-04:  63%|██████▎   | 3309/5287 [26:58<16:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3309: train loss 0.70127. lr 4.662177e-04:  63%|██████▎   | 3309/5287 [26:58<16:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3309: train loss 0.70127. lr 4.662177e-04:  63%|██████▎   | 3310/5287 [26:58<16:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3310: train loss 0.68358. lr 4.661434e-04:  63%|██████▎   | 3310/5287 [26:59<16:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3310: train loss 0.68358. lr 4.661434e-04:  63%|██████▎   | 3311/5287 [26:59<16:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3311: train loss 0.70404. lr 4.660692e-04:  63%|██████▎   | 3311/5287 [26:59<16:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3311: train loss 0.70404. lr 4.660692e-04:  63%|██████▎   | 3312/5287 [26:59<16:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3312: train loss 0.70824. lr 4.659949e-04:  63%|██████▎   | 3312/5287 [27:00<16:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3312: train loss 0.70824. lr 4.659949e-04:  63%|██████▎   | 3313/5287 [27:00<16:16,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3313: train loss 0.68453. lr 4.659207e-04:  63%|██████▎   | 3313/5287 [27:00<16:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3313: train loss 0.68453. lr 4.659207e-04:  63%|██████▎   | 3314/5287 [27:00<16:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3314: train loss 0.69969. lr 4.658464e-04:  63%|██████▎   | 3314/5287 [27:01<16:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3314: train loss 0.69969. lr 4.658464e-04:  63%|██████▎   | 3315/5287 [27:01<16:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3315: train loss 0.67197. lr 4.657721e-04:  63%|██████▎   | 3315/5287 [27:01<16:16,  2.02it/s]\u001b[AIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 1 iter 126: train loss 6.16449. lr 5.999777e-04:   1%|          | 126/16329 [01:01<2:10:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 6.16449. lr 5.999777e-04:   1%|          | 127/16329 [01:01<2:10:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 6.15122. lr 5.999773e-04:   1%|          | 127/16329 [01:01<2:10:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 6.15122. lr 5.999773e-04:   1%|          | 128/16329 [01:01<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 6.08000. lr 5.999770e-04:   1%|          | 128/16329 [01:02<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 6.08000. lr 5.999770e-04:   1%|          | 129/16329 [01:02<2:10:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 6.15342. lr 5.999766e-04:   1%|          | 129/16329 [01:02<2:10:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 6.15342. lr 5.999766e-04:   1%|          | 130/16329 [01:02<2:10:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 6.12150. lr 5.999762e-04:   1%|          | 130/16329 [01:03<2:10:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 6.12150. lr 5.999762e-04:   1%|          | 131/16329 [01:03<2:10:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 6.10767. lr 5.999759e-04:   1%|          | 131/16329 [01:03<2:10:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 6.10767. lr 5.999759e-04:   1%|          | 132/16329 [01:03<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 6.07394. lr 5.999755e-04:   1%|          | 132/16329 [01:04<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 6.07394. lr 5.999755e-04:   1%|          | 133/16329 [01:04<2:10:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 6.09385. lr 5.999751e-04:   1%|          | 133/16329 [01:04<2:10:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 6.09385. lr 5.999751e-04:   1%|          | 134/16329 [01:04<2:10:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 6.12726. lr 5.999748e-04:   1%|          | 134/16329 [01:05<2:10:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 6.12726. lr 5.999748e-04:   1%|          | 135/16329 [01:05<2:10:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 6.03166. lr 5.999744e-04:   1%|          | 135/16329 [01:05<2:10:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 6.03166. lr 5.999744e-04:   1%|          | 136/16329 [01:05<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 6.15028. lr 5.999740e-04:   1%|          | 136/16329 [01:06<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 6.15028. lr 5.999740e-04:   1%|          | 137/16329 [01:06<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 6.08279. lr 5.999736e-04:   1%|          | 137/16329 [01:06<2:10:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 6.08279. lr 5.999736e-04:   1%|          | 138/16329 [01:06<2:10:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 6.12505. lr 5.999732e-04:   1%|          | 138/16329 [01:07<2:10:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 6.12505. lr 5.999732e-04:   1%|          | 139/16329 [01:07<2:10:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 6.01163. lr 5.999729e-04:   1%|          | 139/16329 [01:07<2:10:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 6.01163. lr 5.999729e-04:   1%|          | 140/16329 [01:07<2:10:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 6.06440. lr 5.999725e-04:   1%|          | 140/16329 [01:08<2:10:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 6.06440. lr 5.999725e-04:   1%|          | 141/16329 [01:08<2:10:28,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 6.09833. lr 5.999721e-04:   1%|          | 141/16329 [01:08<2:10:28,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 6.09833. lr 5.999721e-04:   1%|          | 142/16329 [01:08<2:10:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 6.06173. lr 5.999717e-04:   1%|          | 142/16329 [01:08<2:10:29,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 6.06173. lr 5.999717e-04:   1%|          | 143/16329 [01:08<2:10:31,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 6.04213. lr 5.999713e-04:   1%|          | 143/16329 [01:09<2:10:31,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 6.04213. lr 5.999713e-04:   1%|          | 144/16329 [01:09<2:10:24,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 6.10077. lr 5.999709e-04:   1%|          | 144/16329 [01:09<2:10:24,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 6.10077. lr 5.999709e-04:   1%|          | 145/16329 [01:09<2:09:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 6.04267. lr 5.999705e-04:   1%|          | 145/16329 [01:10<2:09:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 6.04267. lr 5.999705e-04:   1%|          | 146/16329 [01:10<2:09:41,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 6.07231. lr 5.999701e-04:   1%|          | 146/16329 [01:10<2:09:41,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 6.07231. lr 5.999701e-04:   1%|          | 147/16329 [01:10<2:09:37,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 6.04309. lr 5.999697e-04:   1%|          | 147/16329 [01:11<2:09:37,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 6.04309. lr 5.999697e-04:   1%|          | 148/16329 [01:11<2:09:25,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 6.07754. lr 5.999692e-04:   1%|          | 148/16329 [01:11<2:09:25,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 6.07754. lr 5.999692e-04:   1%|          | 149/16329 [01:11<2:09:18,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 6.09125. lr 5.999688e-04:   1%|          | 149/16329 [01:12<2:09:18,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 6.09125. lr 5.999688e-04:   1%|          | 150/16329 [01:12<2:09:09,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 150: train loss 6.03803. lr 5.999684e-04:   1%|          | 150/16329 [01:12<2:09:09,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 150: train loss 6.03803. lr 5.999684e-04:   1%|          | 151/16329 [01:12<2:09:07,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 6.02273. lr 5.999680e-04:   1%|          | 151/16329 [01:13<2:09:07,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 6.02273. lr 5.999680e-04:   1%|          | 152/16329 [01:13<2:09:05,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 6.05618. lr 5.999676e-04:   1%|          | 152/16329 [01:13<2:09:05,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 6.05618. lr 5.999676e-04:   1%|          | 153/16329 [01:13<2:09:00,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 6.01597. lr 5.999671e-04:   1%|          | 153/16329 [01:14<2:09:00,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 6.01597. lr 5.999671e-04:   1%|          | 154/16329 [01:14<2:09:00,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 6.00844. lr 5.999667e-04:   1%|          | 154/16329 [01:14<2:09:00,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 6.00844. lr 5.999667e-04:   1%|          | 155/16329 [01:14<2:08:58,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 6.01249. lr 5.999663e-04:   1%|          | 155/16329 [01:15<2:08:58,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 6.01249. lr 5.999663e-04:   1%|          | 156/16329 [01:15<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 6.00407. lr 5.999659e-04:   1%|          | 156/16329 [01:15<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 6.00407. lr 5.999659e-04:   1%|          | 157/16329 [01:15<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 5.97766. lr 5.999654e-04:   1%|          | 157/16329 [01:16<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 5.97766. lr 5.999654e-04:   1%|          | 158/16329 [01:16<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 5.93502. lr 5.999650e-04:   1%|          | 158/16329 [01:16<2:08:57,  2.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 158: train loss 5.93502. lr 5.999650e-04:   1%|          | 159/16329 [01:16<2:08:56,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 6.02163. lr 5.999645e-04:   1%|          | 159/16329 [01:17<2:08:56,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 6.02163. lr 5.999645e-04:   1%|          | 160/16329 [01:17<2:08:58,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 5.97657. lr 5.999641e-04:   1%|          | 160/16329 [01:17<2:08:58,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 5.97657. lr 5.999641e-04:   1%|          | 161/16329 [01:17<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 5.99533. lr 5.999636e-04:   1%|          | 161/16329 [01:18<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 5.99533. lr 5.999636e-04:   1%|          | 162/16329 [01:18<2:08:59,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 5.94194. lr 5.999632e-04:   1%|          | 162/16329 [01:18<2:08:59,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 5.94194. lr 5.999632e-04:   1%|          | 163/16329 [01:18<2:08:59,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 5.89383. lr 5.999627e-04:   1%|          | 163/16329 [01:19<2:08:59,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 5.89383. lr 5.999627e-04:   1%|          | 164/16329 [01:19<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 5.99156. lr 5.999623e-04:   1%|          | 164/16329 [01:19<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 5.99156. lr 5.999623e-04:   1%|          | 165/16329 [01:19<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 5.93238. lr 5.999618e-04:   1%|          | 165/16329 [01:19<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 5.93238. lr 5.999618e-04:   1%|          | 166/16329 [01:19<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 5.97531. lr 5.999614e-04:   1%|          | 166/16329 [01:20<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 5.97531. lr 5.999614e-04:   1%|          | 167/16329 [01:20<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 5.95107. lr 5.999609e-04:   1%|          | 167/16329 [01:20<2:08:57,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 5.95107. lr 5.999609e-04:   1%|          | 168/16329 [01:20<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 5.95414. lr 5.999604e-04:   1%|          | 168/16329 [01:21<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 5.95414. lr 5.999604e-04:   1%|          | 169/16329 [01:21<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 5.91556. lr 5.999600e-04:   1%|          | 169/16329 [01:21<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 5.91556. lr 5.999600e-04:   1%|          | 170/16329 [01:21<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 5.92931. lr 5.999595e-04:   1%|          | 170/16329 [01:22<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 5.92931. lr 5.999595e-04:   1%|          | 171/16329 [01:22<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 5.87864. lr 5.999590e-04:   1%|          | 171/16329 [01:22<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 5.87864. lr 5.999590e-04:   1%|          | 172/16329 [01:22<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 5.92506. lr 5.999585e-04:   1%|          | 172/16329 [01:23<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 5.92506. lr 5.999585e-04:   1%|          | 173/16329 [01:23<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 5.96226. lr 5.999580e-04:   1%|          | 173/16329 [01:23<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 5.96226. lr 5.999580e-04:   1%|          | 174/16329 [01:23<2:08:53,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 5.85974. lr 5.999576e-04:   1%|          | 174/16329 [01:24<2:08:53,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 5.85974. lr 5.999576e-04:   1%|          | 175/16329 [01:24<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 5.96330. lr 5.999571e-04:   1%|          | 175/16329 [01:24<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 5.96330. lr 5.999571e-04:   1%|          | 176/16329 [01:24<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 5.93704. lr 5.999566e-04:   1%|          | 176/16329 [01:25<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 5.93704. lr 5.999566e-04:   1%|          | 177/16329 [01:25<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 5.87876. lr 5.999561e-04:   1%|          | 177/16329 [01:25<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 5.87876. lr 5.999561e-04:   1%|          | 178/16329 [01:25<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 5.90466. lr 5.999556e-04:   1%|          | 178/16329 [01:26<2:08:55,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 5.90466. lr 5.999556e-04:   1%|          | 179/16329 [01:26<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 5.87187. lr 5.999551e-04:   1%|          | 179/16329 [01:26<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 5.87187. lr 5.999551e-04:   1%|          | 180/16329 [01:26<2:08:53,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 5.88035. lr 5.999546e-04:   1%|          | 180/16329 [01:27<2:08:53,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 5.88035. lr 5.999546e-04:   1%|          | 181/16329 [01:27<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 5.81242. lr 5.999541e-04:   1%|          | 181/16329 [01:27<2:08:54,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 5.81242. lr 5.999541e-04:   1%|          | 182/16329 [01:27<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 5.76991. lr 5.999536e-04:   1%|          | 182/16329 [01:28<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 5.76991. lr 5.999536e-04:   1%|          | 183/16329 [01:28<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 5.87866. lr 5.999531e-04:   1%|          | 183/16329 [01:28<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 5.87866. lr 5.999531e-04:   1%|          | 184/16329 [01:28<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 5.89971. lr 5.999526e-04:   1%|          | 184/16329 [01:29<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 5.89971. lr 5.999526e-04:   1%|          | 185/16329 [01:29<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 5.87042. lr 5.999521e-04:   1%|          | 185/16329 [01:29<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 5.87042. lr 5.999521e-04:   1%|          | 186/16329 [01:29<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 5.88788. lr 5.999515e-04:   1%|          | 186/16329 [01:30<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 5.88788. lr 5.999515e-04:   1%|          | 187/16329 [01:30<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 187: train loss 5.82974. lr 5.999510e-04:   1%|          | 187/16329 [01:30<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 187: train loss 5.82974. lr 5.999510e-04:   1%|          | 188/16329 [01:30<2:08:49,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 5.84941. lr 5.999505e-04:   1%|          | 188/16329 [01:31<2:08:49,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 5.84941. lr 5.999505e-04:   1%|          | 189/16329 [01:31<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 5.82341. lr 5.999500e-04:   1%|          | 189/16329 [01:31<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 5.82341. lr 5.999500e-04:   1%|          | 190/16329 [01:31<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 5.84077. lr 5.999494e-04:   1%|          | 190/16329 [01:31<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 5.84077. lr 5.999494e-04:   1%|          | 191/16329 [01:31<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 5.82606. lr 5.999489e-04:   1%|          | 191/16329 [01:32<2:08:50,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 5.82606. lr 5.999489e-04:   1%|          | 192/16329 [01:32<2:08:47,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 5.79566. lr 5.999484e-04:   1%|          | 192/16329 [01:32<2:08:47,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 5.79566. lr 5.999484e-04:   1%|          | 193/16329 [01:32<2:08:45,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 5.88976. lr 5.999478e-04:   1%|          | 193/16329 [01:33<2:08:45,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 5.88976. lr 5.999478e-04:   1%|          | 194/16329 [01:33<2:08:45,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 5.81047. lr 5.999473e-04:   1%|          | 194/16329 [01:33<2:08:45,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 5.81047. lr 5.999473e-04:   1%|          | 195/16329 [01:33<2:08:47,  2.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 195: train loss 5.83952. lr 5.999468e-04:   1%|          | 195/16329 [01:34<2:08:47,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 5.83952. lr 5.999468e-04:   1%|          | 196/16329 [01:34<2:08:46,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 5.79618. lr 5.999462e-04:   1%|          | 196/16329 [01:34<2:08:46,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 5.79618. lr 5.999462e-04:   1%|          | 197/16329 [01:34<2:08:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 5.84495. lr 5.999457e-04:   1%|          | 197/16329 [01:35<2:08:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 5.84495. lr 5.999457e-04:   1%|          | 198/16329 [01:35<2:08:56,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 5.76150. lr 5.999451e-04:   1%|          | 198/16329 [01:35<2:08:56,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 5.76150. lr 5.999451e-04:   1%|          | 199/16329 [01:35<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 5.79216. lr 5.999446e-04:   1%|          | 199/16329 [01:36<2:08:52,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 5.79216. lr 5.999446e-04:   1%|          | 200/16329 [01:36<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 5.84535. lr 5.999440e-04:   1%|          | 200/16329 [01:36<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 5.84535. lr 5.999440e-04:   1%|          | 201/16329 [01:36<2:08:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 5.80976. lr 5.999434e-04:   1%|          | 201/16329 [01:37<2:08:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 5.80976. lr 5.999434e-04:   1%|          | 202/16329 [01:37<2:08:55,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 5.78737. lr 5.999429e-04:   1%|          | 202/16329 [01:37<2:08:55,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 5.78737. lr 5.999429e-04:   1%|          | 203/16329 [01:37<2:08:51,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 5.82968. lr 5.999423e-04:   1%|          | 203/16329 [01:38<2:08:51,  2.09it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 5.82968. lr 5.999423e-04:   1%|          | 204/16329 [01:38<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 5.80614. lr 5.999418e-04:   1%|          | 204/16329 [01:38<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 5.80614. lr 5.999418e-04:   1%|▏         | 205/16329 [01:38<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 5.79451. lr 5.999412e-04:   1%|▏         | 205/16329 [01:39<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 5.79451. lr 5.999412e-04:   1%|▏         | 206/16329 [01:39<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 5.75500. lr 5.999406e-04:   1%|▏         | 206/16329 [01:39<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 5.75500. lr 5.999406e-04:   1%|▏         | 207/16329 [01:39<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 5.73750. lr 5.999400e-04:   1%|▏         | 207/16329 [01:40<2:08:59,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 5.73750. lr 5.999400e-04:   1%|▏         | 208/16329 [01:40<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 5.76080. lr 5.999395e-04:   1%|▏         | 208/16329 [01:40<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 5.76080. lr 5.999395e-04:   1%|▏         | 209/16329 [01:40<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 5.77685. lr 5.999389e-04:   1%|▏         | 209/16329 [01:41<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 5.77685. lr 5.999389e-04:   1%|▏         | 210/16329 [01:41<2:08:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 5.67750. lr 5.999383e-04:   1%|▏         | 210/16329 [01:41<2:08:57,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 5.67750. lr 5.999383e-04:   1%|▏         | 211/16329 [01:41<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 5.77676. lr 5.999377e-04:   1%|▏         | 211/16329 [01:42<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 5.77676. lr 5.999377e-04:   1%|▏         | 212/16329 [01:42<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 5.75279. lr 5.999371e-04:   1%|▏         | 212/16329 [01:42<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 5.75279. lr 5.999371e-04:   1%|▏         | 213/16329 [01:42<2:09:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 5.79943. lr 5.999365e-04:   1%|▏         | 213/16329 [01:42<2:09:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 5.79943. lr 5.999365e-04:   1%|▏         | 214/16329 [01:43<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 5.75498. lr 5.999359e-04:   1%|▏         | 214/16329 [01:43<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 5.75498. lr 5.999359e-04:   1%|▏         | 215/16329 [01:43<2:09:09,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 5.71607. lr 5.999353e-04:   1%|▏         | 215/16329 [01:43<2:09:09,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 5.71607. lr 5.999353e-04:   1%|▏         | 216/16329 [01:43<2:09:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 5.80678. lr 5.999347e-04:   1%|▏         | 216/16329 [01:44<2:09:11,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 5.80678. lr 5.999347e-04:   1%|▏         | 217/16329 [01:44<2:09:09,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 5.78932. lr 5.999341e-04:   1%|▏         | 217/16329 [01:44<2:09:09,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 5.78932. lr 5.999341e-04:   1%|▏         | 218/16329 [01:44<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 5.77721. lr 5.999335e-04:   1%|▏         | 218/16329 [01:45<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 5.77721. lr 5.999335e-04:   1%|▏         | 219/16329 [01:45<2:09:01,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 5.70048. lr 5.999329e-04:   1%|▏         | 219/16329 [01:45<2:09:01,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 5.70048. lr 5.999329e-04:   1%|▏         | 220/16329 [01:45<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 5.72256. lr 5.999323e-04:   1%|▏         | 220/16329 [01:46<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 5.72256. lr 5.999323e-04:   1%|▏         | 221/16329 [01:46<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 5.70831. lr 5.999317e-04:   1%|▏         | 221/16329 [01:46<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 5.70831. lr 5.999317e-04:   1%|▏         | 222/16329 [01:46<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 5.69801. lr 5.999311e-04:   1%|▏         | 222/16329 [01:47<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 5.69801. lr 5.999311e-04:   1%|▏         | 223/16329 [01:47<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 5.82189. lr 5.999304e-04:   1%|▏         | 223/16329 [01:47<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 5.82189. lr 5.999304e-04:   1%|▏         | 224/16329 [01:47<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 5.66723. lr 5.999298e-04:   1%|▏         | 224/16329 [01:48<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 5.66723. lr 5.999298e-04:   1%|▏         | 225/16329 [01:48<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 225: train loss 5.70834. lr 5.999292e-04:   1%|▏         | 225/16329 [01:48<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 225: train loss 5.70834. lr 5.999292e-04:   1%|▏         | 226/16329 [01:48<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 5.68184. lr 5.999286e-04:   1%|▏         | 226/16329 [01:49<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 5.68184. lr 5.999286e-04:   1%|▏         | 227/16329 [01:49<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 5.67316. lr 5.999279e-04:   1%|▏         | 227/16329 [01:49<2:09:03,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 5.67316. lr 5.999279e-04:   1%|▏         | 228/16329 [01:49<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 5.70875. lr 5.999273e-04:   1%|▏         | 228/16329 [01:50<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 5.70875. lr 5.999273e-04:   1%|▏         | 229/16329 [01:50<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 5.61329. lr 5.999267e-04:   1%|▏         | 229/16329 [01:50<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 5.61329. lr 5.999267e-04:   1%|▏         | 230/16329 [01:50<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 5.66243. lr 5.999260e-04:   1%|▏         | 230/16329 [01:51<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 5.66243. lr 5.999260e-04:   1%|▏         | 231/16329 [01:51<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 5.68531. lr 5.999254e-04:   1%|▏         | 231/16329 [01:51<2:09:07,  2.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 231: train loss 5.68531. lr 5.999254e-04:   1%|▏         | 232/16329 [01:51<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 5.63006. lr 5.999247e-04:   1%|▏         | 232/16329 [01:52<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 5.63006. lr 5.999247e-04:   1%|▏         | 233/16329 [01:52<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 5.63101. lr 5.999241e-04:   1%|▏         | 233/16329 [01:52<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 5.63101. lr 5.999241e-04:   1%|▏         | 234/16329 [01:52<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 5.64733. lr 5.999234e-04:   1%|▏         | 234/16329 [01:53<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 5.64733. lr 5.999234e-04:   1%|▏         | 235/16329 [01:53<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 5.63722. lr 5.999228e-04:   1%|▏         | 235/16329 [01:53<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 5.63722. lr 5.999228e-04:   1%|▏         | 236/16329 [01:53<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 5.68391. lr 5.999221e-04:   1%|▏         | 236/16329 [01:54<2:09:04,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 5.68391. lr 5.999221e-04:   1%|▏         | 237/16329 [01:54<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 5.69546. lr 5.999215e-04:   1%|▏         | 237/16329 [01:54<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 5.69546. lr 5.999215e-04:   1%|▏         | 238/16329 [01:54<2:09:13,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 5.63494. lr 5.999208e-04:   1%|▏         | 238/16329 [01:55<2:09:13,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 5.63494. lr 5.999208e-04:   1%|▏         | 239/16329 [01:55<2:09:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 5.64189. lr 5.999201e-04:   1%|▏         | 239/16329 [01:55<2:09:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 5.64189. lr 5.999201e-04:   1%|▏         | 240/16329 [01:55<2:09:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 5.64632. lr 5.999195e-04:   1%|▏         | 240/16329 [01:55<2:09:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 5.64632. lr 5.999195e-04:   1%|▏         | 241/16329 [01:55<2:09:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 5.59697. lr 5.999188e-04:   1%|▏         | 241/16329 [01:56<2:09:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 5.59697. lr 5.999188e-04:   1%|▏         | 242/16329 [01:56<2:09:12,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 5.55909. lr 5.999181e-04:   1%|▏         | 242/16329 [01:56<2:09:12,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 5.55909. lr 5.999181e-04:   1%|▏         | 243/16329 [01:56<2:09:10,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 5.59002. lr 5.999175e-04:   1%|▏         | 243/16329 [01:57<2:09:10,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 5.59002. lr 5.999175e-04:   1%|▏         | 244/16329 [01:57<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 5.64985. lr 5.999168e-04:   1%|▏         | 244/16329 [01:57<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 5.64985. lr 5.999168e-04:   2%|▏         | 245/16329 [01:57<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 5.62524. lr 5.999161e-04:   2%|▏         | 245/16329 [01:58<2:09:07,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 5.62524. lr 5.999161e-04:   2%|▏         | 246/16329 [01:58<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 5.67288. lr 5.999154e-04:   2%|▏         | 246/16329 [01:58<2:09:05,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 5.67288. lr 5.999154e-04:   2%|▏         | 247/16329 [01:58<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 5.58337. lr 5.999147e-04:   2%|▏         | 247/16329 [01:59<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 5.58337. lr 5.999147e-04:   2%|▏         | 248/16329 [01:59<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 5.59031. lr 5.999140e-04:   2%|▏         | 248/16329 [01:59<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 5.59031. lr 5.999140e-04:   2%|▏         | 249/16329 [01:59<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 5.60929. lr 5.999134e-04:   2%|▏         | 249/16329 [02:00<2:09:06,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 5.60929. lr 5.999134e-04:   2%|▏         | 250/16329 [02:00<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 5.62594. lr 5.999127e-04:   2%|▏         | 250/16329 [02:00<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 5.62594. lr 5.999127e-04:   2%|▏         | 251/16329 [02:00<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 5.59418. lr 5.999120e-04:   2%|▏         | 251/16329 [02:01<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 5.59418. lr 5.999120e-04:   2%|▏         | 252/16329 [02:01<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 5.54720. lr 5.999113e-04:   2%|▏         | 252/16329 [02:01<2:09:02,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 5.54720. lr 5.999113e-04:   2%|▏         | 253/16329 [02:01<2:09:10,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 5.61099. lr 5.999106e-04:   2%|▏         | 253/16329 [02:02<2:09:10,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 5.61099. lr 5.999106e-04:   2%|▏         | 254/16329 [02:02<2:09:07,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 5.53531. lr 5.999098e-04:   2%|▏         | 254/16329 [02:02<2:09:07,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 5.53531. lr 5.999098e-04:   2%|▏         | 255/16329 [02:02<2:09:08,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 5.57890. lr 5.999091e-04:   2%|▏         | 255/16329 [02:03<2:09:08,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 5.57890. lr 5.999091e-04:   2%|▏         | 256/16329 [02:03<2:09:01,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 5.58159. lr 5.999084e-04:   2%|▏         | 256/16329 [02:03<2:09:01,  2.08it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 5.58159. lr 5.999084e-04:   2%|▏         | 257/16329 [02:03<2:09:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 5.56447. lr 5.999077e-04:   2%|▏         | 257/16329 [02:04<2:09:18,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 5.56447. lr 5.999077e-04:   2%|▏         | 258/16329 [02:04<2:09:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 5.55271. lr 5.999070e-04:   2%|▏         | 258/16329 [02:04<2:09:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 5.55271. lr 5.999070e-04:   2%|▏         | 259/16329 [02:04<2:09:14,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 5.54803. lr 5.999063e-04:   2%|▏         | 259/16329 [02:05<2:09:14,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 5.54803. lr 5.999063e-04:   2%|▏         | 260/16329 [02:05<2:09:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 5.58384. lr 5.999056e-04:   2%|▏         | 260/16329 [02:05<2:09:20,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 5.58384. lr 5.999056e-04:   2%|▏         | 261/16329 [02:05<2:09:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 5.52097. lr 5.999048e-04:   2%|▏         | 261/16329 [02:06<2:09:17,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 5.52097. lr 5.999048e-04:   2%|▏         | 262/16329 [02:06<2:09:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 262: train loss 5.51924. lr 5.999041e-04:   2%|▏         | 262/16329 [02:06<2:09:16,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 262: train loss 5.51924. lr 5.999041e-04:   2%|▏         | 263/16329 [02:06<2:09:15,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 5.53228. lr 5.999034e-04:   2%|▏         | 263/16329 [02:07<2:09:15,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 5.53228. lr 5.999034e-04:   2%|▏         | 264/16329 [02:07<2:09:11,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 5.45309. lr 5.999026e-04:   2%|▏         | 264/16329 [02:07<2:09:11,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 5.45309. lr 5.999026e-04:   2%|▏         | 265/16329 [02:07<2:09:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 5.56722. lr 5.999019e-04:   2%|▏         | 265/16329 [02:08<2:09:13,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 5.56722. lr 5.999019e-04:   2%|▏         | 266/16329 [02:08<2:09:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 5.55085. lr 5.999012e-04:   2%|▏         | 266/16329 [02:08<2:09:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 5.55085. lr 5.999012e-04:   2%|▏         | 267/16329 [02:08<2:09:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 5.54921. lr 5.999004e-04:   2%|▏         | 267/16329 [02:09<2:09:19,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 5.54921. lr 5.999004e-04:   2%|▏         | 268/16329 [02:09<2:09:38,  2.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 268: train loss 5.59180. lr 5.998997e-04:   2%|▏         | 268/16329 [02:09<2:09:38,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 5.59180. lr 5.998997e-04:   2%|▏         | 269/16329 [02:09<2:10:13,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 5.60404. lr 5.998989e-04:   2%|▏         | 269/16329 [02:09<2:10:13,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 5.60404. lr 5.998989e-04:   2%|▏         | 270/16329 [02:09<2:09:58,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 5.57377. lr 5.998982e-04:   2%|▏         | 270/16329 [02:10<2:09:58,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 5.57377. lr 5.998982e-04:   2%|▏         | 271/16329 [02:10<2:09:52,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 5.52320. lr 5.998974e-04:   2%|▏         | 271/16329 [02:10<2:09:52,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 5.52320. lr 5.998974e-04:   2%|▏         | 272/16329 [02:10<2:09:40,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 5.50254. lr 5.998967e-04:   2%|▏         | 272/16329 [02:11<2:09:40,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 5.50254. lr 5.998967e-04:   2%|▏         | 273/16329 [02:11<2:09:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 5.53985. lr 5.998959e-04:   2%|▏         | 273/16329 [02:11<2:09:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 5.53985. lr 5.998959e-04:   2%|▏         | 274/16329 [02:11<2:09:50,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 5.52299. lr 5.998951e-04:   2%|▏         | 274/16329 [02:12<2:09:50,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 5.52299. lr 5.998951e-04:   2%|▏         | 275/16329 [02:12<2:09:35,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 5.48844. lr 5.998944e-04:   2%|▏         | 275/16329 [02:12<2:09:35,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 5.48844. lr 5.998944e-04:   2%|▏         | 276/16329 [02:12<2:09:49,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 5.54095. lr 5.998936e-04:   2%|▏         | 276/16329 [02:13<2:09:49,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 5.54095. lr 5.998936e-04:   2%|▏         | 277/16329 [02:13<2:09:47,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 5.51223. lr 5.998928e-04:   2%|▏         | 277/16329 [02:13<2:09:47,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 5.51223. lr 5.998928e-04:   2%|▏         | 278/16329 [02:13<2:09:41,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 5.53957. lr 5.998921e-04:   2%|▏         | 278/16329 [02:14<2:09:41,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 5.53957. lr 5.998921e-04:   2%|▏         | 279/16329 [02:14<2:09:51,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 5.53702. lr 5.998913e-04:   2%|▏         | 279/16329 [02:14<2:09:51,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 5.53702. lr 5.998913e-04:   2%|▏         | 280/16329 [02:14<2:09:33,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 5.51474. lr 5.998905e-04:   2%|▏         | 280/16329 [02:15<2:09:33,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 5.51474. lr 5.998905e-04:   2%|▏         | 281/16329 [02:15<2:09:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 5.45292. lr 5.998897e-04:   2%|▏         | 281/16329 [02:15<2:09:22,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 5.45292. lr 5.998897e-04:   2%|▏         | 282/16329 [02:15<2:09:33,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 5.41325. lr 5.998890e-04:   2%|▏         | 282/16329 [02:16<2:09:33,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 5.41325. lr 5.998890e-04:   2%|▏         | 283/16329 [02:16<2:09:26,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 5.45695. lr 5.998882e-04:   2%|▏         | 283/16329 [02:16<2:09:26,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 5.45695. lr 5.998882e-04:   2%|▏         | 284/16329 [02:16<2:09:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 5.48834. lr 5.998874e-04:   2%|▏         | 284/16329 [02:17<2:09:23,  2.07it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 5.48834. lr 5.998874e-04:   2%|▏         | 285/16329 [02:17<2:09:52,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 5.45644. lr 5.998866e-04:   2%|▏         | 285/16329 [02:17<2:09:52,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 5.45644. lr 5.998866e-04:   2%|▏         | 286/16329 [02:17<2:09:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 5.41477. lr 5.998858e-04:   2%|▏         | 286/16329 [02:18<2:09:43,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 5.41477. lr 5.998858e-04:   2%|▏         | 287/16329 [02:18<2:09:45,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 5.50728. lr 5.998850e-04:   2%|▏         | 287/16329 [02:18<2:09:45,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 5.50728. lr 5.998850e-04:   2%|▏         | 288/16329 [02:18<2:10:23,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 5.40949. lr 5.998842e-04:   2%|▏         | 288/16329 [02:19<2:10:23,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 5.40949. lr 5.998842e-04:   2%|▏         | 289/16329 [02:19<2:10:00,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 5.43862. lr 5.998834e-04:   2%|▏         | 289/16329 [02:19<2:10:00,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 5.43862. lr 5.998834e-04:   2%|▏         | 290/16329 [02:19<2:10:16,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 5.45102. lr 5.998826e-04:   2%|▏         | 290/16329 [02:20<2:10:16,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 5.45102. lr 5.998826e-04:   2%|▏         | 291/16329 [02:20<2:10:14,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 5.51163. lr 5.998818e-04:   2%|▏         | 291/16329 [02:20<2:10:14,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 5.51163. lr 5.998818e-04:   2%|▏         | 292/16329 [02:20<2:10:15,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 5.48493. lr 5.998810e-04:   2%|▏         | 292/16329 [02:21<2:10:15,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 5.48493. lr 5.998810e-04:   2%|▏         | 293/16329 [02:21<2:10:28,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 5.40624. lr 5.998801e-04:   2%|▏         | 293/16329 [02:21<2:10:28,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 5.40624. lr 5.998801e-04:   2%|▏         | 294/16329 [02:21<2:10:20,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 5.44828. lr 5.998793e-04:   2%|▏         | 294/16329 [02:22<2:10:20,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 5.44828. lr 5.998793e-04:   2%|▏         | 295/16329 [02:22<2:10:32,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 5.44625. lr 5.998785e-04:   2%|▏         | 295/16329 [02:22<2:10:32,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 5.44625. lr 5.998785e-04:   2%|▏         | 296/16329 [02:22<2:10:16,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 5.49262. lr 5.998777e-04:   2%|▏         | 296/16329 [02:23<2:10:16,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 5.49262. lr 5.998777e-04:   2%|▏         | 297/16329 [02:23<2:09:57,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 5.45164. lr 5.998769e-04:   2%|▏         | 297/16329 [02:23<2:09:57,  2.06it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 5.45164. lr 5.998769e-04:   2%|▏         | 298/16329 [02:23<2:10:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 5.50583. lr 5.998760e-04:   2%|▏         | 298/16329 [02:24<2:10:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 5.50583. lr 5.998760e-04:   2%|▏         | 299/16329 [02:24<2:10:12,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 5.44837. lr 5.998752e-04:   2%|▏         | 299/16329 [02:24<2:10:12,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 5.44837. lr 5.998752e-04:   2%|▏         | 300/16329 [02:24<2:10:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 300: train loss 5.47242. lr 5.998744e-04:   2%|▏         | 300/16329 [02:25<2:10:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 300: train loss 5.47242. lr 5.998744e-04:   2%|▏         | 301/16329 [02:25<2:10:26,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 5.46827. lr 5.998735e-04:   2%|▏         | 301/16329 [02:25<2:10:26,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 5.46827. lr 5.998735e-04:   2%|▏         | 302/16329 [02:25<2:10:37,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 5.42010. lr 5.998727e-04:   2%|▏         | 302/16329 [02:26<2:10:37,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 5.42010. lr 5.998727e-04:   2%|▏         | 303/16329 [02:26<2:10:46,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 5.42053. lr 5.998718e-04:   2%|▏         | 303/16329 [02:26<2:10:46,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 5.42053. lr 5.998718e-04:   2%|▏         | 304/16329 [02:26<2:10:27,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 5.37448. lr 5.998710e-04:   2%|▏         | 304/16329 [02:27<2:10:27,  2.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 304: train loss 5.37448. lr 5.998710e-04:   2%|▏         | 305/16329 [02:27<2:10:27,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 5.38482. lr 5.998702e-04:   2%|▏         | 305/16329 [02:27<2:10:27,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 5.38482. lr 5.998702e-04:   2%|▏         | 306/16329 [02:27<2:10:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 5.36579. lr 5.998693e-04:   2%|▏         | 306/16329 [02:28<2:10:22,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 5.36579. lr 5.998693e-04:   2%|▏         | 307/16329 [02:28<2:10:26,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 5.38004. lr 5.998685e-04:   2%|▏         | 307/16329 [02:28<2:10:26,  2.05it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 5.38004. lr 5.998685e-04:   2%|▏         | 308/16329 [02:28<2:10:57,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 5.42412. lr 5.998676e-04:   2%|▏         | 308/16329 [02:28<2:10:57,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 5.42412. lr 5.998676e-04:   2%|▏         | 309/16329 [02:28<2:10:54,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 5.32787. lr 5.998667e-04:   2%|▏         | 309/16329 [02:29<2:10:54,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 5.32787. lr 5.998667e-04:   2%|▏         | 310/16329 [02:29<2:10:36,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 5.45283. lr 5.998659e-04:   2%|▏         | 310/16329 [02:29<2:10:36,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 5.45283. lr 5.998659e-04:   2%|▏         | 311/16329 [02:29<2:11:09,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 5.42032. lr 5.998650e-04:   2%|▏         | 311/16329 [02:30<2:11:09,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 5.42032. lr 5.998650e-04:   2%|▏         | 312/16329 [02:30<2:11:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 5.34950. lr 5.998641e-04:   2%|▏         | 312/16329 [02:30<2:11:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 5.34950. lr 5.998641e-04:   2%|▏         | 313/16329 [02:30<2:11:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 5.35041. lr 5.998633e-04:   2%|▏         | 313/16329 [02:31<2:11:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 5.35041. lr 5.998633e-04:   2%|▏         | 314/16329 [02:31<2:11:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 5.34333. lr 5.998624e-04:   2%|▏         | 314/16329 [02:31<2:11:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 5.34333. lr 5.998624e-04:   2%|▏         | 315/16329 [02:31<2:10:57,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 5.38357. lr 5.998615e-04:   2%|▏         | 315/16329 [02:32<2:10:57,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 5.38357. lr 5.998615e-04:   2%|▏         | 316/16329 [02:32<2:11:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 316: train loss 5.31147. lr 5.998606e-04:   2%|▏         | 316/16329 [02:32<2:11:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 316: train loss 5.31147. lr 5.998606e-04:   2%|▏         | 317/16329 [02:32<2:11:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 317: train loss 5.37110. lr 5.998598e-04:   2%|▏         | 317/16329 [02:33<2:11:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 317: train loss 5.37110. lr 5.998598e-04:   2%|▏         | 318/16329 [02:33<2:11:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 318: train loss 5.41724. lr 5.998589e-04:   2%|▏         | 318/16329 [02:33<2:11:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 318: train loss 5.41724. lr 5.998589e-04:   2%|▏         | 319/16329 [02:33<2:11:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 319: train loss 5.32503. lr 5.998580e-04:   2%|▏         | 319/16329 [02:34<2:11:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 319: train loss 5.32503. lr 5.998580e-04:   2%|▏         | 320/16329 [02:34<2:11:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 320: train loss 5.36871. lr 5.998571e-04:   2%|▏         | 320/16329 [02:34<2:11:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 320: train loss 5.36871. lr 5.998571e-04:   2%|▏         | 321/16329 [02:34<2:11:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 321: train loss 5.36957. lr 5.998562e-04:   2%|▏         | 321/16329 [02:35<2:11:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 321: train loss 5.36957. lr 5.998562e-04:   2%|▏         | 322/16329 [02:35<2:12:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 322: train loss 5.32918. lr 5.998553e-04:   2%|▏         | 322/16329 [02:35<2:12:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 322: train loss 5.32918. lr 5.998553e-04:   2%|▏         | 323/16329 [02:35<2:12:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 323: train loss 5.42100. lr 5.998544e-04:   2%|▏         | 323/16329 [02:36<2:12:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 323: train loss 5.42100. lr 5.998544e-04:   2%|▏         | 324/16329 [02:36<2:40:18,  1.66it/s]\u001b[A\n",
      "epoch 1 iter 324: train loss 5.39245. lr 5.998535e-04:   2%|▏         | 324/16329 [02:37<2:40:18,  1.66it/s]\u001b[A\n",
      "epoch 1 iter 324: train loss 5.39245. lr 5.998535e-04:   2%|▏         | 325/16329 [02:37<2:31:38,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 325: train loss 5.33471. lr 5.998526e-04:   2%|▏         | 325/16329 [02:37<2:31:38,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 325: train loss 5.33471. lr 5.998526e-04:   2%|▏         | 326/16329 [02:37<2:25:53,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 326: train loss 5.33866. lr 5.998517e-04:   2%|▏         | 326/16329 [02:38<2:25:53,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 326: train loss 5.33866. lr 5.998517e-04:   2%|▏         | 327/16329 [02:38<2:21:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 327: train loss 5.28302. lr 5.998508e-04:   2%|▏         | 327/16329 [02:38<2:21:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 327: train loss 5.28302. lr 5.998508e-04:   2%|▏         | 328/16329 [02:38<2:18:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 328: train loss 5.36610. lr 5.998499e-04:   2%|▏         | 328/16329 [02:39<2:18:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 328: train loss 5.36610. lr 5.998499e-04:   2%|▏         | 329/16329 [02:39<2:16:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 329: train loss 5.38649. lr 5.998490e-04:   2%|▏         | 329/16329 [02:39<2:16:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 329: train loss 5.38649. lr 5.998490e-04:   2%|▏         | 330/16329 [02:39<2:14:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 330: train loss 5.31577. lr 5.998481e-04:   2%|▏         | 330/16329 [02:40<2:14:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 330: train loss 5.31577. lr 5.998481e-04:   2%|▏         | 331/16329 [02:40<2:14:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 331: train loss 5.35697. lr 5.998471e-04:   2%|▏         | 331/16329 [02:40<2:14:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 331: train loss 5.35697. lr 5.998471e-04:   2%|▏         | 332/16329 [02:40<2:13:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 332: train loss 5.30111. lr 5.998462e-04:   2%|▏         | 332/16329 [02:41<2:13:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 332: train loss 5.30111. lr 5.998462e-04:   2%|▏         | 333/16329 [02:41<2:13:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 333: train loss 5.38254. lr 5.998453e-04:   2%|▏         | 333/16329 [02:41<2:13:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 333: train loss 5.38254. lr 5.998453e-04:   2%|▏         | 334/16329 [02:41<2:12:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 334: train loss 5.35533. lr 5.998444e-04:   2%|▏         | 334/16329 [02:42<2:12:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 334: train loss 5.35533. lr 5.998444e-04:   2%|▏         | 335/16329 [02:42<2:12:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 335: train loss 5.31859. lr 5.998434e-04:   2%|▏         | 335/16329 [02:42<2:12:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 335: train loss 5.31859. lr 5.998434e-04:   2%|▏         | 336/16329 [02:42<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 336: train loss 5.34176. lr 5.998425e-04:   2%|▏         | 336/16329 [02:43<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 336: train loss 5.34176. lr 5.998425e-04:   2%|▏         | 337/16329 [02:43<2:14:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 337: train loss 5.32104. lr 5.998416e-04:   2%|▏         | 337/16329 [02:43<2:14:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 337: train loss 5.32104. lr 5.998416e-04:   2%|▏         | 338/16329 [02:43<2:15:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 338: train loss 5.33719. lr 5.998406e-04:   2%|▏         | 338/16329 [02:44<2:15:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 338: train loss 5.33719. lr 5.998406e-04:   2%|▏         | 339/16329 [02:44<2:15:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 339: train loss 5.27160. lr 5.998397e-04:   2%|▏         | 339/16329 [02:44<2:15:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 339: train loss 5.27160. lr 5.998397e-04:   2%|▏         | 340/16329 [02:44<2:15:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 340: train loss 5.34802. lr 5.998387e-04:   2%|▏         | 340/16329 [02:45<2:15:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 340: train loss 5.34802. lr 5.998387e-04:   2%|▏         | 341/16329 [02:45<2:14:56,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 341: train loss 5.31048. lr 5.998378e-04:   2%|▏         | 341/16329 [02:45<2:14:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 341: train loss 5.31048. lr 5.998378e-04:   2%|▏         | 342/16329 [02:45<2:14:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 342: train loss 5.35940. lr 5.998368e-04:   2%|▏         | 342/16329 [02:46<2:14:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 342: train loss 5.35940. lr 5.998368e-04:   2%|▏         | 343/16329 [02:46<2:13:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 343: train loss 5.24128. lr 5.998359e-04:   2%|▏         | 343/16329 [02:46<2:13:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 343: train loss 5.24128. lr 5.998359e-04:   2%|▏         | 344/16329 [02:46<2:13:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 344: train loss 5.36845. lr 5.998349e-04:   2%|▏         | 344/16329 [02:47<2:13:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 344: train loss 5.36845. lr 5.998349e-04:   2%|▏         | 345/16329 [02:47<2:13:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 345: train loss 5.26613. lr 5.998340e-04:   2%|▏         | 345/16329 [02:47<2:13:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 345: train loss 5.26613. lr 5.998340e-04:   2%|▏         | 346/16329 [02:47<2:13:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 346: train loss 5.24967. lr 5.998330e-04:   2%|▏         | 346/16329 [02:48<2:13:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 346: train loss 5.24967. lr 5.998330e-04:   2%|▏         | 347/16329 [02:48<2:13:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 347: train loss 5.35142. lr 5.998321e-04:   2%|▏         | 347/16329 [02:48<2:13:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 347: train loss 5.35142. lr 5.998321e-04:   2%|▏         | 348/16329 [02:48<2:12:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 348: train loss 5.19116. lr 5.998311e-04:   2%|▏         | 348/16329 [02:49<2:12:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 348: train loss 5.19116. lr 5.998311e-04:   2%|▏         | 349/16329 [02:49<2:26:45,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 349: train loss 5.25199. lr 5.998301e-04:   2%|▏         | 349/16329 [02:49<2:26:45,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 349: train loss 5.25199. lr 5.998301e-04:   2%|▏         | 350/16329 [02:49<2:22:20,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 350: train loss 5.25537. lr 5.998291e-04:   2%|▏         | 350/16329 [02:50<2:22:20,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 350: train loss 5.25537. lr 5.998291e-04:   2%|▏         | 351/16329 [02:50<2:18:55,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 351: train loss 5.24555. lr 5.998282e-04:   2%|▏         | 351/16329 [02:50<2:18:55,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 351: train loss 5.24555. lr 5.998282e-04:   2%|▏         | 352/16329 [02:50<2:16:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 352: train loss 5.28433. lr 5.998272e-04:   2%|▏         | 352/16329 [02:51<2:16:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 352: train loss 5.28433. lr 5.998272e-04:   2%|▏         | 353/16329 [02:51<2:15:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 353: train loss 5.25149. lr 5.998262e-04:   2%|▏         | 353/16329 [02:51<2:15:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 353: train loss 5.25149. lr 5.998262e-04:   2%|▏         | 354/16329 [02:51<2:14:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 354: train loss 5.21433. lr 5.998252e-04:   2%|▏         | 354/16329 [02:52<2:14:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 354: train loss 5.21433. lr 5.998252e-04:   2%|▏         | 355/16329 [02:52<2:13:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 355: train loss 5.23490. lr 5.998242e-04:   2%|▏         | 355/16329 [02:52<2:13:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 355: train loss 5.23490. lr 5.998242e-04:   2%|▏         | 356/16329 [02:52<2:13:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 356: train loss 5.22784. lr 5.998232e-04:   2%|▏         | 356/16329 [02:53<2:13:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 356: train loss 5.22784. lr 5.998232e-04:   2%|▏         | 357/16329 [02:53<2:13:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 357: train loss 5.23371. lr 5.998223e-04:   2%|▏         | 357/16329 [02:53<2:13:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 357: train loss 5.23371. lr 5.998223e-04:   2%|▏         | 358/16329 [02:53<2:12:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 358: train loss 5.18928. lr 5.998213e-04:   2%|▏         | 358/16329 [02:54<2:12:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 358: train loss 5.18928. lr 5.998213e-04:   2%|▏         | 359/16329 [02:54<2:12:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 359: train loss 5.26752. lr 5.998203e-04:   2%|▏         | 359/16329 [02:54<2:12:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 359: train loss 5.26752. lr 5.998203e-04:   2%|▏         | 360/16329 [02:54<2:12:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 360: train loss 5.28403. lr 5.998193e-04:   2%|▏         | 360/16329 [02:55<2:12:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 360: train loss 5.28403. lr 5.998193e-04:   2%|▏         | 361/16329 [02:55<2:12:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 361: train loss 5.25770. lr 5.998183e-04:   2%|▏         | 361/16329 [02:55<2:12:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 361: train loss 5.25770. lr 5.998183e-04:   2%|▏         | 362/16329 [02:55<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 362: train loss 5.20131. lr 5.998173e-04:   2%|▏         | 362/16329 [02:56<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 362: train loss 5.20131. lr 5.998173e-04:   2%|▏         | 363/16329 [02:56<2:12:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 363: train loss 5.19108. lr 5.998162e-04:   2%|▏         | 363/16329 [02:56<2:12:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 363: train loss 5.19108. lr 5.998162e-04:   2%|▏         | 364/16329 [02:56<2:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 364: train loss 5.24476. lr 5.998152e-04:   2%|▏         | 364/16329 [02:57<2:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 364: train loss 5.24476. lr 5.998152e-04:   2%|▏         | 365/16329 [02:57<2:11:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 365: train loss 5.18089. lr 5.998142e-04:   2%|▏         | 365/16329 [02:57<2:11:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 365: train loss 5.18089. lr 5.998142e-04:   2%|▏         | 366/16329 [02:57<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 366: train loss 5.27890. lr 5.998132e-04:   2%|▏         | 366/16329 [02:58<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 366: train loss 5.27890. lr 5.998132e-04:   2%|▏         | 367/16329 [02:58<2:14:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 367: train loss 5.19678. lr 5.998122e-04:   2%|▏         | 367/16329 [02:58<2:14:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 367: train loss 5.19678. lr 5.998122e-04:   2%|▏         | 368/16329 [02:58<2:16:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 368: train loss 5.22257. lr 5.998112e-04:   2%|▏         | 368/16329 [02:59<2:16:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 368: train loss 5.22257. lr 5.998112e-04:   2%|▏         | 369/16329 [02:59<2:16:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 369: train loss 5.17236. lr 5.998101e-04:   2%|▏         | 369/16329 [02:59<2:16:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 369: train loss 5.17236. lr 5.998101e-04:   2%|▏         | 370/16329 [02:59<2:16:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 370: train loss 5.19311. lr 5.998091e-04:   2%|▏         | 370/16329 [03:00<2:16:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 370: train loss 5.19311. lr 5.998091e-04:   2%|▏         | 371/16329 [03:00<2:16:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 371: train loss 5.18145. lr 5.998081e-04:   2%|▏         | 371/16329 [03:00<2:16:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 371: train loss 5.18145. lr 5.998081e-04:   2%|▏         | 372/16329 [03:00<2:15:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 372: train loss 5.29953. lr 5.998070e-04:   2%|▏         | 372/16329 [03:01<2:15:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 372: train loss 5.29953. lr 5.998070e-04:   2%|▏         | 373/16329 [03:01<2:15:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 373: train loss 5.20081. lr 5.998060e-04:   2%|▏         | 373/16329 [03:01<2:15:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 373: train loss 5.20081. lr 5.998060e-04:   2%|▏         | 374/16329 [03:01<2:14:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 374: train loss 5.17658. lr 5.998050e-04:   2%|▏         | 374/16329 [03:02<2:14:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 374: train loss 5.17658. lr 5.998050e-04:   2%|▏         | 375/16329 [03:02<2:14:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 375: train loss 5.20273. lr 5.998039e-04:   2%|▏         | 375/16329 [03:03<2:14:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 375: train loss 5.20273. lr 5.998039e-04:   2%|▏         | 376/16329 [03:03<2:30:01,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 376: train loss 5.20223. lr 5.998029e-04:   2%|▏         | 376/16329 [03:03<2:30:01,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 376: train loss 5.20223. lr 5.998029e-04:   2%|▏         | 377/16329 [03:03<2:24:08,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 377: train loss 5.19126. lr 5.998018e-04:   2%|▏         | 377/16329 [03:04<2:24:08,  1.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 377: train loss 5.19126. lr 5.998018e-04:   2%|▏         | 378/16329 [03:04<2:21:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 378: train loss 5.17157. lr 5.998008e-04:   2%|▏         | 378/16329 [03:04<2:21:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 378: train loss 5.17157. lr 5.998008e-04:   2%|▏         | 379/16329 [03:04<2:18:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 379: train loss 5.16210. lr 5.997997e-04:   2%|▏         | 379/16329 [03:05<2:18:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 379: train loss 5.16210. lr 5.997997e-04:   2%|▏         | 380/16329 [03:05<2:15:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 380: train loss 5.15891. lr 5.997987e-04:   2%|▏         | 380/16329 [03:05<2:15:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 380: train loss 5.15891. lr 5.997987e-04:   2%|▏         | 381/16329 [03:05<2:15:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 381: train loss 5.15637. lr 5.997976e-04:   2%|▏         | 381/16329 [03:06<2:15:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 381: train loss 5.15637. lr 5.997976e-04:   2%|▏         | 382/16329 [03:06<2:13:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 382: train loss 5.13708. lr 5.997966e-04:   2%|▏         | 382/16329 [03:06<2:13:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 382: train loss 5.13708. lr 5.997966e-04:   2%|▏         | 383/16329 [03:06<2:13:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 383: train loss 5.16222. lr 5.997955e-04:   2%|▏         | 383/16329 [03:07<2:13:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 383: train loss 5.16222. lr 5.997955e-04:   2%|▏         | 384/16329 [03:07<2:15:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 384: train loss 5.16705. lr 5.997944e-04:   2%|▏         | 384/16329 [03:07<2:15:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 384: train loss 5.16705. lr 5.997944e-04:   2%|▏         | 385/16329 [03:07<2:16:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 385: train loss 5.14436. lr 5.997934e-04:   2%|▏         | 385/16329 [03:08<2:16:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 385: train loss 5.14436. lr 5.997934e-04:   2%|▏         | 386/16329 [03:08<2:16:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 386: train loss 5.15310. lr 5.997923e-04:   2%|▏         | 386/16329 [03:08<2:16:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 386: train loss 5.15310. lr 5.997923e-04:   2%|▏         | 387/16329 [03:08<2:16:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 387: train loss 5.16315. lr 5.997912e-04:   2%|▏         | 387/16329 [03:09<2:16:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 387: train loss 5.16315. lr 5.997912e-04:   2%|▏         | 388/16329 [03:09<2:16:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 388: train loss 5.12364. lr 5.997901e-04:   2%|▏         | 388/16329 [03:09<2:16:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 388: train loss 5.12364. lr 5.997901e-04:   2%|▏         | 389/16329 [03:09<2:15:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 389: train loss 5.18646. lr 5.997890e-04:   2%|▏         | 389/16329 [03:10<2:15:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 389: train loss 5.18646. lr 5.997890e-04:   2%|▏         | 390/16329 [03:10<2:14:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 390: train loss 5.14743. lr 5.997880e-04:   2%|▏         | 390/16329 [03:10<2:14:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 390: train loss 5.14743. lr 5.997880e-04:   2%|▏         | 391/16329 [03:10<2:14:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 391: train loss 5.19861. lr 5.997869e-04:   2%|▏         | 391/16329 [03:11<2:14:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 391: train loss 5.19861. lr 5.997869e-04:   2%|▏         | 392/16329 [03:11<2:13:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 392: train loss 5.11254. lr 5.997858e-04:   2%|▏         | 392/16329 [03:11<2:13:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 392: train loss 5.11254. lr 5.997858e-04:   2%|▏         | 393/16329 [03:11<2:13:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 393: train loss 5.09763. lr 5.997847e-04:   2%|▏         | 393/16329 [03:12<2:13:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 393: train loss 5.09763. lr 5.997847e-04:   2%|▏         | 394/16329 [03:12<2:12:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 394: train loss 5.12993. lr 5.997836e-04:   2%|▏         | 394/16329 [03:12<2:12:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 394: train loss 5.12993. lr 5.997836e-04:   2%|▏         | 395/16329 [03:12<2:12:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 395: train loss 5.13259. lr 5.997825e-04:   2%|▏         | 395/16329 [03:13<2:12:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 395: train loss 5.13259. lr 5.997825e-04:   2%|▏         | 396/16329 [03:13<2:12:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 396: train loss 5.20924. lr 5.997814e-04:   2%|▏         | 396/16329 [03:13<2:12:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 396: train loss 5.20924. lr 5.997814e-04:   2%|▏         | 397/16329 [03:13<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 397: train loss 5.10630. lr 5.997803e-04:   2%|▏         | 397/16329 [03:14<2:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 397: train loss 5.10630. lr 5.997803e-04:   2%|▏         | 398/16329 [03:14<2:12:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 398: train loss 5.11999. lr 5.997792e-04:   2%|▏         | 398/16329 [03:14<2:12:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 398: train loss 5.11999. lr 5.997792e-04:   2%|▏         | 399/16329 [03:14<2:12:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 399: train loss 5.16650. lr 5.997781e-04:   2%|▏         | 399/16329 [03:15<2:12:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 399: train loss 5.16650. lr 5.997781e-04:   2%|▏         | 400/16329 [03:15<2:12:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 400: train loss 5.17499. lr 5.997770e-04:   2%|▏         | 400/16329 [03:15<2:12:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 400: train loss 5.17499. lr 5.997770e-04:   2%|▏         | 401/16329 [03:15<2:12:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 401: train loss 5.12308. lr 5.997759e-04:   2%|▏         | 401/16329 [03:16<2:12:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 401: train loss 5.12308. lr 5.997759e-04:   2%|▏         | 402/16329 [03:16<2:11:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 402: train loss 5.10197. lr 5.997747e-04:   2%|▏         | 402/16329 [03:16<2:11:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 402: train loss 5.10197. lr 5.997747e-04:   2%|▏         | 403/16329 [03:16<2:12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 403: train loss 5.08611. lr 5.997736e-04:   2%|▏         | 403/16329 [03:17<2:12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 403: train loss 5.08611. lr 5.997736e-04:   2%|▏         | 404/16329 [03:17<2:12:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 404: train loss 5.16273. lr 5.997725e-04:   2%|▏         | 404/16329 [03:17<2:12:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 404: train loss 5.16273. lr 5.997725e-04:   2%|▏         | 405/16329 [03:17<2:12:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 405: train loss 5.16332. lr 5.997714e-04:   2%|▏         | 405/16329 [03:18<2:12:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 405: train loss 5.16332. lr 5.997714e-04:   2%|▏         | 406/16329 [03:18<2:12:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 406: train loss 5.16270. lr 5.997703e-04:   2%|▏         | 406/16329 [03:18<2:12:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 406: train loss 5.16270. lr 5.997703e-04:   2%|▏         | 407/16329 [03:18<2:12:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 407: train loss 5.17044. lr 5.997691e-04:   2%|▏         | 407/16329 [03:19<2:12:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 407: train loss 5.17044. lr 5.997691e-04:   2%|▏         | 408/16329 [03:19<2:13:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 408: train loss 5.12931. lr 5.997680e-04:   2%|▏         | 408/16329 [03:19<2:13:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 408: train loss 5.12931. lr 5.997680e-04:   3%|▎         | 409/16329 [03:19<2:13:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 409: train loss 5.07172. lr 5.997669e-04:   3%|▎         | 409/16329 [03:20<2:13:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 409: train loss 5.07172. lr 5.997669e-04:   3%|▎         | 410/16329 [03:20<2:13:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 410: train loss 5.09626. lr 5.997657e-04:   3%|▎         | 410/16329 [03:20<2:13:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 410: train loss 5.09626. lr 5.997657e-04:   3%|▎         | 411/16329 [03:20<2:13:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 411: train loss 5.04837. lr 5.997646e-04:   3%|▎         | 411/16329 [03:21<2:13:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 411: train loss 5.04837. lr 5.997646e-04:   3%|▎         | 412/16329 [03:21<2:13:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 412: train loss 5.09035. lr 5.997634e-04:   3%|▎         | 412/16329 [03:21<2:13:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 412: train loss 5.09035. lr 5.997634e-04:   3%|▎         | 413/16329 [03:21<2:13:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 413: train loss 5.12600. lr 5.997623e-04:   3%|▎         | 413/16329 [03:22<2:13:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 413: train loss 5.12600. lr 5.997623e-04:   3%|▎         | 414/16329 [03:22<2:12:55,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 414: train loss 5.09645. lr 5.997611e-04:   3%|▎         | 414/16329 [03:22<2:12:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 414: train loss 5.09645. lr 5.997611e-04:   3%|▎         | 415/16329 [03:22<2:12:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 415: train loss 5.09217. lr 5.997600e-04:   3%|▎         | 415/16329 [03:23<2:12:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 415: train loss 5.09217. lr 5.997600e-04:   3%|▎         | 416/16329 [03:23<2:28:29,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 416: train loss 5.09752. lr 5.997588e-04:   3%|▎         | 416/16329 [03:23<2:28:29,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 416: train loss 5.09752. lr 5.997588e-04:   3%|▎         | 417/16329 [03:23<2:23:26,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 417: train loss 5.09515. lr 5.997577e-04:   3%|▎         | 417/16329 [03:24<2:23:26,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 417: train loss 5.09515. lr 5.997577e-04:   3%|▎         | 418/16329 [03:24<2:20:01,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 418: train loss 5.07115. lr 5.997565e-04:   3%|▎         | 418/16329 [03:24<2:20:01,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 418: train loss 5.07115. lr 5.997565e-04:   3%|▎         | 419/16329 [03:24<2:17:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 419: train loss 5.05910. lr 5.997553e-04:   3%|▎         | 419/16329 [03:25<2:17:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 419: train loss 5.05910. lr 5.997553e-04:   3%|▎         | 420/16329 [03:25<2:16:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 420: train loss 5.02527. lr 5.997542e-04:   3%|▎         | 420/16329 [03:25<2:16:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 420: train loss 5.02527. lr 5.997542e-04:   3%|▎         | 421/16329 [03:25<2:15:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 421: train loss 5.09387. lr 5.997530e-04:   3%|▎         | 421/16329 [03:26<2:15:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 421: train loss 5.09387. lr 5.997530e-04:   3%|▎         | 422/16329 [03:26<2:14:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 422: train loss 5.12537. lr 5.997518e-04:   3%|▎         | 422/16329 [03:26<2:14:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 422: train loss 5.12537. lr 5.997518e-04:   3%|▎         | 423/16329 [03:26<2:14:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 423: train loss 5.06321. lr 5.997507e-04:   3%|▎         | 423/16329 [03:27<2:14:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 423: train loss 5.06321. lr 5.997507e-04:   3%|▎         | 424/16329 [03:27<2:13:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 424: train loss 5.10761. lr 5.997495e-04:   3%|▎         | 424/16329 [03:27<2:13:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 424: train loss 5.10761. lr 5.997495e-04:   3%|▎         | 425/16329 [03:27<2:13:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 425: train loss 5.00576. lr 5.997483e-04:   3%|▎         | 425/16329 [03:28<2:13:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 425: train loss 5.00576. lr 5.997483e-04:   3%|▎         | 426/16329 [03:28<2:13:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 426: train loss 5.02492. lr 5.997471e-04:   3%|▎         | 426/16329 [03:28<2:13:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 426: train loss 5.02492. lr 5.997471e-04:   3%|▎         | 427/16329 [03:28<2:13:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 427: train loss 5.03855. lr 5.997459e-04:   3%|▎         | 427/16329 [03:29<2:13:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 427: train loss 5.03855. lr 5.997459e-04:   3%|▎         | 428/16329 [03:29<2:12:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 428: train loss 5.05809. lr 5.997447e-04:   3%|▎         | 428/16329 [03:29<2:12:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 428: train loss 5.05809. lr 5.997447e-04:   3%|▎         | 429/16329 [03:29<2:12:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 429: train loss 5.07243. lr 5.997435e-04:   3%|▎         | 429/16329 [03:30<2:12:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 429: train loss 5.07243. lr 5.997435e-04:   3%|▎         | 430/16329 [03:30<2:13:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 430: train loss 5.05653. lr 5.997424e-04:   3%|▎         | 430/16329 [03:30<2:13:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 430: train loss 5.05653. lr 5.997424e-04:   3%|▎         | 431/16329 [03:30<2:13:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 431: train loss 5.04908. lr 5.997412e-04:   3%|▎         | 431/16329 [03:31<2:13:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 431: train loss 5.04908. lr 5.997412e-04:   3%|▎         | 432/16329 [03:31<2:13:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 432: train loss 4.99548. lr 5.997400e-04:   3%|▎         | 432/16329 [03:31<2:13:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 432: train loss 4.99548. lr 5.997400e-04:   3%|▎         | 433/16329 [03:31<2:18:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 433: train loss 5.00751. lr 5.997388e-04:   3%|▎         | 433/16329 [03:32<2:18:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 433: train loss 5.00751. lr 5.997388e-04:   3%|▎         | 434/16329 [03:32<2:20:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 434: train loss 5.01961. lr 5.997375e-04:   3%|▎         | 434/16329 [03:33<2:20:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 434: train loss 5.01961. lr 5.997375e-04:   3%|▎         | 435/16329 [03:33<2:22:04,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 435: train loss 5.05098. lr 5.997363e-04:   3%|▎         | 435/16329 [03:33<2:22:04,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 435: train loss 5.05098. lr 5.997363e-04:   3%|▎         | 436/16329 [03:33<2:21:49,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 436: train loss 5.10125. lr 5.997351e-04:   3%|▎         | 436/16329 [03:34<2:21:49,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 436: train loss 5.10125. lr 5.997351e-04:   3%|▎         | 437/16329 [03:34<2:20:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 437: train loss 5.00544. lr 5.997339e-04:   3%|▎         | 437/16329 [03:34<2:20:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 437: train loss 5.00544. lr 5.997339e-04:   3%|▎         | 438/16329 [03:34<2:19:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 438: train loss 5.08069. lr 5.997327e-04:   3%|▎         | 438/16329 [03:35<2:19:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 438: train loss 5.08069. lr 5.997327e-04:   3%|▎         | 439/16329 [03:35<2:18:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 439: train loss 5.05106. lr 5.997315e-04:   3%|▎         | 439/16329 [03:35<2:18:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 439: train loss 5.05106. lr 5.997315e-04:   3%|▎         | 440/16329 [03:35<2:16:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 440: train loss 5.05493. lr 5.997303e-04:   3%|▎         | 440/16329 [03:36<2:16:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 440: train loss 5.05493. lr 5.997303e-04:   3%|▎         | 441/16329 [03:36<2:16:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 441: train loss 5.03827. lr 5.997290e-04:   3%|▎         | 441/16329 [03:36<2:16:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 441: train loss 5.03827. lr 5.997290e-04:   3%|▎         | 442/16329 [03:36<2:15:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 442: train loss 5.02256. lr 5.997278e-04:   3%|▎         | 442/16329 [03:37<2:15:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 442: train loss 5.02256. lr 5.997278e-04:   3%|▎         | 443/16329 [03:37<2:14:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 443: train loss 4.96518. lr 5.997266e-04:   3%|▎         | 443/16329 [03:37<2:14:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 443: train loss 4.96518. lr 5.997266e-04:   3%|▎         | 444/16329 [03:37<2:13:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 444: train loss 5.11085. lr 5.997253e-04:   3%|▎         | 444/16329 [03:38<2:13:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 444: train loss 5.11085. lr 5.997253e-04:   3%|▎         | 445/16329 [03:38<2:13:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 445: train loss 5.09313. lr 5.997241e-04:   3%|▎         | 445/16329 [03:38<2:13:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 445: train loss 5.09313. lr 5.997241e-04:   3%|▎         | 446/16329 [03:38<2:13:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 446: train loss 5.04265. lr 5.997229e-04:   3%|▎         | 446/16329 [03:39<2:13:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 446: train loss 5.04265. lr 5.997229e-04:   3%|▎         | 447/16329 [03:39<2:13:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 447: train loss 5.00022. lr 5.997216e-04:   3%|▎         | 447/16329 [03:39<2:13:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 447: train loss 5.00022. lr 5.997216e-04:   3%|▎         | 448/16329 [03:39<2:12:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 448: train loss 5.00848. lr 5.997204e-04:   3%|▎         | 448/16329 [03:40<2:12:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 448: train loss 5.00848. lr 5.997204e-04:   3%|▎         | 449/16329 [03:40<2:13:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 449: train loss 5.07863. lr 5.997191e-04:   3%|▎         | 449/16329 [03:40<2:13:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 449: train loss 5.07863. lr 5.997191e-04:   3%|▎         | 450/16329 [03:40<2:12:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 450: train loss 5.03757. lr 5.997179e-04:   3%|▎         | 450/16329 [03:41<2:12:33,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 450: train loss 5.03757. lr 5.997179e-04:   3%|▎         | 451/16329 [03:41<2:25:33,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 451: train loss 4.96721. lr 5.997166e-04:   3%|▎         | 451/16329 [03:41<2:25:33,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 451: train loss 4.96721. lr 5.997166e-04:   3%|▎         | 452/16329 [03:41<2:21:35,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 452: train loss 5.08537. lr 5.997154e-04:   3%|▎         | 452/16329 [03:42<2:21:35,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 452: train loss 5.08537. lr 5.997154e-04:   3%|▎         | 453/16329 [03:42<2:19:22,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 453: train loss 4.94469. lr 5.997141e-04:   3%|▎         | 453/16329 [03:42<2:19:22,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 453: train loss 4.94469. lr 5.997141e-04:   3%|▎         | 454/16329 [03:42<2:17:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 454: train loss 4.97389. lr 5.997129e-04:   3%|▎         | 454/16329 [03:43<2:17:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 454: train loss 4.97389. lr 5.997129e-04:   3%|▎         | 455/16329 [03:43<2:16:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 455: train loss 4.98880. lr 5.997116e-04:   3%|▎         | 455/16329 [03:43<2:16:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 455: train loss 4.98880. lr 5.997116e-04:   3%|▎         | 456/16329 [03:43<2:15:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 456: train loss 4.99609. lr 5.997103e-04:   3%|▎         | 456/16329 [03:44<2:15:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 456: train loss 4.99609. lr 5.997103e-04:   3%|▎         | 457/16329 [03:44<2:14:25,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 457: train loss 5.02140. lr 5.997091e-04:   3%|▎         | 457/16329 [03:44<2:14:25,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 457: train loss 5.02140. lr 5.997091e-04:   3%|▎         | 458/16329 [03:44<2:13:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 458: train loss 4.94240. lr 5.997078e-04:   3%|▎         | 458/16329 [03:45<2:13:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 458: train loss 4.94240. lr 5.997078e-04:   3%|▎         | 459/16329 [03:45<2:13:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 459: train loss 5.04124. lr 5.997065e-04:   3%|▎         | 459/16329 [03:45<2:13:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 459: train loss 5.04124. lr 5.997065e-04:   3%|▎         | 460/16329 [03:45<2:12:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 460: train loss 4.93667. lr 5.997052e-04:   3%|▎         | 460/16329 [03:46<2:12:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 460: train loss 4.93667. lr 5.997052e-04:   3%|▎         | 461/16329 [03:46<2:13:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 461: train loss 4.97723. lr 5.997039e-04:   3%|▎         | 461/16329 [03:46<2:13:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 461: train loss 4.97723. lr 5.997039e-04:   3%|▎         | 462/16329 [03:46<2:13:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 462: train loss 4.95810. lr 5.997027e-04:   3%|▎         | 462/16329 [03:47<2:13:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 462: train loss 4.95810. lr 5.997027e-04:   3%|▎         | 463/16329 [03:47<2:13:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 463: train loss 4.95903. lr 5.997014e-04:   3%|▎         | 463/16329 [03:47<2:13:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 463: train loss 4.95903. lr 5.997014e-04:   3%|▎         | 464/16329 [03:47<2:12:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 464: train loss 4.97794. lr 5.997001e-04:   3%|▎         | 464/16329 [03:48<2:12:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 464: train loss 4.97794. lr 5.997001e-04:   3%|▎         | 465/16329 [03:48<2:13:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 465: train loss 4.87317. lr 5.996988e-04:   3%|▎         | 465/16329 [03:48<2:13:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 465: train loss 4.87317. lr 5.996988e-04:   3%|▎         | 466/16329 [03:48<2:12:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 466: train loss 4.90492. lr 5.996975e-04:   3%|▎         | 466/16329 [03:49<2:12:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 466: train loss 4.90492. lr 5.996975e-04:   3%|▎         | 467/16329 [03:49<2:13:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 467: train loss 4.99154. lr 5.996962e-04:   3%|▎         | 467/16329 [03:49<2:13:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 467: train loss 4.99154. lr 5.996962e-04:   3%|▎         | 468/16329 [03:49<2:12:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 468: train loss 5.00855. lr 5.996949e-04:   3%|▎         | 468/16329 [03:50<2:12:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 468: train loss 5.00855. lr 5.996949e-04:   3%|▎         | 469/16329 [03:50<2:12:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 469: train loss 4.85681. lr 5.996936e-04:   3%|▎         | 469/16329 [03:50<2:12:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 469: train loss 4.85681. lr 5.996936e-04:   3%|▎         | 470/16329 [03:50<2:12:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 470: train loss 4.96752. lr 5.996923e-04:   3%|▎         | 470/16329 [03:51<2:12:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 470: train loss 4.96752. lr 5.996923e-04:   3%|▎         | 471/16329 [03:51<2:12:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 471: train loss 4.97604. lr 5.996910e-04:   3%|▎         | 471/16329 [03:51<2:12:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 471: train loss 4.97604. lr 5.996910e-04:   3%|▎         | 472/16329 [03:51<2:12:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 472: train loss 4.95412. lr 5.996897e-04:   3%|▎         | 472/16329 [03:52<2:12:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 472: train loss 4.95412. lr 5.996897e-04:   3%|▎         | 473/16329 [03:52<2:16:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 473: train loss 4.93353. lr 5.996884e-04:   3%|▎         | 473/16329 [03:52<2:16:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 473: train loss 4.93353. lr 5.996884e-04:   3%|▎         | 474/16329 [03:52<2:18:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 474: train loss 4.93491. lr 5.996870e-04:   3%|▎         | 474/16329 [03:53<2:18:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 474: train loss 4.93491. lr 5.996870e-04:   3%|▎         | 475/16329 [03:53<2:18:52,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 475: train loss 4.96690. lr 5.996857e-04:   3%|▎         | 475/16329 [03:54<2:18:52,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 475: train loss 4.96690. lr 5.996857e-04:   3%|▎         | 476/16329 [03:54<2:33:44,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 476: train loss 4.93812. lr 5.996844e-04:   3%|▎         | 476/16329 [03:54<2:33:44,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 476: train loss 4.93812. lr 5.996844e-04:   3%|▎         | 477/16329 [03:54<2:27:18,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 477: train loss 4.86662. lr 5.996831e-04:   3%|▎         | 477/16329 [03:55<2:27:18,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 477: train loss 4.86662. lr 5.996831e-04:   3%|▎         | 478/16329 [03:55<2:22:27,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 478: train loss 4.95115. lr 5.996818e-04:   3%|▎         | 478/16329 [03:55<2:22:27,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 478: train loss 4.95115. lr 5.996818e-04:   3%|▎         | 479/16329 [03:55<2:19:31,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 479: train loss 4.95649. lr 5.996804e-04:   3%|▎         | 479/16329 [03:56<2:19:31,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 479: train loss 4.95649. lr 5.996804e-04:   3%|▎         | 480/16329 [03:56<2:17:10,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 480: train loss 4.98106. lr 5.996791e-04:   3%|▎         | 480/16329 [03:56<2:17:10,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 480: train loss 4.98106. lr 5.996791e-04:   3%|▎         | 481/16329 [03:56<2:15:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 481: train loss 4.89871. lr 5.996778e-04:   3%|▎         | 481/16329 [03:57<2:15:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 481: train loss 4.89871. lr 5.996778e-04:   3%|▎         | 482/16329 [03:57<2:14:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 482: train loss 4.96594. lr 5.996764e-04:   3%|▎         | 482/16329 [03:57<2:14:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 482: train loss 4.96594. lr 5.996764e-04:   3%|▎         | 483/16329 [03:57<2:14:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 483: train loss 4.89412. lr 5.996751e-04:   3%|▎         | 483/16329 [03:58<2:14:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 483: train loss 4.89412. lr 5.996751e-04:   3%|▎         | 484/16329 [03:58<2:13:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 484: train loss 4.93215. lr 5.996737e-04:   3%|▎         | 484/16329 [03:58<2:13:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 484: train loss 4.93215. lr 5.996737e-04:   3%|▎         | 485/16329 [03:58<2:13:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 485: train loss 4.94983. lr 5.996724e-04:   3%|▎         | 485/16329 [03:59<2:13:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 485: train loss 4.94983. lr 5.996724e-04:   3%|▎         | 486/16329 [03:59<2:13:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 486: train loss 4.88622. lr 5.996710e-04:   3%|▎         | 486/16329 [03:59<2:13:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 486: train loss 4.88622. lr 5.996710e-04:   3%|▎         | 487/16329 [03:59<2:13:16,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 487: train loss 4.93057. lr 5.996697e-04:   3%|▎         | 487/16329 [04:00<2:13:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 487: train loss 4.93057. lr 5.996697e-04:   3%|▎         | 488/16329 [04:00<2:12:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 488: train loss 4.97426. lr 5.996683e-04:   3%|▎         | 488/16329 [04:00<2:12:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 488: train loss 4.97426. lr 5.996683e-04:   3%|▎         | 489/16329 [04:00<2:12:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 489: train loss 4.94429. lr 5.996670e-04:   3%|▎         | 489/16329 [04:01<2:12:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 489: train loss 4.94429. lr 5.996670e-04:   3%|▎         | 490/16329 [04:01<2:12:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 490: train loss 4.85322. lr 5.996656e-04:   3%|▎         | 490/16329 [04:01<2:12:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 490: train loss 4.85322. lr 5.996656e-04:   3%|▎         | 491/16329 [04:01<2:12:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 491: train loss 4.95849. lr 5.996642e-04:   3%|▎         | 491/16329 [04:02<2:12:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 491: train loss 4.95849. lr 5.996642e-04:   3%|▎         | 492/16329 [04:02<2:12:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 492: train loss 4.96714. lr 5.996629e-04:   3%|▎         | 492/16329 [04:02<2:12:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 492: train loss 4.96714. lr 5.996629e-04:   3%|▎         | 493/16329 [04:02<2:12:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 493: train loss 4.94378. lr 5.996615e-04:   3%|▎         | 493/16329 [04:03<2:12:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 493: train loss 4.94378. lr 5.996615e-04:   3%|▎         | 494/16329 [04:03<2:12:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 494: train loss 4.86860. lr 5.996601e-04:   3%|▎         | 494/16329 [04:03<2:12:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 494: train loss 4.86860. lr 5.996601e-04:   3%|▎         | 495/16329 [04:03<2:12:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 495: train loss 4.84660. lr 5.996588e-04:   3%|▎         | 495/16329 [04:04<2:12:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 495: train loss 4.84660. lr 5.996588e-04:   3%|▎         | 496/16329 [04:04<2:16:37,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 496: train loss 4.91986. lr 5.996574e-04:   3%|▎         | 496/16329 [04:04<2:16:37,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 496: train loss 4.91986. lr 5.996574e-04:   3%|▎         | 497/16329 [04:04<2:21:27,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 497: train loss 4.90326. lr 5.996560e-04:   3%|▎         | 497/16329 [04:05<2:21:27,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 497: train loss 4.90326. lr 5.996560e-04:   3%|▎         | 498/16329 [04:05<2:23:10,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 498: train loss 4.93196. lr 5.996546e-04:   3%|▎         | 498/16329 [04:05<2:23:10,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 498: train loss 4.93196. lr 5.996546e-04:   3%|▎         | 499/16329 [04:05<2:23:24,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 499: train loss 4.83096. lr 5.996532e-04:   3%|▎         | 499/16329 [04:06<2:23:24,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 499: train loss 4.83096. lr 5.996532e-04:   3%|▎         | 500/16329 [04:06<2:22:54,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 500: train loss 4.87832. lr 5.996518e-04:   3%|▎         | 500/16329 [04:07<2:22:54,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 500: train loss 4.87832. lr 5.996518e-04:   3%|▎         | 501/16329 [04:07<2:21:55,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 501: train loss 4.93333. lr 5.996505e-04:   3%|▎         | 501/16329 [04:07<2:21:55,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 501: train loss 4.93333. lr 5.996505e-04:   3%|▎         | 502/16329 [04:07<2:20:58,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 502: train loss 4.96451. lr 5.996491e-04:   3%|▎         | 502/16329 [04:08<2:20:58,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 502: train loss 4.96451. lr 5.996491e-04:   3%|▎         | 503/16329 [04:08<2:34:52,  1.70it/s]\u001b[A\n",
      "epoch 1 iter 503: train loss 4.86292. lr 5.996477e-04:   3%|▎         | 503/16329 [04:08<2:34:52,  1.70it/s]\u001b[A\n",
      "epoch 1 iter 503: train loss 4.86292. lr 5.996477e-04:   3%|▎         | 504/16329 [04:08<2:28:58,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 504: train loss 4.94967. lr 5.996463e-04:   3%|▎         | 504/16329 [04:09<2:28:58,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 504: train loss 4.94967. lr 5.996463e-04:   3%|▎         | 505/16329 [04:09<2:24:15,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 505: train loss 4.90151. lr 5.996449e-04:   3%|▎         | 505/16329 [04:09<2:24:15,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 505: train loss 4.90151. lr 5.996449e-04:   3%|▎         | 506/16329 [04:09<2:20:28,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 506: train loss 4.93444. lr 5.996435e-04:   3%|▎         | 506/16329 [04:10<2:20:28,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 506: train loss 4.93444. lr 5.996435e-04:   3%|▎         | 507/16329 [04:10<2:18:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 507: train loss 4.95876. lr 5.996420e-04:   3%|▎         | 507/16329 [04:10<2:18:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 507: train loss 4.95876. lr 5.996420e-04:   3%|▎         | 508/16329 [04:10<2:15:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 508: train loss 4.88067. lr 5.996406e-04:   3%|▎         | 508/16329 [04:11<2:15:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 508: train loss 4.88067. lr 5.996406e-04:   3%|▎         | 509/16329 [04:11<2:14:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 509: train loss 4.94500. lr 5.996392e-04:   3%|▎         | 509/16329 [04:11<2:14:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 509: train loss 4.94500. lr 5.996392e-04:   3%|▎         | 510/16329 [04:11<2:14:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 510: train loss 4.84859. lr 5.996378e-04:   3%|▎         | 510/16329 [04:12<2:14:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 510: train loss 4.84859. lr 5.996378e-04:   3%|▎         | 511/16329 [04:12<2:13:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 511: train loss 4.89380. lr 5.996364e-04:   3%|▎         | 511/16329 [04:12<2:13:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 511: train loss 4.89380. lr 5.996364e-04:   3%|▎         | 512/16329 [04:12<2:13:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 512: train loss 4.96511. lr 5.996350e-04:   3%|▎         | 512/16329 [04:13<2:13:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 512: train loss 4.96511. lr 5.996350e-04:   3%|▎         | 513/16329 [04:13<2:12:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 513: train loss 4.82030. lr 5.996335e-04:   3%|▎         | 513/16329 [04:13<2:12:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 513: train loss 4.82030. lr 5.996335e-04:   3%|▎         | 514/16329 [04:13<2:12:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 514: train loss 4.85584. lr 5.996321e-04:   3%|▎         | 514/16329 [04:14<2:12:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 514: train loss 4.85584. lr 5.996321e-04:   3%|▎         | 515/16329 [04:14<2:12:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 515: train loss 4.90925. lr 5.996307e-04:   3%|▎         | 515/16329 [04:14<2:12:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 515: train loss 4.90925. lr 5.996307e-04:   3%|▎         | 516/16329 [04:14<2:12:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 516: train loss 4.86234. lr 5.996293e-04:   3%|▎         | 516/16329 [04:15<2:12:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 516: train loss 4.86234. lr 5.996293e-04:   3%|▎         | 517/16329 [04:15<2:12:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 517: train loss 4.87677. lr 5.996278e-04:   3%|▎         | 517/16329 [04:15<2:12:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 517: train loss 4.87677. lr 5.996278e-04:   3%|▎         | 518/16329 [04:15<2:12:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 518: train loss 4.83973. lr 5.996264e-04:   3%|▎         | 518/16329 [04:16<2:12:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 518: train loss 4.83973. lr 5.996264e-04:   3%|▎         | 519/16329 [04:16<2:12:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 519: train loss 4.84864. lr 5.996249e-04:   3%|▎         | 519/16329 [04:16<2:12:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 519: train loss 4.84864. lr 5.996249e-04:   3%|▎         | 520/16329 [04:16<2:12:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 520: train loss 4.91317. lr 5.996235e-04:   3%|▎         | 520/16329 [04:17<2:12:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 520: train loss 4.91317. lr 5.996235e-04:   3%|▎         | 521/16329 [04:17<2:13:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 521: train loss 4.82543. lr 5.996220e-04:   3%|▎         | 521/16329 [04:17<2:13:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 521: train loss 4.82543. lr 5.996220e-04:   3%|▎         | 522/16329 [04:17<2:13:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 522: train loss 4.92319. lr 5.996206e-04:   3%|▎         | 522/16329 [04:18<2:13:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 522: train loss 4.92319. lr 5.996206e-04:   3%|▎         | 523/16329 [04:18<2:13:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 523: train loss 4.85761. lr 5.996191e-04:   3%|▎         | 523/16329 [04:18<2:13:35,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 523: train loss 4.85761. lr 5.996191e-04:   3%|▎         | 524/16329 [04:18<2:13:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 524: train loss 4.83223. lr 5.996177e-04:   3%|▎         | 524/16329 [04:19<2:13:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 524: train loss 4.83223. lr 5.996177e-04:   3%|▎         | 525/16329 [04:19<2:13:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 525: train loss 4.84499. lr 5.996162e-04:   3%|▎         | 525/16329 [04:19<2:13:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 525: train loss 4.84499. lr 5.996162e-04:   3%|▎         | 526/16329 [04:19<2:12:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 526: train loss 4.79301. lr 5.996148e-04:   3%|▎         | 526/16329 [04:20<2:12:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 526: train loss 4.79301. lr 5.996148e-04:   3%|▎         | 527/16329 [04:20<2:12:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 527: train loss 4.84564. lr 5.996133e-04:   3%|▎         | 527/16329 [04:20<2:12:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 527: train loss 4.84564. lr 5.996133e-04:   3%|▎         | 528/16329 [04:20<2:12:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 528: train loss 4.85292. lr 5.996118e-04:   3%|▎         | 528/16329 [04:21<2:12:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 528: train loss 4.85292. lr 5.996118e-04:   3%|▎         | 529/16329 [04:21<2:12:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 529: train loss 4.89464. lr 5.996104e-04:   3%|▎         | 529/16329 [04:21<2:12:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 529: train loss 4.89464. lr 5.996104e-04:   3%|▎         | 530/16329 [04:21<2:12:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 530: train loss 4.86534. lr 5.996089e-04:   3%|▎         | 530/16329 [04:22<2:12:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 530: train loss 4.86534. lr 5.996089e-04:   3%|▎         | 531/16329 [04:22<2:12:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 531: train loss 4.88414. lr 5.996074e-04:   3%|▎         | 531/16329 [04:22<2:12:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 531: train loss 4.88414. lr 5.996074e-04:   3%|▎         | 532/16329 [04:22<2:12:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 532: train loss 4.80774. lr 5.996059e-04:   3%|▎         | 532/16329 [04:23<2:12:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 532: train loss 4.80774. lr 5.996059e-04:   3%|▎         | 533/16329 [04:23<2:12:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 533: train loss 4.89604. lr 5.996045e-04:   3%|▎         | 533/16329 [04:23<2:12:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 533: train loss 4.89604. lr 5.996045e-04:   3%|▎         | 534/16329 [04:23<2:11:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 534: train loss 4.89881. lr 5.996030e-04:   3%|▎         | 534/16329 [04:24<2:11:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 534: train loss 4.89881. lr 5.996030e-04:   3%|▎         | 535/16329 [04:24<2:11:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 535: train loss 4.86933. lr 5.996015e-04:   3%|▎         | 535/16329 [04:24<2:11:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 535: train loss 4.86933. lr 5.996015e-04:   3%|▎         | 536/16329 [04:24<2:11:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 536: train loss 4.83420. lr 5.996000e-04:   3%|▎         | 536/16329 [04:25<2:11:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 536: train loss 4.83420. lr 5.996000e-04:   3%|▎         | 537/16329 [04:25<2:11:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 537: train loss 4.78513. lr 5.995985e-04:   3%|▎         | 537/16329 [04:25<2:11:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 537: train loss 4.78513. lr 5.995985e-04:   3%|▎         | 538/16329 [04:25<2:11:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 538: train loss 4.77242. lr 5.995970e-04:   3%|▎         | 538/16329 [04:26<2:11:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 538: train loss 4.77242. lr 5.995970e-04:   3%|▎         | 539/16329 [04:26<2:11:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 539: train loss 4.85290. lr 5.995955e-04:   3%|▎         | 539/16329 [04:26<2:11:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 539: train loss 4.85290. lr 5.995955e-04:   3%|▎         | 540/16329 [04:26<2:11:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 540: train loss 4.87471. lr 5.995940e-04:   3%|▎         | 540/16329 [04:27<2:11:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 540: train loss 4.87471. lr 5.995940e-04:   3%|▎         | 541/16329 [04:27<2:11:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 541: train loss 4.87712. lr 5.995925e-04:   3%|▎         | 541/16329 [04:27<2:11:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 541: train loss 4.87712. lr 5.995925e-04:   3%|▎         | 542/16329 [04:27<2:12:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 542: train loss 4.81874. lr 5.995910e-04:   3%|▎         | 542/16329 [04:28<2:12:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 542: train loss 4.81874. lr 5.995910e-04:   3%|▎         | 543/16329 [04:28<2:28:09,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 543: train loss 4.80337. lr 5.995895e-04:   3%|▎         | 543/16329 [04:29<2:28:09,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 543: train loss 4.80337. lr 5.995895e-04:   3%|▎         | 544/16329 [04:29<2:23:09,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 544: train loss 4.75474. lr 5.995880e-04:   3%|▎         | 544/16329 [04:29<2:23:09,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 544: train loss 4.75474. lr 5.995880e-04:   3%|▎         | 545/16329 [04:29<2:19:47,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 545: train loss 4.82011. lr 5.995865e-04:   3%|▎         | 545/16329 [04:30<2:19:47,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 545: train loss 4.82011. lr 5.995865e-04:   3%|▎         | 546/16329 [04:30<2:17:28,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 546: train loss 4.78705. lr 5.995850e-04:   3%|▎         | 546/16329 [04:30<2:17:28,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 546: train loss 4.78705. lr 5.995850e-04:   3%|▎         | 547/16329 [04:30<2:16:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 547: train loss 4.80898. lr 5.995835e-04:   3%|▎         | 547/16329 [04:31<2:16:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 547: train loss 4.80898. lr 5.995835e-04:   3%|▎         | 548/16329 [04:31<2:20:30,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 548: train loss 4.80635. lr 5.995819e-04:   3%|▎         | 548/16329 [04:31<2:20:30,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 548: train loss 4.80635. lr 5.995819e-04:   3%|▎         | 549/16329 [04:31<2:21:58,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 549: train loss 4.84266. lr 5.995804e-04:   3%|▎         | 549/16329 [04:32<2:21:58,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 549: train loss 4.84266. lr 5.995804e-04:   3%|▎         | 550/16329 [04:32<2:22:06,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 550: train loss 4.81702. lr 5.995789e-04:   3%|▎         | 550/16329 [04:32<2:22:06,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 550: train loss 4.81702. lr 5.995789e-04:   3%|▎         | 551/16329 [04:32<2:21:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 551: train loss 4.85215. lr 5.995773e-04:   3%|▎         | 551/16329 [04:33<2:21:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 551: train loss 4.85215. lr 5.995773e-04:   3%|▎         | 552/16329 [04:33<2:21:00,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 552: train loss 4.77493. lr 5.995758e-04:   3%|▎         | 552/16329 [04:33<2:21:00,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 552: train loss 4.77493. lr 5.995758e-04:   3%|▎         | 553/16329 [04:33<2:19:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 553: train loss 4.85173. lr 5.995743e-04:   3%|▎         | 553/16329 [04:34<2:19:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 553: train loss 4.85173. lr 5.995743e-04:   3%|▎         | 554/16329 [04:34<2:17:28,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 554: train loss 4.81283. lr 5.995727e-04:   3%|▎         | 554/16329 [04:34<2:17:28,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 554: train loss 4.81283. lr 5.995727e-04:   3%|▎         | 555/16329 [04:34<2:16:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 555: train loss 4.79190. lr 5.995712e-04:   3%|▎         | 555/16329 [04:35<2:16:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 555: train loss 4.79190. lr 5.995712e-04:   3%|▎         | 556/16329 [04:35<2:15:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 556: train loss 4.80752. lr 5.995697e-04:   3%|▎         | 556/16329 [04:35<2:15:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 556: train loss 4.80752. lr 5.995697e-04:   3%|▎         | 557/16329 [04:35<2:14:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 557: train loss 4.80310. lr 5.995681e-04:   3%|▎         | 557/16329 [04:36<2:14:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 557: train loss 4.80310. lr 5.995681e-04:   3%|▎         | 558/16329 [04:36<2:13:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 558: train loss 4.80026. lr 5.995666e-04:   3%|▎         | 558/16329 [04:36<2:13:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 558: train loss 4.80026. lr 5.995666e-04:   3%|▎         | 559/16329 [04:36<2:13:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 559: train loss 4.83080. lr 5.995650e-04:   3%|▎         | 559/16329 [04:37<2:13:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 559: train loss 4.83080. lr 5.995650e-04:   3%|▎         | 560/16329 [04:37<2:13:11,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 560: train loss 4.74763. lr 5.995635e-04:   3%|▎         | 560/16329 [04:37<2:13:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 560: train loss 4.74763. lr 5.995635e-04:   3%|▎         | 561/16329 [04:37<2:12:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 561: train loss 4.82786. lr 5.995619e-04:   3%|▎         | 561/16329 [04:38<2:12:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 561: train loss 4.82786. lr 5.995619e-04:   3%|▎         | 562/16329 [04:38<2:12:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 562: train loss 4.81648. lr 5.995603e-04:   3%|▎         | 562/16329 [04:38<2:12:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 562: train loss 4.81648. lr 5.995603e-04:   3%|▎         | 563/16329 [04:38<2:12:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 563: train loss 4.75342. lr 5.995588e-04:   3%|▎         | 563/16329 [04:39<2:12:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 563: train loss 4.75342. lr 5.995588e-04:   3%|▎         | 564/16329 [04:39<2:12:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 564: train loss 4.83799. lr 5.995572e-04:   3%|▎         | 564/16329 [04:39<2:12:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 564: train loss 4.83799. lr 5.995572e-04:   3%|▎         | 565/16329 [04:39<2:11:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 565: train loss 4.78297. lr 5.995556e-04:   3%|▎         | 565/16329 [04:40<2:11:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 565: train loss 4.78297. lr 5.995556e-04:   3%|▎         | 566/16329 [04:40<2:12:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 566: train loss 4.78817. lr 5.995541e-04:   3%|▎         | 566/16329 [04:40<2:12:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 566: train loss 4.78817. lr 5.995541e-04:   3%|▎         | 567/16329 [04:40<2:11:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 567: train loss 4.80349. lr 5.995525e-04:   3%|▎         | 567/16329 [04:41<2:11:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 567: train loss 4.80349. lr 5.995525e-04:   3%|▎         | 568/16329 [04:41<2:12:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 568: train loss 4.82408. lr 5.995509e-04:   3%|▎         | 568/16329 [04:41<2:12:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 568: train loss 4.82408. lr 5.995509e-04:   3%|▎         | 569/16329 [04:41<2:11:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 569: train loss 4.76138. lr 5.995493e-04:   3%|▎         | 569/16329 [04:42<2:11:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 569: train loss 4.76138. lr 5.995493e-04:   3%|▎         | 570/16329 [04:42<2:11:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 570: train loss 4.77259. lr 5.995478e-04:   3%|▎         | 570/16329 [04:42<2:11:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 570: train loss 4.77259. lr 5.995478e-04:   3%|▎         | 571/16329 [04:42<2:17:55,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 571: train loss 4.72428. lr 5.995462e-04:   3%|▎         | 571/16329 [04:43<2:17:55,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 571: train loss 4.72428. lr 5.995462e-04:   4%|▎         | 572/16329 [04:43<2:21:34,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 572: train loss 4.81648. lr 5.995446e-04:   4%|▎         | 572/16329 [04:44<2:21:34,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 572: train loss 4.81648. lr 5.995446e-04:   4%|▎         | 573/16329 [04:44<2:22:32,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 573: train loss 4.77979. lr 5.995430e-04:   4%|▎         | 573/16329 [04:44<2:22:32,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 573: train loss 4.77979. lr 5.995430e-04:   4%|▎         | 574/16329 [04:44<2:23:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 574: train loss 4.76495. lr 5.995414e-04:   4%|▎         | 574/16329 [04:45<2:23:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 574: train loss 4.76495. lr 5.995414e-04:   4%|▎         | 575/16329 [04:45<2:24:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 575: train loss 4.76250. lr 5.995398e-04:   4%|▎         | 575/16329 [04:45<2:24:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 575: train loss 4.76250. lr 5.995398e-04:   4%|▎         | 576/16329 [04:45<2:23:22,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 576: train loss 4.82332. lr 5.995382e-04:   4%|▎         | 576/16329 [04:46<2:23:22,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 576: train loss 4.82332. lr 5.995382e-04:   4%|▎         | 577/16329 [04:46<2:21:30,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 577: train loss 4.71914. lr 5.995366e-04:   4%|▎         | 577/16329 [04:47<2:21:30,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 577: train loss 4.71914. lr 5.995366e-04:   4%|▎         | 578/16329 [04:47<2:36:52,  1.67it/s]\u001b[A\n",
      "epoch 1 iter 578: train loss 4.74981. lr 5.995350e-04:   4%|▎         | 578/16329 [04:47<2:36:52,  1.67it/s]\u001b[A\n",
      "epoch 1 iter 578: train loss 4.74981. lr 5.995350e-04:   4%|▎         | 579/16329 [04:47<2:30:01,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 579: train loss 4.77503. lr 5.995334e-04:   4%|▎         | 579/16329 [04:48<2:30:01,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 579: train loss 4.77503. lr 5.995334e-04:   4%|▎         | 580/16329 [04:48<2:29:44,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 580: train loss 4.73442. lr 5.995318e-04:   4%|▎         | 580/16329 [04:48<2:29:44,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 580: train loss 4.73442. lr 5.995318e-04:   4%|▎         | 581/16329 [04:48<2:28:45,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 581: train loss 4.78443. lr 5.995302e-04:   4%|▎         | 581/16329 [04:49<2:28:45,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 581: train loss 4.78443. lr 5.995302e-04:   4%|▎         | 582/16329 [04:49<2:26:28,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 582: train loss 4.79964. lr 5.995285e-04:   4%|▎         | 582/16329 [04:49<2:26:28,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 582: train loss 4.79964. lr 5.995285e-04:   4%|▎         | 583/16329 [04:49<2:24:59,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 583: train loss 4.71166. lr 5.995269e-04:   4%|▎         | 583/16329 [04:50<2:24:59,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 583: train loss 4.71166. lr 5.995269e-04:   4%|▎         | 584/16329 [04:50<2:22:37,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 584: train loss 4.69215. lr 5.995253e-04:   4%|▎         | 584/16329 [04:50<2:22:37,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 584: train loss 4.69215. lr 5.995253e-04:   4%|▎         | 585/16329 [04:50<2:19:12,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 585: train loss 4.80005. lr 5.995237e-04:   4%|▎         | 585/16329 [04:51<2:19:12,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 585: train loss 4.80005. lr 5.995237e-04:   4%|▎         | 586/16329 [04:51<2:17:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 586: train loss 4.75786. lr 5.995221e-04:   4%|▎         | 586/16329 [04:51<2:17:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 586: train loss 4.75786. lr 5.995221e-04:   4%|▎         | 587/16329 [04:51<2:15:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 587: train loss 4.76868. lr 5.995204e-04:   4%|▎         | 587/16329 [04:52<2:15:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 587: train loss 4.76868. lr 5.995204e-04:   4%|▎         | 588/16329 [04:52<2:14:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 588: train loss 4.74055. lr 5.995188e-04:   4%|▎         | 588/16329 [04:52<2:14:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 588: train loss 4.74055. lr 5.995188e-04:   4%|▎         | 589/16329 [04:52<2:13:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 589: train loss 4.64966. lr 5.995172e-04:   4%|▎         | 589/16329 [04:53<2:13:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 589: train loss 4.64966. lr 5.995172e-04:   4%|▎         | 590/16329 [04:53<2:12:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 590: train loss 4.68554. lr 5.995155e-04:   4%|▎         | 590/16329 [04:53<2:12:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 590: train loss 4.68554. lr 5.995155e-04:   4%|▎         | 591/16329 [04:53<2:11:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 591: train loss 4.69557. lr 5.995139e-04:   4%|▎         | 591/16329 [04:54<2:11:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 591: train loss 4.69557. lr 5.995139e-04:   4%|▎         | 592/16329 [04:54<2:11:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 592: train loss 4.69329. lr 5.995122e-04:   4%|▎         | 592/16329 [04:54<2:11:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 592: train loss 4.69329. lr 5.995122e-04:   4%|▎         | 593/16329 [04:54<2:11:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 593: train loss 4.74577. lr 5.995106e-04:   4%|▎         | 593/16329 [04:55<2:11:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 593: train loss 4.74577. lr 5.995106e-04:   4%|▎         | 594/16329 [04:55<2:10:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 594: train loss 4.73285. lr 5.995089e-04:   4%|▎         | 594/16329 [04:55<2:10:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 594: train loss 4.73285. lr 5.995089e-04:   4%|▎         | 595/16329 [04:55<2:11:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 595: train loss 4.80976. lr 5.995073e-04:   4%|▎         | 595/16329 [04:56<2:11:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 595: train loss 4.80976. lr 5.995073e-04:   4%|▎         | 596/16329 [04:56<2:11:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 596: train loss 4.75926. lr 5.995056e-04:   4%|▎         | 596/16329 [04:56<2:11:54,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 596: train loss 4.75926. lr 5.995056e-04:   4%|▎         | 597/16329 [04:56<2:12:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 597: train loss 4.70465. lr 5.995040e-04:   4%|▎         | 597/16329 [04:57<2:12:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 597: train loss 4.70465. lr 5.995040e-04:   4%|▎         | 598/16329 [04:57<2:12:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 598: train loss 4.74142. lr 5.995023e-04:   4%|▎         | 598/16329 [04:57<2:12:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 598: train loss 4.74142. lr 5.995023e-04:   4%|▎         | 599/16329 [04:57<2:11:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 599: train loss 4.71991. lr 5.995006e-04:   4%|▎         | 599/16329 [04:58<2:11:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 599: train loss 4.71991. lr 5.995006e-04:   4%|▎         | 600/16329 [04:58<2:12:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 600: train loss 4.77146. lr 5.994990e-04:   4%|▎         | 600/16329 [04:58<2:12:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 600: train loss 4.77146. lr 5.994990e-04:   4%|▎         | 601/16329 [04:58<2:12:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 601: train loss 4.70006. lr 5.994973e-04:   4%|▎         | 601/16329 [04:59<2:12:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 601: train loss 4.70006. lr 5.994973e-04:   4%|▎         | 602/16329 [04:59<2:12:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 602: train loss 4.69397. lr 5.994956e-04:   4%|▎         | 602/16329 [04:59<2:12:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 602: train loss 4.69397. lr 5.994956e-04:   4%|▎         | 603/16329 [04:59<2:25:40,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 603: train loss 4.73175. lr 5.994940e-04:   4%|▎         | 603/16329 [05:00<2:25:40,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 603: train loss 4.73175. lr 5.994940e-04:   4%|▎         | 604/16329 [05:00<2:21:40,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 604: train loss 4.67947. lr 5.994923e-04:   4%|▎         | 604/16329 [05:00<2:21:40,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 604: train loss 4.67947. lr 5.994923e-04:   4%|▎         | 605/16329 [05:00<2:18:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 605: train loss 4.77161. lr 5.994906e-04:   4%|▎         | 605/16329 [05:01<2:18:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 605: train loss 4.77161. lr 5.994906e-04:   4%|▎         | 606/16329 [05:01<2:16:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 606: train loss 4.65756. lr 5.994889e-04:   4%|▎         | 606/16329 [05:01<2:16:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 606: train loss 4.65756. lr 5.994889e-04:   4%|▎         | 607/16329 [05:01<2:15:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 607: train loss 4.73105. lr 5.994872e-04:   4%|▎         | 607/16329 [05:02<2:15:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 607: train loss 4.73105. lr 5.994872e-04:   4%|▎         | 608/16329 [05:02<2:14:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 608: train loss 4.73077. lr 5.994856e-04:   4%|▎         | 608/16329 [05:02<2:14:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 608: train loss 4.73077. lr 5.994856e-04:   4%|▎         | 609/16329 [05:02<2:14:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 609: train loss 4.66149. lr 5.994839e-04:   4%|▎         | 609/16329 [05:03<2:14:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 609: train loss 4.66149. lr 5.994839e-04:   4%|▎         | 610/16329 [05:03<2:13:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 610: train loss 4.70951. lr 5.994822e-04:   4%|▎         | 610/16329 [05:04<2:13:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 610: train loss 4.70951. lr 5.994822e-04:   4%|▎         | 611/16329 [05:04<2:12:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 611: train loss 4.76118. lr 5.994805e-04:   4%|▎         | 611/16329 [05:04<2:12:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 611: train loss 4.76118. lr 5.994805e-04:   4%|▎         | 612/16329 [05:04<2:12:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 612: train loss 4.64386. lr 5.994788e-04:   4%|▎         | 612/16329 [05:05<2:12:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 612: train loss 4.64386. lr 5.994788e-04:   4%|▍         | 613/16329 [05:05<2:12:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 613: train loss 4.70372. lr 5.994771e-04:   4%|▍         | 613/16329 [05:05<2:12:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 613: train loss 4.70372. lr 5.994771e-04:   4%|▍         | 614/16329 [05:05<2:12:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 614: train loss 4.71576. lr 5.994754e-04:   4%|▍         | 614/16329 [05:06<2:12:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 614: train loss 4.71576. lr 5.994754e-04:   4%|▍         | 615/16329 [05:06<2:13:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 615: train loss 4.67199. lr 5.994737e-04:   4%|▍         | 615/16329 [05:06<2:13:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 615: train loss 4.67199. lr 5.994737e-04:   4%|▍         | 616/16329 [05:06<2:12:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 616: train loss 4.73715. lr 5.994720e-04:   4%|▍         | 616/16329 [05:07<2:12:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 616: train loss 4.73715. lr 5.994720e-04:   4%|▍         | 617/16329 [05:07<2:13:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 617: train loss 4.71611. lr 5.994702e-04:   4%|▍         | 617/16329 [05:07<2:13:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 617: train loss 4.71611. lr 5.994702e-04:   4%|▍         | 618/16329 [05:07<2:12:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 618: train loss 4.70456. lr 5.994685e-04:   4%|▍         | 618/16329 [05:08<2:12:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 618: train loss 4.70456. lr 5.994685e-04:   4%|▍         | 619/16329 [05:08<2:12:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 619: train loss 4.73321. lr 5.994668e-04:   4%|▍         | 619/16329 [05:08<2:12:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 619: train loss 4.73321. lr 5.994668e-04:   4%|▍         | 620/16329 [05:08<2:19:30,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 620: train loss 4.71504. lr 5.994651e-04:   4%|▍         | 620/16329 [05:09<2:19:30,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 620: train loss 4.71504. lr 5.994651e-04:   4%|▍         | 621/16329 [05:09<2:21:53,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 621: train loss 4.55171. lr 5.994634e-04:   4%|▍         | 621/16329 [05:09<2:21:53,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 621: train loss 4.55171. lr 5.994634e-04:   4%|▍         | 622/16329 [05:09<2:21:57,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 622: train loss 4.64650. lr 5.994616e-04:   4%|▍         | 622/16329 [05:10<2:21:57,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 622: train loss 4.64650. lr 5.994616e-04:   4%|▍         | 623/16329 [05:10<2:20:59,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 623: train loss 4.67126. lr 5.994599e-04:   4%|▍         | 623/16329 [05:10<2:20:59,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 623: train loss 4.67126. lr 5.994599e-04:   4%|▍         | 624/16329 [05:10<2:19:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 624: train loss 4.69308. lr 5.994582e-04:   4%|▍         | 624/16329 [05:11<2:19:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 624: train loss 4.69308. lr 5.994582e-04:   4%|▍         | 625/16329 [05:11<2:18:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 625: train loss 4.68441. lr 5.994564e-04:   4%|▍         | 625/16329 [05:11<2:18:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 625: train loss 4.68441. lr 5.994564e-04:   4%|▍         | 626/16329 [05:11<2:17:12,  1.91it/s]\u001b[A\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "epoch 1 iter 2281: train loss 3.07029. lr 5.928009e-04:  14%|█▍        | 2281/16329 [19:16<2:08:54,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2281: train loss 3.07029. lr 5.928009e-04:  14%|█▍        | 2282/16329 [19:16<2:04:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2282: train loss 3.01979. lr 5.927946e-04:  14%|█▍        | 2282/16329 [19:17<2:04:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2282: train loss 3.01979. lr 5.927946e-04:  14%|█▍        | 2283/16329 [19:17<2:02:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2283: train loss 3.05023. lr 5.927883e-04:  14%|█▍        | 2283/16329 [19:17<2:02:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2283: train loss 3.05023. lr 5.927883e-04:  14%|█▍        | 2284/16329 [19:17<2:00:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2284: train loss 3.11941. lr 5.927820e-04:  14%|█▍        | 2284/16329 [19:18<2:00:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2284: train loss 3.11941. lr 5.927820e-04:  14%|█▍        | 2285/16329 [19:18<1:58:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2285: train loss 3.12327. lr 5.927757e-04:  14%|█▍        | 2285/16329 [19:18<1:58:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2285: train loss 3.12327. lr 5.927757e-04:  14%|█▍        | 2286/16329 [19:18<1:57:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2286: train loss 3.13383. lr 5.927694e-04:  14%|█▍        | 2286/16329 [19:19<1:57:34,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2286: train loss 3.13383. lr 5.927694e-04:  14%|█▍        | 2287/16329 [19:19<1:56:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2287: train loss 3.05883. lr 5.927632e-04:  14%|█▍        | 2287/16329 [19:19<1:56:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2287: train loss 3.05883. lr 5.927632e-04:  14%|█▍        | 2288/16329 [19:19<1:56:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2288: train loss 3.09726. lr 5.927568e-04:  14%|█▍        | 2288/16329 [19:20<1:56:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2288: train loss 3.09726. lr 5.927568e-04:  14%|█▍        | 2289/16329 [19:20<1:56:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2289: train loss 3.14285. lr 5.927505e-04:  14%|█▍        | 2289/16329 [19:20<1:56:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2289: train loss 3.14285. lr 5.927505e-04:  14%|█▍        | 2290/16329 [19:20<1:55:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2290: train loss 3.18466. lr 5.927442e-04:  14%|█▍        | 2290/16329 [19:21<1:55:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2290: train loss 3.18466. lr 5.927442e-04:  14%|█▍        | 2291/16329 [19:21<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2291: train loss 3.09452. lr 5.927379e-04:  14%|█▍        | 2291/16329 [19:21<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2291: train loss 3.09452. lr 5.927379e-04:  14%|█▍        | 2292/16329 [19:21<1:55:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2292: train loss 3.00760. lr 5.927316e-04:  14%|█▍        | 2292/16329 [19:22<1:55:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2292: train loss 3.00760. lr 5.927316e-04:  14%|█▍        | 2293/16329 [19:22<1:55:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2293: train loss 3.07957. lr 5.927253e-04:  14%|█▍        | 2293/16329 [19:22<1:55:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2293: train loss 3.07957. lr 5.927253e-04:  14%|█▍        | 2294/16329 [19:22<1:55:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2294: train loss 3.07085. lr 5.927190e-04:  14%|█▍        | 2294/16329 [19:23<1:55:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2294: train loss 3.07085. lr 5.927190e-04:  14%|█▍        | 2295/16329 [19:23<1:55:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2295: train loss 3.05199. lr 5.927127e-04:  14%|█▍        | 2295/16329 [19:23<1:55:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2295: train loss 3.05199. lr 5.927127e-04:  14%|█▍        | 2296/16329 [19:23<1:55:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2296: train loss 3.06301. lr 5.927063e-04:  14%|█▍        | 2296/16329 [19:24<1:55:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2296: train loss 3.06301. lr 5.927063e-04:  14%|█▍        | 2297/16329 [19:24<1:55:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2297: train loss 3.04718. lr 5.927000e-04:  14%|█▍        | 2297/16329 [19:24<1:55:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2297: train loss 3.04718. lr 5.927000e-04:  14%|█▍        | 2298/16329 [19:24<1:55:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2298: train loss 3.08907. lr 5.926937e-04:  14%|█▍        | 2298/16329 [19:25<1:55:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2298: train loss 3.08907. lr 5.926937e-04:  14%|█▍        | 2299/16329 [19:25<1:55:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2299: train loss 3.05286. lr 5.926873e-04:  14%|█▍        | 2299/16329 [19:25<1:55:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2299: train loss 3.05286. lr 5.926873e-04:  14%|█▍        | 2300/16329 [19:25<1:55:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2300: train loss 3.05855. lr 5.926810e-04:  14%|█▍        | 2300/16329 [19:26<1:55:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2300: train loss 3.05855. lr 5.926810e-04:  14%|█▍        | 2301/16329 [19:26<1:55:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2301: train loss 3.08056. lr 5.926747e-04:  14%|█▍        | 2301/16329 [19:26<1:55:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2301: train loss 3.08056. lr 5.926747e-04:  14%|█▍        | 2302/16329 [19:26<1:55:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2302: train loss 3.09656. lr 5.926683e-04:  14%|█▍        | 2302/16329 [19:26<1:55:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2302: train loss 3.09656. lr 5.926683e-04:  14%|█▍        | 2303/16329 [19:26<1:55:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2303: train loss 3.09447. lr 5.926620e-04:  14%|█▍        | 2303/16329 [19:27<1:55:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2303: train loss 3.09447. lr 5.926620e-04:  14%|█▍        | 2304/16329 [19:27<1:55:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2304: train loss 3.01957. lr 5.926556e-04:  14%|█▍        | 2304/16329 [19:27<1:55:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2304: train loss 3.01957. lr 5.926556e-04:  14%|█▍        | 2305/16329 [19:27<1:55:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2305: train loss 3.06866. lr 5.926493e-04:  14%|█▍        | 2305/16329 [19:28<1:55:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2305: train loss 3.06866. lr 5.926493e-04:  14%|█▍        | 2306/16329 [19:28<1:55:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2306: train loss 3.14672. lr 5.926429e-04:  14%|█▍        | 2306/16329 [19:28<1:55:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2306: train loss 3.14672. lr 5.926429e-04:  14%|█▍        | 2307/16329 [19:28<1:55:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2307: train loss 3.06860. lr 5.926366e-04:  14%|█▍        | 2307/16329 [19:29<1:55:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2307: train loss 3.06860. lr 5.926366e-04:  14%|█▍        | 2308/16329 [19:29<1:55:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2308: train loss 3.08095. lr 5.926302e-04:  14%|█▍        | 2308/16329 [19:29<1:55:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2308: train loss 3.08095. lr 5.926302e-04:  14%|█▍        | 2309/16329 [19:29<1:55:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2309: train loss 3.10516. lr 5.926239e-04:  14%|█▍        | 2309/16329 [19:30<1:55:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2309: train loss 3.10516. lr 5.926239e-04:  14%|█▍        | 2310/16329 [19:30<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2310: train loss 3.02978. lr 5.926175e-04:  14%|█▍        | 2310/16329 [19:30<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2310: train loss 3.02978. lr 5.926175e-04:  14%|█▍        | 2311/16329 [19:30<1:55:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2311: train loss 3.02462. lr 5.926112e-04:  14%|█▍        | 2311/16329 [19:31<1:55:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2311: train loss 3.02462. lr 5.926112e-04:  14%|█▍        | 2312/16329 [19:31<1:55:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2312: train loss 3.06878. lr 5.926048e-04:  14%|█▍        | 2312/16329 [19:31<1:55:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2312: train loss 3.06878. lr 5.926048e-04:  14%|█▍        | 2313/16329 [19:31<1:54:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2313: train loss 3.11026. lr 5.925984e-04:  14%|█▍        | 2313/16329 [19:32<1:54:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2313: train loss 3.11026. lr 5.925984e-04:  14%|█▍        | 2314/16329 [19:32<1:55:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2314: train loss 3.06082. lr 5.925920e-04:  14%|█▍        | 2314/16329 [19:32<1:55:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2314: train loss 3.06082. lr 5.925920e-04:  14%|█▍        | 2315/16329 [19:32<1:55:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2315: train loss 2.97322. lr 5.925857e-04:  14%|█▍        | 2315/16329 [19:33<1:55:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2315: train loss 2.97322. lr 5.925857e-04:  14%|█▍        | 2316/16329 [19:33<1:55:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2316: train loss 3.14888. lr 5.925793e-04:  14%|█▍        | 2316/16329 [19:33<1:55:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2316: train loss 3.14888. lr 5.925793e-04:  14%|█▍        | 2317/16329 [19:33<1:55:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2317: train loss 3.07251. lr 5.925729e-04:  14%|█▍        | 2317/16329 [19:34<1:55:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2317: train loss 3.07251. lr 5.925729e-04:  14%|█▍        | 2318/16329 [19:34<1:55:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2318: train loss 3.09257. lr 5.925665e-04:  14%|█▍        | 2318/16329 [19:34<1:55:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2318: train loss 3.09257. lr 5.925665e-04:  14%|█▍        | 2319/16329 [19:34<1:55:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2319: train loss 3.02888. lr 5.925601e-04:  14%|█▍        | 2319/16329 [19:35<1:55:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2319: train loss 3.02888. lr 5.925601e-04:  14%|█▍        | 2320/16329 [19:35<1:55:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2320: train loss 3.10881. lr 5.925537e-04:  14%|█▍        | 2320/16329 [19:36<1:55:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2320: train loss 3.10881. lr 5.925537e-04:  14%|█▍        | 2321/16329 [19:36<2:08:33,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2321: train loss 3.05605. lr 5.925474e-04:  14%|█▍        | 2321/16329 [19:36<2:08:33,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2321: train loss 3.05605. lr 5.925474e-04:  14%|█▍        | 2322/16329 [19:36<2:04:32,  1.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2322: train loss 3.04563. lr 5.925410e-04:  14%|█▍        | 2322/16329 [19:37<2:04:32,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2322: train loss 3.04563. lr 5.925410e-04:  14%|█▍        | 2323/16329 [19:37<2:01:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2323: train loss 3.01654. lr 5.925346e-04:  14%|█▍        | 2323/16329 [19:37<2:01:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2323: train loss 3.01654. lr 5.925346e-04:  14%|█▍        | 2324/16329 [19:37<1:59:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2324: train loss 3.03635. lr 5.925282e-04:  14%|█▍        | 2324/16329 [19:38<1:59:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2324: train loss 3.03635. lr 5.925282e-04:  14%|█▍        | 2325/16329 [19:38<1:58:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2325: train loss 3.10719. lr 5.925218e-04:  14%|█▍        | 2325/16329 [19:38<1:58:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2325: train loss 3.10719. lr 5.925218e-04:  14%|█▍        | 2326/16329 [19:38<1:57:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2326: train loss 3.01858. lr 5.925154e-04:  14%|█▍        | 2326/16329 [19:39<1:57:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2326: train loss 3.01858. lr 5.925154e-04:  14%|█▍        | 2327/16329 [19:39<1:57:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2327: train loss 3.03731. lr 5.925090e-04:  14%|█▍        | 2327/16329 [19:39<1:57:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2327: train loss 3.03731. lr 5.925090e-04:  14%|█▍        | 2328/16329 [19:39<1:56:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2328: train loss 3.06517. lr 5.925025e-04:  14%|█▍        | 2328/16329 [19:40<1:56:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2328: train loss 3.06517. lr 5.925025e-04:  14%|█▍        | 2329/16329 [19:40<1:56:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2329: train loss 3.02067. lr 5.924961e-04:  14%|█▍        | 2329/16329 [19:40<1:56:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2329: train loss 3.02067. lr 5.924961e-04:  14%|█▍        | 2330/16329 [19:40<1:55:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2330: train loss 3.11184. lr 5.924897e-04:  14%|█▍        | 2330/16329 [19:41<1:55:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2330: train loss 3.11184. lr 5.924897e-04:  14%|█▍        | 2331/16329 [19:41<1:55:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2331: train loss 2.99706. lr 5.924833e-04:  14%|█▍        | 2331/16329 [19:41<1:55:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2331: train loss 2.99706. lr 5.924833e-04:  14%|█▍        | 2332/16329 [19:41<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2332: train loss 3.10352. lr 5.924769e-04:  14%|█▍        | 2332/16329 [19:42<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2332: train loss 3.10352. lr 5.924769e-04:  14%|█▍        | 2333/16329 [19:42<1:55:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2333: train loss 3.02753. lr 5.924704e-04:  14%|█▍        | 2333/16329 [19:42<1:55:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2333: train loss 3.02753. lr 5.924704e-04:  14%|█▍        | 2334/16329 [19:42<1:55:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2334: train loss 3.07952. lr 5.924640e-04:  14%|█▍        | 2334/16329 [19:43<1:55:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2334: train loss 3.07952. lr 5.924640e-04:  14%|█▍        | 2335/16329 [19:43<1:55:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2335: train loss 3.10253. lr 5.924576e-04:  14%|█▍        | 2335/16329 [19:43<1:55:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2335: train loss 3.10253. lr 5.924576e-04:  14%|█▍        | 2336/16329 [19:43<1:55:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2336: train loss 3.09580. lr 5.924512e-04:  14%|█▍        | 2336/16329 [19:43<1:55:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2336: train loss 3.09580. lr 5.924512e-04:  14%|█▍        | 2337/16329 [19:43<1:55:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2337: train loss 3.16547. lr 5.924447e-04:  14%|█▍        | 2337/16329 [19:44<1:55:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2337: train loss 3.16547. lr 5.924447e-04:  14%|█▍        | 2338/16329 [19:44<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2338: train loss 3.12901. lr 5.924383e-04:  14%|█▍        | 2338/16329 [19:44<1:55:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2338: train loss 3.12901. lr 5.924383e-04:  14%|█▍        | 2339/16329 [19:44<1:55:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2339: train loss 2.97150. lr 5.924318e-04:  14%|█▍        | 2339/16329 [19:45<1:55:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2339: train loss 2.97150. lr 5.924318e-04:  14%|█▍        | 2340/16329 [19:45<1:55:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2340: train loss 3.03080. lr 5.924254e-04:  14%|█▍        | 2340/16329 [19:45<1:55:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2340: train loss 3.03080. lr 5.924254e-04:  14%|█▍        | 2341/16329 [19:45<1:55:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2341: train loss 3.11273. lr 5.924190e-04:  14%|█▍        | 2341/16329 [19:46<1:55:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2341: train loss 3.11273. lr 5.924190e-04:  14%|█▍        | 2342/16329 [19:46<1:55:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2342: train loss 3.09232. lr 5.924125e-04:  14%|█▍        | 2342/16329 [19:46<1:55:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2342: train loss 3.09232. lr 5.924125e-04:  14%|█▍        | 2343/16329 [19:46<1:55:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2343: train loss 2.98939. lr 5.924061e-04:  14%|█▍        | 2343/16329 [19:47<1:55:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2343: train loss 2.98939. lr 5.924061e-04:  14%|█▍        | 2344/16329 [19:47<1:55:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2344: train loss 3.04495. lr 5.923996e-04:  14%|█▍        | 2344/16329 [19:47<1:55:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2344: train loss 3.04495. lr 5.923996e-04:  14%|█▍        | 2345/16329 [19:47<1:55:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2345: train loss 3.01501. lr 5.923931e-04:  14%|█▍        | 2345/16329 [19:48<1:55:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2345: train loss 3.01501. lr 5.923931e-04:  14%|█▍        | 2346/16329 [19:48<1:55:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2346: train loss 3.08044. lr 5.923867e-04:  14%|█▍        | 2346/16329 [19:48<1:55:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2346: train loss 3.08044. lr 5.923867e-04:  14%|█▍        | 2347/16329 [19:48<1:55:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2347: train loss 3.02293. lr 5.923802e-04:  14%|█▍        | 2347/16329 [19:49<1:55:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2347: train loss 3.02293. lr 5.923802e-04:  14%|█▍        | 2348/16329 [19:49<1:54:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2348: train loss 3.06336. lr 5.923738e-04:  14%|█▍        | 2348/16329 [19:49<1:54:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2348: train loss 3.06336. lr 5.923738e-04:  14%|█▍        | 2349/16329 [19:49<1:55:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2349: train loss 3.13101. lr 5.923673e-04:  14%|█▍        | 2349/16329 [19:50<1:55:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2349: train loss 3.13101. lr 5.923673e-04:  14%|█▍        | 2350/16329 [19:50<1:55:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2350: train loss 3.02740. lr 5.923608e-04:  14%|█▍        | 2350/16329 [19:50<1:55:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2350: train loss 3.02740. lr 5.923608e-04:  14%|█▍        | 2351/16329 [19:50<1:55:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2351: train loss 2.99979. lr 5.923544e-04:  14%|█▍        | 2351/16329 [19:51<1:55:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2351: train loss 2.99979. lr 5.923544e-04:  14%|█▍        | 2352/16329 [19:51<1:55:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2352: train loss 3.03784. lr 5.923479e-04:  14%|█▍        | 2352/16329 [19:51<1:55:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2352: train loss 3.03784. lr 5.923479e-04:  14%|█▍        | 2353/16329 [19:51<1:56:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2353: train loss 3.02089. lr 5.923414e-04:  14%|█▍        | 2353/16329 [19:52<1:56:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2353: train loss 3.02089. lr 5.923414e-04:  14%|█▍        | 2354/16329 [19:52<1:56:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2354: train loss 3.09918. lr 5.923349e-04:  14%|█▍        | 2354/16329 [19:52<1:56:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2354: train loss 3.09918. lr 5.923349e-04:  14%|█▍        | 2355/16329 [19:52<1:55:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2355: train loss 3.02662. lr 5.923284e-04:  14%|█▍        | 2355/16329 [19:53<1:55:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2355: train loss 3.02662. lr 5.923284e-04:  14%|█▍        | 2356/16329 [19:53<2:08:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2356: train loss 3.04737. lr 5.923219e-04:  14%|█▍        | 2356/16329 [19:54<2:08:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2356: train loss 3.04737. lr 5.923219e-04:  14%|█▍        | 2357/16329 [19:54<2:04:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2357: train loss 3.02982. lr 5.923155e-04:  14%|█▍        | 2357/16329 [19:54<2:04:10,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2357: train loss 3.02982. lr 5.923155e-04:  14%|█▍        | 2358/16329 [19:54<2:01:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2358: train loss 2.97521. lr 5.923090e-04:  14%|█▍        | 2358/16329 [19:55<2:01:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2358: train loss 2.97521. lr 5.923090e-04:  14%|█▍        | 2359/16329 [19:55<1:59:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2359: train loss 3.05864. lr 5.923025e-04:  14%|█▍        | 2359/16329 [19:55<1:59:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2359: train loss 3.05864. lr 5.923025e-04:  14%|█▍        | 2360/16329 [19:55<1:57:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2360: train loss 3.06198. lr 5.922960e-04:  14%|█▍        | 2360/16329 [19:56<1:57:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2360: train loss 3.06198. lr 5.922960e-04:  14%|█▍        | 2361/16329 [19:56<1:57:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2361: train loss 3.00102. lr 5.922895e-04:  14%|█▍        | 2361/16329 [19:56<1:57:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2361: train loss 3.00102. lr 5.922895e-04:  14%|█▍        | 2362/16329 [19:56<1:56:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2362: train loss 3.01176. lr 5.922830e-04:  14%|█▍        | 2362/16329 [19:57<1:56:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2362: train loss 3.01176. lr 5.922830e-04:  14%|█▍        | 2363/16329 [19:57<1:55:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2363: train loss 2.98116. lr 5.922765e-04:  14%|█▍        | 2363/16329 [19:57<1:55:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2363: train loss 2.98116. lr 5.922765e-04:  14%|█▍        | 2364/16329 [19:57<1:55:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2364: train loss 3.01377. lr 5.922700e-04:  14%|█▍        | 2364/16329 [19:58<1:55:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2364: train loss 3.01377. lr 5.922700e-04:  14%|█▍        | 2365/16329 [19:58<1:55:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2365: train loss 3.00344. lr 5.922635e-04:  14%|█▍        | 2365/16329 [19:58<1:55:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2365: train loss 3.00344. lr 5.922635e-04:  14%|█▍        | 2366/16329 [19:58<1:55:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2366: train loss 3.07528. lr 5.922569e-04:  14%|█▍        | 2366/16329 [19:59<1:55:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2366: train loss 3.07528. lr 5.922569e-04:  14%|█▍        | 2367/16329 [19:59<1:54:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2367: train loss 3.10211. lr 5.922504e-04:  14%|█▍        | 2367/16329 [19:59<1:54:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2367: train loss 3.10211. lr 5.922504e-04:  15%|█▍        | 2368/16329 [19:59<1:54:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2368: train loss 3.09844. lr 5.922439e-04:  15%|█▍        | 2368/16329 [20:00<1:54:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2368: train loss 3.09844. lr 5.922439e-04:  15%|█▍        | 2369/16329 [20:00<1:54:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2369: train loss 3.11310. lr 5.922374e-04:  15%|█▍        | 2369/16329 [20:00<1:54:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2369: train loss 3.11310. lr 5.922374e-04:  15%|█▍        | 2370/16329 [20:00<1:54:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2370: train loss 2.99719. lr 5.922309e-04:  15%|█▍        | 2370/16329 [20:00<1:54:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2370: train loss 2.99719. lr 5.922309e-04:  15%|█▍        | 2371/16329 [20:00<1:54:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2371: train loss 3.00657. lr 5.922243e-04:  15%|█▍        | 2371/16329 [20:01<1:54:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2371: train loss 3.00657. lr 5.922243e-04:  15%|█▍        | 2372/16329 [20:01<1:54:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2372: train loss 3.05548. lr 5.922178e-04:  15%|█▍        | 2372/16329 [20:01<1:54:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2372: train loss 3.05548. lr 5.922178e-04:  15%|█▍        | 2373/16329 [20:01<1:55:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2373: train loss 3.06358. lr 5.922113e-04:  15%|█▍        | 2373/16329 [20:02<1:55:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2373: train loss 3.06358. lr 5.922113e-04:  15%|█▍        | 2374/16329 [20:02<1:55:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2374: train loss 3.05470. lr 5.922047e-04:  15%|█▍        | 2374/16329 [20:02<1:55:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2374: train loss 3.05470. lr 5.922047e-04:  15%|█▍        | 2375/16329 [20:02<1:54:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2375: train loss 3.07434. lr 5.921982e-04:  15%|█▍        | 2375/16329 [20:03<1:54:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2375: train loss 3.07434. lr 5.921982e-04:  15%|█▍        | 2376/16329 [20:03<1:54:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2376: train loss 3.11865. lr 5.921917e-04:  15%|█▍        | 2376/16329 [20:03<1:54:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2376: train loss 3.11865. lr 5.921917e-04:  15%|█▍        | 2377/16329 [20:03<1:54:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2377: train loss 3.03595. lr 5.921851e-04:  15%|█▍        | 2377/16329 [20:04<1:54:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2377: train loss 3.03595. lr 5.921851e-04:  15%|█▍        | 2378/16329 [20:04<1:54:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2378: train loss 3.04691. lr 5.921786e-04:  15%|█▍        | 2378/16329 [20:04<1:54:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2378: train loss 3.04691. lr 5.921786e-04:  15%|█▍        | 2379/16329 [20:04<1:55:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2379: train loss 3.12197. lr 5.921720e-04:  15%|█▍        | 2379/16329 [20:05<1:55:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2379: train loss 3.12197. lr 5.921720e-04:  15%|█▍        | 2380/16329 [20:05<1:55:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2380: train loss 3.02344. lr 5.921655e-04:  15%|█▍        | 2380/16329 [20:06<1:55:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2380: train loss 3.02344. lr 5.921655e-04:  15%|█▍        | 2381/16329 [20:06<2:07:08,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2381: train loss 3.01840. lr 5.921589e-04:  15%|█▍        | 2381/16329 [20:06<2:07:08,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2381: train loss 3.01840. lr 5.921589e-04:  15%|█▍        | 2382/16329 [20:06<2:03:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2382: train loss 3.01625. lr 5.921524e-04:  15%|█▍        | 2382/16329 [20:07<2:03:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2382: train loss 3.01625. lr 5.921524e-04:  15%|█▍        | 2383/16329 [20:07<2:01:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2383: train loss 3.02656. lr 5.921458e-04:  15%|█▍        | 2383/16329 [20:07<2:01:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2383: train loss 3.02656. lr 5.921458e-04:  15%|█▍        | 2384/16329 [20:07<1:59:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2384: train loss 3.09079. lr 5.921392e-04:  15%|█▍        | 2384/16329 [20:08<1:59:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2384: train loss 3.09079. lr 5.921392e-04:  15%|█▍        | 2385/16329 [20:08<1:57:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2385: train loss 3.01807. lr 5.921327e-04:  15%|█▍        | 2385/16329 [20:08<1:57:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2385: train loss 3.01807. lr 5.921327e-04:  15%|█▍        | 2386/16329 [20:08<1:56:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2386: train loss 2.99969. lr 5.921261e-04:  15%|█▍        | 2386/16329 [20:09<1:56:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2386: train loss 2.99969. lr 5.921261e-04:  15%|█▍        | 2387/16329 [20:09<1:56:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2387: train loss 3.10022. lr 5.921195e-04:  15%|█▍        | 2387/16329 [20:09<1:56:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2387: train loss 3.10022. lr 5.921195e-04:  15%|█▍        | 2388/16329 [20:09<1:55:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2388: train loss 2.99044. lr 5.921130e-04:  15%|█▍        | 2388/16329 [20:10<1:55:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2388: train loss 2.99044. lr 5.921130e-04:  15%|█▍        | 2389/16329 [20:10<1:55:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2389: train loss 3.02278. lr 5.921064e-04:  15%|█▍        | 2389/16329 [20:10<1:55:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2389: train loss 3.02278. lr 5.921064e-04:  15%|█▍        | 2390/16329 [20:10<1:55:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2390: train loss 2.99210. lr 5.920998e-04:  15%|█▍        | 2390/16329 [20:11<1:55:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2390: train loss 2.99210. lr 5.920998e-04:  15%|█▍        | 2391/16329 [20:11<1:55:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2391: train loss 2.93952. lr 5.920932e-04:  15%|█▍        | 2391/16329 [20:11<1:55:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2391: train loss 2.93952. lr 5.920932e-04:  15%|█▍        | 2392/16329 [20:11<1:54:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2392: train loss 3.04350. lr 5.920866e-04:  15%|█▍        | 2392/16329 [20:12<1:54:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2392: train loss 3.04350. lr 5.920866e-04:  15%|█▍        | 2393/16329 [20:12<1:55:20,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2393: train loss 2.93376. lr 5.920801e-04:  15%|█▍        | 2393/16329 [20:12<1:55:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2393: train loss 2.93376. lr 5.920801e-04:  15%|█▍        | 2394/16329 [20:12<1:55:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2394: train loss 3.04660. lr 5.920735e-04:  15%|█▍        | 2394/16329 [20:13<1:55:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2394: train loss 3.04660. lr 5.920735e-04:  15%|█▍        | 2395/16329 [20:13<1:55:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2395: train loss 3.03953. lr 5.920669e-04:  15%|█▍        | 2395/16329 [20:13<1:55:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2395: train loss 3.03953. lr 5.920669e-04:  15%|█▍        | 2396/16329 [20:13<1:54:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2396: train loss 3.07816. lr 5.920603e-04:  15%|█▍        | 2396/16329 [20:14<1:54:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2396: train loss 3.07816. lr 5.920603e-04:  15%|█▍        | 2397/16329 [20:14<1:54:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2397: train loss 3.05018. lr 5.920537e-04:  15%|█▍        | 2397/16329 [20:14<1:54:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2397: train loss 3.05018. lr 5.920537e-04:  15%|█▍        | 2398/16329 [20:14<1:54:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2398: train loss 3.03841. lr 5.920471e-04:  15%|█▍        | 2398/16329 [20:15<1:54:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2398: train loss 3.03841. lr 5.920471e-04:  15%|█▍        | 2399/16329 [20:15<1:54:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2399: train loss 3.07748. lr 5.920405e-04:  15%|█▍        | 2399/16329 [20:15<1:54:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2399: train loss 3.07748. lr 5.920405e-04:  15%|█▍        | 2400/16329 [20:15<1:54:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2400: train loss 3.04344. lr 5.920339e-04:  15%|█▍        | 2400/16329 [20:16<1:54:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2400: train loss 3.04344. lr 5.920339e-04:  15%|█▍        | 2401/16329 [20:16<1:54:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2401: train loss 2.95179. lr 5.920273e-04:  15%|█▍        | 2401/16329 [20:16<1:54:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2401: train loss 2.95179. lr 5.920273e-04:  15%|█▍        | 2402/16329 [20:16<1:54:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2402: train loss 3.07424. lr 5.920207e-04:  15%|█▍        | 2402/16329 [20:17<1:54:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2402: train loss 3.07424. lr 5.920207e-04:  15%|█▍        | 2403/16329 [20:17<1:59:21,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2403: train loss 2.96565. lr 5.920140e-04:  15%|█▍        | 2403/16329 [20:17<1:59:21,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2403: train loss 2.96565. lr 5.920140e-04:  15%|█▍        | 2404/16329 [20:17<2:02:50,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2404: train loss 3.04966. lr 5.920074e-04:  15%|█▍        | 2404/16329 [20:18<2:02:50,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2404: train loss 3.04966. lr 5.920074e-04:  15%|█▍        | 2405/16329 [20:18<2:04:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2405: train loss 2.99677. lr 5.920008e-04:  15%|█▍        | 2405/16329 [20:18<2:04:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2405: train loss 2.99677. lr 5.920008e-04:  15%|█▍        | 2406/16329 [20:18<2:03:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2406: train loss 2.96115. lr 5.919942e-04:  15%|█▍        | 2406/16329 [20:19<2:03:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2406: train loss 2.96115. lr 5.919942e-04:  15%|█▍        | 2407/16329 [20:19<2:02:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 2407: train loss 2.99007. lr 5.919876e-04:  15%|█▍        | 2407/16329 [20:19<2:02:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 2407: train loss 2.99007. lr 5.919876e-04:  15%|█▍        | 2408/16329 [20:19<2:13:01,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 2408: train loss 3.03801. lr 5.919809e-04:  15%|█▍        | 2408/16329 [20:20<2:13:01,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 2408: train loss 3.03801. lr 5.919809e-04:  15%|█▍        | 2409/16329 [20:20<2:08:04,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2409: train loss 2.94498. lr 5.919743e-04:  15%|█▍        | 2409/16329 [20:20<2:08:04,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2409: train loss 2.94498. lr 5.919743e-04:  15%|█▍        | 2410/16329 [20:20<2:04:28,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2410: train loss 3.01152. lr 5.919677e-04:  15%|█▍        | 2410/16329 [20:21<2:04:28,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2410: train loss 3.01152. lr 5.919677e-04:  15%|█▍        | 2411/16329 [20:21<2:01:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2411: train loss 3.05604. lr 5.919610e-04:  15%|█▍        | 2411/16329 [20:21<2:01:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2411: train loss 3.05604. lr 5.919610e-04:  15%|█▍        | 2412/16329 [20:21<1:59:31,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2412: train loss 3.04032. lr 5.919544e-04:  15%|█▍        | 2412/16329 [20:22<1:59:31,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2412: train loss 3.04032. lr 5.919544e-04:  15%|█▍        | 2413/16329 [20:22<1:57:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2413: train loss 3.06744. lr 5.919478e-04:  15%|█▍        | 2413/16329 [20:22<1:57:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2413: train loss 3.06744. lr 5.919478e-04:  15%|█▍        | 2414/16329 [20:22<1:57:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2414: train loss 3.03640. lr 5.919411e-04:  15%|█▍        | 2414/16329 [20:23<1:57:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2414: train loss 3.03640. lr 5.919411e-04:  15%|█▍        | 2415/16329 [20:23<1:56:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2415: train loss 2.92398. lr 5.919345e-04:  15%|█▍        | 2415/16329 [20:23<1:56:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2415: train loss 2.92398. lr 5.919345e-04:  15%|█▍        | 2416/16329 [20:23<1:55:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2416: train loss 3.00034. lr 5.919278e-04:  15%|█▍        | 2416/16329 [20:24<1:55:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2416: train loss 3.00034. lr 5.919278e-04:  15%|█▍        | 2417/16329 [20:24<1:55:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2417: train loss 2.94237. lr 5.919212e-04:  15%|█▍        | 2417/16329 [20:24<1:55:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2417: train loss 2.94237. lr 5.919212e-04:  15%|█▍        | 2418/16329 [20:24<1:54:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2418: train loss 3.01413. lr 5.919145e-04:  15%|█▍        | 2418/16329 [20:25<1:54:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2418: train loss 3.01413. lr 5.919145e-04:  15%|█▍        | 2419/16329 [20:25<1:55:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2419: train loss 3.00763. lr 5.919079e-04:  15%|█▍        | 2419/16329 [20:25<1:55:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2419: train loss 3.00763. lr 5.919079e-04:  15%|█▍        | 2420/16329 [20:25<1:54:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2420: train loss 2.96644. lr 5.919012e-04:  15%|█▍        | 2420/16329 [20:26<1:54:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2420: train loss 2.96644. lr 5.919012e-04:  15%|█▍        | 2421/16329 [20:26<1:54:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2421: train loss 3.00966. lr 5.918945e-04:  15%|█▍        | 2421/16329 [20:26<1:54:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2421: train loss 3.00966. lr 5.918945e-04:  15%|█▍        | 2422/16329 [20:26<1:54:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2422: train loss 3.05272. lr 5.918879e-04:  15%|█▍        | 2422/16329 [20:27<1:54:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2422: train loss 3.05272. lr 5.918879e-04:  15%|█▍        | 2423/16329 [20:27<1:54:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2423: train loss 3.03987. lr 5.918812e-04:  15%|█▍        | 2423/16329 [20:27<1:54:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2423: train loss 3.03987. lr 5.918812e-04:  15%|█▍        | 2424/16329 [20:27<1:54:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2424: train loss 2.98552. lr 5.918745e-04:  15%|█▍        | 2424/16329 [20:28<1:54:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2424: train loss 2.98552. lr 5.918745e-04:  15%|█▍        | 2425/16329 [20:28<1:54:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2425: train loss 2.98647. lr 5.918679e-04:  15%|█▍        | 2425/16329 [20:28<1:54:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2425: train loss 2.98647. lr 5.918679e-04:  15%|█▍        | 2426/16329 [20:28<1:54:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2426: train loss 3.03621. lr 5.918612e-04:  15%|█▍        | 2426/16329 [20:29<1:54:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2426: train loss 3.03621. lr 5.918612e-04:  15%|█▍        | 2427/16329 [20:29<1:54:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2427: train loss 3.05268. lr 5.918545e-04:  15%|█▍        | 2427/16329 [20:29<1:54:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2427: train loss 3.05268. lr 5.918545e-04:  15%|█▍        | 2428/16329 [20:29<1:54:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2428: train loss 3.06797. lr 5.918478e-04:  15%|█▍        | 2428/16329 [20:30<1:54:06,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2428: train loss 3.06797. lr 5.918478e-04:  15%|█▍        | 2429/16329 [20:30<1:54:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2429: train loss 3.02429. lr 5.918411e-04:  15%|█▍        | 2429/16329 [20:30<1:54:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2429: train loss 3.02429. lr 5.918411e-04:  15%|█▍        | 2430/16329 [20:30<1:54:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2430: train loss 3.04833. lr 5.918345e-04:  15%|█▍        | 2430/16329 [20:31<1:54:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2430: train loss 3.04833. lr 5.918345e-04:  15%|█▍        | 2431/16329 [20:31<1:54:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2431: train loss 3.02203. lr 5.918278e-04:  15%|█▍        | 2431/16329 [20:31<1:54:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2431: train loss 3.02203. lr 5.918278e-04:  15%|█▍        | 2432/16329 [20:31<1:54:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2432: train loss 3.06889. lr 5.918211e-04:  15%|█▍        | 2432/16329 [20:32<1:54:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2432: train loss 3.06889. lr 5.918211e-04:  15%|█▍        | 2433/16329 [20:32<1:54:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2433: train loss 3.04554. lr 5.918144e-04:  15%|█▍        | 2433/16329 [20:32<1:54:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2433: train loss 3.04554. lr 5.918144e-04:  15%|█▍        | 2434/16329 [20:32<1:54:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2434: train loss 3.01739. lr 5.918077e-04:  15%|█▍        | 2434/16329 [20:33<1:54:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2434: train loss 3.01739. lr 5.918077e-04:  15%|█▍        | 2435/16329 [20:33<1:54:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2435: train loss 2.99860. lr 5.918010e-04:  15%|█▍        | 2435/16329 [20:33<1:54:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2435: train loss 2.99860. lr 5.918010e-04:  15%|█▍        | 2436/16329 [20:33<1:54:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2436: train loss 3.01494. lr 5.917943e-04:  15%|█▍        | 2436/16329 [20:34<1:54:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2436: train loss 3.01494. lr 5.917943e-04:  15%|█▍        | 2437/16329 [20:34<1:54:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2437: train loss 3.02541. lr 5.917876e-04:  15%|█▍        | 2437/16329 [20:34<1:54:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2437: train loss 3.02541. lr 5.917876e-04:  15%|█▍        | 2438/16329 [20:34<1:54:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2438: train loss 2.94357. lr 5.917809e-04:  15%|█▍        | 2438/16329 [20:35<1:54:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2438: train loss 2.94357. lr 5.917809e-04:  15%|█▍        | 2439/16329 [20:35<1:54:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2439: train loss 3.00228. lr 5.917742e-04:  15%|█▍        | 2439/16329 [20:35<1:54:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2439: train loss 3.00228. lr 5.917742e-04:  15%|█▍        | 2440/16329 [20:35<1:54:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2440: train loss 3.03321. lr 5.917675e-04:  15%|█▍        | 2440/16329 [20:36<1:54:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2440: train loss 3.03321. lr 5.917675e-04:  15%|█▍        | 2441/16329 [20:36<1:54:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2441: train loss 2.98751. lr 5.917607e-04:  15%|█▍        | 2441/16329 [20:36<1:54:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2441: train loss 2.98751. lr 5.917607e-04:  15%|█▍        | 2442/16329 [20:36<1:54:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2442: train loss 2.93263. lr 5.917540e-04:  15%|█▍        | 2442/16329 [20:37<1:54:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2442: train loss 2.93263. lr 5.917540e-04:  15%|█▍        | 2443/16329 [20:37<1:54:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2443: train loss 3.06141. lr 5.917473e-04:  15%|█▍        | 2443/16329 [20:37<1:54:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2443: train loss 3.06141. lr 5.917473e-04:  15%|█▍        | 2444/16329 [20:37<1:54:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2444: train loss 3.00180. lr 5.917406e-04:  15%|█▍        | 2444/16329 [20:38<1:54:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2444: train loss 3.00180. lr 5.917406e-04:  15%|█▍        | 2445/16329 [20:38<1:54:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2445: train loss 2.96076. lr 5.917338e-04:  15%|█▍        | 2445/16329 [20:38<1:54:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2445: train loss 2.96076. lr 5.917338e-04:  15%|█▍        | 2446/16329 [20:38<1:54:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2446: train loss 2.94369. lr 5.917271e-04:  15%|█▍        | 2446/16329 [20:39<1:54:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2446: train loss 2.94369. lr 5.917271e-04:  15%|█▍        | 2447/16329 [20:39<1:54:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2447: train loss 2.99172. lr 5.917204e-04:  15%|█▍        | 2447/16329 [20:39<1:54:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2447: train loss 2.99172. lr 5.917204e-04:  15%|█▍        | 2448/16329 [20:39<2:06:20,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2448: train loss 2.94476. lr 5.917136e-04:  15%|█▍        | 2448/16329 [20:40<2:06:20,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2448: train loss 2.94476. lr 5.917136e-04:  15%|█▍        | 2449/16329 [20:40<2:02:53,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2449: train loss 2.97232. lr 5.917069e-04:  15%|█▍        | 2449/16329 [20:40<2:02:53,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2449: train loss 2.97232. lr 5.917069e-04:  15%|█▌        | 2450/16329 [20:40<2:00:32,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2450: train loss 2.99859. lr 5.917002e-04:  15%|█▌        | 2450/16329 [20:41<2:00:32,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2450: train loss 2.99859. lr 5.917002e-04:  15%|█▌        | 2451/16329 [20:41<1:59:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2451: train loss 2.86623. lr 5.916934e-04:  15%|█▌        | 2451/16329 [20:41<1:59:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2451: train loss 2.86623. lr 5.916934e-04:  15%|█▌        | 2452/16329 [20:41<1:57:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2452: train loss 2.99472. lr 5.916867e-04:  15%|█▌        | 2452/16329 [20:42<1:57:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2452: train loss 2.99472. lr 5.916867e-04:  15%|█▌        | 2453/16329 [20:42<1:56:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2453: train loss 3.00346. lr 5.916799e-04:  15%|█▌        | 2453/16329 [20:42<1:56:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2453: train loss 3.00346. lr 5.916799e-04:  15%|█▌        | 2454/16329 [20:42<1:55:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2454: train loss 3.04565. lr 5.916732e-04:  15%|█▌        | 2454/16329 [20:43<1:55:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2454: train loss 3.04565. lr 5.916732e-04:  15%|█▌        | 2455/16329 [20:43<1:55:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2455: train loss 2.96055. lr 5.916664e-04:  15%|█▌        | 2455/16329 [20:43<1:55:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2455: train loss 2.96055. lr 5.916664e-04:  15%|█▌        | 2456/16329 [20:43<1:55:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2456: train loss 3.04045. lr 5.916597e-04:  15%|█▌        | 2456/16329 [20:44<1:55:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2456: train loss 3.04045. lr 5.916597e-04:  15%|█▌        | 2457/16329 [20:44<1:54:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2457: train loss 2.97076. lr 5.916529e-04:  15%|█▌        | 2457/16329 [20:44<1:54:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2457: train loss 2.97076. lr 5.916529e-04:  15%|█▌        | 2458/16329 [20:44<1:54:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2458: train loss 2.99094. lr 5.916462e-04:  15%|█▌        | 2458/16329 [20:45<1:54:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2458: train loss 2.99094. lr 5.916462e-04:  15%|█▌        | 2459/16329 [20:45<1:54:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2459: train loss 2.99661. lr 5.916394e-04:  15%|█▌        | 2459/16329 [20:45<1:54:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2459: train loss 2.99661. lr 5.916394e-04:  15%|█▌        | 2460/16329 [20:45<1:54:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2460: train loss 3.01567. lr 5.916326e-04:  15%|█▌        | 2460/16329 [20:46<1:54:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2460: train loss 3.01567. lr 5.916326e-04:  15%|█▌        | 2461/16329 [20:46<1:55:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2461: train loss 3.00214. lr 5.916258e-04:  15%|█▌        | 2461/16329 [20:46<1:55:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2461: train loss 3.00214. lr 5.916258e-04:  15%|█▌        | 2462/16329 [20:46<1:54:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2462: train loss 3.02847. lr 5.916191e-04:  15%|█▌        | 2462/16329 [20:47<1:54:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2462: train loss 3.02847. lr 5.916191e-04:  15%|█▌        | 2463/16329 [20:47<1:54:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2463: train loss 2.97568. lr 5.916123e-04:  15%|█▌        | 2463/16329 [20:47<1:54:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2463: train loss 2.97568. lr 5.916123e-04:  15%|█▌        | 2464/16329 [20:47<1:54:29,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2464: train loss 2.97205. lr 5.916055e-04:  15%|█▌        | 2464/16329 [20:48<1:54:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2464: train loss 2.97205. lr 5.916055e-04:  15%|█▌        | 2465/16329 [20:48<1:54:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2465: train loss 3.00744. lr 5.915987e-04:  15%|█▌        | 2465/16329 [20:48<1:54:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2465: train loss 3.00744. lr 5.915987e-04:  15%|█▌        | 2466/16329 [20:48<1:54:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2466: train loss 2.97335. lr 5.915920e-04:  15%|█▌        | 2466/16329 [20:49<1:54:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2466: train loss 2.97335. lr 5.915920e-04:  15%|█▌        | 2467/16329 [20:49<1:53:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2467: train loss 2.98777. lr 5.915852e-04:  15%|█▌        | 2467/16329 [20:49<1:53:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2467: train loss 2.98777. lr 5.915852e-04:  15%|█▌        | 2468/16329 [20:49<1:54:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2468: train loss 3.01447. lr 5.915784e-04:  15%|█▌        | 2468/16329 [20:50<1:54:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2468: train loss 3.01447. lr 5.915784e-04:  15%|█▌        | 2469/16329 [20:50<1:54:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2469: train loss 3.01493. lr 5.915716e-04:  15%|█▌        | 2469/16329 [20:50<1:54:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2469: train loss 3.01493. lr 5.915716e-04:  15%|█▌        | 2470/16329 [20:50<1:54:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2470: train loss 2.96153. lr 5.915648e-04:  15%|█▌        | 2470/16329 [20:51<1:54:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2470: train loss 2.96153. lr 5.915648e-04:  15%|█▌        | 2471/16329 [20:51<1:54:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2471: train loss 3.00228. lr 5.915580e-04:  15%|█▌        | 2471/16329 [20:51<1:54:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2471: train loss 3.00228. lr 5.915580e-04:  15%|█▌        | 2472/16329 [20:51<1:53:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2472: train loss 2.93988. lr 5.915512e-04:  15%|█▌        | 2472/16329 [20:52<1:53:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2472: train loss 2.93988. lr 5.915512e-04:  15%|█▌        | 2473/16329 [20:52<1:53:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2473: train loss 2.97363. lr 5.915444e-04:  15%|█▌        | 2473/16329 [20:52<1:53:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2473: train loss 2.97363. lr 5.915444e-04:  15%|█▌        | 2474/16329 [20:52<1:53:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2474: train loss 3.01251. lr 5.915376e-04:  15%|█▌        | 2474/16329 [20:53<1:53:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2474: train loss 3.01251. lr 5.915376e-04:  15%|█▌        | 2475/16329 [20:53<1:54:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2475: train loss 2.96889. lr 5.915308e-04:  15%|█▌        | 2475/16329 [20:53<1:54:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2475: train loss 2.96889. lr 5.915308e-04:  15%|█▌        | 2476/16329 [20:53<1:54:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2476: train loss 2.95113. lr 5.915240e-04:  15%|█▌        | 2476/16329 [20:54<1:54:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2476: train loss 2.95113. lr 5.915240e-04:  15%|█▌        | 2477/16329 [20:54<1:53:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2477: train loss 2.96883. lr 5.915172e-04:  15%|█▌        | 2477/16329 [20:54<1:53:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2477: train loss 2.96883. lr 5.915172e-04:  15%|█▌        | 2478/16329 [20:54<1:54:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2478: train loss 2.99477. lr 5.915103e-04:  15%|█▌        | 2478/16329 [20:55<1:54:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2478: train loss 2.99477. lr 5.915103e-04:  15%|█▌        | 2479/16329 [20:55<1:53:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2479: train loss 3.07671. lr 5.915035e-04:  15%|█▌        | 2479/16329 [20:55<1:53:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2479: train loss 3.07671. lr 5.915035e-04:  15%|█▌        | 2480/16329 [20:55<1:54:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2480: train loss 2.99592. lr 5.914967e-04:  15%|█▌        | 2480/16329 [20:56<1:54:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2480: train loss 2.99592. lr 5.914967e-04:  15%|█▌        | 2481/16329 [20:56<1:53:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2481: train loss 2.99695. lr 5.914899e-04:  15%|█▌        | 2481/16329 [20:56<1:53:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2481: train loss 2.99695. lr 5.914899e-04:  15%|█▌        | 2482/16329 [20:56<1:54:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2482: train loss 3.02280. lr 5.914831e-04:  15%|█▌        | 2482/16329 [20:57<1:54:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2482: train loss 3.02280. lr 5.914831e-04:  15%|█▌        | 2483/16329 [20:57<2:08:26,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 2483: train loss 2.87491. lr 5.914762e-04:  15%|█▌        | 2483/16329 [20:57<2:08:26,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 2483: train loss 2.87491. lr 5.914762e-04:  15%|█▌        | 2484/16329 [20:57<2:03:43,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2484: train loss 2.94893. lr 5.914694e-04:  15%|█▌        | 2484/16329 [20:58<2:03:43,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2484: train loss 2.94893. lr 5.914694e-04:  15%|█▌        | 2485/16329 [20:58<2:00:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2485: train loss 2.99475. lr 5.914626e-04:  15%|█▌        | 2485/16329 [20:58<2:00:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2485: train loss 2.99475. lr 5.914626e-04:  15%|█▌        | 2486/16329 [20:58<1:58:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2486: train loss 2.92406. lr 5.914557e-04:  15%|█▌        | 2486/16329 [20:59<1:58:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2486: train loss 2.92406. lr 5.914557e-04:  15%|█▌        | 2487/16329 [20:59<1:57:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2487: train loss 2.95099. lr 5.914489e-04:  15%|█▌        | 2487/16329 [20:59<1:57:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2487: train loss 2.95099. lr 5.914489e-04:  15%|█▌        | 2488/16329 [20:59<1:56:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2488: train loss 2.94091. lr 5.914420e-04:  15%|█▌        | 2488/16329 [21:00<1:56:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2488: train loss 2.94091. lr 5.914420e-04:  15%|█▌        | 2489/16329 [21:00<1:56:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2489: train loss 2.98037. lr 5.914352e-04:  15%|█▌        | 2489/16329 [21:00<1:56:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2489: train loss 2.98037. lr 5.914352e-04:  15%|█▌        | 2490/16329 [21:00<1:56:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2490: train loss 2.99798. lr 5.914283e-04:  15%|█▌        | 2490/16329 [21:01<1:56:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2490: train loss 2.99798. lr 5.914283e-04:  15%|█▌        | 2491/16329 [21:01<1:55:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2491: train loss 2.95908. lr 5.914215e-04:  15%|█▌        | 2491/16329 [21:01<1:55:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2491: train loss 2.95908. lr 5.914215e-04:  15%|█▌        | 2492/16329 [21:01<1:55:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2492: train loss 2.87825. lr 5.914146e-04:  15%|█▌        | 2492/16329 [21:02<1:55:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2492: train loss 2.87825. lr 5.914146e-04:  15%|█▌        | 2493/16329 [21:02<1:54:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2493: train loss 2.96604. lr 5.914078e-04:  15%|█▌        | 2493/16329 [21:02<1:54:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2493: train loss 2.96604. lr 5.914078e-04:  15%|█▌        | 2494/16329 [21:02<1:54:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2494: train loss 2.96608. lr 5.914009e-04:  15%|█▌        | 2494/16329 [21:03<1:54:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2494: train loss 2.96608. lr 5.914009e-04:  15%|█▌        | 2495/16329 [21:03<1:54:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2495: train loss 3.01435. lr 5.913941e-04:  15%|█▌        | 2495/16329 [21:03<1:54:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2495: train loss 3.01435. lr 5.913941e-04:  15%|█▌        | 2496/16329 [21:03<1:53:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2496: train loss 2.97813. lr 5.913872e-04:  15%|█▌        | 2496/16329 [21:04<1:53:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2496: train loss 2.97813. lr 5.913872e-04:  15%|█▌        | 2497/16329 [21:04<1:53:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2497: train loss 2.96211. lr 5.913803e-04:  15%|█▌        | 2497/16329 [21:04<1:53:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2497: train loss 2.96211. lr 5.913803e-04:  15%|█▌        | 2498/16329 [21:04<1:53:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2498: train loss 2.97370. lr 5.913735e-04:  15%|█▌        | 2498/16329 [21:05<1:53:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2498: train loss 2.97370. lr 5.913735e-04:  15%|█▌        | 2499/16329 [21:05<1:54:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2499: train loss 2.97723. lr 5.913666e-04:  15%|█▌        | 2499/16329 [21:05<1:54:06,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2499: train loss 2.97723. lr 5.913666e-04:  15%|█▌        | 2500/16329 [21:05<1:53:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2500: train loss 2.92384. lr 5.913597e-04:  15%|█▌        | 2500/16329 [21:06<1:53:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2500: train loss 2.92384. lr 5.913597e-04:  15%|█▌        | 2501/16329 [21:06<1:53:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2501: train loss 2.91686. lr 5.913528e-04:  15%|█▌        | 2501/16329 [21:06<1:53:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2501: train loss 2.91686. lr 5.913528e-04:  15%|█▌        | 2502/16329 [21:06<1:53:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2502: train loss 2.92749. lr 5.913460e-04:  15%|█▌        | 2502/16329 [21:07<1:53:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2502: train loss 2.92749. lr 5.913460e-04:  15%|█▌        | 2503/16329 [21:07<1:53:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2503: train loss 2.97610. lr 5.913391e-04:  15%|█▌        | 2503/16329 [21:07<1:53:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2503: train loss 2.97610. lr 5.913391e-04:  15%|█▌        | 2504/16329 [21:07<1:53:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2504: train loss 2.96041. lr 5.913322e-04:  15%|█▌        | 2504/16329 [21:08<1:53:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2504: train loss 2.96041. lr 5.913322e-04:  15%|█▌        | 2505/16329 [21:08<1:53:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2505: train loss 2.98309. lr 5.913253e-04:  15%|█▌        | 2505/16329 [21:08<1:53:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2505: train loss 2.98309. lr 5.913253e-04:  15%|█▌        | 2506/16329 [21:08<1:53:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2506: train loss 3.03642. lr 5.913184e-04:  15%|█▌        | 2506/16329 [21:09<1:53:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2506: train loss 3.03642. lr 5.913184e-04:  15%|█▌        | 2507/16329 [21:09<1:54:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2507: train loss 2.95422. lr 5.913115e-04:  15%|█▌        | 2507/16329 [21:09<1:54:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2507: train loss 2.95422. lr 5.913115e-04:  15%|█▌        | 2508/16329 [21:09<2:07:26,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2508: train loss 2.93281. lr 5.913046e-04:  15%|█▌        | 2508/16329 [21:10<2:07:26,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2508: train loss 2.93281. lr 5.913046e-04:  15%|█▌        | 2509/16329 [21:10<2:03:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2509: train loss 2.90791. lr 5.912977e-04:  15%|█▌        | 2509/16329 [21:10<2:03:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 2509: train loss 2.90791. lr 5.912977e-04:  15%|█▌        | 2510/16329 [21:10<2:00:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2510: train loss 2.91187. lr 5.912908e-04:  15%|█▌        | 2510/16329 [21:11<2:00:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2510: train loss 2.91187. lr 5.912908e-04:  15%|█▌        | 2511/16329 [21:11<1:58:25,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2511: train loss 2.96870. lr 5.912839e-04:  15%|█▌        | 2511/16329 [21:11<1:58:25,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2511: train loss 2.96870. lr 5.912839e-04:  15%|█▌        | 2512/16329 [21:11<1:57:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2512: train loss 2.96348. lr 5.912770e-04:  15%|█▌        | 2512/16329 [21:12<1:57:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2512: train loss 2.96348. lr 5.912770e-04:  15%|█▌        | 2513/16329 [21:12<1:56:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2513: train loss 2.97152. lr 5.912701e-04:  15%|█▌        | 2513/16329 [21:12<1:56:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2513: train loss 2.97152. lr 5.912701e-04:  15%|█▌        | 2514/16329 [21:12<1:55:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2514: train loss 2.94420. lr 5.912632e-04:  15%|█▌        | 2514/16329 [21:13<1:55:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2514: train loss 2.94420. lr 5.912632e-04:  15%|█▌        | 2515/16329 [21:13<1:54:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2515: train loss 2.91785. lr 5.912563e-04:  15%|█▌        | 2515/16329 [21:13<1:54:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2515: train loss 2.91785. lr 5.912563e-04:  15%|█▌        | 2516/16329 [21:13<1:54:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2516: train loss 2.95457. lr 5.912493e-04:  15%|█▌        | 2516/16329 [21:14<1:54:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2516: train loss 2.95457. lr 5.912493e-04:  15%|█▌        | 2517/16329 [21:14<1:54:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2517: train loss 2.98573. lr 5.912424e-04:  15%|█▌        | 2517/16329 [21:14<1:54:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2517: train loss 2.98573. lr 5.912424e-04:  15%|█▌        | 2518/16329 [21:14<1:54:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2518: train loss 3.04938. lr 5.912355e-04:  15%|█▌        | 2518/16329 [21:15<1:54:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2518: train loss 3.04938. lr 5.912355e-04:  15%|█▌        | 2519/16329 [21:15<1:54:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2519: train loss 2.97166. lr 5.912286e-04:  15%|█▌        | 2519/16329 [21:15<1:54:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2519: train loss 2.97166. lr 5.912286e-04:  15%|█▌        | 2520/16329 [21:15<1:54:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2520: train loss 2.99907. lr 5.912216e-04:  15%|█▌        | 2520/16329 [21:16<1:54:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2520: train loss 2.99907. lr 5.912216e-04:  15%|█▌        | 2521/16329 [21:16<1:54:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2521: train loss 2.93263. lr 5.912147e-04:  15%|█▌        | 2521/16329 [21:16<1:54:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2521: train loss 2.93263. lr 5.912147e-04:  15%|█▌        | 2522/16329 [21:16<1:53:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2522: train loss 2.92487. lr 5.912078e-04:  15%|█▌        | 2522/16329 [21:17<1:53:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2522: train loss 2.92487. lr 5.912078e-04:  15%|█▌        | 2523/16329 [21:17<1:53:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2523: train loss 2.89442. lr 5.912008e-04:  15%|█▌        | 2523/16329 [21:17<1:53:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2523: train loss 2.89442. lr 5.912008e-04:  15%|█▌        | 2524/16329 [21:17<1:53:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2524: train loss 3.02231. lr 5.911939e-04:  15%|█▌        | 2524/16329 [21:18<1:53:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2524: train loss 3.02231. lr 5.911939e-04:  15%|█▌        | 2525/16329 [21:18<1:53:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2525: train loss 2.86876. lr 5.911870e-04:  15%|█▌        | 2525/16329 [21:18<1:53:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2525: train loss 2.86876. lr 5.911870e-04:  15%|█▌        | 2526/16329 [21:18<1:53:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2526: train loss 2.99788. lr 5.911800e-04:  15%|█▌        | 2526/16329 [21:19<1:53:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2526: train loss 2.99788. lr 5.911800e-04:  15%|█▌        | 2527/16329 [21:19<1:53:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2527: train loss 2.93697. lr 5.911731e-04:  15%|█▌        | 2527/16329 [21:19<1:53:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2527: train loss 2.93697. lr 5.911731e-04:  15%|█▌        | 2528/16329 [21:19<1:53:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2528: train loss 2.94729. lr 5.911661e-04:  15%|█▌        | 2528/16329 [21:20<1:53:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2528: train loss 2.94729. lr 5.911661e-04:  15%|█▌        | 2529/16329 [21:20<1:53:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2529: train loss 2.89274. lr 5.911592e-04:  15%|█▌        | 2529/16329 [21:20<1:53:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2529: train loss 2.89274. lr 5.911592e-04:  15%|█▌        | 2530/16329 [21:20<1:53:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2530: train loss 2.97906. lr 5.911522e-04:  15%|█▌        | 2530/16329 [21:21<1:53:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2530: train loss 2.97906. lr 5.911522e-04:  16%|█▌        | 2531/16329 [21:21<1:53:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2531: train loss 2.92494. lr 5.911452e-04:  16%|█▌        | 2531/16329 [21:21<1:53:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2531: train loss 2.92494. lr 5.911452e-04:  16%|█▌        | 2532/16329 [21:21<1:53:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2532: train loss 2.89078. lr 5.911383e-04:  16%|█▌        | 2532/16329 [21:22<1:53:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2532: train loss 2.89078. lr 5.911383e-04:  16%|█▌        | 2533/16329 [21:22<1:53:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2533: train loss 2.95140. lr 5.911313e-04:  16%|█▌        | 2533/16329 [21:22<1:53:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2533: train loss 2.95140. lr 5.911313e-04:  16%|█▌        | 2534/16329 [21:22<1:53:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2534: train loss 2.98893. lr 5.911244e-04:  16%|█▌        | 2534/16329 [21:23<1:53:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2534: train loss 2.98893. lr 5.911244e-04:  16%|█▌        | 2535/16329 [21:23<2:05:39,  1.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2535: train loss 2.92853. lr 5.911174e-04:  16%|█▌        | 2535/16329 [21:23<2:05:39,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2535: train loss 2.92853. lr 5.911174e-04:  16%|█▌        | 2536/16329 [21:23<2:02:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2536: train loss 2.92519. lr 5.911104e-04:  16%|█▌        | 2536/16329 [21:24<2:02:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2536: train loss 2.92519. lr 5.911104e-04:  16%|█▌        | 2537/16329 [21:24<1:59:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2537: train loss 2.93142. lr 5.911034e-04:  16%|█▌        | 2537/16329 [21:24<1:59:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2537: train loss 2.93142. lr 5.911034e-04:  16%|█▌        | 2538/16329 [21:24<1:57:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2538: train loss 2.88920. lr 5.910965e-04:  16%|█▌        | 2538/16329 [21:25<1:57:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2538: train loss 2.88920. lr 5.910965e-04:  16%|█▌        | 2539/16329 [21:25<1:56:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2539: train loss 3.00669. lr 5.910895e-04:  16%|█▌        | 2539/16329 [21:25<1:56:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2539: train loss 3.00669. lr 5.910895e-04:  16%|█▌        | 2540/16329 [21:25<1:55:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2540: train loss 2.91968. lr 5.910825e-04:  16%|█▌        | 2540/16329 [21:26<1:55:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2540: train loss 2.91968. lr 5.910825e-04:  16%|█▌        | 2541/16329 [21:26<1:57:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2541: train loss 3.00579. lr 5.910755e-04:  16%|█▌        | 2541/16329 [21:26<1:57:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2541: train loss 3.00579. lr 5.910755e-04:  16%|█▌        | 2542/16329 [21:26<1:58:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2542: train loss 2.92554. lr 5.910685e-04:  16%|█▌        | 2542/16329 [21:27<1:58:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2542: train loss 2.92554. lr 5.910685e-04:  16%|█▌        | 2543/16329 [21:27<1:58:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2543: train loss 2.98800. lr 5.910615e-04:  16%|█▌        | 2543/16329 [21:27<1:58:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2543: train loss 2.98800. lr 5.910615e-04:  16%|█▌        | 2544/16329 [21:27<1:58:14,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2544: train loss 2.92244. lr 5.910545e-04:  16%|█▌        | 2544/16329 [21:28<1:58:14,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2544: train loss 2.92244. lr 5.910545e-04:  16%|█▌        | 2545/16329 [21:28<1:57:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2545: train loss 2.99497. lr 5.910475e-04:  16%|█▌        | 2545/16329 [21:28<1:57:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2545: train loss 2.99497. lr 5.910475e-04:  16%|█▌        | 2546/16329 [21:28<1:56:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2546: train loss 2.92852. lr 5.910405e-04:  16%|█▌        | 2546/16329 [21:29<1:56:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2546: train loss 2.92852. lr 5.910405e-04:  16%|█▌        | 2547/16329 [21:29<1:56:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2547: train loss 2.99764. lr 5.910335e-04:  16%|█▌        | 2547/16329 [21:29<1:56:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2547: train loss 2.99764. lr 5.910335e-04:  16%|█▌        | 2548/16329 [21:29<1:55:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2548: train loss 2.91737. lr 5.910265e-04:  16%|█▌        | 2548/16329 [21:30<1:55:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2548: train loss 2.91737. lr 5.910265e-04:  16%|█▌        | 2549/16329 [21:30<1:54:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2549: train loss 2.95491. lr 5.910195e-04:  16%|█▌        | 2549/16329 [21:30<1:54:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2549: train loss 2.95491. lr 5.910195e-04:  16%|█▌        | 2550/16329 [21:30<1:54:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2550: train loss 2.92163. lr 5.910125e-04:  16%|█▌        | 2550/16329 [21:31<1:54:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2550: train loss 2.92163. lr 5.910125e-04:  16%|█▌        | 2551/16329 [21:31<1:53:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2551: train loss 2.97648. lr 5.910055e-04:  16%|█▌        | 2551/16329 [21:31<1:53:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2551: train loss 2.97648. lr 5.910055e-04:  16%|█▌        | 2552/16329 [21:31<1:53:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2552: train loss 2.94699. lr 5.909985e-04:  16%|█▌        | 2552/16329 [21:32<1:53:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2552: train loss 2.94699. lr 5.909985e-04:  16%|█▌        | 2553/16329 [21:32<1:53:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2553: train loss 3.01404. lr 5.909915e-04:  16%|█▌        | 2553/16329 [21:32<1:53:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2553: train loss 3.01404. lr 5.909915e-04:  16%|█▌        | 2554/16329 [21:32<1:53:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2554: train loss 2.85134. lr 5.909845e-04:  16%|█▌        | 2554/16329 [21:33<1:53:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2554: train loss 2.85134. lr 5.909845e-04:  16%|█▌        | 2555/16329 [21:33<1:53:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2555: train loss 2.92758. lr 5.909774e-04:  16%|█▌        | 2555/16329 [21:33<1:53:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2555: train loss 2.92758. lr 5.909774e-04:  16%|█▌        | 2556/16329 [21:33<1:53:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2556: train loss 2.96082. lr 5.909704e-04:  16%|█▌        | 2556/16329 [21:34<1:53:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2556: train loss 2.96082. lr 5.909704e-04:  16%|█▌        | 2557/16329 [21:34<1:53:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2557: train loss 2.92726. lr 5.909634e-04:  16%|█▌        | 2557/16329 [21:34<1:53:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2557: train loss 2.92726. lr 5.909634e-04:  16%|█▌        | 2558/16329 [21:34<1:52:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2558: train loss 2.93974. lr 5.909563e-04:  16%|█▌        | 2558/16329 [21:35<1:52:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2558: train loss 2.93974. lr 5.909563e-04:  16%|█▌        | 2559/16329 [21:35<1:53:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2559: train loss 2.92390. lr 5.909493e-04:  16%|█▌        | 2559/16329 [21:35<1:53:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2559: train loss 2.92390. lr 5.909493e-04:  16%|█▌        | 2560/16329 [21:35<1:53:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2560: train loss 2.91021. lr 5.909423e-04:  16%|█▌        | 2560/16329 [21:36<1:53:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2560: train loss 2.91021. lr 5.909423e-04:  16%|█▌        | 2561/16329 [21:36<1:53:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2561: train loss 2.95983. lr 5.909352e-04:  16%|█▌        | 2561/16329 [21:36<1:53:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2561: train loss 2.95983. lr 5.909352e-04:  16%|█▌        | 2562/16329 [21:36<1:53:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2562: train loss 2.83595. lr 5.909282e-04:  16%|█▌        | 2562/16329 [21:37<1:53:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2562: train loss 2.83595. lr 5.909282e-04:  16%|█▌        | 2563/16329 [21:37<1:53:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2563: train loss 2.87462. lr 5.909211e-04:  16%|█▌        | 2563/16329 [21:37<1:53:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2563: train loss 2.87462. lr 5.909211e-04:  16%|█▌        | 2564/16329 [21:37<1:53:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2564: train loss 2.81725. lr 5.909141e-04:  16%|█▌        | 2564/16329 [21:38<1:53:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2564: train loss 2.81725. lr 5.909141e-04:  16%|█▌        | 2565/16329 [21:38<1:53:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2565: train loss 2.92129. lr 5.909070e-04:  16%|█▌        | 2565/16329 [21:38<1:53:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2565: train loss 2.92129. lr 5.909070e-04:  16%|█▌        | 2566/16329 [21:38<1:53:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2566: train loss 2.96967. lr 5.909000e-04:  16%|█▌        | 2566/16329 [21:39<1:53:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2566: train loss 2.96967. lr 5.909000e-04:  16%|█▌        | 2567/16329 [21:39<1:53:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2567: train loss 2.91110. lr 5.908929e-04:  16%|█▌        | 2567/16329 [21:39<1:53:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2567: train loss 2.91110. lr 5.908929e-04:  16%|█▌        | 2568/16329 [21:39<1:53:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2568: train loss 2.96989. lr 5.908859e-04:  16%|█▌        | 2568/16329 [21:40<1:53:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2568: train loss 2.96989. lr 5.908859e-04:  16%|█▌        | 2569/16329 [21:40<1:53:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2569: train loss 2.91575. lr 5.908788e-04:  16%|█▌        | 2569/16329 [21:40<1:53:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2569: train loss 2.91575. lr 5.908788e-04:  16%|█▌        | 2570/16329 [21:40<1:52:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2570: train loss 3.01409. lr 5.908718e-04:  16%|█▌        | 2570/16329 [21:41<1:52:51,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2570: train loss 3.01409. lr 5.908718e-04:  16%|█▌        | 2571/16329 [21:41<1:53:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2571: train loss 2.91295. lr 5.908647e-04:  16%|█▌        | 2571/16329 [21:41<1:53:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2571: train loss 2.91295. lr 5.908647e-04:  16%|█▌        | 2572/16329 [21:41<1:53:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2572: train loss 2.99866. lr 5.908576e-04:  16%|█▌        | 2572/16329 [21:42<1:53:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2572: train loss 2.99866. lr 5.908576e-04:  16%|█▌        | 2573/16329 [21:42<1:53:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2573: train loss 2.84753. lr 5.908505e-04:  16%|█▌        | 2573/16329 [21:42<1:53:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2573: train loss 2.84753. lr 5.908505e-04:  16%|█▌        | 2574/16329 [21:42<1:53:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2574: train loss 2.95952. lr 5.908435e-04:  16%|█▌        | 2574/16329 [21:43<1:53:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2574: train loss 2.95952. lr 5.908435e-04:  16%|█▌        | 2575/16329 [21:43<2:04:52,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2575: train loss 2.96245. lr 5.908364e-04:  16%|█▌        | 2575/16329 [21:43<2:04:52,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2575: train loss 2.96245. lr 5.908364e-04:  16%|█▌        | 2576/16329 [21:43<2:01:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2576: train loss 2.92952. lr 5.908293e-04:  16%|█▌        | 2576/16329 [21:44<2:01:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2576: train loss 2.92952. lr 5.908293e-04:  16%|█▌        | 2577/16329 [21:44<1:58:58,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2577: train loss 2.96713. lr 5.908222e-04:  16%|█▌        | 2577/16329 [21:44<1:58:58,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2577: train loss 2.96713. lr 5.908222e-04:  16%|█▌        | 2578/16329 [21:44<1:57:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2578: train loss 2.84605. lr 5.908151e-04:  16%|█▌        | 2578/16329 [21:45<1:57:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2578: train loss 2.84605. lr 5.908151e-04:  16%|█▌        | 2579/16329 [21:45<1:56:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2579: train loss 2.92312. lr 5.908081e-04:  16%|█▌        | 2579/16329 [21:45<1:56:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2579: train loss 2.92312. lr 5.908081e-04:  16%|█▌        | 2580/16329 [21:45<1:54:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2580: train loss 2.90895. lr 5.908010e-04:  16%|█▌        | 2580/16329 [21:46<1:54:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2580: train loss 2.90895. lr 5.908010e-04:  16%|█▌        | 2581/16329 [21:46<1:54:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2581: train loss 2.94252. lr 5.907939e-04:  16%|█▌        | 2581/16329 [21:46<1:54:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2581: train loss 2.94252. lr 5.907939e-04:  16%|█▌        | 2582/16329 [21:46<1:53:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2582: train loss 2.97385. lr 5.907868e-04:  16%|█▌        | 2582/16329 [21:47<1:53:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2582: train loss 2.97385. lr 5.907868e-04:  16%|█▌        | 2583/16329 [21:47<1:53:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2583: train loss 2.90804. lr 5.907797e-04:  16%|█▌        | 2583/16329 [21:47<1:53:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2583: train loss 2.90804. lr 5.907797e-04:  16%|█▌        | 2584/16329 [21:47<1:53:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2584: train loss 2.89238. lr 5.907726e-04:  16%|█▌        | 2584/16329 [21:48<1:53:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2584: train loss 2.89238. lr 5.907726e-04:  16%|█▌        | 2585/16329 [21:48<1:52:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2585: train loss 2.89357. lr 5.907655e-04:  16%|█▌        | 2585/16329 [21:48<1:52:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2585: train loss 2.89357. lr 5.907655e-04:  16%|█▌        | 2586/16329 [21:48<1:53:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2586: train loss 2.87490. lr 5.907584e-04:  16%|█▌        | 2586/16329 [21:49<1:53:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2586: train loss 2.87490. lr 5.907584e-04:  16%|█▌        | 2587/16329 [21:49<1:52:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2587: train loss 2.92171. lr 5.907513e-04:  16%|█▌        | 2587/16329 [21:49<1:52:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2587: train loss 2.92171. lr 5.907513e-04:  16%|█▌        | 2588/16329 [21:49<1:53:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2588: train loss 2.91775. lr 5.907441e-04:  16%|█▌        | 2588/16329 [21:50<1:53:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2588: train loss 2.91775. lr 5.907441e-04:  16%|█▌        | 2589/16329 [21:50<1:53:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2589: train loss 2.90445. lr 5.907370e-04:  16%|█▌        | 2589/16329 [21:50<1:53:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2589: train loss 2.90445. lr 5.907370e-04:  16%|█▌        | 2590/16329 [21:50<1:52:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2590: train loss 2.90436. lr 5.907299e-04:  16%|█▌        | 2590/16329 [21:51<1:52:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2590: train loss 2.90436. lr 5.907299e-04:  16%|█▌        | 2591/16329 [21:51<1:52:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2591: train loss 2.94961. lr 5.907228e-04:  16%|█▌        | 2591/16329 [21:51<1:52:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2591: train loss 2.94961. lr 5.907228e-04:  16%|█▌        | 2592/16329 [21:51<1:52:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2592: train loss 2.88051. lr 5.907157e-04:  16%|█▌        | 2592/16329 [21:52<1:52:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2592: train loss 2.88051. lr 5.907157e-04:  16%|█▌        | 2593/16329 [21:52<1:53:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2593: train loss 2.92322. lr 5.907085e-04:  16%|█▌        | 2593/16329 [21:52<1:53:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2593: train loss 2.92322. lr 5.907085e-04:  16%|█▌        | 2594/16329 [21:52<1:53:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2594: train loss 2.92842. lr 5.907014e-04:  16%|█▌        | 2594/16329 [21:53<1:53:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2594: train loss 2.92842. lr 5.907014e-04:  16%|█▌        | 2595/16329 [21:53<1:52:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2595: train loss 2.86111. lr 5.906943e-04:  16%|█▌        | 2595/16329 [21:53<1:52:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2595: train loss 2.86111. lr 5.906943e-04:  16%|█▌        | 2596/16329 [21:53<1:52:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2596: train loss 2.87339. lr 5.906872e-04:  16%|█▌        | 2596/16329 [21:54<1:52:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2596: train loss 2.87339. lr 5.906872e-04:  16%|█▌        | 2597/16329 [21:54<1:52:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2597: train loss 2.91232. lr 5.906800e-04:  16%|█▌        | 2597/16329 [21:54<1:52:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2597: train loss 2.91232. lr 5.906800e-04:  16%|█▌        | 2598/16329 [21:54<1:53:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2598: train loss 2.90922. lr 5.906729e-04:  16%|█▌        | 2598/16329 [21:55<1:53:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2598: train loss 2.90922. lr 5.906729e-04:  16%|█▌        | 2599/16329 [21:55<1:53:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2599: train loss 2.97408. lr 5.906657e-04:  16%|█▌        | 2599/16329 [21:55<1:53:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2599: train loss 2.97408. lr 5.906657e-04:  16%|█▌        | 2600/16329 [21:55<1:52:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2600: train loss 2.90107. lr 5.906586e-04:  16%|█▌        | 2600/16329 [21:56<1:52:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2600: train loss 2.90107. lr 5.906586e-04:  16%|█▌        | 2601/16329 [21:56<1:56:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2601: train loss 2.88150. lr 5.906514e-04:  16%|█▌        | 2601/16329 [21:56<1:56:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2601: train loss 2.88150. lr 5.906514e-04:  16%|█▌        | 2602/16329 [21:56<1:58:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2602: train loss 2.93728. lr 5.906443e-04:  16%|█▌        | 2602/16329 [21:57<1:58:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2602: train loss 2.93728. lr 5.906443e-04:  16%|█▌        | 2603/16329 [21:57<1:59:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2603: train loss 2.92412. lr 5.906371e-04:  16%|█▌        | 2603/16329 [21:57<1:59:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2603: train loss 2.92412. lr 5.906371e-04:  16%|█▌        | 2604/16329 [21:57<1:59:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2604: train loss 2.88037. lr 5.906300e-04:  16%|█▌        | 2604/16329 [21:58<1:59:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2604: train loss 2.88037. lr 5.906300e-04:  16%|█▌        | 2605/16329 [21:58<1:58:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2605: train loss 2.87662. lr 5.906228e-04:  16%|█▌        | 2605/16329 [21:59<1:58:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2605: train loss 2.87662. lr 5.906228e-04:  16%|█▌        | 2606/16329 [21:59<2:03:38,  1.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2606: train loss 2.84416. lr 5.906157e-04:  16%|█▌        | 2606/16329 [21:59<2:03:38,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 2606: train loss 2.84416. lr 5.906157e-04:  16%|█▌        | 2607/16329 [21:59<2:05:21,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2607: train loss 2.94925. lr 5.906085e-04:  16%|█▌        | 2607/16329 [22:00<2:05:21,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2607: train loss 2.94925. lr 5.906085e-04:  16%|█▌        | 2608/16329 [22:00<2:05:26,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2608: train loss 2.96360. lr 5.906013e-04:  16%|█▌        | 2608/16329 [22:00<2:05:26,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2608: train loss 2.96360. lr 5.906013e-04:  16%|█▌        | 2609/16329 [22:00<2:04:17,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2609: train loss 2.93835. lr 5.905942e-04:  16%|█▌        | 2609/16329 [22:01<2:04:17,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2609: train loss 2.93835. lr 5.905942e-04:  16%|█▌        | 2610/16329 [22:01<2:14:06,  1.70it/s]\u001b[A\n",
      "epoch 1 iter 2610: train loss 2.90423. lr 5.905870e-04:  16%|█▌        | 2610/16329 [22:01<2:14:06,  1.70it/s]\u001b[A\n",
      "epoch 1 iter 2610: train loss 2.90423. lr 5.905870e-04:  16%|█▌        | 2611/16329 [22:01<2:08:52,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 2611: train loss 2.91313. lr 5.905798e-04:  16%|█▌        | 2611/16329 [22:02<2:08:52,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 2611: train loss 2.91313. lr 5.905798e-04:  16%|█▌        | 2612/16329 [22:02<2:04:50,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2612: train loss 2.88052. lr 5.905726e-04:  16%|█▌        | 2612/16329 [22:02<2:04:50,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2612: train loss 2.88052. lr 5.905726e-04:  16%|█▌        | 2613/16329 [22:02<2:01:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2613: train loss 2.90778. lr 5.905655e-04:  16%|█▌        | 2613/16329 [22:03<2:01:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2613: train loss 2.90778. lr 5.905655e-04:  16%|█▌        | 2614/16329 [22:03<1:59:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2614: train loss 2.83239. lr 5.905583e-04:  16%|█▌        | 2614/16329 [22:03<1:59:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2614: train loss 2.83239. lr 5.905583e-04:  16%|█▌        | 2615/16329 [22:03<1:57:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2615: train loss 2.91558. lr 5.905511e-04:  16%|█▌        | 2615/16329 [22:04<1:57:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2615: train loss 2.91558. lr 5.905511e-04:  16%|█▌        | 2616/16329 [22:04<1:55:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2616: train loss 2.93267. lr 5.905439e-04:  16%|█▌        | 2616/16329 [22:04<1:55:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2616: train loss 2.93267. lr 5.905439e-04:  16%|█▌        | 2617/16329 [22:04<1:55:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2617: train loss 2.86454. lr 5.905367e-04:  16%|█▌        | 2617/16329 [22:05<1:55:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2617: train loss 2.86454. lr 5.905367e-04:  16%|█▌        | 2618/16329 [22:05<1:54:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2618: train loss 2.94271. lr 5.905295e-04:  16%|█▌        | 2618/16329 [22:05<1:54:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2618: train loss 2.94271. lr 5.905295e-04:  16%|█▌        | 2619/16329 [22:05<1:53:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2619: train loss 2.94225. lr 5.905223e-04:  16%|█▌        | 2619/16329 [22:06<1:53:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2619: train loss 2.94225. lr 5.905223e-04:  16%|█▌        | 2620/16329 [22:06<1:53:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2620: train loss 2.90087. lr 5.905151e-04:  16%|█▌        | 2620/16329 [22:06<1:53:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2620: train loss 2.90087. lr 5.905151e-04:  16%|█▌        | 2621/16329 [22:06<1:52:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2621: train loss 2.85101. lr 5.905079e-04:  16%|█▌        | 2621/16329 [22:07<1:52:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2621: train loss 2.85101. lr 5.905079e-04:  16%|█▌        | 2622/16329 [22:07<1:52:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2622: train loss 2.85216. lr 5.905007e-04:  16%|█▌        | 2622/16329 [22:07<1:52:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2622: train loss 2.85216. lr 5.905007e-04:  16%|█▌        | 2623/16329 [22:07<1:52:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2623: train loss 2.87377. lr 5.904935e-04:  16%|█▌        | 2623/16329 [22:08<1:52:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2623: train loss 2.87377. lr 5.904935e-04:  16%|█▌        | 2624/16329 [22:08<1:52:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2624: train loss 2.86818. lr 5.904863e-04:  16%|█▌        | 2624/16329 [22:08<1:52:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2624: train loss 2.86818. lr 5.904863e-04:  16%|█▌        | 2625/16329 [22:08<1:52:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2625: train loss 2.87662. lr 5.904791e-04:  16%|█▌        | 2625/16329 [22:09<1:52:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2625: train loss 2.87662. lr 5.904791e-04:  16%|█▌        | 2626/16329 [22:09<1:52:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2626: train loss 2.78853. lr 5.904719e-04:  16%|█▌        | 2626/16329 [22:09<1:52:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2626: train loss 2.78853. lr 5.904719e-04:  16%|█▌        | 2627/16329 [22:09<1:52:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2627: train loss 2.88370. lr 5.904647e-04:  16%|█▌        | 2627/16329 [22:10<1:52:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2627: train loss 2.88370. lr 5.904647e-04:  16%|█▌        | 2628/16329 [22:10<1:52:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2628: train loss 2.89190. lr 5.904575e-04:  16%|█▌        | 2628/16329 [22:10<1:52:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2628: train loss 2.89190. lr 5.904575e-04:  16%|█▌        | 2629/16329 [22:10<1:52:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2629: train loss 2.93545. lr 5.904502e-04:  16%|█▌        | 2629/16329 [22:11<1:52:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2629: train loss 2.93545. lr 5.904502e-04:  16%|█▌        | 2630/16329 [22:11<1:52:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2630: train loss 2.88742. lr 5.904430e-04:  16%|█▌        | 2630/16329 [22:11<1:52:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2630: train loss 2.88742. lr 5.904430e-04:  16%|█▌        | 2631/16329 [22:11<1:52:00,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2631: train loss 2.89874. lr 5.904358e-04:  16%|█▌        | 2631/16329 [22:12<1:52:00,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2631: train loss 2.89874. lr 5.904358e-04:  16%|█▌        | 2632/16329 [22:12<1:52:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2632: train loss 2.88392. lr 5.904285e-04:  16%|█▌        | 2632/16329 [22:12<1:52:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2632: train loss 2.88392. lr 5.904285e-04:  16%|█▌        | 2633/16329 [22:12<1:52:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2633: train loss 2.87384. lr 5.904213e-04:  16%|█▌        | 2633/16329 [22:13<1:52:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2633: train loss 2.87384. lr 5.904213e-04:  16%|█▌        | 2634/16329 [22:13<1:52:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2634: train loss 2.89637. lr 5.904141e-04:  16%|█▌        | 2634/16329 [22:13<1:52:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2634: train loss 2.89637. lr 5.904141e-04:  16%|█▌        | 2635/16329 [22:13<2:04:38,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2635: train loss 2.94215. lr 5.904068e-04:  16%|█▌        | 2635/16329 [22:14<2:04:38,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2635: train loss 2.94215. lr 5.904068e-04:  16%|█▌        | 2636/16329 [22:14<2:00:32,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2636: train loss 2.85941. lr 5.903996e-04:  16%|█▌        | 2636/16329 [22:14<2:00:32,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2636: train loss 2.85941. lr 5.903996e-04:  16%|█▌        | 2637/16329 [22:14<1:58:19,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2637: train loss 2.80955. lr 5.903924e-04:  16%|█▌        | 2637/16329 [22:15<1:58:19,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2637: train loss 2.80955. lr 5.903924e-04:  16%|█▌        | 2638/16329 [22:15<1:56:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2638: train loss 2.85625. lr 5.903851e-04:  16%|█▌        | 2638/16329 [22:15<1:56:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2638: train loss 2.85625. lr 5.903851e-04:  16%|█▌        | 2639/16329 [22:15<1:55:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2639: train loss 2.97116. lr 5.903779e-04:  16%|█▌        | 2639/16329 [22:16<1:55:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2639: train loss 2.97116. lr 5.903779e-04:  16%|█▌        | 2640/16329 [22:16<1:54:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2640: train loss 2.84769. lr 5.903706e-04:  16%|█▌        | 2640/16329 [22:16<1:54:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2640: train loss 2.84769. lr 5.903706e-04:  16%|█▌        | 2641/16329 [22:16<1:53:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2641: train loss 2.88536. lr 5.903634e-04:  16%|█▌        | 2641/16329 [22:17<1:53:30,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2641: train loss 2.88536. lr 5.903634e-04:  16%|█▌        | 2642/16329 [22:17<1:53:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2642: train loss 2.81557. lr 5.903561e-04:  16%|█▌        | 2642/16329 [22:17<1:53:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2642: train loss 2.81557. lr 5.903561e-04:  16%|█▌        | 2643/16329 [22:17<1:53:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2643: train loss 2.91664. lr 5.903488e-04:  16%|█▌        | 2643/16329 [22:18<1:53:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2643: train loss 2.91664. lr 5.903488e-04:  16%|█▌        | 2644/16329 [22:18<1:54:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2644: train loss 2.81046. lr 5.903416e-04:  16%|█▌        | 2644/16329 [22:18<1:54:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2644: train loss 2.81046. lr 5.903416e-04:  16%|█▌        | 2645/16329 [22:18<1:53:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2645: train loss 2.91495. lr 5.903343e-04:  16%|█▌        | 2645/16329 [22:19<1:53:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2645: train loss 2.91495. lr 5.903343e-04:  16%|█▌        | 2646/16329 [22:19<1:52:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2646: train loss 2.91561. lr 5.903270e-04:  16%|█▌        | 2646/16329 [22:19<1:52:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2646: train loss 2.91561. lr 5.903270e-04:  16%|█▌        | 2647/16329 [22:19<1:53:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2647: train loss 2.91589. lr 5.903198e-04:  16%|█▌        | 2647/16329 [22:20<1:53:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2647: train loss 2.91589. lr 5.903198e-04:  16%|█▌        | 2648/16329 [22:20<1:52:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2648: train loss 2.82615. lr 5.903125e-04:  16%|█▌        | 2648/16329 [22:20<1:52:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2648: train loss 2.82615. lr 5.903125e-04:  16%|█▌        | 2649/16329 [22:20<1:52:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2649: train loss 2.92161. lr 5.903052e-04:  16%|█▌        | 2649/16329 [22:21<1:52:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2649: train loss 2.92161. lr 5.903052e-04:  16%|█▌        | 2650/16329 [22:21<1:52:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2650: train loss 2.91817. lr 5.902979e-04:  16%|█▌        | 2650/16329 [22:21<1:52:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2650: train loss 2.91817. lr 5.902979e-04:  16%|█▌        | 2651/16329 [22:21<1:52:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2651: train loss 2.92897. lr 5.902907e-04:  16%|█▌        | 2651/16329 [22:22<1:52:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2651: train loss 2.92897. lr 5.902907e-04:  16%|█▌        | 2652/16329 [22:22<1:52:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2652: train loss 2.88236. lr 5.902834e-04:  16%|█▌        | 2652/16329 [22:22<1:52:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2652: train loss 2.88236. lr 5.902834e-04:  16%|█▌        | 2653/16329 [22:22<1:52:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2653: train loss 2.87271. lr 5.902761e-04:  16%|█▌        | 2653/16329 [22:23<1:52:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2653: train loss 2.87271. lr 5.902761e-04:  16%|█▋        | 2654/16329 [22:23<1:52:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2654: train loss 2.89111. lr 5.902688e-04:  16%|█▋        | 2654/16329 [22:23<1:52:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2654: train loss 2.89111. lr 5.902688e-04:  16%|█▋        | 2655/16329 [22:23<1:52:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2655: train loss 2.82321. lr 5.902615e-04:  16%|█▋        | 2655/16329 [22:24<1:52:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2655: train loss 2.82321. lr 5.902615e-04:  16%|█▋        | 2656/16329 [22:24<1:52:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2656: train loss 2.92441. lr 5.902542e-04:  16%|█▋        | 2656/16329 [22:24<1:52:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2656: train loss 2.92441. lr 5.902542e-04:  16%|█▋        | 2657/16329 [22:24<1:52:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2657: train loss 2.90477. lr 5.902469e-04:  16%|█▋        | 2657/16329 [22:25<1:52:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2657: train loss 2.90477. lr 5.902469e-04:  16%|█▋        | 2658/16329 [22:25<1:52:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2658: train loss 2.90374. lr 5.902396e-04:  16%|█▋        | 2658/16329 [22:25<1:52:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2658: train loss 2.90374. lr 5.902396e-04:  16%|█▋        | 2659/16329 [22:25<1:52:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2659: train loss 2.86082. lr 5.902323e-04:  16%|█▋        | 2659/16329 [22:26<1:52:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2659: train loss 2.86082. lr 5.902323e-04:  16%|█▋        | 2660/16329 [22:26<1:52:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2660: train loss 2.84472. lr 5.902250e-04:  16%|█▋        | 2660/16329 [22:26<1:52:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2660: train loss 2.84472. lr 5.902250e-04:  16%|█▋        | 2661/16329 [22:26<1:52:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2661: train loss 2.83268. lr 5.902177e-04:  16%|█▋        | 2661/16329 [22:27<1:52:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2661: train loss 2.83268. lr 5.902177e-04:  16%|█▋        | 2662/16329 [22:27<2:04:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2662: train loss 2.88723. lr 5.902104e-04:  16%|█▋        | 2662/16329 [22:27<2:04:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2662: train loss 2.88723. lr 5.902104e-04:  16%|█▋        | 2663/16329 [22:27<2:01:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2663: train loss 2.93624. lr 5.902031e-04:  16%|█▋        | 2663/16329 [22:28<2:01:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2663: train loss 2.93624. lr 5.902031e-04:  16%|█▋        | 2664/16329 [22:28<1:58:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2664: train loss 2.83833. lr 5.901958e-04:  16%|█▋        | 2664/16329 [22:28<1:58:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2664: train loss 2.83833. lr 5.901958e-04:  16%|█▋        | 2665/16329 [22:28<1:56:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2665: train loss 2.87150. lr 5.901884e-04:  16%|█▋        | 2665/16329 [22:29<1:56:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2665: train loss 2.87150. lr 5.901884e-04:  16%|█▋        | 2666/16329 [22:29<1:55:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2666: train loss 2.79241. lr 5.901811e-04:  16%|█▋        | 2666/16329 [22:29<1:55:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2666: train loss 2.79241. lr 5.901811e-04:  16%|█▋        | 2667/16329 [22:29<1:54:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2667: train loss 2.83376. lr 5.901738e-04:  16%|█▋        | 2667/16329 [22:30<1:54:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2667: train loss 2.83376. lr 5.901738e-04:  16%|█▋        | 2668/16329 [22:30<1:53:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2668: train loss 2.95404. lr 5.901665e-04:  16%|█▋        | 2668/16329 [22:30<1:53:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2668: train loss 2.95404. lr 5.901665e-04:  16%|█▋        | 2669/16329 [22:30<1:53:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2669: train loss 2.83894. lr 5.901591e-04:  16%|█▋        | 2669/16329 [22:31<1:53:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2669: train loss 2.83894. lr 5.901591e-04:  16%|█▋        | 2670/16329 [22:31<1:52:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2670: train loss 2.78588. lr 5.901518e-04:  16%|█▋        | 2670/16329 [22:31<1:52:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2670: train loss 2.78588. lr 5.901518e-04:  16%|█▋        | 2671/16329 [22:31<1:52:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2671: train loss 2.81189. lr 5.901445e-04:  16%|█▋        | 2671/16329 [22:32<1:52:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2671: train loss 2.81189. lr 5.901445e-04:  16%|█▋        | 2672/16329 [22:32<1:52:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2672: train loss 2.78105. lr 5.901371e-04:  16%|█▋        | 2672/16329 [22:32<1:52:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2672: train loss 2.78105. lr 5.901371e-04:  16%|█▋        | 2673/16329 [22:32<1:52:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2673: train loss 2.86998. lr 5.901298e-04:  16%|█▋        | 2673/16329 [22:33<1:52:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2673: train loss 2.86998. lr 5.901298e-04:  16%|█▋        | 2674/16329 [22:33<1:52:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2674: train loss 2.82492. lr 5.901224e-04:  16%|█▋        | 2674/16329 [22:33<1:52:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2674: train loss 2.82492. lr 5.901224e-04:  16%|█▋        | 2675/16329 [22:33<1:52:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2675: train loss 2.89983. lr 5.901151e-04:  16%|█▋        | 2675/16329 [22:34<1:52:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2675: train loss 2.89983. lr 5.901151e-04:  16%|█▋        | 2676/16329 [22:34<1:52:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2676: train loss 2.85733. lr 5.901077e-04:  16%|█▋        | 2676/16329 [22:34<1:52:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2676: train loss 2.85733. lr 5.901077e-04:  16%|█▋        | 2677/16329 [22:34<1:52:20,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2677: train loss 2.82446. lr 5.901004e-04:  16%|█▋        | 2677/16329 [22:35<1:52:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2677: train loss 2.82446. lr 5.901004e-04:  16%|█▋        | 2678/16329 [22:35<1:51:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2678: train loss 2.90445. lr 5.900930e-04:  16%|█▋        | 2678/16329 [22:35<1:51:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2678: train loss 2.90445. lr 5.900930e-04:  16%|█▋        | 2679/16329 [22:35<1:52:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2679: train loss 2.87353. lr 5.900857e-04:  16%|█▋        | 2679/16329 [22:36<1:52:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2679: train loss 2.87353. lr 5.900857e-04:  16%|█▋        | 2680/16329 [22:36<1:52:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2680: train loss 2.82705. lr 5.900783e-04:  16%|█▋        | 2680/16329 [22:36<1:52:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2680: train loss 2.82705. lr 5.900783e-04:  16%|█▋        | 2681/16329 [22:36<1:52:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2681: train loss 2.87109. lr 5.900710e-04:  16%|█▋        | 2681/16329 [22:37<1:52:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2681: train loss 2.87109. lr 5.900710e-04:  16%|█▋        | 2682/16329 [22:37<1:52:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2682: train loss 2.84889. lr 5.900636e-04:  16%|█▋        | 2682/16329 [22:37<1:52:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2682: train loss 2.84889. lr 5.900636e-04:  16%|█▋        | 2683/16329 [22:37<1:51:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2683: train loss 2.84640. lr 5.900562e-04:  16%|█▋        | 2683/16329 [22:38<1:51:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2683: train loss 2.84640. lr 5.900562e-04:  16%|█▋        | 2684/16329 [22:38<1:54:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2684: train loss 2.89895. lr 5.900489e-04:  16%|█▋        | 2684/16329 [22:38<1:54:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2684: train loss 2.89895. lr 5.900489e-04:  16%|█▋        | 2685/16329 [22:38<1:55:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2685: train loss 2.87576. lr 5.900415e-04:  16%|█▋        | 2685/16329 [22:39<1:55:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2685: train loss 2.87576. lr 5.900415e-04:  16%|█▋        | 2686/16329 [22:39<1:55:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2686: train loss 2.82010. lr 5.900341e-04:  16%|█▋        | 2686/16329 [22:39<1:55:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2686: train loss 2.82010. lr 5.900341e-04:  16%|█▋        | 2687/16329 [22:39<1:55:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2687: train loss 2.88182. lr 5.900267e-04:  16%|█▋        | 2687/16329 [22:40<1:55:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2687: train loss 2.88182. lr 5.900267e-04:  16%|█▋        | 2688/16329 [22:40<1:55:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2688: train loss 2.79412. lr 5.900193e-04:  16%|█▋        | 2688/16329 [22:40<1:55:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2688: train loss 2.79412. lr 5.900193e-04:  16%|█▋        | 2689/16329 [22:40<1:54:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2689: train loss 2.84231. lr 5.900120e-04:  16%|█▋        | 2689/16329 [22:41<1:54:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2689: train loss 2.84231. lr 5.900120e-04:  16%|█▋        | 2690/16329 [22:41<1:54:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2690: train loss 2.87803. lr 5.900046e-04:  16%|█▋        | 2690/16329 [22:41<1:54:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2690: train loss 2.87803. lr 5.900046e-04:  16%|█▋        | 2691/16329 [22:41<1:53:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2691: train loss 2.82274. lr 5.899972e-04:  16%|█▋        | 2691/16329 [22:42<1:53:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2691: train loss 2.82274. lr 5.899972e-04:  16%|█▋        | 2692/16329 [22:42<1:53:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2692: train loss 2.86606. lr 5.899898e-04:  16%|█▋        | 2692/16329 [22:42<1:53:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2692: train loss 2.86606. lr 5.899898e-04:  16%|█▋        | 2693/16329 [22:42<1:52:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2693: train loss 2.86379. lr 5.899824e-04:  16%|█▋        | 2693/16329 [22:43<1:52:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2693: train loss 2.86379. lr 5.899824e-04:  16%|█▋        | 2694/16329 [22:43<1:52:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2694: train loss 2.95263. lr 5.899750e-04:  16%|█▋        | 2694/16329 [22:43<1:52:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2694: train loss 2.95263. lr 5.899750e-04:  17%|█▋        | 2695/16329 [22:43<1:52:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2695: train loss 2.91089. lr 5.899676e-04:  17%|█▋        | 2695/16329 [22:44<1:52:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2695: train loss 2.91089. lr 5.899676e-04:  17%|█▋        | 2696/16329 [22:44<1:52:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2696: train loss 2.87922. lr 5.899602e-04:  17%|█▋        | 2696/16329 [22:44<1:52:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2696: train loss 2.87922. lr 5.899602e-04:  17%|█▋        | 2697/16329 [22:44<1:52:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2697: train loss 2.85405. lr 5.899528e-04:  17%|█▋        | 2697/16329 [22:45<1:52:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2697: train loss 2.85405. lr 5.899528e-04:  17%|█▋        | 2698/16329 [22:45<1:52:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2698: train loss 2.83565. lr 5.899454e-04:  17%|█▋        | 2698/16329 [22:45<1:52:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2698: train loss 2.83565. lr 5.899454e-04:  17%|█▋        | 2699/16329 [22:45<1:51:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2699: train loss 2.81259. lr 5.899380e-04:  17%|█▋        | 2699/16329 [22:46<1:51:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2699: train loss 2.81259. lr 5.899380e-04:  17%|█▋        | 2700/16329 [22:46<1:51:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2700: train loss 2.80082. lr 5.899306e-04:  17%|█▋        | 2700/16329 [22:46<1:51:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2700: train loss 2.80082. lr 5.899306e-04:  17%|█▋        | 2701/16329 [22:46<1:51:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2701: train loss 2.86140. lr 5.899232e-04:  17%|█▋        | 2701/16329 [22:47<1:51:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2701: train loss 2.86140. lr 5.899232e-04:  17%|█▋        | 2702/16329 [22:47<2:06:53,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 2702: train loss 2.76848. lr 5.899157e-04:  17%|█▋        | 2702/16329 [22:47<2:06:53,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 2702: train loss 2.76848. lr 5.899157e-04:  17%|█▋        | 2703/16329 [22:47<2:02:22,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2703: train loss 2.86972. lr 5.899083e-04:  17%|█▋        | 2703/16329 [22:48<2:02:22,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2703: train loss 2.86972. lr 5.899083e-04:  17%|█▋        | 2704/16329 [22:48<1:59:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2704: train loss 2.90127. lr 5.899009e-04:  17%|█▋        | 2704/16329 [22:48<1:59:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2704: train loss 2.90127. lr 5.899009e-04:  17%|█▋        | 2705/16329 [22:48<1:56:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2705: train loss 2.82324. lr 5.898935e-04:  17%|█▋        | 2705/16329 [22:49<1:56:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2705: train loss 2.82324. lr 5.898935e-04:  17%|█▋        | 2706/16329 [22:49<1:55:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2706: train loss 2.87250. lr 5.898860e-04:  17%|█▋        | 2706/16329 [22:49<1:55:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2706: train loss 2.87250. lr 5.898860e-04:  17%|█▋        | 2707/16329 [22:49<1:54:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2707: train loss 2.89433. lr 5.898786e-04:  17%|█▋        | 2707/16329 [22:50<1:54:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2707: train loss 2.89433. lr 5.898786e-04:  17%|█▋        | 2708/16329 [22:50<1:53:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2708: train loss 2.83430. lr 5.898712e-04:  17%|█▋        | 2708/16329 [22:50<1:53:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2708: train loss 2.83430. lr 5.898712e-04:  17%|█▋        | 2709/16329 [22:50<1:52:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2709: train loss 2.89261. lr 5.898637e-04:  17%|█▋        | 2709/16329 [22:51<1:52:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2709: train loss 2.89261. lr 5.898637e-04:  17%|█▋        | 2710/16329 [22:51<1:52:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2710: train loss 2.87607. lr 5.898563e-04:  17%|█▋        | 2710/16329 [22:51<1:52:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2710: train loss 2.87607. lr 5.898563e-04:  17%|█▋        | 2711/16329 [22:51<1:52:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2711: train loss 2.88058. lr 5.898488e-04:  17%|█▋        | 2711/16329 [22:52<1:52:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2711: train loss 2.88058. lr 5.898488e-04:  17%|█▋        | 2712/16329 [22:52<1:52:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2712: train loss 2.82426. lr 5.898414e-04:  17%|█▋        | 2712/16329 [22:52<1:52:37,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2712: train loss 2.82426. lr 5.898414e-04:  17%|█▋        | 2713/16329 [22:52<1:52:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2713: train loss 2.87457. lr 5.898340e-04:  17%|█▋        | 2713/16329 [22:53<1:52:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2713: train loss 2.87457. lr 5.898340e-04:  17%|█▋        | 2714/16329 [22:53<1:52:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2714: train loss 2.82076. lr 5.898265e-04:  17%|█▋        | 2714/16329 [22:53<1:52:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2714: train loss 2.82076. lr 5.898265e-04:  17%|█▋        | 2715/16329 [22:53<1:52:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2715: train loss 2.89609. lr 5.898190e-04:  17%|█▋        | 2715/16329 [22:54<1:52:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2715: train loss 2.89609. lr 5.898190e-04:  17%|█▋        | 2716/16329 [22:54<1:51:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2716: train loss 2.80998. lr 5.898116e-04:  17%|█▋        | 2716/16329 [22:54<1:51:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2716: train loss 2.80998. lr 5.898116e-04:  17%|█▋        | 2717/16329 [22:54<1:51:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2717: train loss 2.88412. lr 5.898041e-04:  17%|█▋        | 2717/16329 [22:55<1:51:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2717: train loss 2.88412. lr 5.898041e-04:  17%|█▋        | 2718/16329 [22:55<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2718: train loss 2.87419. lr 5.897967e-04:  17%|█▋        | 2718/16329 [22:55<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2718: train loss 2.87419. lr 5.897967e-04:  17%|█▋        | 2719/16329 [22:55<1:51:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2719: train loss 2.84166. lr 5.897892e-04:  17%|█▋        | 2719/16329 [22:56<1:51:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2719: train loss 2.84166. lr 5.897892e-04:  17%|█▋        | 2720/16329 [22:56<1:52:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2720: train loss 2.84766. lr 5.897817e-04:  17%|█▋        | 2720/16329 [22:56<1:52:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2720: train loss 2.84766. lr 5.897817e-04:  17%|█▋        | 2721/16329 [22:56<1:51:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2721: train loss 2.88450. lr 5.897743e-04:  17%|█▋        | 2721/16329 [22:57<1:51:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2721: train loss 2.88450. lr 5.897743e-04:  17%|█▋        | 2722/16329 [22:57<1:52:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2722: train loss 2.86823. lr 5.897668e-04:  17%|█▋        | 2722/16329 [22:57<1:52:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2722: train loss 2.86823. lr 5.897668e-04:  17%|█▋        | 2723/16329 [22:57<1:51:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2723: train loss 2.87274. lr 5.897593e-04:  17%|█▋        | 2723/16329 [22:58<1:51:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2723: train loss 2.87274. lr 5.897593e-04:  17%|█▋        | 2724/16329 [22:58<1:51:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2724: train loss 2.84891. lr 5.897518e-04:  17%|█▋        | 2724/16329 [22:58<1:51:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2724: train loss 2.84891. lr 5.897518e-04:  17%|█▋        | 2725/16329 [22:58<1:51:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2725: train loss 2.76944. lr 5.897444e-04:  17%|█▋        | 2725/16329 [22:59<1:51:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2725: train loss 2.76944. lr 5.897444e-04:  17%|█▋        | 2726/16329 [22:59<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2726: train loss 2.84351. lr 5.897369e-04:  17%|█▋        | 2726/16329 [22:59<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2726: train loss 2.84351. lr 5.897369e-04:  17%|█▋        | 2727/16329 [22:59<1:51:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2727: train loss 2.77891. lr 5.897294e-04:  17%|█▋        | 2727/16329 [23:00<1:51:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2727: train loss 2.77891. lr 5.897294e-04:  17%|█▋        | 2728/16329 [23:00<1:51:14,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2728: train loss 2.84027. lr 5.897219e-04:  17%|█▋        | 2728/16329 [23:00<1:51:14,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 2728: train loss 2.84027. lr 5.897219e-04:  17%|█▋        | 2729/16329 [23:00<1:51:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2729: train loss 2.79681. lr 5.897144e-04:  17%|█▋        | 2729/16329 [23:01<1:51:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2729: train loss 2.79681. lr 5.897144e-04:  17%|█▋        | 2730/16329 [23:01<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2730: train loss 2.80773. lr 5.897069e-04:  17%|█▋        | 2730/16329 [23:01<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2730: train loss 2.80773. lr 5.897069e-04:  17%|█▋        | 2731/16329 [23:01<1:51:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2731: train loss 2.78707. lr 5.896994e-04:  17%|█▋        | 2731/16329 [23:02<1:51:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2731: train loss 2.78707. lr 5.896994e-04:  17%|█▋        | 2732/16329 [23:02<1:51:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2732: train loss 2.87818. lr 5.896919e-04:  17%|█▋        | 2732/16329 [23:02<1:51:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2732: train loss 2.87818. lr 5.896919e-04:  17%|█▋        | 2733/16329 [23:02<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2733: train loss 2.83582. lr 5.896844e-04:  17%|█▋        | 2733/16329 [23:03<1:51:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2733: train loss 2.83582. lr 5.896844e-04:  17%|█▋        | 2734/16329 [23:03<1:51:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2734: train loss 2.84324. lr 5.896769e-04:  17%|█▋        | 2734/16329 [23:03<1:51:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2734: train loss 2.84324. lr 5.896769e-04:  17%|█▋        | 2735/16329 [23:03<1:51:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2735: train loss 2.80643. lr 5.896694e-04:  17%|█▋        | 2735/16329 [23:04<1:51:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2735: train loss 2.80643. lr 5.896694e-04:  17%|█▋        | 2736/16329 [23:04<1:51:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2736: train loss 2.79354. lr 5.896619e-04:  17%|█▋        | 2736/16329 [23:04<1:51:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2736: train loss 2.79354. lr 5.896619e-04:  17%|█▋        | 2737/16329 [23:04<2:04:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2737: train loss 2.80980. lr 5.896544e-04:  17%|█▋        | 2737/16329 [23:05<2:04:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2737: train loss 2.80980. lr 5.896544e-04:  17%|█▋        | 2738/16329 [23:05<2:00:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2738: train loss 2.89511. lr 5.896469e-04:  17%|█▋        | 2738/16329 [23:05<2:00:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2738: train loss 2.89511. lr 5.896469e-04:  17%|█▋        | 2739/16329 [23:05<1:57:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2739: train loss 2.88863. lr 5.896394e-04:  17%|█▋        | 2739/16329 [23:06<1:57:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2739: train loss 2.88863. lr 5.896394e-04:  17%|█▋        | 2740/16329 [23:06<1:56:00,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2740: train loss 2.80096. lr 5.896318e-04:  17%|█▋        | 2740/16329 [23:06<1:56:00,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2740: train loss 2.80096. lr 5.896318e-04:  17%|█▋        | 2741/16329 [23:06<1:54:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2741: train loss 2.85862. lr 5.896243e-04:  17%|█▋        | 2741/16329 [23:07<1:54:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2741: train loss 2.85862. lr 5.896243e-04:  17%|█▋        | 2742/16329 [23:07<1:54:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2742: train loss 2.81647. lr 5.896168e-04:  17%|█▋        | 2742/16329 [23:07<1:54:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2742: train loss 2.81647. lr 5.896168e-04:  17%|█▋        | 2743/16329 [23:07<1:53:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2743: train loss 2.80245. lr 5.896093e-04:  17%|█▋        | 2743/16329 [23:08<1:53:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2743: train loss 2.80245. lr 5.896093e-04:  17%|█▋        | 2744/16329 [23:08<1:53:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2744: train loss 2.79949. lr 5.896017e-04:  17%|█▋        | 2744/16329 [23:08<1:53:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2744: train loss 2.79949. lr 5.896017e-04:  17%|█▋        | 2745/16329 [23:08<1:52:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2745: train loss 2.80707. lr 5.895942e-04:  17%|█▋        | 2745/16329 [23:09<1:52:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2745: train loss 2.80707. lr 5.895942e-04:  17%|█▋        | 2746/16329 [23:09<1:52:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2746: train loss 2.87668. lr 5.895867e-04:  17%|█▋        | 2746/16329 [23:09<1:52:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2746: train loss 2.87668. lr 5.895867e-04:  17%|█▋        | 2747/16329 [23:09<1:52:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2747: train loss 2.79656. lr 5.895791e-04:  17%|█▋        | 2747/16329 [23:10<1:52:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2747: train loss 2.79656. lr 5.895791e-04:  17%|█▋        | 2748/16329 [23:10<1:51:51,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2748: train loss 2.82022. lr 5.895716e-04:  17%|█▋        | 2748/16329 [23:10<1:51:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2748: train loss 2.82022. lr 5.895716e-04:  17%|█▋        | 2749/16329 [23:10<1:51:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2749: train loss 2.82137. lr 5.895640e-04:  17%|█▋        | 2749/16329 [23:11<1:51:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2749: train loss 2.82137. lr 5.895640e-04:  17%|█▋        | 2750/16329 [23:11<1:51:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2750: train loss 2.76363. lr 5.895565e-04:  17%|█▋        | 2750/16329 [23:11<1:51:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2750: train loss 2.76363. lr 5.895565e-04:  17%|█▋        | 2751/16329 [23:11<1:51:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2751: train loss 2.84085. lr 5.895489e-04:  17%|█▋        | 2751/16329 [23:12<1:51:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2751: train loss 2.84085. lr 5.895489e-04:  17%|█▋        | 2752/16329 [23:12<1:51:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2752: train loss 2.79910. lr 5.895414e-04:  17%|█▋        | 2752/16329 [23:12<1:51:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2752: train loss 2.79910. lr 5.895414e-04:  17%|█▋        | 2753/16329 [23:12<1:51:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2753: train loss 2.86074. lr 5.895338e-04:  17%|█▋        | 2753/16329 [23:13<1:51:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2753: train loss 2.86074. lr 5.895338e-04:  17%|█▋        | 2754/16329 [23:13<1:51:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2754: train loss 2.77260. lr 5.895263e-04:  17%|█▋        | 2754/16329 [23:13<1:51:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2754: train loss 2.77260. lr 5.895263e-04:  17%|█▋        | 2755/16329 [23:13<1:51:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2755: train loss 2.81164. lr 5.895187e-04:  17%|█▋        | 2755/16329 [23:14<1:51:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2755: train loss 2.81164. lr 5.895187e-04:  17%|█▋        | 2756/16329 [23:14<1:51:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2756: train loss 2.82938. lr 5.895111e-04:  17%|█▋        | 2756/16329 [23:14<1:51:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2756: train loss 2.82938. lr 5.895111e-04:  17%|█▋        | 2757/16329 [23:14<1:51:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2757: train loss 2.79156. lr 5.895036e-04:  17%|█▋        | 2757/16329 [23:15<1:51:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2757: train loss 2.79156. lr 5.895036e-04:  17%|█▋        | 2758/16329 [23:15<1:51:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2758: train loss 2.79553. lr 5.894960e-04:  17%|█▋        | 2758/16329 [23:15<1:51:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2758: train loss 2.79553. lr 5.894960e-04:  17%|█▋        | 2759/16329 [23:15<1:51:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2759: train loss 2.78777. lr 5.894884e-04:  17%|█▋        | 2759/16329 [23:16<1:51:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2759: train loss 2.78777. lr 5.894884e-04:  17%|█▋        | 2760/16329 [23:16<1:51:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2760: train loss 2.88105. lr 5.894809e-04:  17%|█▋        | 2760/16329 [23:16<1:51:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2760: train loss 2.88105. lr 5.894809e-04:  17%|█▋        | 2761/16329 [23:16<1:51:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2761: train loss 2.84443. lr 5.894733e-04:  17%|█▋        | 2761/16329 [23:17<1:51:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2761: train loss 2.84443. lr 5.894733e-04:  17%|█▋        | 2762/16329 [23:17<2:04:35,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2762: train loss 2.85198. lr 5.894657e-04:  17%|█▋        | 2762/16329 [23:17<2:04:35,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 2762: train loss 2.85198. lr 5.894657e-04:  17%|█▋        | 2763/16329 [23:17<2:01:27,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2763: train loss 2.81901. lr 5.894581e-04:  17%|█▋        | 2763/16329 [23:18<2:01:27,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2763: train loss 2.81901. lr 5.894581e-04:  17%|█▋        | 2764/16329 [23:18<1:59:09,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 2764: train loss 2.84773. lr 5.894505e-04:  17%|█▋        | 2764/16329 [23:18<1:59:09,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 2764: train loss 2.84773. lr 5.894505e-04:  17%|█▋        | 2765/16329 [23:18<1:56:58,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2765: train loss 2.80188. lr 5.894430e-04:  17%|█▋        | 2765/16329 [23:19<1:56:58,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2765: train loss 2.80188. lr 5.894430e-04:  17%|█▋        | 2766/16329 [23:19<1:55:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2766: train loss 2.81834. lr 5.894354e-04:  17%|█▋        | 2766/16329 [23:19<1:55:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2766: train loss 2.81834. lr 5.894354e-04:  17%|█▋        | 2767/16329 [23:19<1:54:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2767: train loss 2.78152. lr 5.894278e-04:  17%|█▋        | 2767/16329 [23:20<1:54:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2767: train loss 2.78152. lr 5.894278e-04:  17%|█▋        | 2768/16329 [23:20<1:53:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2768: train loss 2.89418. lr 5.894202e-04:  17%|█▋        | 2768/16329 [23:20<1:53:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2768: train loss 2.89418. lr 5.894202e-04:  17%|█▋        | 2769/16329 [23:20<1:52:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2769: train loss 2.75761. lr 5.894126e-04:  17%|█▋        | 2769/16329 [23:21<1:52:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2769: train loss 2.75761. lr 5.894126e-04:  17%|█▋        | 2770/16329 [23:21<1:52:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2770: train loss 2.79844. lr 5.894050e-04:  17%|█▋        | 2770/16329 [23:21<1:52:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2770: train loss 2.79844. lr 5.894050e-04:  17%|█▋        | 2771/16329 [23:21<1:52:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2771: train loss 2.83558. lr 5.893974e-04:  17%|█▋        | 2771/16329 [23:22<1:52:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2771: train loss 2.83558. lr 5.893974e-04:  17%|█▋        | 2772/16329 [23:22<1:51:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2772: train loss 2.83516. lr 5.893898e-04:  17%|█▋        | 2772/16329 [23:22<1:51:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2772: train loss 2.83516. lr 5.893898e-04:  17%|█▋        | 2773/16329 [23:22<1:51:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2773: train loss 2.82833. lr 5.893822e-04:  17%|█▋        | 2773/16329 [23:23<1:51:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2773: train loss 2.82833. lr 5.893822e-04:  17%|█▋        | 2774/16329 [23:23<1:51:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2774: train loss 2.81116. lr 5.893746e-04:  17%|█▋        | 2774/16329 [23:23<1:51:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2774: train loss 2.81116. lr 5.893746e-04:  17%|█▋        | 2775/16329 [23:23<1:51:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2775: train loss 2.83556. lr 5.893669e-04:  17%|█▋        | 2775/16329 [23:24<1:51:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2775: train loss 2.83556. lr 5.893669e-04:  17%|█▋        | 2776/16329 [23:24<1:51:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2776: train loss 2.84091. lr 5.893593e-04:  17%|█▋        | 2776/16329 [23:24<1:51:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2776: train loss 2.84091. lr 5.893593e-04:  17%|█▋        | 2777/16329 [23:24<1:51:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2777: train loss 2.81905. lr 5.893517e-04:  17%|█▋        | 2777/16329 [23:25<1:51:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2777: train loss 2.81905. lr 5.893517e-04:  17%|█▋        | 2778/16329 [23:25<1:51:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2778: train loss 2.75355. lr 5.893441e-04:  17%|█▋        | 2778/16329 [23:25<1:51:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2778: train loss 2.75355. lr 5.893441e-04:  17%|█▋        | 2779/16329 [23:25<1:51:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2779: train loss 2.81840. lr 5.893365e-04:  17%|█▋        | 2779/16329 [23:26<1:51:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2779: train loss 2.81840. lr 5.893365e-04:  17%|█▋        | 2780/16329 [23:26<1:51:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2780: train loss 2.77868. lr 5.893288e-04:  17%|█▋        | 2780/16329 [23:26<1:51:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2780: train loss 2.77868. lr 5.893288e-04:  17%|█▋        | 2781/16329 [23:26<1:51:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2781: train loss 2.75286. lr 5.893212e-04:  17%|█▋        | 2781/16329 [23:27<1:51:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2781: train loss 2.75286. lr 5.893212e-04:  17%|█▋        | 2782/16329 [23:27<1:51:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2782: train loss 2.82809. lr 5.893136e-04:  17%|█▋        | 2782/16329 [23:27<1:51:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2782: train loss 2.82809. lr 5.893136e-04:  17%|█▋        | 2783/16329 [23:27<1:51:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2783: train loss 2.86493. lr 5.893059e-04:  17%|█▋        | 2783/16329 [23:28<1:51:13,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2783: train loss 2.86493. lr 5.893059e-04:  17%|█▋        | 2784/16329 [23:28<1:51:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2784: train loss 2.81559. lr 5.892983e-04:  17%|█▋        | 2784/16329 [23:28<1:51:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2784: train loss 2.81559. lr 5.892983e-04:  17%|█▋        | 2785/16329 [23:28<1:51:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2785: train loss 2.86033. lr 5.892906e-04:  17%|█▋        | 2785/16329 [23:29<1:51:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2785: train loss 2.86033. lr 5.892906e-04:  17%|█▋        | 2786/16329 [23:29<1:51:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2786: train loss 2.76046. lr 5.892830e-04:  17%|█▋        | 2786/16329 [23:29<1:51:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2786: train loss 2.76046. lr 5.892830e-04:  17%|█▋        | 2787/16329 [23:29<1:51:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2787: train loss 2.82461. lr 5.892754e-04:  17%|█▋        | 2787/16329 [23:30<1:51:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2787: train loss 2.82461. lr 5.892754e-04:  17%|█▋        | 2788/16329 [23:30<1:51:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2788: train loss 2.74178. lr 5.892677e-04:  17%|█▋        | 2788/16329 [23:30<1:51:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2788: train loss 2.74178. lr 5.892677e-04:  17%|█▋        | 2789/16329 [23:30<2:03:24,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2789: train loss 2.82025. lr 5.892601e-04:  17%|█▋        | 2789/16329 [23:31<2:03:24,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2789: train loss 2.82025. lr 5.892601e-04:  17%|█▋        | 2790/16329 [23:31<1:59:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2790: train loss 2.79356. lr 5.892524e-04:  17%|█▋        | 2790/16329 [23:31<1:59:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2790: train loss 2.79356. lr 5.892524e-04:  17%|█▋        | 2791/16329 [23:31<1:57:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2791: train loss 2.80116. lr 5.892447e-04:  17%|█▋        | 2791/16329 [23:32<1:57:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2791: train loss 2.80116. lr 5.892447e-04:  17%|█▋        | 2792/16329 [23:32<1:55:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2792: train loss 2.79744. lr 5.892371e-04:  17%|█▋        | 2792/16329 [23:32<1:55:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2792: train loss 2.79744. lr 5.892371e-04:  17%|█▋        | 2793/16329 [23:32<1:54:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2793: train loss 2.80485. lr 5.892294e-04:  17%|█▋        | 2793/16329 [23:33<1:54:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2793: train loss 2.80485. lr 5.892294e-04:  17%|█▋        | 2794/16329 [23:33<1:53:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2794: train loss 2.94305. lr 5.892218e-04:  17%|█▋        | 2794/16329 [23:33<1:53:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2794: train loss 2.94305. lr 5.892218e-04:  17%|█▋        | 2795/16329 [23:33<1:53:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2795: train loss 2.82356. lr 5.892141e-04:  17%|█▋        | 2795/16329 [23:34<1:53:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2795: train loss 2.82356. lr 5.892141e-04:  17%|█▋        | 2796/16329 [23:34<1:52:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2796: train loss 2.83406. lr 5.892064e-04:  17%|█▋        | 2796/16329 [23:34<1:52:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2796: train loss 2.83406. lr 5.892064e-04:  17%|█▋        | 2797/16329 [23:34<1:52:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2797: train loss 2.78962. lr 5.891987e-04:  17%|█▋        | 2797/16329 [23:35<1:52:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2797: train loss 2.78962. lr 5.891987e-04:  17%|█▋        | 2798/16329 [23:35<1:52:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2798: train loss 2.85593. lr 5.891911e-04:  17%|█▋        | 2798/16329 [23:35<1:52:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2798: train loss 2.85593. lr 5.891911e-04:  17%|█▋        | 2799/16329 [23:35<1:51:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2799: train loss 2.82443. lr 5.891834e-04:  17%|█▋        | 2799/16329 [23:36<1:51:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2799: train loss 2.82443. lr 5.891834e-04:  17%|█▋        | 2800/16329 [23:36<1:51:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2800: train loss 2.72343. lr 5.891757e-04:  17%|█▋        | 2800/16329 [23:36<1:51:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2800: train loss 2.72343. lr 5.891757e-04:  17%|█▋        | 2801/16329 [23:36<1:51:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2801: train loss 2.79210. lr 5.891680e-04:  17%|█▋        | 2801/16329 [23:37<1:51:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2801: train loss 2.79210. lr 5.891680e-04:  17%|█▋        | 2802/16329 [23:37<1:51:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2802: train loss 2.77246. lr 5.891603e-04:  17%|█▋        | 2802/16329 [23:37<1:51:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2802: train loss 2.77246. lr 5.891603e-04:  17%|█▋        | 2803/16329 [23:37<1:51:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2803: train loss 2.80631. lr 5.891527e-04:  17%|█▋        | 2803/16329 [23:38<1:51:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2803: train loss 2.80631. lr 5.891527e-04:  17%|█▋        | 2804/16329 [23:38<1:51:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2804: train loss 2.81125. lr 5.891450e-04:  17%|█▋        | 2804/16329 [23:38<1:51:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2804: train loss 2.81125. lr 5.891450e-04:  17%|█▋        | 2805/16329 [23:38<1:51:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2805: train loss 2.82639. lr 5.891373e-04:  17%|█▋        | 2805/16329 [23:39<1:51:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2805: train loss 2.82639. lr 5.891373e-04:  17%|█▋        | 2806/16329 [23:39<1:51:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2806: train loss 2.83160. lr 5.891296e-04:  17%|█▋        | 2806/16329 [23:39<1:51:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2806: train loss 2.83160. lr 5.891296e-04:  17%|█▋        | 2807/16329 [23:39<1:51:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2807: train loss 2.80129. lr 5.891219e-04:  17%|█▋        | 2807/16329 [23:40<1:51:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2807: train loss 2.80129. lr 5.891219e-04:  17%|█▋        | 2808/16329 [23:40<1:51:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2808: train loss 2.76344. lr 5.891142e-04:  17%|█▋        | 2808/16329 [23:40<1:51:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2808: train loss 2.76344. lr 5.891142e-04:  17%|█▋        | 2809/16329 [23:40<1:50:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2809: train loss 2.81417. lr 5.891065e-04:  17%|█▋        | 2809/16329 [23:41<1:50:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2809: train loss 2.81417. lr 5.891065e-04:  17%|█▋        | 2810/16329 [23:41<1:51:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2810: train loss 2.84928. lr 5.890988e-04:  17%|█▋        | 2810/16329 [23:41<1:51:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2810: train loss 2.84928. lr 5.890988e-04:  17%|█▋        | 2811/16329 [23:41<1:51:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2811: train loss 2.85818. lr 5.890910e-04:  17%|█▋        | 2811/16329 [23:42<1:51:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2811: train loss 2.85818. lr 5.890910e-04:  17%|█▋        | 2812/16329 [23:42<1:51:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2812: train loss 2.74920. lr 5.890833e-04:  17%|█▋        | 2812/16329 [23:42<1:51:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2812: train loss 2.74920. lr 5.890833e-04:  17%|█▋        | 2813/16329 [23:42<1:51:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2813: train loss 2.79539. lr 5.890756e-04:  17%|█▋        | 2813/16329 [23:43<1:51:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2813: train loss 2.79539. lr 5.890756e-04:  17%|█▋        | 2814/16329 [23:43<1:50:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2814: train loss 2.79656. lr 5.890679e-04:  17%|█▋        | 2814/16329 [23:43<1:50:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2814: train loss 2.79656. lr 5.890679e-04:  17%|█▋        | 2815/16329 [23:43<1:50:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2815: train loss 2.82227. lr 5.890602e-04:  17%|█▋        | 2815/16329 [23:44<1:50:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2815: train loss 2.82227. lr 5.890602e-04:  17%|█▋        | 2816/16329 [23:44<1:50:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2816: train loss 2.80943. lr 5.890524e-04:  17%|█▋        | 2816/16329 [23:44<1:50:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2816: train loss 2.80943. lr 5.890524e-04:  17%|█▋        | 2817/16329 [23:44<1:51:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2817: train loss 2.80450. lr 5.890447e-04:  17%|█▋        | 2817/16329 [23:45<1:51:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2817: train loss 2.80450. lr 5.890447e-04:  17%|█▋        | 2818/16329 [23:45<1:51:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2818: train loss 2.76916. lr 5.890370e-04:  17%|█▋        | 2818/16329 [23:45<1:51:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2818: train loss 2.76916. lr 5.890370e-04:  17%|█▋        | 2819/16329 [23:45<1:50:51,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2819: train loss 2.77072. lr 5.890293e-04:  17%|█▋        | 2819/16329 [23:46<1:50:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2819: train loss 2.77072. lr 5.890293e-04:  17%|█▋        | 2820/16329 [23:46<1:51:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2820: train loss 2.83075. lr 5.890215e-04:  17%|█▋        | 2820/16329 [23:46<1:51:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2820: train loss 2.83075. lr 5.890215e-04:  17%|█▋        | 2821/16329 [23:46<1:50:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2821: train loss 2.81159. lr 5.890138e-04:  17%|█▋        | 2821/16329 [23:47<1:50:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2821: train loss 2.81159. lr 5.890138e-04:  17%|█▋        | 2822/16329 [23:47<1:51:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2822: train loss 2.76696. lr 5.890060e-04:  17%|█▋        | 2822/16329 [23:47<1:51:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2822: train loss 2.76696. lr 5.890060e-04:  17%|█▋        | 2823/16329 [23:47<1:51:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2823: train loss 2.81838. lr 5.889983e-04:  17%|█▋        | 2823/16329 [23:48<1:51:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2823: train loss 2.81838. lr 5.889983e-04:  17%|█▋        | 2824/16329 [23:48<1:51:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2824: train loss 2.77784. lr 5.889906e-04:  17%|█▋        | 2824/16329 [23:48<1:51:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2824: train loss 2.77784. lr 5.889906e-04:  17%|█▋        | 2825/16329 [23:48<1:51:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2825: train loss 2.81074. lr 5.889828e-04:  17%|█▋        | 2825/16329 [23:49<1:51:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2825: train loss 2.81074. lr 5.889828e-04:  17%|█▋        | 2826/16329 [23:49<1:51:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2826: train loss 2.80689. lr 5.889751e-04:  17%|█▋        | 2826/16329 [23:49<1:51:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2826: train loss 2.80689. lr 5.889751e-04:  17%|█▋        | 2827/16329 [23:49<1:51:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2827: train loss 2.80473. lr 5.889673e-04:  17%|█▋        | 2827/16329 [23:50<1:51:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2827: train loss 2.80473. lr 5.889673e-04:  17%|█▋        | 2828/16329 [23:50<1:51:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2828: train loss 2.72310. lr 5.889596e-04:  17%|█▋        | 2828/16329 [23:50<1:51:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2828: train loss 2.72310. lr 5.889596e-04:  17%|█▋        | 2829/16329 [23:50<2:02:15,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2829: train loss 2.82065. lr 5.889518e-04:  17%|█▋        | 2829/16329 [23:51<2:02:15,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2829: train loss 2.82065. lr 5.889518e-04:  17%|█▋        | 2830/16329 [23:51<2:01:46,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 2830: train loss 2.75956. lr 5.889440e-04:  17%|█▋        | 2830/16329 [23:51<2:01:46,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 2830: train loss 2.75956. lr 5.889440e-04:  17%|█▋        | 2831/16329 [23:51<2:00:51,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2831: train loss 2.73500. lr 5.889363e-04:  17%|█▋        | 2831/16329 [23:52<2:00:51,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 2831: train loss 2.73500. lr 5.889363e-04:  17%|█▋        | 2832/16329 [23:52<1:58:55,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2832: train loss 2.81158. lr 5.889285e-04:  17%|█▋        | 2832/16329 [23:52<1:58:55,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2832: train loss 2.81158. lr 5.889285e-04:  17%|█▋        | 2833/16329 [23:52<1:57:42,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2833: train loss 2.75058. lr 5.889207e-04:  17%|█▋        | 2833/16329 [23:53<1:57:42,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 2833: train loss 2.75058. lr 5.889207e-04:  17%|█▋        | 2834/16329 [23:53<1:56:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2834: train loss 2.79147. lr 5.889130e-04:  17%|█▋        | 2834/16329 [23:53<1:56:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2834: train loss 2.79147. lr 5.889130e-04:  17%|█▋        | 2835/16329 [23:53<1:55:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2835: train loss 2.72184. lr 5.889052e-04:  17%|█▋        | 2835/16329 [23:54<1:55:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2835: train loss 2.72184. lr 5.889052e-04:  17%|█▋        | 2836/16329 [23:54<1:54:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2836: train loss 2.83419. lr 5.888974e-04:  17%|█▋        | 2836/16329 [23:54<1:54:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2836: train loss 2.83419. lr 5.888974e-04:  17%|█▋        | 2837/16329 [23:54<1:53:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2837: train loss 2.73772. lr 5.888896e-04:  17%|█▋        | 2837/16329 [23:55<1:53:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2837: train loss 2.73772. lr 5.888896e-04:  17%|█▋        | 2838/16329 [23:55<1:52:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2838: train loss 2.79398. lr 5.888818e-04:  17%|█▋        | 2838/16329 [23:55<1:52:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2838: train loss 2.79398. lr 5.888818e-04:  17%|█▋        | 2839/16329 [23:55<1:52:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2839: train loss 2.76044. lr 5.888741e-04:  17%|█▋        | 2839/16329 [23:56<1:52:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2839: train loss 2.76044. lr 5.888741e-04:  17%|█▋        | 2840/16329 [23:56<1:51:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2840: train loss 2.74861. lr 5.888663e-04:  17%|█▋        | 2840/16329 [23:56<1:51:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2840: train loss 2.74861. lr 5.888663e-04:  17%|█▋        | 2841/16329 [23:56<1:51:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2841: train loss 2.76526. lr 5.888585e-04:  17%|█▋        | 2841/16329 [23:57<1:51:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2841: train loss 2.76526. lr 5.888585e-04:  17%|█▋        | 2842/16329 [23:57<1:51:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2842: train loss 2.73259. lr 5.888507e-04:  17%|█▋        | 2842/16329 [23:57<1:51:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2842: train loss 2.73259. lr 5.888507e-04:  17%|█▋        | 2843/16329 [23:57<1:51:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2843: train loss 2.80077. lr 5.888429e-04:  17%|█▋        | 2843/16329 [23:58<1:51:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2843: train loss 2.80077. lr 5.888429e-04:  17%|█▋        | 2844/16329 [23:58<1:51:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2844: train loss 2.75901. lr 5.888351e-04:  17%|█▋        | 2844/16329 [23:58<1:51:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2844: train loss 2.75901. lr 5.888351e-04:  17%|█▋        | 2845/16329 [23:58<1:51:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2845: train loss 2.76078. lr 5.888273e-04:  17%|█▋        | 2845/16329 [23:59<1:51:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2845: train loss 2.76078. lr 5.888273e-04:  17%|█▋        | 2846/16329 [23:59<1:51:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2846: train loss 2.75528. lr 5.888195e-04:  17%|█▋        | 2846/16329 [23:59<1:51:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2846: train loss 2.75528. lr 5.888195e-04:  17%|█▋        | 2847/16329 [23:59<1:50:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2847: train loss 2.83066. lr 5.888117e-04:  17%|█▋        | 2847/16329 [24:00<1:50:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2847: train loss 2.83066. lr 5.888117e-04:  17%|█▋        | 2848/16329 [24:00<1:51:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2848: train loss 2.80126. lr 5.888039e-04:  17%|█▋        | 2848/16329 [24:00<1:51:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2848: train loss 2.80126. lr 5.888039e-04:  17%|█▋        | 2849/16329 [24:00<1:50:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2849: train loss 2.83237. lr 5.887961e-04:  17%|█▋        | 2849/16329 [24:01<1:50:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2849: train loss 2.83237. lr 5.887961e-04:  17%|█▋        | 2850/16329 [24:01<1:51:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2850: train loss 2.77913. lr 5.887882e-04:  17%|█▋        | 2850/16329 [24:01<1:51:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2850: train loss 2.77913. lr 5.887882e-04:  17%|█▋        | 2851/16329 [24:01<1:51:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2851: train loss 2.78836. lr 5.887804e-04:  17%|█▋        | 2851/16329 [24:02<1:51:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2851: train loss 2.78836. lr 5.887804e-04:  17%|█▋        | 2852/16329 [24:02<1:50:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2852: train loss 2.77509. lr 5.887726e-04:  17%|█▋        | 2852/16329 [24:02<1:50:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2852: train loss 2.77509. lr 5.887726e-04:  17%|█▋        | 2853/16329 [24:02<1:50:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2853: train loss 2.74107. lr 5.887648e-04:  17%|█▋        | 2853/16329 [24:03<1:50:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2853: train loss 2.74107. lr 5.887648e-04:  17%|█▋        | 2854/16329 [24:03<1:50:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2854: train loss 2.87015. lr 5.887570e-04:  17%|█▋        | 2854/16329 [24:03<1:50:34,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2854: train loss 2.87015. lr 5.887570e-04:  17%|█▋        | 2855/16329 [24:03<1:50:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2855: train loss 2.71571. lr 5.887491e-04:  17%|█▋        | 2855/16329 [24:04<1:50:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2855: train loss 2.71571. lr 5.887491e-04:  17%|█▋        | 2856/16329 [24:04<1:50:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2856: train loss 2.73885. lr 5.887413e-04:  17%|█▋        | 2856/16329 [24:04<1:50:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2856: train loss 2.73885. lr 5.887413e-04:  17%|█▋        | 2857/16329 [24:04<1:50:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2857: train loss 2.78357. lr 5.887335e-04:  17%|█▋        | 2857/16329 [24:05<1:50:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2857: train loss 2.78357. lr 5.887335e-04:  18%|█▊        | 2858/16329 [24:05<1:50:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2858: train loss 2.75669. lr 5.887256e-04:  18%|█▊        | 2858/16329 [24:05<1:50:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2858: train loss 2.75669. lr 5.887256e-04:  18%|█▊        | 2859/16329 [24:05<1:50:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2859: train loss 2.71480. lr 5.887178e-04:  18%|█▊        | 2859/16329 [24:06<1:50:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2859: train loss 2.71480. lr 5.887178e-04:  18%|█▊        | 2860/16329 [24:06<1:50:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2860: train loss 2.73732. lr 5.887099e-04:  18%|█▊        | 2860/16329 [24:06<1:50:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2860: train loss 2.73732. lr 5.887099e-04:  18%|█▊        | 2861/16329 [24:06<1:51:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2861: train loss 2.79819. lr 5.887021e-04:  18%|█▊        | 2861/16329 [24:07<1:51:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2861: train loss 2.79819. lr 5.887021e-04:  18%|█▊        | 2862/16329 [24:07<1:52:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2862: train loss 2.71800. lr 5.886943e-04:  18%|█▊        | 2862/16329 [24:07<1:52:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2862: train loss 2.71800. lr 5.886943e-04:  18%|█▊        | 2863/16329 [24:07<1:51:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2863: train loss 2.74361. lr 5.886864e-04:  18%|█▊        | 2863/16329 [24:08<1:51:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2863: train loss 2.74361. lr 5.886864e-04:  18%|█▊        | 2864/16329 [24:08<2:02:28,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2864: train loss 2.80787. lr 5.886786e-04:  18%|█▊        | 2864/16329 [24:08<2:02:28,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2864: train loss 2.80787. lr 5.886786e-04:  18%|█▊        | 2865/16329 [24:08<1:59:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2865: train loss 2.76810. lr 5.886707e-04:  18%|█▊        | 2865/16329 [24:09<1:59:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2865: train loss 2.76810. lr 5.886707e-04:  18%|█▊        | 2866/16329 [24:09<1:56:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2866: train loss 2.77543. lr 5.886628e-04:  18%|█▊        | 2866/16329 [24:09<1:56:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2866: train loss 2.77543. lr 5.886628e-04:  18%|█▊        | 2867/16329 [24:09<1:55:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2867: train loss 2.82948. lr 5.886550e-04:  18%|█▊        | 2867/16329 [24:10<1:55:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2867: train loss 2.82948. lr 5.886550e-04:  18%|█▊        | 2868/16329 [24:10<1:54:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2868: train loss 2.78179. lr 5.886471e-04:  18%|█▊        | 2868/16329 [24:10<1:54:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2868: train loss 2.78179. lr 5.886471e-04:  18%|█▊        | 2869/16329 [24:10<1:52:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2869: train loss 2.74426. lr 5.886393e-04:  18%|█▊        | 2869/16329 [24:11<1:52:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2869: train loss 2.74426. lr 5.886393e-04:  18%|█▊        | 2870/16329 [24:11<1:52:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2870: train loss 2.67167. lr 5.886314e-04:  18%|█▊        | 2870/16329 [24:11<1:52:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2870: train loss 2.67167. lr 5.886314e-04:  18%|█▊        | 2871/16329 [24:11<1:51:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2871: train loss 2.74225. lr 5.886235e-04:  18%|█▊        | 2871/16329 [24:12<1:51:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2871: train loss 2.74225. lr 5.886235e-04:  18%|█▊        | 2872/16329 [24:12<1:51:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2872: train loss 2.69546. lr 5.886156e-04:  18%|█▊        | 2872/16329 [24:12<1:51:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2872: train loss 2.69546. lr 5.886156e-04:  18%|█▊        | 2873/16329 [24:12<1:51:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2873: train loss 2.80843. lr 5.886078e-04:  18%|█▊        | 2873/16329 [24:13<1:51:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2873: train loss 2.80843. lr 5.886078e-04:  18%|█▊        | 2874/16329 [24:13<1:50:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2874: train loss 2.78256. lr 5.885999e-04:  18%|█▊        | 2874/16329 [24:13<1:50:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2874: train loss 2.78256. lr 5.885999e-04:  18%|█▊        | 2875/16329 [24:13<1:50:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2875: train loss 2.77164. lr 5.885920e-04:  18%|█▊        | 2875/16329 [24:14<1:50:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2875: train loss 2.77164. lr 5.885920e-04:  18%|█▊        | 2876/16329 [24:14<1:50:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2876: train loss 2.79281. lr 5.885841e-04:  18%|█▊        | 2876/16329 [24:14<1:50:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2876: train loss 2.79281. lr 5.885841e-04:  18%|█▊        | 2877/16329 [24:14<1:50:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2877: train loss 2.75101. lr 5.885762e-04:  18%|█▊        | 2877/16329 [24:15<1:50:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2877: train loss 2.75101. lr 5.885762e-04:  18%|█▊        | 2878/16329 [24:15<1:50:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2878: train loss 2.76920. lr 5.885683e-04:  18%|█▊        | 2878/16329 [24:15<1:50:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2878: train loss 2.76920. lr 5.885683e-04:  18%|█▊        | 2879/16329 [24:15<1:50:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2879: train loss 2.72216. lr 5.885604e-04:  18%|█▊        | 2879/16329 [24:16<1:50:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2879: train loss 2.72216. lr 5.885604e-04:  18%|█▊        | 2880/16329 [24:16<1:50:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2880: train loss 2.75002. lr 5.885526e-04:  18%|█▊        | 2880/16329 [24:16<1:50:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2880: train loss 2.75002. lr 5.885526e-04:  18%|█▊        | 2881/16329 [24:16<1:50:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2881: train loss 2.73394. lr 5.885447e-04:  18%|█▊        | 2881/16329 [24:17<1:50:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2881: train loss 2.73394. lr 5.885447e-04:  18%|█▊        | 2882/16329 [24:17<1:50:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2882: train loss 2.77717. lr 5.885368e-04:  18%|█▊        | 2882/16329 [24:17<1:50:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2882: train loss 2.77717. lr 5.885368e-04:  18%|█▊        | 2883/16329 [24:17<1:50:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2883: train loss 2.74953. lr 5.885289e-04:  18%|█▊        | 2883/16329 [24:18<1:50:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2883: train loss 2.74953. lr 5.885289e-04:  18%|█▊        | 2884/16329 [24:18<1:50:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2884: train loss 2.77771. lr 5.885209e-04:  18%|█▊        | 2884/16329 [24:18<1:50:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2884: train loss 2.77771. lr 5.885209e-04:  18%|█▊        | 2885/16329 [24:18<1:50:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2885: train loss 2.71129. lr 5.885130e-04:  18%|█▊        | 2885/16329 [24:19<1:50:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2885: train loss 2.71129. lr 5.885130e-04:  18%|█▊        | 2886/16329 [24:19<1:50:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2886: train loss 2.79444. lr 5.885051e-04:  18%|█▊        | 2886/16329 [24:19<1:50:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2886: train loss 2.79444. lr 5.885051e-04:  18%|█▊        | 2887/16329 [24:19<1:50:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2887: train loss 2.72780. lr 5.884972e-04:  18%|█▊        | 2887/16329 [24:20<1:50:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2887: train loss 2.72780. lr 5.884972e-04:  18%|█▊        | 2888/16329 [24:20<1:51:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2888: train loss 2.80453. lr 5.884893e-04:  18%|█▊        | 2888/16329 [24:21<1:51:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2888: train loss 2.80453. lr 5.884893e-04:  18%|█▊        | 2889/16329 [24:21<2:03:01,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2889: train loss 2.76733. lr 5.884814e-04:  18%|█▊        | 2889/16329 [24:21<2:03:01,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2889: train loss 2.76733. lr 5.884814e-04:  18%|█▊        | 2890/16329 [24:21<1:59:08,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2890: train loss 2.70753. lr 5.884735e-04:  18%|█▊        | 2890/16329 [24:22<1:59:08,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2890: train loss 2.70753. lr 5.884735e-04:  18%|█▊        | 2891/16329 [24:22<1:56:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2891: train loss 2.75425. lr 5.884655e-04:  18%|█▊        | 2891/16329 [24:22<1:56:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2891: train loss 2.75425. lr 5.884655e-04:  18%|█▊        | 2892/16329 [24:22<1:54:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2892: train loss 2.71724. lr 5.884576e-04:  18%|█▊        | 2892/16329 [24:23<1:54:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2892: train loss 2.71724. lr 5.884576e-04:  18%|█▊        | 2893/16329 [24:23<1:53:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2893: train loss 2.78177. lr 5.884497e-04:  18%|█▊        | 2893/16329 [24:23<1:53:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2893: train loss 2.78177. lr 5.884497e-04:  18%|█▊        | 2894/16329 [24:23<1:52:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2894: train loss 2.70497. lr 5.884417e-04:  18%|█▊        | 2894/16329 [24:23<1:52:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2894: train loss 2.70497. lr 5.884417e-04:  18%|█▊        | 2895/16329 [24:23<1:52:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2895: train loss 2.76384. lr 5.884338e-04:  18%|█▊        | 2895/16329 [24:24<1:52:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2895: train loss 2.76384. lr 5.884338e-04:  18%|█▊        | 2896/16329 [24:24<1:51:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2896: train loss 2.76659. lr 5.884259e-04:  18%|█▊        | 2896/16329 [24:24<1:51:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2896: train loss 2.76659. lr 5.884259e-04:  18%|█▊        | 2897/16329 [24:24<1:51:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2897: train loss 2.73044. lr 5.884179e-04:  18%|█▊        | 2897/16329 [24:25<1:51:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2897: train loss 2.73044. lr 5.884179e-04:  18%|█▊        | 2898/16329 [24:25<1:50:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2898: train loss 2.78456. lr 5.884100e-04:  18%|█▊        | 2898/16329 [24:25<1:50:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2898: train loss 2.78456. lr 5.884100e-04:  18%|█▊        | 2899/16329 [24:25<1:50:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2899: train loss 2.75391. lr 5.884020e-04:  18%|█▊        | 2899/16329 [24:26<1:50:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2899: train loss 2.75391. lr 5.884020e-04:  18%|█▊        | 2900/16329 [24:26<1:50:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2900: train loss 2.83984. lr 5.883941e-04:  18%|█▊        | 2900/16329 [24:26<1:50:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2900: train loss 2.83984. lr 5.883941e-04:  18%|█▊        | 2901/16329 [24:26<1:50:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2901: train loss 2.72958. lr 5.883861e-04:  18%|█▊        | 2901/16329 [24:27<1:50:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2901: train loss 2.72958. lr 5.883861e-04:  18%|█▊        | 2902/16329 [24:27<1:50:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2902: train loss 2.76742. lr 5.883782e-04:  18%|█▊        | 2902/16329 [24:27<1:50:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2902: train loss 2.76742. lr 5.883782e-04:  18%|█▊        | 2903/16329 [24:27<1:50:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2903: train loss 2.77558. lr 5.883702e-04:  18%|█▊        | 2903/16329 [24:28<1:50:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2903: train loss 2.77558. lr 5.883702e-04:  18%|█▊        | 2904/16329 [24:28<1:50:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2904: train loss 2.84230. lr 5.883623e-04:  18%|█▊        | 2904/16329 [24:28<1:50:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2904: train loss 2.84230. lr 5.883623e-04:  18%|█▊        | 2905/16329 [24:28<1:50:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2905: train loss 2.74718. lr 5.883543e-04:  18%|█▊        | 2905/16329 [24:29<1:50:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2905: train loss 2.74718. lr 5.883543e-04:  18%|█▊        | 2906/16329 [24:29<1:50:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2906: train loss 2.77700. lr 5.883463e-04:  18%|█▊        | 2906/16329 [24:29<1:50:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2906: train loss 2.77700. lr 5.883463e-04:  18%|█▊        | 2907/16329 [24:29<1:50:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2907: train loss 2.75419. lr 5.883384e-04:  18%|█▊        | 2907/16329 [24:30<1:50:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2907: train loss 2.75419. lr 5.883384e-04:  18%|█▊        | 2908/16329 [24:30<1:50:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2908: train loss 2.68644. lr 5.883304e-04:  18%|█▊        | 2908/16329 [24:30<1:50:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2908: train loss 2.68644. lr 5.883304e-04:  18%|█▊        | 2909/16329 [24:30<1:50:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2909: train loss 2.70986. lr 5.883224e-04:  18%|█▊        | 2909/16329 [24:31<1:50:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2909: train loss 2.70986. lr 5.883224e-04:  18%|█▊        | 2910/16329 [24:31<1:50:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2910: train loss 2.74560. lr 5.883145e-04:  18%|█▊        | 2910/16329 [24:31<1:50:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2910: train loss 2.74560. lr 5.883145e-04:  18%|█▊        | 2911/16329 [24:31<1:50:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2911: train loss 2.70788. lr 5.883065e-04:  18%|█▊        | 2911/16329 [24:32<1:50:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2911: train loss 2.70788. lr 5.883065e-04:  18%|█▊        | 2912/16329 [24:32<1:50:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2912: train loss 2.72115. lr 5.882985e-04:  18%|█▊        | 2912/16329 [24:32<1:50:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2912: train loss 2.72115. lr 5.882985e-04:  18%|█▊        | 2913/16329 [24:32<1:50:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2913: train loss 2.71903. lr 5.882905e-04:  18%|█▊        | 2913/16329 [24:33<1:50:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2913: train loss 2.71903. lr 5.882905e-04:  18%|█▊        | 2914/16329 [24:33<1:50:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2914: train loss 2.77736. lr 5.882825e-04:  18%|█▊        | 2914/16329 [24:33<1:50:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2914: train loss 2.77736. lr 5.882825e-04:  18%|█▊        | 2915/16329 [24:33<1:50:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2915: train loss 2.76247. lr 5.882745e-04:  18%|█▊        | 2915/16329 [24:34<1:50:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2915: train loss 2.76247. lr 5.882745e-04:  18%|█▊        | 2916/16329 [24:34<2:01:54,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2916: train loss 2.76780. lr 5.882666e-04:  18%|█▊        | 2916/16329 [24:35<2:01:54,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 2916: train loss 2.76780. lr 5.882666e-04:  18%|█▊        | 2917/16329 [24:35<1:58:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2917: train loss 2.78868. lr 5.882586e-04:  18%|█▊        | 2917/16329 [24:35<1:58:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2917: train loss 2.78868. lr 5.882586e-04:  18%|█▊        | 2918/16329 [24:35<1:56:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2918: train loss 2.79839. lr 5.882506e-04:  18%|█▊        | 2918/16329 [24:36<1:56:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2918: train loss 2.79839. lr 5.882506e-04:  18%|█▊        | 2919/16329 [24:36<1:54:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2919: train loss 2.74186. lr 5.882426e-04:  18%|█▊        | 2919/16329 [24:36<1:54:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2919: train loss 2.74186. lr 5.882426e-04:  18%|█▊        | 2920/16329 [24:36<1:53:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2920: train loss 2.70352. lr 5.882346e-04:  18%|█▊        | 2920/16329 [24:37<1:53:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2920: train loss 2.70352. lr 5.882346e-04:  18%|█▊        | 2921/16329 [24:37<1:52:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2921: train loss 2.71694. lr 5.882266e-04:  18%|█▊        | 2921/16329 [24:37<1:52:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2921: train loss 2.71694. lr 5.882266e-04:  18%|█▊        | 2922/16329 [24:37<1:51:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2922: train loss 2.71765. lr 5.882186e-04:  18%|█▊        | 2922/16329 [24:37<1:51:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2922: train loss 2.71765. lr 5.882186e-04:  18%|█▊        | 2923/16329 [24:37<1:51:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2923: train loss 2.73690. lr 5.882105e-04:  18%|█▊        | 2923/16329 [24:38<1:51:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2923: train loss 2.73690. lr 5.882105e-04:  18%|█▊        | 2924/16329 [24:38<1:51:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2924: train loss 2.76594. lr 5.882025e-04:  18%|█▊        | 2924/16329 [24:38<1:51:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2924: train loss 2.76594. lr 5.882025e-04:  18%|█▊        | 2925/16329 [24:38<1:50:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2925: train loss 2.69546. lr 5.881945e-04:  18%|█▊        | 2925/16329 [24:39<1:50:56,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2925: train loss 2.69546. lr 5.881945e-04:  18%|█▊        | 2926/16329 [24:39<1:51:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2926: train loss 2.79772. lr 5.881865e-04:  18%|█▊        | 2926/16329 [24:39<1:51:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2926: train loss 2.79772. lr 5.881865e-04:  18%|█▊        | 2927/16329 [24:39<1:50:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2927: train loss 2.70951. lr 5.881785e-04:  18%|█▊        | 2927/16329 [24:40<1:50:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2927: train loss 2.70951. lr 5.881785e-04:  18%|█▊        | 2928/16329 [24:40<1:50:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2928: train loss 2.75316. lr 5.881705e-04:  18%|█▊        | 2928/16329 [24:40<1:50:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2928: train loss 2.75316. lr 5.881705e-04:  18%|█▊        | 2929/16329 [24:40<1:50:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2929: train loss 2.68730. lr 5.881624e-04:  18%|█▊        | 2929/16329 [24:41<1:50:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2929: train loss 2.68730. lr 5.881624e-04:  18%|█▊        | 2930/16329 [24:41<1:50:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2930: train loss 2.73877. lr 5.881544e-04:  18%|█▊        | 2930/16329 [24:41<1:50:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2930: train loss 2.73877. lr 5.881544e-04:  18%|█▊        | 2931/16329 [24:41<1:50:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2931: train loss 2.74505. lr 5.881464e-04:  18%|█▊        | 2931/16329 [24:42<1:50:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2931: train loss 2.74505. lr 5.881464e-04:  18%|█▊        | 2932/16329 [24:42<1:50:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2932: train loss 2.76856. lr 5.881383e-04:  18%|█▊        | 2932/16329 [24:42<1:50:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2932: train loss 2.76856. lr 5.881383e-04:  18%|█▊        | 2933/16329 [24:42<1:49:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2933: train loss 2.78931. lr 5.881303e-04:  18%|█▊        | 2933/16329 [24:43<1:49:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2933: train loss 2.78931. lr 5.881303e-04:  18%|█▊        | 2934/16329 [24:43<1:49:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2934: train loss 2.77487. lr 5.881223e-04:  18%|█▊        | 2934/16329 [24:43<1:49:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2934: train loss 2.77487. lr 5.881223e-04:  18%|█▊        | 2935/16329 [24:43<1:50:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2935: train loss 2.75318. lr 5.881142e-04:  18%|█▊        | 2935/16329 [24:44<1:50:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2935: train loss 2.75318. lr 5.881142e-04:  18%|█▊        | 2936/16329 [24:44<1:50:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2936: train loss 2.74295. lr 5.881062e-04:  18%|█▊        | 2936/16329 [24:44<1:50:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2936: train loss 2.74295. lr 5.881062e-04:  18%|█▊        | 2937/16329 [24:44<1:50:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2937: train loss 2.73727. lr 5.880981e-04:  18%|█▊        | 2937/16329 [24:45<1:50:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2937: train loss 2.73727. lr 5.880981e-04:  18%|█▊        | 2938/16329 [24:45<1:50:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2938: train loss 2.72229. lr 5.880901e-04:  18%|█▊        | 2938/16329 [24:45<1:50:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2938: train loss 2.72229. lr 5.880901e-04:  18%|█▊        | 2939/16329 [24:45<1:50:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2939: train loss 2.70124. lr 5.880820e-04:  18%|█▊        | 2939/16329 [24:46<1:50:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2939: train loss 2.70124. lr 5.880820e-04:  18%|█▊        | 2940/16329 [24:46<1:50:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2940: train loss 2.75591. lr 5.880740e-04:  18%|█▊        | 2940/16329 [24:46<1:50:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2940: train loss 2.75591. lr 5.880740e-04:  18%|█▊        | 2941/16329 [24:46<1:50:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2941: train loss 2.77928. lr 5.880659e-04:  18%|█▊        | 2941/16329 [24:47<1:50:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2941: train loss 2.77928. lr 5.880659e-04:  18%|█▊        | 2942/16329 [24:47<1:50:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2942: train loss 2.70610. lr 5.880579e-04:  18%|█▊        | 2942/16329 [24:47<1:50:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2942: train loss 2.70610. lr 5.880579e-04:  18%|█▊        | 2943/16329 [24:47<1:50:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2943: train loss 2.77853. lr 5.880498e-04:  18%|█▊        | 2943/16329 [24:48<1:50:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2943: train loss 2.77853. lr 5.880498e-04:  18%|█▊        | 2944/16329 [24:48<1:50:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2944: train loss 2.74070. lr 5.880417e-04:  18%|█▊        | 2944/16329 [24:48<1:50:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2944: train loss 2.74070. lr 5.880417e-04:  18%|█▊        | 2945/16329 [24:48<1:50:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2945: train loss 2.76844. lr 5.880337e-04:  18%|█▊        | 2945/16329 [24:49<1:50:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2945: train loss 2.76844. lr 5.880337e-04:  18%|█▊        | 2946/16329 [24:49<1:52:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2946: train loss 2.72659. lr 5.880256e-04:  18%|█▊        | 2946/16329 [24:49<1:52:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2946: train loss 2.72659. lr 5.880256e-04:  18%|█▊        | 2947/16329 [24:49<1:53:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2947: train loss 2.78656. lr 5.880175e-04:  18%|█▊        | 2947/16329 [24:50<1:53:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2947: train loss 2.78656. lr 5.880175e-04:  18%|█▊        | 2948/16329 [24:50<1:53:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2948: train loss 2.67167. lr 5.880094e-04:  18%|█▊        | 2948/16329 [24:50<1:53:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2948: train loss 2.67167. lr 5.880094e-04:  18%|█▊        | 2949/16329 [24:50<1:53:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2949: train loss 2.66907. lr 5.880014e-04:  18%|█▊        | 2949/16329 [24:51<1:53:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2949: train loss 2.66907. lr 5.880014e-04:  18%|█▊        | 2950/16329 [24:51<1:52:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2950: train loss 2.72798. lr 5.879933e-04:  18%|█▊        | 2950/16329 [24:51<1:52:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2950: train loss 2.72798. lr 5.879933e-04:  18%|█▊        | 2951/16329 [24:51<1:52:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2951: train loss 2.74855. lr 5.879852e-04:  18%|█▊        | 2951/16329 [24:52<1:52:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2951: train loss 2.74855. lr 5.879852e-04:  18%|█▊        | 2952/16329 [24:52<1:51:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2952: train loss 2.73004. lr 5.879771e-04:  18%|█▊        | 2952/16329 [24:52<1:51:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2952: train loss 2.73004. lr 5.879771e-04:  18%|█▊        | 2953/16329 [24:52<1:51:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2953: train loss 2.70272. lr 5.879690e-04:  18%|█▊        | 2953/16329 [24:53<1:51:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2953: train loss 2.70272. lr 5.879690e-04:  18%|█▊        | 2954/16329 [24:53<1:51:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2954: train loss 2.68402. lr 5.879609e-04:  18%|█▊        | 2954/16329 [24:53<1:51:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2954: train loss 2.68402. lr 5.879609e-04:  18%|█▊        | 2955/16329 [24:53<1:50:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2955: train loss 2.71352. lr 5.879528e-04:  18%|█▊        | 2955/16329 [24:54<1:50:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2955: train loss 2.71352. lr 5.879528e-04:  18%|█▊        | 2956/16329 [24:54<2:02:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2956: train loss 2.76055. lr 5.879447e-04:  18%|█▊        | 2956/16329 [24:55<2:02:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 2956: train loss 2.76055. lr 5.879447e-04:  18%|█▊        | 2957/16329 [24:55<1:58:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2957: train loss 2.74392. lr 5.879366e-04:  18%|█▊        | 2957/16329 [24:55<1:58:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 2957: train loss 2.74392. lr 5.879366e-04:  18%|█▊        | 2958/16329 [24:55<1:55:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2958: train loss 2.74214. lr 5.879285e-04:  18%|█▊        | 2958/16329 [24:56<1:55:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 2958: train loss 2.74214. lr 5.879285e-04:  18%|█▊        | 2959/16329 [24:56<1:53:56,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2959: train loss 2.69214. lr 5.879204e-04:  18%|█▊        | 2959/16329 [24:56<1:53:56,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2959: train loss 2.69214. lr 5.879204e-04:  18%|█▊        | 2960/16329 [24:56<1:52:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2960: train loss 2.72745. lr 5.879123e-04:  18%|█▊        | 2960/16329 [24:57<1:52:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2960: train loss 2.72745. lr 5.879123e-04:  18%|█▊        | 2961/16329 [24:57<1:51:41,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2961: train loss 2.75024. lr 5.879042e-04:  18%|█▊        | 2961/16329 [24:57<1:51:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2961: train loss 2.75024. lr 5.879042e-04:  18%|█▊        | 2962/16329 [24:57<1:51:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2962: train loss 2.66837. lr 5.878961e-04:  18%|█▊        | 2962/16329 [24:58<1:51:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2962: train loss 2.66837. lr 5.878961e-04:  18%|█▊        | 2963/16329 [24:58<1:50:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2963: train loss 2.78210. lr 5.878880e-04:  18%|█▊        | 2963/16329 [24:58<1:50:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2963: train loss 2.78210. lr 5.878880e-04:  18%|█▊        | 2964/16329 [24:58<1:50:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2964: train loss 2.75081. lr 5.878798e-04:  18%|█▊        | 2964/16329 [24:59<1:50:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2964: train loss 2.75081. lr 5.878798e-04:  18%|█▊        | 2965/16329 [24:59<1:50:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2965: train loss 2.75547. lr 5.878717e-04:  18%|█▊        | 2965/16329 [24:59<1:50:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2965: train loss 2.75547. lr 5.878717e-04:  18%|█▊        | 2966/16329 [24:59<1:50:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2966: train loss 2.68526. lr 5.878636e-04:  18%|█▊        | 2966/16329 [25:00<1:50:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2966: train loss 2.68526. lr 5.878636e-04:  18%|█▊        | 2967/16329 [25:00<1:53:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2967: train loss 2.74956. lr 5.878555e-04:  18%|█▊        | 2967/16329 [25:00<1:53:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2967: train loss 2.74956. lr 5.878555e-04:  18%|█▊        | 2968/16329 [25:00<1:54:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2968: train loss 2.73221. lr 5.878473e-04:  18%|█▊        | 2968/16329 [25:01<1:54:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 2968: train loss 2.73221. lr 5.878473e-04:  18%|█▊        | 2969/16329 [25:01<1:54:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2969: train loss 2.64684. lr 5.878392e-04:  18%|█▊        | 2969/16329 [25:01<1:54:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2969: train loss 2.64684. lr 5.878392e-04:  18%|█▊        | 2970/16329 [25:01<1:54:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2970: train loss 2.75458. lr 5.878311e-04:  18%|█▊        | 2970/16329 [25:02<1:54:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 2970: train loss 2.75458. lr 5.878311e-04:  18%|█▊        | 2971/16329 [25:02<1:53:18,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2971: train loss 2.75033. lr 5.878229e-04:  18%|█▊        | 2971/16329 [25:02<1:53:18,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2971: train loss 2.75033. lr 5.878229e-04:  18%|█▊        | 2972/16329 [25:02<1:52:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2972: train loss 2.73471. lr 5.878148e-04:  18%|█▊        | 2972/16329 [25:03<1:52:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 2972: train loss 2.73471. lr 5.878148e-04:  18%|█▊        | 2973/16329 [25:03<1:51:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2973: train loss 2.75246. lr 5.878067e-04:  18%|█▊        | 2973/16329 [25:03<1:51:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 2973: train loss 2.75246. lr 5.878067e-04:  18%|█▊        | 2974/16329 [25:03<1:51:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2974: train loss 2.71376. lr 5.877985e-04:  18%|█▊        | 2974/16329 [25:04<1:51:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2974: train loss 2.71376. lr 5.877985e-04:  18%|█▊        | 2975/16329 [25:04<1:51:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2975: train loss 2.68418. lr 5.877904e-04:  18%|█▊        | 2975/16329 [25:04<1:51:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2975: train loss 2.68418. lr 5.877904e-04:  18%|█▊        | 2976/16329 [25:04<1:50:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2976: train loss 2.78327. lr 5.877822e-04:  18%|█▊        | 2976/16329 [25:05<1:50:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2976: train loss 2.78327. lr 5.877822e-04:  18%|█▊        | 2977/16329 [25:05<1:50:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2977: train loss 2.81689. lr 5.877741e-04:  18%|█▊        | 2977/16329 [25:05<1:50:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2977: train loss 2.81689. lr 5.877741e-04:  18%|█▊        | 2978/16329 [25:05<1:50:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2978: train loss 2.80090. lr 5.877659e-04:  18%|█▊        | 2978/16329 [25:06<1:50:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2978: train loss 2.80090. lr 5.877659e-04:  18%|█▊        | 2979/16329 [25:06<1:49:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2979: train loss 2.73340. lr 5.877577e-04:  18%|█▊        | 2979/16329 [25:06<1:49:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2979: train loss 2.73340. lr 5.877577e-04:  18%|█▊        | 2980/16329 [25:06<1:49:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2980: train loss 2.69041. lr 5.877496e-04:  18%|█▊        | 2980/16329 [25:07<1:49:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2980: train loss 2.69041. lr 5.877496e-04:  18%|█▊        | 2981/16329 [25:07<1:49:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2981: train loss 2.76878. lr 5.877414e-04:  18%|█▊        | 2981/16329 [25:07<1:49:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2981: train loss 2.76878. lr 5.877414e-04:  18%|█▊        | 2982/16329 [25:07<1:49:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2982: train loss 2.67929. lr 5.877332e-04:  18%|█▊        | 2982/16329 [25:08<1:49:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2982: train loss 2.67929. lr 5.877332e-04:  18%|█▊        | 2983/16329 [25:08<1:49:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2983: train loss 2.77688. lr 5.877251e-04:  18%|█▊        | 2983/16329 [25:08<1:49:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2983: train loss 2.77688. lr 5.877251e-04:  18%|█▊        | 2984/16329 [25:08<1:49:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2984: train loss 2.68085. lr 5.877169e-04:  18%|█▊        | 2984/16329 [25:09<1:49:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2984: train loss 2.68085. lr 5.877169e-04:  18%|█▊        | 2985/16329 [25:09<1:49:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2985: train loss 2.70234. lr 5.877087e-04:  18%|█▊        | 2985/16329 [25:09<1:49:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2985: train loss 2.70234. lr 5.877087e-04:  18%|█▊        | 2986/16329 [25:09<1:49:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2986: train loss 2.76516. lr 5.877006e-04:  18%|█▊        | 2986/16329 [25:10<1:49:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2986: train loss 2.76516. lr 5.877006e-04:  18%|█▊        | 2987/16329 [25:10<1:50:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2987: train loss 2.67268. lr 5.876924e-04:  18%|█▊        | 2987/16329 [25:10<1:50:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2987: train loss 2.67268. lr 5.876924e-04:  18%|█▊        | 2988/16329 [25:10<1:50:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2988: train loss 2.66587. lr 5.876842e-04:  18%|█▊        | 2988/16329 [25:10<1:50:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2988: train loss 2.66587. lr 5.876842e-04:  18%|█▊        | 2989/16329 [25:10<1:49:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2989: train loss 2.73261. lr 5.876760e-04:  18%|█▊        | 2989/16329 [25:11<1:49:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2989: train loss 2.73261. lr 5.876760e-04:  18%|█▊        | 2990/16329 [25:11<1:49:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2990: train loss 2.70710. lr 5.876678e-04:  18%|█▊        | 2990/16329 [25:12<1:49:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 2990: train loss 2.70710. lr 5.876678e-04:  18%|█▊        | 2991/16329 [25:12<2:01:06,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2991: train loss 2.76720. lr 5.876596e-04:  18%|█▊        | 2991/16329 [25:12<2:01:06,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 2991: train loss 2.76720. lr 5.876596e-04:  18%|█▊        | 2992/16329 [25:12<1:57:27,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2992: train loss 2.67976. lr 5.876514e-04:  18%|█▊        | 2992/16329 [25:13<1:57:27,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 2992: train loss 2.67976. lr 5.876514e-04:  18%|█▊        | 2993/16329 [25:13<1:55:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2993: train loss 2.63701. lr 5.876432e-04:  18%|█▊        | 2993/16329 [25:13<1:55:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 2993: train loss 2.63701. lr 5.876432e-04:  18%|█▊        | 2994/16329 [25:13<1:53:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2994: train loss 2.75139. lr 5.876350e-04:  18%|█▊        | 2994/16329 [25:14<1:53:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 2994: train loss 2.75139. lr 5.876350e-04:  18%|█▊        | 2995/16329 [25:14<1:52:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2995: train loss 2.60464. lr 5.876268e-04:  18%|█▊        | 2995/16329 [25:14<1:52:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 2995: train loss 2.60464. lr 5.876268e-04:  18%|█▊        | 2996/16329 [25:14<1:51:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 2996: train loss 2.72755. lr 5.876186e-04:  18%|█▊        | 2996/16329 [25:15<1:51:20,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2996: train loss 2.72755. lr 5.876186e-04:  18%|█▊        | 2997/16329 [25:15<1:50:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2997: train loss 2.65435. lr 5.876104e-04:  18%|█▊        | 2997/16329 [25:15<1:50:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2997: train loss 2.65435. lr 5.876104e-04:  18%|█▊        | 2998/16329 [25:15<1:50:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2998: train loss 2.71926. lr 5.876022e-04:  18%|█▊        | 2998/16329 [25:16<1:50:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 2998: train loss 2.71926. lr 5.876022e-04:  18%|█▊        | 2999/16329 [25:16<1:49:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2999: train loss 2.73631. lr 5.875940e-04:  18%|█▊        | 2999/16329 [25:16<1:49:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 2999: train loss 2.73631. lr 5.875940e-04:  18%|█▊        | 3000/16329 [25:16<1:50:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3000: train loss 2.69687. lr 5.875858e-04:  18%|█▊        | 3000/16329 [25:17<1:50:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3000: train loss 2.69687. lr 5.875858e-04:  18%|█▊        | 3001/16329 [25:17<1:49:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3001: train loss 2.68532. lr 5.875776e-04:  18%|█▊        | 3001/16329 [25:17<1:49:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3001: train loss 2.68532. lr 5.875776e-04:  18%|█▊        | 3002/16329 [25:17<1:49:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3002: train loss 2.76979. lr 5.875693e-04:  18%|█▊        | 3002/16329 [25:18<1:49:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3002: train loss 2.76979. lr 5.875693e-04:  18%|█▊        | 3003/16329 [25:18<1:49:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3003: train loss 2.66290. lr 5.875611e-04:  18%|█▊        | 3003/16329 [25:18<1:49:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3003: train loss 2.66290. lr 5.875611e-04:  18%|█▊        | 3004/16329 [25:18<1:49:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3004: train loss 2.64956. lr 5.875529e-04:  18%|█▊        | 3004/16329 [25:19<1:49:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3004: train loss 2.64956. lr 5.875529e-04:  18%|█▊        | 3005/16329 [25:19<1:49:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3005: train loss 2.67172. lr 5.875447e-04:  18%|█▊        | 3005/16329 [25:19<1:49:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3005: train loss 2.67172. lr 5.875447e-04:  18%|█▊        | 3006/16329 [25:19<1:49:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3006: train loss 2.67517. lr 5.875364e-04:  18%|█▊        | 3006/16329 [25:20<1:49:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3006: train loss 2.67517. lr 5.875364e-04:  18%|█▊        | 3007/16329 [25:20<1:50:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3007: train loss 2.69982. lr 5.875282e-04:  18%|█▊        | 3007/16329 [25:20<1:50:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3007: train loss 2.69982. lr 5.875282e-04:  18%|█▊        | 3008/16329 [25:20<1:50:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3008: train loss 2.69180. lr 5.875200e-04:  18%|█▊        | 3008/16329 [25:21<1:50:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3008: train loss 2.69180. lr 5.875200e-04:  18%|█▊        | 3009/16329 [25:21<1:49:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3009: train loss 2.70064. lr 5.875117e-04:  18%|█▊        | 3009/16329 [25:21<1:49:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3009: train loss 2.70064. lr 5.875117e-04:  18%|█▊        | 3010/16329 [25:21<1:49:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3010: train loss 2.72796. lr 5.875035e-04:  18%|█▊        | 3010/16329 [25:22<1:49:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3010: train loss 2.72796. lr 5.875035e-04:  18%|█▊        | 3011/16329 [25:22<1:49:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3011: train loss 2.66699. lr 5.874952e-04:  18%|█▊        | 3011/16329 [25:22<1:49:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3011: train loss 2.66699. lr 5.874952e-04:  18%|█▊        | 3012/16329 [25:22<1:49:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3012: train loss 2.63292. lr 5.874870e-04:  18%|█▊        | 3012/16329 [25:23<1:49:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3012: train loss 2.63292. lr 5.874870e-04:  18%|█▊        | 3013/16329 [25:23<1:49:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3013: train loss 2.69541. lr 5.874787e-04:  18%|█▊        | 3013/16329 [25:23<1:49:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3013: train loss 2.69541. lr 5.874787e-04:  18%|█▊        | 3014/16329 [25:23<1:49:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3014: train loss 2.71153. lr 5.874705e-04:  18%|█▊        | 3014/16329 [25:23<1:49:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3014: train loss 2.71153. lr 5.874705e-04:  18%|█▊        | 3015/16329 [25:23<1:49:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3015: train loss 2.68963. lr 5.874622e-04:  18%|█▊        | 3015/16329 [25:24<1:49:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3015: train loss 2.68963. lr 5.874622e-04:  18%|█▊        | 3016/16329 [25:24<2:00:45,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3016: train loss 2.70253. lr 5.874540e-04:  18%|█▊        | 3016/16329 [25:25<2:00:45,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3016: train loss 2.70253. lr 5.874540e-04:  18%|█▊        | 3017/16329 [25:25<1:57:36,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3017: train loss 2.70723. lr 5.874457e-04:  18%|█▊        | 3017/16329 [25:25<1:57:36,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3017: train loss 2.70723. lr 5.874457e-04:  18%|█▊        | 3018/16329 [25:25<1:55:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3018: train loss 2.69841. lr 5.874375e-04:  18%|█▊        | 3018/16329 [25:26<1:55:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3018: train loss 2.69841. lr 5.874375e-04:  18%|█▊        | 3019/16329 [25:26<1:53:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3019: train loss 2.69921. lr 5.874292e-04:  18%|█▊        | 3019/16329 [25:26<1:53:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3019: train loss 2.69921. lr 5.874292e-04:  18%|█▊        | 3020/16329 [25:26<1:52:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3020: train loss 2.69174. lr 5.874209e-04:  18%|█▊        | 3020/16329 [25:27<1:52:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3020: train loss 2.69174. lr 5.874209e-04:  19%|█▊        | 3021/16329 [25:27<1:51:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3021: train loss 2.64183. lr 5.874127e-04:  19%|█▊        | 3021/16329 [25:27<1:51:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3021: train loss 2.64183. lr 5.874127e-04:  19%|█▊        | 3022/16329 [25:27<1:51:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3022: train loss 2.71390. lr 5.874044e-04:  19%|█▊        | 3022/16329 [25:28<1:51:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3022: train loss 2.71390. lr 5.874044e-04:  19%|█▊        | 3023/16329 [25:28<1:50:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3023: train loss 2.64352. lr 5.873961e-04:  19%|█▊        | 3023/16329 [25:28<1:50:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3023: train loss 2.64352. lr 5.873961e-04:  19%|█▊        | 3024/16329 [25:28<1:49:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3024: train loss 2.72010. lr 5.873878e-04:  19%|█▊        | 3024/16329 [25:29<1:49:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3024: train loss 2.72010. lr 5.873878e-04:  19%|█▊        | 3025/16329 [25:29<1:49:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3025: train loss 2.72264. lr 5.873795e-04:  19%|█▊        | 3025/16329 [25:29<1:49:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3025: train loss 2.72264. lr 5.873795e-04:  19%|█▊        | 3026/16329 [25:29<1:49:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3026: train loss 2.70162. lr 5.873713e-04:  19%|█▊        | 3026/16329 [25:30<1:49:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3026: train loss 2.70162. lr 5.873713e-04:  19%|█▊        | 3027/16329 [25:30<1:49:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3027: train loss 2.67338. lr 5.873630e-04:  19%|█▊        | 3027/16329 [25:30<1:49:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3027: train loss 2.67338. lr 5.873630e-04:  19%|█▊        | 3028/16329 [25:30<1:49:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3028: train loss 2.70499. lr 5.873547e-04:  19%|█▊        | 3028/16329 [25:31<1:49:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3028: train loss 2.70499. lr 5.873547e-04:  19%|█▊        | 3029/16329 [25:31<1:49:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3029: train loss 2.72676. lr 5.873464e-04:  19%|█▊        | 3029/16329 [25:31<1:49:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3029: train loss 2.72676. lr 5.873464e-04:  19%|█▊        | 3030/16329 [25:31<1:49:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3030: train loss 2.64685. lr 5.873381e-04:  19%|█▊        | 3030/16329 [25:32<1:49:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3030: train loss 2.64685. lr 5.873381e-04:  19%|█▊        | 3031/16329 [25:32<1:49:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3031: train loss 2.70596. lr 5.873298e-04:  19%|█▊        | 3031/16329 [25:32<1:49:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3031: train loss 2.70596. lr 5.873298e-04:  19%|█▊        | 3032/16329 [25:32<1:49:23,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3032: train loss 2.66362. lr 5.873215e-04:  19%|█▊        | 3032/16329 [25:33<1:49:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3032: train loss 2.66362. lr 5.873215e-04:  19%|█▊        | 3033/16329 [25:33<1:49:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3033: train loss 2.77328. lr 5.873132e-04:  19%|█▊        | 3033/16329 [25:33<1:49:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3033: train loss 2.77328. lr 5.873132e-04:  19%|█▊        | 3034/16329 [25:33<1:49:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3034: train loss 2.67832. lr 5.873049e-04:  19%|█▊        | 3034/16329 [25:34<1:49:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3034: train loss 2.67832. lr 5.873049e-04:  19%|█▊        | 3035/16329 [25:34<1:49:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3035: train loss 2.71955. lr 5.872966e-04:  19%|█▊        | 3035/16329 [25:34<1:49:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3035: train loss 2.71955. lr 5.872966e-04:  19%|█▊        | 3036/16329 [25:34<1:49:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3036: train loss 2.67930. lr 5.872883e-04:  19%|█▊        | 3036/16329 [25:35<1:49:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3036: train loss 2.67930. lr 5.872883e-04:  19%|█▊        | 3037/16329 [25:35<1:49:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3037: train loss 2.67007. lr 5.872800e-04:  19%|█▊        | 3037/16329 [25:35<1:49:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3037: train loss 2.67007. lr 5.872800e-04:  19%|█▊        | 3038/16329 [25:35<1:49:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3038: train loss 2.69948. lr 5.872716e-04:  19%|█▊        | 3038/16329 [25:36<1:49:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3038: train loss 2.69948. lr 5.872716e-04:  19%|█▊        | 3039/16329 [25:36<1:49:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3039: train loss 2.69644. lr 5.872633e-04:  19%|█▊        | 3039/16329 [25:36<1:49:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3039: train loss 2.69644. lr 5.872633e-04:  19%|█▊        | 3040/16329 [25:36<1:49:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3040: train loss 2.63417. lr 5.872550e-04:  19%|█▊        | 3040/16329 [25:36<1:49:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3040: train loss 2.63417. lr 5.872550e-04:  19%|█▊        | 3041/16329 [25:36<1:49:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3041: train loss 2.72185. lr 5.872467e-04:  19%|█▊        | 3041/16329 [25:37<1:49:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3041: train loss 2.72185. lr 5.872467e-04:  19%|█▊        | 3042/16329 [25:37<1:49:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3042: train loss 2.68168. lr 5.872384e-04:  19%|█▊        | 3042/16329 [25:38<1:49:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3042: train loss 2.68168. lr 5.872384e-04:  19%|█▊        | 3043/16329 [25:38<2:00:35,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3043: train loss 2.66049. lr 5.872300e-04:  19%|█▊        | 3043/16329 [25:38<2:00:35,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3043: train loss 2.66049. lr 5.872300e-04:  19%|█▊        | 3044/16329 [25:38<1:56:57,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3044: train loss 2.72194. lr 5.872217e-04:  19%|█▊        | 3044/16329 [25:39<1:56:57,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3044: train loss 2.72194. lr 5.872217e-04:  19%|█▊        | 3045/16329 [25:39<1:54:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3045: train loss 2.72246. lr 5.872134e-04:  19%|█▊        | 3045/16329 [25:39<1:54:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3045: train loss 2.72246. lr 5.872134e-04:  19%|█▊        | 3046/16329 [25:39<1:52:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3046: train loss 2.69793. lr 5.872050e-04:  19%|█▊        | 3046/16329 [25:40<1:52:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3046: train loss 2.69793. lr 5.872050e-04:  19%|█▊        | 3047/16329 [25:40<1:51:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3047: train loss 2.71076. lr 5.871967e-04:  19%|█▊        | 3047/16329 [25:40<1:51:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3047: train loss 2.71076. lr 5.871967e-04:  19%|█▊        | 3048/16329 [25:40<1:51:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3048: train loss 2.63897. lr 5.871883e-04:  19%|█▊        | 3048/16329 [25:41<1:51:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3048: train loss 2.63897. lr 5.871883e-04:  19%|█▊        | 3049/16329 [25:41<1:50:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3049: train loss 2.64016. lr 5.871800e-04:  19%|█▊        | 3049/16329 [25:41<1:50:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3049: train loss 2.64016. lr 5.871800e-04:  19%|█▊        | 3050/16329 [25:41<1:50:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3050: train loss 2.63861. lr 5.871716e-04:  19%|█▊        | 3050/16329 [25:42<1:50:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3050: train loss 2.63861. lr 5.871716e-04:  19%|█▊        | 3051/16329 [25:42<1:49:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3051: train loss 2.71350. lr 5.871633e-04:  19%|█▊        | 3051/16329 [25:42<1:49:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3051: train loss 2.71350. lr 5.871633e-04:  19%|█▊        | 3052/16329 [25:42<1:49:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3052: train loss 2.65627. lr 5.871549e-04:  19%|█▊        | 3052/16329 [25:43<1:49:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3052: train loss 2.65627. lr 5.871549e-04:  19%|█▊        | 3053/16329 [25:43<1:49:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3053: train loss 2.64185. lr 5.871466e-04:  19%|█▊        | 3053/16329 [25:43<1:49:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3053: train loss 2.64185. lr 5.871466e-04:  19%|█▊        | 3054/16329 [25:43<1:49:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3054: train loss 2.65571. lr 5.871382e-04:  19%|█▊        | 3054/16329 [25:44<1:49:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3054: train loss 2.65571. lr 5.871382e-04:  19%|█▊        | 3055/16329 [25:44<1:49:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3055: train loss 2.67891. lr 5.871299e-04:  19%|█▊        | 3055/16329 [25:44<1:49:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3055: train loss 2.67891. lr 5.871299e-04:  19%|█▊        | 3056/16329 [25:44<1:49:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3056: train loss 2.66649. lr 5.871215e-04:  19%|█▊        | 3056/16329 [25:45<1:49:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3056: train loss 2.66649. lr 5.871215e-04:  19%|█▊        | 3057/16329 [25:45<1:53:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3057: train loss 2.68889. lr 5.871131e-04:  19%|█▊        | 3057/16329 [25:45<1:53:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3057: train loss 2.68889. lr 5.871131e-04:  19%|█▊        | 3058/16329 [25:45<1:55:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3058: train loss 2.71728. lr 5.871048e-04:  19%|█▊        | 3058/16329 [25:46<1:55:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3058: train loss 2.71728. lr 5.871048e-04:  19%|█▊        | 3059/16329 [25:46<1:55:18,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3059: train loss 2.60837. lr 5.870964e-04:  19%|█▊        | 3059/16329 [25:46<1:55:18,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3059: train loss 2.60837. lr 5.870964e-04:  19%|█▊        | 3060/16329 [25:46<1:55:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3060: train loss 2.65009. lr 5.870880e-04:  19%|█▊        | 3060/16329 [25:47<1:55:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3060: train loss 2.65009. lr 5.870880e-04:  19%|█▊        | 3061/16329 [25:47<1:54:03,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3061: train loss 2.72494. lr 5.870796e-04:  19%|█▊        | 3061/16329 [25:47<1:54:03,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3061: train loss 2.72494. lr 5.870796e-04:  19%|█▉        | 3062/16329 [25:47<1:53:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3062: train loss 2.67004. lr 5.870713e-04:  19%|█▉        | 3062/16329 [25:48<1:53:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3062: train loss 2.67004. lr 5.870713e-04:  19%|█▉        | 3063/16329 [25:48<1:52:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3063: train loss 2.65386. lr 5.870629e-04:  19%|█▉        | 3063/16329 [25:48<1:52:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3063: train loss 2.65386. lr 5.870629e-04:  19%|█▉        | 3064/16329 [25:48<1:51:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3064: train loss 2.74394. lr 5.870545e-04:  19%|█▉        | 3064/16329 [25:49<1:51:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3064: train loss 2.74394. lr 5.870545e-04:  19%|█▉        | 3065/16329 [25:49<1:50:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3065: train loss 2.60988. lr 5.870461e-04:  19%|█▉        | 3065/16329 [25:49<1:50:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3065: train loss 2.60988. lr 5.870461e-04:  19%|█▉        | 3066/16329 [25:49<1:49:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3066: train loss 2.70602. lr 5.870377e-04:  19%|█▉        | 3066/16329 [25:50<1:49:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3066: train loss 2.70602. lr 5.870377e-04:  19%|█▉        | 3067/16329 [25:50<1:49:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3067: train loss 2.64349. lr 5.870293e-04:  19%|█▉        | 3067/16329 [25:50<1:49:42,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3067: train loss 2.64349. lr 5.870293e-04:  19%|█▉        | 3068/16329 [25:50<1:49:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3068: train loss 2.63712. lr 5.870209e-04:  19%|█▉        | 3068/16329 [25:51<1:49:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3068: train loss 2.63712. lr 5.870209e-04:  19%|█▉        | 3069/16329 [25:51<1:49:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3069: train loss 2.72014. lr 5.870125e-04:  19%|█▉        | 3069/16329 [25:51<1:49:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3069: train loss 2.72014. lr 5.870125e-04:  19%|█▉        | 3070/16329 [25:51<1:49:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3070: train loss 2.64746. lr 5.870041e-04:  19%|█▉        | 3070/16329 [25:52<1:49:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3070: train loss 2.64746. lr 5.870041e-04:  19%|█▉        | 3071/16329 [25:52<1:49:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3071: train loss 2.57193. lr 5.869957e-04:  19%|█▉        | 3071/16329 [25:52<1:49:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3071: train loss 2.57193. lr 5.869957e-04:  19%|█▉        | 3072/16329 [25:52<1:49:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3072: train loss 2.65763. lr 5.869873e-04:  19%|█▉        | 3072/16329 [25:53<1:49:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3072: train loss 2.65763. lr 5.869873e-04:  19%|█▉        | 3073/16329 [25:53<1:48:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3073: train loss 2.70198. lr 5.869789e-04:  19%|█▉        | 3073/16329 [25:53<1:48:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3073: train loss 2.70198. lr 5.869789e-04:  19%|█▉        | 3074/16329 [25:53<1:49:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3074: train loss 2.64589. lr 5.869705e-04:  19%|█▉        | 3074/16329 [25:54<1:49:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3074: train loss 2.64589. lr 5.869705e-04:  19%|█▉        | 3075/16329 [25:54<1:49:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3075: train loss 2.73306. lr 5.869621e-04:  19%|█▉        | 3075/16329 [25:54<1:49:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3075: train loss 2.73306. lr 5.869621e-04:  19%|█▉        | 3076/16329 [25:54<1:49:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3076: train loss 2.64077. lr 5.869537e-04:  19%|█▉        | 3076/16329 [25:55<1:49:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3076: train loss 2.64077. lr 5.869537e-04:  19%|█▉        | 3077/16329 [25:55<1:49:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3077: train loss 2.70250. lr 5.869452e-04:  19%|█▉        | 3077/16329 [25:55<1:49:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3077: train loss 2.70250. lr 5.869452e-04:  19%|█▉        | 3078/16329 [25:55<1:49:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3078: train loss 2.63977. lr 5.869368e-04:  19%|█▉        | 3078/16329 [25:56<1:49:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3078: train loss 2.63977. lr 5.869368e-04:  19%|█▉        | 3079/16329 [25:56<1:49:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3079: train loss 2.67698. lr 5.869284e-04:  19%|█▉        | 3079/16329 [25:56<1:49:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3079: train loss 2.67698. lr 5.869284e-04:  19%|█▉        | 3080/16329 [25:56<1:49:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3080: train loss 2.67433. lr 5.869200e-04:  19%|█▉        | 3080/16329 [25:57<1:49:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3080: train loss 2.67433. lr 5.869200e-04:  19%|█▉        | 3081/16329 [25:57<1:49:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3081: train loss 2.62323. lr 5.869115e-04:  19%|█▉        | 3081/16329 [25:57<1:49:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3081: train loss 2.62323. lr 5.869115e-04:  19%|█▉        | 3082/16329 [25:57<1:49:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3082: train loss 2.69245. lr 5.869031e-04:  19%|█▉        | 3082/16329 [25:58<1:49:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3082: train loss 2.69245. lr 5.869031e-04:  19%|█▉        | 3083/16329 [25:58<2:03:00,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3083: train loss 2.67462. lr 5.868947e-04:  19%|█▉        | 3083/16329 [25:58<2:03:00,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3083: train loss 2.67462. lr 5.868947e-04:  19%|█▉        | 3084/16329 [25:58<1:58:44,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3084: train loss 2.77819. lr 5.868862e-04:  19%|█▉        | 3084/16329 [25:59<1:58:44,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3084: train loss 2.77819. lr 5.868862e-04:  19%|█▉        | 3085/16329 [25:59<1:55:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3085: train loss 2.70589. lr 5.868778e-04:  19%|█▉        | 3085/16329 [25:59<1:55:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3085: train loss 2.70589. lr 5.868778e-04:  19%|█▉        | 3086/16329 [25:59<1:53:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3086: train loss 2.66323. lr 5.868694e-04:  19%|█▉        | 3086/16329 [26:00<1:53:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3086: train loss 2.66323. lr 5.868694e-04:  19%|█▉        | 3087/16329 [26:00<1:52:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3087: train loss 2.71946. lr 5.868609e-04:  19%|█▉        | 3087/16329 [26:00<1:52:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3087: train loss 2.71946. lr 5.868609e-04:  19%|█▉        | 3088/16329 [26:00<1:51:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3088: train loss 2.62913. lr 5.868525e-04:  19%|█▉        | 3088/16329 [26:01<1:51:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3088: train loss 2.62913. lr 5.868525e-04:  19%|█▉        | 3089/16329 [26:01<1:50:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3089: train loss 2.71209. lr 5.868440e-04:  19%|█▉        | 3089/16329 [26:01<1:50:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3089: train loss 2.71209. lr 5.868440e-04:  19%|█▉        | 3090/16329 [26:01<1:49:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3090: train loss 2.62321. lr 5.868356e-04:  19%|█▉        | 3090/16329 [26:02<1:49:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3090: train loss 2.62321. lr 5.868356e-04:  19%|█▉        | 3091/16329 [26:02<1:49:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3091: train loss 2.70046. lr 5.868271e-04:  19%|█▉        | 3091/16329 [26:02<1:49:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3091: train loss 2.70046. lr 5.868271e-04:  19%|█▉        | 3092/16329 [26:02<1:49:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3092: train loss 2.70669. lr 5.868186e-04:  19%|█▉        | 3092/16329 [26:03<1:49:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3092: train loss 2.70669. lr 5.868186e-04:  19%|█▉        | 3093/16329 [26:03<1:49:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3093: train loss 2.72207. lr 5.868102e-04:  19%|█▉        | 3093/16329 [26:03<1:49:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3093: train loss 2.72207. lr 5.868102e-04:  19%|█▉        | 3094/16329 [26:03<1:48:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3094: train loss 2.69492. lr 5.868017e-04:  19%|█▉        | 3094/16329 [26:04<1:48:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3094: train loss 2.69492. lr 5.868017e-04:  19%|█▉        | 3095/16329 [26:04<1:48:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3095: train loss 2.68993. lr 5.867932e-04:  19%|█▉        | 3095/16329 [26:04<1:48:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3095: train loss 2.68993. lr 5.867932e-04:  19%|█▉        | 3096/16329 [26:04<1:48:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3096: train loss 2.67617. lr 5.867848e-04:  19%|█▉        | 3096/16329 [26:05<1:48:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3096: train loss 2.67617. lr 5.867848e-04:  19%|█▉        | 3097/16329 [26:05<1:48:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3097: train loss 2.64705. lr 5.867763e-04:  19%|█▉        | 3097/16329 [26:05<1:48:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3097: train loss 2.64705. lr 5.867763e-04:  19%|█▉        | 3098/16329 [26:05<1:48:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3098: train loss 2.61843. lr 5.867678e-04:  19%|█▉        | 3098/16329 [26:06<1:48:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3098: train loss 2.61843. lr 5.867678e-04:  19%|█▉        | 3099/16329 [26:06<1:48:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3099: train loss 2.61879. lr 5.867593e-04:  19%|█▉        | 3099/16329 [26:06<1:48:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3099: train loss 2.61879. lr 5.867593e-04:  19%|█▉        | 3100/16329 [26:06<1:48:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3100: train loss 2.68846. lr 5.867509e-04:  19%|█▉        | 3100/16329 [26:07<1:48:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3100: train loss 2.68846. lr 5.867509e-04:  19%|█▉        | 3101/16329 [26:07<1:48:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3101: train loss 2.71355. lr 5.867424e-04:  19%|█▉        | 3101/16329 [26:07<1:48:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3101: train loss 2.71355. lr 5.867424e-04:  19%|█▉        | 3102/16329 [26:07<1:48:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3102: train loss 2.67421. lr 5.867339e-04:  19%|█▉        | 3102/16329 [26:08<1:48:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3102: train loss 2.67421. lr 5.867339e-04:  19%|█▉        | 3103/16329 [26:08<1:49:02,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3103: train loss 2.68138. lr 5.867254e-04:  19%|█▉        | 3103/16329 [26:08<1:49:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3103: train loss 2.68138. lr 5.867254e-04:  19%|█▉        | 3104/16329 [26:08<1:48:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3104: train loss 2.58801. lr 5.867169e-04:  19%|█▉        | 3104/16329 [26:09<1:48:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3104: train loss 2.58801. lr 5.867169e-04:  19%|█▉        | 3105/16329 [26:09<1:48:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3105: train loss 2.65803. lr 5.867084e-04:  19%|█▉        | 3105/16329 [26:09<1:48:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3105: train loss 2.65803. lr 5.867084e-04:  19%|█▉        | 3106/16329 [26:09<1:50:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3106: train loss 2.67784. lr 5.866999e-04:  19%|█▉        | 3106/16329 [26:10<1:50:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3106: train loss 2.67784. lr 5.866999e-04:  19%|█▉        | 3107/16329 [26:10<1:52:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3107: train loss 2.64878. lr 5.866914e-04:  19%|█▉        | 3107/16329 [26:10<1:52:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3107: train loss 2.64878. lr 5.866914e-04:  19%|█▉        | 3108/16329 [26:10<1:53:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3108: train loss 2.60402. lr 5.866829e-04:  19%|█▉        | 3108/16329 [26:11<1:53:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3108: train loss 2.60402. lr 5.866829e-04:  19%|█▉        | 3109/16329 [26:11<1:53:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3109: train loss 2.68544. lr 5.866744e-04:  19%|█▉        | 3109/16329 [26:11<1:53:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3109: train loss 2.68544. lr 5.866744e-04:  19%|█▉        | 3110/16329 [26:11<1:51:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3110: train loss 2.62870. lr 5.866659e-04:  19%|█▉        | 3110/16329 [26:12<1:51:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3110: train loss 2.62870. lr 5.866659e-04:  19%|█▉        | 3111/16329 [26:12<1:50:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3111: train loss 2.66057. lr 5.866574e-04:  19%|█▉        | 3111/16329 [26:12<1:50:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3111: train loss 2.66057. lr 5.866574e-04:  19%|█▉        | 3112/16329 [26:12<1:50:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3112: train loss 2.60584. lr 5.866489e-04:  19%|█▉        | 3112/16329 [26:13<1:50:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3112: train loss 2.60584. lr 5.866489e-04:  19%|█▉        | 3113/16329 [26:13<1:49:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3113: train loss 2.68184. lr 5.866404e-04:  19%|█▉        | 3113/16329 [26:13<1:49:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3113: train loss 2.68184. lr 5.866404e-04:  19%|█▉        | 3114/16329 [26:13<1:49:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3114: train loss 2.65240. lr 5.866319e-04:  19%|█▉        | 3114/16329 [26:14<1:49:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3114: train loss 2.65240. lr 5.866319e-04:  19%|█▉        | 3115/16329 [26:14<1:49:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3115: train loss 2.70729. lr 5.866233e-04:  19%|█▉        | 3115/16329 [26:14<1:49:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3115: train loss 2.70729. lr 5.866233e-04:  19%|█▉        | 3116/16329 [26:14<1:49:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3116: train loss 2.61332. lr 5.866148e-04:  19%|█▉        | 3116/16329 [26:15<1:49:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3116: train loss 2.61332. lr 5.866148e-04:  19%|█▉        | 3117/16329 [26:15<1:49:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3117: train loss 2.67705. lr 5.866063e-04:  19%|█▉        | 3117/16329 [26:15<1:49:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3117: train loss 2.67705. lr 5.866063e-04:  19%|█▉        | 3118/16329 [26:15<2:01:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3118: train loss 2.61444. lr 5.865978e-04:  19%|█▉        | 3118/16329 [26:16<2:01:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3118: train loss 2.61444. lr 5.865978e-04:  19%|█▉        | 3119/16329 [26:16<1:57:47,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3119: train loss 2.66613. lr 5.865892e-04:  19%|█▉        | 3119/16329 [26:16<1:57:47,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3119: train loss 2.66613. lr 5.865892e-04:  19%|█▉        | 3120/16329 [26:16<1:54:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3120: train loss 2.65617. lr 5.865807e-04:  19%|█▉        | 3120/16329 [26:17<1:54:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3120: train loss 2.65617. lr 5.865807e-04:  19%|█▉        | 3121/16329 [26:17<1:52:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3121: train loss 2.64618. lr 5.865722e-04:  19%|█▉        | 3121/16329 [26:17<1:52:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3121: train loss 2.64618. lr 5.865722e-04:  19%|█▉        | 3122/16329 [26:17<1:51:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3122: train loss 2.64220. lr 5.865636e-04:  19%|█▉        | 3122/16329 [26:18<1:51:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3122: train loss 2.64220. lr 5.865636e-04:  19%|█▉        | 3123/16329 [26:18<1:50:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3123: train loss 2.64754. lr 5.865551e-04:  19%|█▉        | 3123/16329 [26:18<1:50:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3123: train loss 2.64754. lr 5.865551e-04:  19%|█▉        | 3124/16329 [26:18<1:50:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3124: train loss 2.68433. lr 5.865465e-04:  19%|█▉        | 3124/16329 [26:19<1:50:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3124: train loss 2.68433. lr 5.865465e-04:  19%|█▉        | 3125/16329 [26:19<1:49:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3125: train loss 2.61729. lr 5.865380e-04:  19%|█▉        | 3125/16329 [26:19<1:49:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3125: train loss 2.61729. lr 5.865380e-04:  19%|█▉        | 3126/16329 [26:19<1:49:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3126: train loss 2.69992. lr 5.865294e-04:  19%|█▉        | 3126/16329 [26:20<1:49:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3126: train loss 2.69992. lr 5.865294e-04:  19%|█▉        | 3127/16329 [26:20<1:48:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3127: train loss 2.65775. lr 5.865209e-04:  19%|█▉        | 3127/16329 [26:20<1:48:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3127: train loss 2.65775. lr 5.865209e-04:  19%|█▉        | 3128/16329 [26:20<1:48:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3128: train loss 2.69786. lr 5.865123e-04:  19%|█▉        | 3128/16329 [26:21<1:48:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3128: train loss 2.69786. lr 5.865123e-04:  19%|█▉        | 3129/16329 [26:21<1:48:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3129: train loss 2.68191. lr 5.865038e-04:  19%|█▉        | 3129/16329 [26:21<1:48:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3129: train loss 2.68191. lr 5.865038e-04:  19%|█▉        | 3130/16329 [26:21<1:48:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3130: train loss 2.66771. lr 5.864952e-04:  19%|█▉        | 3130/16329 [26:22<1:48:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3130: train loss 2.66771. lr 5.864952e-04:  19%|█▉        | 3131/16329 [26:22<1:48:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3131: train loss 2.69232. lr 5.864866e-04:  19%|█▉        | 3131/16329 [26:22<1:48:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3131: train loss 2.69232. lr 5.864866e-04:  19%|█▉        | 3132/16329 [26:22<1:48:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3132: train loss 2.60555. lr 5.864781e-04:  19%|█▉        | 3132/16329 [26:23<1:48:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3132: train loss 2.60555. lr 5.864781e-04:  19%|█▉        | 3133/16329 [26:23<1:48:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3133: train loss 2.65875. lr 5.864695e-04:  19%|█▉        | 3133/16329 [26:23<1:48:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3133: train loss 2.65875. lr 5.864695e-04:  19%|█▉        | 3134/16329 [26:23<1:48:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3134: train loss 2.65348. lr 5.864609e-04:  19%|█▉        | 3134/16329 [26:24<1:48:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3134: train loss 2.65348. lr 5.864609e-04:  19%|█▉        | 3135/16329 [26:24<1:48:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3135: train loss 2.60967. lr 5.864524e-04:  19%|█▉        | 3135/16329 [26:24<1:48:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3135: train loss 2.60967. lr 5.864524e-04:  19%|█▉        | 3136/16329 [26:24<1:48:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3136: train loss 2.64178. lr 5.864438e-04:  19%|█▉        | 3136/16329 [26:25<1:48:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3136: train loss 2.64178. lr 5.864438e-04:  19%|█▉        | 3137/16329 [26:25<1:48:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3137: train loss 2.65391. lr 5.864352e-04:  19%|█▉        | 3137/16329 [26:25<1:48:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3137: train loss 2.65391. lr 5.864352e-04:  19%|█▉        | 3138/16329 [26:25<1:48:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3138: train loss 2.58400. lr 5.864266e-04:  19%|█▉        | 3138/16329 [26:26<1:48:34,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3138: train loss 2.58400. lr 5.864266e-04:  19%|█▉        | 3139/16329 [26:26<1:48:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3139: train loss 2.70031. lr 5.864180e-04:  19%|█▉        | 3139/16329 [26:26<1:48:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3139: train loss 2.70031. lr 5.864180e-04:  19%|█▉        | 3140/16329 [26:26<1:48:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3140: train loss 2.64992. lr 5.864095e-04:  19%|█▉        | 3140/16329 [26:27<1:48:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3140: train loss 2.64992. lr 5.864095e-04:  19%|█▉        | 3141/16329 [26:27<1:48:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3141: train loss 2.62725. lr 5.864009e-04:  19%|█▉        | 3141/16329 [26:27<1:48:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3141: train loss 2.62725. lr 5.864009e-04:  19%|█▉        | 3142/16329 [26:27<1:48:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3142: train loss 2.65517. lr 5.863923e-04:  19%|█▉        | 3142/16329 [26:28<1:48:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3142: train loss 2.65517. lr 5.863923e-04:  19%|█▉        | 3143/16329 [26:28<2:00:42,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3143: train loss 2.66973. lr 5.863837e-04:  19%|█▉        | 3143/16329 [26:28<2:00:42,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3143: train loss 2.66973. lr 5.863837e-04:  19%|█▉        | 3144/16329 [26:28<2:00:44,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3144: train loss 2.68419. lr 5.863751e-04:  19%|█▉        | 3144/16329 [26:29<2:00:44,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3144: train loss 2.68419. lr 5.863751e-04:  19%|█▉        | 3145/16329 [26:29<2:00:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3145: train loss 2.69241. lr 5.863665e-04:  19%|█▉        | 3145/16329 [26:30<2:00:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3145: train loss 2.69241. lr 5.863665e-04:  19%|█▉        | 3146/16329 [26:30<1:59:59,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3146: train loss 2.54210. lr 5.863579e-04:  19%|█▉        | 3146/16329 [26:30<1:59:59,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3146: train loss 2.54210. lr 5.863579e-04:  19%|█▉        | 3147/16329 [26:30<1:58:35,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3147: train loss 2.65565. lr 5.863493e-04:  19%|█▉        | 3147/16329 [26:31<1:58:35,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3147: train loss 2.65565. lr 5.863493e-04:  19%|█▉        | 3148/16329 [26:31<1:56:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3148: train loss 2.66109. lr 5.863407e-04:  19%|█▉        | 3148/16329 [26:31<1:56:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3148: train loss 2.66109. lr 5.863407e-04:  19%|█▉        | 3149/16329 [26:31<1:55:22,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3149: train loss 2.57936. lr 5.863321e-04:  19%|█▉        | 3149/16329 [26:32<1:55:22,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3149: train loss 2.57936. lr 5.863321e-04:  19%|█▉        | 3150/16329 [26:32<1:53:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3150: train loss 2.65528. lr 5.863234e-04:  19%|█▉        | 3150/16329 [26:32<1:53:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3150: train loss 2.65528. lr 5.863234e-04:  19%|█▉        | 3151/16329 [26:32<1:52:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3151: train loss 2.68683. lr 5.863148e-04:  19%|█▉        | 3151/16329 [26:33<1:52:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3151: train loss 2.68683. lr 5.863148e-04:  19%|█▉        | 3152/16329 [26:33<1:51:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3152: train loss 2.67696. lr 5.863062e-04:  19%|█▉        | 3152/16329 [26:33<1:51:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3152: train loss 2.67696. lr 5.863062e-04:  19%|█▉        | 3153/16329 [26:33<1:50:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3153: train loss 2.66276. lr 5.862976e-04:  19%|█▉        | 3153/16329 [26:34<1:50:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3153: train loss 2.66276. lr 5.862976e-04:  19%|█▉        | 3154/16329 [26:34<1:49:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3154: train loss 2.61698. lr 5.862890e-04:  19%|█▉        | 3154/16329 [26:34<1:49:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3154: train loss 2.61698. lr 5.862890e-04:  19%|█▉        | 3155/16329 [26:34<1:49:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3155: train loss 2.60962. lr 5.862803e-04:  19%|█▉        | 3155/16329 [26:35<1:49:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3155: train loss 2.60962. lr 5.862803e-04:  19%|█▉        | 3156/16329 [26:35<1:49:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3156: train loss 2.62831. lr 5.862717e-04:  19%|█▉        | 3156/16329 [26:35<1:49:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3156: train loss 2.62831. lr 5.862717e-04:  19%|█▉        | 3157/16329 [26:35<1:49:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3157: train loss 2.51895. lr 5.862631e-04:  19%|█▉        | 3157/16329 [26:36<1:49:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3157: train loss 2.51895. lr 5.862631e-04:  19%|█▉        | 3158/16329 [26:36<1:53:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3158: train loss 2.68981. lr 5.862544e-04:  19%|█▉        | 3158/16329 [26:36<1:53:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3158: train loss 2.68981. lr 5.862544e-04:  19%|█▉        | 3159/16329 [26:36<1:55:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3159: train loss 2.63755. lr 5.862458e-04:  19%|█▉        | 3159/16329 [26:37<1:55:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3159: train loss 2.63755. lr 5.862458e-04:  19%|█▉        | 3160/16329 [26:37<1:54:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3160: train loss 2.64188. lr 5.862372e-04:  19%|█▉        | 3160/16329 [26:37<1:54:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3160: train loss 2.64188. lr 5.862372e-04:  19%|█▉        | 3161/16329 [26:37<1:54:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3161: train loss 2.68311. lr 5.862285e-04:  19%|█▉        | 3161/16329 [26:38<1:54:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3161: train loss 2.68311. lr 5.862285e-04:  19%|█▉        | 3162/16329 [26:38<1:53:32,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3162: train loss 2.67371. lr 5.862199e-04:  19%|█▉        | 3162/16329 [26:38<1:53:32,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3162: train loss 2.67371. lr 5.862199e-04:  19%|█▉        | 3163/16329 [26:38<1:52:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3163: train loss 2.68598. lr 5.862112e-04:  19%|█▉        | 3163/16329 [26:39<1:52:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3163: train loss 2.68598. lr 5.862112e-04:  19%|█▉        | 3164/16329 [26:39<1:51:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3164: train loss 2.59205. lr 5.862026e-04:  19%|█▉        | 3164/16329 [26:39<1:51:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3164: train loss 2.59205. lr 5.862026e-04:  19%|█▉        | 3165/16329 [26:39<1:50:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3165: train loss 2.68903. lr 5.861939e-04:  19%|█▉        | 3165/16329 [26:40<1:50:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3165: train loss 2.68903. lr 5.861939e-04:  19%|█▉        | 3166/16329 [26:40<1:49:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3166: train loss 2.63622. lr 5.861853e-04:  19%|█▉        | 3166/16329 [26:40<1:49:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3166: train loss 2.63622. lr 5.861853e-04:  19%|█▉        | 3167/16329 [26:40<1:49:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3167: train loss 2.63663. lr 5.861766e-04:  19%|█▉        | 3167/16329 [26:41<1:49:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3167: train loss 2.63663. lr 5.861766e-04:  19%|█▉        | 3168/16329 [26:41<1:51:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3168: train loss 2.60903. lr 5.861680e-04:  19%|█▉        | 3168/16329 [26:41<1:51:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3168: train loss 2.60903. lr 5.861680e-04:  19%|█▉        | 3169/16329 [26:41<1:53:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3169: train loss 2.66180. lr 5.861593e-04:  19%|█▉        | 3169/16329 [26:42<1:53:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3169: train loss 2.66180. lr 5.861593e-04:  19%|█▉        | 3170/16329 [26:42<2:05:32,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 3170: train loss 2.61655. lr 5.861506e-04:  19%|█▉        | 3170/16329 [26:42<2:05:32,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 3170: train loss 2.61655. lr 5.861506e-04:  19%|█▉        | 3171/16329 [26:42<2:01:33,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 3171: train loss 2.58394. lr 5.861420e-04:  19%|█▉        | 3171/16329 [26:43<2:01:33,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 3171: train loss 2.58394. lr 5.861420e-04:  19%|█▉        | 3172/16329 [26:43<1:58:19,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3172: train loss 2.58380. lr 5.861333e-04:  19%|█▉        | 3172/16329 [26:43<1:58:19,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3172: train loss 2.58380. lr 5.861333e-04:  19%|█▉        | 3173/16329 [26:43<1:55:54,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3173: train loss 2.63832. lr 5.861246e-04:  19%|█▉        | 3173/16329 [26:44<1:55:54,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3173: train loss 2.63832. lr 5.861246e-04:  19%|█▉        | 3174/16329 [26:44<1:53:57,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3174: train loss 2.60895. lr 5.861159e-04:  19%|█▉        | 3174/16329 [26:44<1:53:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3174: train loss 2.60895. lr 5.861159e-04:  19%|█▉        | 3175/16329 [26:44<1:52:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3175: train loss 2.60728. lr 5.861073e-04:  19%|█▉        | 3175/16329 [26:45<1:52:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3175: train loss 2.60728. lr 5.861073e-04:  19%|█▉        | 3176/16329 [26:45<1:51:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3176: train loss 2.63620. lr 5.860986e-04:  19%|█▉        | 3176/16329 [26:45<1:51:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3176: train loss 2.63620. lr 5.860986e-04:  19%|█▉        | 3177/16329 [26:45<1:50:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3177: train loss 2.61643. lr 5.860899e-04:  19%|█▉        | 3177/16329 [26:46<1:50:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3177: train loss 2.61643. lr 5.860899e-04:  19%|█▉        | 3178/16329 [26:46<1:49:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3178: train loss 2.60768. lr 5.860812e-04:  19%|█▉        | 3178/16329 [26:46<1:49:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3178: train loss 2.60768. lr 5.860812e-04:  19%|█▉        | 3179/16329 [26:46<1:49:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3179: train loss 2.61734. lr 5.860725e-04:  19%|█▉        | 3179/16329 [26:47<1:49:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3179: train loss 2.61734. lr 5.860725e-04:  19%|█▉        | 3180/16329 [26:47<1:48:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3180: train loss 2.62902. lr 5.860638e-04:  19%|█▉        | 3180/16329 [26:47<1:48:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3180: train loss 2.62902. lr 5.860638e-04:  19%|█▉        | 3181/16329 [26:47<1:48:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3181: train loss 2.67785. lr 5.860551e-04:  19%|█▉        | 3181/16329 [26:48<1:48:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3181: train loss 2.67785. lr 5.860551e-04:  19%|█▉        | 3182/16329 [26:48<1:48:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3182: train loss 2.63554. lr 5.860464e-04:  19%|█▉        | 3182/16329 [26:48<1:48:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3182: train loss 2.63554. lr 5.860464e-04:  19%|█▉        | 3183/16329 [26:48<1:48:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3183: train loss 2.58775. lr 5.860377e-04:  19%|█▉        | 3183/16329 [26:49<1:48:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3183: train loss 2.58775. lr 5.860377e-04:  19%|█▉        | 3184/16329 [26:49<1:48:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3184: train loss 2.63959. lr 5.860290e-04:  19%|█▉        | 3184/16329 [26:49<1:48:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3184: train loss 2.63959. lr 5.860290e-04:  20%|█▉        | 3185/16329 [26:49<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3185: train loss 2.64843. lr 5.860203e-04:  20%|█▉        | 3185/16329 [26:50<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3185: train loss 2.64843. lr 5.860203e-04:  20%|█▉        | 3186/16329 [26:50<1:47:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3186: train loss 2.58372. lr 5.860116e-04:  20%|█▉        | 3186/16329 [26:50<1:47:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3186: train loss 2.58372. lr 5.860116e-04:  20%|█▉        | 3187/16329 [26:50<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3187: train loss 2.59046. lr 5.860029e-04:  20%|█▉        | 3187/16329 [26:51<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3187: train loss 2.59046. lr 5.860029e-04:  20%|█▉        | 3188/16329 [26:51<1:47:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3188: train loss 2.51652. lr 5.859942e-04:  20%|█▉        | 3188/16329 [26:51<1:47:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3188: train loss 2.51652. lr 5.859942e-04:  20%|█▉        | 3189/16329 [26:51<1:47:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3189: train loss 2.63776. lr 5.859855e-04:  20%|█▉        | 3189/16329 [26:52<1:47:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3189: train loss 2.63776. lr 5.859855e-04:  20%|█▉        | 3190/16329 [26:52<1:47:32,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3190: train loss 2.59943. lr 5.859767e-04:  20%|█▉        | 3190/16329 [26:52<1:47:32,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3190: train loss 2.59943. lr 5.859767e-04:  20%|█▉        | 3191/16329 [26:52<1:47:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3191: train loss 2.57748. lr 5.859680e-04:  20%|█▉        | 3191/16329 [26:53<1:47:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3191: train loss 2.57748. lr 5.859680e-04:  20%|█▉        | 3192/16329 [26:53<1:47:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3192: train loss 2.57310. lr 5.859593e-04:  20%|█▉        | 3192/16329 [26:53<1:47:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3192: train loss 2.57310. lr 5.859593e-04:  20%|█▉        | 3193/16329 [26:53<1:47:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3193: train loss 2.60650. lr 5.859506e-04:  20%|█▉        | 3193/16329 [26:54<1:47:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3193: train loss 2.60650. lr 5.859506e-04:  20%|█▉        | 3194/16329 [26:54<1:47:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3194: train loss 2.64214. lr 5.859418e-04:  20%|█▉        | 3194/16329 [26:54<1:47:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3194: train loss 2.64214. lr 5.859418e-04:  20%|█▉        | 3195/16329 [26:54<1:47:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3195: train loss 2.59665. lr 5.859331e-04:  20%|█▉        | 3195/16329 [26:55<1:47:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3195: train loss 2.59665. lr 5.859331e-04:  20%|█▉        | 3196/16329 [26:55<1:47:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3196: train loss 2.59521. lr 5.859244e-04:  20%|█▉        | 3196/16329 [26:55<1:47:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3196: train loss 2.59521. lr 5.859244e-04:  20%|█▉        | 3197/16329 [26:55<1:47:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3197: train loss 2.64834. lr 5.859156e-04:  20%|█▉        | 3197/16329 [26:56<1:47:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3197: train loss 2.64834. lr 5.859156e-04:  20%|█▉        | 3198/16329 [26:56<1:48:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3198: train loss 2.66241. lr 5.859069e-04:  20%|█▉        | 3198/16329 [26:56<1:48:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3198: train loss 2.66241. lr 5.859069e-04:  20%|█▉        | 3199/16329 [26:56<1:47:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3199: train loss 2.56494. lr 5.858981e-04:  20%|█▉        | 3199/16329 [26:57<1:47:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3199: train loss 2.56494. lr 5.858981e-04:  20%|█▉        | 3200/16329 [26:57<1:47:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3200: train loss 2.61234. lr 5.858894e-04:  20%|█▉        | 3200/16329 [26:57<1:47:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3200: train loss 2.61234. lr 5.858894e-04:  20%|█▉        | 3201/16329 [26:57<1:47:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3201: train loss 2.59729. lr 5.858807e-04:  20%|█▉        | 3201/16329 [26:58<1:47:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3201: train loss 2.59729. lr 5.858807e-04:  20%|█▉        | 3202/16329 [26:58<1:47:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3202: train loss 2.57799. lr 5.858719e-04:  20%|█▉        | 3202/16329 [26:58<1:47:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3202: train loss 2.57799. lr 5.858719e-04:  20%|█▉        | 3203/16329 [26:58<1:48:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3203: train loss 2.64899. lr 5.858632e-04:  20%|█▉        | 3203/16329 [26:59<1:48:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3203: train loss 2.64899. lr 5.858632e-04:  20%|█▉        | 3204/16329 [26:59<1:47:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3204: train loss 2.60946. lr 5.858544e-04:  20%|█▉        | 3204/16329 [26:59<1:47:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3204: train loss 2.60946. lr 5.858544e-04:  20%|█▉        | 3205/16329 [26:59<1:47:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3205: train loss 2.58379. lr 5.858456e-04:  20%|█▉        | 3205/16329 [27:00<1:47:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3205: train loss 2.58379. lr 5.858456e-04:  20%|█▉        | 3206/16329 [27:00<1:47:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3206: train loss 2.62046. lr 5.858369e-04:  20%|█▉        | 3206/16329 [27:00<1:47:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3206: train loss 2.62046. lr 5.858369e-04:  20%|█▉        | 3207/16329 [27:00<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3207: train loss 2.58021. lr 5.858281e-04:  20%|█▉        | 3207/16329 [27:01<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3207: train loss 2.58021. lr 5.858281e-04:  20%|█▉        | 3208/16329 [27:01<1:47:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3208: train loss 2.55020. lr 5.858193e-04:  20%|█▉        | 3208/16329 [27:01<1:47:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3208: train loss 2.55020. lr 5.858193e-04:  20%|█▉        | 3209/16329 [27:01<1:47:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3209: train loss 2.61654. lr 5.858106e-04:  20%|█▉        | 3209/16329 [27:02<1:47:44,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3209: train loss 2.61654. lr 5.858106e-04:  20%|█▉        | 3210/16329 [27:02<1:58:39,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3210: train loss 2.56759. lr 5.858018e-04:  20%|█▉        | 3210/16329 [27:02<1:58:39,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3210: train loss 2.56759. lr 5.858018e-04:  20%|█▉        | 3211/16329 [27:02<1:55:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3211: train loss 2.58767. lr 5.857930e-04:  20%|█▉        | 3211/16329 [27:03<1:55:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3211: train loss 2.58767. lr 5.857930e-04:  20%|█▉        | 3212/16329 [27:03<1:53:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3212: train loss 2.72680. lr 5.857842e-04:  20%|█▉        | 3212/16329 [27:03<1:53:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3212: train loss 2.72680. lr 5.857842e-04:  20%|█▉        | 3213/16329 [27:03<1:51:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3213: train loss 2.61692. lr 5.857755e-04:  20%|█▉        | 3213/16329 [27:04<1:51:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3213: train loss 2.61692. lr 5.857755e-04:  20%|█▉        | 3214/16329 [27:04<1:50:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3214: train loss 2.59922. lr 5.857667e-04:  20%|█▉        | 3214/16329 [27:04<1:50:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3214: train loss 2.59922. lr 5.857667e-04:  20%|█▉        | 3215/16329 [27:04<1:49:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3215: train loss 2.63578. lr 5.857579e-04:  20%|█▉        | 3215/16329 [27:05<1:49:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3215: train loss 2.63578. lr 5.857579e-04:  20%|█▉        | 3216/16329 [27:05<1:48:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3216: train loss 2.55773. lr 5.857491e-04:  20%|█▉        | 3216/16329 [27:05<1:48:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3216: train loss 2.55773. lr 5.857491e-04:  20%|█▉        | 3217/16329 [27:05<1:48:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3217: train loss 2.61332. lr 5.857403e-04:  20%|█▉        | 3217/16329 [27:06<1:48:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3217: train loss 2.61332. lr 5.857403e-04:  20%|█▉        | 3218/16329 [27:06<1:48:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3218: train loss 2.57641. lr 5.857315e-04:  20%|█▉        | 3218/16329 [27:06<1:48:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3218: train loss 2.57641. lr 5.857315e-04:  20%|█▉        | 3219/16329 [27:06<1:48:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3219: train loss 2.65721. lr 5.857227e-04:  20%|█▉        | 3219/16329 [27:07<1:48:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3219: train loss 2.65721. lr 5.857227e-04:  20%|█▉        | 3220/16329 [27:07<1:48:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3220: train loss 2.66032. lr 5.857139e-04:  20%|█▉        | 3220/16329 [27:07<1:48:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3220: train loss 2.66032. lr 5.857139e-04:  20%|█▉        | 3221/16329 [27:07<1:52:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3221: train loss 2.62412. lr 5.857051e-04:  20%|█▉        | 3221/16329 [27:08<1:52:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3221: train loss 2.62412. lr 5.857051e-04:  20%|█▉        | 3222/16329 [27:08<1:55:27,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3222: train loss 2.64727. lr 5.856963e-04:  20%|█▉        | 3222/16329 [27:08<1:55:27,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3222: train loss 2.64727. lr 5.856963e-04:  20%|█▉        | 3223/16329 [27:08<1:55:50,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3223: train loss 2.62311. lr 5.856875e-04:  20%|█▉        | 3223/16329 [27:09<1:55:50,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3223: train loss 2.62311. lr 5.856875e-04:  20%|█▉        | 3224/16329 [27:09<1:55:11,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3224: train loss 2.62401. lr 5.856787e-04:  20%|█▉        | 3224/16329 [27:10<1:55:11,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3224: train loss 2.62401. lr 5.856787e-04:  20%|█▉        | 3225/16329 [27:10<1:54:11,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3225: train loss 2.51937. lr 5.856699e-04:  20%|█▉        | 3225/16329 [27:10<1:54:11,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3225: train loss 2.51937. lr 5.856699e-04:  20%|█▉        | 3226/16329 [27:10<1:53:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3226: train loss 2.61306. lr 5.856611e-04:  20%|█▉        | 3226/16329 [27:11<1:53:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3226: train loss 2.61306. lr 5.856611e-04:  20%|█▉        | 3227/16329 [27:11<1:51:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3227: train loss 2.60572. lr 5.856523e-04:  20%|█▉        | 3227/16329 [27:11<1:51:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3227: train loss 2.60572. lr 5.856523e-04:  20%|█▉        | 3228/16329 [27:11<1:51:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3228: train loss 2.59934. lr 5.856435e-04:  20%|█▉        | 3228/16329 [27:12<1:51:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3228: train loss 2.59934. lr 5.856435e-04:  20%|█▉        | 3229/16329 [27:12<1:50:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3229: train loss 2.62964. lr 5.856346e-04:  20%|█▉        | 3229/16329 [27:12<1:50:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3229: train loss 2.62964. lr 5.856346e-04:  20%|█▉        | 3230/16329 [27:12<1:49:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3230: train loss 2.56967. lr 5.856258e-04:  20%|█▉        | 3230/16329 [27:12<1:49:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3230: train loss 2.56967. lr 5.856258e-04:  20%|█▉        | 3231/16329 [27:12<1:48:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3231: train loss 2.67792. lr 5.856170e-04:  20%|█▉        | 3231/16329 [27:13<1:48:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3231: train loss 2.67792. lr 5.856170e-04:  20%|█▉        | 3232/16329 [27:13<1:48:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3232: train loss 2.66249. lr 5.856081e-04:  20%|█▉        | 3232/16329 [27:13<1:48:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3232: train loss 2.66249. lr 5.856081e-04:  20%|█▉        | 3233/16329 [27:13<1:48:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3233: train loss 2.63853. lr 5.855993e-04:  20%|█▉        | 3233/16329 [27:14<1:48:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3233: train loss 2.63853. lr 5.855993e-04:  20%|█▉        | 3234/16329 [27:14<1:47:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3234: train loss 2.62247. lr 5.855905e-04:  20%|█▉        | 3234/16329 [27:14<1:47:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3234: train loss 2.62247. lr 5.855905e-04:  20%|█▉        | 3235/16329 [27:14<1:47:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3235: train loss 2.56208. lr 5.855816e-04:  20%|█▉        | 3235/16329 [27:15<1:47:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3235: train loss 2.56208. lr 5.855816e-04:  20%|█▉        | 3236/16329 [27:15<1:47:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3236: train loss 2.62071. lr 5.855728e-04:  20%|█▉        | 3236/16329 [27:15<1:47:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3236: train loss 2.62071. lr 5.855728e-04:  20%|█▉        | 3237/16329 [27:15<1:48:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3237: train loss 2.60954. lr 5.855640e-04:  20%|█▉        | 3237/16329 [27:16<1:48:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3237: train loss 2.60954. lr 5.855640e-04:  20%|█▉        | 3238/16329 [27:16<1:47:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3238: train loss 2.53395. lr 5.855551e-04:  20%|█▉        | 3238/16329 [27:16<1:47:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3238: train loss 2.53395. lr 5.855551e-04:  20%|█▉        | 3239/16329 [27:16<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3239: train loss 2.52805. lr 5.855463e-04:  20%|█▉        | 3239/16329 [27:17<1:47:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3239: train loss 2.52805. lr 5.855463e-04:  20%|█▉        | 3240/16329 [27:17<1:47:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3240: train loss 2.63138. lr 5.855374e-04:  20%|█▉        | 3240/16329 [27:17<1:47:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3240: train loss 2.63138. lr 5.855374e-04:  20%|█▉        | 3241/16329 [27:17<1:47:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3241: train loss 2.62999. lr 5.855286e-04:  20%|█▉        | 3241/16329 [27:18<1:47:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3241: train loss 2.62999. lr 5.855286e-04:  20%|█▉        | 3242/16329 [27:18<1:47:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3242: train loss 2.65688. lr 5.855197e-04:  20%|█▉        | 3242/16329 [27:18<1:47:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3242: train loss 2.65688. lr 5.855197e-04:  20%|█▉        | 3243/16329 [27:18<1:47:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3243: train loss 2.65463. lr 5.855108e-04:  20%|█▉        | 3243/16329 [27:19<1:47:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3243: train loss 2.65463. lr 5.855108e-04:  20%|█▉        | 3244/16329 [27:19<1:47:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3244: train loss 2.64758. lr 5.855020e-04:  20%|█▉        | 3244/16329 [27:20<1:47:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3244: train loss 2.64758. lr 5.855020e-04:  20%|█▉        | 3245/16329 [27:20<1:59:04,  1.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3245: train loss 2.61275. lr 5.854931e-04:  20%|█▉        | 3245/16329 [27:20<1:59:04,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3245: train loss 2.61275. lr 5.854931e-04:  20%|█▉        | 3246/16329 [27:20<1:55:30,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3246: train loss 2.59102. lr 5.854842e-04:  20%|█▉        | 3246/16329 [27:21<1:55:30,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3246: train loss 2.59102. lr 5.854842e-04:  20%|█▉        | 3247/16329 [27:21<1:53:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3247: train loss 2.63575. lr 5.854754e-04:  20%|█▉        | 3247/16329 [27:21<1:53:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3247: train loss 2.63575. lr 5.854754e-04:  20%|█▉        | 3248/16329 [27:21<1:51:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3248: train loss 2.59334. lr 5.854665e-04:  20%|█▉        | 3248/16329 [27:22<1:51:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3248: train loss 2.59334. lr 5.854665e-04:  20%|█▉        | 3249/16329 [27:22<1:49:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3249: train loss 2.57380. lr 5.854576e-04:  20%|█▉        | 3249/16329 [27:22<1:49:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3249: train loss 2.57380. lr 5.854576e-04:  20%|█▉        | 3250/16329 [27:22<1:51:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3250: train loss 2.58975. lr 5.854487e-04:  20%|█▉        | 3250/16329 [27:23<1:51:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3250: train loss 2.58975. lr 5.854487e-04:  20%|█▉        | 3251/16329 [27:23<1:52:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3251: train loss 2.63580. lr 5.854399e-04:  20%|█▉        | 3251/16329 [27:23<1:52:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3251: train loss 2.63580. lr 5.854399e-04:  20%|█▉        | 3252/16329 [27:23<1:52:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3252: train loss 2.62014. lr 5.854310e-04:  20%|█▉        | 3252/16329 [27:24<1:52:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3252: train loss 2.62014. lr 5.854310e-04:  20%|█▉        | 3253/16329 [27:24<1:51:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3253: train loss 2.58137. lr 5.854221e-04:  20%|█▉        | 3253/16329 [27:24<1:51:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3253: train loss 2.58137. lr 5.854221e-04:  20%|█▉        | 3254/16329 [27:24<1:50:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3254: train loss 2.57427. lr 5.854132e-04:  20%|█▉        | 3254/16329 [27:25<1:50:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3254: train loss 2.57427. lr 5.854132e-04:  20%|█▉        | 3255/16329 [27:25<1:49:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3255: train loss 2.58642. lr 5.854043e-04:  20%|█▉        | 3255/16329 [27:25<1:49:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3255: train loss 2.58642. lr 5.854043e-04:  20%|█▉        | 3256/16329 [27:25<1:49:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3256: train loss 2.50614. lr 5.853954e-04:  20%|█▉        | 3256/16329 [27:26<1:49:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3256: train loss 2.50614. lr 5.853954e-04:  20%|█▉        | 3257/16329 [27:26<1:48:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3257: train loss 2.61642. lr 5.853865e-04:  20%|█▉        | 3257/16329 [27:26<1:48:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3257: train loss 2.61642. lr 5.853865e-04:  20%|█▉        | 3258/16329 [27:26<1:48:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3258: train loss 2.57718. lr 5.853776e-04:  20%|█▉        | 3258/16329 [27:27<1:48:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3258: train loss 2.57718. lr 5.853776e-04:  20%|█▉        | 3259/16329 [27:27<1:48:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3259: train loss 2.63500. lr 5.853687e-04:  20%|█▉        | 3259/16329 [27:27<1:48:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3259: train loss 2.63500. lr 5.853687e-04:  20%|█▉        | 3260/16329 [27:27<1:48:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3260: train loss 2.54438. lr 5.853598e-04:  20%|█▉        | 3260/16329 [27:28<1:48:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3260: train loss 2.54438. lr 5.853598e-04:  20%|█▉        | 3261/16329 [27:28<1:48:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3261: train loss 2.60937. lr 5.853509e-04:  20%|█▉        | 3261/16329 [27:28<1:48:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3261: train loss 2.60937. lr 5.853509e-04:  20%|█▉        | 3262/16329 [27:28<1:48:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3262: train loss 2.49105. lr 5.853420e-04:  20%|█▉        | 3262/16329 [27:29<1:48:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3262: train loss 2.49105. lr 5.853420e-04:  20%|█▉        | 3263/16329 [27:29<1:48:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3263: train loss 2.55389. lr 5.853331e-04:  20%|█▉        | 3263/16329 [27:29<1:48:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3263: train loss 2.55389. lr 5.853331e-04:  20%|█▉        | 3264/16329 [27:29<1:47:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3264: train loss 2.58621. lr 5.853242e-04:  20%|█▉        | 3264/16329 [27:30<1:47:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3264: train loss 2.58621. lr 5.853242e-04:  20%|█▉        | 3265/16329 [27:30<1:47:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3265: train loss 2.55507. lr 5.853153e-04:  20%|█▉        | 3265/16329 [27:30<1:47:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3265: train loss 2.55507. lr 5.853153e-04:  20%|██        | 3266/16329 [27:30<1:47:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3266: train loss 2.56070. lr 5.853063e-04:  20%|██        | 3266/16329 [27:31<1:47:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3266: train loss 2.56070. lr 5.853063e-04:  20%|██        | 3267/16329 [27:31<1:47:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3267: train loss 2.51057. lr 5.852974e-04:  20%|██        | 3267/16329 [27:31<1:47:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3267: train loss 2.51057. lr 5.852974e-04:  20%|██        | 3268/16329 [27:31<1:47:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3268: train loss 2.58590. lr 5.852885e-04:  20%|██        | 3268/16329 [27:32<1:47:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3268: train loss 2.58590. lr 5.852885e-04:  20%|██        | 3269/16329 [27:32<1:47:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3269: train loss 2.54943. lr 5.852796e-04:  20%|██        | 3269/16329 [27:32<1:47:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3269: train loss 2.54943. lr 5.852796e-04:  20%|██        | 3270/16329 [27:32<1:59:12,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3270: train loss 2.54693. lr 5.852706e-04:  20%|██        | 3270/16329 [27:33<1:59:12,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3270: train loss 2.54693. lr 5.852706e-04:  20%|██        | 3271/16329 [27:33<1:55:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3271: train loss 2.65596. lr 5.852617e-04:  20%|██        | 3271/16329 [27:33<1:55:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3271: train loss 2.65596. lr 5.852617e-04:  20%|██        | 3272/16329 [27:33<1:52:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3272: train loss 2.55918. lr 5.852528e-04:  20%|██        | 3272/16329 [27:34<1:52:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3272: train loss 2.55918. lr 5.852528e-04:  20%|██        | 3273/16329 [27:34<1:51:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3273: train loss 2.64850. lr 5.852438e-04:  20%|██        | 3273/16329 [27:34<1:51:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3273: train loss 2.64850. lr 5.852438e-04:  20%|██        | 3274/16329 [27:34<1:49:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3274: train loss 2.64440. lr 5.852349e-04:  20%|██        | 3274/16329 [27:35<1:49:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3274: train loss 2.64440. lr 5.852349e-04:  20%|██        | 3275/16329 [27:35<1:49:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3275: train loss 2.57123. lr 5.852259e-04:  20%|██        | 3275/16329 [27:35<1:49:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3275: train loss 2.57123. lr 5.852259e-04:  20%|██        | 3276/16329 [27:35<1:48:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3276: train loss 2.57882. lr 5.852170e-04:  20%|██        | 3276/16329 [27:36<1:48:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3276: train loss 2.57882. lr 5.852170e-04:  20%|██        | 3277/16329 [27:36<1:48:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3277: train loss 2.58708. lr 5.852080e-04:  20%|██        | 3277/16329 [27:36<1:48:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3277: train loss 2.58708. lr 5.852080e-04:  20%|██        | 3278/16329 [27:36<1:47:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3278: train loss 2.52025. lr 5.851991e-04:  20%|██        | 3278/16329 [27:37<1:47:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3278: train loss 2.52025. lr 5.851991e-04:  20%|██        | 3279/16329 [27:37<1:47:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3279: train loss 2.60148. lr 5.851901e-04:  20%|██        | 3279/16329 [27:37<1:47:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3279: train loss 2.60148. lr 5.851901e-04:  20%|██        | 3280/16329 [27:37<1:47:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3280: train loss 2.58527. lr 5.851812e-04:  20%|██        | 3280/16329 [27:38<1:47:20,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3280: train loss 2.58527. lr 5.851812e-04:  20%|██        | 3281/16329 [27:38<1:47:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3281: train loss 2.59662. lr 5.851722e-04:  20%|██        | 3281/16329 [27:38<1:47:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3281: train loss 2.59662. lr 5.851722e-04:  20%|██        | 3282/16329 [27:38<1:46:45,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3282: train loss 2.61229. lr 5.851633e-04:  20%|██        | 3282/16329 [27:39<1:46:45,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3282: train loss 2.61229. lr 5.851633e-04:  20%|██        | 3283/16329 [27:39<1:47:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3283: train loss 2.57126. lr 5.851543e-04:  20%|██        | 3283/16329 [27:39<1:47:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3283: train loss 2.57126. lr 5.851543e-04:  20%|██        | 3284/16329 [27:39<1:47:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3284: train loss 2.53664. lr 5.851453e-04:  20%|██        | 3284/16329 [27:40<1:47:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3284: train loss 2.53664. lr 5.851453e-04:  20%|██        | 3285/16329 [27:40<1:47:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3285: train loss 2.59026. lr 5.851364e-04:  20%|██        | 3285/16329 [27:40<1:47:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3285: train loss 2.59026. lr 5.851364e-04:  20%|██        | 3286/16329 [27:40<1:47:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3286: train loss 2.58655. lr 5.851274e-04:  20%|██        | 3286/16329 [27:41<1:47:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3286: train loss 2.58655. lr 5.851274e-04:  20%|██        | 3287/16329 [27:41<1:47:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3287: train loss 2.54029. lr 5.851184e-04:  20%|██        | 3287/16329 [27:41<1:47:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3287: train loss 2.54029. lr 5.851184e-04:  20%|██        | 3288/16329 [27:41<1:47:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3288: train loss 2.53990. lr 5.851094e-04:  20%|██        | 3288/16329 [27:42<1:47:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3288: train loss 2.53990. lr 5.851094e-04:  20%|██        | 3289/16329 [27:42<1:47:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3289: train loss 2.62618. lr 5.851004e-04:  20%|██        | 3289/16329 [27:42<1:47:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3289: train loss 2.62618. lr 5.851004e-04:  20%|██        | 3290/16329 [27:42<1:47:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3290: train loss 2.59721. lr 5.850915e-04:  20%|██        | 3290/16329 [27:43<1:47:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3290: train loss 2.59721. lr 5.850915e-04:  20%|██        | 3291/16329 [27:43<1:47:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3291: train loss 2.50290. lr 5.850825e-04:  20%|██        | 3291/16329 [27:43<1:47:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3291: train loss 2.50290. lr 5.850825e-04:  20%|██        | 3292/16329 [27:43<1:46:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3292: train loss 2.57981. lr 5.850735e-04:  20%|██        | 3292/16329 [27:44<1:46:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3292: train loss 2.57981. lr 5.850735e-04:  20%|██        | 3293/16329 [27:44<1:47:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3293: train loss 2.57163. lr 5.850645e-04:  20%|██        | 3293/16329 [27:44<1:47:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3293: train loss 2.57163. lr 5.850645e-04:  20%|██        | 3294/16329 [27:44<1:47:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3294: train loss 2.56694. lr 5.850555e-04:  20%|██        | 3294/16329 [27:45<1:47:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3294: train loss 2.56694. lr 5.850555e-04:  20%|██        | 3295/16329 [27:45<1:47:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3295: train loss 2.56440. lr 5.850465e-04:  20%|██        | 3295/16329 [27:45<1:47:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3295: train loss 2.56440. lr 5.850465e-04:  20%|██        | 3296/16329 [27:45<1:47:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3296: train loss 2.54281. lr 5.850375e-04:  20%|██        | 3296/16329 [27:46<1:47:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3296: train loss 2.54281. lr 5.850375e-04:  20%|██        | 3297/16329 [27:46<1:58:12,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3297: train loss 2.57438. lr 5.850285e-04:  20%|██        | 3297/16329 [27:46<1:58:12,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3297: train loss 2.57438. lr 5.850285e-04:  20%|██        | 3298/16329 [27:46<1:55:04,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3298: train loss 2.56920. lr 5.850195e-04:  20%|██        | 3298/16329 [27:47<1:55:04,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3298: train loss 2.56920. lr 5.850195e-04:  20%|██        | 3299/16329 [27:47<1:52:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3299: train loss 2.54342. lr 5.850105e-04:  20%|██        | 3299/16329 [27:47<1:52:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3299: train loss 2.54342. lr 5.850105e-04:  20%|██        | 3300/16329 [27:47<1:50:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3300: train loss 2.60338. lr 5.850015e-04:  20%|██        | 3300/16329 [27:48<1:50:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3300: train loss 2.60338. lr 5.850015e-04:  20%|██        | 3301/16329 [27:48<1:49:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3301: train loss 2.56912. lr 5.849925e-04:  20%|██        | 3301/16329 [27:48<1:49:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3301: train loss 2.56912. lr 5.849925e-04:  20%|██        | 3302/16329 [27:48<1:48:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3302: train loss 2.57710. lr 5.849835e-04:  20%|██        | 3302/16329 [27:49<1:48:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3302: train loss 2.57710. lr 5.849835e-04:  20%|██        | 3303/16329 [27:49<1:48:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3303: train loss 2.66476. lr 5.849744e-04:  20%|██        | 3303/16329 [27:49<1:48:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3303: train loss 2.66476. lr 5.849744e-04:  20%|██        | 3304/16329 [27:49<1:48:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3304: train loss 2.58861. lr 5.849654e-04:  20%|██        | 3304/16329 [27:50<1:48:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3304: train loss 2.58861. lr 5.849654e-04:  20%|██        | 3305/16329 [27:50<1:47:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3305: train loss 2.56260. lr 5.849564e-04:  20%|██        | 3305/16329 [27:50<1:47:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3305: train loss 2.56260. lr 5.849564e-04:  20%|██        | 3306/16329 [27:50<1:47:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3306: train loss 2.56463. lr 5.849474e-04:  20%|██        | 3306/16329 [27:51<1:47:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3306: train loss 2.56463. lr 5.849474e-04:  20%|██        | 3307/16329 [27:51<1:47:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3307: train loss 2.53649. lr 5.849383e-04:  20%|██        | 3307/16329 [27:51<1:47:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3307: train loss 2.53649. lr 5.849383e-04:  20%|██        | 3308/16329 [27:51<1:47:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3308: train loss 2.58998. lr 5.849293e-04:  20%|██        | 3308/16329 [27:52<1:47:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3308: train loss 2.58998. lr 5.849293e-04:  20%|██        | 3309/16329 [27:52<1:47:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3309: train loss 2.60709. lr 5.849203e-04:  20%|██        | 3309/16329 [27:52<1:47:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3309: train loss 2.60709. lr 5.849203e-04:  20%|██        | 3310/16329 [27:52<1:47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3310: train loss 2.57230. lr 5.849112e-04:  20%|██        | 3310/16329 [27:53<1:47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3310: train loss 2.57230. lr 5.849112e-04:  20%|██        | 3311/16329 [27:53<1:47:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3311: train loss 2.58240. lr 5.849022e-04:  20%|██        | 3311/16329 [27:53<1:47:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3311: train loss 2.58240. lr 5.849022e-04:  20%|██        | 3312/16329 [27:53<1:46:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3312: train loss 2.51043. lr 5.848932e-04:  20%|██        | 3312/16329 [27:54<1:46:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3312: train loss 2.51043. lr 5.848932e-04:  20%|██        | 3313/16329 [27:54<1:51:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3313: train loss 2.60127. lr 5.848841e-04:  20%|██        | 3313/16329 [27:54<1:51:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3313: train loss 2.60127. lr 5.848841e-04:  20%|██        | 3314/16329 [27:54<1:53:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3314: train loss 2.52674. lr 5.848751e-04:  20%|██        | 3314/16329 [27:55<1:53:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3314: train loss 2.52674. lr 5.848751e-04:  20%|██        | 3315/16329 [27:55<1:53:33,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3315: train loss 2.63804. lr 5.848660e-04:  20%|██        | 3315/16329 [27:55<1:53:33,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3315: train loss 2.63804. lr 5.848660e-04:  20%|██        | 3316/16329 [27:55<1:53:05,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3316: train loss 2.58033. lr 5.848570e-04:  20%|██        | 3316/16329 [27:56<1:53:05,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3316: train loss 2.58033. lr 5.848570e-04:  20%|██        | 3317/16329 [27:56<1:52:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3317: train loss 2.57634. lr 5.848479e-04:  20%|██        | 3317/16329 [27:56<1:52:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3317: train loss 2.57634. lr 5.848479e-04:  20%|██        | 3318/16329 [27:56<1:51:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3318: train loss 2.57515. lr 5.848389e-04:  20%|██        | 3318/16329 [27:57<1:51:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3318: train loss 2.57515. lr 5.848389e-04:  20%|██        | 3319/16329 [27:57<1:50:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3319: train loss 2.56075. lr 5.848298e-04:  20%|██        | 3319/16329 [27:57<1:50:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3319: train loss 2.56075. lr 5.848298e-04:  20%|██        | 3320/16329 [27:57<1:49:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3320: train loss 2.64768. lr 5.848207e-04:  20%|██        | 3320/16329 [27:58<1:49:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3320: train loss 2.64768. lr 5.848207e-04:  20%|██        | 3321/16329 [27:58<1:49:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3321: train loss 2.55485. lr 5.848117e-04:  20%|██        | 3321/16329 [27:58<1:49:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3321: train loss 2.55485. lr 5.848117e-04:  20%|██        | 3322/16329 [27:58<1:49:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3322: train loss 2.48358. lr 5.848026e-04:  20%|██        | 3322/16329 [27:59<1:49:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3322: train loss 2.48358. lr 5.848026e-04:  20%|██        | 3323/16329 [27:59<1:48:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3323: train loss 2.56847. lr 5.847935e-04:  20%|██        | 3323/16329 [27:59<1:48:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3323: train loss 2.56847. lr 5.847935e-04:  20%|██        | 3324/16329 [27:59<1:48:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3324: train loss 2.51675. lr 5.847845e-04:  20%|██        | 3324/16329 [28:00<1:48:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3324: train loss 2.51675. lr 5.847845e-04:  20%|██        | 3325/16329 [28:00<1:47:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3325: train loss 2.57917. lr 5.847754e-04:  20%|██        | 3325/16329 [28:00<1:47:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3325: train loss 2.57917. lr 5.847754e-04:  20%|██        | 3326/16329 [28:00<1:47:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3326: train loss 2.59572. lr 5.847663e-04:  20%|██        | 3326/16329 [28:01<1:47:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3326: train loss 2.59572. lr 5.847663e-04:  20%|██        | 3327/16329 [28:01<1:47:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3327: train loss 2.58979. lr 5.847572e-04:  20%|██        | 3327/16329 [28:01<1:47:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3327: train loss 2.58979. lr 5.847572e-04:  20%|██        | 3328/16329 [28:01<1:47:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3328: train loss 2.60902. lr 5.847481e-04:  20%|██        | 3328/16329 [28:02<1:47:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3328: train loss 2.60902. lr 5.847481e-04:  20%|██        | 3329/16329 [28:02<1:46:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3329: train loss 2.53200. lr 5.847391e-04:  20%|██        | 3329/16329 [28:02<1:46:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3329: train loss 2.53200. lr 5.847391e-04:  20%|██        | 3330/16329 [28:02<1:47:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3330: train loss 2.56089. lr 5.847300e-04:  20%|██        | 3330/16329 [28:03<1:47:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3330: train loss 2.56089. lr 5.847300e-04:  20%|██        | 3331/16329 [28:03<1:46:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3331: train loss 2.55724. lr 5.847209e-04:  20%|██        | 3331/16329 [28:03<1:46:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3331: train loss 2.55724. lr 5.847209e-04:  20%|██        | 3332/16329 [28:03<1:46:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3332: train loss 2.58793. lr 5.847118e-04:  20%|██        | 3332/16329 [28:04<1:46:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3332: train loss 2.58793. lr 5.847118e-04:  20%|██        | 3333/16329 [28:04<1:47:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3333: train loss 2.55104. lr 5.847027e-04:  20%|██        | 3333/16329 [28:04<1:47:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3333: train loss 2.55104. lr 5.847027e-04:  20%|██        | 3334/16329 [28:04<1:47:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3334: train loss 2.58547. lr 5.846936e-04:  20%|██        | 3334/16329 [28:05<1:47:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3334: train loss 2.58547. lr 5.846936e-04:  20%|██        | 3335/16329 [28:05<1:46:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3335: train loss 2.62033. lr 5.846845e-04:  20%|██        | 3335/16329 [28:05<1:46:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3335: train loss 2.62033. lr 5.846845e-04:  20%|██        | 3336/16329 [28:05<1:46:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3336: train loss 2.58581. lr 5.846754e-04:  20%|██        | 3336/16329 [28:06<1:46:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3336: train loss 2.58581. lr 5.846754e-04:  20%|██        | 3337/16329 [28:06<1:58:06,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3337: train loss 2.53884. lr 5.846663e-04:  20%|██        | 3337/16329 [28:06<1:58:06,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3337: train loss 2.53884. lr 5.846663e-04:  20%|██        | 3338/16329 [28:06<1:54:43,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3338: train loss 2.57205. lr 5.846572e-04:  20%|██        | 3338/16329 [28:07<1:54:43,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3338: train loss 2.57205. lr 5.846572e-04:  20%|██        | 3339/16329 [28:07<1:52:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3339: train loss 2.57427. lr 5.846480e-04:  20%|██        | 3339/16329 [28:07<1:52:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3339: train loss 2.57427. lr 5.846480e-04:  20%|██        | 3340/16329 [28:07<1:53:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3340: train loss 2.52208. lr 5.846389e-04:  20%|██        | 3340/16329 [28:08<1:53:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3340: train loss 2.52208. lr 5.846389e-04:  20%|██        | 3341/16329 [28:08<1:54:34,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3341: train loss 2.55925. lr 5.846298e-04:  20%|██        | 3341/16329 [28:08<1:54:34,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3341: train loss 2.55925. lr 5.846298e-04:  20%|██        | 3342/16329 [28:08<1:54:33,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3342: train loss 2.58122. lr 5.846207e-04:  20%|██        | 3342/16329 [28:09<1:54:33,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3342: train loss 2.58122. lr 5.846207e-04:  20%|██        | 3343/16329 [28:09<1:53:52,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3343: train loss 2.63584. lr 5.846116e-04:  20%|██        | 3343/16329 [28:09<1:53:52,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3343: train loss 2.63584. lr 5.846116e-04:  20%|██        | 3344/16329 [28:09<1:53:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3344: train loss 2.57092. lr 5.846024e-04:  20%|██        | 3344/16329 [28:10<1:53:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3344: train loss 2.57092. lr 5.846024e-04:  20%|██        | 3345/16329 [28:10<1:52:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3345: train loss 2.55410. lr 5.845933e-04:  20%|██        | 3345/16329 [28:10<1:52:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3345: train loss 2.55410. lr 5.845933e-04:  20%|██        | 3346/16329 [28:10<1:51:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3346: train loss 2.53600. lr 5.845842e-04:  20%|██        | 3346/16329 [28:11<1:51:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3346: train loss 2.53600. lr 5.845842e-04:  20%|██        | 3347/16329 [28:11<1:50:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3347: train loss 2.57100. lr 5.845750e-04:  20%|██        | 3347/16329 [28:11<1:50:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3347: train loss 2.57100. lr 5.845750e-04:  21%|██        | 3348/16329 [28:11<1:50:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3348: train loss 2.55421. lr 5.845659e-04:  21%|██        | 3348/16329 [28:12<1:50:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3348: train loss 2.55421. lr 5.845659e-04:  21%|██        | 3349/16329 [28:12<1:49:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3349: train loss 2.55313. lr 5.845568e-04:  21%|██        | 3349/16329 [28:12<1:49:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3349: train loss 2.55313. lr 5.845568e-04:  21%|██        | 3350/16329 [28:12<1:48:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3350: train loss 2.60262. lr 5.845476e-04:  21%|██        | 3350/16329 [28:13<1:48:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3350: train loss 2.60262. lr 5.845476e-04:  21%|██        | 3351/16329 [28:13<1:48:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3351: train loss 2.55454. lr 5.845385e-04:  21%|██        | 3351/16329 [28:13<1:48:03,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3351: train loss 2.55454. lr 5.845385e-04:  21%|██        | 3352/16329 [28:13<1:47:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3352: train loss 2.60309. lr 5.845293e-04:  21%|██        | 3352/16329 [28:14<1:47:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3352: train loss 2.60309. lr 5.845293e-04:  21%|██        | 3353/16329 [28:14<1:47:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3353: train loss 2.51076. lr 5.845202e-04:  21%|██        | 3353/16329 [28:14<1:47:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3353: train loss 2.51076. lr 5.845202e-04:  21%|██        | 3354/16329 [28:14<1:47:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3354: train loss 2.48850. lr 5.845110e-04:  21%|██        | 3354/16329 [28:15<1:47:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3354: train loss 2.48850. lr 5.845110e-04:  21%|██        | 3355/16329 [28:15<1:46:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3355: train loss 2.59908. lr 5.845019e-04:  21%|██        | 3355/16329 [28:15<1:46:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3355: train loss 2.59908. lr 5.845019e-04:  21%|██        | 3356/16329 [28:15<1:46:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3356: train loss 2.59053. lr 5.844927e-04:  21%|██        | 3356/16329 [28:16<1:46:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3356: train loss 2.59053. lr 5.844927e-04:  21%|██        | 3357/16329 [28:16<1:46:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3357: train loss 2.54508. lr 5.844836e-04:  21%|██        | 3357/16329 [28:16<1:46:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3357: train loss 2.54508. lr 5.844836e-04:  21%|██        | 3358/16329 [28:16<1:46:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3358: train loss 2.54533. lr 5.844744e-04:  21%|██        | 3358/16329 [28:17<1:46:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3358: train loss 2.54533. lr 5.844744e-04:  21%|██        | 3359/16329 [28:17<1:46:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3359: train loss 2.49454. lr 5.844652e-04:  21%|██        | 3359/16329 [28:17<1:46:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3359: train loss 2.49454. lr 5.844652e-04:  21%|██        | 3360/16329 [28:17<1:46:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3360: train loss 2.56668. lr 5.844561e-04:  21%|██        | 3360/16329 [28:18<1:46:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3360: train loss 2.56668. lr 5.844561e-04:  21%|██        | 3361/16329 [28:18<1:46:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3361: train loss 2.55250. lr 5.844469e-04:  21%|██        | 3361/16329 [28:18<1:46:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3361: train loss 2.55250. lr 5.844469e-04:  21%|██        | 3362/16329 [28:18<1:46:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3362: train loss 2.52996. lr 5.844377e-04:  21%|██        | 3362/16329 [28:19<1:46:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3362: train loss 2.52996. lr 5.844377e-04:  21%|██        | 3363/16329 [28:19<1:46:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3363: train loss 2.54600. lr 5.844286e-04:  21%|██        | 3363/16329 [28:19<1:46:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3363: train loss 2.54600. lr 5.844286e-04:  21%|██        | 3364/16329 [28:19<1:46:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3364: train loss 2.56381. lr 5.844194e-04:  21%|██        | 3364/16329 [28:20<1:46:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3364: train loss 2.56381. lr 5.844194e-04:  21%|██        | 3365/16329 [28:20<1:46:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3365: train loss 2.52093. lr 5.844102e-04:  21%|██        | 3365/16329 [28:20<1:46:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3365: train loss 2.52093. lr 5.844102e-04:  21%|██        | 3366/16329 [28:20<1:46:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3366: train loss 2.53406. lr 5.844010e-04:  21%|██        | 3366/16329 [28:21<1:46:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3366: train loss 2.53406. lr 5.844010e-04:  21%|██        | 3367/16329 [28:21<1:46:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3367: train loss 2.61714. lr 5.843918e-04:  21%|██        | 3367/16329 [28:21<1:46:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3367: train loss 2.61714. lr 5.843918e-04:  21%|██        | 3368/16329 [28:21<1:46:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3368: train loss 2.50536. lr 5.843826e-04:  21%|██        | 3368/16329 [28:22<1:46:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3368: train loss 2.50536. lr 5.843826e-04:  21%|██        | 3369/16329 [28:22<1:46:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3369: train loss 2.51373. lr 5.843734e-04:  21%|██        | 3369/16329 [28:22<1:46:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3369: train loss 2.51373. lr 5.843734e-04:  21%|██        | 3370/16329 [28:22<1:46:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3370: train loss 2.53286. lr 5.843642e-04:  21%|██        | 3370/16329 [28:23<1:46:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3370: train loss 2.53286. lr 5.843642e-04:  21%|██        | 3371/16329 [28:23<1:46:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3371: train loss 2.54185. lr 5.843550e-04:  21%|██        | 3371/16329 [28:24<1:46:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3371: train loss 2.54185. lr 5.843550e-04:  21%|██        | 3372/16329 [28:24<1:57:57,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3372: train loss 2.53137. lr 5.843458e-04:  21%|██        | 3372/16329 [28:24<1:57:57,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3372: train loss 2.53137. lr 5.843458e-04:  21%|██        | 3373/16329 [28:24<1:54:07,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3373: train loss 2.51899. lr 5.843366e-04:  21%|██        | 3373/16329 [28:24<1:54:07,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3373: train loss 2.51899. lr 5.843366e-04:  21%|██        | 3374/16329 [28:24<1:52:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3374: train loss 2.52270. lr 5.843274e-04:  21%|██        | 3374/16329 [28:25<1:52:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3374: train loss 2.52270. lr 5.843274e-04:  21%|██        | 3375/16329 [28:25<1:50:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3375: train loss 2.57526. lr 5.843182e-04:  21%|██        | 3375/16329 [28:25<1:50:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3375: train loss 2.57526. lr 5.843182e-04:  21%|██        | 3376/16329 [28:25<1:49:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3376: train loss 2.47056. lr 5.843090e-04:  21%|██        | 3376/16329 [28:26<1:49:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3376: train loss 2.47056. lr 5.843090e-04:  21%|██        | 3377/16329 [28:26<1:48:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3377: train loss 2.54993. lr 5.842998e-04:  21%|██        | 3377/16329 [28:26<1:48:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3377: train loss 2.54993. lr 5.842998e-04:  21%|██        | 3378/16329 [28:26<1:47:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3378: train loss 2.51697. lr 5.842906e-04:  21%|██        | 3378/16329 [28:27<1:47:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3378: train loss 2.51697. lr 5.842906e-04:  21%|██        | 3379/16329 [28:27<1:49:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3379: train loss 2.51550. lr 5.842814e-04:  21%|██        | 3379/16329 [28:28<1:49:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3379: train loss 2.51550. lr 5.842814e-04:  21%|██        | 3380/16329 [28:28<1:50:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3380: train loss 2.57179. lr 5.842722e-04:  21%|██        | 3380/16329 [28:28<1:50:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3380: train loss 2.57179. lr 5.842722e-04:  21%|██        | 3381/16329 [28:28<1:50:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3381: train loss 2.48768. lr 5.842629e-04:  21%|██        | 3381/16329 [28:29<1:50:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3381: train loss 2.48768. lr 5.842629e-04:  21%|██        | 3382/16329 [28:29<1:50:28,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3382: train loss 2.51663. lr 5.842537e-04:  21%|██        | 3382/16329 [28:29<1:50:28,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3382: train loss 2.51663. lr 5.842537e-04:  21%|██        | 3383/16329 [28:29<1:49:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3383: train loss 2.56615. lr 5.842445e-04:  21%|██        | 3383/16329 [28:30<1:49:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3383: train loss 2.56615. lr 5.842445e-04:  21%|██        | 3384/16329 [28:30<1:49:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3384: train loss 2.50769. lr 5.842352e-04:  21%|██        | 3384/16329 [28:30<1:49:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3384: train loss 2.50769. lr 5.842352e-04:  21%|██        | 3385/16329 [28:30<1:48:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3385: train loss 2.56654. lr 5.842260e-04:  21%|██        | 3385/16329 [28:31<1:48:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3385: train loss 2.56654. lr 5.842260e-04:  21%|██        | 3386/16329 [28:31<1:48:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3386: train loss 2.58372. lr 5.842168e-04:  21%|██        | 3386/16329 [28:31<1:48:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3386: train loss 2.58372. lr 5.842168e-04:  21%|██        | 3387/16329 [28:31<1:47:46,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3387: train loss 2.58108. lr 5.842075e-04:  21%|██        | 3387/16329 [28:32<1:47:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3387: train loss 2.58108. lr 5.842075e-04:  21%|██        | 3388/16329 [28:32<1:47:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3388: train loss 2.51330. lr 5.841983e-04:  21%|██        | 3388/16329 [28:32<1:47:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3388: train loss 2.51330. lr 5.841983e-04:  21%|██        | 3389/16329 [28:32<1:46:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3389: train loss 2.55038. lr 5.841891e-04:  21%|██        | 3389/16329 [28:33<1:46:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3389: train loss 2.55038. lr 5.841891e-04:  21%|██        | 3390/16329 [28:33<1:46:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3390: train loss 2.44250. lr 5.841798e-04:  21%|██        | 3390/16329 [28:33<1:46:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3390: train loss 2.44250. lr 5.841798e-04:  21%|██        | 3391/16329 [28:33<1:46:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3391: train loss 2.58146. lr 5.841706e-04:  21%|██        | 3391/16329 [28:34<1:46:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3391: train loss 2.58146. lr 5.841706e-04:  21%|██        | 3392/16329 [28:34<1:46:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3392: train loss 2.50320. lr 5.841613e-04:  21%|██        | 3392/16329 [28:34<1:46:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3392: train loss 2.50320. lr 5.841613e-04:  21%|██        | 3393/16329 [28:34<1:46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3393: train loss 2.58876. lr 5.841521e-04:  21%|██        | 3393/16329 [28:34<1:46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3393: train loss 2.58876. lr 5.841521e-04:  21%|██        | 3394/16329 [28:34<1:46:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3394: train loss 2.46941. lr 5.841428e-04:  21%|██        | 3394/16329 [28:35<1:46:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3394: train loss 2.46941. lr 5.841428e-04:  21%|██        | 3395/16329 [28:35<1:46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3395: train loss 2.47765. lr 5.841335e-04:  21%|██        | 3395/16329 [28:35<1:46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3395: train loss 2.47765. lr 5.841335e-04:  21%|██        | 3396/16329 [28:35<1:46:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3396: train loss 2.52142. lr 5.841243e-04:  21%|██        | 3396/16329 [28:36<1:46:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3396: train loss 2.52142. lr 5.841243e-04:  21%|██        | 3397/16329 [28:36<1:57:47,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3397: train loss 2.54663. lr 5.841150e-04:  21%|██        | 3397/16329 [28:37<1:57:47,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3397: train loss 2.54663. lr 5.841150e-04:  21%|██        | 3398/16329 [28:37<1:54:27,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3398: train loss 2.54203. lr 5.841057e-04:  21%|██        | 3398/16329 [28:37<1:54:27,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3398: train loss 2.54203. lr 5.841057e-04:  21%|██        | 3399/16329 [28:37<1:51:54,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3399: train loss 2.48570. lr 5.840965e-04:  21%|██        | 3399/16329 [28:38<1:51:54,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3399: train loss 2.48570. lr 5.840965e-04:  21%|██        | 3400/16329 [28:38<1:55:16,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3400: train loss 2.58960. lr 5.840872e-04:  21%|██        | 3400/16329 [28:38<1:55:16,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3400: train loss 2.58960. lr 5.840872e-04:  21%|██        | 3401/16329 [28:38<1:56:18,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3401: train loss 2.44948. lr 5.840779e-04:  21%|██        | 3401/16329 [28:39<1:56:18,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3401: train loss 2.44948. lr 5.840779e-04:  21%|██        | 3402/16329 [28:39<1:56:10,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3402: train loss 2.56093. lr 5.840686e-04:  21%|██        | 3402/16329 [28:39<1:56:10,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3402: train loss 2.56093. lr 5.840686e-04:  21%|██        | 3403/16329 [28:39<1:55:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3403: train loss 2.55633. lr 5.840594e-04:  21%|██        | 3403/16329 [28:40<1:55:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3403: train loss 2.55633. lr 5.840594e-04:  21%|██        | 3404/16329 [28:40<1:53:38,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3404: train loss 2.55815. lr 5.840501e-04:  21%|██        | 3404/16329 [28:40<1:53:38,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3404: train loss 2.55815. lr 5.840501e-04:  21%|██        | 3405/16329 [28:40<1:52:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3405: train loss 2.55809. lr 5.840408e-04:  21%|██        | 3405/16329 [28:41<1:52:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3405: train loss 2.55809. lr 5.840408e-04:  21%|██        | 3406/16329 [28:41<1:50:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3406: train loss 2.47057. lr 5.840315e-04:  21%|██        | 3406/16329 [28:41<1:50:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3406: train loss 2.47057. lr 5.840315e-04:  21%|██        | 3407/16329 [28:41<1:49:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3407: train loss 2.54224. lr 5.840222e-04:  21%|██        | 3407/16329 [28:42<1:49:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3407: train loss 2.54224. lr 5.840222e-04:  21%|██        | 3408/16329 [28:42<1:48:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3408: train loss 2.54404. lr 5.840129e-04:  21%|██        | 3408/16329 [28:42<1:48:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3408: train loss 2.54404. lr 5.840129e-04:  21%|██        | 3409/16329 [28:42<1:52:01,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3409: train loss 2.54567. lr 5.840036e-04:  21%|██        | 3409/16329 [28:43<1:52:01,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3409: train loss 2.54567. lr 5.840036e-04:  21%|██        | 3410/16329 [28:43<1:52:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3410: train loss 2.58294. lr 5.839943e-04:  21%|██        | 3410/16329 [28:43<1:52:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3410: train loss 2.58294. lr 5.839943e-04:  21%|██        | 3411/16329 [28:43<1:52:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3411: train loss 2.50994. lr 5.839850e-04:  21%|██        | 3411/16329 [28:44<1:52:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3411: train loss 2.50994. lr 5.839850e-04:  21%|██        | 3412/16329 [28:44<1:51:34,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3412: train loss 2.48180. lr 5.839757e-04:  21%|██        | 3412/16329 [28:44<1:51:34,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3412: train loss 2.48180. lr 5.839757e-04:  21%|██        | 3413/16329 [28:44<1:50:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3413: train loss 2.50710. lr 5.839664e-04:  21%|██        | 3413/16329 [28:45<1:50:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3413: train loss 2.50710. lr 5.839664e-04:  21%|██        | 3414/16329 [28:45<1:49:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3414: train loss 2.50789. lr 5.839571e-04:  21%|██        | 3414/16329 [28:45<1:49:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3414: train loss 2.50789. lr 5.839571e-04:  21%|██        | 3415/16329 [28:45<1:49:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3415: train loss 2.58165. lr 5.839478e-04:  21%|██        | 3415/16329 [28:46<1:49:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3415: train loss 2.58165. lr 5.839478e-04:  21%|██        | 3416/16329 [28:46<1:48:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3416: train loss 2.60354. lr 5.839385e-04:  21%|██        | 3416/16329 [28:46<1:48:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3416: train loss 2.60354. lr 5.839385e-04:  21%|██        | 3417/16329 [28:46<1:48:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3417: train loss 2.54004. lr 5.839291e-04:  21%|██        | 3417/16329 [28:47<1:48:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3417: train loss 2.54004. lr 5.839291e-04:  21%|██        | 3418/16329 [28:47<1:47:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3418: train loss 2.57617. lr 5.839198e-04:  21%|██        | 3418/16329 [28:47<1:47:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3418: train loss 2.57617. lr 5.839198e-04:  21%|██        | 3419/16329 [28:47<1:47:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3419: train loss 2.47910. lr 5.839105e-04:  21%|██        | 3419/16329 [28:48<1:47:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3419: train loss 2.47910. lr 5.839105e-04:  21%|██        | 3420/16329 [28:48<1:46:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3420: train loss 2.59666. lr 5.839012e-04:  21%|██        | 3420/16329 [28:48<1:46:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3420: train loss 2.59666. lr 5.839012e-04:  21%|██        | 3421/16329 [28:48<1:46:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3421: train loss 2.50509. lr 5.838918e-04:  21%|██        | 3421/16329 [28:49<1:46:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3421: train loss 2.50509. lr 5.838918e-04:  21%|██        | 3422/16329 [28:49<1:46:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3422: train loss 2.54303. lr 5.838825e-04:  21%|██        | 3422/16329 [28:49<1:46:18,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3422: train loss 2.54303. lr 5.838825e-04:  21%|██        | 3423/16329 [28:49<1:45:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3423: train loss 2.54310. lr 5.838732e-04:  21%|██        | 3423/16329 [28:50<1:45:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3423: train loss 2.54310. lr 5.838732e-04:  21%|██        | 3424/16329 [28:50<1:57:11,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3424: train loss 2.49475. lr 5.838638e-04:  21%|██        | 3424/16329 [28:51<1:57:11,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3424: train loss 2.49475. lr 5.838638e-04:  21%|██        | 3425/16329 [28:51<1:54:02,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3425: train loss 2.50985. lr 5.838545e-04:  21%|██        | 3425/16329 [28:51<1:54:02,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3425: train loss 2.50985. lr 5.838545e-04:  21%|██        | 3426/16329 [28:51<1:51:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3426: train loss 2.49310. lr 5.838452e-04:  21%|██        | 3426/16329 [28:52<1:51:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3426: train loss 2.49310. lr 5.838452e-04:  21%|██        | 3427/16329 [28:52<1:54:22,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3427: train loss 2.56541. lr 5.838358e-04:  21%|██        | 3427/16329 [28:52<1:54:22,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3427: train loss 2.56541. lr 5.838358e-04:  21%|██        | 3428/16329 [28:52<1:55:17,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3428: train loss 2.45271. lr 5.838265e-04:  21%|██        | 3428/16329 [28:53<1:55:17,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3428: train loss 2.45271. lr 5.838265e-04:  21%|██        | 3429/16329 [28:53<1:55:15,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3429: train loss 2.54887. lr 5.838171e-04:  21%|██        | 3429/16329 [28:53<1:55:15,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3429: train loss 2.54887. lr 5.838171e-04:  21%|██        | 3430/16329 [28:53<1:54:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3430: train loss 2.57227. lr 5.838078e-04:  21%|██        | 3430/16329 [28:54<1:54:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3430: train loss 2.57227. lr 5.838078e-04:  21%|██        | 3431/16329 [28:54<1:53:23,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3431: train loss 2.52253. lr 5.837984e-04:  21%|██        | 3431/16329 [28:54<1:53:23,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3431: train loss 2.52253. lr 5.837984e-04:  21%|██        | 3432/16329 [28:54<1:52:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3432: train loss 2.46037. lr 5.837891e-04:  21%|██        | 3432/16329 [28:55<1:52:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3432: train loss 2.46037. lr 5.837891e-04:  21%|██        | 3433/16329 [28:55<1:50:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3433: train loss 2.56583. lr 5.837797e-04:  21%|██        | 3433/16329 [28:55<1:50:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3433: train loss 2.56583. lr 5.837797e-04:  21%|██        | 3434/16329 [28:55<1:50:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3434: train loss 2.51321. lr 5.837703e-04:  21%|██        | 3434/16329 [28:56<1:50:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3434: train loss 2.51321. lr 5.837703e-04:  21%|██        | 3435/16329 [28:56<1:49:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3435: train loss 2.56535. lr 5.837610e-04:  21%|██        | 3435/16329 [28:56<1:49:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3435: train loss 2.56535. lr 5.837610e-04:  21%|██        | 3436/16329 [28:56<1:48:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3436: train loss 2.45198. lr 5.837516e-04:  21%|██        | 3436/16329 [28:57<1:48:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3436: train loss 2.45198. lr 5.837516e-04:  21%|██        | 3437/16329 [28:57<1:47:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3437: train loss 2.56889. lr 5.837422e-04:  21%|██        | 3437/16329 [28:57<1:47:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3437: train loss 2.56889. lr 5.837422e-04:  21%|██        | 3438/16329 [28:57<1:46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3438: train loss 2.53287. lr 5.837329e-04:  21%|██        | 3438/16329 [28:58<1:46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3438: train loss 2.53287. lr 5.837329e-04:  21%|██        | 3439/16329 [28:58<1:46:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3439: train loss 2.50609. lr 5.837235e-04:  21%|██        | 3439/16329 [28:58<1:46:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3439: train loss 2.50609. lr 5.837235e-04:  21%|██        | 3440/16329 [28:58<1:45:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3440: train loss 2.51375. lr 5.837141e-04:  21%|██        | 3440/16329 [28:59<1:45:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3440: train loss 2.51375. lr 5.837141e-04:  21%|██        | 3441/16329 [28:59<1:45:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3441: train loss 2.51076. lr 5.837047e-04:  21%|██        | 3441/16329 [28:59<1:45:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3441: train loss 2.51076. lr 5.837047e-04:  21%|██        | 3442/16329 [28:59<1:45:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3442: train loss 2.46638. lr 5.836953e-04:  21%|██        | 3442/16329 [29:00<1:45:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3442: train loss 2.46638. lr 5.836953e-04:  21%|██        | 3443/16329 [29:00<1:45:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3443: train loss 2.49307. lr 5.836860e-04:  21%|██        | 3443/16329 [29:00<1:45:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3443: train loss 2.49307. lr 5.836860e-04:  21%|██        | 3444/16329 [29:00<1:45:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3444: train loss 2.50469. lr 5.836766e-04:  21%|██        | 3444/16329 [29:01<1:45:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3444: train loss 2.50469. lr 5.836766e-04:  21%|██        | 3445/16329 [29:01<1:45:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3445: train loss 2.53093. lr 5.836672e-04:  21%|██        | 3445/16329 [29:01<1:45:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3445: train loss 2.53093. lr 5.836672e-04:  21%|██        | 3446/16329 [29:01<1:45:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3446: train loss 2.56678. lr 5.836578e-04:  21%|██        | 3446/16329 [29:02<1:45:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3446: train loss 2.56678. lr 5.836578e-04:  21%|██        | 3447/16329 [29:02<1:45:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3447: train loss 2.50896. lr 5.836484e-04:  21%|██        | 3447/16329 [29:02<1:45:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3447: train loss 2.50896. lr 5.836484e-04:  21%|██        | 3448/16329 [29:02<1:45:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3448: train loss 2.49020. lr 5.836390e-04:  21%|██        | 3448/16329 [29:03<1:45:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3448: train loss 2.49020. lr 5.836390e-04:  21%|██        | 3449/16329 [29:03<1:45:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3449: train loss 2.52783. lr 5.836296e-04:  21%|██        | 3449/16329 [29:03<1:45:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3449: train loss 2.52783. lr 5.836296e-04:  21%|██        | 3450/16329 [29:03<1:45:12,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3450: train loss 2.46925. lr 5.836202e-04:  21%|██        | 3450/16329 [29:04<1:45:12,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3450: train loss 2.46925. lr 5.836202e-04:  21%|██        | 3451/16329 [29:04<1:45:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3451: train loss 2.53193. lr 5.836108e-04:  21%|██        | 3451/16329 [29:04<1:45:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3451: train loss 2.53193. lr 5.836108e-04:  21%|██        | 3452/16329 [29:04<1:45:18,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3452: train loss 2.51176. lr 5.836014e-04:  21%|██        | 3452/16329 [29:05<1:45:18,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3452: train loss 2.51176. lr 5.836014e-04:  21%|██        | 3453/16329 [29:05<1:45:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3453: train loss 2.52757. lr 5.835920e-04:  21%|██        | 3453/16329 [29:05<1:45:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3453: train loss 2.52757. lr 5.835920e-04:  21%|██        | 3454/16329 [29:05<1:45:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3454: train loss 2.51253. lr 5.835825e-04:  21%|██        | 3454/16329 [29:06<1:45:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3454: train loss 2.51253. lr 5.835825e-04:  21%|██        | 3455/16329 [29:06<1:45:11,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3455: train loss 2.51632. lr 5.835731e-04:  21%|██        | 3455/16329 [29:06<1:45:11,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 3455: train loss 2.51632. lr 5.835731e-04:  21%|██        | 3456/16329 [29:06<1:45:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3456: train loss 2.46968. lr 5.835637e-04:  21%|██        | 3456/16329 [29:07<1:45:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3456: train loss 2.46968. lr 5.835637e-04:  21%|██        | 3457/16329 [29:07<1:45:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3457: train loss 2.54080. lr 5.835543e-04:  21%|██        | 3457/16329 [29:07<1:45:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3457: train loss 2.54080. lr 5.835543e-04:  21%|██        | 3458/16329 [29:07<1:45:47,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3458: train loss 2.46755. lr 5.835449e-04:  21%|██        | 3458/16329 [29:08<1:45:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3458: train loss 2.46755. lr 5.835449e-04:  21%|██        | 3459/16329 [29:08<1:46:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3459: train loss 2.51804. lr 5.835354e-04:  21%|██        | 3459/16329 [29:08<1:46:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3459: train loss 2.51804. lr 5.835354e-04:  21%|██        | 3460/16329 [29:08<1:45:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3460: train loss 2.51114. lr 5.835260e-04:  21%|██        | 3460/16329 [29:09<1:45:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3460: train loss 2.51114. lr 5.835260e-04:  21%|██        | 3461/16329 [29:09<1:46:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3461: train loss 2.50319. lr 5.835166e-04:  21%|██        | 3461/16329 [29:09<1:46:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3461: train loss 2.50319. lr 5.835166e-04:  21%|██        | 3462/16329 [29:09<1:45:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3462: train loss 2.49169. lr 5.835071e-04:  21%|██        | 3462/16329 [29:10<1:45:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3462: train loss 2.49169. lr 5.835071e-04:  21%|██        | 3463/16329 [29:10<1:46:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3463: train loss 2.51018. lr 5.834977e-04:  21%|██        | 3463/16329 [29:10<1:46:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3463: train loss 2.51018. lr 5.834977e-04:  21%|██        | 3464/16329 [29:10<1:58:43,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 3464: train loss 2.45453. lr 5.834882e-04:  21%|██        | 3464/16329 [29:11<1:58:43,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 3464: train loss 2.45453. lr 5.834882e-04:  21%|██        | 3465/16329 [29:11<1:54:55,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3465: train loss 2.48260. lr 5.834788e-04:  21%|██        | 3465/16329 [29:11<1:54:55,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3465: train loss 2.48260. lr 5.834788e-04:  21%|██        | 3466/16329 [29:11<1:52:11,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3466: train loss 2.47197. lr 5.834694e-04:  21%|██        | 3466/16329 [29:12<1:52:11,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3466: train loss 2.47197. lr 5.834694e-04:  21%|██        | 3467/16329 [29:12<1:49:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3467: train loss 2.50907. lr 5.834599e-04:  21%|██        | 3467/16329 [29:12<1:49:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3467: train loss 2.50907. lr 5.834599e-04:  21%|██        | 3468/16329 [29:12<1:48:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3468: train loss 2.48419. lr 5.834505e-04:  21%|██        | 3468/16329 [29:13<1:48:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3468: train loss 2.48419. lr 5.834505e-04:  21%|██        | 3469/16329 [29:13<1:47:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3469: train loss 2.55819. lr 5.834410e-04:  21%|██        | 3469/16329 [29:13<1:47:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3469: train loss 2.55819. lr 5.834410e-04:  21%|██▏       | 3470/16329 [29:13<1:47:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3470: train loss 2.45817. lr 5.834315e-04:  21%|██▏       | 3470/16329 [29:14<1:47:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3470: train loss 2.45817. lr 5.834315e-04:  21%|██▏       | 3471/16329 [29:14<1:46:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3471: train loss 2.53131. lr 5.834221e-04:  21%|██▏       | 3471/16329 [29:14<1:46:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3471: train loss 2.53131. lr 5.834221e-04:  21%|██▏       | 3472/16329 [29:14<1:46:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3472: train loss 2.51569. lr 5.834126e-04:  21%|██▏       | 3472/16329 [29:15<1:46:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3472: train loss 2.51569. lr 5.834126e-04:  21%|██▏       | 3473/16329 [29:15<1:46:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3473: train loss 2.49976. lr 5.834032e-04:  21%|██▏       | 3473/16329 [29:15<1:46:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3473: train loss 2.49976. lr 5.834032e-04:  21%|██▏       | 3474/16329 [29:15<1:46:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3474: train loss 2.54371. lr 5.833937e-04:  21%|██▏       | 3474/16329 [29:16<1:46:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3474: train loss 2.54371. lr 5.833937e-04:  21%|██▏       | 3475/16329 [29:16<1:46:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3475: train loss 2.48087. lr 5.833842e-04:  21%|██▏       | 3475/16329 [29:16<1:46:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3475: train loss 2.48087. lr 5.833842e-04:  21%|██▏       | 3476/16329 [29:16<1:46:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3476: train loss 2.55035. lr 5.833747e-04:  21%|██▏       | 3476/16329 [29:17<1:46:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3476: train loss 2.55035. lr 5.833747e-04:  21%|██▏       | 3477/16329 [29:17<1:46:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3477: train loss 2.50501. lr 5.833653e-04:  21%|██▏       | 3477/16329 [29:17<1:46:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3477: train loss 2.50501. lr 5.833653e-04:  21%|██▏       | 3478/16329 [29:17<1:48:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3478: train loss 2.51295. lr 5.833558e-04:  21%|██▏       | 3478/16329 [29:18<1:48:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3478: train loss 2.51295. lr 5.833558e-04:  21%|██▏       | 3479/16329 [29:18<1:49:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3479: train loss 2.42448. lr 5.833463e-04:  21%|██▏       | 3479/16329 [29:18<1:49:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3479: train loss 2.42448. lr 5.833463e-04:  21%|██▏       | 3480/16329 [29:18<1:49:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3480: train loss 2.47293. lr 5.833368e-04:  21%|██▏       | 3480/16329 [29:19<1:49:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3480: train loss 2.47293. lr 5.833368e-04:  21%|██▏       | 3481/16329 [29:19<1:49:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3481: train loss 2.55878. lr 5.833273e-04:  21%|██▏       | 3481/16329 [29:19<1:49:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3481: train loss 2.55878. lr 5.833273e-04:  21%|██▏       | 3482/16329 [29:19<1:48:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3482: train loss 2.46399. lr 5.833179e-04:  21%|██▏       | 3482/16329 [29:20<1:48:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3482: train loss 2.46399. lr 5.833179e-04:  21%|██▏       | 3483/16329 [29:20<1:48:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3483: train loss 2.50574. lr 5.833084e-04:  21%|██▏       | 3483/16329 [29:20<1:48:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3483: train loss 2.50574. lr 5.833084e-04:  21%|██▏       | 3484/16329 [29:20<1:47:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3484: train loss 2.48313. lr 5.832989e-04:  21%|██▏       | 3484/16329 [29:21<1:47:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3484: train loss 2.48313. lr 5.832989e-04:  21%|██▏       | 3485/16329 [29:21<1:47:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3485: train loss 2.54789. lr 5.832894e-04:  21%|██▏       | 3485/16329 [29:21<1:47:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3485: train loss 2.54789. lr 5.832894e-04:  21%|██▏       | 3486/16329 [29:21<1:47:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3486: train loss 2.48251. lr 5.832799e-04:  21%|██▏       | 3486/16329 [29:22<1:47:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3486: train loss 2.48251. lr 5.832799e-04:  21%|██▏       | 3487/16329 [29:22<1:46:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3487: train loss 2.52629. lr 5.832704e-04:  21%|██▏       | 3487/16329 [29:22<1:46:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3487: train loss 2.52629. lr 5.832704e-04:  21%|██▏       | 3488/16329 [29:22<1:46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3488: train loss 2.48213. lr 5.832609e-04:  21%|██▏       | 3488/16329 [29:23<1:46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3488: train loss 2.48213. lr 5.832609e-04:  21%|██▏       | 3489/16329 [29:23<1:46:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3489: train loss 2.38876. lr 5.832514e-04:  21%|██▏       | 3489/16329 [29:23<1:46:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3489: train loss 2.38876. lr 5.832514e-04:  21%|██▏       | 3490/16329 [29:23<1:45:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3490: train loss 2.46714. lr 5.832418e-04:  21%|██▏       | 3490/16329 [29:24<1:45:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3490: train loss 2.46714. lr 5.832418e-04:  21%|██▏       | 3491/16329 [29:24<1:45:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3491: train loss 2.51175. lr 5.832323e-04:  21%|██▏       | 3491/16329 [29:24<1:45:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3491: train loss 2.51175. lr 5.832323e-04:  21%|██▏       | 3492/16329 [29:24<1:45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3492: train loss 2.47919. lr 5.832228e-04:  21%|██▏       | 3492/16329 [29:25<1:45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3492: train loss 2.47919. lr 5.832228e-04:  21%|██▏       | 3493/16329 [29:25<1:45:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3493: train loss 2.48799. lr 5.832133e-04:  21%|██▏       | 3493/16329 [29:25<1:45:55,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3493: train loss 2.48799. lr 5.832133e-04:  21%|██▏       | 3494/16329 [29:25<1:45:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3494: train loss 2.49753. lr 5.832038e-04:  21%|██▏       | 3494/16329 [29:26<1:45:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3494: train loss 2.49753. lr 5.832038e-04:  21%|██▏       | 3495/16329 [29:26<1:45:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3495: train loss 2.54646. lr 5.831943e-04:  21%|██▏       | 3495/16329 [29:26<1:45:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3495: train loss 2.54646. lr 5.831943e-04:  21%|██▏       | 3496/16329 [29:26<1:45:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3496: train loss 2.51519. lr 5.831847e-04:  21%|██▏       | 3496/16329 [29:27<1:45:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3496: train loss 2.51519. lr 5.831847e-04:  21%|██▏       | 3497/16329 [29:27<1:45:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3497: train loss 2.50431. lr 5.831752e-04:  21%|██▏       | 3497/16329 [29:27<1:45:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3497: train loss 2.50431. lr 5.831752e-04:  21%|██▏       | 3498/16329 [29:27<1:45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3498: train loss 2.47659. lr 5.831657e-04:  21%|██▏       | 3498/16329 [29:28<1:45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3498: train loss 2.47659. lr 5.831657e-04:  21%|██▏       | 3499/16329 [29:28<1:59:44,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3499: train loss 2.47028. lr 5.831561e-04:  21%|██▏       | 3499/16329 [29:28<1:59:44,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3499: train loss 2.47028. lr 5.831561e-04:  21%|██▏       | 3500/16329 [29:28<1:55:22,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3500: train loss 2.54135. lr 5.831466e-04:  21%|██▏       | 3500/16329 [29:29<1:55:22,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3500: train loss 2.54135. lr 5.831466e-04:  21%|██▏       | 3501/16329 [29:29<1:52:19,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3501: train loss 2.49725. lr 5.831371e-04:  21%|██▏       | 3501/16329 [29:29<1:52:19,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3501: train loss 2.49725. lr 5.831371e-04:  21%|██▏       | 3502/16329 [29:29<1:49:58,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3502: train loss 2.53960. lr 5.831275e-04:  21%|██▏       | 3502/16329 [29:30<1:49:58,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3502: train loss 2.53960. lr 5.831275e-04:  21%|██▏       | 3503/16329 [29:30<1:48:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3503: train loss 2.47955. lr 5.831180e-04:  21%|██▏       | 3503/16329 [29:30<1:48:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3503: train loss 2.47955. lr 5.831180e-04:  21%|██▏       | 3504/16329 [29:30<1:47:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3504: train loss 2.54934. lr 5.831084e-04:  21%|██▏       | 3504/16329 [29:31<1:47:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3504: train loss 2.54934. lr 5.831084e-04:  21%|██▏       | 3505/16329 [29:31<1:47:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3505: train loss 2.48191. lr 5.830989e-04:  21%|██▏       | 3505/16329 [29:31<1:47:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3505: train loss 2.48191. lr 5.830989e-04:  21%|██▏       | 3506/16329 [29:31<1:46:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3506: train loss 2.47228. lr 5.830893e-04:  21%|██▏       | 3506/16329 [29:32<1:46:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3506: train loss 2.47228. lr 5.830893e-04:  21%|██▏       | 3507/16329 [29:32<1:46:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3507: train loss 2.46388. lr 5.830798e-04:  21%|██▏       | 3507/16329 [29:32<1:46:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3507: train loss 2.46388. lr 5.830798e-04:  21%|██▏       | 3508/16329 [29:32<1:49:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3508: train loss 2.48298. lr 5.830702e-04:  21%|██▏       | 3508/16329 [29:33<1:49:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3508: train loss 2.48298. lr 5.830702e-04:  21%|██▏       | 3509/16329 [29:33<1:50:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3509: train loss 2.46357. lr 5.830607e-04:  21%|██▏       | 3509/16329 [29:33<1:50:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3509: train loss 2.46357. lr 5.830607e-04:  21%|██▏       | 3510/16329 [29:33<1:50:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3510: train loss 2.50710. lr 5.830511e-04:  21%|██▏       | 3510/16329 [29:34<1:50:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3510: train loss 2.50710. lr 5.830511e-04:  22%|██▏       | 3511/16329 [29:34<1:50:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3511: train loss 2.50507. lr 5.830415e-04:  22%|██▏       | 3511/16329 [29:34<1:50:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3511: train loss 2.50507. lr 5.830415e-04:  22%|██▏       | 3512/16329 [29:34<1:49:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3512: train loss 2.52642. lr 5.830320e-04:  22%|██▏       | 3512/16329 [29:35<1:49:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3512: train loss 2.52642. lr 5.830320e-04:  22%|██▏       | 3513/16329 [29:35<1:49:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3513: train loss 2.51079. lr 5.830224e-04:  22%|██▏       | 3513/16329 [29:35<1:49:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3513: train loss 2.51079. lr 5.830224e-04:  22%|██▏       | 3514/16329 [29:35<1:48:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3514: train loss 2.49638. lr 5.830128e-04:  22%|██▏       | 3514/16329 [29:36<1:48:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3514: train loss 2.49638. lr 5.830128e-04:  22%|██▏       | 3515/16329 [29:36<1:47:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3515: train loss 2.45632. lr 5.830033e-04:  22%|██▏       | 3515/16329 [29:36<1:47:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3515: train loss 2.45632. lr 5.830033e-04:  22%|██▏       | 3516/16329 [29:36<1:47:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3516: train loss 2.54090. lr 5.829937e-04:  22%|██▏       | 3516/16329 [29:37<1:47:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3516: train loss 2.54090. lr 5.829937e-04:  22%|██▏       | 3517/16329 [29:37<1:46:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3517: train loss 2.45679. lr 5.829841e-04:  22%|██▏       | 3517/16329 [29:37<1:46:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3517: train loss 2.45679. lr 5.829841e-04:  22%|██▏       | 3518/16329 [29:37<1:46:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3518: train loss 2.54086. lr 5.829745e-04:  22%|██▏       | 3518/16329 [29:38<1:46:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3518: train loss 2.54086. lr 5.829745e-04:  22%|██▏       | 3519/16329 [29:38<1:46:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3519: train loss 2.48717. lr 5.829649e-04:  22%|██▏       | 3519/16329 [29:38<1:46:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3519: train loss 2.48717. lr 5.829649e-04:  22%|██▏       | 3520/16329 [29:38<1:46:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3520: train loss 2.55420. lr 5.829553e-04:  22%|██▏       | 3520/16329 [29:39<1:46:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3520: train loss 2.55420. lr 5.829553e-04:  22%|██▏       | 3521/16329 [29:39<1:46:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3521: train loss 2.46086. lr 5.829458e-04:  22%|██▏       | 3521/16329 [29:39<1:46:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3521: train loss 2.46086. lr 5.829458e-04:  22%|██▏       | 3522/16329 [29:39<1:45:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3522: train loss 2.56069. lr 5.829362e-04:  22%|██▏       | 3522/16329 [29:40<1:45:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3522: train loss 2.56069. lr 5.829362e-04:  22%|██▏       | 3523/16329 [29:40<1:46:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3523: train loss 2.47572. lr 5.829266e-04:  22%|██▏       | 3523/16329 [29:41<1:46:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3523: train loss 2.47572. lr 5.829266e-04:  22%|██▏       | 3524/16329 [29:41<1:57:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3524: train loss 2.47913. lr 5.829170e-04:  22%|██▏       | 3524/16329 [29:41<1:57:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3524: train loss 2.47913. lr 5.829170e-04:  22%|██▏       | 3525/16329 [29:41<1:53:50,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3525: train loss 2.45905. lr 5.829074e-04:  22%|██▏       | 3525/16329 [29:42<1:53:50,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3525: train loss 2.45905. lr 5.829074e-04:  22%|██▏       | 3526/16329 [29:42<1:51:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3526: train loss 2.51218. lr 5.828978e-04:  22%|██▏       | 3526/16329 [29:42<1:51:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3526: train loss 2.51218. lr 5.828978e-04:  22%|██▏       | 3527/16329 [29:42<1:49:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3527: train loss 2.47124. lr 5.828882e-04:  22%|██▏       | 3527/16329 [29:43<1:49:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3527: train loss 2.47124. lr 5.828882e-04:  22%|██▏       | 3528/16329 [29:43<1:48:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3528: train loss 2.49365. lr 5.828785e-04:  22%|██▏       | 3528/16329 [29:43<1:48:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3528: train loss 2.49365. lr 5.828785e-04:  22%|██▏       | 3529/16329 [29:43<1:47:06,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3529: train loss 2.48299. lr 5.828689e-04:  22%|██▏       | 3529/16329 [29:44<1:47:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3529: train loss 2.48299. lr 5.828689e-04:  22%|██▏       | 3530/16329 [29:44<1:46:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3530: train loss 2.50731. lr 5.828593e-04:  22%|██▏       | 3530/16329 [29:44<1:46:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3530: train loss 2.50731. lr 5.828593e-04:  22%|██▏       | 3531/16329 [29:44<1:46:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3531: train loss 2.45442. lr 5.828497e-04:  22%|██▏       | 3531/16329 [29:45<1:46:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3531: train loss 2.45442. lr 5.828497e-04:  22%|██▏       | 3532/16329 [29:45<1:46:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3532: train loss 2.47186. lr 5.828401e-04:  22%|██▏       | 3532/16329 [29:45<1:46:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3532: train loss 2.47186. lr 5.828401e-04:  22%|██▏       | 3533/16329 [29:45<1:46:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3533: train loss 2.49472. lr 5.828305e-04:  22%|██▏       | 3533/16329 [29:46<1:46:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3533: train loss 2.49472. lr 5.828305e-04:  22%|██▏       | 3534/16329 [29:46<1:46:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3534: train loss 2.48218. lr 5.828208e-04:  22%|██▏       | 3534/16329 [29:46<1:46:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3534: train loss 2.48218. lr 5.828208e-04:  22%|██▏       | 3535/16329 [29:46<1:46:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3535: train loss 2.46202. lr 5.828112e-04:  22%|██▏       | 3535/16329 [29:46<1:46:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3535: train loss 2.46202. lr 5.828112e-04:  22%|██▏       | 3536/16329 [29:46<1:45:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3536: train loss 2.51926. lr 5.828016e-04:  22%|██▏       | 3536/16329 [29:47<1:45:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3536: train loss 2.51926. lr 5.828016e-04:  22%|██▏       | 3537/16329 [29:47<1:45:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3537: train loss 2.47361. lr 5.827919e-04:  22%|██▏       | 3537/16329 [29:47<1:45:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3537: train loss 2.47361. lr 5.827919e-04:  22%|██▏       | 3538/16329 [29:47<1:45:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3538: train loss 2.43903. lr 5.827823e-04:  22%|██▏       | 3538/16329 [29:48<1:45:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3538: train loss 2.43903. lr 5.827823e-04:  22%|██▏       | 3539/16329 [29:48<1:45:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3539: train loss 2.48528. lr 5.827727e-04:  22%|██▏       | 3539/16329 [29:49<1:45:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3539: train loss 2.48528. lr 5.827727e-04:  22%|██▏       | 3540/16329 [29:49<1:50:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3540: train loss 2.53201. lr 5.827630e-04:  22%|██▏       | 3540/16329 [29:49<1:50:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3540: train loss 2.53201. lr 5.827630e-04:  22%|██▏       | 3541/16329 [29:49<1:52:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3541: train loss 2.49296. lr 5.827534e-04:  22%|██▏       | 3541/16329 [29:50<1:52:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3541: train loss 2.49296. lr 5.827534e-04:  22%|██▏       | 3542/16329 [29:50<1:52:32,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3542: train loss 2.45081. lr 5.827437e-04:  22%|██▏       | 3542/16329 [29:50<1:52:32,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3542: train loss 2.45081. lr 5.827437e-04:  22%|██▏       | 3543/16329 [29:50<1:51:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3543: train loss 2.44240. lr 5.827341e-04:  22%|██▏       | 3543/16329 [29:51<1:51:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3543: train loss 2.44240. lr 5.827341e-04:  22%|██▏       | 3544/16329 [29:51<1:50:44,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3544: train loss 2.38278. lr 5.827244e-04:  22%|██▏       | 3544/16329 [29:51<1:50:44,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3544: train loss 2.38278. lr 5.827244e-04:  22%|██▏       | 3545/16329 [29:51<1:49:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3545: train loss 2.39310. lr 5.827148e-04:  22%|██▏       | 3545/16329 [29:52<1:49:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3545: train loss 2.39310. lr 5.827148e-04:  22%|██▏       | 3546/16329 [29:52<1:48:34,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3546: train loss 2.48378. lr 5.827051e-04:  22%|██▏       | 3546/16329 [29:52<1:48:34,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3546: train loss 2.48378. lr 5.827051e-04:  22%|██▏       | 3547/16329 [29:52<1:47:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3547: train loss 2.44170. lr 5.826955e-04:  22%|██▏       | 3547/16329 [29:53<1:47:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3547: train loss 2.44170. lr 5.826955e-04:  22%|██▏       | 3548/16329 [29:53<1:46:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3548: train loss 2.42484. lr 5.826858e-04:  22%|██▏       | 3548/16329 [29:53<1:46:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3548: train loss 2.42484. lr 5.826858e-04:  22%|██▏       | 3549/16329 [29:53<1:46:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3549: train loss 2.50496. lr 5.826762e-04:  22%|██▏       | 3549/16329 [29:54<1:46:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3549: train loss 2.50496. lr 5.826762e-04:  22%|██▏       | 3550/16329 [29:54<1:46:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3550: train loss 2.44130. lr 5.826665e-04:  22%|██▏       | 3550/16329 [29:54<1:46:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3550: train loss 2.44130. lr 5.826665e-04:  22%|██▏       | 3551/16329 [29:54<1:56:29,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3551: train loss 2.44279. lr 5.826568e-04:  22%|██▏       | 3551/16329 [29:55<1:56:29,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3551: train loss 2.44279. lr 5.826568e-04:  22%|██▏       | 3552/16329 [29:55<1:53:19,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3552: train loss 2.51522. lr 5.826471e-04:  22%|██▏       | 3552/16329 [29:55<1:53:19,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3552: train loss 2.51522. lr 5.826471e-04:  22%|██▏       | 3553/16329 [29:55<1:50:46,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3553: train loss 2.49079. lr 5.826375e-04:  22%|██▏       | 3553/16329 [29:56<1:50:46,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3553: train loss 2.49079. lr 5.826375e-04:  22%|██▏       | 3554/16329 [29:56<1:48:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3554: train loss 2.44148. lr 5.826278e-04:  22%|██▏       | 3554/16329 [29:56<1:48:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3554: train loss 2.44148. lr 5.826278e-04:  22%|██▏       | 3555/16329 [29:56<1:47:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3555: train loss 2.44718. lr 5.826181e-04:  22%|██▏       | 3555/16329 [29:57<1:47:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3555: train loss 2.44718. lr 5.826181e-04:  22%|██▏       | 3556/16329 [29:57<1:46:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3556: train loss 2.53679. lr 5.826084e-04:  22%|██▏       | 3556/16329 [29:57<1:46:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3556: train loss 2.53679. lr 5.826084e-04:  22%|██▏       | 3557/16329 [29:57<1:46:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3557: train loss 2.47754. lr 5.825987e-04:  22%|██▏       | 3557/16329 [29:58<1:46:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3557: train loss 2.47754. lr 5.825987e-04:  22%|██▏       | 3558/16329 [29:58<1:46:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3558: train loss 2.45872. lr 5.825891e-04:  22%|██▏       | 3558/16329 [29:58<1:46:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3558: train loss 2.45872. lr 5.825891e-04:  22%|██▏       | 3559/16329 [29:58<1:45:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3559: train loss 2.44726. lr 5.825794e-04:  22%|██▏       | 3559/16329 [29:59<1:45:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3559: train loss 2.44726. lr 5.825794e-04:  22%|██▏       | 3560/16329 [29:59<1:45:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3560: train loss 2.44191. lr 5.825697e-04:  22%|██▏       | 3560/16329 [29:59<1:45:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3560: train loss 2.44191. lr 5.825697e-04:  22%|██▏       | 3561/16329 [29:59<1:44:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3561: train loss 2.51451. lr 5.825600e-04:  22%|██▏       | 3561/16329 [30:00<1:44:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3561: train loss 2.51451. lr 5.825600e-04:  22%|██▏       | 3562/16329 [30:00<1:45:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3562: train loss 2.47077. lr 5.825503e-04:  22%|██▏       | 3562/16329 [30:00<1:45:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3562: train loss 2.47077. lr 5.825503e-04:  22%|██▏       | 3563/16329 [30:00<1:45:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3563: train loss 2.49054. lr 5.825406e-04:  22%|██▏       | 3563/16329 [30:01<1:45:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3563: train loss 2.49054. lr 5.825406e-04:  22%|██▏       | 3564/16329 [30:01<1:45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3564: train loss 2.43853. lr 5.825309e-04:  22%|██▏       | 3564/16329 [30:01<1:45:18,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3564: train loss 2.43853. lr 5.825309e-04:  22%|██▏       | 3565/16329 [30:01<1:45:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3565: train loss 2.45394. lr 5.825212e-04:  22%|██▏       | 3565/16329 [30:02<1:45:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3565: train loss 2.45394. lr 5.825212e-04:  22%|██▏       | 3566/16329 [30:02<1:44:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3566: train loss 2.47174. lr 5.825115e-04:  22%|██▏       | 3566/16329 [30:02<1:44:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3566: train loss 2.47174. lr 5.825115e-04:  22%|██▏       | 3567/16329 [30:02<1:45:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3567: train loss 2.46926. lr 5.825018e-04:  22%|██▏       | 3567/16329 [30:03<1:45:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3567: train loss 2.46926. lr 5.825018e-04:  22%|██▏       | 3568/16329 [30:03<1:44:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3568: train loss 2.42535. lr 5.824920e-04:  22%|██▏       | 3568/16329 [30:03<1:44:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3568: train loss 2.42535. lr 5.824920e-04:  22%|██▏       | 3569/16329 [30:03<1:45:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3569: train loss 2.41377. lr 5.824823e-04:  22%|██▏       | 3569/16329 [30:04<1:45:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3569: train loss 2.41377. lr 5.824823e-04:  22%|██▏       | 3570/16329 [30:04<1:45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3570: train loss 2.46590. lr 5.824726e-04:  22%|██▏       | 3570/16329 [30:04<1:45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3570: train loss 2.46590. lr 5.824726e-04:  22%|██▏       | 3571/16329 [30:04<1:44:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3571: train loss 2.48939. lr 5.824629e-04:  22%|██▏       | 3571/16329 [30:05<1:44:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3571: train loss 2.48939. lr 5.824629e-04:  22%|██▏       | 3572/16329 [30:05<1:44:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3572: train loss 2.47056. lr 5.824532e-04:  22%|██▏       | 3572/16329 [30:05<1:44:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3572: train loss 2.47056. lr 5.824532e-04:  22%|██▏       | 3573/16329 [30:05<1:45:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3573: train loss 2.49857. lr 5.824434e-04:  22%|██▏       | 3573/16329 [30:06<1:45:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3573: train loss 2.49857. lr 5.824434e-04:  22%|██▏       | 3574/16329 [30:06<1:45:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3574: train loss 2.46669. lr 5.824337e-04:  22%|██▏       | 3574/16329 [30:06<1:45:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3574: train loss 2.46669. lr 5.824337e-04:  22%|██▏       | 3575/16329 [30:06<1:44:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3575: train loss 2.49469. lr 5.824240e-04:  22%|██▏       | 3575/16329 [30:07<1:44:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3575: train loss 2.49469. lr 5.824240e-04:  22%|██▏       | 3576/16329 [30:07<1:44:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3576: train loss 2.47955. lr 5.824142e-04:  22%|██▏       | 3576/16329 [30:07<1:44:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3576: train loss 2.47955. lr 5.824142e-04:  22%|██▏       | 3577/16329 [30:07<1:44:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3577: train loss 2.45689. lr 5.824045e-04:  22%|██▏       | 3577/16329 [30:08<1:44:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3577: train loss 2.45689. lr 5.824045e-04:  22%|██▏       | 3578/16329 [30:08<1:44:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3578: train loss 2.49541. lr 5.823948e-04:  22%|██▏       | 3578/16329 [30:08<1:44:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3578: train loss 2.49541. lr 5.823948e-04:  22%|██▏       | 3579/16329 [30:08<1:45:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3579: train loss 2.42431. lr 5.823850e-04:  22%|██▏       | 3579/16329 [30:09<1:45:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3579: train loss 2.42431. lr 5.823850e-04:  22%|██▏       | 3580/16329 [30:09<1:45:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3580: train loss 2.47900. lr 5.823753e-04:  22%|██▏       | 3580/16329 [30:09<1:45:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3580: train loss 2.47900. lr 5.823753e-04:  22%|██▏       | 3581/16329 [30:09<1:45:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3581: train loss 2.45490. lr 5.823655e-04:  22%|██▏       | 3581/16329 [30:10<1:45:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3581: train loss 2.45490. lr 5.823655e-04:  22%|██▏       | 3582/16329 [30:10<1:45:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3582: train loss 2.44401. lr 5.823558e-04:  22%|██▏       | 3582/16329 [30:10<1:45:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3582: train loss 2.44401. lr 5.823558e-04:  22%|██▏       | 3583/16329 [30:10<1:44:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3583: train loss 2.43287. lr 5.823460e-04:  22%|██▏       | 3583/16329 [30:11<1:44:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3583: train loss 2.43287. lr 5.823460e-04:  22%|██▏       | 3584/16329 [30:11<1:44:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3584: train loss 2.43997. lr 5.823363e-04:  22%|██▏       | 3584/16329 [30:11<1:44:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3584: train loss 2.43997. lr 5.823363e-04:  22%|██▏       | 3585/16329 [30:11<1:44:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3585: train loss 2.51470. lr 5.823265e-04:  22%|██▏       | 3585/16329 [30:12<1:44:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3585: train loss 2.51470. lr 5.823265e-04:  22%|██▏       | 3586/16329 [30:12<1:44:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3586: train loss 2.41940. lr 5.823167e-04:  22%|██▏       | 3586/16329 [30:12<1:44:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3586: train loss 2.41940. lr 5.823167e-04:  22%|██▏       | 3587/16329 [30:12<1:44:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3587: train loss 2.48961. lr 5.823070e-04:  22%|██▏       | 3587/16329 [30:13<1:44:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3587: train loss 2.48961. lr 5.823070e-04:  22%|██▏       | 3588/16329 [30:13<1:44:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3588: train loss 2.45834. lr 5.822972e-04:  22%|██▏       | 3588/16329 [30:13<1:44:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3588: train loss 2.45834. lr 5.822972e-04:  22%|██▏       | 3589/16329 [30:13<1:44:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3589: train loss 2.50452. lr 5.822874e-04:  22%|██▏       | 3589/16329 [30:14<1:44:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3589: train loss 2.50452. lr 5.822874e-04:  22%|██▏       | 3590/16329 [30:14<1:45:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3590: train loss 2.43483. lr 5.822777e-04:  22%|██▏       | 3590/16329 [30:14<1:45:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3590: train loss 2.43483. lr 5.822777e-04:  22%|██▏       | 3591/16329 [30:14<1:57:06,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 3591: train loss 2.48631. lr 5.822679e-04:  22%|██▏       | 3591/16329 [30:15<1:57:06,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 3591: train loss 2.48631. lr 5.822679e-04:  22%|██▏       | 3592/16329 [30:15<1:53:23,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3592: train loss 2.38854. lr 5.822581e-04:  22%|██▏       | 3592/16329 [30:15<1:53:23,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3592: train loss 2.38854. lr 5.822581e-04:  22%|██▏       | 3593/16329 [30:15<1:50:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3593: train loss 2.45095. lr 5.822483e-04:  22%|██▏       | 3593/16329 [30:16<1:50:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3593: train loss 2.45095. lr 5.822483e-04:  22%|██▏       | 3594/16329 [30:16<1:51:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3594: train loss 2.45598. lr 5.822386e-04:  22%|██▏       | 3594/16329 [30:16<1:51:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3594: train loss 2.45598. lr 5.822386e-04:  22%|██▏       | 3595/16329 [30:16<1:51:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3595: train loss 2.48982. lr 5.822288e-04:  22%|██▏       | 3595/16329 [30:17<1:51:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3595: train loss 2.48982. lr 5.822288e-04:  22%|██▏       | 3596/16329 [30:17<1:51:39,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3596: train loss 2.54225. lr 5.822190e-04:  22%|██▏       | 3596/16329 [30:17<1:51:39,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3596: train loss 2.54225. lr 5.822190e-04:  22%|██▏       | 3597/16329 [30:17<1:50:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3597: train loss 2.41400. lr 5.822092e-04:  22%|██▏       | 3597/16329 [30:18<1:50:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3597: train loss 2.41400. lr 5.822092e-04:  22%|██▏       | 3598/16329 [30:18<1:48:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3598: train loss 2.45252. lr 5.821994e-04:  22%|██▏       | 3598/16329 [30:18<1:48:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3598: train loss 2.45252. lr 5.821994e-04:  22%|██▏       | 3599/16329 [30:18<1:47:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3599: train loss 2.49087. lr 5.821896e-04:  22%|██▏       | 3599/16329 [30:19<1:47:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3599: train loss 2.49087. lr 5.821896e-04:  22%|██▏       | 3600/16329 [30:19<1:46:48,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3600: train loss 2.44780. lr 5.821798e-04:  22%|██▏       | 3600/16329 [30:19<1:46:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3600: train loss 2.44780. lr 5.821798e-04:  22%|██▏       | 3601/16329 [30:19<1:46:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3601: train loss 2.44996. lr 5.821700e-04:  22%|██▏       | 3601/16329 [30:20<1:46:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3601: train loss 2.44996. lr 5.821700e-04:  22%|██▏       | 3602/16329 [30:20<1:45:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3602: train loss 2.49615. lr 5.821602e-04:  22%|██▏       | 3602/16329 [30:20<1:45:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3602: train loss 2.49615. lr 5.821602e-04:  22%|██▏       | 3603/16329 [30:20<1:45:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3603: train loss 2.48420. lr 5.821504e-04:  22%|██▏       | 3603/16329 [30:21<1:45:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3603: train loss 2.48420. lr 5.821504e-04:  22%|██▏       | 3604/16329 [30:21<1:45:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3604: train loss 2.47366. lr 5.821406e-04:  22%|██▏       | 3604/16329 [30:21<1:45:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3604: train loss 2.47366. lr 5.821406e-04:  22%|██▏       | 3605/16329 [30:21<1:45:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3605: train loss 2.46677. lr 5.821308e-04:  22%|██▏       | 3605/16329 [30:22<1:45:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3605: train loss 2.46677. lr 5.821308e-04:  22%|██▏       | 3606/16329 [30:22<1:44:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3606: train loss 2.46211. lr 5.821210e-04:  22%|██▏       | 3606/16329 [30:22<1:44:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3606: train loss 2.46211. lr 5.821210e-04:  22%|██▏       | 3607/16329 [30:22<1:44:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3607: train loss 2.39849. lr 5.821112e-04:  22%|██▏       | 3607/16329 [30:23<1:44:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3607: train loss 2.39849. lr 5.821112e-04:  22%|██▏       | 3608/16329 [30:23<1:44:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3608: train loss 2.44214. lr 5.821013e-04:  22%|██▏       | 3608/16329 [30:23<1:44:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3608: train loss 2.44214. lr 5.821013e-04:  22%|██▏       | 3609/16329 [30:23<1:44:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3609: train loss 2.44292. lr 5.820915e-04:  22%|██▏       | 3609/16329 [30:24<1:44:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3609: train loss 2.44292. lr 5.820915e-04:  22%|██▏       | 3610/16329 [30:24<1:44:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3610: train loss 2.45396. lr 5.820817e-04:  22%|██▏       | 3610/16329 [30:24<1:44:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3610: train loss 2.45396. lr 5.820817e-04:  22%|██▏       | 3611/16329 [30:24<1:44:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3611: train loss 2.44557. lr 5.820719e-04:  22%|██▏       | 3611/16329 [30:25<1:44:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3611: train loss 2.44557. lr 5.820719e-04:  22%|██▏       | 3612/16329 [30:25<1:44:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3612: train loss 2.43234. lr 5.820620e-04:  22%|██▏       | 3612/16329 [30:25<1:44:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3612: train loss 2.43234. lr 5.820620e-04:  22%|██▏       | 3613/16329 [30:25<1:44:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3613: train loss 2.47443. lr 5.820522e-04:  22%|██▏       | 3613/16329 [30:26<1:44:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3613: train loss 2.47443. lr 5.820522e-04:  22%|██▏       | 3614/16329 [30:26<1:44:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3614: train loss 2.45808. lr 5.820424e-04:  22%|██▏       | 3614/16329 [30:26<1:44:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3614: train loss 2.45808. lr 5.820424e-04:  22%|██▏       | 3615/16329 [30:26<1:44:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3615: train loss 2.43455. lr 5.820325e-04:  22%|██▏       | 3615/16329 [30:27<1:44:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3615: train loss 2.43455. lr 5.820325e-04:  22%|██▏       | 3616/16329 [30:27<1:44:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3616: train loss 2.48355. lr 5.820227e-04:  22%|██▏       | 3616/16329 [30:27<1:44:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3616: train loss 2.48355. lr 5.820227e-04:  22%|██▏       | 3617/16329 [30:27<1:45:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3617: train loss 2.46977. lr 5.820129e-04:  22%|██▏       | 3617/16329 [30:28<1:45:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3617: train loss 2.46977. lr 5.820129e-04:  22%|██▏       | 3618/16329 [30:28<1:45:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3618: train loss 2.47775. lr 5.820030e-04:  22%|██▏       | 3618/16329 [30:28<1:45:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3618: train loss 2.47775. lr 5.820030e-04:  22%|██▏       | 3619/16329 [30:28<1:50:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3619: train loss 2.44339. lr 5.819932e-04:  22%|██▏       | 3619/16329 [30:29<1:50:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3619: train loss 2.44339. lr 5.819932e-04:  22%|██▏       | 3620/16329 [30:29<1:52:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3620: train loss 2.40492. lr 5.819833e-04:  22%|██▏       | 3620/16329 [30:29<1:52:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3620: train loss 2.40492. lr 5.819833e-04:  22%|██▏       | 3621/16329 [30:29<1:53:42,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3621: train loss 2.39644. lr 5.819735e-04:  22%|██▏       | 3621/16329 [30:30<1:53:42,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3621: train loss 2.39644. lr 5.819735e-04:  22%|██▏       | 3622/16329 [30:30<1:53:21,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3622: train loss 2.47274. lr 5.819636e-04:  22%|██▏       | 3622/16329 [30:30<1:53:21,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3622: train loss 2.47274. lr 5.819636e-04:  22%|██▏       | 3623/16329 [30:30<1:52:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3623: train loss 2.42518. lr 5.819538e-04:  22%|██▏       | 3623/16329 [30:31<1:52:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3623: train loss 2.42518. lr 5.819538e-04:  22%|██▏       | 3624/16329 [30:31<1:49:48,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3624: train loss 2.42564. lr 5.819439e-04:  22%|██▏       | 3624/16329 [30:31<1:49:48,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3624: train loss 2.42564. lr 5.819439e-04:  22%|██▏       | 3625/16329 [30:31<1:48:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3625: train loss 2.50085. lr 5.819340e-04:  22%|██▏       | 3625/16329 [30:32<1:48:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3625: train loss 2.50085. lr 5.819340e-04:  22%|██▏       | 3626/16329 [30:32<1:58:03,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3626: train loss 2.43033. lr 5.819242e-04:  22%|██▏       | 3626/16329 [30:33<1:58:03,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3626: train loss 2.43033. lr 5.819242e-04:  22%|██▏       | 3627/16329 [30:33<1:53:57,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3627: train loss 2.43442. lr 5.819143e-04:  22%|██▏       | 3627/16329 [30:33<1:53:57,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3627: train loss 2.43442. lr 5.819143e-04:  22%|██▏       | 3628/16329 [30:33<1:51:22,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3628: train loss 2.48144. lr 5.819044e-04:  22%|██▏       | 3628/16329 [30:34<1:51:22,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3628: train loss 2.48144. lr 5.819044e-04:  22%|██▏       | 3629/16329 [30:34<1:49:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3629: train loss 2.38653. lr 5.818946e-04:  22%|██▏       | 3629/16329 [30:34<1:49:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3629: train loss 2.38653. lr 5.818946e-04:  22%|██▏       | 3630/16329 [30:34<1:47:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3630: train loss 2.47668. lr 5.818847e-04:  22%|██▏       | 3630/16329 [30:35<1:47:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3630: train loss 2.47668. lr 5.818847e-04:  22%|██▏       | 3631/16329 [30:35<1:46:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3631: train loss 2.45704. lr 5.818748e-04:  22%|██▏       | 3631/16329 [30:35<1:46:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3631: train loss 2.45704. lr 5.818748e-04:  22%|██▏       | 3632/16329 [30:35<1:45:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3632: train loss 2.38973. lr 5.818649e-04:  22%|██▏       | 3632/16329 [30:36<1:45:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3632: train loss 2.38973. lr 5.818649e-04:  22%|██▏       | 3633/16329 [30:36<1:45:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3633: train loss 2.49087. lr 5.818550e-04:  22%|██▏       | 3633/16329 [30:36<1:45:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3633: train loss 2.49087. lr 5.818550e-04:  22%|██▏       | 3634/16329 [30:36<1:45:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3634: train loss 2.48340. lr 5.818452e-04:  22%|██▏       | 3634/16329 [30:37<1:45:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3634: train loss 2.48340. lr 5.818452e-04:  22%|██▏       | 3635/16329 [30:37<1:45:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3635: train loss 2.48491. lr 5.818353e-04:  22%|██▏       | 3635/16329 [30:37<1:45:02,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3635: train loss 2.48491. lr 5.818353e-04:  22%|██▏       | 3636/16329 [30:37<1:44:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3636: train loss 2.47374. lr 5.818254e-04:  22%|██▏       | 3636/16329 [30:38<1:44:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3636: train loss 2.47374. lr 5.818254e-04:  22%|██▏       | 3637/16329 [30:38<1:44:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3637: train loss 2.51830. lr 5.818155e-04:  22%|██▏       | 3637/16329 [30:38<1:44:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3637: train loss 2.51830. lr 5.818155e-04:  22%|██▏       | 3638/16329 [30:38<1:44:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3638: train loss 2.43050. lr 5.818056e-04:  22%|██▏       | 3638/16329 [30:39<1:44:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3638: train loss 2.43050. lr 5.818056e-04:  22%|██▏       | 3639/16329 [30:39<1:44:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3639: train loss 2.46541. lr 5.817957e-04:  22%|██▏       | 3639/16329 [30:39<1:44:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3639: train loss 2.46541. lr 5.817957e-04:  22%|██▏       | 3640/16329 [30:39<1:44:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3640: train loss 2.43038. lr 5.817858e-04:  22%|██▏       | 3640/16329 [30:39<1:44:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3640: train loss 2.43038. lr 5.817858e-04:  22%|██▏       | 3641/16329 [30:39<1:44:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3641: train loss 2.44283. lr 5.817759e-04:  22%|██▏       | 3641/16329 [30:40<1:44:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3641: train loss 2.44283. lr 5.817759e-04:  22%|██▏       | 3642/16329 [30:40<1:44:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3642: train loss 2.47636. lr 5.817660e-04:  22%|██▏       | 3642/16329 [30:40<1:44:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3642: train loss 2.47636. lr 5.817660e-04:  22%|██▏       | 3643/16329 [30:40<1:44:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3643: train loss 2.41582. lr 5.817561e-04:  22%|██▏       | 3643/16329 [30:41<1:44:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3643: train loss 2.41582. lr 5.817561e-04:  22%|██▏       | 3644/16329 [30:41<1:44:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3644: train loss 2.45729. lr 5.817462e-04:  22%|██▏       | 3644/16329 [30:41<1:44:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3644: train loss 2.45729. lr 5.817462e-04:  22%|██▏       | 3645/16329 [30:41<1:44:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3645: train loss 2.45253. lr 5.817362e-04:  22%|██▏       | 3645/16329 [30:42<1:44:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3645: train loss 2.45253. lr 5.817362e-04:  22%|██▏       | 3646/16329 [30:42<1:44:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3646: train loss 2.44004. lr 5.817263e-04:  22%|██▏       | 3646/16329 [30:42<1:44:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3646: train loss 2.44004. lr 5.817263e-04:  22%|██▏       | 3647/16329 [30:42<1:43:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3647: train loss 2.50572. lr 5.817164e-04:  22%|██▏       | 3647/16329 [30:43<1:43:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3647: train loss 2.50572. lr 5.817164e-04:  22%|██▏       | 3648/16329 [30:43<1:44:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3648: train loss 2.43575. lr 5.817065e-04:  22%|██▏       | 3648/16329 [30:43<1:44:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3648: train loss 2.43575. lr 5.817065e-04:  22%|██▏       | 3649/16329 [30:43<1:44:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3649: train loss 2.46501. lr 5.816966e-04:  22%|██▏       | 3649/16329 [30:44<1:44:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3649: train loss 2.46501. lr 5.816966e-04:  22%|██▏       | 3650/16329 [30:44<1:44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3650: train loss 2.48762. lr 5.816866e-04:  22%|██▏       | 3650/16329 [30:45<1:44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3650: train loss 2.48762. lr 5.816866e-04:  22%|██▏       | 3651/16329 [30:45<1:55:28,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3651: train loss 2.40742. lr 5.816767e-04:  22%|██▏       | 3651/16329 [30:45<1:55:28,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3651: train loss 2.40742. lr 5.816767e-04:  22%|██▏       | 3652/16329 [30:45<1:51:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3652: train loss 2.46133. lr 5.816668e-04:  22%|██▏       | 3652/16329 [30:46<1:51:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3652: train loss 2.46133. lr 5.816668e-04:  22%|██▏       | 3653/16329 [30:46<1:49:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3653: train loss 2.48421. lr 5.816568e-04:  22%|██▏       | 3653/16329 [30:46<1:49:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3653: train loss 2.48421. lr 5.816568e-04:  22%|██▏       | 3654/16329 [30:46<1:48:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3654: train loss 2.40976. lr 5.816469e-04:  22%|██▏       | 3654/16329 [30:47<1:48:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3654: train loss 2.40976. lr 5.816469e-04:  22%|██▏       | 3655/16329 [30:47<1:47:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3655: train loss 2.47797. lr 5.816369e-04:  22%|██▏       | 3655/16329 [30:47<1:47:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3655: train loss 2.47797. lr 5.816369e-04:  22%|██▏       | 3656/16329 [30:47<1:46:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3656: train loss 2.44459. lr 5.816270e-04:  22%|██▏       | 3656/16329 [30:48<1:46:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3656: train loss 2.44459. lr 5.816270e-04:  22%|██▏       | 3657/16329 [30:48<1:45:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3657: train loss 2.38518. lr 5.816171e-04:  22%|██▏       | 3657/16329 [30:48<1:45:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3657: train loss 2.38518. lr 5.816171e-04:  22%|██▏       | 3658/16329 [30:48<1:47:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3658: train loss 2.44231. lr 5.816071e-04:  22%|██▏       | 3658/16329 [30:49<1:47:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3658: train loss 2.44231. lr 5.816071e-04:  22%|██▏       | 3659/16329 [30:49<1:48:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3659: train loss 2.43452. lr 5.815972e-04:  22%|██▏       | 3659/16329 [30:49<1:48:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3659: train loss 2.43452. lr 5.815972e-04:  22%|██▏       | 3660/16329 [30:49<1:48:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3660: train loss 2.46475. lr 5.815872e-04:  22%|██▏       | 3660/16329 [30:50<1:48:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3660: train loss 2.46475. lr 5.815872e-04:  22%|██▏       | 3661/16329 [30:50<1:47:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3661: train loss 2.45131. lr 5.815772e-04:  22%|██▏       | 3661/16329 [30:50<1:47:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3661: train loss 2.45131. lr 5.815772e-04:  22%|██▏       | 3662/16329 [30:50<1:47:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3662: train loss 2.43257. lr 5.815673e-04:  22%|██▏       | 3662/16329 [30:51<1:47:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3662: train loss 2.43257. lr 5.815673e-04:  22%|██▏       | 3663/16329 [30:51<1:46:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3663: train loss 2.44202. lr 5.815573e-04:  22%|██▏       | 3663/16329 [30:51<1:46:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3663: train loss 2.44202. lr 5.815573e-04:  22%|██▏       | 3664/16329 [30:51<1:46:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3664: train loss 2.46653. lr 5.815474e-04:  22%|██▏       | 3664/16329 [30:52<1:46:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3664: train loss 2.46653. lr 5.815474e-04:  22%|██▏       | 3665/16329 [30:52<1:45:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3665: train loss 2.44547. lr 5.815374e-04:  22%|██▏       | 3665/16329 [30:52<1:45:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3665: train loss 2.44547. lr 5.815374e-04:  22%|██▏       | 3666/16329 [30:52<1:45:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3666: train loss 2.44872. lr 5.815274e-04:  22%|██▏       | 3666/16329 [30:53<1:45:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3666: train loss 2.44872. lr 5.815274e-04:  22%|██▏       | 3667/16329 [30:53<1:44:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3667: train loss 2.46798. lr 5.815175e-04:  22%|██▏       | 3667/16329 [30:53<1:44:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3667: train loss 2.46798. lr 5.815175e-04:  22%|██▏       | 3668/16329 [30:53<1:44:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3668: train loss 2.44620. lr 5.815075e-04:  22%|██▏       | 3668/16329 [30:54<1:44:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3668: train loss 2.44620. lr 5.815075e-04:  22%|██▏       | 3669/16329 [30:54<1:44:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3669: train loss 2.44439. lr 5.814975e-04:  22%|██▏       | 3669/16329 [30:54<1:44:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3669: train loss 2.44439. lr 5.814975e-04:  22%|██▏       | 3670/16329 [30:54<1:44:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3670: train loss 2.44860. lr 5.814875e-04:  22%|██▏       | 3670/16329 [30:55<1:44:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3670: train loss 2.44860. lr 5.814875e-04:  22%|██▏       | 3671/16329 [30:55<1:44:18,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3671: train loss 2.39909. lr 5.814775e-04:  22%|██▏       | 3671/16329 [30:55<1:44:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3671: train loss 2.39909. lr 5.814775e-04:  22%|██▏       | 3672/16329 [30:55<1:44:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3672: train loss 2.44203. lr 5.814676e-04:  22%|██▏       | 3672/16329 [30:56<1:44:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3672: train loss 2.44203. lr 5.814676e-04:  22%|██▏       | 3673/16329 [30:56<1:43:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3673: train loss 2.48215. lr 5.814576e-04:  22%|██▏       | 3673/16329 [30:56<1:43:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3673: train loss 2.48215. lr 5.814576e-04:  22%|██▏       | 3674/16329 [30:56<1:43:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3674: train loss 2.41903. lr 5.814476e-04:  22%|██▏       | 3674/16329 [30:57<1:43:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3674: train loss 2.41903. lr 5.814476e-04:  23%|██▎       | 3675/16329 [30:57<1:43:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3675: train loss 2.42177. lr 5.814376e-04:  23%|██▎       | 3675/16329 [30:57<1:43:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3675: train loss 2.42177. lr 5.814376e-04:  23%|██▎       | 3676/16329 [30:57<1:43:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3676: train loss 2.46428. lr 5.814276e-04:  23%|██▎       | 3676/16329 [30:58<1:43:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3676: train loss 2.46428. lr 5.814276e-04:  23%|██▎       | 3677/16329 [30:58<1:44:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3677: train loss 2.46876. lr 5.814176e-04:  23%|██▎       | 3677/16329 [30:58<1:44:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3677: train loss 2.46876. lr 5.814176e-04:  23%|██▎       | 3678/16329 [30:58<1:56:08,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3678: train loss 2.46303. lr 5.814076e-04:  23%|██▎       | 3678/16329 [30:59<1:56:08,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3678: train loss 2.46303. lr 5.814076e-04:  23%|██▎       | 3679/16329 [30:59<1:57:00,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 3679: train loss 2.43385. lr 5.813976e-04:  23%|██▎       | 3679/16329 [30:59<1:57:00,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 3679: train loss 2.43385. lr 5.813976e-04:  23%|██▎       | 3680/16329 [30:59<1:55:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3680: train loss 2.37778. lr 5.813876e-04:  23%|██▎       | 3680/16329 [31:00<1:55:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3680: train loss 2.37778. lr 5.813876e-04:  23%|██▎       | 3681/16329 [31:00<1:54:00,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3681: train loss 2.40393. lr 5.813776e-04:  23%|██▎       | 3681/16329 [31:00<1:54:00,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 3681: train loss 2.40393. lr 5.813776e-04:  23%|██▎       | 3682/16329 [31:00<1:52:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3682: train loss 2.45566. lr 5.813676e-04:  23%|██▎       | 3682/16329 [31:01<1:52:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3682: train loss 2.45566. lr 5.813676e-04:  23%|██▎       | 3683/16329 [31:01<1:51:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3683: train loss 2.42648. lr 5.813575e-04:  23%|██▎       | 3683/16329 [31:01<1:51:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3683: train loss 2.42648. lr 5.813575e-04:  23%|██▎       | 3684/16329 [31:01<1:50:19,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3684: train loss 2.39773. lr 5.813475e-04:  23%|██▎       | 3684/16329 [31:02<1:50:19,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3684: train loss 2.39773. lr 5.813475e-04:  23%|██▎       | 3685/16329 [31:02<1:48:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3685: train loss 2.45676. lr 5.813375e-04:  23%|██▎       | 3685/16329 [31:02<1:48:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3685: train loss 2.45676. lr 5.813375e-04:  23%|██▎       | 3686/16329 [31:02<1:47:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3686: train loss 2.43532. lr 5.813275e-04:  23%|██▎       | 3686/16329 [31:03<1:47:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3686: train loss 2.43532. lr 5.813275e-04:  23%|██▎       | 3687/16329 [31:03<1:46:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3687: train loss 2.41109. lr 5.813175e-04:  23%|██▎       | 3687/16329 [31:03<1:46:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3687: train loss 2.41109. lr 5.813175e-04:  23%|██▎       | 3688/16329 [31:03<1:45:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3688: train loss 2.44702. lr 5.813074e-04:  23%|██▎       | 3688/16329 [31:04<1:45:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3688: train loss 2.44702. lr 5.813074e-04:  23%|██▎       | 3689/16329 [31:04<1:45:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3689: train loss 2.43991. lr 5.812974e-04:  23%|██▎       | 3689/16329 [31:04<1:45:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3689: train loss 2.43991. lr 5.812974e-04:  23%|██▎       | 3690/16329 [31:04<1:44:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3690: train loss 2.38097. lr 5.812874e-04:  23%|██▎       | 3690/16329 [31:05<1:44:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3690: train loss 2.38097. lr 5.812874e-04:  23%|██▎       | 3691/16329 [31:05<1:44:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3691: train loss 2.42472. lr 5.812773e-04:  23%|██▎       | 3691/16329 [31:05<1:44:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3691: train loss 2.42472. lr 5.812773e-04:  23%|██▎       | 3692/16329 [31:05<1:44:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3692: train loss 2.37129. lr 5.812673e-04:  23%|██▎       | 3692/16329 [31:06<1:44:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3692: train loss 2.37129. lr 5.812673e-04:  23%|██▎       | 3693/16329 [31:06<1:44:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3693: train loss 2.43396. lr 5.812573e-04:  23%|██▎       | 3693/16329 [31:06<1:44:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3693: train loss 2.43396. lr 5.812573e-04:  23%|██▎       | 3694/16329 [31:06<1:44:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3694: train loss 2.49597. lr 5.812472e-04:  23%|██▎       | 3694/16329 [31:07<1:44:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3694: train loss 2.49597. lr 5.812472e-04:  23%|██▎       | 3695/16329 [31:07<1:43:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3695: train loss 2.48674. lr 5.812372e-04:  23%|██▎       | 3695/16329 [31:07<1:43:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3695: train loss 2.48674. lr 5.812372e-04:  23%|██▎       | 3696/16329 [31:07<1:43:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3696: train loss 2.48750. lr 5.812271e-04:  23%|██▎       | 3696/16329 [31:08<1:43:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3696: train loss 2.48750. lr 5.812271e-04:  23%|██▎       | 3697/16329 [31:08<1:44:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3697: train loss 2.42157. lr 5.812171e-04:  23%|██▎       | 3697/16329 [31:08<1:44:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3697: train loss 2.42157. lr 5.812171e-04:  23%|██▎       | 3698/16329 [31:08<1:44:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3698: train loss 2.47317. lr 5.812070e-04:  23%|██▎       | 3698/16329 [31:09<1:44:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3698: train loss 2.47317. lr 5.812070e-04:  23%|██▎       | 3699/16329 [31:09<1:44:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3699: train loss 2.43510. lr 5.811970e-04:  23%|██▎       | 3699/16329 [31:09<1:44:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3699: train loss 2.43510. lr 5.811970e-04:  23%|██▎       | 3700/16329 [31:09<1:44:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3700: train loss 2.42540. lr 5.811869e-04:  23%|██▎       | 3700/16329 [31:10<1:44:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3700: train loss 2.42540. lr 5.811869e-04:  23%|██▎       | 3701/16329 [31:10<1:43:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3701: train loss 2.44799. lr 5.811769e-04:  23%|██▎       | 3701/16329 [31:10<1:43:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3701: train loss 2.44799. lr 5.811769e-04:  23%|██▎       | 3702/16329 [31:10<1:43:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3702: train loss 2.38512. lr 5.811668e-04:  23%|██▎       | 3702/16329 [31:11<1:43:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3702: train loss 2.38512. lr 5.811668e-04:  23%|██▎       | 3703/16329 [31:11<1:43:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3703: train loss 2.38172. lr 5.811567e-04:  23%|██▎       | 3703/16329 [31:11<1:43:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3703: train loss 2.38172. lr 5.811567e-04:  23%|██▎       | 3704/16329 [31:11<1:43:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3704: train loss 2.39429. lr 5.811467e-04:  23%|██▎       | 3704/16329 [31:12<1:43:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3704: train loss 2.39429. lr 5.811467e-04:  23%|██▎       | 3705/16329 [31:12<1:43:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3705: train loss 2.42019. lr 5.811366e-04:  23%|██▎       | 3705/16329 [31:12<1:43:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3705: train loss 2.42019. lr 5.811366e-04:  23%|██▎       | 3706/16329 [31:12<1:43:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3706: train loss 2.43248. lr 5.811265e-04:  23%|██▎       | 3706/16329 [31:13<1:43:48,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3706: train loss 2.43248. lr 5.811265e-04:  23%|██▎       | 3707/16329 [31:13<1:43:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3707: train loss 2.43329. lr 5.811164e-04:  23%|██▎       | 3707/16329 [31:13<1:43:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3707: train loss 2.43329. lr 5.811164e-04:  23%|██▎       | 3708/16329 [31:13<1:43:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3708: train loss 2.47264. lr 5.811064e-04:  23%|██▎       | 3708/16329 [31:14<1:43:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3708: train loss 2.47264. lr 5.811064e-04:  23%|██▎       | 3709/16329 [31:14<1:44:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3709: train loss 2.40749. lr 5.810963e-04:  23%|██▎       | 3709/16329 [31:14<1:44:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3709: train loss 2.40749. lr 5.810963e-04:  23%|██▎       | 3710/16329 [31:14<1:44:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3710: train loss 2.44197. lr 5.810862e-04:  23%|██▎       | 3710/16329 [31:15<1:44:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3710: train loss 2.44197. lr 5.810862e-04:  23%|██▎       | 3711/16329 [31:15<1:44:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3711: train loss 2.41508. lr 5.810761e-04:  23%|██▎       | 3711/16329 [31:15<1:44:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3711: train loss 2.41508. lr 5.810761e-04:  23%|██▎       | 3712/16329 [31:15<1:43:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3712: train loss 2.42113. lr 5.810660e-04:  23%|██▎       | 3712/16329 [31:16<1:43:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3712: train loss 2.42113. lr 5.810660e-04:  23%|██▎       | 3713/16329 [31:16<1:45:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3713: train loss 2.40790. lr 5.810559e-04:  23%|██▎       | 3713/16329 [31:16<1:45:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3713: train loss 2.40790. lr 5.810559e-04:  23%|██▎       | 3714/16329 [31:16<1:46:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3714: train loss 2.43864. lr 5.810458e-04:  23%|██▎       | 3714/16329 [31:17<1:46:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3714: train loss 2.43864. lr 5.810458e-04:  23%|██▎       | 3715/16329 [31:17<1:46:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3715: train loss 2.44038. lr 5.810357e-04:  23%|██▎       | 3715/16329 [31:17<1:46:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3715: train loss 2.44038. lr 5.810357e-04:  23%|██▎       | 3716/16329 [31:17<1:46:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3716: train loss 2.40315. lr 5.810256e-04:  23%|██▎       | 3716/16329 [31:18<1:46:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3716: train loss 2.40315. lr 5.810256e-04:  23%|██▎       | 3717/16329 [31:18<1:47:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3717: train loss 2.39079. lr 5.810155e-04:  23%|██▎       | 3717/16329 [31:19<1:47:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3717: train loss 2.39079. lr 5.810155e-04:  23%|██▎       | 3718/16329 [31:19<2:02:05,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 3718: train loss 2.36292. lr 5.810054e-04:  23%|██▎       | 3718/16329 [31:19<2:02:05,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 3718: train loss 2.36292. lr 5.810054e-04:  23%|██▎       | 3719/16329 [31:19<1:57:29,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3719: train loss 2.42258. lr 5.809953e-04:  23%|██▎       | 3719/16329 [31:20<1:57:29,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3719: train loss 2.42258. lr 5.809953e-04:  23%|██▎       | 3720/16329 [31:20<1:54:09,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3720: train loss 2.39129. lr 5.809852e-04:  23%|██▎       | 3720/16329 [31:20<1:54:09,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3720: train loss 2.39129. lr 5.809852e-04:  23%|██▎       | 3721/16329 [31:20<1:51:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3721: train loss 2.42294. lr 5.809751e-04:  23%|██▎       | 3721/16329 [31:21<1:51:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3721: train loss 2.42294. lr 5.809751e-04:  23%|██▎       | 3722/16329 [31:21<1:49:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3722: train loss 2.44593. lr 5.809650e-04:  23%|██▎       | 3722/16329 [31:21<1:49:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3722: train loss 2.44593. lr 5.809650e-04:  23%|██▎       | 3723/16329 [31:21<1:47:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3723: train loss 2.38442. lr 5.809549e-04:  23%|██▎       | 3723/16329 [31:22<1:47:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3723: train loss 2.38442. lr 5.809549e-04:  23%|██▎       | 3724/16329 [31:22<1:46:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3724: train loss 2.38323. lr 5.809447e-04:  23%|██▎       | 3724/16329 [31:22<1:46:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3724: train loss 2.38323. lr 5.809447e-04:  23%|██▎       | 3725/16329 [31:22<1:46:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3725: train loss 2.45559. lr 5.809346e-04:  23%|██▎       | 3725/16329 [31:23<1:46:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3725: train loss 2.45559. lr 5.809346e-04:  23%|██▎       | 3726/16329 [31:23<1:45:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3726: train loss 2.42224. lr 5.809245e-04:  23%|██▎       | 3726/16329 [31:23<1:45:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3726: train loss 2.42224. lr 5.809245e-04:  23%|██▎       | 3727/16329 [31:23<1:44:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3727: train loss 2.42729. lr 5.809144e-04:  23%|██▎       | 3727/16329 [31:24<1:44:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3727: train loss 2.42729. lr 5.809144e-04:  23%|██▎       | 3728/16329 [31:24<1:44:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3728: train loss 2.36714. lr 5.809042e-04:  23%|██▎       | 3728/16329 [31:24<1:44:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3728: train loss 2.36714. lr 5.809042e-04:  23%|██▎       | 3729/16329 [31:24<1:43:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3729: train loss 2.43045. lr 5.808941e-04:  23%|██▎       | 3729/16329 [31:25<1:43:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3729: train loss 2.43045. lr 5.808941e-04:  23%|██▎       | 3730/16329 [31:25<1:43:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3730: train loss 2.43603. lr 5.808840e-04:  23%|██▎       | 3730/16329 [31:25<1:43:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3730: train loss 2.43603. lr 5.808840e-04:  23%|██▎       | 3731/16329 [31:25<1:43:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3731: train loss 2.35865. lr 5.808738e-04:  23%|██▎       | 3731/16329 [31:25<1:43:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3731: train loss 2.35865. lr 5.808738e-04:  23%|██▎       | 3732/16329 [31:25<1:43:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3732: train loss 2.41481. lr 5.808637e-04:  23%|██▎       | 3732/16329 [31:26<1:43:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3732: train loss 2.41481. lr 5.808637e-04:  23%|██▎       | 3733/16329 [31:26<1:43:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3733: train loss 2.40494. lr 5.808535e-04:  23%|██▎       | 3733/16329 [31:26<1:43:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3733: train loss 2.40494. lr 5.808535e-04:  23%|██▎       | 3734/16329 [31:26<1:43:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3734: train loss 2.39519. lr 5.808434e-04:  23%|██▎       | 3734/16329 [31:27<1:43:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3734: train loss 2.39519. lr 5.808434e-04:  23%|██▎       | 3735/16329 [31:27<1:43:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3735: train loss 2.43876. lr 5.808332e-04:  23%|██▎       | 3735/16329 [31:27<1:43:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3735: train loss 2.43876. lr 5.808332e-04:  23%|██▎       | 3736/16329 [31:27<1:43:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3736: train loss 2.41311. lr 5.808231e-04:  23%|██▎       | 3736/16329 [31:28<1:43:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3736: train loss 2.41311. lr 5.808231e-04:  23%|██▎       | 3737/16329 [31:28<1:43:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3737: train loss 2.41997. lr 5.808129e-04:  23%|██▎       | 3737/16329 [31:28<1:43:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3737: train loss 2.41997. lr 5.808129e-04:  23%|██▎       | 3738/16329 [31:28<1:43:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3738: train loss 2.41583. lr 5.808028e-04:  23%|██▎       | 3738/16329 [31:29<1:43:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3738: train loss 2.41583. lr 5.808028e-04:  23%|██▎       | 3739/16329 [31:29<1:43:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3739: train loss 2.41413. lr 5.807926e-04:  23%|██▎       | 3739/16329 [31:29<1:43:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3739: train loss 2.41413. lr 5.807926e-04:  23%|██▎       | 3740/16329 [31:29<1:43:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3740: train loss 2.37423. lr 5.807825e-04:  23%|██▎       | 3740/16329 [31:30<1:43:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3740: train loss 2.37423. lr 5.807825e-04:  23%|██▎       | 3741/16329 [31:30<1:43:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3741: train loss 2.37978. lr 5.807723e-04:  23%|██▎       | 3741/16329 [31:30<1:43:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3741: train loss 2.37978. lr 5.807723e-04:  23%|██▎       | 3742/16329 [31:30<1:43:48,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3742: train loss 2.41378. lr 5.807621e-04:  23%|██▎       | 3742/16329 [31:31<1:43:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3742: train loss 2.41378. lr 5.807621e-04:  23%|██▎       | 3743/16329 [31:31<1:43:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3743: train loss 2.36722. lr 5.807520e-04:  23%|██▎       | 3743/16329 [31:31<1:43:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3743: train loss 2.36722. lr 5.807520e-04:  23%|██▎       | 3744/16329 [31:31<1:43:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3744: train loss 2.35915. lr 5.807418e-04:  23%|██▎       | 3744/16329 [31:32<1:43:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3744: train loss 2.35915. lr 5.807418e-04:  23%|██▎       | 3745/16329 [31:32<1:43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3745: train loss 2.35299. lr 5.807316e-04:  23%|██▎       | 3745/16329 [31:32<1:43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3745: train loss 2.35299. lr 5.807316e-04:  23%|██▎       | 3746/16329 [31:32<1:43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3746: train loss 2.45575. lr 5.807214e-04:  23%|██▎       | 3746/16329 [31:33<1:43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3746: train loss 2.45575. lr 5.807214e-04:  23%|██▎       | 3747/16329 [31:33<1:43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3747: train loss 2.44728. lr 5.807113e-04:  23%|██▎       | 3747/16329 [31:33<1:43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3747: train loss 2.44728. lr 5.807113e-04:  23%|██▎       | 3748/16329 [31:33<1:43:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3748: train loss 2.37314. lr 5.807011e-04:  23%|██▎       | 3748/16329 [31:34<1:43:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3748: train loss 2.37314. lr 5.807011e-04:  23%|██▎       | 3749/16329 [31:34<1:43:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3749: train loss 2.45619. lr 5.806909e-04:  23%|██▎       | 3749/16329 [31:34<1:43:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3749: train loss 2.45619. lr 5.806909e-04:  23%|██▎       | 3750/16329 [31:34<1:43:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3750: train loss 2.41689. lr 5.806807e-04:  23%|██▎       | 3750/16329 [31:35<1:43:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3750: train loss 2.41689. lr 5.806807e-04:  23%|██▎       | 3751/16329 [31:35<1:43:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3751: train loss 2.43589. lr 5.806705e-04:  23%|██▎       | 3751/16329 [31:35<1:43:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3751: train loss 2.43589. lr 5.806705e-04:  23%|██▎       | 3752/16329 [31:35<1:43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3752: train loss 2.37221. lr 5.806603e-04:  23%|██▎       | 3752/16329 [31:36<1:43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3752: train loss 2.37221. lr 5.806603e-04:  23%|██▎       | 3753/16329 [31:36<1:54:49,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3753: train loss 2.36279. lr 5.806501e-04:  23%|██▎       | 3753/16329 [31:37<1:54:49,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3753: train loss 2.36279. lr 5.806501e-04:  23%|██▎       | 3754/16329 [31:37<1:51:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3754: train loss 2.42650. lr 5.806399e-04:  23%|██▎       | 3754/16329 [31:37<1:51:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3754: train loss 2.42650. lr 5.806399e-04:  23%|██▎       | 3755/16329 [31:37<1:48:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3755: train loss 2.47413. lr 5.806297e-04:  23%|██▎       | 3755/16329 [31:38<1:48:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3755: train loss 2.47413. lr 5.806297e-04:  23%|██▎       | 3756/16329 [31:38<1:47:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3756: train loss 2.38342. lr 5.806195e-04:  23%|██▎       | 3756/16329 [31:38<1:47:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3756: train loss 2.38342. lr 5.806195e-04:  23%|██▎       | 3757/16329 [31:38<1:46:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3757: train loss 2.41801. lr 5.806093e-04:  23%|██▎       | 3757/16329 [31:38<1:46:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3757: train loss 2.41801. lr 5.806093e-04:  23%|██▎       | 3758/16329 [31:38<1:45:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3758: train loss 2.37830. lr 5.805991e-04:  23%|██▎       | 3758/16329 [31:39<1:45:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3758: train loss 2.37830. lr 5.805991e-04:  23%|██▎       | 3759/16329 [31:39<1:44:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3759: train loss 2.42137. lr 5.805889e-04:  23%|██▎       | 3759/16329 [31:39<1:44:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3759: train loss 2.42137. lr 5.805889e-04:  23%|██▎       | 3760/16329 [31:39<1:44:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3760: train loss 2.34412. lr 5.805787e-04:  23%|██▎       | 3760/16329 [31:40<1:44:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3760: train loss 2.34412. lr 5.805787e-04:  23%|██▎       | 3761/16329 [31:40<1:44:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3761: train loss 2.39869. lr 5.805685e-04:  23%|██▎       | 3761/16329 [31:40<1:44:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3761: train loss 2.39869. lr 5.805685e-04:  23%|██▎       | 3762/16329 [31:40<1:44:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3762: train loss 2.39956. lr 5.805582e-04:  23%|██▎       | 3762/16329 [31:41<1:44:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3762: train loss 2.39956. lr 5.805582e-04:  23%|██▎       | 3763/16329 [31:41<1:43:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3763: train loss 2.40469. lr 5.805480e-04:  23%|██▎       | 3763/16329 [31:41<1:43:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3763: train loss 2.40469. lr 5.805480e-04:  23%|██▎       | 3764/16329 [31:41<1:43:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3764: train loss 2.40641. lr 5.805378e-04:  23%|██▎       | 3764/16329 [31:42<1:43:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3764: train loss 2.40641. lr 5.805378e-04:  23%|██▎       | 3765/16329 [31:42<1:47:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3765: train loss 2.40668. lr 5.805276e-04:  23%|██▎       | 3765/16329 [31:43<1:47:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3765: train loss 2.40668. lr 5.805276e-04:  23%|██▎       | 3766/16329 [31:43<1:50:43,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3766: train loss 2.42294. lr 5.805173e-04:  23%|██▎       | 3766/16329 [31:43<1:50:43,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3766: train loss 2.42294. lr 5.805173e-04:  23%|██▎       | 3767/16329 [31:43<1:51:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3767: train loss 2.36613. lr 5.805071e-04:  23%|██▎       | 3767/16329 [31:44<1:51:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3767: train loss 2.36613. lr 5.805071e-04:  23%|██▎       | 3768/16329 [31:44<1:51:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3768: train loss 2.40822. lr 5.804969e-04:  23%|██▎       | 3768/16329 [31:44<1:51:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3768: train loss 2.40822. lr 5.804969e-04:  23%|██▎       | 3769/16329 [31:44<1:50:06,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3769: train loss 2.42503. lr 5.804866e-04:  23%|██▎       | 3769/16329 [31:45<1:50:06,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3769: train loss 2.42503. lr 5.804866e-04:  23%|██▎       | 3770/16329 [31:45<1:48:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3770: train loss 2.34162. lr 5.804764e-04:  23%|██▎       | 3770/16329 [31:45<1:48:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3770: train loss 2.34162. lr 5.804764e-04:  23%|██▎       | 3771/16329 [31:45<1:47:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3771: train loss 2.45926. lr 5.804662e-04:  23%|██▎       | 3771/16329 [31:46<1:47:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3771: train loss 2.45926. lr 5.804662e-04:  23%|██▎       | 3772/16329 [31:46<1:46:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3772: train loss 2.44108. lr 5.804559e-04:  23%|██▎       | 3772/16329 [31:46<1:46:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3772: train loss 2.44108. lr 5.804559e-04:  23%|██▎       | 3773/16329 [31:46<1:46:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3773: train loss 2.39935. lr 5.804457e-04:  23%|██▎       | 3773/16329 [31:47<1:46:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3773: train loss 2.39935. lr 5.804457e-04:  23%|██▎       | 3774/16329 [31:47<1:45:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3774: train loss 2.39633. lr 5.804354e-04:  23%|██▎       | 3774/16329 [31:47<1:45:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3774: train loss 2.39633. lr 5.804354e-04:  23%|██▎       | 3775/16329 [31:47<1:44:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3775: train loss 2.44851. lr 5.804252e-04:  23%|██▎       | 3775/16329 [31:48<1:44:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3775: train loss 2.44851. lr 5.804252e-04:  23%|██▎       | 3776/16329 [31:48<1:44:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3776: train loss 2.39239. lr 5.804149e-04:  23%|██▎       | 3776/16329 [31:48<1:44:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3776: train loss 2.39239. lr 5.804149e-04:  23%|██▎       | 3777/16329 [31:48<1:44:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3777: train loss 2.36445. lr 5.804046e-04:  23%|██▎       | 3777/16329 [31:49<1:44:12,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3777: train loss 2.36445. lr 5.804046e-04:  23%|██▎       | 3778/16329 [31:49<1:55:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3778: train loss 2.35168. lr 5.803944e-04:  23%|██▎       | 3778/16329 [31:49<1:55:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 3778: train loss 2.35168. lr 5.803944e-04:  23%|██▎       | 3779/16329 [31:49<1:51:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3779: train loss 2.40653. lr 5.803841e-04:  23%|██▎       | 3779/16329 [31:50<1:51:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3779: train loss 2.40653. lr 5.803841e-04:  23%|██▎       | 3780/16329 [31:50<1:48:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3780: train loss 2.42021. lr 5.803739e-04:  23%|██▎       | 3780/16329 [31:50<1:48:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3780: train loss 2.42021. lr 5.803739e-04:  23%|██▎       | 3781/16329 [31:50<1:47:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3781: train loss 2.46252. lr 5.803636e-04:  23%|██▎       | 3781/16329 [31:51<1:47:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3781: train loss 2.46252. lr 5.803636e-04:  23%|██▎       | 3782/16329 [31:51<1:45:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3782: train loss 2.38107. lr 5.803533e-04:  23%|██▎       | 3782/16329 [31:51<1:45:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3782: train loss 2.38107. lr 5.803533e-04:  23%|██▎       | 3783/16329 [31:51<1:44:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3783: train loss 2.42367. lr 5.803430e-04:  23%|██▎       | 3783/16329 [31:52<1:44:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3783: train loss 2.42367. lr 5.803430e-04:  23%|██▎       | 3784/16329 [31:52<1:44:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3784: train loss 2.42987. lr 5.803328e-04:  23%|██▎       | 3784/16329 [31:52<1:44:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3784: train loss 2.42987. lr 5.803328e-04:  23%|██▎       | 3785/16329 [31:52<1:43:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3785: train loss 2.39009. lr 5.803225e-04:  23%|██▎       | 3785/16329 [31:53<1:43:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3785: train loss 2.39009. lr 5.803225e-04:  23%|██▎       | 3786/16329 [31:53<1:43:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3786: train loss 2.38455. lr 5.803122e-04:  23%|██▎       | 3786/16329 [31:53<1:43:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3786: train loss 2.38455. lr 5.803122e-04:  23%|██▎       | 3787/16329 [31:53<1:43:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3787: train loss 2.35086. lr 5.803019e-04:  23%|██▎       | 3787/16329 [31:54<1:43:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3787: train loss 2.35086. lr 5.803019e-04:  23%|██▎       | 3788/16329 [31:54<1:43:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3788: train loss 2.35271. lr 5.802916e-04:  23%|██▎       | 3788/16329 [31:54<1:43:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3788: train loss 2.35271. lr 5.802916e-04:  23%|██▎       | 3789/16329 [31:54<1:43:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3789: train loss 2.40707. lr 5.802813e-04:  23%|██▎       | 3789/16329 [31:55<1:43:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3789: train loss 2.40707. lr 5.802813e-04:  23%|██▎       | 3790/16329 [31:55<1:43:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3790: train loss 2.36498. lr 5.802711e-04:  23%|██▎       | 3790/16329 [31:55<1:43:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3790: train loss 2.36498. lr 5.802711e-04:  23%|██▎       | 3791/16329 [31:55<1:43:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3791: train loss 2.38206. lr 5.802608e-04:  23%|██▎       | 3791/16329 [31:56<1:43:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3791: train loss 2.38206. lr 5.802608e-04:  23%|██▎       | 3792/16329 [31:56<1:42:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3792: train loss 2.34704. lr 5.802505e-04:  23%|██▎       | 3792/16329 [31:56<1:42:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3792: train loss 2.34704. lr 5.802505e-04:  23%|██▎       | 3793/16329 [31:56<1:43:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3793: train loss 2.34898. lr 5.802402e-04:  23%|██▎       | 3793/16329 [31:57<1:43:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3793: train loss 2.34898. lr 5.802402e-04:  23%|██▎       | 3794/16329 [31:57<1:43:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3794: train loss 2.42930. lr 5.802299e-04:  23%|██▎       | 3794/16329 [31:57<1:43:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3794: train loss 2.42930. lr 5.802299e-04:  23%|██▎       | 3795/16329 [31:57<1:42:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3795: train loss 2.40365. lr 5.802196e-04:  23%|██▎       | 3795/16329 [31:58<1:42:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3795: train loss 2.40365. lr 5.802196e-04:  23%|██▎       | 3796/16329 [31:58<1:43:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3796: train loss 2.36233. lr 5.802092e-04:  23%|██▎       | 3796/16329 [31:58<1:43:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3796: train loss 2.36233. lr 5.802092e-04:  23%|██▎       | 3797/16329 [31:58<1:42:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3797: train loss 2.41383. lr 5.801989e-04:  23%|██▎       | 3797/16329 [31:59<1:42:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3797: train loss 2.41383. lr 5.801989e-04:  23%|██▎       | 3798/16329 [31:59<1:43:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3798: train loss 2.34984. lr 5.801886e-04:  23%|██▎       | 3798/16329 [31:59<1:43:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3798: train loss 2.34984. lr 5.801886e-04:  23%|██▎       | 3799/16329 [31:59<1:43:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3799: train loss 2.41349. lr 5.801783e-04:  23%|██▎       | 3799/16329 [32:00<1:43:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3799: train loss 2.41349. lr 5.801783e-04:  23%|██▎       | 3800/16329 [32:00<1:42:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3800: train loss 2.35242. lr 5.801680e-04:  23%|██▎       | 3800/16329 [32:00<1:42:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3800: train loss 2.35242. lr 5.801680e-04:  23%|██▎       | 3801/16329 [32:00<1:43:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3801: train loss 2.37541. lr 5.801577e-04:  23%|██▎       | 3801/16329 [32:01<1:43:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3801: train loss 2.37541. lr 5.801577e-04:  23%|██▎       | 3802/16329 [32:01<1:42:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3802: train loss 2.35576. lr 5.801473e-04:  23%|██▎       | 3802/16329 [32:01<1:42:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3802: train loss 2.35576. lr 5.801473e-04:  23%|██▎       | 3803/16329 [32:01<1:43:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3803: train loss 2.37010. lr 5.801370e-04:  23%|██▎       | 3803/16329 [32:02<1:43:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3803: train loss 2.37010. lr 5.801370e-04:  23%|██▎       | 3804/16329 [32:02<1:43:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3804: train loss 2.36063. lr 5.801267e-04:  23%|██▎       | 3804/16329 [32:02<1:43:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3804: train loss 2.36063. lr 5.801267e-04:  23%|██▎       | 3805/16329 [32:02<1:53:43,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3805: train loss 2.35190. lr 5.801164e-04:  23%|██▎       | 3805/16329 [32:03<1:53:43,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3805: train loss 2.35190. lr 5.801164e-04:  23%|██▎       | 3806/16329 [32:03<1:50:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3806: train loss 2.33625. lr 5.801060e-04:  23%|██▎       | 3806/16329 [32:03<1:50:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3806: train loss 2.33625. lr 5.801060e-04:  23%|██▎       | 3807/16329 [32:03<1:48:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3807: train loss 2.40415. lr 5.800957e-04:  23%|██▎       | 3807/16329 [32:04<1:48:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3807: train loss 2.40415. lr 5.800957e-04:  23%|██▎       | 3808/16329 [32:04<1:47:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3808: train loss 2.38650. lr 5.800854e-04:  23%|██▎       | 3808/16329 [32:04<1:47:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3808: train loss 2.38650. lr 5.800854e-04:  23%|██▎       | 3809/16329 [32:04<1:45:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3809: train loss 2.43196. lr 5.800750e-04:  23%|██▎       | 3809/16329 [32:05<1:45:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3809: train loss 2.43196. lr 5.800750e-04:  23%|██▎       | 3810/16329 [32:05<1:45:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3810: train loss 2.41490. lr 5.800647e-04:  23%|██▎       | 3810/16329 [32:05<1:45:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3810: train loss 2.41490. lr 5.800647e-04:  23%|██▎       | 3811/16329 [32:05<1:45:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3811: train loss 2.39289. lr 5.800543e-04:  23%|██▎       | 3811/16329 [32:06<1:45:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3811: train loss 2.39289. lr 5.800543e-04:  23%|██▎       | 3812/16329 [32:06<1:44:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3812: train loss 2.33027. lr 5.800440e-04:  23%|██▎       | 3812/16329 [32:06<1:44:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3812: train loss 2.33027. lr 5.800440e-04:  23%|██▎       | 3813/16329 [32:06<1:44:33,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3813: train loss 2.39962. lr 5.800336e-04:  23%|██▎       | 3813/16329 [32:07<1:44:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3813: train loss 2.39962. lr 5.800336e-04:  23%|██▎       | 3814/16329 [32:07<1:44:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3814: train loss 2.39340. lr 5.800233e-04:  23%|██▎       | 3814/16329 [32:07<1:44:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3814: train loss 2.39340. lr 5.800233e-04:  23%|██▎       | 3815/16329 [32:07<1:44:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3815: train loss 2.39030. lr 5.800129e-04:  23%|██▎       | 3815/16329 [32:08<1:44:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3815: train loss 2.39030. lr 5.800129e-04:  23%|██▎       | 3816/16329 [32:08<1:44:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3816: train loss 2.36349. lr 5.800026e-04:  23%|██▎       | 3816/16329 [32:08<1:44:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3816: train loss 2.36349. lr 5.800026e-04:  23%|██▎       | 3817/16329 [32:08<1:43:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3817: train loss 2.35258. lr 5.799922e-04:  23%|██▎       | 3817/16329 [32:09<1:43:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3817: train loss 2.35258. lr 5.799922e-04:  23%|██▎       | 3818/16329 [32:09<1:44:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3818: train loss 2.32473. lr 5.799818e-04:  23%|██▎       | 3818/16329 [32:09<1:44:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3818: train loss 2.32473. lr 5.799818e-04:  23%|██▎       | 3819/16329 [32:09<1:43:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3819: train loss 2.34660. lr 5.799715e-04:  23%|██▎       | 3819/16329 [32:10<1:43:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3819: train loss 2.34660. lr 5.799715e-04:  23%|██▎       | 3820/16329 [32:10<1:44:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3820: train loss 2.36527. lr 5.799611e-04:  23%|██▎       | 3820/16329 [32:10<1:44:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3820: train loss 2.36527. lr 5.799611e-04:  23%|██▎       | 3821/16329 [32:10<1:43:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3821: train loss 2.38354. lr 5.799507e-04:  23%|██▎       | 3821/16329 [32:11<1:43:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3821: train loss 2.38354. lr 5.799507e-04:  23%|██▎       | 3822/16329 [32:11<1:44:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3822: train loss 2.38305. lr 5.799403e-04:  23%|██▎       | 3822/16329 [32:11<1:44:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3822: train loss 2.38305. lr 5.799403e-04:  23%|██▎       | 3823/16329 [32:11<1:44:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3823: train loss 2.38708. lr 5.799300e-04:  23%|██▎       | 3823/16329 [32:12<1:44:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3823: train loss 2.38708. lr 5.799300e-04:  23%|██▎       | 3824/16329 [32:12<1:43:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3824: train loss 2.28438. lr 5.799196e-04:  23%|██▎       | 3824/16329 [32:12<1:43:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3824: train loss 2.28438. lr 5.799196e-04:  23%|██▎       | 3825/16329 [32:12<1:43:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3825: train loss 2.33162. lr 5.799092e-04:  23%|██▎       | 3825/16329 [32:13<1:43:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3825: train loss 2.33162. lr 5.799092e-04:  23%|██▎       | 3826/16329 [32:13<1:43:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3826: train loss 2.36933. lr 5.798988e-04:  23%|██▎       | 3826/16329 [32:13<1:43:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3826: train loss 2.36933. lr 5.798988e-04:  23%|██▎       | 3827/16329 [32:13<1:47:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3827: train loss 2.35518. lr 5.798884e-04:  23%|██▎       | 3827/16329 [32:14<1:47:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3827: train loss 2.35518. lr 5.798884e-04:  23%|██▎       | 3828/16329 [32:14<1:49:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3828: train loss 2.30550. lr 5.798780e-04:  23%|██▎       | 3828/16329 [32:14<1:49:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3828: train loss 2.30550. lr 5.798780e-04:  23%|██▎       | 3829/16329 [32:14<1:48:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3829: train loss 2.35291. lr 5.798676e-04:  23%|██▎       | 3829/16329 [32:15<1:48:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3829: train loss 2.35291. lr 5.798676e-04:  23%|██▎       | 3830/16329 [32:15<1:48:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3830: train loss 2.40007. lr 5.798573e-04:  23%|██▎       | 3830/16329 [32:15<1:48:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3830: train loss 2.40007. lr 5.798573e-04:  23%|██▎       | 3831/16329 [32:15<1:47:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3831: train loss 2.37061. lr 5.798469e-04:  23%|██▎       | 3831/16329 [32:16<1:47:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3831: train loss 2.37061. lr 5.798469e-04:  23%|██▎       | 3832/16329 [32:16<1:46:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3832: train loss 2.39757. lr 5.798365e-04:  23%|██▎       | 3832/16329 [32:16<1:46:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3832: train loss 2.39757. lr 5.798365e-04:  23%|██▎       | 3833/16329 [32:16<1:45:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3833: train loss 2.38978. lr 5.798261e-04:  23%|██▎       | 3833/16329 [32:17<1:45:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3833: train loss 2.38978. lr 5.798261e-04:  23%|██▎       | 3834/16329 [32:17<1:44:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3834: train loss 2.33139. lr 5.798156e-04:  23%|██▎       | 3834/16329 [32:17<1:44:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3834: train loss 2.33139. lr 5.798156e-04:  23%|██▎       | 3835/16329 [32:17<1:44:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3835: train loss 2.38130. lr 5.798052e-04:  23%|██▎       | 3835/16329 [32:18<1:44:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3835: train loss 2.38130. lr 5.798052e-04:  23%|██▎       | 3836/16329 [32:18<1:43:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3836: train loss 2.38976. lr 5.797948e-04:  23%|██▎       | 3836/16329 [32:18<1:43:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3836: train loss 2.38976. lr 5.797948e-04:  23%|██▎       | 3837/16329 [32:18<1:43:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3837: train loss 2.33929. lr 5.797844e-04:  23%|██▎       | 3837/16329 [32:19<1:43:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3837: train loss 2.33929. lr 5.797844e-04:  24%|██▎       | 3838/16329 [32:19<1:43:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3838: train loss 2.44517. lr 5.797740e-04:  24%|██▎       | 3838/16329 [32:19<1:43:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3838: train loss 2.44517. lr 5.797740e-04:  24%|██▎       | 3839/16329 [32:19<1:43:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3839: train loss 2.34051. lr 5.797636e-04:  24%|██▎       | 3839/16329 [32:20<1:43:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3839: train loss 2.34051. lr 5.797636e-04:  24%|██▎       | 3840/16329 [32:20<1:42:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3840: train loss 2.30210. lr 5.797532e-04:  24%|██▎       | 3840/16329 [32:20<1:42:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3840: train loss 2.30210. lr 5.797532e-04:  24%|██▎       | 3841/16329 [32:20<1:42:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3841: train loss 2.28178. lr 5.797427e-04:  24%|██▎       | 3841/16329 [32:21<1:42:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3841: train loss 2.28178. lr 5.797427e-04:  24%|██▎       | 3842/16329 [32:21<1:42:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3842: train loss 2.38153. lr 5.797323e-04:  24%|██▎       | 3842/16329 [32:21<1:42:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3842: train loss 2.38153. lr 5.797323e-04:  24%|██▎       | 3843/16329 [32:21<1:42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3843: train loss 2.42531. lr 5.797219e-04:  24%|██▎       | 3843/16329 [32:22<1:42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3843: train loss 2.42531. lr 5.797219e-04:  24%|██▎       | 3844/16329 [32:22<1:42:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3844: train loss 2.32362. lr 5.797114e-04:  24%|██▎       | 3844/16329 [32:23<1:42:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3844: train loss 2.32362. lr 5.797114e-04:  24%|██▎       | 3845/16329 [32:23<1:53:35,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3845: train loss 2.43615. lr 5.797010e-04:  24%|██▎       | 3845/16329 [32:23<1:53:35,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 3845: train loss 2.43615. lr 5.797010e-04:  24%|██▎       | 3846/16329 [32:23<1:49:48,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3846: train loss 2.33751. lr 5.796906e-04:  24%|██▎       | 3846/16329 [32:23<1:49:48,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3846: train loss 2.33751. lr 5.796906e-04:  24%|██▎       | 3847/16329 [32:23<1:47:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3847: train loss 2.36891. lr 5.796801e-04:  24%|██▎       | 3847/16329 [32:24<1:47:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3847: train loss 2.36891. lr 5.796801e-04:  24%|██▎       | 3848/16329 [32:24<1:46:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3848: train loss 2.36961. lr 5.796697e-04:  24%|██▎       | 3848/16329 [32:24<1:46:10,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3848: train loss 2.36961. lr 5.796697e-04:  24%|██▎       | 3849/16329 [32:24<1:44:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3849: train loss 2.33158. lr 5.796592e-04:  24%|██▎       | 3849/16329 [32:25<1:44:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3849: train loss 2.33158. lr 5.796592e-04:  24%|██▎       | 3850/16329 [32:25<1:44:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3850: train loss 2.37729. lr 5.796488e-04:  24%|██▎       | 3850/16329 [32:25<1:44:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3850: train loss 2.37729. lr 5.796488e-04:  24%|██▎       | 3851/16329 [32:25<1:43:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3851: train loss 2.35421. lr 5.796384e-04:  24%|██▎       | 3851/16329 [32:26<1:43:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3851: train loss 2.35421. lr 5.796384e-04:  24%|██▎       | 3852/16329 [32:26<1:43:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3852: train loss 2.40090. lr 5.796279e-04:  24%|██▎       | 3852/16329 [32:26<1:43:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3852: train loss 2.40090. lr 5.796279e-04:  24%|██▎       | 3853/16329 [32:26<1:43:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3853: train loss 2.35660. lr 5.796174e-04:  24%|██▎       | 3853/16329 [32:27<1:43:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3853: train loss 2.35660. lr 5.796174e-04:  24%|██▎       | 3854/16329 [32:27<1:43:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3854: train loss 2.38743. lr 5.796070e-04:  24%|██▎       | 3854/16329 [32:27<1:43:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3854: train loss 2.38743. lr 5.796070e-04:  24%|██▎       | 3855/16329 [32:27<1:43:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3855: train loss 2.38905. lr 5.795965e-04:  24%|██▎       | 3855/16329 [32:28<1:43:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3855: train loss 2.38905. lr 5.795965e-04:  24%|██▎       | 3856/16329 [32:28<1:43:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3856: train loss 2.40237. lr 5.795861e-04:  24%|██▎       | 3856/16329 [32:28<1:43:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3856: train loss 2.40237. lr 5.795861e-04:  24%|██▎       | 3857/16329 [32:28<1:46:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3857: train loss 2.31519. lr 5.795756e-04:  24%|██▎       | 3857/16329 [32:29<1:46:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3857: train loss 2.31519. lr 5.795756e-04:  24%|██▎       | 3858/16329 [32:29<1:48:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3858: train loss 2.38001. lr 5.795651e-04:  24%|██▎       | 3858/16329 [32:30<1:48:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3858: train loss 2.38001. lr 5.795651e-04:  24%|██▎       | 3859/16329 [32:30<1:49:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3859: train loss 2.39604. lr 5.795547e-04:  24%|██▎       | 3859/16329 [32:30<1:49:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3859: train loss 2.39604. lr 5.795547e-04:  24%|██▎       | 3860/16329 [32:30<1:49:30,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3860: train loss 2.38039. lr 5.795442e-04:  24%|██▎       | 3860/16329 [32:31<1:49:30,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3860: train loss 2.38039. lr 5.795442e-04:  24%|██▎       | 3861/16329 [32:31<1:48:44,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3861: train loss 2.40875. lr 5.795337e-04:  24%|██▎       | 3861/16329 [32:31<1:48:44,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3861: train loss 2.40875. lr 5.795337e-04:  24%|██▎       | 3862/16329 [32:31<1:47:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3862: train loss 2.36718. lr 5.795232e-04:  24%|██▎       | 3862/16329 [32:32<1:47:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3862: train loss 2.36718. lr 5.795232e-04:  24%|██▎       | 3863/16329 [32:32<1:46:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3863: train loss 2.41137. lr 5.795127e-04:  24%|██▎       | 3863/16329 [32:32<1:46:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3863: train loss 2.41137. lr 5.795127e-04:  24%|██▎       | 3864/16329 [32:32<1:46:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3864: train loss 2.33635. lr 5.795023e-04:  24%|██▎       | 3864/16329 [32:33<1:46:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3864: train loss 2.33635. lr 5.795023e-04:  24%|██▎       | 3865/16329 [32:33<1:45:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3865: train loss 2.39494. lr 5.794918e-04:  24%|██▎       | 3865/16329 [32:33<1:45:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3865: train loss 2.39494. lr 5.794918e-04:  24%|██▎       | 3866/16329 [32:33<1:44:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3866: train loss 2.37944. lr 5.794813e-04:  24%|██▎       | 3866/16329 [32:34<1:44:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3866: train loss 2.37944. lr 5.794813e-04:  24%|██▎       | 3867/16329 [32:34<1:43:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3867: train loss 2.40770. lr 5.794708e-04:  24%|██▎       | 3867/16329 [32:34<1:43:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3867: train loss 2.40770. lr 5.794708e-04:  24%|██▎       | 3868/16329 [32:34<1:43:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3868: train loss 2.25943. lr 5.794603e-04:  24%|██▎       | 3868/16329 [32:35<1:43:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3868: train loss 2.25943. lr 5.794603e-04:  24%|██▎       | 3869/16329 [32:35<1:43:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3869: train loss 2.37551. lr 5.794498e-04:  24%|██▎       | 3869/16329 [32:35<1:43:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3869: train loss 2.37551. lr 5.794498e-04:  24%|██▎       | 3870/16329 [32:35<1:42:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3870: train loss 2.33217. lr 5.794393e-04:  24%|██▎       | 3870/16329 [32:36<1:42:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3870: train loss 2.33217. lr 5.794393e-04:  24%|██▎       | 3871/16329 [32:36<1:42:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3871: train loss 2.32644. lr 5.794288e-04:  24%|██▎       | 3871/16329 [32:36<1:42:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3871: train loss 2.32644. lr 5.794288e-04:  24%|██▎       | 3872/16329 [32:36<1:42:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3872: train loss 2.35824. lr 5.794183e-04:  24%|██▎       | 3872/16329 [32:37<1:42:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3872: train loss 2.35824. lr 5.794183e-04:  24%|██▎       | 3873/16329 [32:37<1:42:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3873: train loss 2.32081. lr 5.794078e-04:  24%|██▎       | 3873/16329 [32:37<1:42:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3873: train loss 2.32081. lr 5.794078e-04:  24%|██▎       | 3874/16329 [32:37<1:42:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3874: train loss 2.36470. lr 5.793973e-04:  24%|██▎       | 3874/16329 [32:38<1:42:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3874: train loss 2.36470. lr 5.793973e-04:  24%|██▎       | 3875/16329 [32:38<1:42:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3875: train loss 2.30376. lr 5.793868e-04:  24%|██▎       | 3875/16329 [32:38<1:42:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3875: train loss 2.30376. lr 5.793868e-04:  24%|██▎       | 3876/16329 [32:38<1:42:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3876: train loss 2.38347. lr 5.793763e-04:  24%|██▎       | 3876/16329 [32:39<1:42:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3876: train loss 2.38347. lr 5.793763e-04:  24%|██▎       | 3877/16329 [32:39<1:42:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3877: train loss 2.34716. lr 5.793657e-04:  24%|██▎       | 3877/16329 [32:39<1:42:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3877: train loss 2.34716. lr 5.793657e-04:  24%|██▎       | 3878/16329 [32:39<1:42:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3878: train loss 2.36229. lr 5.793552e-04:  24%|██▎       | 3878/16329 [32:40<1:42:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3878: train loss 2.36229. lr 5.793552e-04:  24%|██▍       | 3879/16329 [32:40<1:42:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3879: train loss 2.37578. lr 5.793447e-04:  24%|██▍       | 3879/16329 [32:40<1:42:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3879: train loss 2.37578. lr 5.793447e-04:  24%|██▍       | 3880/16329 [32:40<1:53:00,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3880: train loss 2.33305. lr 5.793342e-04:  24%|██▍       | 3880/16329 [32:41<1:53:00,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3880: train loss 2.33305. lr 5.793342e-04:  24%|██▍       | 3881/16329 [32:41<1:50:01,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3881: train loss 2.32217. lr 5.793237e-04:  24%|██▍       | 3881/16329 [32:41<1:50:01,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3881: train loss 2.32217. lr 5.793237e-04:  24%|██▍       | 3882/16329 [32:41<1:47:33,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3882: train loss 2.41095. lr 5.793131e-04:  24%|██▍       | 3882/16329 [32:42<1:47:33,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3882: train loss 2.41095. lr 5.793131e-04:  24%|██▍       | 3883/16329 [32:42<1:46:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3883: train loss 2.37460. lr 5.793026e-04:  24%|██▍       | 3883/16329 [32:42<1:46:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 3883: train loss 2.37460. lr 5.793026e-04:  24%|██▍       | 3884/16329 [32:42<1:44:42,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3884: train loss 2.37477. lr 5.792921e-04:  24%|██▍       | 3884/16329 [32:43<1:44:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3884: train loss 2.37477. lr 5.792921e-04:  24%|██▍       | 3885/16329 [32:43<1:43:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3885: train loss 2.32853. lr 5.792815e-04:  24%|██▍       | 3885/16329 [32:43<1:43:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3885: train loss 2.32853. lr 5.792815e-04:  24%|██▍       | 3886/16329 [32:43<1:43:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3886: train loss 2.33438. lr 5.792710e-04:  24%|██▍       | 3886/16329 [32:44<1:43:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3886: train loss 2.33438. lr 5.792710e-04:  24%|██▍       | 3887/16329 [32:44<1:42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3887: train loss 2.35352. lr 5.792604e-04:  24%|██▍       | 3887/16329 [32:44<1:42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3887: train loss 2.35352. lr 5.792604e-04:  24%|██▍       | 3888/16329 [32:44<1:42:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3888: train loss 2.37749. lr 5.792499e-04:  24%|██▍       | 3888/16329 [32:45<1:42:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3888: train loss 2.37749. lr 5.792499e-04:  24%|██▍       | 3889/16329 [32:45<1:42:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3889: train loss 2.28421. lr 5.792393e-04:  24%|██▍       | 3889/16329 [32:45<1:42:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3889: train loss 2.28421. lr 5.792393e-04:  24%|██▍       | 3890/16329 [32:45<1:42:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3890: train loss 2.36206. lr 5.792288e-04:  24%|██▍       | 3890/16329 [32:46<1:42:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3890: train loss 2.36206. lr 5.792288e-04:  24%|██▍       | 3891/16329 [32:46<1:42:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3891: train loss 2.28894. lr 5.792182e-04:  24%|██▍       | 3891/16329 [32:46<1:42:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3891: train loss 2.28894. lr 5.792182e-04:  24%|██▍       | 3892/16329 [32:46<1:42:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3892: train loss 2.41771. lr 5.792077e-04:  24%|██▍       | 3892/16329 [32:47<1:42:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3892: train loss 2.41771. lr 5.792077e-04:  24%|██▍       | 3893/16329 [32:47<1:42:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3893: train loss 2.37616. lr 5.791971e-04:  24%|██▍       | 3893/16329 [32:47<1:42:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3893: train loss 2.37616. lr 5.791971e-04:  24%|██▍       | 3894/16329 [32:47<1:42:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3894: train loss 2.34922. lr 5.791866e-04:  24%|██▍       | 3894/16329 [32:48<1:42:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3894: train loss 2.34922. lr 5.791866e-04:  24%|██▍       | 3895/16329 [32:48<1:42:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3895: train loss 2.37718. lr 5.791760e-04:  24%|██▍       | 3895/16329 [32:48<1:42:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3895: train loss 2.37718. lr 5.791760e-04:  24%|██▍       | 3896/16329 [32:48<1:42:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3896: train loss 2.33767. lr 5.791654e-04:  24%|██▍       | 3896/16329 [32:49<1:42:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3896: train loss 2.33767. lr 5.791654e-04:  24%|██▍       | 3897/16329 [32:49<1:42:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3897: train loss 2.39892. lr 5.791549e-04:  24%|██▍       | 3897/16329 [32:49<1:42:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3897: train loss 2.39892. lr 5.791549e-04:  24%|██▍       | 3898/16329 [32:49<1:42:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3898: train loss 2.38154. lr 5.791443e-04:  24%|██▍       | 3898/16329 [32:50<1:42:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3898: train loss 2.38154. lr 5.791443e-04:  24%|██▍       | 3899/16329 [32:50<1:42:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3899: train loss 2.39491. lr 5.791337e-04:  24%|██▍       | 3899/16329 [32:50<1:42:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3899: train loss 2.39491. lr 5.791337e-04:  24%|██▍       | 3900/16329 [32:50<1:42:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3900: train loss 2.37189. lr 5.791231e-04:  24%|██▍       | 3900/16329 [32:51<1:42:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3900: train loss 2.37189. lr 5.791231e-04:  24%|██▍       | 3901/16329 [32:51<1:42:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3901: train loss 2.36428. lr 5.791126e-04:  24%|██▍       | 3901/16329 [32:51<1:42:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3901: train loss 2.36428. lr 5.791126e-04:  24%|██▍       | 3902/16329 [32:51<1:42:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3902: train loss 2.33828. lr 5.791020e-04:  24%|██▍       | 3902/16329 [32:52<1:42:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3902: train loss 2.33828. lr 5.791020e-04:  24%|██▍       | 3903/16329 [32:52<1:42:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3903: train loss 2.35769. lr 5.790914e-04:  24%|██▍       | 3903/16329 [32:52<1:42:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3903: train loss 2.35769. lr 5.790914e-04:  24%|██▍       | 3904/16329 [32:52<1:42:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3904: train loss 2.31108. lr 5.790808e-04:  24%|██▍       | 3904/16329 [32:53<1:42:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3904: train loss 2.31108. lr 5.790808e-04:  24%|██▍       | 3905/16329 [32:53<1:55:29,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3905: train loss 2.37318. lr 5.790702e-04:  24%|██▍       | 3905/16329 [32:53<1:55:29,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 3905: train loss 2.37318. lr 5.790702e-04:  24%|██▍       | 3906/16329 [32:53<1:51:30,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3906: train loss 2.35693. lr 5.790596e-04:  24%|██▍       | 3906/16329 [32:54<1:51:30,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 3906: train loss 2.35693. lr 5.790596e-04:  24%|██▍       | 3907/16329 [32:54<1:48:26,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3907: train loss 2.34398. lr 5.790490e-04:  24%|██▍       | 3907/16329 [32:54<1:48:26,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 3907: train loss 2.34398. lr 5.790490e-04:  24%|██▍       | 3908/16329 [32:54<1:46:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3908: train loss 2.33219. lr 5.790384e-04:  24%|██▍       | 3908/16329 [32:55<1:46:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3908: train loss 2.33219. lr 5.790384e-04:  24%|██▍       | 3909/16329 [32:55<1:45:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3909: train loss 2.28747. lr 5.790278e-04:  24%|██▍       | 3909/16329 [32:55<1:45:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3909: train loss 2.28747. lr 5.790278e-04:  24%|██▍       | 3910/16329 [32:55<1:44:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3910: train loss 2.37075. lr 5.790172e-04:  24%|██▍       | 3910/16329 [32:56<1:44:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3910: train loss 2.37075. lr 5.790172e-04:  24%|██▍       | 3911/16329 [32:56<1:43:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3911: train loss 2.31330. lr 5.790066e-04:  24%|██▍       | 3911/16329 [32:56<1:43:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3911: train loss 2.31330. lr 5.790066e-04:  24%|██▍       | 3912/16329 [32:56<1:43:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3912: train loss 2.31228. lr 5.789960e-04:  24%|██▍       | 3912/16329 [32:57<1:43:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3912: train loss 2.31228. lr 5.789960e-04:  24%|██▍       | 3913/16329 [32:57<1:43:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3913: train loss 2.35879. lr 5.789854e-04:  24%|██▍       | 3913/16329 [32:57<1:43:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3913: train loss 2.35879. lr 5.789854e-04:  24%|██▍       | 3914/16329 [32:57<1:42:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3914: train loss 2.40164. lr 5.789748e-04:  24%|██▍       | 3914/16329 [32:58<1:42:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3914: train loss 2.40164. lr 5.789748e-04:  24%|██▍       | 3915/16329 [32:58<1:42:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3915: train loss 2.34135. lr 5.789642e-04:  24%|██▍       | 3915/16329 [32:58<1:42:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3915: train loss 2.34135. lr 5.789642e-04:  24%|██▍       | 3916/16329 [32:58<1:42:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3916: train loss 2.33280. lr 5.789536e-04:  24%|██▍       | 3916/16329 [32:59<1:42:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3916: train loss 2.33280. lr 5.789536e-04:  24%|██▍       | 3917/16329 [32:59<1:42:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3917: train loss 2.37554. lr 5.789429e-04:  24%|██▍       | 3917/16329 [32:59<1:42:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3917: train loss 2.37554. lr 5.789429e-04:  24%|██▍       | 3918/16329 [32:59<1:42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3918: train loss 2.34121. lr 5.789323e-04:  24%|██▍       | 3918/16329 [33:00<1:42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3918: train loss 2.34121. lr 5.789323e-04:  24%|██▍       | 3919/16329 [33:00<1:42:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3919: train loss 2.39924. lr 5.789217e-04:  24%|██▍       | 3919/16329 [33:00<1:42:11,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3919: train loss 2.39924. lr 5.789217e-04:  24%|██▍       | 3920/16329 [33:00<1:42:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3920: train loss 2.32046. lr 5.789111e-04:  24%|██▍       | 3920/16329 [33:01<1:42:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3920: train loss 2.32046. lr 5.789111e-04:  24%|██▍       | 3921/16329 [33:01<1:42:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3921: train loss 2.35347. lr 5.789004e-04:  24%|██▍       | 3921/16329 [33:01<1:42:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3921: train loss 2.35347. lr 5.789004e-04:  24%|██▍       | 3922/16329 [33:01<1:42:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3922: train loss 2.29078. lr 5.788898e-04:  24%|██▍       | 3922/16329 [33:02<1:42:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3922: train loss 2.29078. lr 5.788898e-04:  24%|██▍       | 3923/16329 [33:02<1:42:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3923: train loss 2.30130. lr 5.788792e-04:  24%|██▍       | 3923/16329 [33:02<1:42:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3923: train loss 2.30130. lr 5.788792e-04:  24%|██▍       | 3924/16329 [33:02<1:42:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3924: train loss 2.40665. lr 5.788685e-04:  24%|██▍       | 3924/16329 [33:03<1:42:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3924: train loss 2.40665. lr 5.788685e-04:  24%|██▍       | 3925/16329 [33:03<1:42:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3925: train loss 2.34677. lr 5.788579e-04:  24%|██▍       | 3925/16329 [33:03<1:42:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3925: train loss 2.34677. lr 5.788579e-04:  24%|██▍       | 3926/16329 [33:03<1:42:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3926: train loss 2.35227. lr 5.788472e-04:  24%|██▍       | 3926/16329 [33:04<1:42:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3926: train loss 2.35227. lr 5.788472e-04:  24%|██▍       | 3927/16329 [33:04<1:42:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3927: train loss 2.35830. lr 5.788366e-04:  24%|██▍       | 3927/16329 [33:04<1:42:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3927: train loss 2.35830. lr 5.788366e-04:  24%|██▍       | 3928/16329 [33:04<1:42:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3928: train loss 2.37506. lr 5.788259e-04:  24%|██▍       | 3928/16329 [33:05<1:42:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3928: train loss 2.37506. lr 5.788259e-04:  24%|██▍       | 3929/16329 [33:05<1:41:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3929: train loss 2.34009. lr 5.788153e-04:  24%|██▍       | 3929/16329 [33:05<1:41:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3929: train loss 2.34009. lr 5.788153e-04:  24%|██▍       | 3930/16329 [33:05<1:42:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3930: train loss 2.29593. lr 5.788046e-04:  24%|██▍       | 3930/16329 [33:06<1:42:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3930: train loss 2.29593. lr 5.788046e-04:  24%|██▍       | 3931/16329 [33:06<1:41:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3931: train loss 2.36958. lr 5.787940e-04:  24%|██▍       | 3931/16329 [33:06<1:41:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3931: train loss 2.36958. lr 5.787940e-04:  24%|██▍       | 3932/16329 [33:06<1:53:52,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 3932: train loss 2.36572. lr 5.787833e-04:  24%|██▍       | 3932/16329 [33:07<1:53:52,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 3932: train loss 2.36572. lr 5.787833e-04:  24%|██▍       | 3933/16329 [33:07<1:50:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3933: train loss 2.37195. lr 5.787727e-04:  24%|██▍       | 3933/16329 [33:07<1:50:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3933: train loss 2.37195. lr 5.787727e-04:  24%|██▍       | 3934/16329 [33:07<1:47:30,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3934: train loss 2.33180. lr 5.787620e-04:  24%|██▍       | 3934/16329 [33:08<1:47:30,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3934: train loss 2.33180. lr 5.787620e-04:  24%|██▍       | 3935/16329 [33:08<1:45:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3935: train loss 2.35609. lr 5.787513e-04:  24%|██▍       | 3935/16329 [33:08<1:45:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3935: train loss 2.35609. lr 5.787513e-04:  24%|██▍       | 3936/16329 [33:08<1:44:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3936: train loss 2.35768. lr 5.787407e-04:  24%|██▍       | 3936/16329 [33:09<1:44:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3936: train loss 2.35768. lr 5.787407e-04:  24%|██▍       | 3937/16329 [33:09<1:43:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3937: train loss 2.30872. lr 5.787300e-04:  24%|██▍       | 3937/16329 [33:09<1:43:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3937: train loss 2.30872. lr 5.787300e-04:  24%|██▍       | 3938/16329 [33:09<1:43:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3938: train loss 2.34881. lr 5.787193e-04:  24%|██▍       | 3938/16329 [33:10<1:43:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3938: train loss 2.34881. lr 5.787193e-04:  24%|██▍       | 3939/16329 [33:10<1:43:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3939: train loss 2.34565. lr 5.787086e-04:  24%|██▍       | 3939/16329 [33:10<1:43:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3939: train loss 2.34565. lr 5.787086e-04:  24%|██▍       | 3940/16329 [33:10<1:42:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3940: train loss 2.38445. lr 5.786980e-04:  24%|██▍       | 3940/16329 [33:11<1:42:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3940: train loss 2.38445. lr 5.786980e-04:  24%|██▍       | 3941/16329 [33:11<1:42:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3941: train loss 2.35839. lr 5.786873e-04:  24%|██▍       | 3941/16329 [33:11<1:42:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3941: train loss 2.35839. lr 5.786873e-04:  24%|██▍       | 3942/16329 [33:11<1:42:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3942: train loss 2.33871. lr 5.786766e-04:  24%|██▍       | 3942/16329 [33:12<1:42:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3942: train loss 2.33871. lr 5.786766e-04:  24%|██▍       | 3943/16329 [33:12<1:42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3943: train loss 2.36529. lr 5.786659e-04:  24%|██▍       | 3943/16329 [33:12<1:42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3943: train loss 2.36529. lr 5.786659e-04:  24%|██▍       | 3944/16329 [33:12<1:42:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3944: train loss 2.30416. lr 5.786552e-04:  24%|██▍       | 3944/16329 [33:13<1:42:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3944: train loss 2.30416. lr 5.786552e-04:  24%|██▍       | 3945/16329 [33:13<1:42:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3945: train loss 2.36533. lr 5.786445e-04:  24%|██▍       | 3945/16329 [33:13<1:42:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3945: train loss 2.36533. lr 5.786445e-04:  24%|██▍       | 3946/16329 [33:13<1:42:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3946: train loss 2.31988. lr 5.786338e-04:  24%|██▍       | 3946/16329 [33:14<1:42:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3946: train loss 2.31988. lr 5.786338e-04:  24%|██▍       | 3947/16329 [33:14<1:46:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3947: train loss 2.34069. lr 5.786231e-04:  24%|██▍       | 3947/16329 [33:14<1:46:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3947: train loss 2.34069. lr 5.786231e-04:  24%|██▍       | 3948/16329 [33:14<1:48:58,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3948: train loss 2.36356. lr 5.786124e-04:  24%|██▍       | 3948/16329 [33:15<1:48:58,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3948: train loss 2.36356. lr 5.786124e-04:  24%|██▍       | 3949/16329 [33:15<1:49:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3949: train loss 2.32300. lr 5.786017e-04:  24%|██▍       | 3949/16329 [33:15<1:49:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 3949: train loss 2.32300. lr 5.786017e-04:  24%|██▍       | 3950/16329 [33:15<1:49:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3950: train loss 2.38102. lr 5.785910e-04:  24%|██▍       | 3950/16329 [33:16<1:49:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3950: train loss 2.38102. lr 5.785910e-04:  24%|██▍       | 3951/16329 [33:16<1:48:30,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3951: train loss 2.27579. lr 5.785803e-04:  24%|██▍       | 3951/16329 [33:16<1:48:30,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 3951: train loss 2.27579. lr 5.785803e-04:  24%|██▍       | 3952/16329 [33:16<1:47:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3952: train loss 2.37337. lr 5.785696e-04:  24%|██▍       | 3952/16329 [33:17<1:47:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3952: train loss 2.37337. lr 5.785696e-04:  24%|██▍       | 3953/16329 [33:17<1:46:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3953: train loss 2.31983. lr 5.785589e-04:  24%|██▍       | 3953/16329 [33:17<1:46:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 3953: train loss 2.31983. lr 5.785589e-04:  24%|██▍       | 3954/16329 [33:17<1:45:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3954: train loss 2.39861. lr 5.785482e-04:  24%|██▍       | 3954/16329 [33:18<1:45:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3954: train loss 2.39861. lr 5.785482e-04:  24%|██▍       | 3955/16329 [33:18<1:44:52,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3955: train loss 2.39412. lr 5.785375e-04:  24%|██▍       | 3955/16329 [33:18<1:44:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3955: train loss 2.39412. lr 5.785375e-04:  24%|██▍       | 3956/16329 [33:18<1:44:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3956: train loss 2.29222. lr 5.785267e-04:  24%|██▍       | 3956/16329 [33:19<1:44:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 3956: train loss 2.29222. lr 5.785267e-04:  24%|██▍       | 3957/16329 [33:19<1:43:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3957: train loss 2.37532. lr 5.785160e-04:  24%|██▍       | 3957/16329 [33:19<1:43:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3957: train loss 2.37532. lr 5.785160e-04:  24%|██▍       | 3958/16329 [33:19<1:42:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3958: train loss 2.31608. lr 5.785053e-04:  24%|██▍       | 3958/16329 [33:20<1:42:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3958: train loss 2.31608. lr 5.785053e-04:  24%|██▍       | 3959/16329 [33:20<1:42:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3959: train loss 2.32755. lr 5.784946e-04:  24%|██▍       | 3959/16329 [33:20<1:42:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3959: train loss 2.32755. lr 5.784946e-04:  24%|██▍       | 3960/16329 [33:20<1:42:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3960: train loss 2.36983. lr 5.784838e-04:  24%|██▍       | 3960/16329 [33:21<1:42:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3960: train loss 2.36983. lr 5.784838e-04:  24%|██▍       | 3961/16329 [33:21<1:42:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3961: train loss 2.29619. lr 5.784731e-04:  24%|██▍       | 3961/16329 [33:21<1:42:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3961: train loss 2.29619. lr 5.784731e-04:  24%|██▍       | 3962/16329 [33:21<1:41:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3962: train loss 2.37897. lr 5.784623e-04:  24%|██▍       | 3962/16329 [33:22<1:41:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3962: train loss 2.37897. lr 5.784623e-04:  24%|██▍       | 3963/16329 [33:22<1:41:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3963: train loss 2.27161. lr 5.784516e-04:  24%|██▍       | 3963/16329 [33:22<1:41:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3963: train loss 2.27161. lr 5.784516e-04:  24%|██▍       | 3964/16329 [33:22<1:41:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3964: train loss 2.32980. lr 5.784409e-04:  24%|██▍       | 3964/16329 [33:23<1:41:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3964: train loss 2.32980. lr 5.784409e-04:  24%|██▍       | 3965/16329 [33:23<1:42:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3965: train loss 2.35763. lr 5.784301e-04:  24%|██▍       | 3965/16329 [33:23<1:42:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3965: train loss 2.35763. lr 5.784301e-04:  24%|██▍       | 3966/16329 [33:23<1:41:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3966: train loss 2.36116. lr 5.784194e-04:  24%|██▍       | 3966/16329 [33:24<1:41:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3966: train loss 2.36116. lr 5.784194e-04:  24%|██▍       | 3967/16329 [33:24<1:41:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3967: train loss 2.34006. lr 5.784086e-04:  24%|██▍       | 3967/16329 [33:24<1:41:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3967: train loss 2.34006. lr 5.784086e-04:  24%|██▍       | 3968/16329 [33:24<1:46:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3968: train loss 2.31451. lr 5.783979e-04:  24%|██▍       | 3968/16329 [33:25<1:46:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 3968: train loss 2.31451. lr 5.783979e-04:  24%|██▍       | 3969/16329 [33:25<1:49:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3969: train loss 2.27160. lr 5.783871e-04:  24%|██▍       | 3969/16329 [33:26<1:49:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3969: train loss 2.27160. lr 5.783871e-04:  24%|██▍       | 3970/16329 [33:26<1:50:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3970: train loss 2.33123. lr 5.783764e-04:  24%|██▍       | 3970/16329 [33:26<1:50:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3970: train loss 2.33123. lr 5.783764e-04:  24%|██▍       | 3971/16329 [33:26<1:49:58,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3971: train loss 2.31364. lr 5.783656e-04:  24%|██▍       | 3971/16329 [33:27<1:49:58,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 3971: train loss 2.31364. lr 5.783656e-04:  24%|██▍       | 3972/16329 [33:27<2:00:51,  1.70it/s]\u001b[A\n",
      "epoch 1 iter 3972: train loss 2.28034. lr 5.783548e-04:  24%|██▍       | 3972/16329 [33:27<2:00:51,  1.70it/s]\u001b[A\n",
      "epoch 1 iter 3972: train loss 2.28034. lr 5.783548e-04:  24%|██▍       | 3973/16329 [33:27<1:55:59,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 3973: train loss 2.37674. lr 5.783441e-04:  24%|██▍       | 3973/16329 [33:28<1:55:59,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 3973: train loss 2.37674. lr 5.783441e-04:  24%|██▍       | 3974/16329 [33:28<1:52:12,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3974: train loss 2.33892. lr 5.783333e-04:  24%|██▍       | 3974/16329 [33:28<1:52:12,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 3974: train loss 2.33892. lr 5.783333e-04:  24%|██▍       | 3975/16329 [33:28<1:49:09,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3975: train loss 2.29970. lr 5.783225e-04:  24%|██▍       | 3975/16329 [33:29<1:49:09,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 3975: train loss 2.29970. lr 5.783225e-04:  24%|██▍       | 3976/16329 [33:29<1:46:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3976: train loss 2.29012. lr 5.783118e-04:  24%|██▍       | 3976/16329 [33:29<1:46:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 3976: train loss 2.29012. lr 5.783118e-04:  24%|██▍       | 3977/16329 [33:29<1:45:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3977: train loss 2.34061. lr 5.783010e-04:  24%|██▍       | 3977/16329 [33:30<1:45:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 3977: train loss 2.34061. lr 5.783010e-04:  24%|██▍       | 3978/16329 [33:30<1:44:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3978: train loss 2.34184. lr 5.782902e-04:  24%|██▍       | 3978/16329 [33:30<1:44:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 3978: train loss 2.34184. lr 5.782902e-04:  24%|██▍       | 3979/16329 [33:30<1:43:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3979: train loss 2.27451. lr 5.782794e-04:  24%|██▍       | 3979/16329 [33:31<1:43:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 3979: train loss 2.27451. lr 5.782794e-04:  24%|██▍       | 3980/16329 [33:31<1:42:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3980: train loss 2.27937. lr 5.782687e-04:  24%|██▍       | 3980/16329 [33:31<1:42:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 3980: train loss 2.27937. lr 5.782687e-04:  24%|██▍       | 3981/16329 [33:31<1:42:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3981: train loss 2.32643. lr 5.782579e-04:  24%|██▍       | 3981/16329 [33:32<1:42:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 3981: train loss 2.32643. lr 5.782579e-04:  24%|██▍       | 3982/16329 [33:32<1:42:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3982: train loss 2.33949. lr 5.782471e-04:  24%|██▍       | 3982/16329 [33:32<1:42:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3982: train loss 2.33949. lr 5.782471e-04:  24%|██▍       | 3983/16329 [33:32<1:41:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3983: train loss 2.26997. lr 5.782363e-04:  24%|██▍       | 3983/16329 [33:33<1:41:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3983: train loss 2.26997. lr 5.782363e-04:  24%|██▍       | 3984/16329 [33:33<1:41:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3984: train loss 2.30662. lr 5.782255e-04:  24%|██▍       | 3984/16329 [33:33<1:41:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3984: train loss 2.30662. lr 5.782255e-04:  24%|██▍       | 3985/16329 [33:33<1:41:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3985: train loss 2.31518. lr 5.782147e-04:  24%|██▍       | 3985/16329 [33:34<1:41:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3985: train loss 2.31518. lr 5.782147e-04:  24%|██▍       | 3986/16329 [33:34<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3986: train loss 2.31025. lr 5.782039e-04:  24%|██▍       | 3986/16329 [33:34<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3986: train loss 2.31025. lr 5.782039e-04:  24%|██▍       | 3987/16329 [33:34<1:41:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3987: train loss 2.40663. lr 5.781931e-04:  24%|██▍       | 3987/16329 [33:35<1:41:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3987: train loss 2.40663. lr 5.781931e-04:  24%|██▍       | 3988/16329 [33:35<1:41:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3988: train loss 2.32013. lr 5.781823e-04:  24%|██▍       | 3988/16329 [33:35<1:41:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3988: train loss 2.32013. lr 5.781823e-04:  24%|██▍       | 3989/16329 [33:35<1:41:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3989: train loss 2.34694. lr 5.781715e-04:  24%|██▍       | 3989/16329 [33:36<1:41:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3989: train loss 2.34694. lr 5.781715e-04:  24%|██▍       | 3990/16329 [33:36<1:41:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3990: train loss 2.31916. lr 5.781607e-04:  24%|██▍       | 3990/16329 [33:36<1:41:31,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3990: train loss 2.31916. lr 5.781607e-04:  24%|██▍       | 3991/16329 [33:36<1:41:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3991: train loss 2.33776. lr 5.781499e-04:  24%|██▍       | 3991/16329 [33:37<1:41:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3991: train loss 2.33776. lr 5.781499e-04:  24%|██▍       | 3992/16329 [33:37<1:41:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3992: train loss 2.28053. lr 5.781391e-04:  24%|██▍       | 3992/16329 [33:37<1:41:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3992: train loss 2.28053. lr 5.781391e-04:  24%|██▍       | 3993/16329 [33:37<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3993: train loss 2.31388. lr 5.781282e-04:  24%|██▍       | 3993/16329 [33:38<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3993: train loss 2.31388. lr 5.781282e-04:  24%|██▍       | 3994/16329 [33:38<1:41:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3994: train loss 2.36086. lr 5.781174e-04:  24%|██▍       | 3994/16329 [33:38<1:41:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3994: train loss 2.36086. lr 5.781174e-04:  24%|██▍       | 3995/16329 [33:38<1:41:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3995: train loss 2.36768. lr 5.781066e-04:  24%|██▍       | 3995/16329 [33:39<1:41:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3995: train loss 2.36768. lr 5.781066e-04:  24%|██▍       | 3996/16329 [33:39<1:41:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3996: train loss 2.26784. lr 5.780958e-04:  24%|██▍       | 3996/16329 [33:39<1:41:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3996: train loss 2.26784. lr 5.780958e-04:  24%|██▍       | 3997/16329 [33:39<1:41:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3997: train loss 2.31734. lr 5.780849e-04:  24%|██▍       | 3997/16329 [33:40<1:41:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 3997: train loss 2.31734. lr 5.780849e-04:  24%|██▍       | 3998/16329 [33:40<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3998: train loss 2.32596. lr 5.780741e-04:  24%|██▍       | 3998/16329 [33:40<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3998: train loss 2.32596. lr 5.780741e-04:  24%|██▍       | 3999/16329 [33:40<1:41:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3999: train loss 2.35695. lr 5.780633e-04:  24%|██▍       | 3999/16329 [33:41<1:41:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 3999: train loss 2.35695. lr 5.780633e-04:  24%|██▍       | 4000/16329 [33:41<1:41:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4000: train loss 2.31110. lr 5.780525e-04:  24%|██▍       | 4000/16329 [33:41<1:41:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4000: train loss 2.31110. lr 5.780525e-04:  25%|██▍       | 4001/16329 [33:41<1:41:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4001: train loss 2.35935. lr 5.780416e-04:  25%|██▍       | 4001/16329 [33:42<1:41:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4001: train loss 2.35935. lr 5.780416e-04:  25%|██▍       | 4002/16329 [33:42<1:41:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4002: train loss 2.34584. lr 5.780308e-04:  25%|██▍       | 4002/16329 [33:42<1:41:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4002: train loss 2.34584. lr 5.780308e-04:  25%|██▍       | 4003/16329 [33:42<1:41:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4003: train loss 2.29390. lr 5.780199e-04:  25%|██▍       | 4003/16329 [33:43<1:41:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4003: train loss 2.29390. lr 5.780199e-04:  25%|██▍       | 4004/16329 [33:43<1:41:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4004: train loss 2.30042. lr 5.780091e-04:  25%|██▍       | 4004/16329 [33:43<1:41:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4004: train loss 2.30042. lr 5.780091e-04:  25%|██▍       | 4005/16329 [33:43<1:41:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4005: train loss 2.36705. lr 5.779982e-04:  25%|██▍       | 4005/16329 [33:44<1:41:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4005: train loss 2.36705. lr 5.779982e-04:  25%|██▍       | 4006/16329 [33:44<1:41:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4006: train loss 2.29526. lr 5.779874e-04:  25%|██▍       | 4006/16329 [33:44<1:41:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4006: train loss 2.29526. lr 5.779874e-04:  25%|██▍       | 4007/16329 [33:44<1:52:19,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4007: train loss 2.28345. lr 5.779765e-04:  25%|██▍       | 4007/16329 [33:45<1:52:19,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4007: train loss 2.28345. lr 5.779765e-04:  25%|██▍       | 4008/16329 [33:45<1:48:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4008: train loss 2.30926. lr 5.779657e-04:  25%|██▍       | 4008/16329 [33:45<1:48:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4008: train loss 2.30926. lr 5.779657e-04:  25%|██▍       | 4009/16329 [33:45<1:46:25,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4009: train loss 2.34553. lr 5.779548e-04:  25%|██▍       | 4009/16329 [33:46<1:46:25,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4009: train loss 2.34553. lr 5.779548e-04:  25%|██▍       | 4010/16329 [33:46<1:44:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4010: train loss 2.30439. lr 5.779440e-04:  25%|██▍       | 4010/16329 [33:46<1:44:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4010: train loss 2.30439. lr 5.779440e-04:  25%|██▍       | 4011/16329 [33:46<1:44:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4011: train loss 2.31429. lr 5.779331e-04:  25%|██▍       | 4011/16329 [33:47<1:44:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4011: train loss 2.31429. lr 5.779331e-04:  25%|██▍       | 4012/16329 [33:47<1:43:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4012: train loss 2.36025. lr 5.779222e-04:  25%|██▍       | 4012/16329 [33:47<1:43:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4012: train loss 2.36025. lr 5.779222e-04:  25%|██▍       | 4013/16329 [33:47<1:42:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4013: train loss 2.35763. lr 5.779114e-04:  25%|██▍       | 4013/16329 [33:48<1:42:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4013: train loss 2.35763. lr 5.779114e-04:  25%|██▍       | 4014/16329 [33:48<1:42:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4014: train loss 2.30436. lr 5.779005e-04:  25%|██▍       | 4014/16329 [33:48<1:42:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4014: train loss 2.30436. lr 5.779005e-04:  25%|██▍       | 4015/16329 [33:48<1:41:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4015: train loss 2.31893. lr 5.778896e-04:  25%|██▍       | 4015/16329 [33:49<1:41:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4015: train loss 2.31893. lr 5.778896e-04:  25%|██▍       | 4016/16329 [33:49<1:41:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4016: train loss 2.35924. lr 5.778788e-04:  25%|██▍       | 4016/16329 [33:49<1:41:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4016: train loss 2.35924. lr 5.778788e-04:  25%|██▍       | 4017/16329 [33:49<1:41:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4017: train loss 2.35980. lr 5.778679e-04:  25%|██▍       | 4017/16329 [33:50<1:41:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4017: train loss 2.35980. lr 5.778679e-04:  25%|██▍       | 4018/16329 [33:50<1:41:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4018: train loss 2.26169. lr 5.778570e-04:  25%|██▍       | 4018/16329 [33:50<1:41:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4018: train loss 2.26169. lr 5.778570e-04:  25%|██▍       | 4019/16329 [33:50<1:41:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4019: train loss 2.28676. lr 5.778461e-04:  25%|██▍       | 4019/16329 [33:51<1:41:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4019: train loss 2.28676. lr 5.778461e-04:  25%|██▍       | 4020/16329 [33:51<1:41:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4020: train loss 2.37265. lr 5.778352e-04:  25%|██▍       | 4020/16329 [33:51<1:41:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4020: train loss 2.37265. lr 5.778352e-04:  25%|██▍       | 4021/16329 [33:51<1:41:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4021: train loss 2.27318. lr 5.778243e-04:  25%|██▍       | 4021/16329 [33:52<1:41:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4021: train loss 2.27318. lr 5.778243e-04:  25%|██▍       | 4022/16329 [33:52<1:41:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4022: train loss 2.40317. lr 5.778134e-04:  25%|██▍       | 4022/16329 [33:52<1:41:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4022: train loss 2.40317. lr 5.778134e-04:  25%|██▍       | 4023/16329 [33:52<1:41:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4023: train loss 2.29805. lr 5.778026e-04:  25%|██▍       | 4023/16329 [33:53<1:41:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4023: train loss 2.29805. lr 5.778026e-04:  25%|██▍       | 4024/16329 [33:53<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4024: train loss 2.27982. lr 5.777917e-04:  25%|██▍       | 4024/16329 [33:53<1:41:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4024: train loss 2.27982. lr 5.777917e-04:  25%|██▍       | 4025/16329 [33:53<1:41:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4025: train loss 2.31921. lr 5.777808e-04:  25%|██▍       | 4025/16329 [33:54<1:41:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4025: train loss 2.31921. lr 5.777808e-04:  25%|██▍       | 4026/16329 [33:54<1:41:13,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4026: train loss 2.34612. lr 5.777699e-04:  25%|██▍       | 4026/16329 [33:54<1:41:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4026: train loss 2.34612. lr 5.777699e-04:  25%|██▍       | 4027/16329 [33:54<1:41:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4027: train loss 2.35494. lr 5.777590e-04:  25%|██▍       | 4027/16329 [33:55<1:41:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4027: train loss 2.35494. lr 5.777590e-04:  25%|██▍       | 4028/16329 [33:55<1:41:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4028: train loss 2.32231. lr 5.777480e-04:  25%|██▍       | 4028/16329 [33:55<1:41:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4028: train loss 2.32231. lr 5.777480e-04:  25%|██▍       | 4029/16329 [33:55<1:41:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4029: train loss 2.35621. lr 5.777371e-04:  25%|██▍       | 4029/16329 [33:56<1:41:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4029: train loss 2.35621. lr 5.777371e-04:  25%|██▍       | 4030/16329 [33:56<1:40:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4030: train loss 2.31625. lr 5.777262e-04:  25%|██▍       | 4030/16329 [33:56<1:40:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4030: train loss 2.31625. lr 5.777262e-04:  25%|██▍       | 4031/16329 [33:56<1:45:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4031: train loss 2.33693. lr 5.777153e-04:  25%|██▍       | 4031/16329 [33:57<1:45:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4031: train loss 2.33693. lr 5.777153e-04:  25%|██▍       | 4032/16329 [33:57<2:04:36,  1.64it/s]\u001b[A\n",
      "epoch 1 iter 4032: train loss 2.32152. lr 5.777044e-04:  25%|██▍       | 4032/16329 [33:57<2:04:36,  1.64it/s]\u001b[A\n",
      "epoch 1 iter 4032: train loss 2.32152. lr 5.777044e-04:  25%|██▍       | 4033/16329 [33:57<1:59:12,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 4033: train loss 2.31985. lr 5.776935e-04:  25%|██▍       | 4033/16329 [33:58<1:59:12,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 4033: train loss 2.31985. lr 5.776935e-04:  25%|██▍       | 4034/16329 [33:58<1:54:50,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4034: train loss 2.26886. lr 5.776826e-04:  25%|██▍       | 4034/16329 [33:59<1:54:50,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4034: train loss 2.26886. lr 5.776826e-04:  25%|██▍       | 4035/16329 [33:59<1:51:47,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4035: train loss 2.34158. lr 5.776716e-04:  25%|██▍       | 4035/16329 [33:59<1:51:47,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4035: train loss 2.34158. lr 5.776716e-04:  25%|██▍       | 4036/16329 [33:59<1:48:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4036: train loss 2.30577. lr 5.776607e-04:  25%|██▍       | 4036/16329 [34:00<1:48:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4036: train loss 2.30577. lr 5.776607e-04:  25%|██▍       | 4037/16329 [34:00<1:46:10,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4037: train loss 2.31363. lr 5.776498e-04:  25%|██▍       | 4037/16329 [34:00<1:46:10,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4037: train loss 2.31363. lr 5.776498e-04:  25%|██▍       | 4038/16329 [34:00<1:44:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4038: train loss 2.33046. lr 5.776388e-04:  25%|██▍       | 4038/16329 [34:00<1:44:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4038: train loss 2.33046. lr 5.776388e-04:  25%|██▍       | 4039/16329 [34:00<1:43:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4039: train loss 2.26269. lr 5.776279e-04:  25%|██▍       | 4039/16329 [34:01<1:43:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4039: train loss 2.26269. lr 5.776279e-04:  25%|██▍       | 4040/16329 [34:01<1:42:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4040: train loss 2.25442. lr 5.776170e-04:  25%|██▍       | 4040/16329 [34:01<1:42:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4040: train loss 2.25442. lr 5.776170e-04:  25%|██▍       | 4041/16329 [34:01<1:42:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4041: train loss 2.22887. lr 5.776060e-04:  25%|██▍       | 4041/16329 [34:02<1:42:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4041: train loss 2.22887. lr 5.776060e-04:  25%|██▍       | 4042/16329 [34:02<1:42:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4042: train loss 2.35068. lr 5.775951e-04:  25%|██▍       | 4042/16329 [34:02<1:42:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4042: train loss 2.35068. lr 5.775951e-04:  25%|██▍       | 4043/16329 [34:02<1:41:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4043: train loss 2.33466. lr 5.775841e-04:  25%|██▍       | 4043/16329 [34:03<1:41:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4043: train loss 2.33466. lr 5.775841e-04:  25%|██▍       | 4044/16329 [34:03<1:41:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4044: train loss 2.33354. lr 5.775732e-04:  25%|██▍       | 4044/16329 [34:03<1:41:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4044: train loss 2.33354. lr 5.775732e-04:  25%|██▍       | 4045/16329 [34:03<1:41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4045: train loss 2.30340. lr 5.775622e-04:  25%|██▍       | 4045/16329 [34:04<1:41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4045: train loss 2.30340. lr 5.775622e-04:  25%|██▍       | 4046/16329 [34:04<1:41:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4046: train loss 2.27651. lr 5.775513e-04:  25%|██▍       | 4046/16329 [34:04<1:41:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4046: train loss 2.27651. lr 5.775513e-04:  25%|██▍       | 4047/16329 [34:04<1:41:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4047: train loss 2.34037. lr 5.775403e-04:  25%|██▍       | 4047/16329 [34:05<1:41:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4047: train loss 2.34037. lr 5.775403e-04:  25%|██▍       | 4048/16329 [34:05<1:40:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4048: train loss 2.32076. lr 5.775294e-04:  25%|██▍       | 4048/16329 [34:05<1:40:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4048: train loss 2.32076. lr 5.775294e-04:  25%|██▍       | 4049/16329 [34:05<1:40:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4049: train loss 2.23354. lr 5.775184e-04:  25%|██▍       | 4049/16329 [34:06<1:40:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4049: train loss 2.23354. lr 5.775184e-04:  25%|██▍       | 4050/16329 [34:06<1:40:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4050: train loss 2.33613. lr 5.775075e-04:  25%|██▍       | 4050/16329 [34:06<1:40:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4050: train loss 2.33613. lr 5.775075e-04:  25%|██▍       | 4051/16329 [34:06<1:40:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4051: train loss 2.33682. lr 5.774965e-04:  25%|██▍       | 4051/16329 [34:07<1:40:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4051: train loss 2.33682. lr 5.774965e-04:  25%|██▍       | 4052/16329 [34:07<1:41:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4052: train loss 2.33237. lr 5.774855e-04:  25%|██▍       | 4052/16329 [34:07<1:41:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4052: train loss 2.33237. lr 5.774855e-04:  25%|██▍       | 4053/16329 [34:07<1:40:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4053: train loss 2.30654. lr 5.774745e-04:  25%|██▍       | 4053/16329 [34:08<1:40:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4053: train loss 2.30654. lr 5.774745e-04:  25%|██▍       | 4054/16329 [34:08<1:40:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4054: train loss 2.27548. lr 5.774636e-04:  25%|██▍       | 4054/16329 [34:08<1:40:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4054: train loss 2.27548. lr 5.774636e-04:  25%|██▍       | 4055/16329 [34:08<1:40:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4055: train loss 2.26233. lr 5.774526e-04:  25%|██▍       | 4055/16329 [34:09<1:40:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4055: train loss 2.26233. lr 5.774526e-04:  25%|██▍       | 4056/16329 [34:09<1:40:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4056: train loss 2.29852. lr 5.774416e-04:  25%|██▍       | 4056/16329 [34:09<1:40:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4056: train loss 2.29852. lr 5.774416e-04:  25%|██▍       | 4057/16329 [34:09<1:41:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4057: train loss 2.35386. lr 5.774306e-04:  25%|██▍       | 4057/16329 [34:10<1:41:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4057: train loss 2.35386. lr 5.774306e-04:  25%|██▍       | 4058/16329 [34:10<1:40:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4058: train loss 2.22942. lr 5.774197e-04:  25%|██▍       | 4058/16329 [34:11<1:40:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4058: train loss 2.22942. lr 5.774197e-04:  25%|██▍       | 4059/16329 [34:11<1:56:46,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 4059: train loss 2.29177. lr 5.774087e-04:  25%|██▍       | 4059/16329 [34:11<1:56:46,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 4059: train loss 2.29177. lr 5.774087e-04:  25%|██▍       | 4060/16329 [34:11<1:51:46,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4060: train loss 2.29515. lr 5.773977e-04:  25%|██▍       | 4060/16329 [34:12<1:51:46,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4060: train loss 2.29515. lr 5.773977e-04:  25%|██▍       | 4061/16329 [34:12<1:48:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4061: train loss 2.32083. lr 5.773867e-04:  25%|██▍       | 4061/16329 [34:12<1:48:38,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4061: train loss 2.32083. lr 5.773867e-04:  25%|██▍       | 4062/16329 [34:12<1:46:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4062: train loss 2.27574. lr 5.773757e-04:  25%|██▍       | 4062/16329 [34:13<1:46:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4062: train loss 2.27574. lr 5.773757e-04:  25%|██▍       | 4063/16329 [34:13<1:44:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4063: train loss 2.23653. lr 5.773647e-04:  25%|██▍       | 4063/16329 [34:13<1:44:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4063: train loss 2.23653. lr 5.773647e-04:  25%|██▍       | 4064/16329 [34:13<1:43:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4064: train loss 2.34708. lr 5.773537e-04:  25%|██▍       | 4064/16329 [34:14<1:43:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4064: train loss 2.34708. lr 5.773537e-04:  25%|██▍       | 4065/16329 [34:14<1:42:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4065: train loss 2.33465. lr 5.773427e-04:  25%|██▍       | 4065/16329 [34:14<1:42:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4065: train loss 2.33465. lr 5.773427e-04:  25%|██▍       | 4066/16329 [34:14<1:42:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4066: train loss 2.36106. lr 5.773317e-04:  25%|██▍       | 4066/16329 [34:15<1:42:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4066: train loss 2.36106. lr 5.773317e-04:  25%|██▍       | 4067/16329 [34:15<1:41:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4067: train loss 2.30204. lr 5.773207e-04:  25%|██▍       | 4067/16329 [34:15<1:41:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4067: train loss 2.30204. lr 5.773207e-04:  25%|██▍       | 4068/16329 [34:15<1:41:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4068: train loss 2.30682. lr 5.773097e-04:  25%|██▍       | 4068/16329 [34:16<1:41:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4068: train loss 2.30682. lr 5.773097e-04:  25%|██▍       | 4069/16329 [34:16<1:41:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4069: train loss 2.34417. lr 5.772987e-04:  25%|██▍       | 4069/16329 [34:16<1:41:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4069: train loss 2.34417. lr 5.772987e-04:  25%|██▍       | 4070/16329 [34:16<1:40:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4070: train loss 2.29830. lr 5.772877e-04:  25%|██▍       | 4070/16329 [34:17<1:40:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4070: train loss 2.29830. lr 5.772877e-04:  25%|██▍       | 4071/16329 [34:17<1:41:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4071: train loss 2.31425. lr 5.772766e-04:  25%|██▍       | 4071/16329 [34:17<1:41:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4071: train loss 2.31425. lr 5.772766e-04:  25%|██▍       | 4072/16329 [34:17<1:40:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4072: train loss 2.29799. lr 5.772656e-04:  25%|██▍       | 4072/16329 [34:18<1:40:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4072: train loss 2.29799. lr 5.772656e-04:  25%|██▍       | 4073/16329 [34:18<1:40:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4073: train loss 2.35498. lr 5.772546e-04:  25%|██▍       | 4073/16329 [34:18<1:40:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4073: train loss 2.35498. lr 5.772546e-04:  25%|██▍       | 4074/16329 [34:18<1:40:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4074: train loss 2.31749. lr 5.772436e-04:  25%|██▍       | 4074/16329 [34:18<1:40:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4074: train loss 2.31749. lr 5.772436e-04:  25%|██▍       | 4075/16329 [34:18<1:40:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4075: train loss 2.33604. lr 5.772325e-04:  25%|██▍       | 4075/16329 [34:19<1:40:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4075: train loss 2.33604. lr 5.772325e-04:  25%|██▍       | 4076/16329 [34:19<1:41:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4076: train loss 2.32827. lr 5.772215e-04:  25%|██▍       | 4076/16329 [34:19<1:41:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4076: train loss 2.32827. lr 5.772215e-04:  25%|██▍       | 4077/16329 [34:19<1:40:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4077: train loss 2.29731. lr 5.772105e-04:  25%|██▍       | 4077/16329 [34:20<1:40:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4077: train loss 2.29731. lr 5.772105e-04:  25%|██▍       | 4078/16329 [34:20<1:40:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4078: train loss 2.31678. lr 5.771994e-04:  25%|██▍       | 4078/16329 [34:20<1:40:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4078: train loss 2.31678. lr 5.771994e-04:  25%|██▍       | 4079/16329 [34:20<1:41:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4079: train loss 2.35027. lr 5.771884e-04:  25%|██▍       | 4079/16329 [34:21<1:41:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4079: train loss 2.35027. lr 5.771884e-04:  25%|██▍       | 4080/16329 [34:21<1:40:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4080: train loss 2.22981. lr 5.771774e-04:  25%|██▍       | 4080/16329 [34:21<1:40:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4080: train loss 2.22981. lr 5.771774e-04:  25%|██▍       | 4081/16329 [34:21<1:41:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4081: train loss 2.24363. lr 5.771663e-04:  25%|██▍       | 4081/16329 [34:22<1:41:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4081: train loss 2.24363. lr 5.771663e-04:  25%|██▍       | 4082/16329 [34:22<1:40:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4082: train loss 2.29673. lr 5.771553e-04:  25%|██▍       | 4082/16329 [34:22<1:40:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4082: train loss 2.29673. lr 5.771553e-04:  25%|██▌       | 4083/16329 [34:22<1:41:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4083: train loss 2.29582. lr 5.771442e-04:  25%|██▌       | 4083/16329 [34:23<1:41:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4083: train loss 2.29582. lr 5.771442e-04:  25%|██▌       | 4084/16329 [34:23<1:40:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4084: train loss 2.27283. lr 5.771332e-04:  25%|██▌       | 4084/16329 [34:23<1:40:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4084: train loss 2.27283. lr 5.771332e-04:  25%|██▌       | 4085/16329 [34:23<1:40:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4085: train loss 2.20155. lr 5.771221e-04:  25%|██▌       | 4085/16329 [34:24<1:40:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4085: train loss 2.20155. lr 5.771221e-04:  25%|██▌       | 4086/16329 [34:24<1:43:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4086: train loss 2.33098. lr 5.771111e-04:  25%|██▌       | 4086/16329 [34:25<1:43:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4086: train loss 2.33098. lr 5.771111e-04:  25%|██▌       | 4087/16329 [34:25<1:44:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4087: train loss 2.26783. lr 5.771000e-04:  25%|██▌       | 4087/16329 [34:25<1:44:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4087: train loss 2.26783. lr 5.771000e-04:  25%|██▌       | 4088/16329 [34:25<1:45:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4088: train loss 2.24697. lr 5.770890e-04:  25%|██▌       | 4088/16329 [34:26<1:45:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4088: train loss 2.24697. lr 5.770890e-04:  25%|██▌       | 4089/16329 [34:26<1:45:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4089: train loss 2.28866. lr 5.770779e-04:  25%|██▌       | 4089/16329 [34:26<1:45:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4089: train loss 2.28866. lr 5.770779e-04:  25%|██▌       | 4090/16329 [34:26<1:44:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4090: train loss 2.30488. lr 5.770668e-04:  25%|██▌       | 4090/16329 [34:27<1:44:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4090: train loss 2.30488. lr 5.770668e-04:  25%|██▌       | 4091/16329 [34:27<1:43:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4091: train loss 2.22443. lr 5.770558e-04:  25%|██▌       | 4091/16329 [34:27<1:43:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4091: train loss 2.22443. lr 5.770558e-04:  25%|██▌       | 4092/16329 [34:27<1:42:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4092: train loss 2.29946. lr 5.770447e-04:  25%|██▌       | 4092/16329 [34:28<1:42:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4092: train loss 2.29946. lr 5.770447e-04:  25%|██▌       | 4093/16329 [34:28<1:41:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4093: train loss 2.33386. lr 5.770336e-04:  25%|██▌       | 4093/16329 [34:28<1:41:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4093: train loss 2.33386. lr 5.770336e-04:  25%|██▌       | 4094/16329 [34:28<1:41:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4094: train loss 2.31900. lr 5.770225e-04:  25%|██▌       | 4094/16329 [34:29<1:41:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4094: train loss 2.31900. lr 5.770225e-04:  25%|██▌       | 4095/16329 [34:29<1:41:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4095: train loss 2.30652. lr 5.770115e-04:  25%|██▌       | 4095/16329 [34:29<1:41:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4095: train loss 2.30652. lr 5.770115e-04:  25%|██▌       | 4096/16329 [34:29<1:41:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4096: train loss 2.27534. lr 5.770004e-04:  25%|██▌       | 4096/16329 [34:30<1:41:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4096: train loss 2.27534. lr 5.770004e-04:  25%|██▌       | 4097/16329 [34:30<1:41:26,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4097: train loss 2.27655. lr 5.769893e-04:  25%|██▌       | 4097/16329 [34:30<1:41:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4097: train loss 2.27655. lr 5.769893e-04:  25%|██▌       | 4098/16329 [34:30<1:41:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4098: train loss 2.27513. lr 5.769782e-04:  25%|██▌       | 4098/16329 [34:31<1:41:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4098: train loss 2.27513. lr 5.769782e-04:  25%|██▌       | 4099/16329 [34:31<1:54:32,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4099: train loss 2.30748. lr 5.769671e-04:  25%|██▌       | 4099/16329 [34:31<1:54:32,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4099: train loss 2.30748. lr 5.769671e-04:  25%|██▌       | 4100/16329 [34:31<1:50:05,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 4100: train loss 2.29444. lr 5.769560e-04:  25%|██▌       | 4100/16329 [34:32<1:50:05,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 4100: train loss 2.29444. lr 5.769560e-04:  25%|██▌       | 4101/16329 [34:32<1:51:14,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4101: train loss 2.29802. lr 5.769449e-04:  25%|██▌       | 4101/16329 [34:32<1:51:14,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4101: train loss 2.29802. lr 5.769449e-04:  25%|██▌       | 4102/16329 [34:32<1:50:44,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4102: train loss 2.28611. lr 5.769338e-04:  25%|██▌       | 4102/16329 [34:33<1:50:44,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4102: train loss 2.28611. lr 5.769338e-04:  25%|██▌       | 4103/16329 [34:33<1:49:27,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4103: train loss 2.31627. lr 5.769227e-04:  25%|██▌       | 4103/16329 [34:33<1:49:27,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4103: train loss 2.31627. lr 5.769227e-04:  25%|██▌       | 4104/16329 [34:33<1:48:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4104: train loss 2.31234. lr 5.769116e-04:  25%|██▌       | 4104/16329 [34:34<1:48:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4104: train loss 2.31234. lr 5.769116e-04:  25%|██▌       | 4105/16329 [34:34<1:49:27,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4105: train loss 2.25885. lr 5.769005e-04:  25%|██▌       | 4105/16329 [34:34<1:49:27,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4105: train loss 2.25885. lr 5.769005e-04:  25%|██▌       | 4106/16329 [34:34<1:49:01,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4106: train loss 2.30667. lr 5.768894e-04:  25%|██▌       | 4106/16329 [34:35<1:49:01,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4106: train loss 2.30667. lr 5.768894e-04:  25%|██▌       | 4107/16329 [34:35<1:47:59,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4107: train loss 2.27674. lr 5.768783e-04:  25%|██▌       | 4107/16329 [34:35<1:47:59,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4107: train loss 2.27674. lr 5.768783e-04:  25%|██▌       | 4108/16329 [34:35<1:46:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4108: train loss 2.29246. lr 5.768672e-04:  25%|██▌       | 4108/16329 [34:36<1:46:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4108: train loss 2.29246. lr 5.768672e-04:  25%|██▌       | 4109/16329 [34:36<1:45:25,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4109: train loss 2.25586. lr 5.768561e-04:  25%|██▌       | 4109/16329 [34:36<1:45:25,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4109: train loss 2.25586. lr 5.768561e-04:  25%|██▌       | 4110/16329 [34:36<1:44:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4110: train loss 2.34564. lr 5.768450e-04:  25%|██▌       | 4110/16329 [34:37<1:44:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4110: train loss 2.34564. lr 5.768450e-04:  25%|██▌       | 4111/16329 [34:37<1:43:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4111: train loss 2.28525. lr 5.768339e-04:  25%|██▌       | 4111/16329 [34:37<1:43:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4111: train loss 2.28525. lr 5.768339e-04:  25%|██▌       | 4112/16329 [34:37<1:43:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4112: train loss 2.21215. lr 5.768227e-04:  25%|██▌       | 4112/16329 [34:38<1:43:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4112: train loss 2.21215. lr 5.768227e-04:  25%|██▌       | 4113/16329 [34:38<1:42:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4113: train loss 2.26807. lr 5.768116e-04:  25%|██▌       | 4113/16329 [34:38<1:42:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4113: train loss 2.26807. lr 5.768116e-04:  25%|██▌       | 4114/16329 [34:38<1:41:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4114: train loss 2.30138. lr 5.768005e-04:  25%|██▌       | 4114/16329 [34:39<1:41:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4114: train loss 2.30138. lr 5.768005e-04:  25%|██▌       | 4115/16329 [34:39<1:41:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4115: train loss 2.30640. lr 5.767894e-04:  25%|██▌       | 4115/16329 [34:39<1:41:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4115: train loss 2.30640. lr 5.767894e-04:  25%|██▌       | 4116/16329 [34:39<1:41:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4116: train loss 2.29138. lr 5.767782e-04:  25%|██▌       | 4116/16329 [34:40<1:41:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4116: train loss 2.29138. lr 5.767782e-04:  25%|██▌       | 4117/16329 [34:40<1:40:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4117: train loss 2.33715. lr 5.767671e-04:  25%|██▌       | 4117/16329 [34:40<1:40:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4117: train loss 2.33715. lr 5.767671e-04:  25%|██▌       | 4118/16329 [34:40<1:40:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4118: train loss 2.26866. lr 5.767560e-04:  25%|██▌       | 4118/16329 [34:41<1:40:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4118: train loss 2.26866. lr 5.767560e-04:  25%|██▌       | 4119/16329 [34:41<1:40:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4119: train loss 2.23587. lr 5.767448e-04:  25%|██▌       | 4119/16329 [34:41<1:40:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4119: train loss 2.23587. lr 5.767448e-04:  25%|██▌       | 4120/16329 [34:41<1:40:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4120: train loss 2.26520. lr 5.767337e-04:  25%|██▌       | 4120/16329 [34:42<1:40:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4120: train loss 2.26520. lr 5.767337e-04:  25%|██▌       | 4121/16329 [34:42<1:40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4121: train loss 2.25927. lr 5.767225e-04:  25%|██▌       | 4121/16329 [34:42<1:40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4121: train loss 2.25927. lr 5.767225e-04:  25%|██▌       | 4122/16329 [34:42<1:40:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4122: train loss 2.26948. lr 5.767114e-04:  25%|██▌       | 4122/16329 [34:43<1:40:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4122: train loss 2.26948. lr 5.767114e-04:  25%|██▌       | 4123/16329 [34:43<1:40:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4123: train loss 2.30954. lr 5.767002e-04:  25%|██▌       | 4123/16329 [34:43<1:40:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4123: train loss 2.30954. lr 5.767002e-04:  25%|██▌       | 4124/16329 [34:43<1:42:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4124: train loss 2.27968. lr 5.766891e-04:  25%|██▌       | 4124/16329 [34:44<1:42:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4124: train loss 2.27968. lr 5.766891e-04:  25%|██▌       | 4125/16329 [34:44<1:43:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4125: train loss 2.22311. lr 5.766779e-04:  25%|██▌       | 4125/16329 [34:44<1:43:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4125: train loss 2.22311. lr 5.766779e-04:  25%|██▌       | 4126/16329 [34:44<1:43:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4126: train loss 2.30111. lr 5.766668e-04:  25%|██▌       | 4126/16329 [34:45<1:43:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4126: train loss 2.30111. lr 5.766668e-04:  25%|██▌       | 4127/16329 [34:45<1:43:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4127: train loss 2.26172. lr 5.766556e-04:  25%|██▌       | 4127/16329 [34:45<1:43:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4127: train loss 2.26172. lr 5.766556e-04:  25%|██▌       | 4128/16329 [34:45<1:42:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4128: train loss 2.26206. lr 5.766444e-04:  25%|██▌       | 4128/16329 [34:46<1:42:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4128: train loss 2.26206. lr 5.766444e-04:  25%|██▌       | 4129/16329 [34:46<1:42:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4129: train loss 2.27876. lr 5.766333e-04:  25%|██▌       | 4129/16329 [34:46<1:42:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4129: train loss 2.27876. lr 5.766333e-04:  25%|██▌       | 4130/16329 [34:46<1:41:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4130: train loss 2.35002. lr 5.766221e-04:  25%|██▌       | 4130/16329 [34:47<1:41:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4130: train loss 2.35002. lr 5.766221e-04:  25%|██▌       | 4131/16329 [34:47<1:41:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4131: train loss 2.31512. lr 5.766109e-04:  25%|██▌       | 4131/16329 [34:47<1:41:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4131: train loss 2.31512. lr 5.766109e-04:  25%|██▌       | 4132/16329 [34:47<1:41:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4132: train loss 2.24803. lr 5.765998e-04:  25%|██▌       | 4132/16329 [34:48<1:41:11,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4132: train loss 2.24803. lr 5.765998e-04:  25%|██▌       | 4133/16329 [34:48<1:40:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4133: train loss 2.29865. lr 5.765886e-04:  25%|██▌       | 4133/16329 [34:49<1:40:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4133: train loss 2.29865. lr 5.765886e-04:  25%|██▌       | 4134/16329 [34:49<1:50:52,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4134: train loss 2.26054. lr 5.765774e-04:  25%|██▌       | 4134/16329 [34:49<1:50:52,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4134: train loss 2.26054. lr 5.765774e-04:  25%|██▌       | 4135/16329 [34:49<1:47:57,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4135: train loss 2.26152. lr 5.765662e-04:  25%|██▌       | 4135/16329 [34:50<1:47:57,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4135: train loss 2.26152. lr 5.765662e-04:  25%|██▌       | 4136/16329 [34:50<1:45:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4136: train loss 2.25814. lr 5.765550e-04:  25%|██▌       | 4136/16329 [34:50<1:45:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4136: train loss 2.25814. lr 5.765550e-04:  25%|██▌       | 4137/16329 [34:50<1:43:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4137: train loss 2.27690. lr 5.765439e-04:  25%|██▌       | 4137/16329 [34:51<1:43:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4137: train loss 2.27690. lr 5.765439e-04:  25%|██▌       | 4138/16329 [34:51<1:42:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4138: train loss 2.32768. lr 5.765327e-04:  25%|██▌       | 4138/16329 [34:51<1:42:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4138: train loss 2.32768. lr 5.765327e-04:  25%|██▌       | 4139/16329 [34:51<1:41:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4139: train loss 2.32332. lr 5.765215e-04:  25%|██▌       | 4139/16329 [34:52<1:41:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4139: train loss 2.32332. lr 5.765215e-04:  25%|██▌       | 4140/16329 [34:52<1:41:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4140: train loss 2.27853. lr 5.765103e-04:  25%|██▌       | 4140/16329 [34:52<1:41:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4140: train loss 2.27853. lr 5.765103e-04:  25%|██▌       | 4141/16329 [34:52<1:41:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4141: train loss 2.24393. lr 5.764991e-04:  25%|██▌       | 4141/16329 [34:53<1:41:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4141: train loss 2.24393. lr 5.764991e-04:  25%|██▌       | 4142/16329 [34:53<1:40:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4142: train loss 2.25932. lr 5.764879e-04:  25%|██▌       | 4142/16329 [34:53<1:40:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4142: train loss 2.25932. lr 5.764879e-04:  25%|██▌       | 4143/16329 [34:53<1:40:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4143: train loss 2.31149. lr 5.764767e-04:  25%|██▌       | 4143/16329 [34:54<1:40:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4143: train loss 2.31149. lr 5.764767e-04:  25%|██▌       | 4144/16329 [34:54<1:40:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4144: train loss 2.26157. lr 5.764655e-04:  25%|██▌       | 4144/16329 [34:54<1:40:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4144: train loss 2.26157. lr 5.764655e-04:  25%|██▌       | 4145/16329 [34:54<1:40:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4145: train loss 2.22887. lr 5.764543e-04:  25%|██▌       | 4145/16329 [34:55<1:40:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4145: train loss 2.22887. lr 5.764543e-04:  25%|██▌       | 4146/16329 [34:55<1:40:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4146: train loss 2.31831. lr 5.764431e-04:  25%|██▌       | 4146/16329 [34:55<1:40:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4146: train loss 2.31831. lr 5.764431e-04:  25%|██▌       | 4147/16329 [34:55<1:40:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4147: train loss 2.28706. lr 5.764319e-04:  25%|██▌       | 4147/16329 [34:56<1:40:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4147: train loss 2.28706. lr 5.764319e-04:  25%|██▌       | 4148/16329 [34:56<1:40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4148: train loss 2.31454. lr 5.764206e-04:  25%|██▌       | 4148/16329 [34:56<1:40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4148: train loss 2.31454. lr 5.764206e-04:  25%|██▌       | 4149/16329 [34:56<1:40:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4149: train loss 2.26147. lr 5.764094e-04:  25%|██▌       | 4149/16329 [34:56<1:40:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4149: train loss 2.26147. lr 5.764094e-04:  25%|██▌       | 4150/16329 [34:56<1:40:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4150: train loss 2.26390. lr 5.763982e-04:  25%|██▌       | 4150/16329 [34:57<1:40:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4150: train loss 2.26390. lr 5.763982e-04:  25%|██▌       | 4151/16329 [34:57<1:40:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4151: train loss 2.28865. lr 5.763870e-04:  25%|██▌       | 4151/16329 [34:57<1:40:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4151: train loss 2.28865. lr 5.763870e-04:  25%|██▌       | 4152/16329 [34:57<1:40:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4152: train loss 2.26130. lr 5.763758e-04:  25%|██▌       | 4152/16329 [34:58<1:40:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4152: train loss 2.26130. lr 5.763758e-04:  25%|██▌       | 4153/16329 [34:58<1:40:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4153: train loss 2.32698. lr 5.763645e-04:  25%|██▌       | 4153/16329 [34:58<1:40:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4153: train loss 2.32698. lr 5.763645e-04:  25%|██▌       | 4154/16329 [34:58<1:40:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4154: train loss 2.25905. lr 5.763533e-04:  25%|██▌       | 4154/16329 [34:59<1:40:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4154: train loss 2.25905. lr 5.763533e-04:  25%|██▌       | 4155/16329 [34:59<1:40:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4155: train loss 2.26713. lr 5.763421e-04:  25%|██▌       | 4155/16329 [34:59<1:40:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4155: train loss 2.26713. lr 5.763421e-04:  25%|██▌       | 4156/16329 [34:59<1:40:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4156: train loss 2.31549. lr 5.763308e-04:  25%|██▌       | 4156/16329 [35:00<1:40:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4156: train loss 2.31549. lr 5.763308e-04:  25%|██▌       | 4157/16329 [35:00<1:40:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4157: train loss 2.22267. lr 5.763196e-04:  25%|██▌       | 4157/16329 [35:00<1:40:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4157: train loss 2.22267. lr 5.763196e-04:  25%|██▌       | 4158/16329 [35:00<1:40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4158: train loss 2.29685. lr 5.763084e-04:  25%|██▌       | 4158/16329 [35:01<1:40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4158: train loss 2.29685. lr 5.763084e-04:  25%|██▌       | 4159/16329 [35:01<1:57:38,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 4159: train loss 2.24911. lr 5.762971e-04:  25%|██▌       | 4159/16329 [35:02<1:57:38,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 4159: train loss 2.24911. lr 5.762971e-04:  25%|██▌       | 4160/16329 [35:02<1:52:06,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 4160: train loss 2.24369. lr 5.762859e-04:  25%|██▌       | 4160/16329 [35:02<1:52:06,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 4160: train loss 2.24369. lr 5.762859e-04:  25%|██▌       | 4161/16329 [35:02<1:48:47,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4161: train loss 2.25292. lr 5.762746e-04:  25%|██▌       | 4161/16329 [35:03<1:48:47,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4161: train loss 2.25292. lr 5.762746e-04:  25%|██▌       | 4162/16329 [35:03<1:46:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4162: train loss 2.23225. lr 5.762634e-04:  25%|██▌       | 4162/16329 [35:03<1:46:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4162: train loss 2.23225. lr 5.762634e-04:  25%|██▌       | 4163/16329 [35:03<1:44:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4163: train loss 2.27868. lr 5.762521e-04:  25%|██▌       | 4163/16329 [35:04<1:44:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4163: train loss 2.27868. lr 5.762521e-04:  26%|██▌       | 4164/16329 [35:04<1:42:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4164: train loss 2.28862. lr 5.762409e-04:  26%|██▌       | 4164/16329 [35:04<1:42:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4164: train loss 2.28862. lr 5.762409e-04:  26%|██▌       | 4165/16329 [35:04<1:41:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4165: train loss 2.21877. lr 5.762296e-04:  26%|██▌       | 4165/16329 [35:05<1:41:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4165: train loss 2.21877. lr 5.762296e-04:  26%|██▌       | 4166/16329 [35:05<1:41:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4166: train loss 2.28991. lr 5.762184e-04:  26%|██▌       | 4166/16329 [35:05<1:41:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4166: train loss 2.28991. lr 5.762184e-04:  26%|██▌       | 4167/16329 [35:05<1:40:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4167: train loss 2.30134. lr 5.762071e-04:  26%|██▌       | 4167/16329 [35:06<1:40:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4167: train loss 2.30134. lr 5.762071e-04:  26%|██▌       | 4168/16329 [35:06<1:40:42,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4168: train loss 2.31020. lr 5.761958e-04:  26%|██▌       | 4168/16329 [35:06<1:40:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4168: train loss 2.31020. lr 5.761958e-04:  26%|██▌       | 4169/16329 [35:06<1:40:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4169: train loss 2.30190. lr 5.761846e-04:  26%|██▌       | 4169/16329 [35:07<1:40:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4169: train loss 2.30190. lr 5.761846e-04:  26%|██▌       | 4170/16329 [35:07<1:39:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4170: train loss 2.33994. lr 5.761733e-04:  26%|██▌       | 4170/16329 [35:07<1:39:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4170: train loss 2.33994. lr 5.761733e-04:  26%|██▌       | 4171/16329 [35:07<1:39:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4171: train loss 2.30243. lr 5.761620e-04:  26%|██▌       | 4171/16329 [35:08<1:39:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4171: train loss 2.30243. lr 5.761620e-04:  26%|██▌       | 4172/16329 [35:08<1:39:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4172: train loss 2.26502. lr 5.761507e-04:  26%|██▌       | 4172/16329 [35:08<1:39:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4172: train loss 2.26502. lr 5.761507e-04:  26%|██▌       | 4173/16329 [35:08<1:40:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4173: train loss 2.25270. lr 5.761395e-04:  26%|██▌       | 4173/16329 [35:09<1:40:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4173: train loss 2.25270. lr 5.761395e-04:  26%|██▌       | 4174/16329 [35:09<1:40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4174: train loss 2.22374. lr 5.761282e-04:  26%|██▌       | 4174/16329 [35:09<1:40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4174: train loss 2.22374. lr 5.761282e-04:  26%|██▌       | 4175/16329 [35:09<1:39:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4175: train loss 2.28997. lr 5.761169e-04:  26%|██▌       | 4175/16329 [35:10<1:39:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4175: train loss 2.28997. lr 5.761169e-04:  26%|██▌       | 4176/16329 [35:10<1:39:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4176: train loss 2.32214. lr 5.761056e-04:  26%|██▌       | 4176/16329 [35:10<1:39:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4176: train loss 2.32214. lr 5.761056e-04:  26%|██▌       | 4177/16329 [35:10<1:39:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4177: train loss 2.22764. lr 5.760943e-04:  26%|██▌       | 4177/16329 [35:11<1:39:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4177: train loss 2.22764. lr 5.760943e-04:  26%|██▌       | 4178/16329 [35:11<1:40:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4178: train loss 2.26614. lr 5.760830e-04:  26%|██▌       | 4178/16329 [35:11<1:40:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4178: train loss 2.26614. lr 5.760830e-04:  26%|██▌       | 4179/16329 [35:11<1:40:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4179: train loss 2.27935. lr 5.760717e-04:  26%|██▌       | 4179/16329 [35:12<1:40:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4179: train loss 2.27935. lr 5.760717e-04:  26%|██▌       | 4180/16329 [35:12<1:39:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4180: train loss 2.27822. lr 5.760604e-04:  26%|██▌       | 4180/16329 [35:12<1:39:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4180: train loss 2.27822. lr 5.760604e-04:  26%|██▌       | 4181/16329 [35:12<1:40:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4181: train loss 2.24246. lr 5.760491e-04:  26%|██▌       | 4181/16329 [35:13<1:40:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4181: train loss 2.24246. lr 5.760491e-04:  26%|██▌       | 4182/16329 [35:13<1:39:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4182: train loss 2.29896. lr 5.760378e-04:  26%|██▌       | 4182/16329 [35:13<1:39:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4182: train loss 2.29896. lr 5.760378e-04:  26%|██▌       | 4183/16329 [35:13<1:40:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4183: train loss 2.20036. lr 5.760265e-04:  26%|██▌       | 4183/16329 [35:14<1:40:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4183: train loss 2.20036. lr 5.760265e-04:  26%|██▌       | 4184/16329 [35:14<1:39:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4184: train loss 2.25059. lr 5.760152e-04:  26%|██▌       | 4184/16329 [35:14<1:39:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4184: train loss 2.25059. lr 5.760152e-04:  26%|██▌       | 4185/16329 [35:14<1:39:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4185: train loss 2.27570. lr 5.760039e-04:  26%|██▌       | 4185/16329 [35:15<1:39:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4185: train loss 2.27570. lr 5.760039e-04:  26%|██▌       | 4186/16329 [35:15<1:53:37,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4186: train loss 2.20255. lr 5.759926e-04:  26%|██▌       | 4186/16329 [35:15<1:53:37,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4186: train loss 2.20255. lr 5.759926e-04:  26%|██▌       | 4187/16329 [35:15<1:49:16,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 4187: train loss 2.20901. lr 5.759813e-04:  26%|██▌       | 4187/16329 [35:16<1:49:16,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 4187: train loss 2.20901. lr 5.759813e-04:  26%|██▌       | 4188/16329 [35:16<1:46:39,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4188: train loss 2.29971. lr 5.759700e-04:  26%|██▌       | 4188/16329 [35:16<1:46:39,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4188: train loss 2.29971. lr 5.759700e-04:  26%|██▌       | 4189/16329 [35:16<1:44:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4189: train loss 2.29551. lr 5.759587e-04:  26%|██▌       | 4189/16329 [35:17<1:44:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4189: train loss 2.29551. lr 5.759587e-04:  26%|██▌       | 4190/16329 [35:17<1:42:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4190: train loss 2.27079. lr 5.759473e-04:  26%|██▌       | 4190/16329 [35:17<1:42:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4190: train loss 2.27079. lr 5.759473e-04:  26%|██▌       | 4191/16329 [35:17<1:42:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4191: train loss 2.28002. lr 5.759360e-04:  26%|██▌       | 4191/16329 [35:18<1:42:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4191: train loss 2.28002. lr 5.759360e-04:  26%|██▌       | 4192/16329 [35:18<1:41:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4192: train loss 2.32002. lr 5.759247e-04:  26%|██▌       | 4192/16329 [35:18<1:41:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4192: train loss 2.32002. lr 5.759247e-04:  26%|██▌       | 4193/16329 [35:18<1:41:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4193: train loss 2.27250. lr 5.759134e-04:  26%|██▌       | 4193/16329 [35:19<1:41:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4193: train loss 2.27250. lr 5.759134e-04:  26%|██▌       | 4194/16329 [35:19<1:40:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4194: train loss 2.28934. lr 5.759020e-04:  26%|██▌       | 4194/16329 [35:19<1:40:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4194: train loss 2.28934. lr 5.759020e-04:  26%|██▌       | 4195/16329 [35:19<1:40:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4195: train loss 2.24207. lr 5.758907e-04:  26%|██▌       | 4195/16329 [35:20<1:40:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4195: train loss 2.24207. lr 5.758907e-04:  26%|██▌       | 4196/16329 [35:20<1:40:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4196: train loss 2.27359. lr 5.758794e-04:  26%|██▌       | 4196/16329 [35:20<1:40:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4196: train loss 2.27359. lr 5.758794e-04:  26%|██▌       | 4197/16329 [35:20<1:40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4197: train loss 2.26771. lr 5.758680e-04:  26%|██▌       | 4197/16329 [35:21<1:40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4197: train loss 2.26771. lr 5.758680e-04:  26%|██▌       | 4198/16329 [35:21<1:40:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4198: train loss 2.21691. lr 5.758567e-04:  26%|██▌       | 4198/16329 [35:21<1:40:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4198: train loss 2.21691. lr 5.758567e-04:  26%|██▌       | 4199/16329 [35:21<1:39:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4199: train loss 2.20031. lr 5.758453e-04:  26%|██▌       | 4199/16329 [35:22<1:39:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4199: train loss 2.20031. lr 5.758453e-04:  26%|██▌       | 4200/16329 [35:22<1:39:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4200: train loss 2.26354. lr 5.758340e-04:  26%|██▌       | 4200/16329 [35:22<1:39:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4200: train loss 2.26354. lr 5.758340e-04:  26%|██▌       | 4201/16329 [35:22<1:39:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4201: train loss 2.28734. lr 5.758226e-04:  26%|██▌       | 4201/16329 [35:23<1:39:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4201: train loss 2.28734. lr 5.758226e-04:  26%|██▌       | 4202/16329 [35:23<1:39:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4202: train loss 2.22988. lr 5.758113e-04:  26%|██▌       | 4202/16329 [35:23<1:39:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4202: train loss 2.22988. lr 5.758113e-04:  26%|██▌       | 4203/16329 [35:23<1:39:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4203: train loss 2.30598. lr 5.757999e-04:  26%|██▌       | 4203/16329 [35:24<1:39:39,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4203: train loss 2.30598. lr 5.757999e-04:  26%|██▌       | 4204/16329 [35:24<1:39:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4204: train loss 2.25250. lr 5.757886e-04:  26%|██▌       | 4204/16329 [35:24<1:39:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4204: train loss 2.25250. lr 5.757886e-04:  26%|██▌       | 4205/16329 [35:24<1:39:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4205: train loss 2.29853. lr 5.757772e-04:  26%|██▌       | 4205/16329 [35:25<1:39:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4205: train loss 2.29853. lr 5.757772e-04:  26%|██▌       | 4206/16329 [35:25<1:39:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4206: train loss 2.29034. lr 5.757658e-04:  26%|██▌       | 4206/16329 [35:25<1:39:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4206: train loss 2.29034. lr 5.757658e-04:  26%|██▌       | 4207/16329 [35:25<1:39:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4207: train loss 2.25280. lr 5.757545e-04:  26%|██▌       | 4207/16329 [35:26<1:39:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4207: train loss 2.25280. lr 5.757545e-04:  26%|██▌       | 4208/16329 [35:26<1:39:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4208: train loss 2.28096. lr 5.757431e-04:  26%|██▌       | 4208/16329 [35:26<1:39:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4208: train loss 2.28096. lr 5.757431e-04:  26%|██▌       | 4209/16329 [35:26<1:39:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4209: train loss 2.34184. lr 5.757317e-04:  26%|██▌       | 4209/16329 [35:27<1:39:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4209: train loss 2.34184. lr 5.757317e-04:  26%|██▌       | 4210/16329 [35:27<1:39:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4210: train loss 2.16902. lr 5.757204e-04:  26%|██▌       | 4210/16329 [35:27<1:39:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4210: train loss 2.16902. lr 5.757204e-04:  26%|██▌       | 4211/16329 [35:27<1:39:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4211: train loss 2.28967. lr 5.757090e-04:  26%|██▌       | 4211/16329 [35:28<1:39:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4211: train loss 2.28967. lr 5.757090e-04:  26%|██▌       | 4212/16329 [35:28<1:40:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4212: train loss 2.22760. lr 5.756976e-04:  26%|██▌       | 4212/16329 [35:28<1:40:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4212: train loss 2.22760. lr 5.756976e-04:  26%|██▌       | 4213/16329 [35:28<1:40:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4213: train loss 2.20301. lr 5.756862e-04:  26%|██▌       | 4213/16329 [35:29<1:40:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4213: train loss 2.20301. lr 5.756862e-04:  26%|██▌       | 4214/16329 [35:29<1:40:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4214: train loss 2.22432. lr 5.756749e-04:  26%|██▌       | 4214/16329 [35:29<1:40:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4214: train loss 2.22432. lr 5.756749e-04:  26%|██▌       | 4215/16329 [35:29<1:40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4215: train loss 2.24321. lr 5.756635e-04:  26%|██▌       | 4215/16329 [35:30<1:40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4215: train loss 2.24321. lr 5.756635e-04:  26%|██▌       | 4216/16329 [35:30<1:39:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4216: train loss 2.21037. lr 5.756521e-04:  26%|██▌       | 4216/16329 [35:30<1:39:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4216: train loss 2.21037. lr 5.756521e-04:  26%|██▌       | 4217/16329 [35:30<1:39:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4217: train loss 2.28656. lr 5.756407e-04:  26%|██▌       | 4217/16329 [35:31<1:39:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4217: train loss 2.28656. lr 5.756407e-04:  26%|██▌       | 4218/16329 [35:31<1:39:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4218: train loss 2.27643. lr 5.756293e-04:  26%|██▌       | 4218/16329 [35:31<1:39:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4218: train loss 2.27643. lr 5.756293e-04:  26%|██▌       | 4219/16329 [35:31<1:40:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4219: train loss 2.27831. lr 5.756179e-04:  26%|██▌       | 4219/16329 [35:32<1:40:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4219: train loss 2.27831. lr 5.756179e-04:  26%|██▌       | 4220/16329 [35:32<1:39:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4220: train loss 2.23534. lr 5.756065e-04:  26%|██▌       | 4220/16329 [35:32<1:39:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4220: train loss 2.23534. lr 5.756065e-04:  26%|██▌       | 4221/16329 [35:32<1:39:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4221: train loss 2.16228. lr 5.755951e-04:  26%|██▌       | 4221/16329 [35:33<1:39:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4221: train loss 2.16228. lr 5.755951e-04:  26%|██▌       | 4222/16329 [35:33<1:41:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4222: train loss 2.28654. lr 5.755837e-04:  26%|██▌       | 4222/16329 [35:33<1:41:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4222: train loss 2.28654. lr 5.755837e-04:  26%|██▌       | 4223/16329 [35:33<1:43:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4223: train loss 2.25655. lr 5.755723e-04:  26%|██▌       | 4223/16329 [35:34<1:43:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4223: train loss 2.25655. lr 5.755723e-04:  26%|██▌       | 4224/16329 [35:34<1:43:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4224: train loss 2.23911. lr 5.755609e-04:  26%|██▌       | 4224/16329 [35:34<1:43:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4224: train loss 2.23911. lr 5.755609e-04:  26%|██▌       | 4225/16329 [35:34<1:43:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4225: train loss 2.13176. lr 5.755495e-04:  26%|██▌       | 4225/16329 [35:35<1:43:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4225: train loss 2.13176. lr 5.755495e-04:  26%|██▌       | 4226/16329 [35:35<1:53:34,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4226: train loss 2.25961. lr 5.755381e-04:  26%|██▌       | 4226/16329 [35:35<1:53:34,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4226: train loss 2.25961. lr 5.755381e-04:  26%|██▌       | 4227/16329 [35:35<1:49:39,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4227: train loss 2.24493. lr 5.755267e-04:  26%|██▌       | 4227/16329 [35:36<1:49:39,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4227: train loss 2.24493. lr 5.755267e-04:  26%|██▌       | 4228/16329 [35:36<1:46:57,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4228: train loss 2.24671. lr 5.755152e-04:  26%|██▌       | 4228/16329 [35:36<1:46:57,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4228: train loss 2.24671. lr 5.755152e-04:  26%|██▌       | 4229/16329 [35:36<1:44:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4229: train loss 2.21392. lr 5.755038e-04:  26%|██▌       | 4229/16329 [35:37<1:44:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4229: train loss 2.21392. lr 5.755038e-04:  26%|██▌       | 4230/16329 [35:37<1:43:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4230: train loss 2.19277. lr 5.754924e-04:  26%|██▌       | 4230/16329 [35:37<1:43:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4230: train loss 2.19277. lr 5.754924e-04:  26%|██▌       | 4231/16329 [35:37<1:42:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4231: train loss 2.23120. lr 5.754810e-04:  26%|██▌       | 4231/16329 [35:38<1:42:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4231: train loss 2.23120. lr 5.754810e-04:  26%|██▌       | 4232/16329 [35:38<1:41:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4232: train loss 2.29880. lr 5.754695e-04:  26%|██▌       | 4232/16329 [35:38<1:41:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4232: train loss 2.29880. lr 5.754695e-04:  26%|██▌       | 4233/16329 [35:38<1:40:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4233: train loss 2.27962. lr 5.754581e-04:  26%|██▌       | 4233/16329 [35:39<1:40:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4233: train loss 2.27962. lr 5.754581e-04:  26%|██▌       | 4234/16329 [35:39<1:40:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4234: train loss 2.20330. lr 5.754467e-04:  26%|██▌       | 4234/16329 [35:39<1:40:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4234: train loss 2.20330. lr 5.754467e-04:  26%|██▌       | 4235/16329 [35:39<1:40:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4235: train loss 2.23521. lr 5.754352e-04:  26%|██▌       | 4235/16329 [35:40<1:40:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4235: train loss 2.23521. lr 5.754352e-04:  26%|██▌       | 4236/16329 [35:40<1:39:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4236: train loss 2.24941. lr 5.754238e-04:  26%|██▌       | 4236/16329 [35:40<1:39:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4236: train loss 2.24941. lr 5.754238e-04:  26%|██▌       | 4237/16329 [35:40<1:40:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4237: train loss 2.25582. lr 5.754124e-04:  26%|██▌       | 4237/16329 [35:41<1:40:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4237: train loss 2.25582. lr 5.754124e-04:  26%|██▌       | 4238/16329 [35:41<1:40:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4238: train loss 2.22389. lr 5.754009e-04:  26%|██▌       | 4238/16329 [35:41<1:40:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4238: train loss 2.22389. lr 5.754009e-04:  26%|██▌       | 4239/16329 [35:41<1:39:50,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4239: train loss 2.25071. lr 5.753895e-04:  26%|██▌       | 4239/16329 [35:42<1:39:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4239: train loss 2.25071. lr 5.753895e-04:  26%|██▌       | 4240/16329 [35:42<1:39:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4240: train loss 2.18138. lr 5.753780e-04:  26%|██▌       | 4240/16329 [35:42<1:39:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4240: train loss 2.18138. lr 5.753780e-04:  26%|██▌       | 4241/16329 [35:42<1:39:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4241: train loss 2.25772. lr 5.753666e-04:  26%|██▌       | 4241/16329 [35:43<1:39:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4241: train loss 2.25772. lr 5.753666e-04:  26%|██▌       | 4242/16329 [35:43<1:39:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4242: train loss 2.28086. lr 5.753551e-04:  26%|██▌       | 4242/16329 [35:43<1:39:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4242: train loss 2.28086. lr 5.753551e-04:  26%|██▌       | 4243/16329 [35:43<1:39:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4243: train loss 2.32592. lr 5.753437e-04:  26%|██▌       | 4243/16329 [35:44<1:39:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4243: train loss 2.32592. lr 5.753437e-04:  26%|██▌       | 4244/16329 [35:44<1:39:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4244: train loss 2.25740. lr 5.753322e-04:  26%|██▌       | 4244/16329 [35:44<1:39:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4244: train loss 2.25740. lr 5.753322e-04:  26%|██▌       | 4245/16329 [35:44<1:39:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4245: train loss 2.21969. lr 5.753207e-04:  26%|██▌       | 4245/16329 [35:45<1:39:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4245: train loss 2.21969. lr 5.753207e-04:  26%|██▌       | 4246/16329 [35:45<1:39:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4246: train loss 2.25968. lr 5.753093e-04:  26%|██▌       | 4246/16329 [35:45<1:39:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4246: train loss 2.25968. lr 5.753093e-04:  26%|██▌       | 4247/16329 [35:45<1:39:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4247: train loss 2.26716. lr 5.752978e-04:  26%|██▌       | 4247/16329 [35:46<1:39:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4247: train loss 2.26716. lr 5.752978e-04:  26%|██▌       | 4248/16329 [35:46<1:39:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4248: train loss 2.29628. lr 5.752863e-04:  26%|██▌       | 4248/16329 [35:46<1:39:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4248: train loss 2.29628. lr 5.752863e-04:  26%|██▌       | 4249/16329 [35:46<1:39:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4249: train loss 2.24376. lr 5.752749e-04:  26%|██▌       | 4249/16329 [35:47<1:39:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4249: train loss 2.24376. lr 5.752749e-04:  26%|██▌       | 4250/16329 [35:47<1:39:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4250: train loss 2.26061. lr 5.752634e-04:  26%|██▌       | 4250/16329 [35:47<1:39:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4250: train loss 2.26061. lr 5.752634e-04:  26%|██▌       | 4251/16329 [35:47<1:39:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4251: train loss 2.22675. lr 5.752519e-04:  26%|██▌       | 4251/16329 [35:48<1:39:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4251: train loss 2.22675. lr 5.752519e-04:  26%|██▌       | 4252/16329 [35:48<1:39:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4252: train loss 2.25168. lr 5.752404e-04:  26%|██▌       | 4252/16329 [35:48<1:39:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4252: train loss 2.25168. lr 5.752404e-04:  26%|██▌       | 4253/16329 [35:48<1:39:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4253: train loss 2.25742. lr 5.752289e-04:  26%|██▌       | 4253/16329 [35:49<1:39:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4253: train loss 2.25742. lr 5.752289e-04:  26%|██▌       | 4254/16329 [35:49<1:39:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4254: train loss 2.25755. lr 5.752175e-04:  26%|██▌       | 4254/16329 [35:49<1:39:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4254: train loss 2.25755. lr 5.752175e-04:  26%|██▌       | 4255/16329 [35:49<1:39:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4255: train loss 2.19592. lr 5.752060e-04:  26%|██▌       | 4255/16329 [35:50<1:39:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4255: train loss 2.19592. lr 5.752060e-04:  26%|██▌       | 4256/16329 [35:50<1:39:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4256: train loss 2.30320. lr 5.751945e-04:  26%|██▌       | 4256/16329 [35:50<1:39:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4256: train loss 2.30320. lr 5.751945e-04:  26%|██▌       | 4257/16329 [35:50<1:39:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4257: train loss 2.28747. lr 5.751830e-04:  26%|██▌       | 4257/16329 [35:51<1:39:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4257: train loss 2.28747. lr 5.751830e-04:  26%|██▌       | 4258/16329 [35:51<1:39:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4258: train loss 2.23614. lr 5.751715e-04:  26%|██▌       | 4258/16329 [35:51<1:39:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4258: train loss 2.23614. lr 5.751715e-04:  26%|██▌       | 4259/16329 [35:51<1:39:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4259: train loss 2.18619. lr 5.751600e-04:  26%|██▌       | 4259/16329 [35:52<1:39:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4259: train loss 2.18619. lr 5.751600e-04:  26%|██▌       | 4260/16329 [35:52<1:39:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4260: train loss 2.26251. lr 5.751485e-04:  26%|██▌       | 4260/16329 [35:52<1:39:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4260: train loss 2.26251. lr 5.751485e-04:  26%|██▌       | 4261/16329 [35:52<1:50:46,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4261: train loss 2.23759. lr 5.751370e-04:  26%|██▌       | 4261/16329 [35:53<1:50:46,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4261: train loss 2.23759. lr 5.751370e-04:  26%|██▌       | 4262/16329 [35:53<1:47:30,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4262: train loss 2.22056. lr 5.751255e-04:  26%|██▌       | 4262/16329 [35:53<1:47:30,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4262: train loss 2.22056. lr 5.751255e-04:  26%|██▌       | 4263/16329 [35:53<1:45:10,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4263: train loss 2.27460. lr 5.751140e-04:  26%|██▌       | 4263/16329 [35:54<1:45:10,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4263: train loss 2.27460. lr 5.751140e-04:  26%|██▌       | 4264/16329 [35:54<1:43:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4264: train loss 2.28820. lr 5.751025e-04:  26%|██▌       | 4264/16329 [35:54<1:43:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4264: train loss 2.28820. lr 5.751025e-04:  26%|██▌       | 4265/16329 [35:54<1:42:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4265: train loss 2.28213. lr 5.750910e-04:  26%|██▌       | 4265/16329 [35:55<1:42:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4265: train loss 2.28213. lr 5.750910e-04:  26%|██▌       | 4266/16329 [35:55<1:41:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4266: train loss 2.21975. lr 5.750794e-04:  26%|██▌       | 4266/16329 [35:55<1:41:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4266: train loss 2.21975. lr 5.750794e-04:  26%|██▌       | 4267/16329 [35:55<1:40:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4267: train loss 2.18832. lr 5.750679e-04:  26%|██▌       | 4267/16329 [35:56<1:40:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4267: train loss 2.18832. lr 5.750679e-04:  26%|██▌       | 4268/16329 [35:56<1:40:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4268: train loss 2.28109. lr 5.750564e-04:  26%|██▌       | 4268/16329 [35:56<1:40:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4268: train loss 2.28109. lr 5.750564e-04:  26%|██▌       | 4269/16329 [35:56<1:40:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4269: train loss 2.23170. lr 5.750449e-04:  26%|██▌       | 4269/16329 [35:57<1:40:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4269: train loss 2.23170. lr 5.750449e-04:  26%|██▌       | 4270/16329 [35:57<1:39:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4270: train loss 2.17878. lr 5.750334e-04:  26%|██▌       | 4270/16329 [35:57<1:39:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4270: train loss 2.17878. lr 5.750334e-04:  26%|██▌       | 4271/16329 [35:57<1:39:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4271: train loss 2.21459. lr 5.750218e-04:  26%|██▌       | 4271/16329 [35:58<1:39:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4271: train loss 2.21459. lr 5.750218e-04:  26%|██▌       | 4272/16329 [35:58<1:39:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4272: train loss 2.24203. lr 5.750103e-04:  26%|██▌       | 4272/16329 [35:58<1:39:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4272: train loss 2.24203. lr 5.750103e-04:  26%|██▌       | 4273/16329 [35:58<1:39:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4273: train loss 2.23524. lr 5.749988e-04:  26%|██▌       | 4273/16329 [35:59<1:39:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4273: train loss 2.23524. lr 5.749988e-04:  26%|██▌       | 4274/16329 [35:59<1:39:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4274: train loss 2.24444. lr 5.749872e-04:  26%|██▌       | 4274/16329 [35:59<1:39:32,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4274: train loss 2.24444. lr 5.749872e-04:  26%|██▌       | 4275/16329 [35:59<1:39:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4275: train loss 2.26078. lr 5.749757e-04:  26%|██▌       | 4275/16329 [36:00<1:39:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4275: train loss 2.26078. lr 5.749757e-04:  26%|██▌       | 4276/16329 [36:00<1:40:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4276: train loss 2.23700. lr 5.749642e-04:  26%|██▌       | 4276/16329 [36:00<1:40:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4276: train loss 2.23700. lr 5.749642e-04:  26%|██▌       | 4277/16329 [36:00<1:40:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4277: train loss 2.23465. lr 5.749526e-04:  26%|██▌       | 4277/16329 [36:01<1:40:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4277: train loss 2.23465. lr 5.749526e-04:  26%|██▌       | 4278/16329 [36:01<1:39:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4278: train loss 2.26007. lr 5.749411e-04:  26%|██▌       | 4278/16329 [36:01<1:39:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4278: train loss 2.26007. lr 5.749411e-04:  26%|██▌       | 4279/16329 [36:01<1:39:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4279: train loss 2.23739. lr 5.749295e-04:  26%|██▌       | 4279/16329 [36:02<1:39:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4279: train loss 2.23739. lr 5.749295e-04:  26%|██▌       | 4280/16329 [36:02<1:39:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4280: train loss 2.14385. lr 5.749180e-04:  26%|██▌       | 4280/16329 [36:02<1:39:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4280: train loss 2.14385. lr 5.749180e-04:  26%|██▌       | 4281/16329 [36:02<1:39:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4281: train loss 2.25076. lr 5.749064e-04:  26%|██▌       | 4281/16329 [36:03<1:39:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4281: train loss 2.25076. lr 5.749064e-04:  26%|██▌       | 4282/16329 [36:03<1:39:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4282: train loss 2.21381. lr 5.748949e-04:  26%|██▌       | 4282/16329 [36:03<1:39:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4282: train loss 2.21381. lr 5.748949e-04:  26%|██▌       | 4283/16329 [36:03<1:39:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4283: train loss 2.24940. lr 5.748833e-04:  26%|██▌       | 4283/16329 [36:04<1:39:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4283: train loss 2.24940. lr 5.748833e-04:  26%|██▌       | 4284/16329 [36:04<1:39:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4284: train loss 2.27715. lr 5.748717e-04:  26%|██▌       | 4284/16329 [36:04<1:39:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4284: train loss 2.27715. lr 5.748717e-04:  26%|██▌       | 4285/16329 [36:04<1:38:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4285: train loss 2.27190. lr 5.748602e-04:  26%|██▌       | 4285/16329 [36:05<1:38:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4285: train loss 2.27190. lr 5.748602e-04:  26%|██▌       | 4286/16329 [36:05<1:57:22,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 4286: train loss 2.28304. lr 5.748486e-04:  26%|██▌       | 4286/16329 [36:05<1:57:22,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 4286: train loss 2.28304. lr 5.748486e-04:  26%|██▋       | 4287/16329 [36:05<1:51:41,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 4287: train loss 2.24273. lr 5.748370e-04:  26%|██▋       | 4287/16329 [36:06<1:51:41,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 4287: train loss 2.24273. lr 5.748370e-04:  26%|██▋       | 4288/16329 [36:06<1:47:43,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4288: train loss 2.24711. lr 5.748255e-04:  26%|██▋       | 4288/16329 [36:06<1:47:43,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4288: train loss 2.24711. lr 5.748255e-04:  26%|██▋       | 4289/16329 [36:06<1:44:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4289: train loss 2.23714. lr 5.748139e-04:  26%|██▋       | 4289/16329 [36:07<1:44:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4289: train loss 2.23714. lr 5.748139e-04:  26%|██▋       | 4290/16329 [36:07<1:43:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4290: train loss 2.27996. lr 5.748023e-04:  26%|██▋       | 4290/16329 [36:07<1:43:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4290: train loss 2.27996. lr 5.748023e-04:  26%|██▋       | 4291/16329 [36:07<1:41:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4291: train loss 2.24162. lr 5.747907e-04:  26%|██▋       | 4291/16329 [36:08<1:41:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4291: train loss 2.24162. lr 5.747907e-04:  26%|██▋       | 4292/16329 [36:08<1:41:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4292: train loss 2.25397. lr 5.747792e-04:  26%|██▋       | 4292/16329 [36:08<1:41:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4292: train loss 2.25397. lr 5.747792e-04:  26%|██▋       | 4293/16329 [36:08<1:40:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4293: train loss 2.26456. lr 5.747676e-04:  26%|██▋       | 4293/16329 [36:09<1:40:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4293: train loss 2.26456. lr 5.747676e-04:  26%|██▋       | 4294/16329 [36:09<1:39:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4294: train loss 2.33441. lr 5.747560e-04:  26%|██▋       | 4294/16329 [36:09<1:39:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4294: train loss 2.33441. lr 5.747560e-04:  26%|██▋       | 4295/16329 [36:09<1:39:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4295: train loss 2.22999. lr 5.747444e-04:  26%|██▋       | 4295/16329 [36:10<1:39:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4295: train loss 2.22999. lr 5.747444e-04:  26%|██▋       | 4296/16329 [36:10<1:39:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4296: train loss 2.25668. lr 5.747328e-04:  26%|██▋       | 4296/16329 [36:10<1:39:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4296: train loss 2.25668. lr 5.747328e-04:  26%|██▋       | 4297/16329 [36:10<1:39:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4297: train loss 2.26934. lr 5.747212e-04:  26%|██▋       | 4297/16329 [36:11<1:39:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4297: train loss 2.26934. lr 5.747212e-04:  26%|██▋       | 4298/16329 [36:11<1:39:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4298: train loss 2.21326. lr 5.747096e-04:  26%|██▋       | 4298/16329 [36:11<1:39:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4298: train loss 2.21326. lr 5.747096e-04:  26%|██▋       | 4299/16329 [36:11<1:39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4299: train loss 2.22129. lr 5.746980e-04:  26%|██▋       | 4299/16329 [36:12<1:39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4299: train loss 2.22129. lr 5.746980e-04:  26%|██▋       | 4300/16329 [36:12<1:39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4300: train loss 2.28887. lr 5.746864e-04:  26%|██▋       | 4300/16329 [36:12<1:39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4300: train loss 2.28887. lr 5.746864e-04:  26%|██▋       | 4301/16329 [36:12<1:39:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4301: train loss 2.24049. lr 5.746748e-04:  26%|██▋       | 4301/16329 [36:13<1:39:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4301: train loss 2.24049. lr 5.746748e-04:  26%|██▋       | 4302/16329 [36:13<1:39:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4302: train loss 2.25928. lr 5.746632e-04:  26%|██▋       | 4302/16329 [36:13<1:39:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4302: train loss 2.25928. lr 5.746632e-04:  26%|██▋       | 4303/16329 [36:13<1:39:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4303: train loss 2.24946. lr 5.746516e-04:  26%|██▋       | 4303/16329 [36:14<1:39:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4303: train loss 2.24946. lr 5.746516e-04:  26%|██▋       | 4304/16329 [36:14<1:39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4304: train loss 2.29261. lr 5.746400e-04:  26%|██▋       | 4304/16329 [36:14<1:39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4304: train loss 2.29261. lr 5.746400e-04:  26%|██▋       | 4305/16329 [36:14<1:39:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4305: train loss 2.22340. lr 5.746284e-04:  26%|██▋       | 4305/16329 [36:15<1:39:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4305: train loss 2.22340. lr 5.746284e-04:  26%|██▋       | 4306/16329 [36:15<1:38:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4306: train loss 2.23820. lr 5.746167e-04:  26%|██▋       | 4306/16329 [36:15<1:38:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4306: train loss 2.23820. lr 5.746167e-04:  26%|██▋       | 4307/16329 [36:15<1:39:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4307: train loss 2.19731. lr 5.746051e-04:  26%|██▋       | 4307/16329 [36:16<1:39:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4307: train loss 2.19731. lr 5.746051e-04:  26%|██▋       | 4308/16329 [36:16<1:38:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4308: train loss 2.22317. lr 5.745935e-04:  26%|██▋       | 4308/16329 [36:16<1:38:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4308: train loss 2.22317. lr 5.745935e-04:  26%|██▋       | 4309/16329 [36:16<1:39:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4309: train loss 2.27379. lr 5.745819e-04:  26%|██▋       | 4309/16329 [36:17<1:39:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4309: train loss 2.27379. lr 5.745819e-04:  26%|██▋       | 4310/16329 [36:17<1:38:55,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4310: train loss 2.26089. lr 5.745703e-04:  26%|██▋       | 4310/16329 [36:17<1:38:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4310: train loss 2.26089. lr 5.745703e-04:  26%|██▋       | 4311/16329 [36:17<1:38:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4311: train loss 2.26070. lr 5.745586e-04:  26%|██▋       | 4311/16329 [36:18<1:38:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4311: train loss 2.26070. lr 5.745586e-04:  26%|██▋       | 4312/16329 [36:18<1:39:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4312: train loss 2.18898. lr 5.745470e-04:  26%|██▋       | 4312/16329 [36:19<1:39:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4312: train loss 2.18898. lr 5.745470e-04:  26%|██▋       | 4313/16329 [36:19<1:54:27,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 4313: train loss 2.23530. lr 5.745354e-04:  26%|██▋       | 4313/16329 [36:19<1:54:27,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 4313: train loss 2.23530. lr 5.745354e-04:  26%|██▋       | 4314/16329 [36:19<1:49:44,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4314: train loss 2.22198. lr 5.745237e-04:  26%|██▋       | 4314/16329 [36:20<1:49:44,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4314: train loss 2.22198. lr 5.745237e-04:  26%|██▋       | 4315/16329 [36:20<1:46:11,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4315: train loss 2.22192. lr 5.745121e-04:  26%|██▋       | 4315/16329 [36:20<1:46:11,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4315: train loss 2.22192. lr 5.745121e-04:  26%|██▋       | 4316/16329 [36:20<1:44:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4316: train loss 2.26675. lr 5.745004e-04:  26%|██▋       | 4316/16329 [36:21<1:44:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4316: train loss 2.26675. lr 5.745004e-04:  26%|██▋       | 4317/16329 [36:21<1:42:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4317: train loss 2.24116. lr 5.744888e-04:  26%|██▋       | 4317/16329 [36:21<1:42:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4317: train loss 2.24116. lr 5.744888e-04:  26%|██▋       | 4318/16329 [36:21<1:41:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4318: train loss 2.27042. lr 5.744771e-04:  26%|██▋       | 4318/16329 [36:22<1:41:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4318: train loss 2.27042. lr 5.744771e-04:  26%|██▋       | 4319/16329 [36:22<1:40:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4319: train loss 2.24427. lr 5.744655e-04:  26%|██▋       | 4319/16329 [36:22<1:40:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4319: train loss 2.24427. lr 5.744655e-04:  26%|██▋       | 4320/16329 [36:22<1:40:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4320: train loss 2.25693. lr 5.744538e-04:  26%|██▋       | 4320/16329 [36:23<1:40:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4320: train loss 2.25693. lr 5.744538e-04:  26%|██▋       | 4321/16329 [36:23<1:39:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4321: train loss 2.23039. lr 5.744422e-04:  26%|██▋       | 4321/16329 [36:23<1:39:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4321: train loss 2.23039. lr 5.744422e-04:  26%|██▋       | 4322/16329 [36:23<1:39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4322: train loss 2.22109. lr 5.744305e-04:  26%|██▋       | 4322/16329 [36:24<1:39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4322: train loss 2.22109. lr 5.744305e-04:  26%|██▋       | 4323/16329 [36:24<1:39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4323: train loss 2.22086. lr 5.744189e-04:  26%|██▋       | 4323/16329 [36:24<1:39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4323: train loss 2.22086. lr 5.744189e-04:  26%|██▋       | 4324/16329 [36:24<1:39:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4324: train loss 2.22538. lr 5.744072e-04:  26%|██▋       | 4324/16329 [36:24<1:39:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4324: train loss 2.22538. lr 5.744072e-04:  26%|██▋       | 4325/16329 [36:24<1:38:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4325: train loss 2.25934. lr 5.743955e-04:  26%|██▋       | 4325/16329 [36:25<1:38:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4325: train loss 2.25934. lr 5.743955e-04:  26%|██▋       | 4326/16329 [36:25<1:38:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4326: train loss 2.25033. lr 5.743839e-04:  26%|██▋       | 4326/16329 [36:25<1:38:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4326: train loss 2.25033. lr 5.743839e-04:  26%|██▋       | 4327/16329 [36:25<1:38:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4327: train loss 2.22315. lr 5.743722e-04:  26%|██▋       | 4327/16329 [36:26<1:38:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4327: train loss 2.22315. lr 5.743722e-04:  27%|██▋       | 4328/16329 [36:26<1:38:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4328: train loss 2.24274. lr 5.743605e-04:  27%|██▋       | 4328/16329 [36:26<1:38:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4328: train loss 2.24274. lr 5.743605e-04:  27%|██▋       | 4329/16329 [36:26<1:38:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4329: train loss 2.25842. lr 5.743489e-04:  27%|██▋       | 4329/16329 [36:27<1:38:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4329: train loss 2.25842. lr 5.743489e-04:  27%|██▋       | 4330/16329 [36:27<1:39:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4330: train loss 2.25756. lr 5.743372e-04:  27%|██▋       | 4330/16329 [36:27<1:39:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4330: train loss 2.25756. lr 5.743372e-04:  27%|██▋       | 4331/16329 [36:27<1:39:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4331: train loss 2.20780. lr 5.743255e-04:  27%|██▋       | 4331/16329 [36:28<1:39:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4331: train loss 2.20780. lr 5.743255e-04:  27%|██▋       | 4332/16329 [36:28<1:38:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4332: train loss 2.22753. lr 5.743138e-04:  27%|██▋       | 4332/16329 [36:28<1:38:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4332: train loss 2.22753. lr 5.743138e-04:  27%|██▋       | 4333/16329 [36:28<1:38:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4333: train loss 2.23232. lr 5.743021e-04:  27%|██▋       | 4333/16329 [36:29<1:38:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4333: train loss 2.23232. lr 5.743021e-04:  27%|██▋       | 4334/16329 [36:29<1:38:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4334: train loss 2.22856. lr 5.742904e-04:  27%|██▋       | 4334/16329 [36:29<1:38:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4334: train loss 2.22856. lr 5.742904e-04:  27%|██▋       | 4335/16329 [36:29<1:38:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4335: train loss 2.18329. lr 5.742787e-04:  27%|██▋       | 4335/16329 [36:30<1:38:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4335: train loss 2.18329. lr 5.742787e-04:  27%|██▋       | 4336/16329 [36:30<1:38:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4336: train loss 2.19544. lr 5.742671e-04:  27%|██▋       | 4336/16329 [36:30<1:38:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4336: train loss 2.19544. lr 5.742671e-04:  27%|██▋       | 4337/16329 [36:30<1:38:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4337: train loss 2.18931. lr 5.742554e-04:  27%|██▋       | 4337/16329 [36:31<1:38:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4337: train loss 2.18931. lr 5.742554e-04:  27%|██▋       | 4338/16329 [36:31<1:42:55,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4338: train loss 2.18257. lr 5.742437e-04:  27%|██▋       | 4338/16329 [36:32<1:42:55,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4338: train loss 2.18257. lr 5.742437e-04:  27%|██▋       | 4339/16329 [36:32<1:45:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4339: train loss 2.21375. lr 5.742320e-04:  27%|██▋       | 4339/16329 [36:32<1:45:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4339: train loss 2.21375. lr 5.742320e-04:  27%|██▋       | 4340/16329 [36:32<1:46:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4340: train loss 2.14532. lr 5.742203e-04:  27%|██▋       | 4340/16329 [36:33<1:46:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4340: train loss 2.14532. lr 5.742203e-04:  27%|██▋       | 4341/16329 [36:33<1:46:09,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4341: train loss 2.20682. lr 5.742085e-04:  27%|██▋       | 4341/16329 [36:33<1:46:09,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4341: train loss 2.20682. lr 5.742085e-04:  27%|██▋       | 4342/16329 [36:33<1:45:05,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4342: train loss 2.25044. lr 5.741968e-04:  27%|██▋       | 4342/16329 [36:34<1:45:05,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4342: train loss 2.25044. lr 5.741968e-04:  27%|██▋       | 4343/16329 [36:34<1:44:01,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4343: train loss 2.25230. lr 5.741851e-04:  27%|██▋       | 4343/16329 [36:34<1:44:01,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4343: train loss 2.25230. lr 5.741851e-04:  27%|██▋       | 4344/16329 [36:34<1:42:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4344: train loss 2.22838. lr 5.741734e-04:  27%|██▋       | 4344/16329 [36:35<1:42:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4344: train loss 2.22838. lr 5.741734e-04:  27%|██▋       | 4345/16329 [36:35<1:41:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4345: train loss 2.21044. lr 5.741617e-04:  27%|██▋       | 4345/16329 [36:35<1:41:59,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4345: train loss 2.21044. lr 5.741617e-04:  27%|██▋       | 4346/16329 [36:35<1:41:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4346: train loss 2.22092. lr 5.741500e-04:  27%|██▋       | 4346/16329 [36:36<1:41:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4346: train loss 2.22092. lr 5.741500e-04:  27%|██▋       | 4347/16329 [36:36<1:40:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4347: train loss 2.17864. lr 5.741383e-04:  27%|██▋       | 4347/16329 [36:36<1:40:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4347: train loss 2.17864. lr 5.741383e-04:  27%|██▋       | 4348/16329 [36:36<1:39:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4348: train loss 2.16641. lr 5.741265e-04:  27%|██▋       | 4348/16329 [36:37<1:39:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4348: train loss 2.16641. lr 5.741265e-04:  27%|██▋       | 4349/16329 [36:37<1:39:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4349: train loss 2.22424. lr 5.741148e-04:  27%|██▋       | 4349/16329 [36:37<1:39:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4349: train loss 2.22424. lr 5.741148e-04:  27%|██▋       | 4350/16329 [36:37<1:39:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4350: train loss 2.26060. lr 5.741031e-04:  27%|██▋       | 4350/16329 [36:38<1:39:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4350: train loss 2.26060. lr 5.741031e-04:  27%|██▋       | 4351/16329 [36:38<1:38:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4351: train loss 2.24669. lr 5.740914e-04:  27%|██▋       | 4351/16329 [36:38<1:38:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4351: train loss 2.24669. lr 5.740914e-04:  27%|██▋       | 4352/16329 [36:38<1:38:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4352: train loss 2.25445. lr 5.740796e-04:  27%|██▋       | 4352/16329 [36:39<1:38:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4352: train loss 2.25445. lr 5.740796e-04:  27%|██▋       | 4353/16329 [36:39<1:48:50,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4353: train loss 2.21061. lr 5.740679e-04:  27%|██▋       | 4353/16329 [36:39<1:48:50,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4353: train loss 2.21061. lr 5.740679e-04:  27%|██▋       | 4354/16329 [36:39<1:45:51,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4354: train loss 2.22629. lr 5.740561e-04:  27%|██▋       | 4354/16329 [36:40<1:45:51,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4354: train loss 2.22629. lr 5.740561e-04:  27%|██▋       | 4355/16329 [36:40<1:43:24,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4355: train loss 2.22618. lr 5.740444e-04:  27%|██▋       | 4355/16329 [36:40<1:43:24,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4355: train loss 2.22618. lr 5.740444e-04:  27%|██▋       | 4356/16329 [36:40<1:41:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4356: train loss 2.24624. lr 5.740327e-04:  27%|██▋       | 4356/16329 [36:41<1:41:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4356: train loss 2.24624. lr 5.740327e-04:  27%|██▋       | 4357/16329 [36:41<1:40:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4357: train loss 2.20223. lr 5.740209e-04:  27%|██▋       | 4357/16329 [36:41<1:40:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4357: train loss 2.20223. lr 5.740209e-04:  27%|██▋       | 4358/16329 [36:41<1:39:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4358: train loss 2.22695. lr 5.740092e-04:  27%|██▋       | 4358/16329 [36:42<1:39:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4358: train loss 2.22695. lr 5.740092e-04:  27%|██▋       | 4359/16329 [36:42<1:39:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4359: train loss 2.22838. lr 5.739974e-04:  27%|██▋       | 4359/16329 [36:42<1:39:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4359: train loss 2.22838. lr 5.739974e-04:  27%|██▋       | 4360/16329 [36:42<1:39:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4360: train loss 2.16760. lr 5.739857e-04:  27%|██▋       | 4360/16329 [36:43<1:39:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4360: train loss 2.16760. lr 5.739857e-04:  27%|██▋       | 4361/16329 [36:43<1:38:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4361: train loss 2.14894. lr 5.739739e-04:  27%|██▋       | 4361/16329 [36:43<1:38:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4361: train loss 2.14894. lr 5.739739e-04:  27%|██▋       | 4362/16329 [36:43<1:41:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4362: train loss 2.25026. lr 5.739621e-04:  27%|██▋       | 4362/16329 [36:44<1:41:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4362: train loss 2.25026. lr 5.739621e-04:  27%|██▋       | 4363/16329 [36:44<1:42:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4363: train loss 2.24108. lr 5.739504e-04:  27%|██▋       | 4363/16329 [36:44<1:42:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4363: train loss 2.24108. lr 5.739504e-04:  27%|██▋       | 4364/16329 [36:44<1:42:55,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4364: train loss 2.23352. lr 5.739386e-04:  27%|██▋       | 4364/16329 [36:45<1:42:55,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4364: train loss 2.23352. lr 5.739386e-04:  27%|██▋       | 4365/16329 [36:45<1:42:55,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4365: train loss 2.22916. lr 5.739268e-04:  27%|██▋       | 4365/16329 [36:45<1:42:55,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4365: train loss 2.22916. lr 5.739268e-04:  27%|██▋       | 4366/16329 [36:45<1:42:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4366: train loss 2.25825. lr 5.739151e-04:  27%|██▋       | 4366/16329 [36:46<1:42:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4366: train loss 2.25825. lr 5.739151e-04:  27%|██▋       | 4367/16329 [36:46<1:41:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4367: train loss 2.21499. lr 5.739033e-04:  27%|██▋       | 4367/16329 [36:46<1:41:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4367: train loss 2.21499. lr 5.739033e-04:  27%|██▋       | 4368/16329 [36:46<1:41:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4368: train loss 2.24356. lr 5.738915e-04:  27%|██▋       | 4368/16329 [36:47<1:41:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4368: train loss 2.24356. lr 5.738915e-04:  27%|██▋       | 4369/16329 [36:47<1:40:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4369: train loss 2.20506. lr 5.738798e-04:  27%|██▋       | 4369/16329 [36:47<1:40:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4369: train loss 2.20506. lr 5.738798e-04:  27%|██▋       | 4370/16329 [36:47<1:40:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4370: train loss 2.20745. lr 5.738680e-04:  27%|██▋       | 4370/16329 [36:48<1:40:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4370: train loss 2.20745. lr 5.738680e-04:  27%|██▋       | 4371/16329 [36:48<1:39:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4371: train loss 2.15725. lr 5.738562e-04:  27%|██▋       | 4371/16329 [36:48<1:39:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4371: train loss 2.15725. lr 5.738562e-04:  27%|██▋       | 4372/16329 [36:48<1:39:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4372: train loss 2.25105. lr 5.738444e-04:  27%|██▋       | 4372/16329 [36:49<1:39:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4372: train loss 2.25105. lr 5.738444e-04:  27%|██▋       | 4373/16329 [36:49<1:38:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4373: train loss 2.25003. lr 5.738326e-04:  27%|██▋       | 4373/16329 [36:49<1:38:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4373: train loss 2.25003. lr 5.738326e-04:  27%|██▋       | 4374/16329 [36:49<1:38:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4374: train loss 2.19703. lr 5.738208e-04:  27%|██▋       | 4374/16329 [36:50<1:38:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4374: train loss 2.19703. lr 5.738208e-04:  27%|██▋       | 4375/16329 [36:50<1:38:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4375: train loss 2.25176. lr 5.738090e-04:  27%|██▋       | 4375/16329 [36:50<1:38:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4375: train loss 2.25176. lr 5.738090e-04:  27%|██▋       | 4376/16329 [36:50<1:38:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4376: train loss 2.20830. lr 5.737972e-04:  27%|██▋       | 4376/16329 [36:51<1:38:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4376: train loss 2.20830. lr 5.737972e-04:  27%|██▋       | 4377/16329 [36:51<1:38:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4377: train loss 2.21968. lr 5.737854e-04:  27%|██▋       | 4377/16329 [36:51<1:38:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4377: train loss 2.21968. lr 5.737854e-04:  27%|██▋       | 4378/16329 [36:51<1:38:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4378: train loss 2.19433. lr 5.737736e-04:  27%|██▋       | 4378/16329 [36:52<1:38:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4378: train loss 2.19433. lr 5.737736e-04:  27%|██▋       | 4379/16329 [36:52<1:38:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4379: train loss 2.19259. lr 5.737618e-04:  27%|██▋       | 4379/16329 [36:52<1:38:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4379: train loss 2.19259. lr 5.737618e-04:  27%|██▋       | 4380/16329 [36:52<1:37:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4380: train loss 2.22774. lr 5.737500e-04:  27%|██▋       | 4380/16329 [36:53<1:37:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4380: train loss 2.22774. lr 5.737500e-04:  27%|██▋       | 4381/16329 [36:53<1:37:37,  2.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4381: train loss 2.17703. lr 5.737382e-04:  27%|██▋       | 4381/16329 [36:53<1:37:37,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4381: train loss 2.17703. lr 5.737382e-04:  27%|██▋       | 4382/16329 [36:53<1:37:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4382: train loss 2.23648. lr 5.737264e-04:  27%|██▋       | 4382/16329 [36:54<1:37:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4382: train loss 2.23648. lr 5.737264e-04:  27%|██▋       | 4383/16329 [36:54<1:37:37,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4383: train loss 2.14184. lr 5.737146e-04:  27%|██▋       | 4383/16329 [36:54<1:37:37,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4383: train loss 2.14184. lr 5.737146e-04:  27%|██▋       | 4384/16329 [36:54<1:37:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4384: train loss 2.19759. lr 5.737028e-04:  27%|██▋       | 4384/16329 [36:55<1:37:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4384: train loss 2.19759. lr 5.737028e-04:  27%|██▋       | 4385/16329 [36:55<1:37:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4385: train loss 2.15483. lr 5.736910e-04:  27%|██▋       | 4385/16329 [36:55<1:37:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4385: train loss 2.15483. lr 5.736910e-04:  27%|██▋       | 4386/16329 [36:55<1:37:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4386: train loss 2.16577. lr 5.736792e-04:  27%|██▋       | 4386/16329 [36:56<1:37:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4386: train loss 2.16577. lr 5.736792e-04:  27%|██▋       | 4387/16329 [36:56<1:38:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4387: train loss 2.20459. lr 5.736673e-04:  27%|██▋       | 4387/16329 [36:56<1:38:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4387: train loss 2.20459. lr 5.736673e-04:  27%|██▋       | 4388/16329 [36:56<1:48:39,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4388: train loss 2.26053. lr 5.736555e-04:  27%|██▋       | 4388/16329 [36:57<1:48:39,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4388: train loss 2.26053. lr 5.736555e-04:  27%|██▋       | 4389/16329 [36:57<1:45:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4389: train loss 2.26931. lr 5.736437e-04:  27%|██▋       | 4389/16329 [36:57<1:45:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4389: train loss 2.26931. lr 5.736437e-04:  27%|██▋       | 4390/16329 [36:57<1:43:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4390: train loss 2.22817. lr 5.736319e-04:  27%|██▋       | 4390/16329 [36:58<1:43:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4390: train loss 2.22817. lr 5.736319e-04:  27%|██▋       | 4391/16329 [36:58<1:41:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4391: train loss 2.20305. lr 5.736200e-04:  27%|██▋       | 4391/16329 [36:58<1:41:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4391: train loss 2.20305. lr 5.736200e-04:  27%|██▋       | 4392/16329 [36:58<1:40:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4392: train loss 2.20518. lr 5.736082e-04:  27%|██▋       | 4392/16329 [36:59<1:40:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4392: train loss 2.20518. lr 5.736082e-04:  27%|██▋       | 4393/16329 [36:59<1:39:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4393: train loss 2.22802. lr 5.735963e-04:  27%|██▋       | 4393/16329 [36:59<1:39:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4393: train loss 2.22802. lr 5.735963e-04:  27%|██▋       | 4394/16329 [36:59<1:39:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4394: train loss 2.21029. lr 5.735845e-04:  27%|██▋       | 4394/16329 [37:00<1:39:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4394: train loss 2.21029. lr 5.735845e-04:  27%|██▋       | 4395/16329 [37:00<1:40:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4395: train loss 2.20427. lr 5.735727e-04:  27%|██▋       | 4395/16329 [37:00<1:40:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4395: train loss 2.20427. lr 5.735727e-04:  27%|██▋       | 4396/16329 [37:00<1:41:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4396: train loss 2.16049. lr 5.735608e-04:  27%|██▋       | 4396/16329 [37:01<1:41:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4396: train loss 2.16049. lr 5.735608e-04:  27%|██▋       | 4397/16329 [37:01<1:42:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4397: train loss 2.26851. lr 5.735490e-04:  27%|██▋       | 4397/16329 [37:01<1:42:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4397: train loss 2.26851. lr 5.735490e-04:  27%|██▋       | 4398/16329 [37:01<1:41:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4398: train loss 2.20234. lr 5.735371e-04:  27%|██▋       | 4398/16329 [37:02<1:41:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4398: train loss 2.20234. lr 5.735371e-04:  27%|██▋       | 4399/16329 [37:02<1:41:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4399: train loss 2.21037. lr 5.735253e-04:  27%|██▋       | 4399/16329 [37:02<1:41:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4399: train loss 2.21037. lr 5.735253e-04:  27%|██▋       | 4400/16329 [37:02<1:41:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4400: train loss 2.19734. lr 5.735134e-04:  27%|██▋       | 4400/16329 [37:03<1:41:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4400: train loss 2.19734. lr 5.735134e-04:  27%|██▋       | 4401/16329 [37:03<1:40:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4401: train loss 2.25217. lr 5.735016e-04:  27%|██▋       | 4401/16329 [37:03<1:40:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4401: train loss 2.25217. lr 5.735016e-04:  27%|██▋       | 4402/16329 [37:03<1:39:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4402: train loss 2.20744. lr 5.734897e-04:  27%|██▋       | 4402/16329 [37:04<1:39:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4402: train loss 2.20744. lr 5.734897e-04:  27%|██▋       | 4403/16329 [37:04<1:39:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4403: train loss 2.23408. lr 5.734778e-04:  27%|██▋       | 4403/16329 [37:04<1:39:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4403: train loss 2.23408. lr 5.734778e-04:  27%|██▋       | 4404/16329 [37:04<1:38:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4404: train loss 2.18421. lr 5.734660e-04:  27%|██▋       | 4404/16329 [37:05<1:38:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4404: train loss 2.18421. lr 5.734660e-04:  27%|██▋       | 4405/16329 [37:05<1:38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4405: train loss 2.16539. lr 5.734541e-04:  27%|██▋       | 4405/16329 [37:05<1:38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4405: train loss 2.16539. lr 5.734541e-04:  27%|██▋       | 4406/16329 [37:05<1:38:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4406: train loss 2.20322. lr 5.734422e-04:  27%|██▋       | 4406/16329 [37:06<1:38:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4406: train loss 2.20322. lr 5.734422e-04:  27%|██▋       | 4407/16329 [37:06<1:38:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4407: train loss 2.19934. lr 5.734304e-04:  27%|██▋       | 4407/16329 [37:06<1:38:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4407: train loss 2.19934. lr 5.734304e-04:  27%|██▋       | 4408/16329 [37:06<1:37:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4408: train loss 2.22325. lr 5.734185e-04:  27%|██▋       | 4408/16329 [37:07<1:37:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4408: train loss 2.22325. lr 5.734185e-04:  27%|██▋       | 4409/16329 [37:07<1:37:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4409: train loss 2.17005. lr 5.734066e-04:  27%|██▋       | 4409/16329 [37:07<1:37:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4409: train loss 2.17005. lr 5.734066e-04:  27%|██▋       | 4410/16329 [37:07<1:38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4410: train loss 2.23096. lr 5.733947e-04:  27%|██▋       | 4410/16329 [37:08<1:38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4410: train loss 2.23096. lr 5.733947e-04:  27%|██▋       | 4411/16329 [37:08<1:37:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4411: train loss 2.22942. lr 5.733828e-04:  27%|██▋       | 4411/16329 [37:08<1:37:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4411: train loss 2.22942. lr 5.733828e-04:  27%|██▋       | 4412/16329 [37:08<1:37:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4412: train loss 2.20967. lr 5.733709e-04:  27%|██▋       | 4412/16329 [37:09<1:37:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4412: train loss 2.20967. lr 5.733709e-04:  27%|██▋       | 4413/16329 [37:09<1:48:45,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4413: train loss 2.19808. lr 5.733591e-04:  27%|██▋       | 4413/16329 [37:09<1:48:45,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4413: train loss 2.19808. lr 5.733591e-04:  27%|██▋       | 4414/16329 [37:09<1:45:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4414: train loss 2.30263. lr 5.733472e-04:  27%|██▋       | 4414/16329 [37:10<1:45:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4414: train loss 2.30263. lr 5.733472e-04:  27%|██▋       | 4415/16329 [37:10<1:43:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4415: train loss 2.19984. lr 5.733353e-04:  27%|██▋       | 4415/16329 [37:10<1:43:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4415: train loss 2.19984. lr 5.733353e-04:  27%|██▋       | 4416/16329 [37:10<1:41:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4416: train loss 2.21961. lr 5.733234e-04:  27%|██▋       | 4416/16329 [37:11<1:41:34,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4416: train loss 2.21961. lr 5.733234e-04:  27%|██▋       | 4417/16329 [37:11<1:40:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4417: train loss 2.11921. lr 5.733115e-04:  27%|██▋       | 4417/16329 [37:11<1:40:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4417: train loss 2.11921. lr 5.733115e-04:  27%|██▋       | 4418/16329 [37:11<1:39:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4418: train loss 2.23657. lr 5.732996e-04:  27%|██▋       | 4418/16329 [37:12<1:39:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4418: train loss 2.23657. lr 5.732996e-04:  27%|██▋       | 4419/16329 [37:12<1:38:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4419: train loss 2.23307. lr 5.732877e-04:  27%|██▋       | 4419/16329 [37:12<1:38:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4419: train loss 2.23307. lr 5.732877e-04:  27%|██▋       | 4420/16329 [37:12<1:38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4420: train loss 2.17281. lr 5.732758e-04:  27%|██▋       | 4420/16329 [37:13<1:38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4420: train loss 2.17281. lr 5.732758e-04:  27%|██▋       | 4421/16329 [37:13<1:38:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4421: train loss 2.20063. lr 5.732639e-04:  27%|██▋       | 4421/16329 [37:13<1:38:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4421: train loss 2.20063. lr 5.732639e-04:  27%|██▋       | 4422/16329 [37:13<1:37:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4422: train loss 2.18234. lr 5.732520e-04:  27%|██▋       | 4422/16329 [37:14<1:37:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4422: train loss 2.18234. lr 5.732520e-04:  27%|██▋       | 4423/16329 [37:14<1:40:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4423: train loss 2.25152. lr 5.732400e-04:  27%|██▋       | 4423/16329 [37:14<1:40:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4423: train loss 2.25152. lr 5.732400e-04:  27%|██▋       | 4424/16329 [37:14<1:41:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4424: train loss 2.20445. lr 5.732281e-04:  27%|██▋       | 4424/16329 [37:15<1:41:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4424: train loss 2.20445. lr 5.732281e-04:  27%|██▋       | 4425/16329 [37:15<1:41:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4425: train loss 2.18267. lr 5.732162e-04:  27%|██▋       | 4425/16329 [37:15<1:41:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4425: train loss 2.18267. lr 5.732162e-04:  27%|██▋       | 4426/16329 [37:15<1:40:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4426: train loss 2.19734. lr 5.732043e-04:  27%|██▋       | 4426/16329 [37:16<1:40:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4426: train loss 2.19734. lr 5.732043e-04:  27%|██▋       | 4427/16329 [37:16<1:40:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4427: train loss 2.14376. lr 5.731924e-04:  27%|██▋       | 4427/16329 [37:16<1:40:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4427: train loss 2.14376. lr 5.731924e-04:  27%|██▋       | 4428/16329 [37:16<1:39:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4428: train loss 2.19234. lr 5.731804e-04:  27%|██▋       | 4428/16329 [37:17<1:39:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4428: train loss 2.19234. lr 5.731804e-04:  27%|██▋       | 4429/16329 [37:17<1:39:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4429: train loss 2.17377. lr 5.731685e-04:  27%|██▋       | 4429/16329 [37:17<1:39:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4429: train loss 2.17377. lr 5.731685e-04:  27%|██▋       | 4430/16329 [37:17<1:38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4430: train loss 2.20567. lr 5.731566e-04:  27%|██▋       | 4430/16329 [37:18<1:38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4430: train loss 2.20567. lr 5.731566e-04:  27%|██▋       | 4431/16329 [37:18<1:38:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4431: train loss 2.21681. lr 5.731446e-04:  27%|██▋       | 4431/16329 [37:18<1:38:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4431: train loss 2.21681. lr 5.731446e-04:  27%|██▋       | 4432/16329 [37:18<1:38:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4432: train loss 2.17878. lr 5.731327e-04:  27%|██▋       | 4432/16329 [37:19<1:38:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4432: train loss 2.17878. lr 5.731327e-04:  27%|██▋       | 4433/16329 [37:19<1:37:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4433: train loss 2.24467. lr 5.731208e-04:  27%|██▋       | 4433/16329 [37:19<1:37:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4433: train loss 2.24467. lr 5.731208e-04:  27%|██▋       | 4434/16329 [37:19<1:37:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4434: train loss 2.20657. lr 5.731088e-04:  27%|██▋       | 4434/16329 [37:20<1:37:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4434: train loss 2.20657. lr 5.731088e-04:  27%|██▋       | 4435/16329 [37:20<1:37:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4435: train loss 2.17753. lr 5.730969e-04:  27%|██▋       | 4435/16329 [37:20<1:37:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4435: train loss 2.17753. lr 5.730969e-04:  27%|██▋       | 4436/16329 [37:20<1:38:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4436: train loss 2.23212. lr 5.730849e-04:  27%|██▋       | 4436/16329 [37:21<1:38:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4436: train loss 2.23212. lr 5.730849e-04:  27%|██▋       | 4437/16329 [37:21<1:37:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4437: train loss 2.12410. lr 5.730730e-04:  27%|██▋       | 4437/16329 [37:21<1:37:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4437: train loss 2.12410. lr 5.730730e-04:  27%|██▋       | 4438/16329 [37:21<1:37:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4438: train loss 2.23276. lr 5.730610e-04:  27%|██▋       | 4438/16329 [37:22<1:37:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4438: train loss 2.23276. lr 5.730610e-04:  27%|██▋       | 4439/16329 [37:22<1:37:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4439: train loss 2.24619. lr 5.730491e-04:  27%|██▋       | 4439/16329 [37:23<1:37:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4439: train loss 2.24619. lr 5.730491e-04:  27%|██▋       | 4440/16329 [37:23<1:48:07,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4440: train loss 2.18956. lr 5.730371e-04:  27%|██▋       | 4440/16329 [37:23<1:48:07,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4440: train loss 2.18956. lr 5.730371e-04:  27%|██▋       | 4441/16329 [37:23<1:45:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4441: train loss 2.18472. lr 5.730252e-04:  27%|██▋       | 4441/16329 [37:24<1:45:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4441: train loss 2.18472. lr 5.730252e-04:  27%|██▋       | 4442/16329 [37:24<1:42:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4442: train loss 2.16170. lr 5.730132e-04:  27%|██▋       | 4442/16329 [37:24<1:42:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4442: train loss 2.16170. lr 5.730132e-04:  27%|██▋       | 4443/16329 [37:24<1:41:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4443: train loss 2.13596. lr 5.730012e-04:  27%|██▋       | 4443/16329 [37:25<1:41:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4443: train loss 2.13596. lr 5.730012e-04:  27%|██▋       | 4444/16329 [37:25<1:40:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4444: train loss 2.15010. lr 5.729893e-04:  27%|██▋       | 4444/16329 [37:25<1:40:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4444: train loss 2.15010. lr 5.729893e-04:  27%|██▋       | 4445/16329 [37:25<1:39:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4445: train loss 2.18033. lr 5.729773e-04:  27%|██▋       | 4445/16329 [37:26<1:39:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4445: train loss 2.18033. lr 5.729773e-04:  27%|██▋       | 4446/16329 [37:26<1:39:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4446: train loss 2.16853. lr 5.729653e-04:  27%|██▋       | 4446/16329 [37:26<1:39:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4446: train loss 2.16853. lr 5.729653e-04:  27%|██▋       | 4447/16329 [37:26<1:38:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4447: train loss 2.22631. lr 5.729534e-04:  27%|██▋       | 4447/16329 [37:27<1:38:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4447: train loss 2.22631. lr 5.729534e-04:  27%|██▋       | 4448/16329 [37:27<1:38:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4448: train loss 2.16176. lr 5.729414e-04:  27%|██▋       | 4448/16329 [37:27<1:38:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4448: train loss 2.16176. lr 5.729414e-04:  27%|██▋       | 4449/16329 [37:27<1:38:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4449: train loss 2.23496. lr 5.729294e-04:  27%|██▋       | 4449/16329 [37:28<1:38:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4449: train loss 2.23496. lr 5.729294e-04:  27%|██▋       | 4450/16329 [37:28<1:37:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4450: train loss 2.24655. lr 5.729174e-04:  27%|██▋       | 4450/16329 [37:28<1:37:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4450: train loss 2.24655. lr 5.729174e-04:  27%|██▋       | 4451/16329 [37:28<1:38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4451: train loss 2.17076. lr 5.729054e-04:  27%|██▋       | 4451/16329 [37:29<1:38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4451: train loss 2.17076. lr 5.729054e-04:  27%|██▋       | 4452/16329 [37:29<1:38:03,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4452: train loss 2.13915. lr 5.728934e-04:  27%|██▋       | 4452/16329 [37:29<1:38:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4452: train loss 2.13915. lr 5.728934e-04:  27%|██▋       | 4453/16329 [37:29<1:37:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4453: train loss 2.20980. lr 5.728815e-04:  27%|██▋       | 4453/16329 [37:30<1:37:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4453: train loss 2.20980. lr 5.728815e-04:  27%|██▋       | 4454/16329 [37:30<1:42:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4454: train loss 2.23242. lr 5.728695e-04:  27%|██▋       | 4454/16329 [37:30<1:42:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4454: train loss 2.23242. lr 5.728695e-04:  27%|██▋       | 4455/16329 [37:30<1:44:52,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4455: train loss 2.18243. lr 5.728575e-04:  27%|██▋       | 4455/16329 [37:31<1:44:52,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4455: train loss 2.18243. lr 5.728575e-04:  27%|██▋       | 4456/16329 [37:31<1:45:49,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4456: train loss 2.19391. lr 5.728455e-04:  27%|██▋       | 4456/16329 [37:31<1:45:49,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4456: train loss 2.19391. lr 5.728455e-04:  27%|██▋       | 4457/16329 [37:31<1:45:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4457: train loss 2.23262. lr 5.728335e-04:  27%|██▋       | 4457/16329 [37:32<1:45:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4457: train loss 2.23262. lr 5.728335e-04:  27%|██▋       | 4458/16329 [37:32<1:44:18,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4458: train loss 2.22928. lr 5.728215e-04:  27%|██▋       | 4458/16329 [37:32<1:44:18,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4458: train loss 2.22928. lr 5.728215e-04:  27%|██▋       | 4459/16329 [37:32<1:43:18,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4459: train loss 2.19128. lr 5.728095e-04:  27%|██▋       | 4459/16329 [37:33<1:43:18,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4459: train loss 2.19128. lr 5.728095e-04:  27%|██▋       | 4460/16329 [37:33<1:42:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4460: train loss 2.21797. lr 5.727975e-04:  27%|██▋       | 4460/16329 [37:33<1:42:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4460: train loss 2.21797. lr 5.727975e-04:  27%|██▋       | 4461/16329 [37:33<1:40:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4461: train loss 2.21769. lr 5.727854e-04:  27%|██▋       | 4461/16329 [37:34<1:40:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4461: train loss 2.21769. lr 5.727854e-04:  27%|██▋       | 4462/16329 [37:34<1:39:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4462: train loss 2.18743. lr 5.727734e-04:  27%|██▋       | 4462/16329 [37:34<1:39:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4462: train loss 2.18743. lr 5.727734e-04:  27%|██▋       | 4463/16329 [37:34<1:38:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4463: train loss 2.16250. lr 5.727614e-04:  27%|██▋       | 4463/16329 [37:35<1:38:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4463: train loss 2.16250. lr 5.727614e-04:  27%|██▋       | 4464/16329 [37:35<1:38:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4464: train loss 2.16222. lr 5.727494e-04:  27%|██▋       | 4464/16329 [37:35<1:38:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4464: train loss 2.16222. lr 5.727494e-04:  27%|██▋       | 4465/16329 [37:35<1:38:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4465: train loss 2.22636. lr 5.727374e-04:  27%|██▋       | 4465/16329 [37:36<1:38:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4465: train loss 2.22636. lr 5.727374e-04:  27%|██▋       | 4466/16329 [37:36<1:37:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4466: train loss 2.20906. lr 5.727254e-04:  27%|██▋       | 4466/16329 [37:36<1:37:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4466: train loss 2.20906. lr 5.727254e-04:  27%|██▋       | 4467/16329 [37:36<1:37:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4467: train loss 2.19069. lr 5.727133e-04:  27%|██▋       | 4467/16329 [37:37<1:37:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4467: train loss 2.19069. lr 5.727133e-04:  27%|██▋       | 4468/16329 [37:37<1:37:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4468: train loss 2.22709. lr 5.727013e-04:  27%|██▋       | 4468/16329 [37:37<1:37:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4468: train loss 2.22709. lr 5.727013e-04:  27%|██▋       | 4469/16329 [37:37<1:37:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4469: train loss 2.18006. lr 5.726893e-04:  27%|██▋       | 4469/16329 [37:38<1:37:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4469: train loss 2.18006. lr 5.726893e-04:  27%|██▋       | 4470/16329 [37:38<1:37:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4470: train loss 2.21683. lr 5.726772e-04:  27%|██▋       | 4470/16329 [37:38<1:37:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4470: train loss 2.21683. lr 5.726772e-04:  27%|██▋       | 4471/16329 [37:38<1:37:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4471: train loss 2.16425. lr 5.726652e-04:  27%|██▋       | 4471/16329 [37:39<1:37:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4471: train loss 2.16425. lr 5.726652e-04:  27%|██▋       | 4472/16329 [37:39<1:37:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4472: train loss 2.19249. lr 5.726532e-04:  27%|██▋       | 4472/16329 [37:39<1:37:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4472: train loss 2.19249. lr 5.726532e-04:  27%|██▋       | 4473/16329 [37:39<1:37:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4473: train loss 2.15875. lr 5.726411e-04:  27%|██▋       | 4473/16329 [37:40<1:37:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4473: train loss 2.15875. lr 5.726411e-04:  27%|██▋       | 4474/16329 [37:40<1:37:04,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4474: train loss 2.18803. lr 5.726291e-04:  27%|██▋       | 4474/16329 [37:40<1:37:04,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4474: train loss 2.18803. lr 5.726291e-04:  27%|██▋       | 4475/16329 [37:40<1:37:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4475: train loss 2.18487. lr 5.726170e-04:  27%|██▋       | 4475/16329 [37:41<1:37:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4475: train loss 2.18487. lr 5.726170e-04:  27%|██▋       | 4476/16329 [37:41<1:37:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4476: train loss 2.22570. lr 5.726050e-04:  27%|██▋       | 4476/16329 [37:41<1:37:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4476: train loss 2.22570. lr 5.726050e-04:  27%|██▋       | 4477/16329 [37:41<1:37:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4477: train loss 2.20589. lr 5.725929e-04:  27%|██▋       | 4477/16329 [37:42<1:37:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4477: train loss 2.20589. lr 5.725929e-04:  27%|██▋       | 4478/16329 [37:42<1:37:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4478: train loss 2.21521. lr 5.725809e-04:  27%|██▋       | 4478/16329 [37:42<1:37:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4478: train loss 2.21521. lr 5.725809e-04:  27%|██▋       | 4479/16329 [37:42<1:37:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4479: train loss 2.25599. lr 5.725688e-04:  27%|██▋       | 4479/16329 [37:43<1:37:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4479: train loss 2.25599. lr 5.725688e-04:  27%|██▋       | 4480/16329 [37:43<1:47:42,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4480: train loss 2.12178. lr 5.725568e-04:  27%|██▋       | 4480/16329 [37:43<1:47:42,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4480: train loss 2.12178. lr 5.725568e-04:  27%|██▋       | 4481/16329 [37:43<1:44:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4481: train loss 2.18183. lr 5.725447e-04:  27%|██▋       | 4481/16329 [37:44<1:44:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4481: train loss 2.18183. lr 5.725447e-04:  27%|██▋       | 4482/16329 [37:44<1:42:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4482: train loss 2.20150. lr 5.725327e-04:  27%|██▋       | 4482/16329 [37:44<1:42:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4482: train loss 2.20150. lr 5.725327e-04:  27%|██▋       | 4483/16329 [37:44<1:42:29,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4483: train loss 2.11307. lr 5.725206e-04:  27%|██▋       | 4483/16329 [37:45<1:42:29,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4483: train loss 2.11307. lr 5.725206e-04:  27%|██▋       | 4484/16329 [37:45<1:42:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4484: train loss 2.12400. lr 5.725085e-04:  27%|██▋       | 4484/16329 [37:45<1:42:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4484: train loss 2.12400. lr 5.725085e-04:  27%|██▋       | 4485/16329 [37:45<1:41:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4485: train loss 2.17976. lr 5.724965e-04:  27%|██▋       | 4485/16329 [37:46<1:41:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4485: train loss 2.17976. lr 5.724965e-04:  27%|██▋       | 4486/16329 [37:46<1:41:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4486: train loss 2.15347. lr 5.724844e-04:  27%|██▋       | 4486/16329 [37:46<1:41:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4486: train loss 2.15347. lr 5.724844e-04:  27%|██▋       | 4487/16329 [37:46<1:41:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4487: train loss 2.23564. lr 5.724723e-04:  27%|██▋       | 4487/16329 [37:47<1:41:40,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4487: train loss 2.23564. lr 5.724723e-04:  27%|██▋       | 4488/16329 [37:47<1:42:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4488: train loss 2.20690. lr 5.724602e-04:  27%|██▋       | 4488/16329 [37:47<1:42:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4488: train loss 2.20690. lr 5.724602e-04:  27%|██▋       | 4489/16329 [37:47<1:42:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4489: train loss 2.16359. lr 5.724482e-04:  27%|██▋       | 4489/16329 [37:48<1:42:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4489: train loss 2.16359. lr 5.724482e-04:  27%|██▋       | 4490/16329 [37:48<1:41:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4490: train loss 2.19672. lr 5.724361e-04:  27%|██▋       | 4490/16329 [37:48<1:41:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4490: train loss 2.19672. lr 5.724361e-04:  28%|██▊       | 4491/16329 [37:48<1:40:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4491: train loss 2.18398. lr 5.724240e-04:  28%|██▊       | 4491/16329 [37:49<1:40:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4491: train loss 2.18398. lr 5.724240e-04:  28%|██▊       | 4492/16329 [37:49<1:40:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4492: train loss 2.21458. lr 5.724119e-04:  28%|██▊       | 4492/16329 [37:49<1:40:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4492: train loss 2.21458. lr 5.724119e-04:  28%|██▊       | 4493/16329 [37:49<1:39:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4493: train loss 2.19717. lr 5.723998e-04:  28%|██▊       | 4493/16329 [37:50<1:39:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4493: train loss 2.19717. lr 5.723998e-04:  28%|██▊       | 4494/16329 [37:50<1:38:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4494: train loss 2.15280. lr 5.723877e-04:  28%|██▊       | 4494/16329 [37:50<1:38:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4494: train loss 2.15280. lr 5.723877e-04:  28%|██▊       | 4495/16329 [37:50<1:38:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4495: train loss 2.15683. lr 5.723756e-04:  28%|██▊       | 4495/16329 [37:51<1:38:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4495: train loss 2.15683. lr 5.723756e-04:  28%|██▊       | 4496/16329 [37:51<1:37:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4496: train loss 2.18333. lr 5.723635e-04:  28%|██▊       | 4496/16329 [37:51<1:37:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4496: train loss 2.18333. lr 5.723635e-04:  28%|██▊       | 4497/16329 [37:51<1:37:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4497: train loss 2.21388. lr 5.723514e-04:  28%|██▊       | 4497/16329 [37:52<1:37:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4497: train loss 2.21388. lr 5.723514e-04:  28%|██▊       | 4498/16329 [37:52<1:37:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4498: train loss 2.18265. lr 5.723393e-04:  28%|██▊       | 4498/16329 [37:52<1:37:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4498: train loss 2.18265. lr 5.723393e-04:  28%|██▊       | 4499/16329 [37:52<1:36:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4499: train loss 2.19913. lr 5.723272e-04:  28%|██▊       | 4499/16329 [37:53<1:36:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4499: train loss 2.19913. lr 5.723272e-04:  28%|██▊       | 4500/16329 [37:53<1:37:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4500: train loss 2.22211. lr 5.723151e-04:  28%|██▊       | 4500/16329 [37:53<1:37:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4500: train loss 2.22211. lr 5.723151e-04:  28%|██▊       | 4501/16329 [37:53<1:37:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4501: train loss 2.15838. lr 5.723030e-04:  28%|██▊       | 4501/16329 [37:54<1:37:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4501: train loss 2.15838. lr 5.723030e-04:  28%|██▊       | 4502/16329 [37:54<1:36:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4502: train loss 2.19349. lr 5.722909e-04:  28%|██▊       | 4502/16329 [37:54<1:36:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4502: train loss 2.19349. lr 5.722909e-04:  28%|██▊       | 4503/16329 [37:54<1:36:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4503: train loss 2.15083. lr 5.722788e-04:  28%|██▊       | 4503/16329 [37:55<1:36:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4503: train loss 2.15083. lr 5.722788e-04:  28%|██▊       | 4504/16329 [37:55<1:36:41,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4504: train loss 2.16222. lr 5.722666e-04:  28%|██▊       | 4504/16329 [37:55<1:36:41,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4504: train loss 2.16222. lr 5.722666e-04:  28%|██▊       | 4505/16329 [37:55<1:36:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4505: train loss 2.23921. lr 5.722545e-04:  28%|██▊       | 4505/16329 [37:56<1:36:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4505: train loss 2.23921. lr 5.722545e-04:  28%|██▊       | 4506/16329 [37:56<1:36:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4506: train loss 2.15572. lr 5.722424e-04:  28%|██▊       | 4506/16329 [37:56<1:36:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4506: train loss 2.15572. lr 5.722424e-04:  28%|██▊       | 4507/16329 [37:56<1:37:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4507: train loss 2.15385. lr 5.722303e-04:  28%|██▊       | 4507/16329 [37:57<1:37:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4507: train loss 2.15385. lr 5.722303e-04:  28%|██▊       | 4508/16329 [37:57<1:37:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4508: train loss 2.14680. lr 5.722181e-04:  28%|██▊       | 4508/16329 [37:57<1:37:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4508: train loss 2.14680. lr 5.722181e-04:  28%|██▊       | 4509/16329 [37:57<1:36:46,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4509: train loss 2.22204. lr 5.722060e-04:  28%|██▊       | 4509/16329 [37:58<1:36:46,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4509: train loss 2.22204. lr 5.722060e-04:  28%|██▊       | 4510/16329 [37:58<1:37:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4510: train loss 2.18449. lr 5.721939e-04:  28%|██▊       | 4510/16329 [37:58<1:37:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4510: train loss 2.18449. lr 5.721939e-04:  28%|██▊       | 4511/16329 [37:58<1:37:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4511: train loss 2.19888. lr 5.721817e-04:  28%|██▊       | 4511/16329 [37:59<1:37:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4511: train loss 2.19888. lr 5.721817e-04:  28%|██▊       | 4512/16329 [37:59<1:37:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4512: train loss 2.17888. lr 5.721696e-04:  28%|██▊       | 4512/16329 [37:59<1:37:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4512: train loss 2.17888. lr 5.721696e-04:  28%|██▊       | 4513/16329 [37:59<1:37:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4513: train loss 2.19805. lr 5.721575e-04:  28%|██▊       | 4513/16329 [38:00<1:37:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4513: train loss 2.19805. lr 5.721575e-04:  28%|██▊       | 4514/16329 [38:00<1:36:45,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4514: train loss 2.22716. lr 5.721453e-04:  28%|██▊       | 4514/16329 [38:00<1:36:45,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4514: train loss 2.22716. lr 5.721453e-04:  28%|██▊       | 4515/16329 [38:00<1:47:03,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4515: train loss 2.21706. lr 5.721332e-04:  28%|██▊       | 4515/16329 [38:01<1:47:03,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4515: train loss 2.21706. lr 5.721332e-04:  28%|██▊       | 4516/16329 [38:01<1:43:48,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4516: train loss 2.13661. lr 5.721210e-04:  28%|██▊       | 4516/16329 [38:01<1:43:48,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4516: train loss 2.13661. lr 5.721210e-04:  28%|██▊       | 4517/16329 [38:01<1:41:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4517: train loss 2.25866. lr 5.721089e-04:  28%|██▊       | 4517/16329 [38:02<1:41:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4517: train loss 2.25866. lr 5.721089e-04:  28%|██▊       | 4518/16329 [38:02<1:40:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4518: train loss 2.15274. lr 5.720967e-04:  28%|██▊       | 4518/16329 [38:02<1:40:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4518: train loss 2.15274. lr 5.720967e-04:  28%|██▊       | 4519/16329 [38:02<1:39:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4519: train loss 2.12422. lr 5.720846e-04:  28%|██▊       | 4519/16329 [38:03<1:39:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4519: train loss 2.12422. lr 5.720846e-04:  28%|██▊       | 4520/16329 [38:03<1:38:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4520: train loss 2.19644. lr 5.720724e-04:  28%|██▊       | 4520/16329 [38:03<1:38:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4520: train loss 2.19644. lr 5.720724e-04:  28%|██▊       | 4521/16329 [38:03<1:38:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4521: train loss 2.13453. lr 5.720603e-04:  28%|██▊       | 4521/16329 [38:04<1:38:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4521: train loss 2.13453. lr 5.720603e-04:  28%|██▊       | 4522/16329 [38:04<1:37:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4522: train loss 2.14655. lr 5.720481e-04:  28%|██▊       | 4522/16329 [38:04<1:37:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4522: train loss 2.14655. lr 5.720481e-04:  28%|██▊       | 4523/16329 [38:04<1:41:31,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4523: train loss 2.15726. lr 5.720359e-04:  28%|██▊       | 4523/16329 [38:05<1:41:31,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4523: train loss 2.15726. lr 5.720359e-04:  28%|██▊       | 4524/16329 [38:05<1:42:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4524: train loss 2.23271. lr 5.720238e-04:  28%|██▊       | 4524/16329 [38:05<1:42:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4524: train loss 2.23271. lr 5.720238e-04:  28%|██▊       | 4525/16329 [38:05<1:42:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4525: train loss 2.07830. lr 5.720116e-04:  28%|██▊       | 4525/16329 [38:06<1:42:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4525: train loss 2.07830. lr 5.720116e-04:  28%|██▊       | 4526/16329 [38:06<1:42:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4526: train loss 2.18409. lr 5.719994e-04:  28%|██▊       | 4526/16329 [38:06<1:42:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4526: train loss 2.18409. lr 5.719994e-04:  28%|██▊       | 4527/16329 [38:06<1:41:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4527: train loss 2.18624. lr 5.719872e-04:  28%|██▊       | 4527/16329 [38:07<1:41:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4527: train loss 2.18624. lr 5.719872e-04:  28%|██▊       | 4528/16329 [38:07<1:40:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4528: train loss 2.20913. lr 5.719751e-04:  28%|██▊       | 4528/16329 [38:07<1:40:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4528: train loss 2.20913. lr 5.719751e-04:  28%|██▊       | 4529/16329 [38:07<1:39:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4529: train loss 2.20990. lr 5.719629e-04:  28%|██▊       | 4529/16329 [38:08<1:39:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4529: train loss 2.20990. lr 5.719629e-04:  28%|██▊       | 4530/16329 [38:08<1:38:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4530: train loss 2.17248. lr 5.719507e-04:  28%|██▊       | 4530/16329 [38:08<1:38:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4530: train loss 2.17248. lr 5.719507e-04:  28%|██▊       | 4531/16329 [38:08<1:38:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4531: train loss 2.23702. lr 5.719385e-04:  28%|██▊       | 4531/16329 [38:09<1:38:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4531: train loss 2.23702. lr 5.719385e-04:  28%|██▊       | 4532/16329 [38:09<1:37:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4532: train loss 2.13613. lr 5.719263e-04:  28%|██▊       | 4532/16329 [38:09<1:37:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4532: train loss 2.13613. lr 5.719263e-04:  28%|██▊       | 4533/16329 [38:09<1:37:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4533: train loss 2.16152. lr 5.719141e-04:  28%|██▊       | 4533/16329 [38:10<1:37:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4533: train loss 2.16152. lr 5.719141e-04:  28%|██▊       | 4534/16329 [38:10<1:37:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4534: train loss 2.16509. lr 5.719019e-04:  28%|██▊       | 4534/16329 [38:10<1:37:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4534: train loss 2.16509. lr 5.719019e-04:  28%|██▊       | 4535/16329 [38:10<1:37:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4535: train loss 2.21505. lr 5.718897e-04:  28%|██▊       | 4535/16329 [38:11<1:37:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4535: train loss 2.21505. lr 5.718897e-04:  28%|██▊       | 4536/16329 [38:11<1:37:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4536: train loss 2.09147. lr 5.718775e-04:  28%|██▊       | 4536/16329 [38:11<1:37:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4536: train loss 2.09147. lr 5.718775e-04:  28%|██▊       | 4537/16329 [38:11<1:36:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4537: train loss 2.17110. lr 5.718653e-04:  28%|██▊       | 4537/16329 [38:12<1:36:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4537: train loss 2.17110. lr 5.718653e-04:  28%|██▊       | 4538/16329 [38:12<1:36:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4538: train loss 2.17721. lr 5.718531e-04:  28%|██▊       | 4538/16329 [38:12<1:36:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4538: train loss 2.17721. lr 5.718531e-04:  28%|██▊       | 4539/16329 [38:12<1:37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4539: train loss 2.14432. lr 5.718409e-04:  28%|██▊       | 4539/16329 [38:13<1:37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4539: train loss 2.14432. lr 5.718409e-04:  28%|██▊       | 4540/16329 [38:13<1:47:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4540: train loss 2.14987. lr 5.718287e-04:  28%|██▊       | 4540/16329 [38:14<1:47:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4540: train loss 2.14987. lr 5.718287e-04:  28%|██▊       | 4541/16329 [38:14<1:44:46,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4541: train loss 2.18817. lr 5.718165e-04:  28%|██▊       | 4541/16329 [38:14<1:44:46,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4541: train loss 2.18817. lr 5.718165e-04:  28%|██▊       | 4542/16329 [38:14<1:41:52,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4542: train loss 2.17936. lr 5.718043e-04:  28%|██▊       | 4542/16329 [38:15<1:41:52,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4542: train loss 2.17936. lr 5.718043e-04:  28%|██▊       | 4543/16329 [38:15<1:40:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4543: train loss 2.16726. lr 5.717921e-04:  28%|██▊       | 4543/16329 [38:15<1:40:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4543: train loss 2.16726. lr 5.717921e-04:  28%|██▊       | 4544/16329 [38:15<1:39:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4544: train loss 2.22277. lr 5.717799e-04:  28%|██▊       | 4544/16329 [38:15<1:39:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4544: train loss 2.22277. lr 5.717799e-04:  28%|██▊       | 4545/16329 [38:15<1:38:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4545: train loss 2.19701. lr 5.717676e-04:  28%|██▊       | 4545/16329 [38:16<1:38:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4545: train loss 2.19701. lr 5.717676e-04:  28%|██▊       | 4546/16329 [38:16<1:38:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4546: train loss 2.15826. lr 5.717554e-04:  28%|██▊       | 4546/16329 [38:16<1:38:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4546: train loss 2.15826. lr 5.717554e-04:  28%|██▊       | 4547/16329 [38:16<1:37:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4547: train loss 2.14921. lr 5.717432e-04:  28%|██▊       | 4547/16329 [38:17<1:37:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4547: train loss 2.14921. lr 5.717432e-04:  28%|██▊       | 4548/16329 [38:17<1:37:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4548: train loss 2.19151. lr 5.717310e-04:  28%|██▊       | 4548/16329 [38:17<1:37:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4548: train loss 2.19151. lr 5.717310e-04:  28%|██▊       | 4549/16329 [38:17<1:37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4549: train loss 2.15245. lr 5.717187e-04:  28%|██▊       | 4549/16329 [38:18<1:37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4549: train loss 2.15245. lr 5.717187e-04:  28%|██▊       | 4550/16329 [38:18<1:37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4550: train loss 2.13977. lr 5.717065e-04:  28%|██▊       | 4550/16329 [38:18<1:37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4550: train loss 2.13977. lr 5.717065e-04:  28%|██▊       | 4551/16329 [38:18<1:36:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4551: train loss 2.16151. lr 5.716943e-04:  28%|██▊       | 4551/16329 [38:19<1:36:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4551: train loss 2.16151. lr 5.716943e-04:  28%|██▊       | 4552/16329 [38:19<1:36:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4552: train loss 2.11574. lr 5.716820e-04:  28%|██▊       | 4552/16329 [38:19<1:36:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4552: train loss 2.11574. lr 5.716820e-04:  28%|██▊       | 4553/16329 [38:19<1:36:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4553: train loss 2.16121. lr 5.716698e-04:  28%|██▊       | 4553/16329 [38:20<1:36:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4553: train loss 2.16121. lr 5.716698e-04:  28%|██▊       | 4554/16329 [38:20<1:36:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4554: train loss 2.22837. lr 5.716575e-04:  28%|██▊       | 4554/16329 [38:20<1:36:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4554: train loss 2.22837. lr 5.716575e-04:  28%|██▊       | 4555/16329 [38:20<1:37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4555: train loss 2.11779. lr 5.716453e-04:  28%|██▊       | 4555/16329 [38:21<1:37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4555: train loss 2.11779. lr 5.716453e-04:  28%|██▊       | 4556/16329 [38:21<1:36:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4556: train loss 2.15727. lr 5.716330e-04:  28%|██▊       | 4556/16329 [38:21<1:36:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4556: train loss 2.15727. lr 5.716330e-04:  28%|██▊       | 4557/16329 [38:21<1:36:24,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4557: train loss 2.18237. lr 5.716208e-04:  28%|██▊       | 4557/16329 [38:22<1:36:24,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4557: train loss 2.18237. lr 5.716208e-04:  28%|██▊       | 4558/16329 [38:22<1:36:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4558: train loss 2.13443. lr 5.716085e-04:  28%|██▊       | 4558/16329 [38:22<1:36:40,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4558: train loss 2.13443. lr 5.716085e-04:  28%|██▊       | 4559/16329 [38:22<1:36:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4559: train loss 2.20727. lr 5.715963e-04:  28%|██▊       | 4559/16329 [38:23<1:36:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4559: train loss 2.20727. lr 5.715963e-04:  28%|██▊       | 4560/16329 [38:23<1:36:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4560: train loss 2.15807. lr 5.715840e-04:  28%|██▊       | 4560/16329 [38:23<1:36:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4560: train loss 2.15807. lr 5.715840e-04:  28%|██▊       | 4561/16329 [38:23<1:36:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4561: train loss 2.12689. lr 5.715718e-04:  28%|██▊       | 4561/16329 [38:24<1:36:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4561: train loss 2.12689. lr 5.715718e-04:  28%|██▊       | 4562/16329 [38:24<1:36:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4562: train loss 2.16392. lr 5.715595e-04:  28%|██▊       | 4562/16329 [38:24<1:36:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4562: train loss 2.16392. lr 5.715595e-04:  28%|██▊       | 4563/16329 [38:24<1:39:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4563: train loss 2.15411. lr 5.715472e-04:  28%|██▊       | 4563/16329 [38:25<1:39:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4563: train loss 2.15411. lr 5.715472e-04:  28%|██▊       | 4564/16329 [38:25<1:41:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4564: train loss 2.14814. lr 5.715350e-04:  28%|██▊       | 4564/16329 [38:25<1:41:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4564: train loss 2.14814. lr 5.715350e-04:  28%|██▊       | 4565/16329 [38:25<1:40:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4565: train loss 2.14411. lr 5.715227e-04:  28%|██▊       | 4565/16329 [38:26<1:40:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4565: train loss 2.14411. lr 5.715227e-04:  28%|██▊       | 4566/16329 [38:26<1:41:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4566: train loss 2.17897. lr 5.715104e-04:  28%|██▊       | 4566/16329 [38:27<1:41:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4566: train loss 2.17897. lr 5.715104e-04:  28%|██▊       | 4567/16329 [38:27<1:50:50,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 4567: train loss 2.20014. lr 5.714981e-04:  28%|██▊       | 4567/16329 [38:27<1:50:50,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 4567: train loss 2.20014. lr 5.714981e-04:  28%|██▊       | 4568/16329 [38:27<1:47:03,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4568: train loss 2.13403. lr 5.714858e-04:  28%|██▊       | 4568/16329 [38:28<1:47:03,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4568: train loss 2.13403. lr 5.714858e-04:  28%|██▊       | 4569/16329 [38:28<1:44:05,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4569: train loss 2.14837. lr 5.714736e-04:  28%|██▊       | 4569/16329 [38:28<1:44:05,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4569: train loss 2.14837. lr 5.714736e-04:  28%|██▊       | 4570/16329 [38:28<1:41:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4570: train loss 2.16705. lr 5.714613e-04:  28%|██▊       | 4570/16329 [38:29<1:41:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4570: train loss 2.16705. lr 5.714613e-04:  28%|██▊       | 4571/16329 [38:29<1:40:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4571: train loss 2.11976. lr 5.714490e-04:  28%|██▊       | 4571/16329 [38:29<1:40:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4571: train loss 2.11976. lr 5.714490e-04:  28%|██▊       | 4572/16329 [38:29<1:39:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4572: train loss 2.16944. lr 5.714367e-04:  28%|██▊       | 4572/16329 [38:30<1:39:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4572: train loss 2.16944. lr 5.714367e-04:  28%|██▊       | 4573/16329 [38:30<1:38:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4573: train loss 2.13341. lr 5.714244e-04:  28%|██▊       | 4573/16329 [38:30<1:38:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4573: train loss 2.13341. lr 5.714244e-04:  28%|██▊       | 4574/16329 [38:30<1:38:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4574: train loss 2.15569. lr 5.714121e-04:  28%|██▊       | 4574/16329 [38:31<1:38:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4574: train loss 2.15569. lr 5.714121e-04:  28%|██▊       | 4575/16329 [38:31<1:37:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4575: train loss 2.18018. lr 5.713998e-04:  28%|██▊       | 4575/16329 [38:31<1:37:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4575: train loss 2.18018. lr 5.713998e-04:  28%|██▊       | 4576/16329 [38:31<1:37:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4576: train loss 2.18048. lr 5.713875e-04:  28%|██▊       | 4576/16329 [38:32<1:37:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4576: train loss 2.18048. lr 5.713875e-04:  28%|██▊       | 4577/16329 [38:32<1:37:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4577: train loss 2.09940. lr 5.713752e-04:  28%|██▊       | 4577/16329 [38:32<1:37:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4577: train loss 2.09940. lr 5.713752e-04:  28%|██▊       | 4578/16329 [38:32<1:37:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4578: train loss 2.11959. lr 5.713629e-04:  28%|██▊       | 4578/16329 [38:33<1:37:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4578: train loss 2.11959. lr 5.713629e-04:  28%|██▊       | 4579/16329 [38:33<1:37:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4579: train loss 2.13274. lr 5.713506e-04:  28%|██▊       | 4579/16329 [38:33<1:37:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4579: train loss 2.13274. lr 5.713506e-04:  28%|██▊       | 4580/16329 [38:33<1:36:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4580: train loss 2.07650. lr 5.713383e-04:  28%|██▊       | 4580/16329 [38:34<1:36:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4580: train loss 2.07650. lr 5.713383e-04:  28%|██▊       | 4581/16329 [38:34<1:41:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4581: train loss 2.20053. lr 5.713260e-04:  28%|██▊       | 4581/16329 [38:34<1:41:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4581: train loss 2.20053. lr 5.713260e-04:  28%|██▊       | 4582/16329 [38:34<1:43:47,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4582: train loss 2.15652. lr 5.713137e-04:  28%|██▊       | 4582/16329 [38:35<1:43:47,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4582: train loss 2.15652. lr 5.713137e-04:  28%|██▊       | 4583/16329 [38:35<1:44:52,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4583: train loss 2.17214. lr 5.713014e-04:  28%|██▊       | 4583/16329 [38:35<1:44:52,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4583: train loss 2.17214. lr 5.713014e-04:  28%|██▊       | 4584/16329 [38:35<1:44:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4584: train loss 2.16139. lr 5.712890e-04:  28%|██▊       | 4584/16329 [38:36<1:44:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4584: train loss 2.16139. lr 5.712890e-04:  28%|██▊       | 4585/16329 [38:36<1:43:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4585: train loss 2.12722. lr 5.712767e-04:  28%|██▊       | 4585/16329 [38:36<1:43:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4585: train loss 2.12722. lr 5.712767e-04:  28%|██▊       | 4586/16329 [38:36<1:42:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4586: train loss 2.21796. lr 5.712644e-04:  28%|██▊       | 4586/16329 [38:37<1:42:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4586: train loss 2.21796. lr 5.712644e-04:  28%|██▊       | 4587/16329 [38:37<1:40:58,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4587: train loss 2.18689. lr 5.712521e-04:  28%|██▊       | 4587/16329 [38:37<1:40:58,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4587: train loss 2.18689. lr 5.712521e-04:  28%|██▊       | 4588/16329 [38:37<1:39:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4588: train loss 2.19448. lr 5.712397e-04:  28%|██▊       | 4588/16329 [38:38<1:39:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4588: train loss 2.19448. lr 5.712397e-04:  28%|██▊       | 4589/16329 [38:38<1:38:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4589: train loss 2.19421. lr 5.712274e-04:  28%|██▊       | 4589/16329 [38:38<1:38:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4589: train loss 2.19421. lr 5.712274e-04:  28%|██▊       | 4590/16329 [38:38<1:37:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4590: train loss 2.11792. lr 5.712151e-04:  28%|██▊       | 4590/16329 [38:39<1:37:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4590: train loss 2.11792. lr 5.712151e-04:  28%|██▊       | 4591/16329 [38:39<1:37:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4591: train loss 2.19983. lr 5.712027e-04:  28%|██▊       | 4591/16329 [38:39<1:37:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4591: train loss 2.19983. lr 5.712027e-04:  28%|██▊       | 4592/16329 [38:39<1:37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4592: train loss 2.15572. lr 5.711904e-04:  28%|██▊       | 4592/16329 [38:40<1:37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4592: train loss 2.15572. lr 5.711904e-04:  28%|██▊       | 4593/16329 [38:40<1:36:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4593: train loss 2.15990. lr 5.711781e-04:  28%|██▊       | 4593/16329 [38:40<1:36:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4593: train loss 2.15990. lr 5.711781e-04:  28%|██▊       | 4594/16329 [38:40<1:36:30,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4594: train loss 2.09862. lr 5.711657e-04:  28%|██▊       | 4594/16329 [38:41<1:36:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4594: train loss 2.09862. lr 5.711657e-04:  28%|██▊       | 4595/16329 [38:41<1:36:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4595: train loss 2.09442. lr 5.711534e-04:  28%|██▊       | 4595/16329 [38:41<1:36:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4595: train loss 2.09442. lr 5.711534e-04:  28%|██▊       | 4596/16329 [38:41<1:36:00,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4596: train loss 2.15944. lr 5.711410e-04:  28%|██▊       | 4596/16329 [38:42<1:36:00,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4596: train loss 2.15944. lr 5.711410e-04:  28%|██▊       | 4597/16329 [38:42<1:36:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4597: train loss 2.15398. lr 5.711287e-04:  28%|██▊       | 4597/16329 [38:42<1:36:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4597: train loss 2.15398. lr 5.711287e-04:  28%|██▊       | 4598/16329 [38:42<1:36:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4598: train loss 2.16600. lr 5.711163e-04:  28%|██▊       | 4598/16329 [38:43<1:36:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4598: train loss 2.16600. lr 5.711163e-04:  28%|██▊       | 4599/16329 [38:43<1:36:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4599: train loss 2.15783. lr 5.711040e-04:  28%|██▊       | 4599/16329 [38:43<1:36:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4599: train loss 2.15783. lr 5.711040e-04:  28%|██▊       | 4600/16329 [38:43<1:36:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4600: train loss 2.13677. lr 5.710916e-04:  28%|██▊       | 4600/16329 [38:44<1:36:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4600: train loss 2.13677. lr 5.710916e-04:  28%|██▊       | 4601/16329 [38:44<1:35:50,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4601: train loss 2.19180. lr 5.710792e-04:  28%|██▊       | 4601/16329 [38:44<1:35:50,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 4601: train loss 2.19180. lr 5.710792e-04:  28%|██▊       | 4602/16329 [38:44<1:36:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4602: train loss 2.14800. lr 5.710669e-04:  28%|██▊       | 4602/16329 [38:45<1:36:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4602: train loss 2.14800. lr 5.710669e-04:  28%|██▊       | 4603/16329 [38:45<1:36:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4603: train loss 2.18135. lr 5.710545e-04:  28%|██▊       | 4603/16329 [38:45<1:36:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4603: train loss 2.18135. lr 5.710545e-04:  28%|██▊       | 4604/16329 [38:45<1:36:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4604: train loss 2.19912. lr 5.710421e-04:  28%|██▊       | 4604/16329 [38:46<1:36:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4604: train loss 2.19912. lr 5.710421e-04:  28%|██▊       | 4605/16329 [38:46<1:36:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4605: train loss 2.22563. lr 5.710298e-04:  28%|██▊       | 4605/16329 [38:46<1:36:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4605: train loss 2.22563. lr 5.710298e-04:  28%|██▊       | 4606/16329 [38:46<1:36:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4606: train loss 2.10245. lr 5.710174e-04:  28%|██▊       | 4606/16329 [38:47<1:36:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4606: train loss 2.10245. lr 5.710174e-04:  28%|██▊       | 4607/16329 [38:47<1:46:42,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4607: train loss 2.12565. lr 5.710050e-04:  28%|██▊       | 4607/16329 [38:47<1:46:42,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4607: train loss 2.12565. lr 5.710050e-04:  28%|██▊       | 4608/16329 [38:47<1:43:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4608: train loss 2.14661. lr 5.709926e-04:  28%|██▊       | 4608/16329 [38:48<1:43:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4608: train loss 2.14661. lr 5.709926e-04:  28%|██▊       | 4609/16329 [38:48<1:41:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4609: train loss 2.12810. lr 5.709802e-04:  28%|██▊       | 4609/16329 [38:48<1:41:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4609: train loss 2.12810. lr 5.709802e-04:  28%|██▊       | 4610/16329 [38:48<1:40:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4610: train loss 2.11700. lr 5.709679e-04:  28%|██▊       | 4610/16329 [38:49<1:40:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4610: train loss 2.11700. lr 5.709679e-04:  28%|██▊       | 4611/16329 [38:49<1:38:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4611: train loss 2.13906. lr 5.709555e-04:  28%|██▊       | 4611/16329 [38:49<1:38:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4611: train loss 2.13906. lr 5.709555e-04:  28%|██▊       | 4612/16329 [38:49<1:38:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4612: train loss 2.18696. lr 5.709431e-04:  28%|██▊       | 4612/16329 [38:50<1:38:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4612: train loss 2.18696. lr 5.709431e-04:  28%|██▊       | 4613/16329 [38:50<1:37:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4613: train loss 2.13196. lr 5.709307e-04:  28%|██▊       | 4613/16329 [38:50<1:37:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4613: train loss 2.13196. lr 5.709307e-04:  28%|██▊       | 4614/16329 [38:50<1:37:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4614: train loss 2.10938. lr 5.709183e-04:  28%|██▊       | 4614/16329 [38:51<1:37:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4614: train loss 2.10938. lr 5.709183e-04:  28%|██▊       | 4615/16329 [38:51<1:37:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4615: train loss 2.13994. lr 5.709059e-04:  28%|██▊       | 4615/16329 [38:51<1:37:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4615: train loss 2.13994. lr 5.709059e-04:  28%|██▊       | 4616/16329 [38:51<1:36:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4616: train loss 2.21333. lr 5.708935e-04:  28%|██▊       | 4616/16329 [38:52<1:36:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4616: train loss 2.21333. lr 5.708935e-04:  28%|██▊       | 4617/16329 [38:52<1:36:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4617: train loss 2.05388. lr 5.708811e-04:  28%|██▊       | 4617/16329 [38:52<1:36:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4617: train loss 2.05388. lr 5.708811e-04:  28%|██▊       | 4618/16329 [38:52<1:36:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4618: train loss 2.22115. lr 5.708687e-04:  28%|██▊       | 4618/16329 [38:53<1:36:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4618: train loss 2.22115. lr 5.708687e-04:  28%|██▊       | 4619/16329 [38:53<1:36:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4619: train loss 2.16225. lr 5.708563e-04:  28%|██▊       | 4619/16329 [38:53<1:36:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4619: train loss 2.16225. lr 5.708563e-04:  28%|██▊       | 4620/16329 [38:53<1:36:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4620: train loss 2.12218. lr 5.708439e-04:  28%|██▊       | 4620/16329 [38:54<1:36:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4620: train loss 2.12218. lr 5.708439e-04:  28%|██▊       | 4621/16329 [38:54<1:36:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4621: train loss 2.18705. lr 5.708315e-04:  28%|██▊       | 4621/16329 [38:54<1:36:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4621: train loss 2.18705. lr 5.708315e-04:  28%|██▊       | 4622/16329 [38:54<1:36:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4622: train loss 2.10550. lr 5.708190e-04:  28%|██▊       | 4622/16329 [38:55<1:36:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4622: train loss 2.10550. lr 5.708190e-04:  28%|██▊       | 4623/16329 [38:55<1:36:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4623: train loss 2.18703. lr 5.708066e-04:  28%|██▊       | 4623/16329 [38:55<1:36:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4623: train loss 2.18703. lr 5.708066e-04:  28%|██▊       | 4624/16329 [38:55<1:36:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4624: train loss 2.09780. lr 5.707942e-04:  28%|██▊       | 4624/16329 [38:56<1:36:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4624: train loss 2.09780. lr 5.707942e-04:  28%|██▊       | 4625/16329 [38:56<1:36:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4625: train loss 2.13747. lr 5.707818e-04:  28%|██▊       | 4625/16329 [38:56<1:36:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4625: train loss 2.13747. lr 5.707818e-04:  28%|██▊       | 4626/16329 [38:56<1:36:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4626: train loss 2.13018. lr 5.707694e-04:  28%|██▊       | 4626/16329 [38:57<1:36:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4626: train loss 2.13018. lr 5.707694e-04:  28%|██▊       | 4627/16329 [38:57<1:36:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4627: train loss 2.21055. lr 5.707569e-04:  28%|██▊       | 4627/16329 [38:57<1:36:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4627: train loss 2.21055. lr 5.707569e-04:  28%|██▊       | 4628/16329 [38:57<1:36:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4628: train loss 2.12793. lr 5.707445e-04:  28%|██▊       | 4628/16329 [38:58<1:36:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4628: train loss 2.12793. lr 5.707445e-04:  28%|██▊       | 4629/16329 [38:58<1:36:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4629: train loss 2.09710. lr 5.707321e-04:  28%|██▊       | 4629/16329 [38:58<1:36:20,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4629: train loss 2.09710. lr 5.707321e-04:  28%|██▊       | 4630/16329 [38:58<1:36:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4630: train loss 2.13486. lr 5.707196e-04:  28%|██▊       | 4630/16329 [38:59<1:36:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4630: train loss 2.13486. lr 5.707196e-04:  28%|██▊       | 4631/16329 [38:59<1:36:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4631: train loss 2.17186. lr 5.707072e-04:  28%|██▊       | 4631/16329 [38:59<1:36:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4631: train loss 2.17186. lr 5.707072e-04:  28%|██▊       | 4632/16329 [38:59<1:36:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4632: train loss 2.14883. lr 5.706948e-04:  28%|██▊       | 4632/16329 [39:00<1:36:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4632: train loss 2.14883. lr 5.706948e-04:  28%|██▊       | 4633/16329 [39:00<1:36:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4633: train loss 2.16391. lr 5.706823e-04:  28%|██▊       | 4633/16329 [39:00<1:36:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4633: train loss 2.16391. lr 5.706823e-04:  28%|██▊       | 4634/16329 [39:00<1:36:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4634: train loss 2.10215. lr 5.706699e-04:  28%|██▊       | 4634/16329 [39:01<1:36:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4634: train loss 2.10215. lr 5.706699e-04:  28%|██▊       | 4635/16329 [39:01<1:36:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4635: train loss 2.10282. lr 5.706574e-04:  28%|██▊       | 4635/16329 [39:01<1:36:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4635: train loss 2.10282. lr 5.706574e-04:  28%|██▊       | 4636/16329 [39:01<1:36:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4636: train loss 2.15322. lr 5.706450e-04:  28%|██▊       | 4636/16329 [39:02<1:36:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4636: train loss 2.15322. lr 5.706450e-04:  28%|██▊       | 4637/16329 [39:02<1:36:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4637: train loss 2.16119. lr 5.706325e-04:  28%|██▊       | 4637/16329 [39:02<1:36:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4637: train loss 2.16119. lr 5.706325e-04:  28%|██▊       | 4638/16329 [39:02<1:35:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4638: train loss 2.15174. lr 5.706201e-04:  28%|██▊       | 4638/16329 [39:03<1:35:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4638: train loss 2.15174. lr 5.706201e-04:  28%|██▊       | 4639/16329 [39:03<1:36:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4639: train loss 2.13533. lr 5.706076e-04:  28%|██▊       | 4639/16329 [39:03<1:36:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4639: train loss 2.13533. lr 5.706076e-04:  28%|██▊       | 4640/16329 [39:03<1:37:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4640: train loss 2.13859. lr 5.705952e-04:  28%|██▊       | 4640/16329 [39:04<1:37:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4640: train loss 2.13859. lr 5.705952e-04:  28%|██▊       | 4641/16329 [39:04<1:38:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4641: train loss 2.12280. lr 5.705827e-04:  28%|██▊       | 4641/16329 [39:04<1:38:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4641: train loss 2.12280. lr 5.705827e-04:  28%|██▊       | 4642/16329 [39:04<1:51:21,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 4642: train loss 2.15059. lr 5.705702e-04:  28%|██▊       | 4642/16329 [39:05<1:51:21,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 4642: train loss 2.15059. lr 5.705702e-04:  28%|██▊       | 4643/16329 [39:05<1:47:01,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4643: train loss 2.13381. lr 5.705578e-04:  28%|██▊       | 4643/16329 [39:05<1:47:01,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4643: train loss 2.13381. lr 5.705578e-04:  28%|██▊       | 4644/16329 [39:05<1:43:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4644: train loss 2.12413. lr 5.705453e-04:  28%|██▊       | 4644/16329 [39:06<1:43:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4644: train loss 2.12413. lr 5.705453e-04:  28%|██▊       | 4645/16329 [39:06<1:41:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4645: train loss 2.14477. lr 5.705328e-04:  28%|██▊       | 4645/16329 [39:06<1:41:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4645: train loss 2.14477. lr 5.705328e-04:  28%|██▊       | 4646/16329 [39:06<1:39:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4646: train loss 2.13912. lr 5.705203e-04:  28%|██▊       | 4646/16329 [39:07<1:39:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4646: train loss 2.13912. lr 5.705203e-04:  28%|██▊       | 4647/16329 [39:07<1:38:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4647: train loss 2.11478. lr 5.705079e-04:  28%|██▊       | 4647/16329 [39:07<1:38:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4647: train loss 2.11478. lr 5.705079e-04:  28%|██▊       | 4648/16329 [39:07<1:37:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4648: train loss 2.12061. lr 5.704954e-04:  28%|██▊       | 4648/16329 [39:08<1:37:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4648: train loss 2.12061. lr 5.704954e-04:  28%|██▊       | 4649/16329 [39:08<1:37:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4649: train loss 2.11152. lr 5.704829e-04:  28%|██▊       | 4649/16329 [39:08<1:37:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4649: train loss 2.11152. lr 5.704829e-04:  28%|██▊       | 4650/16329 [39:08<1:37:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4650: train loss 2.12824. lr 5.704704e-04:  28%|██▊       | 4650/16329 [39:09<1:37:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4650: train loss 2.12824. lr 5.704704e-04:  28%|██▊       | 4651/16329 [39:09<1:37:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4651: train loss 2.13377. lr 5.704579e-04:  28%|██▊       | 4651/16329 [39:09<1:37:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4651: train loss 2.13377. lr 5.704579e-04:  28%|██▊       | 4652/16329 [39:09<1:36:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4652: train loss 2.16756. lr 5.704454e-04:  28%|██▊       | 4652/16329 [39:10<1:36:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4652: train loss 2.16756. lr 5.704454e-04:  28%|██▊       | 4653/16329 [39:10<1:36:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4653: train loss 2.09773. lr 5.704330e-04:  28%|██▊       | 4653/16329 [39:10<1:36:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4653: train loss 2.09773. lr 5.704330e-04:  29%|██▊       | 4654/16329 [39:10<1:36:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4654: train loss 2.10143. lr 5.704205e-04:  29%|██▊       | 4654/16329 [39:11<1:36:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4654: train loss 2.10143. lr 5.704205e-04:  29%|██▊       | 4655/16329 [39:11<1:36:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4655: train loss 2.10975. lr 5.704080e-04:  29%|██▊       | 4655/16329 [39:11<1:36:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4655: train loss 2.10975. lr 5.704080e-04:  29%|██▊       | 4656/16329 [39:11<1:38:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4656: train loss 2.10798. lr 5.703955e-04:  29%|██▊       | 4656/16329 [39:12<1:38:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4656: train loss 2.10798. lr 5.703955e-04:  29%|██▊       | 4657/16329 [39:12<1:39:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4657: train loss 2.12986. lr 5.703830e-04:  29%|██▊       | 4657/16329 [39:12<1:39:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4657: train loss 2.12986. lr 5.703830e-04:  29%|██▊       | 4658/16329 [39:12<1:39:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4658: train loss 2.15713. lr 5.703705e-04:  29%|██▊       | 4658/16329 [39:13<1:39:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4658: train loss 2.15713. lr 5.703705e-04:  29%|██▊       | 4659/16329 [39:13<1:39:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4659: train loss 2.14468. lr 5.703579e-04:  29%|██▊       | 4659/16329 [39:13<1:39:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4659: train loss 2.14468. lr 5.703579e-04:  29%|██▊       | 4660/16329 [39:13<1:39:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4660: train loss 2.15386. lr 5.703454e-04:  29%|██▊       | 4660/16329 [39:14<1:39:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4660: train loss 2.15386. lr 5.703454e-04:  29%|██▊       | 4661/16329 [39:14<1:38:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4661: train loss 2.10524. lr 5.703329e-04:  29%|██▊       | 4661/16329 [39:14<1:38:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4661: train loss 2.10524. lr 5.703329e-04:  29%|██▊       | 4662/16329 [39:14<1:38:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4662: train loss 2.20593. lr 5.703204e-04:  29%|██▊       | 4662/16329 [39:15<1:38:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4662: train loss 2.20593. lr 5.703204e-04:  29%|██▊       | 4663/16329 [39:15<1:37:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4663: train loss 2.15116. lr 5.703079e-04:  29%|██▊       | 4663/16329 [39:15<1:37:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4663: train loss 2.15116. lr 5.703079e-04:  29%|██▊       | 4664/16329 [39:15<1:37:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4664: train loss 2.13458. lr 5.702954e-04:  29%|██▊       | 4664/16329 [39:16<1:37:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4664: train loss 2.13458. lr 5.702954e-04:  29%|██▊       | 4665/16329 [39:16<1:37:51,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4665: train loss 2.14970. lr 5.702828e-04:  29%|██▊       | 4665/16329 [39:16<1:37:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4665: train loss 2.14970. lr 5.702828e-04:  29%|██▊       | 4666/16329 [39:16<1:37:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4666: train loss 2.09571. lr 5.702703e-04:  29%|██▊       | 4666/16329 [39:17<1:37:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4666: train loss 2.09571. lr 5.702703e-04:  29%|██▊       | 4667/16329 [39:17<1:48:56,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4667: train loss 2.15488. lr 5.702578e-04:  29%|██▊       | 4667/16329 [39:18<1:48:56,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 4667: train loss 2.15488. lr 5.702578e-04:  29%|██▊       | 4668/16329 [39:18<1:45:28,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4668: train loss 2.12651. lr 5.702453e-04:  29%|██▊       | 4668/16329 [39:18<1:45:28,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 4668: train loss 2.12651. lr 5.702453e-04:  29%|██▊       | 4669/16329 [39:18<1:42:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4669: train loss 2.12889. lr 5.702327e-04:  29%|██▊       | 4669/16329 [39:19<1:42:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4669: train loss 2.12889. lr 5.702327e-04:  29%|██▊       | 4670/16329 [39:19<1:40:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4670: train loss 2.19429. lr 5.702202e-04:  29%|██▊       | 4670/16329 [39:19<1:40:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4670: train loss 2.19429. lr 5.702202e-04:  29%|██▊       | 4671/16329 [39:19<1:39:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4671: train loss 2.16420. lr 5.702077e-04:  29%|██▊       | 4671/16329 [39:20<1:39:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4671: train loss 2.16420. lr 5.702077e-04:  29%|██▊       | 4672/16329 [39:20<1:38:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4672: train loss 2.11417. lr 5.701951e-04:  29%|██▊       | 4672/16329 [39:20<1:38:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4672: train loss 2.11417. lr 5.701951e-04:  29%|██▊       | 4673/16329 [39:20<1:38:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4673: train loss 2.08161. lr 5.701826e-04:  29%|██▊       | 4673/16329 [39:21<1:38:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4673: train loss 2.08161. lr 5.701826e-04:  29%|██▊       | 4674/16329 [39:21<1:37:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4674: train loss 2.08983. lr 5.701700e-04:  29%|██▊       | 4674/16329 [39:21<1:37:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4674: train loss 2.08983. lr 5.701700e-04:  29%|██▊       | 4675/16329 [39:21<1:36:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4675: train loss 2.12092. lr 5.701575e-04:  29%|██▊       | 4675/16329 [39:22<1:36:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4675: train loss 2.12092. lr 5.701575e-04:  29%|██▊       | 4676/16329 [39:22<1:36:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4676: train loss 2.14387. lr 5.701449e-04:  29%|██▊       | 4676/16329 [39:22<1:36:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4676: train loss 2.14387. lr 5.701449e-04:  29%|██▊       | 4677/16329 [39:22<1:36:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4677: train loss 2.10488. lr 5.701324e-04:  29%|██▊       | 4677/16329 [39:23<1:36:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4677: train loss 2.10488. lr 5.701324e-04:  29%|██▊       | 4678/16329 [39:23<1:36:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4678: train loss 2.10973. lr 5.701198e-04:  29%|██▊       | 4678/16329 [39:23<1:36:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4678: train loss 2.10973. lr 5.701198e-04:  29%|██▊       | 4679/16329 [39:23<1:36:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4679: train loss 2.09151. lr 5.701073e-04:  29%|██▊       | 4679/16329 [39:24<1:36:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4679: train loss 2.09151. lr 5.701073e-04:  29%|██▊       | 4680/16329 [39:24<1:36:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4680: train loss 2.11383. lr 5.700947e-04:  29%|██▊       | 4680/16329 [39:24<1:36:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4680: train loss 2.11383. lr 5.700947e-04:  29%|██▊       | 4681/16329 [39:24<1:36:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4681: train loss 2.11387. lr 5.700822e-04:  29%|██▊       | 4681/16329 [39:25<1:36:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4681: train loss 2.11387. lr 5.700822e-04:  29%|██▊       | 4682/16329 [39:25<1:36:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4682: train loss 2.16362. lr 5.700696e-04:  29%|██▊       | 4682/16329 [39:25<1:36:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4682: train loss 2.16362. lr 5.700696e-04:  29%|██▊       | 4683/16329 [39:25<1:37:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4683: train loss 2.16445. lr 5.700570e-04:  29%|██▊       | 4683/16329 [39:26<1:37:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4683: train loss 2.16445. lr 5.700570e-04:  29%|██▊       | 4684/16329 [39:26<1:37:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4684: train loss 2.12684. lr 5.700444e-04:  29%|██▊       | 4684/16329 [39:26<1:37:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4684: train loss 2.12684. lr 5.700444e-04:  29%|██▊       | 4685/16329 [39:26<1:37:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4685: train loss 2.11241. lr 5.700319e-04:  29%|██▊       | 4685/16329 [39:27<1:37:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4685: train loss 2.11241. lr 5.700319e-04:  29%|██▊       | 4686/16329 [39:27<1:37:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4686: train loss 2.15024. lr 5.700193e-04:  29%|██▊       | 4686/16329 [39:27<1:37:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4686: train loss 2.15024. lr 5.700193e-04:  29%|██▊       | 4687/16329 [39:27<1:36:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4687: train loss 2.15101. lr 5.700067e-04:  29%|██▊       | 4687/16329 [39:28<1:36:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4687: train loss 2.15101. lr 5.700067e-04:  29%|██▊       | 4688/16329 [39:28<1:36:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4688: train loss 2.09884. lr 5.699941e-04:  29%|██▊       | 4688/16329 [39:28<1:36:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4688: train loss 2.09884. lr 5.699941e-04:  29%|██▊       | 4689/16329 [39:28<1:36:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4689: train loss 2.08082. lr 5.699816e-04:  29%|██▊       | 4689/16329 [39:29<1:36:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4689: train loss 2.08082. lr 5.699816e-04:  29%|██▊       | 4690/16329 [39:29<1:36:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4690: train loss 2.11405. lr 5.699690e-04:  29%|██▊       | 4690/16329 [39:29<1:36:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4690: train loss 2.11405. lr 5.699690e-04:  29%|██▊       | 4691/16329 [39:29<1:36:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4691: train loss 2.13724. lr 5.699564e-04:  29%|██▊       | 4691/16329 [39:30<1:36:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4691: train loss 2.13724. lr 5.699564e-04:  29%|██▊       | 4692/16329 [39:30<1:36:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4692: train loss 2.12923. lr 5.699438e-04:  29%|██▊       | 4692/16329 [39:30<1:36:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4692: train loss 2.12923. lr 5.699438e-04:  29%|██▊       | 4693/16329 [39:30<1:36:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4693: train loss 2.11485. lr 5.699312e-04:  29%|██▊       | 4693/16329 [39:31<1:36:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4693: train loss 2.11485. lr 5.699312e-04:  29%|██▊       | 4694/16329 [39:31<1:46:52,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 4694: train loss 2.12970. lr 5.699186e-04:  29%|██▊       | 4694/16329 [39:31<1:46:52,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 4694: train loss 2.12970. lr 5.699186e-04:  29%|██▉       | 4695/16329 [39:31<1:43:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4695: train loss 2.16747. lr 5.699060e-04:  29%|██▉       | 4695/16329 [39:32<1:43:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4695: train loss 2.16747. lr 5.699060e-04:  29%|██▉       | 4696/16329 [39:32<1:41:30,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4696: train loss 2.15688. lr 5.698934e-04:  29%|██▉       | 4696/16329 [39:32<1:41:30,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4696: train loss 2.15688. lr 5.698934e-04:  29%|██▉       | 4697/16329 [39:32<1:39:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4697: train loss 2.14410. lr 5.698808e-04:  29%|██▉       | 4697/16329 [39:33<1:39:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4697: train loss 2.14410. lr 5.698808e-04:  29%|██▉       | 4698/16329 [39:33<1:38:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4698: train loss 2.11609. lr 5.698682e-04:  29%|██▉       | 4698/16329 [39:33<1:38:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4698: train loss 2.11609. lr 5.698682e-04:  29%|██▉       | 4699/16329 [39:33<1:37:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4699: train loss 2.10876. lr 5.698556e-04:  29%|██▉       | 4699/16329 [39:34<1:37:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4699: train loss 2.10876. lr 5.698556e-04:  29%|██▉       | 4700/16329 [39:34<1:37:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4700: train loss 2.11694. lr 5.698430e-04:  29%|██▉       | 4700/16329 [39:34<1:37:21,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4700: train loss 2.11694. lr 5.698430e-04:  29%|██▉       | 4701/16329 [39:34<1:37:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4701: train loss 2.17429. lr 5.698304e-04:  29%|██▉       | 4701/16329 [39:35<1:37:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4701: train loss 2.17429. lr 5.698304e-04:  29%|██▉       | 4702/16329 [39:35<1:36:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4702: train loss 2.12322. lr 5.698178e-04:  29%|██▉       | 4702/16329 [39:35<1:36:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4702: train loss 2.12322. lr 5.698178e-04:  29%|██▉       | 4703/16329 [39:35<1:36:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4703: train loss 2.13098. lr 5.698051e-04:  29%|██▉       | 4703/16329 [39:36<1:36:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4703: train loss 2.13098. lr 5.698051e-04:  29%|██▉       | 4704/16329 [39:36<1:36:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4704: train loss 2.07302. lr 5.697925e-04:  29%|██▉       | 4704/16329 [39:36<1:36:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4704: train loss 2.07302. lr 5.697925e-04:  29%|██▉       | 4705/16329 [39:36<1:36:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4705: train loss 2.11240. lr 5.697799e-04:  29%|██▉       | 4705/16329 [39:37<1:36:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4705: train loss 2.11240. lr 5.697799e-04:  29%|██▉       | 4706/16329 [39:37<1:36:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4706: train loss 2.17032. lr 5.697673e-04:  29%|██▉       | 4706/16329 [39:37<1:36:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4706: train loss 2.17032. lr 5.697673e-04:  29%|██▉       | 4707/16329 [39:37<1:36:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4707: train loss 2.12057. lr 5.697547e-04:  29%|██▉       | 4707/16329 [39:38<1:36:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4707: train loss 2.12057. lr 5.697547e-04:  29%|██▉       | 4708/16329 [39:38<1:38:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4708: train loss 2.11558. lr 5.697420e-04:  29%|██▉       | 4708/16329 [39:38<1:38:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4708: train loss 2.11558. lr 5.697420e-04:  29%|██▉       | 4709/16329 [39:38<1:39:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4709: train loss 2.15359. lr 5.697294e-04:  29%|██▉       | 4709/16329 [39:39<1:39:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4709: train loss 2.15359. lr 5.697294e-04:  29%|██▉       | 4710/16329 [39:39<1:39:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4710: train loss 2.15810. lr 5.697168e-04:  29%|██▉       | 4710/16329 [39:39<1:39:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4710: train loss 2.15810. lr 5.697168e-04:  29%|██▉       | 4711/16329 [39:39<1:39:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4711: train loss 2.11701. lr 5.697041e-04:  29%|██▉       | 4711/16329 [39:40<1:39:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4711: train loss 2.11701. lr 5.697041e-04:  29%|██▉       | 4712/16329 [39:40<1:39:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4712: train loss 2.07371. lr 5.696915e-04:  29%|██▉       | 4712/16329 [39:40<1:39:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4712: train loss 2.07371. lr 5.696915e-04:  29%|██▉       | 4713/16329 [39:40<1:38:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4713: train loss 2.17073. lr 5.696788e-04:  29%|██▉       | 4713/16329 [39:41<1:38:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4713: train loss 2.17073. lr 5.696788e-04:  29%|██▉       | 4714/16329 [39:41<1:38:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4714: train loss 2.12439. lr 5.696662e-04:  29%|██▉       | 4714/16329 [39:41<1:38:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4714: train loss 2.12439. lr 5.696662e-04:  29%|██▉       | 4715/16329 [39:41<1:37:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4715: train loss 2.10121. lr 5.696535e-04:  29%|██▉       | 4715/16329 [39:42<1:37:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4715: train loss 2.10121. lr 5.696535e-04:  29%|██▉       | 4716/16329 [39:42<1:40:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4716: train loss 2.09571. lr 5.696409e-04:  29%|██▉       | 4716/16329 [39:42<1:40:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4716: train loss 2.09571. lr 5.696409e-04:  29%|██▉       | 4717/16329 [39:42<1:42:00,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4717: train loss 2.14693. lr 5.696282e-04:  29%|██▉       | 4717/16329 [39:43<1:42:00,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4717: train loss 2.14693. lr 5.696282e-04:  29%|██▉       | 4718/16329 [39:43<1:42:29,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4718: train loss 2.12087. lr 5.696156e-04:  29%|██▉       | 4718/16329 [39:43<1:42:29,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4718: train loss 2.12087. lr 5.696156e-04:  29%|██▉       | 4719/16329 [39:43<1:42:01,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4719: train loss 2.06632. lr 5.696029e-04:  29%|██▉       | 4719/16329 [39:44<1:42:01,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4719: train loss 2.06632. lr 5.696029e-04:  29%|██▉       | 4720/16329 [39:44<1:40:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4720: train loss 2.12787. lr 5.695903e-04:  29%|██▉       | 4720/16329 [39:44<1:40:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4720: train loss 2.12787. lr 5.695903e-04:  29%|██▉       | 4721/16329 [39:44<1:40:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4721: train loss 2.09245. lr 5.695776e-04:  29%|██▉       | 4721/16329 [39:45<1:40:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4721: train loss 2.09245. lr 5.695776e-04:  29%|██▉       | 4722/16329 [39:45<1:39:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4722: train loss 2.12321. lr 5.695649e-04:  29%|██▉       | 4722/16329 [39:45<1:39:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4722: train loss 2.12321. lr 5.695649e-04:  29%|██▉       | 4723/16329 [39:45<1:38:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4723: train loss 2.12505. lr 5.695523e-04:  29%|██▉       | 4723/16329 [39:46<1:38:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4723: train loss 2.12505. lr 5.695523e-04:  29%|██▉       | 4724/16329 [39:46<1:37:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4724: train loss 2.08898. lr 5.695396e-04:  29%|██▉       | 4724/16329 [39:46<1:37:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4724: train loss 2.08898. lr 5.695396e-04:  29%|██▉       | 4725/16329 [39:46<1:37:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4725: train loss 2.13317. lr 5.695269e-04:  29%|██▉       | 4725/16329 [39:47<1:37:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4725: train loss 2.13317. lr 5.695269e-04:  29%|██▉       | 4726/16329 [39:47<1:36:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4726: train loss 2.11640. lr 5.695143e-04:  29%|██▉       | 4726/16329 [39:47<1:36:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4726: train loss 2.11640. lr 5.695143e-04:  29%|██▉       | 4727/16329 [39:47<1:36:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4727: train loss 2.14692. lr 5.695016e-04:  29%|██▉       | 4727/16329 [39:48<1:36:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4727: train loss 2.14692. lr 5.695016e-04:  29%|██▉       | 4728/16329 [39:48<1:36:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4728: train loss 2.10437. lr 5.694889e-04:  29%|██▉       | 4728/16329 [39:48<1:36:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4728: train loss 2.10437. lr 5.694889e-04:  29%|██▉       | 4729/16329 [39:48<1:35:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4729: train loss 2.15345. lr 5.694762e-04:  29%|██▉       | 4729/16329 [39:49<1:35:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4729: train loss 2.15345. lr 5.694762e-04:  29%|██▉       | 4730/16329 [39:49<1:35:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4730: train loss 2.09251. lr 5.694635e-04:  29%|██▉       | 4730/16329 [39:49<1:35:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4730: train loss 2.09251. lr 5.694635e-04:  29%|██▉       | 4731/16329 [39:49<1:35:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4731: train loss 2.16370. lr 5.694508e-04:  29%|██▉       | 4731/16329 [39:50<1:35:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4731: train loss 2.16370. lr 5.694508e-04:  29%|██▉       | 4732/16329 [39:50<1:35:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4732: train loss 2.13693. lr 5.694382e-04:  29%|██▉       | 4732/16329 [39:50<1:35:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4732: train loss 2.13693. lr 5.694382e-04:  29%|██▉       | 4733/16329 [39:50<1:35:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4733: train loss 2.14229. lr 5.694255e-04:  29%|██▉       | 4733/16329 [39:51<1:35:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4733: train loss 2.14229. lr 5.694255e-04:  29%|██▉       | 4734/16329 [39:51<1:46:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4734: train loss 2.11879. lr 5.694128e-04:  29%|██▉       | 4734/16329 [39:52<1:46:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4734: train loss 2.11879. lr 5.694128e-04:  29%|██▉       | 4735/16329 [39:52<1:43:17,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4735: train loss 2.14652. lr 5.694001e-04:  29%|██▉       | 4735/16329 [39:52<1:43:17,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4735: train loss 2.14652. lr 5.694001e-04:  29%|██▉       | 4736/16329 [39:52<1:41:03,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4736: train loss 2.15135. lr 5.693874e-04:  29%|██▉       | 4736/16329 [39:53<1:41:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4736: train loss 2.15135. lr 5.693874e-04:  29%|██▉       | 4737/16329 [39:53<1:39:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4737: train loss 2.13476. lr 5.693747e-04:  29%|██▉       | 4737/16329 [39:53<1:39:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4737: train loss 2.13476. lr 5.693747e-04:  29%|██▉       | 4738/16329 [39:53<1:38:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4738: train loss 2.12041. lr 5.693620e-04:  29%|██▉       | 4738/16329 [39:54<1:38:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4738: train loss 2.12041. lr 5.693620e-04:  29%|██▉       | 4739/16329 [39:54<1:37:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4739: train loss 2.08981. lr 5.693493e-04:  29%|██▉       | 4739/16329 [39:54<1:37:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4739: train loss 2.08981. lr 5.693493e-04:  29%|██▉       | 4740/16329 [39:54<1:37:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4740: train loss 2.08771. lr 5.693366e-04:  29%|██▉       | 4740/16329 [39:55<1:37:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4740: train loss 2.08771. lr 5.693366e-04:  29%|██▉       | 4741/16329 [39:55<1:36:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4741: train loss 2.06313. lr 5.693238e-04:  29%|██▉       | 4741/16329 [39:55<1:36:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4741: train loss 2.06313. lr 5.693238e-04:  29%|██▉       | 4742/16329 [39:55<1:36:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4742: train loss 2.10583. lr 5.693111e-04:  29%|██▉       | 4742/16329 [39:56<1:36:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4742: train loss 2.10583. lr 5.693111e-04:  29%|██▉       | 4743/16329 [39:56<1:36:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4743: train loss 2.13267. lr 5.692984e-04:  29%|██▉       | 4743/16329 [39:56<1:36:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4743: train loss 2.13267. lr 5.692984e-04:  29%|██▉       | 4744/16329 [39:56<1:36:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4744: train loss 2.07710. lr 5.692857e-04:  29%|██▉       | 4744/16329 [39:57<1:36:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4744: train loss 2.07710. lr 5.692857e-04:  29%|██▉       | 4745/16329 [39:57<1:36:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4745: train loss 2.08060. lr 5.692730e-04:  29%|██▉       | 4745/16329 [39:57<1:36:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4745: train loss 2.08060. lr 5.692730e-04:  29%|██▉       | 4746/16329 [39:57<1:35:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4746: train loss 2.14539. lr 5.692602e-04:  29%|██▉       | 4746/16329 [39:58<1:35:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4746: train loss 2.14539. lr 5.692602e-04:  29%|██▉       | 4747/16329 [39:58<1:36:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4747: train loss 2.08966. lr 5.692475e-04:  29%|██▉       | 4747/16329 [39:58<1:36:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4747: train loss 2.08966. lr 5.692475e-04:  29%|██▉       | 4748/16329 [39:58<1:35:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4748: train loss 2.16777. lr 5.692348e-04:  29%|██▉       | 4748/16329 [39:59<1:35:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4748: train loss 2.16777. lr 5.692348e-04:  29%|██▉       | 4749/16329 [39:59<1:35:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4749: train loss 2.12548. lr 5.692221e-04:  29%|██▉       | 4749/16329 [39:59<1:35:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4749: train loss 2.12548. lr 5.692221e-04:  29%|██▉       | 4750/16329 [39:59<1:35:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4750: train loss 2.09747. lr 5.692093e-04:  29%|██▉       | 4750/16329 [40:00<1:35:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4750: train loss 2.09747. lr 5.692093e-04:  29%|██▉       | 4751/16329 [40:00<1:35:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4751: train loss 2.10765. lr 5.691966e-04:  29%|██▉       | 4751/16329 [40:00<1:35:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4751: train loss 2.10765. lr 5.691966e-04:  29%|██▉       | 4752/16329 [40:00<1:39:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4752: train loss 2.18545. lr 5.691838e-04:  29%|██▉       | 4752/16329 [40:01<1:39:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4752: train loss 2.18545. lr 5.691838e-04:  29%|██▉       | 4753/16329 [40:01<1:41:26,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4753: train loss 2.08601. lr 5.691711e-04:  29%|██▉       | 4753/16329 [40:01<1:41:26,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4753: train loss 2.08601. lr 5.691711e-04:  29%|██▉       | 4754/16329 [40:01<1:41:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4754: train loss 2.16039. lr 5.691584e-04:  29%|██▉       | 4754/16329 [40:02<1:41:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4754: train loss 2.16039. lr 5.691584e-04:  29%|██▉       | 4755/16329 [40:02<1:42:10,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4755: train loss 2.12394. lr 5.691456e-04:  29%|██▉       | 4755/16329 [40:02<1:42:10,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4755: train loss 2.12394. lr 5.691456e-04:  29%|██▉       | 4756/16329 [40:02<1:42:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4756: train loss 2.11603. lr 5.691329e-04:  29%|██▉       | 4756/16329 [40:03<1:42:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4756: train loss 2.11603. lr 5.691329e-04:  29%|██▉       | 4757/16329 [40:03<1:42:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4757: train loss 2.15389. lr 5.691201e-04:  29%|██▉       | 4757/16329 [40:03<1:42:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4757: train loss 2.15389. lr 5.691201e-04:  29%|██▉       | 4758/16329 [40:03<1:41:39,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4758: train loss 2.17707. lr 5.691074e-04:  29%|██▉       | 4758/16329 [40:04<1:41:39,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4758: train loss 2.17707. lr 5.691074e-04:  29%|██▉       | 4759/16329 [40:04<1:40:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4759: train loss 2.10825. lr 5.690946e-04:  29%|██▉       | 4759/16329 [40:04<1:40:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4759: train loss 2.10825. lr 5.690946e-04:  29%|██▉       | 4760/16329 [40:04<1:40:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4760: train loss 2.14951. lr 5.690818e-04:  29%|██▉       | 4760/16329 [40:05<1:40:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4760: train loss 2.14951. lr 5.690818e-04:  29%|██▉       | 4761/16329 [40:05<1:39:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4761: train loss 2.10071. lr 5.690691e-04:  29%|██▉       | 4761/16329 [40:05<1:39:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4761: train loss 2.10071. lr 5.690691e-04:  29%|██▉       | 4762/16329 [40:05<1:38:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4762: train loss 2.06506. lr 5.690563e-04:  29%|██▉       | 4762/16329 [40:06<1:38:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4762: train loss 2.06506. lr 5.690563e-04:  29%|██▉       | 4763/16329 [40:06<1:38:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4763: train loss 2.08653. lr 5.690435e-04:  29%|██▉       | 4763/16329 [40:06<1:38:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4763: train loss 2.08653. lr 5.690435e-04:  29%|██▉       | 4764/16329 [40:06<1:37:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4764: train loss 2.11002. lr 5.690308e-04:  29%|██▉       | 4764/16329 [40:07<1:37:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4764: train loss 2.11002. lr 5.690308e-04:  29%|██▉       | 4765/16329 [40:07<1:36:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4765: train loss 2.07513. lr 5.690180e-04:  29%|██▉       | 4765/16329 [40:07<1:36:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4765: train loss 2.07513. lr 5.690180e-04:  29%|██▉       | 4766/16329 [40:07<1:36:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4766: train loss 2.17683. lr 5.690052e-04:  29%|██▉       | 4766/16329 [40:08<1:36:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4766: train loss 2.17683. lr 5.690052e-04:  29%|██▉       | 4767/16329 [40:08<1:35:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4767: train loss 2.12835. lr 5.689925e-04:  29%|██▉       | 4767/16329 [40:08<1:35:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4767: train loss 2.12835. lr 5.689925e-04:  29%|██▉       | 4768/16329 [40:08<1:35:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4768: train loss 2.14882. lr 5.689797e-04:  29%|██▉       | 4768/16329 [40:09<1:35:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4768: train loss 2.14882. lr 5.689797e-04:  29%|██▉       | 4769/16329 [40:09<1:45:50,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4769: train loss 2.11498. lr 5.689669e-04:  29%|██▉       | 4769/16329 [40:09<1:45:50,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4769: train loss 2.11498. lr 5.689669e-04:  29%|██▉       | 4770/16329 [40:09<1:42:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4770: train loss 2.10385. lr 5.689541e-04:  29%|██▉       | 4770/16329 [40:10<1:42:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4770: train loss 2.10385. lr 5.689541e-04:  29%|██▉       | 4771/16329 [40:10<1:40:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4771: train loss 2.13471. lr 5.689413e-04:  29%|██▉       | 4771/16329 [40:10<1:40:11,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4771: train loss 2.13471. lr 5.689413e-04:  29%|██▉       | 4772/16329 [40:10<1:38:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4772: train loss 2.13895. lr 5.689285e-04:  29%|██▉       | 4772/16329 [40:11<1:38:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4772: train loss 2.13895. lr 5.689285e-04:  29%|██▉       | 4773/16329 [40:11<1:37:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4773: train loss 2.09984. lr 5.689157e-04:  29%|██▉       | 4773/16329 [40:11<1:37:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4773: train loss 2.09984. lr 5.689157e-04:  29%|██▉       | 4774/16329 [40:11<1:37:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4774: train loss 2.13899. lr 5.689029e-04:  29%|██▉       | 4774/16329 [40:12<1:37:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4774: train loss 2.13899. lr 5.689029e-04:  29%|██▉       | 4775/16329 [40:12<1:36:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4775: train loss 2.15741. lr 5.688901e-04:  29%|██▉       | 4775/16329 [40:12<1:36:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4775: train loss 2.15741. lr 5.688901e-04:  29%|██▉       | 4776/16329 [40:12<1:36:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4776: train loss 2.12376. lr 5.688773e-04:  29%|██▉       | 4776/16329 [40:13<1:36:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4776: train loss 2.12376. lr 5.688773e-04:  29%|██▉       | 4777/16329 [40:13<1:36:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4777: train loss 2.09147. lr 5.688645e-04:  29%|██▉       | 4777/16329 [40:13<1:36:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4777: train loss 2.09147. lr 5.688645e-04:  29%|██▉       | 4778/16329 [40:13<1:35:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4778: train loss 2.15015. lr 5.688517e-04:  29%|██▉       | 4778/16329 [40:14<1:35:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4778: train loss 2.15015. lr 5.688517e-04:  29%|██▉       | 4779/16329 [40:14<1:35:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4779: train loss 2.06901. lr 5.688389e-04:  29%|██▉       | 4779/16329 [40:14<1:35:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4779: train loss 2.06901. lr 5.688389e-04:  29%|██▉       | 4780/16329 [40:14<1:35:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4780: train loss 2.06213. lr 5.688261e-04:  29%|██▉       | 4780/16329 [40:15<1:35:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4780: train loss 2.06213. lr 5.688261e-04:  29%|██▉       | 4781/16329 [40:15<1:35:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4781: train loss 2.14604. lr 5.688133e-04:  29%|██▉       | 4781/16329 [40:15<1:35:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4781: train loss 2.14604. lr 5.688133e-04:  29%|██▉       | 4782/16329 [40:15<1:35:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4782: train loss 2.06203. lr 5.688005e-04:  29%|██▉       | 4782/16329 [40:16<1:35:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4782: train loss 2.06203. lr 5.688005e-04:  29%|██▉       | 4783/16329 [40:16<1:35:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4783: train loss 2.05372. lr 5.687877e-04:  29%|██▉       | 4783/16329 [40:16<1:35:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4783: train loss 2.05372. lr 5.687877e-04:  29%|██▉       | 4784/16329 [40:16<1:35:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4784: train loss 2.17229. lr 5.687749e-04:  29%|██▉       | 4784/16329 [40:17<1:35:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4784: train loss 2.17229. lr 5.687749e-04:  29%|██▉       | 4785/16329 [40:17<1:36:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4785: train loss 2.06357. lr 5.687620e-04:  29%|██▉       | 4785/16329 [40:17<1:36:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4785: train loss 2.06357. lr 5.687620e-04:  29%|██▉       | 4786/16329 [40:17<1:36:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4786: train loss 2.12623. lr 5.687492e-04:  29%|██▉       | 4786/16329 [40:18<1:36:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4786: train loss 2.12623. lr 5.687492e-04:  29%|██▉       | 4787/16329 [40:18<1:36:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4787: train loss 2.10409. lr 5.687364e-04:  29%|██▉       | 4787/16329 [40:18<1:36:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4787: train loss 2.10409. lr 5.687364e-04:  29%|██▉       | 4788/16329 [40:18<1:36:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4788: train loss 2.16364. lr 5.687236e-04:  29%|██▉       | 4788/16329 [40:19<1:36:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4788: train loss 2.16364. lr 5.687236e-04:  29%|██▉       | 4789/16329 [40:19<1:36:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4789: train loss 2.10983. lr 5.687107e-04:  29%|██▉       | 4789/16329 [40:19<1:36:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4789: train loss 2.10983. lr 5.687107e-04:  29%|██▉       | 4790/16329 [40:19<1:36:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4790: train loss 2.07822. lr 5.686979e-04:  29%|██▉       | 4790/16329 [40:20<1:36:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4790: train loss 2.07822. lr 5.686979e-04:  29%|██▉       | 4791/16329 [40:20<1:36:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4791: train loss 2.12162. lr 5.686851e-04:  29%|██▉       | 4791/16329 [40:20<1:36:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4791: train loss 2.12162. lr 5.686851e-04:  29%|██▉       | 4792/16329 [40:20<1:35:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4792: train loss 2.07998. lr 5.686722e-04:  29%|██▉       | 4792/16329 [40:21<1:35:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4792: train loss 2.07998. lr 5.686722e-04:  29%|██▉       | 4793/16329 [40:21<1:36:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4793: train loss 2.04262. lr 5.686594e-04:  29%|██▉       | 4793/16329 [40:22<1:36:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4793: train loss 2.04262. lr 5.686594e-04:  29%|██▉       | 4794/16329 [40:22<1:49:04,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 4794: train loss 2.12071. lr 5.686465e-04:  29%|██▉       | 4794/16329 [40:22<1:49:04,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 4794: train loss 2.12071. lr 5.686465e-04:  29%|██▉       | 4795/16329 [40:22<1:45:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4795: train loss 2.01588. lr 5.686337e-04:  29%|██▉       | 4795/16329 [40:23<1:45:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4795: train loss 2.01588. lr 5.686337e-04:  29%|██▉       | 4796/16329 [40:23<1:42:36,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4796: train loss 2.13913. lr 5.686208e-04:  29%|██▉       | 4796/16329 [40:23<1:42:36,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4796: train loss 2.13913. lr 5.686208e-04:  29%|██▉       | 4797/16329 [40:23<1:40:47,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4797: train loss 2.10234. lr 5.686080e-04:  29%|██▉       | 4797/16329 [40:24<1:40:47,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4797: train loss 2.10234. lr 5.686080e-04:  29%|██▉       | 4798/16329 [40:24<1:39:50,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4798: train loss 2.06819. lr 5.685951e-04:  29%|██▉       | 4798/16329 [40:24<1:39:50,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4798: train loss 2.06819. lr 5.685951e-04:  29%|██▉       | 4799/16329 [40:24<1:39:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4799: train loss 2.10248. lr 5.685823e-04:  29%|██▉       | 4799/16329 [40:25<1:39:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4799: train loss 2.10248. lr 5.685823e-04:  29%|██▉       | 4800/16329 [40:25<1:38:01,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4800: train loss 2.03614. lr 5.685694e-04:  29%|██▉       | 4800/16329 [40:25<1:38:01,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4800: train loss 2.03614. lr 5.685694e-04:  29%|██▉       | 4801/16329 [40:25<1:37:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4801: train loss 2.10800. lr 5.685566e-04:  29%|██▉       | 4801/16329 [40:26<1:37:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4801: train loss 2.10800. lr 5.685566e-04:  29%|██▉       | 4802/16329 [40:26<1:36:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4802: train loss 2.07272. lr 5.685437e-04:  29%|██▉       | 4802/16329 [40:26<1:36:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4802: train loss 2.07272. lr 5.685437e-04:  29%|██▉       | 4803/16329 [40:26<1:36:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4803: train loss 2.13962. lr 5.685308e-04:  29%|██▉       | 4803/16329 [40:27<1:36:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4803: train loss 2.13962. lr 5.685308e-04:  29%|██▉       | 4804/16329 [40:27<1:36:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4804: train loss 2.09961. lr 5.685180e-04:  29%|██▉       | 4804/16329 [40:27<1:36:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4804: train loss 2.09961. lr 5.685180e-04:  29%|██▉       | 4805/16329 [40:27<1:36:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4805: train loss 2.11190. lr 5.685051e-04:  29%|██▉       | 4805/16329 [40:28<1:36:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4805: train loss 2.11190. lr 5.685051e-04:  29%|██▉       | 4806/16329 [40:28<1:36:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4806: train loss 2.06214. lr 5.684922e-04:  29%|██▉       | 4806/16329 [40:28<1:36:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4806: train loss 2.06214. lr 5.684922e-04:  29%|██▉       | 4807/16329 [40:28<1:36:13,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4807: train loss 2.08578. lr 5.684793e-04:  29%|██▉       | 4807/16329 [40:29<1:36:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4807: train loss 2.08578. lr 5.684793e-04:  29%|██▉       | 4808/16329 [40:29<1:36:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4808: train loss 2.04879. lr 5.684665e-04:  29%|██▉       | 4808/16329 [40:29<1:36:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4808: train loss 2.04879. lr 5.684665e-04:  29%|██▉       | 4809/16329 [40:29<1:36:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4809: train loss 2.04552. lr 5.684536e-04:  29%|██▉       | 4809/16329 [40:30<1:36:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4809: train loss 2.04552. lr 5.684536e-04:  29%|██▉       | 4810/16329 [40:30<1:35:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4810: train loss 2.04888. lr 5.684407e-04:  29%|██▉       | 4810/16329 [40:30<1:35:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4810: train loss 2.04888. lr 5.684407e-04:  29%|██▉       | 4811/16329 [40:30<1:36:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4811: train loss 2.02683. lr 5.684278e-04:  29%|██▉       | 4811/16329 [40:31<1:36:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4811: train loss 2.02683. lr 5.684278e-04:  29%|██▉       | 4812/16329 [40:31<1:35:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4812: train loss 2.16580. lr 5.684149e-04:  29%|██▉       | 4812/16329 [40:31<1:35:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4812: train loss 2.16580. lr 5.684149e-04:  29%|██▉       | 4813/16329 [40:31<1:36:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4813: train loss 2.11143. lr 5.684020e-04:  29%|██▉       | 4813/16329 [40:32<1:36:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4813: train loss 2.11143. lr 5.684020e-04:  29%|██▉       | 4814/16329 [40:32<1:36:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4814: train loss 2.08500. lr 5.683891e-04:  29%|██▉       | 4814/16329 [40:32<1:36:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4814: train loss 2.08500. lr 5.683891e-04:  29%|██▉       | 4815/16329 [40:32<1:36:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4815: train loss 2.09318. lr 5.683762e-04:  29%|██▉       | 4815/16329 [40:33<1:36:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4815: train loss 2.09318. lr 5.683762e-04:  29%|██▉       | 4816/16329 [40:33<1:36:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4816: train loss 2.08382. lr 5.683633e-04:  29%|██▉       | 4816/16329 [40:33<1:36:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4816: train loss 2.08382. lr 5.683633e-04:  29%|██▉       | 4817/16329 [40:33<1:36:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4817: train loss 2.15138. lr 5.683504e-04:  29%|██▉       | 4817/16329 [40:34<1:36:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4817: train loss 2.15138. lr 5.683504e-04:  30%|██▉       | 4818/16329 [40:34<1:36:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4818: train loss 2.05606. lr 5.683375e-04:  30%|██▉       | 4818/16329 [40:34<1:36:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4818: train loss 2.05606. lr 5.683375e-04:  30%|██▉       | 4819/16329 [40:34<1:36:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4819: train loss 2.06734. lr 5.683246e-04:  30%|██▉       | 4819/16329 [40:35<1:36:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4819: train loss 2.06734. lr 5.683246e-04:  30%|██▉       | 4820/16329 [40:35<1:36:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4820: train loss 2.08329. lr 5.683117e-04:  30%|██▉       | 4820/16329 [40:35<1:36:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4820: train loss 2.08329. lr 5.683117e-04:  30%|██▉       | 4821/16329 [40:35<1:46:44,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 4821: train loss 2.07573. lr 5.682988e-04:  30%|██▉       | 4821/16329 [40:36<1:46:44,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 4821: train loss 2.07573. lr 5.682988e-04:  30%|██▉       | 4822/16329 [40:36<1:43:51,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 4822: train loss 2.11357. lr 5.682859e-04:  30%|██▉       | 4822/16329 [40:36<1:43:51,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 4822: train loss 2.11357. lr 5.682859e-04:  30%|██▉       | 4823/16329 [40:36<1:41:32,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4823: train loss 2.13890. lr 5.682730e-04:  30%|██▉       | 4823/16329 [40:37<1:41:32,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 4823: train loss 2.13890. lr 5.682730e-04:  30%|██▉       | 4824/16329 [40:37<1:40:03,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4824: train loss 2.03469. lr 5.682601e-04:  30%|██▉       | 4824/16329 [40:37<1:40:03,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4824: train loss 2.03469. lr 5.682601e-04:  30%|██▉       | 4825/16329 [40:37<1:38:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4825: train loss 2.06617. lr 5.682471e-04:  30%|██▉       | 4825/16329 [40:38<1:38:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4825: train loss 2.06617. lr 5.682471e-04:  30%|██▉       | 4826/16329 [40:38<1:38:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4826: train loss 2.10925. lr 5.682342e-04:  30%|██▉       | 4826/16329 [40:38<1:38:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4826: train loss 2.10925. lr 5.682342e-04:  30%|██▉       | 4827/16329 [40:38<1:37:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4827: train loss 2.10425. lr 5.682213e-04:  30%|██▉       | 4827/16329 [40:39<1:37:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4827: train loss 2.10425. lr 5.682213e-04:  30%|██▉       | 4828/16329 [40:39<1:37:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4828: train loss 2.08032. lr 5.682084e-04:  30%|██▉       | 4828/16329 [40:39<1:37:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4828: train loss 2.08032. lr 5.682084e-04:  30%|██▉       | 4829/16329 [40:39<1:36:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4829: train loss 2.06907. lr 5.681954e-04:  30%|██▉       | 4829/16329 [40:40<1:36:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4829: train loss 2.06907. lr 5.681954e-04:  30%|██▉       | 4830/16329 [40:40<1:36:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4830: train loss 2.11669. lr 5.681825e-04:  30%|██▉       | 4830/16329 [40:40<1:36:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4830: train loss 2.11669. lr 5.681825e-04:  30%|██▉       | 4831/16329 [40:40<1:36:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4831: train loss 2.07740. lr 5.681696e-04:  30%|██▉       | 4831/16329 [40:41<1:36:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4831: train loss 2.07740. lr 5.681696e-04:  30%|██▉       | 4832/16329 [40:41<1:35:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4832: train loss 2.05559. lr 5.681566e-04:  30%|██▉       | 4832/16329 [40:41<1:35:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4832: train loss 2.05559. lr 5.681566e-04:  30%|██▉       | 4833/16329 [40:41<1:36:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4833: train loss 2.14723. lr 5.681437e-04:  30%|██▉       | 4833/16329 [40:42<1:36:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4833: train loss 2.14723. lr 5.681437e-04:  30%|██▉       | 4834/16329 [40:42<1:36:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4834: train loss 2.14404. lr 5.681307e-04:  30%|██▉       | 4834/16329 [40:42<1:36:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4834: train loss 2.14404. lr 5.681307e-04:  30%|██▉       | 4835/16329 [40:42<1:36:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4835: train loss 2.15890. lr 5.681178e-04:  30%|██▉       | 4835/16329 [40:43<1:36:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4835: train loss 2.15890. lr 5.681178e-04:  30%|██▉       | 4836/16329 [40:43<1:35:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4836: train loss 2.12407. lr 5.681048e-04:  30%|██▉       | 4836/16329 [40:43<1:35:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4836: train loss 2.12407. lr 5.681048e-04:  30%|██▉       | 4837/16329 [40:43<1:35:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4837: train loss 2.15353. lr 5.680919e-04:  30%|██▉       | 4837/16329 [40:44<1:35:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4837: train loss 2.15353. lr 5.680919e-04:  30%|██▉       | 4838/16329 [40:44<1:35:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4838: train loss 2.10156. lr 5.680789e-04:  30%|██▉       | 4838/16329 [40:44<1:35:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4838: train loss 2.10156. lr 5.680789e-04:  30%|██▉       | 4839/16329 [40:44<1:35:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4839: train loss 2.11118. lr 5.680660e-04:  30%|██▉       | 4839/16329 [40:45<1:35:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4839: train loss 2.11118. lr 5.680660e-04:  30%|██▉       | 4840/16329 [40:45<1:35:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4840: train loss 2.10066. lr 5.680530e-04:  30%|██▉       | 4840/16329 [40:45<1:35:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4840: train loss 2.10066. lr 5.680530e-04:  30%|██▉       | 4841/16329 [40:45<1:35:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4841: train loss 2.09305. lr 5.680401e-04:  30%|██▉       | 4841/16329 [40:46<1:35:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4841: train loss 2.09305. lr 5.680401e-04:  30%|██▉       | 4842/16329 [40:46<1:36:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4842: train loss 2.11359. lr 5.680271e-04:  30%|██▉       | 4842/16329 [40:46<1:36:07,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4842: train loss 2.11359. lr 5.680271e-04:  30%|██▉       | 4843/16329 [40:46<1:36:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4843: train loss 2.07773. lr 5.680141e-04:  30%|██▉       | 4843/16329 [40:47<1:36:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4843: train loss 2.07773. lr 5.680141e-04:  30%|██▉       | 4844/16329 [40:47<1:36:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4844: train loss 2.07924. lr 5.680012e-04:  30%|██▉       | 4844/16329 [40:47<1:36:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4844: train loss 2.07924. lr 5.680012e-04:  30%|██▉       | 4845/16329 [40:47<1:36:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4845: train loss 2.08910. lr 5.679882e-04:  30%|██▉       | 4845/16329 [40:48<1:36:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4845: train loss 2.08910. lr 5.679882e-04:  30%|██▉       | 4846/16329 [40:48<1:36:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4846: train loss 2.11288. lr 5.679752e-04:  30%|██▉       | 4846/16329 [40:48<1:36:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4846: train loss 2.11288. lr 5.679752e-04:  30%|██▉       | 4847/16329 [40:48<1:35:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4847: train loss 2.08770. lr 5.679622e-04:  30%|██▉       | 4847/16329 [40:49<1:35:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4847: train loss 2.08770. lr 5.679622e-04:  30%|██▉       | 4848/16329 [40:49<1:35:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4848: train loss 2.13156. lr 5.679493e-04:  30%|██▉       | 4848/16329 [40:49<1:35:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4848: train loss 2.13156. lr 5.679493e-04:  30%|██▉       | 4849/16329 [40:49<1:35:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4849: train loss 2.07186. lr 5.679363e-04:  30%|██▉       | 4849/16329 [40:50<1:35:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4849: train loss 2.07186. lr 5.679363e-04:  30%|██▉       | 4850/16329 [40:50<1:35:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4850: train loss 2.10523. lr 5.679233e-04:  30%|██▉       | 4850/16329 [40:50<1:35:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4850: train loss 2.10523. lr 5.679233e-04:  30%|██▉       | 4851/16329 [40:50<1:35:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4851: train loss 2.06558. lr 5.679103e-04:  30%|██▉       | 4851/16329 [40:51<1:35:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4851: train loss 2.06558. lr 5.679103e-04:  30%|██▉       | 4852/16329 [40:51<1:39:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4852: train loss 2.08558. lr 5.678973e-04:  30%|██▉       | 4852/16329 [40:51<1:39:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4852: train loss 2.08558. lr 5.678973e-04:  30%|██▉       | 4853/16329 [40:51<1:40:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4853: train loss 2.10203. lr 5.678843e-04:  30%|██▉       | 4853/16329 [40:52<1:40:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4853: train loss 2.10203. lr 5.678843e-04:  30%|██▉       | 4854/16329 [40:52<1:40:48,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4854: train loss 2.09372. lr 5.678713e-04:  30%|██▉       | 4854/16329 [40:53<1:40:48,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4854: train loss 2.09372. lr 5.678713e-04:  30%|██▉       | 4855/16329 [40:53<1:40:28,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4855: train loss 2.11149. lr 5.678584e-04:  30%|██▉       | 4855/16329 [40:53<1:40:28,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4855: train loss 2.11149. lr 5.678584e-04:  30%|██▉       | 4856/16329 [40:53<1:40:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4856: train loss 2.09479. lr 5.678454e-04:  30%|██▉       | 4856/16329 [40:54<1:40:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4856: train loss 2.09479. lr 5.678454e-04:  30%|██▉       | 4857/16329 [40:54<1:39:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4857: train loss 2.08094. lr 5.678324e-04:  30%|██▉       | 4857/16329 [40:54<1:39:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4857: train loss 2.08094. lr 5.678324e-04:  30%|██▉       | 4858/16329 [40:54<1:39:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4858: train loss 2.14402. lr 5.678194e-04:  30%|██▉       | 4858/16329 [40:55<1:39:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4858: train loss 2.14402. lr 5.678194e-04:  30%|██▉       | 4859/16329 [40:55<1:38:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4859: train loss 2.10747. lr 5.678063e-04:  30%|██▉       | 4859/16329 [40:55<1:38:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4859: train loss 2.10747. lr 5.678063e-04:  30%|██▉       | 4860/16329 [40:55<1:38:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4860: train loss 2.11135. lr 5.677933e-04:  30%|██▉       | 4860/16329 [40:56<1:38:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4860: train loss 2.11135. lr 5.677933e-04:  30%|██▉       | 4861/16329 [40:56<1:47:45,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 4861: train loss 2.06179. lr 5.677803e-04:  30%|██▉       | 4861/16329 [40:56<1:47:45,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 4861: train loss 2.06179. lr 5.677803e-04:  30%|██▉       | 4862/16329 [40:56<1:44:18,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4862: train loss 2.11022. lr 5.677673e-04:  30%|██▉       | 4862/16329 [40:57<1:44:18,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 4862: train loss 2.11022. lr 5.677673e-04:  30%|██▉       | 4863/16329 [40:57<1:41:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4863: train loss 2.08388. lr 5.677543e-04:  30%|██▉       | 4863/16329 [40:57<1:41:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4863: train loss 2.08388. lr 5.677543e-04:  30%|██▉       | 4864/16329 [40:57<1:39:41,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4864: train loss 2.07195. lr 5.677413e-04:  30%|██▉       | 4864/16329 [40:58<1:39:41,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4864: train loss 2.07195. lr 5.677413e-04:  30%|██▉       | 4865/16329 [40:58<1:38:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4865: train loss 2.03680. lr 5.677283e-04:  30%|██▉       | 4865/16329 [40:58<1:38:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4865: train loss 2.03680. lr 5.677283e-04:  30%|██▉       | 4866/16329 [40:58<1:37:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4866: train loss 2.07749. lr 5.677152e-04:  30%|██▉       | 4866/16329 [40:59<1:37:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4866: train loss 2.07749. lr 5.677152e-04:  30%|██▉       | 4867/16329 [40:59<1:37:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4867: train loss 2.06613. lr 5.677022e-04:  30%|██▉       | 4867/16329 [40:59<1:37:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4867: train loss 2.06613. lr 5.677022e-04:  30%|██▉       | 4868/16329 [40:59<1:36:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4868: train loss 2.09269. lr 5.676892e-04:  30%|██▉       | 4868/16329 [41:00<1:36:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4868: train loss 2.09269. lr 5.676892e-04:  30%|██▉       | 4869/16329 [41:00<1:36:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4869: train loss 2.06641. lr 5.676762e-04:  30%|██▉       | 4869/16329 [41:00<1:36:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4869: train loss 2.06641. lr 5.676762e-04:  30%|██▉       | 4870/16329 [41:00<1:36:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4870: train loss 2.09846. lr 5.676631e-04:  30%|██▉       | 4870/16329 [41:01<1:36:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4870: train loss 2.09846. lr 5.676631e-04:  30%|██▉       | 4871/16329 [41:01<1:36:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4871: train loss 2.06881. lr 5.676501e-04:  30%|██▉       | 4871/16329 [41:01<1:36:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4871: train loss 2.06881. lr 5.676501e-04:  30%|██▉       | 4872/16329 [41:01<1:35:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4872: train loss 2.08918. lr 5.676370e-04:  30%|██▉       | 4872/16329 [41:02<1:35:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4872: train loss 2.08918. lr 5.676370e-04:  30%|██▉       | 4873/16329 [41:02<1:35:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4873: train loss 2.07020. lr 5.676240e-04:  30%|██▉       | 4873/16329 [41:02<1:35:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4873: train loss 2.07020. lr 5.676240e-04:  30%|██▉       | 4874/16329 [41:02<1:37:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4874: train loss 2.03213. lr 5.676110e-04:  30%|██▉       | 4874/16329 [41:03<1:37:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4874: train loss 2.03213. lr 5.676110e-04:  30%|██▉       | 4875/16329 [41:03<1:39:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4875: train loss 2.05821. lr 5.675979e-04:  30%|██▉       | 4875/16329 [41:03<1:39:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4875: train loss 2.05821. lr 5.675979e-04:  30%|██▉       | 4876/16329 [41:03<1:39:51,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4876: train loss 1.99715. lr 5.675849e-04:  30%|██▉       | 4876/16329 [41:04<1:39:51,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4876: train loss 1.99715. lr 5.675849e-04:  30%|██▉       | 4877/16329 [41:04<1:39:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4877: train loss 2.02877. lr 5.675718e-04:  30%|██▉       | 4877/16329 [41:04<1:39:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4877: train loss 2.02877. lr 5.675718e-04:  30%|██▉       | 4878/16329 [41:04<1:39:31,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4878: train loss 2.11117. lr 5.675588e-04:  30%|██▉       | 4878/16329 [41:05<1:39:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4878: train loss 2.11117. lr 5.675588e-04:  30%|██▉       | 4879/16329 [41:05<1:38:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4879: train loss 2.09163. lr 5.675457e-04:  30%|██▉       | 4879/16329 [41:05<1:38:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4879: train loss 2.09163. lr 5.675457e-04:  30%|██▉       | 4880/16329 [41:05<1:38:15,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4880: train loss 2.13740. lr 5.675327e-04:  30%|██▉       | 4880/16329 [41:06<1:38:15,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4880: train loss 2.13740. lr 5.675327e-04:  30%|██▉       | 4881/16329 [41:06<1:37:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4881: train loss 2.01467. lr 5.675196e-04:  30%|██▉       | 4881/16329 [41:06<1:37:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4881: train loss 2.01467. lr 5.675196e-04:  30%|██▉       | 4882/16329 [41:06<1:37:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4882: train loss 2.10486. lr 5.675065e-04:  30%|██▉       | 4882/16329 [41:07<1:37:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4882: train loss 2.10486. lr 5.675065e-04:  30%|██▉       | 4883/16329 [41:07<1:36:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4883: train loss 2.08080. lr 5.674935e-04:  30%|██▉       | 4883/16329 [41:07<1:36:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4883: train loss 2.08080. lr 5.674935e-04:  30%|██▉       | 4884/16329 [41:07<1:36:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4884: train loss 2.08709. lr 5.674804e-04:  30%|██▉       | 4884/16329 [41:08<1:36:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4884: train loss 2.08709. lr 5.674804e-04:  30%|██▉       | 4885/16329 [41:08<1:36:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4885: train loss 2.11226. lr 5.674673e-04:  30%|██▉       | 4885/16329 [41:08<1:36:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4885: train loss 2.11226. lr 5.674673e-04:  30%|██▉       | 4886/16329 [41:08<1:35:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4886: train loss 2.09371. lr 5.674543e-04:  30%|██▉       | 4886/16329 [41:09<1:35:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4886: train loss 2.09371. lr 5.674543e-04:  30%|██▉       | 4887/16329 [41:09<1:35:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4887: train loss 2.07447. lr 5.674412e-04:  30%|██▉       | 4887/16329 [41:09<1:35:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4887: train loss 2.07447. lr 5.674412e-04:  30%|██▉       | 4888/16329 [41:09<1:35:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4888: train loss 2.08415. lr 5.674281e-04:  30%|██▉       | 4888/16329 [41:10<1:35:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4888: train loss 2.08415. lr 5.674281e-04:  30%|██▉       | 4889/16329 [41:10<1:35:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4889: train loss 2.07197. lr 5.674150e-04:  30%|██▉       | 4889/16329 [41:10<1:35:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4889: train loss 2.07197. lr 5.674150e-04:  30%|██▉       | 4890/16329 [41:10<1:35:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4890: train loss 2.06212. lr 5.674019e-04:  30%|██▉       | 4890/16329 [41:11<1:35:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4890: train loss 2.06212. lr 5.674019e-04:  30%|██▉       | 4891/16329 [41:11<1:35:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4891: train loss 2.08838. lr 5.673889e-04:  30%|██▉       | 4891/16329 [41:11<1:35:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4891: train loss 2.08838. lr 5.673889e-04:  30%|██▉       | 4892/16329 [41:11<1:35:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4892: train loss 2.05498. lr 5.673758e-04:  30%|██▉       | 4892/16329 [41:12<1:35:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4892: train loss 2.05498. lr 5.673758e-04:  30%|██▉       | 4893/16329 [41:12<1:35:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4893: train loss 2.07814. lr 5.673627e-04:  30%|██▉       | 4893/16329 [41:12<1:35:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4893: train loss 2.07814. lr 5.673627e-04:  30%|██▉       | 4894/16329 [41:12<1:35:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4894: train loss 2.10526. lr 5.673496e-04:  30%|██▉       | 4894/16329 [41:13<1:35:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4894: train loss 2.10526. lr 5.673496e-04:  30%|██▉       | 4895/16329 [41:13<1:35:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4895: train loss 1.99663. lr 5.673365e-04:  30%|██▉       | 4895/16329 [41:14<1:35:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4895: train loss 1.99663. lr 5.673365e-04:  30%|██▉       | 4896/16329 [41:14<1:45:10,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 4896: train loss 2.05597. lr 5.673234e-04:  30%|██▉       | 4896/16329 [41:14<1:45:10,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 4896: train loss 2.05597. lr 5.673234e-04:  30%|██▉       | 4897/16329 [41:14<1:42:26,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4897: train loss 2.06380. lr 5.673103e-04:  30%|██▉       | 4897/16329 [41:15<1:42:26,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 4897: train loss 2.06380. lr 5.673103e-04:  30%|██▉       | 4898/16329 [41:15<1:41:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4898: train loss 2.14468. lr 5.672972e-04:  30%|██▉       | 4898/16329 [41:15<1:41:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4898: train loss 2.14468. lr 5.672972e-04:  30%|███       | 4899/16329 [41:15<1:40:13,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4899: train loss 2.16409. lr 5.672841e-04:  30%|███       | 4899/16329 [41:16<1:40:13,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 4899: train loss 2.16409. lr 5.672841e-04:  30%|███       | 4900/16329 [41:16<1:39:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4900: train loss 2.09609. lr 5.672710e-04:  30%|███       | 4900/16329 [41:16<1:39:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4900: train loss 2.09609. lr 5.672710e-04:  30%|███       | 4901/16329 [41:16<1:38:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4901: train loss 2.08027. lr 5.672579e-04:  30%|███       | 4901/16329 [41:17<1:38:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4901: train loss 2.08027. lr 5.672579e-04:  30%|███       | 4902/16329 [41:17<1:39:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4902: train loss 2.06682. lr 5.672448e-04:  30%|███       | 4902/16329 [41:17<1:39:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4902: train loss 2.06682. lr 5.672448e-04:  30%|███       | 4903/16329 [41:17<1:39:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4903: train loss 2.13572. lr 5.672317e-04:  30%|███       | 4903/16329 [41:18<1:39:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4903: train loss 2.13572. lr 5.672317e-04:  30%|███       | 4904/16329 [41:18<1:38:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4904: train loss 2.06954. lr 5.672185e-04:  30%|███       | 4904/16329 [41:18<1:38:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4904: train loss 2.06954. lr 5.672185e-04:  30%|███       | 4905/16329 [41:18<1:38:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4905: train loss 2.09054. lr 5.672054e-04:  30%|███       | 4905/16329 [41:19<1:38:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4905: train loss 2.09054. lr 5.672054e-04:  30%|███       | 4906/16329 [41:19<1:37:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4906: train loss 2.04956. lr 5.671923e-04:  30%|███       | 4906/16329 [41:19<1:37:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4906: train loss 2.04956. lr 5.671923e-04:  30%|███       | 4907/16329 [41:19<1:37:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4907: train loss 2.06664. lr 5.671792e-04:  30%|███       | 4907/16329 [41:20<1:37:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4907: train loss 2.06664. lr 5.671792e-04:  30%|███       | 4908/16329 [41:20<1:36:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4908: train loss 2.10221. lr 5.671660e-04:  30%|███       | 4908/16329 [41:20<1:36:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4908: train loss 2.10221. lr 5.671660e-04:  30%|███       | 4909/16329 [41:20<1:36:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4909: train loss 2.11631. lr 5.671529e-04:  30%|███       | 4909/16329 [41:21<1:36:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4909: train loss 2.11631. lr 5.671529e-04:  30%|███       | 4910/16329 [41:21<1:35:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4910: train loss 2.05783. lr 5.671398e-04:  30%|███       | 4910/16329 [41:21<1:35:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4910: train loss 2.05783. lr 5.671398e-04:  30%|███       | 4911/16329 [41:21<1:35:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4911: train loss 2.02676. lr 5.671267e-04:  30%|███       | 4911/16329 [41:22<1:35:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4911: train loss 2.02676. lr 5.671267e-04:  30%|███       | 4912/16329 [41:22<1:35:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4912: train loss 2.07001. lr 5.671135e-04:  30%|███       | 4912/16329 [41:22<1:35:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4912: train loss 2.07001. lr 5.671135e-04:  30%|███       | 4913/16329 [41:22<1:34:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4913: train loss 2.09996. lr 5.671004e-04:  30%|███       | 4913/16329 [41:23<1:34:57,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4913: train loss 2.09996. lr 5.671004e-04:  30%|███       | 4914/16329 [41:23<1:34:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4914: train loss 2.12619. lr 5.670872e-04:  30%|███       | 4914/16329 [41:23<1:34:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4914: train loss 2.12619. lr 5.670872e-04:  30%|███       | 4915/16329 [41:23<1:34:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4915: train loss 2.08822. lr 5.670741e-04:  30%|███       | 4915/16329 [41:24<1:34:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4915: train loss 2.08822. lr 5.670741e-04:  30%|███       | 4916/16329 [41:24<1:34:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4916: train loss 2.08703. lr 5.670609e-04:  30%|███       | 4916/16329 [41:24<1:34:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4916: train loss 2.08703. lr 5.670609e-04:  30%|███       | 4917/16329 [41:24<1:34:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4917: train loss 2.08686. lr 5.670478e-04:  30%|███       | 4917/16329 [41:25<1:34:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4917: train loss 2.08686. lr 5.670478e-04:  30%|███       | 4918/16329 [41:25<1:34:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4918: train loss 2.09102. lr 5.670346e-04:  30%|███       | 4918/16329 [41:25<1:34:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4918: train loss 2.09102. lr 5.670346e-04:  30%|███       | 4919/16329 [41:25<1:34:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4919: train loss 2.06860. lr 5.670215e-04:  30%|███       | 4919/16329 [41:26<1:34:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4919: train loss 2.06860. lr 5.670215e-04:  30%|███       | 4920/16329 [41:26<1:33:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4920: train loss 2.05714. lr 5.670083e-04:  30%|███       | 4920/16329 [41:26<1:33:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 4920: train loss 2.05714. lr 5.670083e-04:  30%|███       | 4921/16329 [41:26<1:44:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4921: train loss 2.09281. lr 5.669952e-04:  30%|███       | 4921/16329 [41:27<1:44:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4921: train loss 2.09281. lr 5.669952e-04:  30%|███       | 4922/16329 [41:27<1:41:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4922: train loss 2.09723. lr 5.669820e-04:  30%|███       | 4922/16329 [41:27<1:41:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4922: train loss 2.09723. lr 5.669820e-04:  30%|███       | 4923/16329 [41:27<1:39:16,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4923: train loss 2.09954. lr 5.669688e-04:  30%|███       | 4923/16329 [41:28<1:39:16,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4923: train loss 2.09954. lr 5.669688e-04:  30%|███       | 4924/16329 [41:28<1:37:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4924: train loss 2.09168. lr 5.669557e-04:  30%|███       | 4924/16329 [41:28<1:37:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 4924: train loss 2.09168. lr 5.669557e-04:  30%|███       | 4925/16329 [41:28<1:36:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4925: train loss 2.07758. lr 5.669425e-04:  30%|███       | 4925/16329 [41:29<1:36:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4925: train loss 2.07758. lr 5.669425e-04:  30%|███       | 4926/16329 [41:29<1:35:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4926: train loss 2.12438. lr 5.669293e-04:  30%|███       | 4926/16329 [41:29<1:35:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4926: train loss 2.12438. lr 5.669293e-04:  30%|███       | 4927/16329 [41:29<1:35:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4927: train loss 2.09452. lr 5.669162e-04:  30%|███       | 4927/16329 [41:30<1:35:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4927: train loss 2.09452. lr 5.669162e-04:  30%|███       | 4928/16329 [41:30<1:35:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4928: train loss 2.10519. lr 5.669030e-04:  30%|███       | 4928/16329 [41:30<1:35:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4928: train loss 2.10519. lr 5.669030e-04:  30%|███       | 4929/16329 [41:30<1:35:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4929: train loss 2.04817. lr 5.668898e-04:  30%|███       | 4929/16329 [41:31<1:35:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4929: train loss 2.04817. lr 5.668898e-04:  30%|███       | 4930/16329 [41:31<1:34:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4930: train loss 2.12947. lr 5.668766e-04:  30%|███       | 4930/16329 [41:31<1:34:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4930: train loss 2.12947. lr 5.668766e-04:  30%|███       | 4931/16329 [41:31<1:34:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4931: train loss 2.02017. lr 5.668635e-04:  30%|███       | 4931/16329 [41:32<1:34:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4931: train loss 2.02017. lr 5.668635e-04:  30%|███       | 4932/16329 [41:32<1:34:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4932: train loss 2.04725. lr 5.668503e-04:  30%|███       | 4932/16329 [41:32<1:34:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4932: train loss 2.04725. lr 5.668503e-04:  30%|███       | 4933/16329 [41:32<1:34:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4933: train loss 2.03734. lr 5.668371e-04:  30%|███       | 4933/16329 [41:33<1:34:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4933: train loss 2.03734. lr 5.668371e-04:  30%|███       | 4934/16329 [41:33<1:34:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4934: train loss 2.06580. lr 5.668239e-04:  30%|███       | 4934/16329 [41:33<1:34:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4934: train loss 2.06580. lr 5.668239e-04:  30%|███       | 4935/16329 [41:33<1:34:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4935: train loss 2.08103. lr 5.668107e-04:  30%|███       | 4935/16329 [41:34<1:34:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4935: train loss 2.08103. lr 5.668107e-04:  30%|███       | 4936/16329 [41:34<1:34:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4936: train loss 2.02673. lr 5.667975e-04:  30%|███       | 4936/16329 [41:34<1:34:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4936: train loss 2.02673. lr 5.667975e-04:  30%|███       | 4937/16329 [41:34<1:33:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4937: train loss 2.07292. lr 5.667843e-04:  30%|███       | 4937/16329 [41:35<1:33:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4937: train loss 2.07292. lr 5.667843e-04:  30%|███       | 4938/16329 [41:35<1:34:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4938: train loss 2.12367. lr 5.667711e-04:  30%|███       | 4938/16329 [41:35<1:34:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4938: train loss 2.12367. lr 5.667711e-04:  30%|███       | 4939/16329 [41:35<1:33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4939: train loss 2.07381. lr 5.667579e-04:  30%|███       | 4939/16329 [41:36<1:33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4939: train loss 2.07381. lr 5.667579e-04:  30%|███       | 4940/16329 [41:36<1:34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4940: train loss 2.07907. lr 5.667447e-04:  30%|███       | 4940/16329 [41:36<1:34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4940: train loss 2.07907. lr 5.667447e-04:  30%|███       | 4941/16329 [41:36<1:34:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4941: train loss 2.08655. lr 5.667315e-04:  30%|███       | 4941/16329 [41:37<1:34:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4941: train loss 2.08655. lr 5.667315e-04:  30%|███       | 4942/16329 [41:37<1:34:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4942: train loss 2.05027. lr 5.667183e-04:  30%|███       | 4942/16329 [41:37<1:34:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4942: train loss 2.05027. lr 5.667183e-04:  30%|███       | 4943/16329 [41:37<1:33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4943: train loss 2.06263. lr 5.667051e-04:  30%|███       | 4943/16329 [41:38<1:33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4943: train loss 2.06263. lr 5.667051e-04:  30%|███       | 4944/16329 [41:38<1:33:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4944: train loss 1.99658. lr 5.666918e-04:  30%|███       | 4944/16329 [41:38<1:33:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4944: train loss 1.99658. lr 5.666918e-04:  30%|███       | 4945/16329 [41:38<1:34:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4945: train loss 2.06665. lr 5.666786e-04:  30%|███       | 4945/16329 [41:39<1:34:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4945: train loss 2.06665. lr 5.666786e-04:  30%|███       | 4946/16329 [41:39<1:34:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4946: train loss 2.03492. lr 5.666654e-04:  30%|███       | 4946/16329 [41:39<1:34:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4946: train loss 2.03492. lr 5.666654e-04:  30%|███       | 4947/16329 [41:39<1:34:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4947: train loss 2.09463. lr 5.666522e-04:  30%|███       | 4947/16329 [41:40<1:34:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4947: train loss 2.09463. lr 5.666522e-04:  30%|███       | 4948/16329 [41:40<1:44:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4948: train loss 2.06794. lr 5.666390e-04:  30%|███       | 4948/16329 [41:40<1:44:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4948: train loss 2.06794. lr 5.666390e-04:  30%|███       | 4949/16329 [41:40<1:40:58,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4949: train loss 1.99805. lr 5.666257e-04:  30%|███       | 4949/16329 [41:41<1:40:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 4949: train loss 1.99805. lr 5.666257e-04:  30%|███       | 4950/16329 [41:41<1:39:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4950: train loss 2.08692. lr 5.666125e-04:  30%|███       | 4950/16329 [41:41<1:39:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4950: train loss 2.08692. lr 5.666125e-04:  30%|███       | 4951/16329 [41:41<1:37:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4951: train loss 1.96093. lr 5.665993e-04:  30%|███       | 4951/16329 [41:42<1:37:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4951: train loss 1.96093. lr 5.665993e-04:  30%|███       | 4952/16329 [41:42<1:36:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4952: train loss 2.02624. lr 5.665860e-04:  30%|███       | 4952/16329 [41:42<1:36:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4952: train loss 2.02624. lr 5.665860e-04:  30%|███       | 4953/16329 [41:42<1:35:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4953: train loss 2.06743. lr 5.665728e-04:  30%|███       | 4953/16329 [41:43<1:35:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4953: train loss 2.06743. lr 5.665728e-04:  30%|███       | 4954/16329 [41:43<1:35:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4954: train loss 2.02688. lr 5.665595e-04:  30%|███       | 4954/16329 [41:43<1:35:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4954: train loss 2.02688. lr 5.665595e-04:  30%|███       | 4955/16329 [41:43<1:34:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4955: train loss 2.07624. lr 5.665463e-04:  30%|███       | 4955/16329 [41:44<1:34:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4955: train loss 2.07624. lr 5.665463e-04:  30%|███       | 4956/16329 [41:44<1:34:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4956: train loss 2.05423. lr 5.665331e-04:  30%|███       | 4956/16329 [41:44<1:34:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4956: train loss 2.05423. lr 5.665331e-04:  30%|███       | 4957/16329 [41:44<1:34:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4957: train loss 2.01174. lr 5.665198e-04:  30%|███       | 4957/16329 [41:45<1:34:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4957: train loss 2.01174. lr 5.665198e-04:  30%|███       | 4958/16329 [41:45<1:34:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4958: train loss 2.08073. lr 5.665066e-04:  30%|███       | 4958/16329 [41:45<1:34:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4958: train loss 2.08073. lr 5.665066e-04:  30%|███       | 4959/16329 [41:45<1:34:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4959: train loss 2.06238. lr 5.664933e-04:  30%|███       | 4959/16329 [41:46<1:34:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4959: train loss 2.06238. lr 5.664933e-04:  30%|███       | 4960/16329 [41:46<1:34:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4960: train loss 2.07806. lr 5.664801e-04:  30%|███       | 4960/16329 [41:46<1:34:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4960: train loss 2.07806. lr 5.664801e-04:  30%|███       | 4961/16329 [41:46<1:34:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4961: train loss 2.16182. lr 5.664668e-04:  30%|███       | 4961/16329 [41:47<1:34:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4961: train loss 2.16182. lr 5.664668e-04:  30%|███       | 4962/16329 [41:47<1:34:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4962: train loss 2.11507. lr 5.664535e-04:  30%|███       | 4962/16329 [41:47<1:34:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4962: train loss 2.11507. lr 5.664535e-04:  30%|███       | 4963/16329 [41:47<1:33:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4963: train loss 2.11231. lr 5.664403e-04:  30%|███       | 4963/16329 [41:48<1:33:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4963: train loss 2.11231. lr 5.664403e-04:  30%|███       | 4964/16329 [41:48<1:34:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4964: train loss 2.04016. lr 5.664270e-04:  30%|███       | 4964/16329 [41:48<1:34:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4964: train loss 2.04016. lr 5.664270e-04:  30%|███       | 4965/16329 [41:48<1:33:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4965: train loss 2.02726. lr 5.664137e-04:  30%|███       | 4965/16329 [41:49<1:33:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4965: train loss 2.02726. lr 5.664137e-04:  30%|███       | 4966/16329 [41:49<1:34:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4966: train loss 2.02671. lr 5.664005e-04:  30%|███       | 4966/16329 [41:49<1:34:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4966: train loss 2.02671. lr 5.664005e-04:  30%|███       | 4967/16329 [41:49<1:34:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4967: train loss 2.04174. lr 5.663872e-04:  30%|███       | 4967/16329 [41:50<1:34:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4967: train loss 2.04174. lr 5.663872e-04:  30%|███       | 4968/16329 [41:50<1:33:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4968: train loss 2.04753. lr 5.663739e-04:  30%|███       | 4968/16329 [41:50<1:33:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4968: train loss 2.04753. lr 5.663739e-04:  30%|███       | 4969/16329 [41:50<1:34:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4969: train loss 2.06333. lr 5.663606e-04:  30%|███       | 4969/16329 [41:51<1:34:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4969: train loss 2.06333. lr 5.663606e-04:  30%|███       | 4970/16329 [41:51<1:33:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4970: train loss 2.07022. lr 5.663474e-04:  30%|███       | 4970/16329 [41:51<1:33:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4970: train loss 2.07022. lr 5.663474e-04:  30%|███       | 4971/16329 [41:51<1:34:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4971: train loss 2.02999. lr 5.663341e-04:  30%|███       | 4971/16329 [41:52<1:34:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4971: train loss 2.02999. lr 5.663341e-04:  30%|███       | 4972/16329 [41:52<1:34:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4972: train loss 2.07454. lr 5.663208e-04:  30%|███       | 4972/16329 [41:52<1:34:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4972: train loss 2.07454. lr 5.663208e-04:  30%|███       | 4973/16329 [41:52<1:34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4973: train loss 2.11243. lr 5.663075e-04:  30%|███       | 4973/16329 [41:53<1:34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4973: train loss 2.11243. lr 5.663075e-04:  30%|███       | 4974/16329 [41:53<1:34:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4974: train loss 2.04001. lr 5.662942e-04:  30%|███       | 4974/16329 [41:53<1:34:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4974: train loss 2.04001. lr 5.662942e-04:  30%|███       | 4975/16329 [41:53<1:34:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4975: train loss 2.12351. lr 5.662809e-04:  30%|███       | 4975/16329 [41:54<1:34:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4975: train loss 2.12351. lr 5.662809e-04:  30%|███       | 4976/16329 [41:54<1:34:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4976: train loss 2.03483. lr 5.662676e-04:  30%|███       | 4976/16329 [41:54<1:34:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4976: train loss 2.03483. lr 5.662676e-04:  30%|███       | 4977/16329 [41:54<1:34:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4977: train loss 2.07193. lr 5.662543e-04:  30%|███       | 4977/16329 [41:55<1:34:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4977: train loss 2.07193. lr 5.662543e-04:  30%|███       | 4978/16329 [41:55<1:34:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4978: train loss 2.05243. lr 5.662410e-04:  30%|███       | 4978/16329 [41:55<1:34:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4978: train loss 2.05243. lr 5.662410e-04:  30%|███       | 4979/16329 [41:55<1:34:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4979: train loss 2.11493. lr 5.662277e-04:  30%|███       | 4979/16329 [41:56<1:34:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4979: train loss 2.11493. lr 5.662277e-04:  30%|███       | 4980/16329 [41:56<1:34:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4980: train loss 2.02763. lr 5.662144e-04:  30%|███       | 4980/16329 [41:56<1:34:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4980: train loss 2.02763. lr 5.662144e-04:  31%|███       | 4981/16329 [41:56<1:34:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4981: train loss 2.10908. lr 5.662011e-04:  31%|███       | 4981/16329 [41:57<1:34:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4981: train loss 2.10908. lr 5.662011e-04:  31%|███       | 4982/16329 [41:57<1:33:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4982: train loss 2.00215. lr 5.661878e-04:  31%|███       | 4982/16329 [41:57<1:33:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 4982: train loss 2.00215. lr 5.661878e-04:  31%|███       | 4983/16329 [41:57<1:35:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4983: train loss 1.97005. lr 5.661745e-04:  31%|███       | 4983/16329 [41:58<1:35:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 4983: train loss 1.97005. lr 5.661745e-04:  31%|███       | 4984/16329 [41:58<1:37:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4984: train loss 2.02907. lr 5.661612e-04:  31%|███       | 4984/16329 [41:58<1:37:41,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4984: train loss 2.02907. lr 5.661612e-04:  31%|███       | 4985/16329 [41:58<1:38:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4985: train loss 2.01235. lr 5.661479e-04:  31%|███       | 4985/16329 [41:59<1:38:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 4985: train loss 2.01235. lr 5.661479e-04:  31%|███       | 4986/16329 [41:59<1:38:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4986: train loss 2.07436. lr 5.661346e-04:  31%|███       | 4986/16329 [41:59<1:38:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4986: train loss 2.07436. lr 5.661346e-04:  31%|███       | 4987/16329 [41:59<1:37:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4987: train loss 2.11921. lr 5.661212e-04:  31%|███       | 4987/16329 [42:00<1:37:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 4987: train loss 2.11921. lr 5.661212e-04:  31%|███       | 4988/16329 [42:00<1:47:25,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 4988: train loss 2.08587. lr 5.661079e-04:  31%|███       | 4988/16329 [42:01<1:47:25,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 4988: train loss 2.08587. lr 5.661079e-04:  31%|███       | 4989/16329 [42:01<1:43:47,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4989: train loss 2.02136. lr 5.660946e-04:  31%|███       | 4989/16329 [42:01<1:43:47,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 4989: train loss 2.02136. lr 5.660946e-04:  31%|███       | 4990/16329 [42:01<1:41:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4990: train loss 2.02777. lr 5.660813e-04:  31%|███       | 4990/16329 [42:02<1:41:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 4990: train loss 2.02777. lr 5.660813e-04:  31%|███       | 4991/16329 [42:02<1:39:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4991: train loss 1.98636. lr 5.660679e-04:  31%|███       | 4991/16329 [42:02<1:39:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 4991: train loss 1.98636. lr 5.660679e-04:  31%|███       | 4992/16329 [42:02<1:37:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4992: train loss 2.03305. lr 5.660546e-04:  31%|███       | 4992/16329 [42:03<1:37:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 4992: train loss 2.03305. lr 5.660546e-04:  31%|███       | 4993/16329 [42:03<1:36:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4993: train loss 2.11185. lr 5.660413e-04:  31%|███       | 4993/16329 [42:03<1:36:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 4993: train loss 2.11185. lr 5.660413e-04:  31%|███       | 4994/16329 [42:03<1:35:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4994: train loss 2.03767. lr 5.660279e-04:  31%|███       | 4994/16329 [42:04<1:35:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 4994: train loss 2.03767. lr 5.660279e-04:  31%|███       | 4995/16329 [42:04<1:35:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4995: train loss 2.09274. lr 5.660146e-04:  31%|███       | 4995/16329 [42:04<1:35:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 4995: train loss 2.09274. lr 5.660146e-04:  31%|███       | 4996/16329 [42:04<1:34:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4996: train loss 2.02907. lr 5.660012e-04:  31%|███       | 4996/16329 [42:05<1:34:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 4996: train loss 2.02907. lr 5.660012e-04:  31%|███       | 4997/16329 [42:05<1:34:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4997: train loss 2.08153. lr 5.659879e-04:  31%|███       | 4997/16329 [42:05<1:34:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4997: train loss 2.08153. lr 5.659879e-04:  31%|███       | 4998/16329 [42:05<1:33:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4998: train loss 2.07905. lr 5.659745e-04:  31%|███       | 4998/16329 [42:06<1:33:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4998: train loss 2.07905. lr 5.659745e-04:  31%|███       | 4999/16329 [42:06<1:33:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4999: train loss 2.07232. lr 5.659612e-04:  31%|███       | 4999/16329 [42:06<1:33:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 4999: train loss 2.07232. lr 5.659612e-04:  31%|███       | 5000/16329 [42:06<1:33:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5000: train loss 2.05859. lr 5.659478e-04:  31%|███       | 5000/16329 [42:07<1:33:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5000: train loss 2.05859. lr 5.659478e-04:  31%|███       | 5001/16329 [42:07<1:33:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5001: train loss 2.06482. lr 5.659345e-04:  31%|███       | 5001/16329 [42:07<1:33:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5001: train loss 2.06482. lr 5.659345e-04:  31%|███       | 5002/16329 [42:07<1:33:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5002: train loss 2.01763. lr 5.659211e-04:  31%|███       | 5002/16329 [42:08<1:33:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5002: train loss 2.01763. lr 5.659211e-04:  31%|███       | 5003/16329 [42:08<1:33:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5003: train loss 2.08021. lr 5.659078e-04:  31%|███       | 5003/16329 [42:08<1:33:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5003: train loss 2.08021. lr 5.659078e-04:  31%|███       | 5004/16329 [42:08<1:33:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5004: train loss 2.05445. lr 5.658944e-04:  31%|███       | 5004/16329 [42:09<1:33:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5004: train loss 2.05445. lr 5.658944e-04:  31%|███       | 5005/16329 [42:09<1:33:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5005: train loss 2.06915. lr 5.658810e-04:  31%|███       | 5005/16329 [42:09<1:33:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5005: train loss 2.06915. lr 5.658810e-04:  31%|███       | 5006/16329 [42:09<1:33:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5006: train loss 2.03219. lr 5.658677e-04:  31%|███       | 5006/16329 [42:10<1:33:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5006: train loss 2.03219. lr 5.658677e-04:  31%|███       | 5007/16329 [42:10<1:33:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5007: train loss 2.04883. lr 5.658543e-04:  31%|███       | 5007/16329 [42:10<1:33:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5007: train loss 2.04883. lr 5.658543e-04:  31%|███       | 5008/16329 [42:10<1:33:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5008: train loss 2.01531. lr 5.658409e-04:  31%|███       | 5008/16329 [42:11<1:33:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5008: train loss 2.01531. lr 5.658409e-04:  31%|███       | 5009/16329 [42:11<1:33:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5009: train loss 2.04080. lr 5.658275e-04:  31%|███       | 5009/16329 [42:11<1:33:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5009: train loss 2.04080. lr 5.658275e-04:  31%|███       | 5010/16329 [42:11<1:33:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5010: train loss 2.07472. lr 5.658142e-04:  31%|███       | 5010/16329 [42:12<1:33:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5010: train loss 2.07472. lr 5.658142e-04:  31%|███       | 5011/16329 [42:12<1:33:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5011: train loss 2.02123. lr 5.658008e-04:  31%|███       | 5011/16329 [42:12<1:33:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5011: train loss 2.02123. lr 5.658008e-04:  31%|███       | 5012/16329 [42:12<1:33:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5012: train loss 2.01808. lr 5.657874e-04:  31%|███       | 5012/16329 [42:13<1:33:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5012: train loss 2.01808. lr 5.657874e-04:  31%|███       | 5013/16329 [42:13<1:33:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5013: train loss 2.03060. lr 5.657740e-04:  31%|███       | 5013/16329 [42:13<1:33:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5013: train loss 2.03060. lr 5.657740e-04:  31%|███       | 5014/16329 [42:13<1:33:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5014: train loss 2.07431. lr 5.657606e-04:  31%|███       | 5014/16329 [42:14<1:33:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5014: train loss 2.07431. lr 5.657606e-04:  31%|███       | 5015/16329 [42:14<1:33:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5015: train loss 2.06408. lr 5.657472e-04:  31%|███       | 5015/16329 [42:14<1:33:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5015: train loss 2.06408. lr 5.657472e-04:  31%|███       | 5016/16329 [42:14<1:33:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5016: train loss 2.07291. lr 5.657338e-04:  31%|███       | 5016/16329 [42:15<1:33:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5016: train loss 2.07291. lr 5.657338e-04:  31%|███       | 5017/16329 [42:15<1:33:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5017: train loss 2.10593. lr 5.657204e-04:  31%|███       | 5017/16329 [42:15<1:33:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5017: train loss 2.10593. lr 5.657204e-04:  31%|███       | 5018/16329 [42:15<1:33:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5018: train loss 2.01099. lr 5.657070e-04:  31%|███       | 5018/16329 [42:16<1:33:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5018: train loss 2.01099. lr 5.657070e-04:  31%|███       | 5019/16329 [42:16<1:38:33,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5019: train loss 2.06630. lr 5.656936e-04:  31%|███       | 5019/16329 [42:16<1:38:33,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5019: train loss 2.06630. lr 5.656936e-04:  31%|███       | 5020/16329 [42:16<1:40:17,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5020: train loss 2.05987. lr 5.656802e-04:  31%|███       | 5020/16329 [42:17<1:40:17,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5020: train loss 2.05987. lr 5.656802e-04:  31%|███       | 5021/16329 [42:17<1:40:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5021: train loss 2.07225. lr 5.656668e-04:  31%|███       | 5021/16329 [42:17<1:40:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5021: train loss 2.07225. lr 5.656668e-04:  31%|███       | 5022/16329 [42:17<1:39:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5022: train loss 2.04017. lr 5.656534e-04:  31%|███       | 5022/16329 [42:18<1:39:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5022: train loss 2.04017. lr 5.656534e-04:  31%|███       | 5023/16329 [42:18<1:48:13,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 5023: train loss 2.04244. lr 5.656400e-04:  31%|███       | 5023/16329 [42:18<1:48:13,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 5023: train loss 2.04244. lr 5.656400e-04:  31%|███       | 5024/16329 [42:18<1:44:11,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5024: train loss 2.06573. lr 5.656266e-04:  31%|███       | 5024/16329 [42:19<1:44:11,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5024: train loss 2.06573. lr 5.656266e-04:  31%|███       | 5025/16329 [42:19<1:41:17,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5025: train loss 2.05198. lr 5.656132e-04:  31%|███       | 5025/16329 [42:19<1:41:17,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5025: train loss 2.05198. lr 5.656132e-04:  31%|███       | 5026/16329 [42:19<1:39:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5026: train loss 2.03566. lr 5.655998e-04:  31%|███       | 5026/16329 [42:20<1:39:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5026: train loss 2.03566. lr 5.655998e-04:  31%|███       | 5027/16329 [42:20<1:37:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5027: train loss 1.96347. lr 5.655864e-04:  31%|███       | 5027/16329 [42:20<1:37:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5027: train loss 1.96347. lr 5.655864e-04:  31%|███       | 5028/16329 [42:20<1:36:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5028: train loss 2.08219. lr 5.655729e-04:  31%|███       | 5028/16329 [42:21<1:36:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5028: train loss 2.08219. lr 5.655729e-04:  31%|███       | 5029/16329 [42:21<1:35:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5029: train loss 2.04276. lr 5.655595e-04:  31%|███       | 5029/16329 [42:21<1:35:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5029: train loss 2.04276. lr 5.655595e-04:  31%|███       | 5030/16329 [42:21<1:34:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5030: train loss 2.05365. lr 5.655461e-04:  31%|███       | 5030/16329 [42:22<1:34:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5030: train loss 2.05365. lr 5.655461e-04:  31%|███       | 5031/16329 [42:22<1:34:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5031: train loss 2.07116. lr 5.655326e-04:  31%|███       | 5031/16329 [42:22<1:34:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5031: train loss 2.07116. lr 5.655326e-04:  31%|███       | 5032/16329 [42:22<1:33:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5032: train loss 2.07737. lr 5.655192e-04:  31%|███       | 5032/16329 [42:23<1:33:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5032: train loss 2.07737. lr 5.655192e-04:  31%|███       | 5033/16329 [42:23<1:33:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5033: train loss 2.07780. lr 5.655058e-04:  31%|███       | 5033/16329 [42:23<1:33:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5033: train loss 2.07780. lr 5.655058e-04:  31%|███       | 5034/16329 [42:23<1:33:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5034: train loss 2.01974. lr 5.654923e-04:  31%|███       | 5034/16329 [42:24<1:33:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5034: train loss 2.01974. lr 5.654923e-04:  31%|███       | 5035/16329 [42:24<1:33:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5035: train loss 2.08961. lr 5.654789e-04:  31%|███       | 5035/16329 [42:24<1:33:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5035: train loss 2.08961. lr 5.654789e-04:  31%|███       | 5036/16329 [42:24<1:33:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5036: train loss 2.03030. lr 5.654655e-04:  31%|███       | 5036/16329 [42:25<1:33:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5036: train loss 2.03030. lr 5.654655e-04:  31%|███       | 5037/16329 [42:25<1:33:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5037: train loss 2.08650. lr 5.654520e-04:  31%|███       | 5037/16329 [42:25<1:33:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5037: train loss 2.08650. lr 5.654520e-04:  31%|███       | 5038/16329 [42:25<1:33:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5038: train loss 2.10568. lr 5.654386e-04:  31%|███       | 5038/16329 [42:26<1:33:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5038: train loss 2.10568. lr 5.654386e-04:  31%|███       | 5039/16329 [42:26<1:33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5039: train loss 2.06395. lr 5.654251e-04:  31%|███       | 5039/16329 [42:26<1:33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5039: train loss 2.06395. lr 5.654251e-04:  31%|███       | 5040/16329 [42:26<1:33:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5040: train loss 2.07479. lr 5.654117e-04:  31%|███       | 5040/16329 [42:27<1:33:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5040: train loss 2.07479. lr 5.654117e-04:  31%|███       | 5041/16329 [42:27<1:33:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5041: train loss 2.05232. lr 5.653982e-04:  31%|███       | 5041/16329 [42:27<1:33:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5041: train loss 2.05232. lr 5.653982e-04:  31%|███       | 5042/16329 [42:27<1:33:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5042: train loss 2.04978. lr 5.653848e-04:  31%|███       | 5042/16329 [42:28<1:33:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5042: train loss 2.04978. lr 5.653848e-04:  31%|███       | 5043/16329 [42:28<1:33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5043: train loss 2.08418. lr 5.653713e-04:  31%|███       | 5043/16329 [42:28<1:33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5043: train loss 2.08418. lr 5.653713e-04:  31%|███       | 5044/16329 [42:28<1:33:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5044: train loss 2.08875. lr 5.653578e-04:  31%|███       | 5044/16329 [42:29<1:33:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5044: train loss 2.08875. lr 5.653578e-04:  31%|███       | 5045/16329 [42:29<1:33:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5045: train loss 1.96783. lr 5.653444e-04:  31%|███       | 5045/16329 [42:29<1:33:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5045: train loss 1.96783. lr 5.653444e-04:  31%|███       | 5046/16329 [42:29<1:34:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5046: train loss 2.06757. lr 5.653309e-04:  31%|███       | 5046/16329 [42:30<1:34:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5046: train loss 2.06757. lr 5.653309e-04:  31%|███       | 5047/16329 [42:30<1:35:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5047: train loss 2.04044. lr 5.653174e-04:  31%|███       | 5047/16329 [42:31<1:35:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5047: train loss 2.04044. lr 5.653174e-04:  31%|███       | 5048/16329 [42:31<1:45:59,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5048: train loss 2.06763. lr 5.653040e-04:  31%|███       | 5048/16329 [42:31<1:45:59,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5048: train loss 2.06763. lr 5.653040e-04:  31%|███       | 5049/16329 [42:31<1:42:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5049: train loss 2.06986. lr 5.652905e-04:  31%|███       | 5049/16329 [42:32<1:42:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5049: train loss 2.06986. lr 5.652905e-04:  31%|███       | 5050/16329 [42:32<1:39:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5050: train loss 2.04789. lr 5.652770e-04:  31%|███       | 5050/16329 [42:32<1:39:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5050: train loss 2.04789. lr 5.652770e-04:  31%|███       | 5051/16329 [42:32<1:38:14,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5051: train loss 2.04608. lr 5.652635e-04:  31%|███       | 5051/16329 [42:33<1:38:14,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5051: train loss 2.04608. lr 5.652635e-04:  31%|███       | 5052/16329 [42:33<1:36:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5052: train loss 2.04246. lr 5.652500e-04:  31%|███       | 5052/16329 [42:33<1:36:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5052: train loss 2.04246. lr 5.652500e-04:  31%|███       | 5053/16329 [42:33<1:35:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5053: train loss 2.02375. lr 5.652366e-04:  31%|███       | 5053/16329 [42:34<1:35:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5053: train loss 2.02375. lr 5.652366e-04:  31%|███       | 5054/16329 [42:34<1:34:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5054: train loss 2.03012. lr 5.652231e-04:  31%|███       | 5054/16329 [42:34<1:34:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5054: train loss 2.03012. lr 5.652231e-04:  31%|███       | 5055/16329 [42:34<1:34:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5055: train loss 2.00720. lr 5.652096e-04:  31%|███       | 5055/16329 [42:35<1:34:17,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5055: train loss 2.00720. lr 5.652096e-04:  31%|███       | 5056/16329 [42:35<1:34:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5056: train loss 2.00713. lr 5.651961e-04:  31%|███       | 5056/16329 [42:35<1:34:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5056: train loss 2.00713. lr 5.651961e-04:  31%|███       | 5057/16329 [42:35<1:33:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5057: train loss 2.08981. lr 5.651826e-04:  31%|███       | 5057/16329 [42:36<1:33:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5057: train loss 2.08981. lr 5.651826e-04:  31%|███       | 5058/16329 [42:36<1:33:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5058: train loss 2.04997. lr 5.651691e-04:  31%|███       | 5058/16329 [42:36<1:33:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5058: train loss 2.04997. lr 5.651691e-04:  31%|███       | 5059/16329 [42:36<1:33:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5059: train loss 2.06915. lr 5.651556e-04:  31%|███       | 5059/16329 [42:37<1:33:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5059: train loss 2.06915. lr 5.651556e-04:  31%|███       | 5060/16329 [42:37<1:33:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5060: train loss 2.00630. lr 5.651421e-04:  31%|███       | 5060/16329 [42:37<1:33:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5060: train loss 2.00630. lr 5.651421e-04:  31%|███       | 5061/16329 [42:37<1:33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5061: train loss 1.99362. lr 5.651286e-04:  31%|███       | 5061/16329 [42:38<1:33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5061: train loss 1.99362. lr 5.651286e-04:  31%|███       | 5062/16329 [42:38<1:33:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5062: train loss 2.03740. lr 5.651151e-04:  31%|███       | 5062/16329 [42:38<1:33:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5062: train loss 2.03740. lr 5.651151e-04:  31%|███       | 5063/16329 [42:38<1:33:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5063: train loss 2.11443. lr 5.651016e-04:  31%|███       | 5063/16329 [42:39<1:33:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5063: train loss 2.11443. lr 5.651016e-04:  31%|███       | 5064/16329 [42:39<1:33:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5064: train loss 2.03906. lr 5.650881e-04:  31%|███       | 5064/16329 [42:39<1:33:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5064: train loss 2.03906. lr 5.650881e-04:  31%|███       | 5065/16329 [42:39<1:33:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5065: train loss 2.04255. lr 5.650746e-04:  31%|███       | 5065/16329 [42:40<1:33:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5065: train loss 2.04255. lr 5.650746e-04:  31%|███       | 5066/16329 [42:40<1:33:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5066: train loss 1.98620. lr 5.650611e-04:  31%|███       | 5066/16329 [42:40<1:33:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5066: train loss 1.98620. lr 5.650611e-04:  31%|███       | 5067/16329 [42:40<1:33:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5067: train loss 2.06756. lr 5.650475e-04:  31%|███       | 5067/16329 [42:41<1:33:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5067: train loss 2.06756. lr 5.650475e-04:  31%|███       | 5068/16329 [42:41<1:33:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5068: train loss 2.02152. lr 5.650340e-04:  31%|███       | 5068/16329 [42:41<1:33:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5068: train loss 2.02152. lr 5.650340e-04:  31%|███       | 5069/16329 [42:41<1:33:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5069: train loss 2.02185. lr 5.650205e-04:  31%|███       | 5069/16329 [42:42<1:33:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5069: train loss 2.02185. lr 5.650205e-04:  31%|███       | 5070/16329 [42:42<1:34:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5070: train loss 2.00208. lr 5.650070e-04:  31%|███       | 5070/16329 [42:42<1:34:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5070: train loss 2.00208. lr 5.650070e-04:  31%|███       | 5071/16329 [42:42<1:33:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5071: train loss 2.08279. lr 5.649934e-04:  31%|███       | 5071/16329 [42:43<1:33:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5071: train loss 2.08279. lr 5.649934e-04:  31%|███       | 5072/16329 [42:43<1:33:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5072: train loss 2.02709. lr 5.649799e-04:  31%|███       | 5072/16329 [42:43<1:33:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5072: train loss 2.02709. lr 5.649799e-04:  31%|███       | 5073/16329 [42:43<1:33:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5073: train loss 2.03897. lr 5.649664e-04:  31%|███       | 5073/16329 [42:44<1:33:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5073: train loss 2.03897. lr 5.649664e-04:  31%|███       | 5074/16329 [42:44<1:33:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5074: train loss 2.07560. lr 5.649528e-04:  31%|███       | 5074/16329 [42:44<1:33:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5074: train loss 2.07560. lr 5.649528e-04:  31%|███       | 5075/16329 [42:44<1:46:31,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 5075: train loss 2.06936. lr 5.649393e-04:  31%|███       | 5075/16329 [42:45<1:46:31,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 5075: train loss 2.06936. lr 5.649393e-04:  31%|███       | 5076/16329 [42:45<1:42:14,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5076: train loss 2.06821. lr 5.649258e-04:  31%|███       | 5076/16329 [42:45<1:42:14,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5076: train loss 2.06821. lr 5.649258e-04:  31%|███       | 5077/16329 [42:45<1:39:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5077: train loss 2.01453. lr 5.649122e-04:  31%|███       | 5077/16329 [42:46<1:39:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5077: train loss 2.01453. lr 5.649122e-04:  31%|███       | 5078/16329 [42:46<1:37:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5078: train loss 2.01264. lr 5.648987e-04:  31%|███       | 5078/16329 [42:46<1:37:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5078: train loss 2.01264. lr 5.648987e-04:  31%|███       | 5079/16329 [42:46<1:36:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5079: train loss 2.00457. lr 5.648851e-04:  31%|███       | 5079/16329 [42:47<1:36:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5079: train loss 2.00457. lr 5.648851e-04:  31%|███       | 5080/16329 [42:47<1:35:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5080: train loss 2.00650. lr 5.648716e-04:  31%|███       | 5080/16329 [42:47<1:35:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5080: train loss 2.00650. lr 5.648716e-04:  31%|███       | 5081/16329 [42:47<1:34:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5081: train loss 2.03611. lr 5.648580e-04:  31%|███       | 5081/16329 [42:48<1:34:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5081: train loss 2.03611. lr 5.648580e-04:  31%|███       | 5082/16329 [42:48<1:34:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5082: train loss 2.02334. lr 5.648445e-04:  31%|███       | 5082/16329 [42:48<1:34:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5082: train loss 2.02334. lr 5.648445e-04:  31%|███       | 5083/16329 [42:48<1:33:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5083: train loss 2.04845. lr 5.648309e-04:  31%|███       | 5083/16329 [42:49<1:33:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5083: train loss 2.04845. lr 5.648309e-04:  31%|███       | 5084/16329 [42:49<1:33:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5084: train loss 2.01660. lr 5.648173e-04:  31%|███       | 5084/16329 [42:49<1:33:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5084: train loss 2.01660. lr 5.648173e-04:  31%|███       | 5085/16329 [42:49<1:33:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5085: train loss 2.04783. lr 5.648038e-04:  31%|███       | 5085/16329 [42:50<1:33:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5085: train loss 2.04783. lr 5.648038e-04:  31%|███       | 5086/16329 [42:50<1:33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5086: train loss 2.02222. lr 5.647902e-04:  31%|███       | 5086/16329 [42:50<1:33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5086: train loss 2.02222. lr 5.647902e-04:  31%|███       | 5087/16329 [42:50<1:33:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5087: train loss 2.03520. lr 5.647767e-04:  31%|███       | 5087/16329 [42:51<1:33:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5087: train loss 2.03520. lr 5.647767e-04:  31%|███       | 5088/16329 [42:51<1:33:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5088: train loss 2.06915. lr 5.647631e-04:  31%|███       | 5088/16329 [42:51<1:33:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5088: train loss 2.06915. lr 5.647631e-04:  31%|███       | 5089/16329 [42:51<1:34:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5089: train loss 2.05283. lr 5.647495e-04:  31%|███       | 5089/16329 [42:52<1:34:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5089: train loss 2.05283. lr 5.647495e-04:  31%|███       | 5090/16329 [42:52<1:35:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5090: train loss 2.07634. lr 5.647359e-04:  31%|███       | 5090/16329 [42:52<1:35:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5090: train loss 2.07634. lr 5.647359e-04:  31%|███       | 5091/16329 [42:52<1:36:06,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5091: train loss 1.98172. lr 5.647224e-04:  31%|███       | 5091/16329 [42:53<1:36:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5091: train loss 1.98172. lr 5.647224e-04:  31%|███       | 5092/16329 [42:53<1:35:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5092: train loss 2.04243. lr 5.647088e-04:  31%|███       | 5092/16329 [42:53<1:35:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5092: train loss 2.04243. lr 5.647088e-04:  31%|███       | 5093/16329 [42:53<1:35:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5093: train loss 2.01027. lr 5.646952e-04:  31%|███       | 5093/16329 [42:54<1:35:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5093: train loss 2.01027. lr 5.646952e-04:  31%|███       | 5094/16329 [42:54<1:35:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5094: train loss 2.02527. lr 5.646816e-04:  31%|███       | 5094/16329 [42:54<1:35:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5094: train loss 2.02527. lr 5.646816e-04:  31%|███       | 5095/16329 [42:54<1:34:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5095: train loss 1.97048. lr 5.646680e-04:  31%|███       | 5095/16329 [42:55<1:34:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5095: train loss 1.97048. lr 5.646680e-04:  31%|███       | 5096/16329 [42:55<1:34:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5096: train loss 2.01313. lr 5.646544e-04:  31%|███       | 5096/16329 [42:55<1:34:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5096: train loss 2.01313. lr 5.646544e-04:  31%|███       | 5097/16329 [42:55<1:34:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5097: train loss 2.02470. lr 5.646408e-04:  31%|███       | 5097/16329 [42:56<1:34:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5097: train loss 2.02470. lr 5.646408e-04:  31%|███       | 5098/16329 [42:56<1:33:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5098: train loss 2.09443. lr 5.646273e-04:  31%|███       | 5098/16329 [42:56<1:33:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5098: train loss 2.09443. lr 5.646273e-04:  31%|███       | 5099/16329 [42:56<1:33:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5099: train loss 2.05306. lr 5.646137e-04:  31%|███       | 5099/16329 [42:57<1:33:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5099: train loss 2.05306. lr 5.646137e-04:  31%|███       | 5100/16329 [42:57<1:33:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5100: train loss 2.00630. lr 5.646001e-04:  31%|███       | 5100/16329 [42:57<1:33:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5100: train loss 2.00630. lr 5.646001e-04:  31%|███       | 5101/16329 [42:57<1:32:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5101: train loss 2.01188. lr 5.645865e-04:  31%|███       | 5101/16329 [42:58<1:32:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5101: train loss 2.01188. lr 5.645865e-04:  31%|███       | 5102/16329 [42:58<1:32:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5102: train loss 2.06048. lr 5.645728e-04:  31%|███       | 5102/16329 [42:58<1:32:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5102: train loss 2.06048. lr 5.645728e-04:  31%|███▏      | 5103/16329 [42:58<1:32:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5103: train loss 2.00270. lr 5.645592e-04:  31%|███▏      | 5103/16329 [42:59<1:32:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5103: train loss 2.00270. lr 5.645592e-04:  31%|███▏      | 5104/16329 [42:59<1:32:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5104: train loss 1.96973. lr 5.645456e-04:  31%|███▏      | 5104/16329 [42:59<1:32:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5104: train loss 1.96973. lr 5.645456e-04:  31%|███▏      | 5105/16329 [42:59<1:32:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5105: train loss 2.02886. lr 5.645320e-04:  31%|███▏      | 5105/16329 [43:00<1:32:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5105: train loss 2.02886. lr 5.645320e-04:  31%|███▏      | 5106/16329 [43:00<1:32:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5106: train loss 2.05697. lr 5.645184e-04:  31%|███▏      | 5106/16329 [43:00<1:32:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5106: train loss 2.05697. lr 5.645184e-04:  31%|███▏      | 5107/16329 [43:00<1:32:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5107: train loss 2.02628. lr 5.645048e-04:  31%|███▏      | 5107/16329 [43:01<1:32:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5107: train loss 2.02628. lr 5.645048e-04:  31%|███▏      | 5108/16329 [43:01<1:32:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5108: train loss 2.01641. lr 5.644912e-04:  31%|███▏      | 5108/16329 [43:01<1:32:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5108: train loss 2.01641. lr 5.644912e-04:  31%|███▏      | 5109/16329 [43:01<1:32:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5109: train loss 2.05341. lr 5.644776e-04:  31%|███▏      | 5109/16329 [43:02<1:32:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5109: train loss 2.05341. lr 5.644776e-04:  31%|███▏      | 5110/16329 [43:02<1:32:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5110: train loss 1.95541. lr 5.644639e-04:  31%|███▏      | 5110/16329 [43:02<1:32:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5110: train loss 1.95541. lr 5.644639e-04:  31%|███▏      | 5111/16329 [43:02<1:32:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5111: train loss 2.07527. lr 5.644503e-04:  31%|███▏      | 5111/16329 [43:03<1:32:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5111: train loss 2.07527. lr 5.644503e-04:  31%|███▏      | 5112/16329 [43:03<1:32:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5112: train loss 2.09660. lr 5.644367e-04:  31%|███▏      | 5112/16329 [43:03<1:32:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5112: train loss 2.09660. lr 5.644367e-04:  31%|███▏      | 5113/16329 [43:03<1:32:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5113: train loss 2.03040. lr 5.644230e-04:  31%|███▏      | 5113/16329 [43:04<1:32:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5113: train loss 2.03040. lr 5.644230e-04:  31%|███▏      | 5114/16329 [43:04<1:32:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5114: train loss 2.00216. lr 5.644094e-04:  31%|███▏      | 5114/16329 [43:04<1:32:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5114: train loss 2.00216. lr 5.644094e-04:  31%|███▏      | 5115/16329 [43:04<1:42:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5115: train loss 2.03200. lr 5.643958e-04:  31%|███▏      | 5115/16329 [43:05<1:42:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5115: train loss 2.03200. lr 5.643958e-04:  31%|███▏      | 5116/16329 [43:05<1:39:37,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5116: train loss 2.05154. lr 5.643821e-04:  31%|███▏      | 5116/16329 [43:05<1:39:37,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5116: train loss 2.05154. lr 5.643821e-04:  31%|███▏      | 5117/16329 [43:05<1:37:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5117: train loss 1.99625. lr 5.643685e-04:  31%|███▏      | 5117/16329 [43:06<1:37:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5117: train loss 1.99625. lr 5.643685e-04:  31%|███▏      | 5118/16329 [43:06<1:35:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5118: train loss 2.06129. lr 5.643549e-04:  31%|███▏      | 5118/16329 [43:06<1:35:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5118: train loss 2.06129. lr 5.643549e-04:  31%|███▏      | 5119/16329 [43:06<1:34:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5119: train loss 2.02053. lr 5.643412e-04:  31%|███▏      | 5119/16329 [43:07<1:34:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5119: train loss 2.02053. lr 5.643412e-04:  31%|███▏      | 5120/16329 [43:07<1:34:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5120: train loss 2.02038. lr 5.643276e-04:  31%|███▏      | 5120/16329 [43:07<1:34:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5120: train loss 2.02038. lr 5.643276e-04:  31%|███▏      | 5121/16329 [43:07<1:33:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5121: train loss 2.09763. lr 5.643139e-04:  31%|███▏      | 5121/16329 [43:08<1:33:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5121: train loss 2.09763. lr 5.643139e-04:  31%|███▏      | 5122/16329 [43:08<1:33:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5122: train loss 1.98915. lr 5.643003e-04:  31%|███▏      | 5122/16329 [43:08<1:33:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5122: train loss 1.98915. lr 5.643003e-04:  31%|███▏      | 5123/16329 [43:08<1:33:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5123: train loss 2.00685. lr 5.642866e-04:  31%|███▏      | 5123/16329 [43:09<1:33:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5123: train loss 2.00685. lr 5.642866e-04:  31%|███▏      | 5124/16329 [43:09<1:32:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5124: train loss 1.96688. lr 5.642729e-04:  31%|███▏      | 5124/16329 [43:09<1:32:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5124: train loss 1.96688. lr 5.642729e-04:  31%|███▏      | 5125/16329 [43:09<1:32:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5125: train loss 2.06166. lr 5.642593e-04:  31%|███▏      | 5125/16329 [43:10<1:32:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5125: train loss 2.06166. lr 5.642593e-04:  31%|███▏      | 5126/16329 [43:10<1:32:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5126: train loss 2.00930. lr 5.642456e-04:  31%|███▏      | 5126/16329 [43:10<1:32:43,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5126: train loss 2.00930. lr 5.642456e-04:  31%|███▏      | 5127/16329 [43:10<1:32:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5127: train loss 2.02224. lr 5.642320e-04:  31%|███▏      | 5127/16329 [43:11<1:32:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5127: train loss 2.02224. lr 5.642320e-04:  31%|███▏      | 5128/16329 [43:11<1:32:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5128: train loss 2.02796. lr 5.642183e-04:  31%|███▏      | 5128/16329 [43:11<1:32:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5128: train loss 2.02796. lr 5.642183e-04:  31%|███▏      | 5129/16329 [43:11<1:32:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5129: train loss 2.04059. lr 5.642046e-04:  31%|███▏      | 5129/16329 [43:12<1:32:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5129: train loss 2.04059. lr 5.642046e-04:  31%|███▏      | 5130/16329 [43:12<1:32:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5130: train loss 1.99156. lr 5.641909e-04:  31%|███▏      | 5130/16329 [43:12<1:32:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5130: train loss 1.99156. lr 5.641909e-04:  31%|███▏      | 5131/16329 [43:12<1:32:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5131: train loss 2.02409. lr 5.641773e-04:  31%|███▏      | 5131/16329 [43:13<1:32:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5131: train loss 2.02409. lr 5.641773e-04:  31%|███▏      | 5132/16329 [43:13<1:32:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5132: train loss 2.00314. lr 5.641636e-04:  31%|███▏      | 5132/16329 [43:13<1:32:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5132: train loss 2.00314. lr 5.641636e-04:  31%|███▏      | 5133/16329 [43:13<1:32:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5133: train loss 1.99821. lr 5.641499e-04:  31%|███▏      | 5133/16329 [43:14<1:32:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5133: train loss 1.99821. lr 5.641499e-04:  31%|███▏      | 5134/16329 [43:14<1:32:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5134: train loss 2.01570. lr 5.641362e-04:  31%|███▏      | 5134/16329 [43:14<1:32:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5134: train loss 2.01570. lr 5.641362e-04:  31%|███▏      | 5135/16329 [43:14<1:32:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5135: train loss 2.04193. lr 5.641225e-04:  31%|███▏      | 5135/16329 [43:15<1:32:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5135: train loss 2.04193. lr 5.641225e-04:  31%|███▏      | 5136/16329 [43:15<1:32:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5136: train loss 2.07432. lr 5.641089e-04:  31%|███▏      | 5136/16329 [43:15<1:32:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5136: train loss 2.07432. lr 5.641089e-04:  31%|███▏      | 5137/16329 [43:15<1:32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5137: train loss 2.06410. lr 5.640952e-04:  31%|███▏      | 5137/16329 [43:16<1:32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5137: train loss 2.06410. lr 5.640952e-04:  31%|███▏      | 5138/16329 [43:16<1:32:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5138: train loss 2.01047. lr 5.640815e-04:  31%|███▏      | 5138/16329 [43:16<1:32:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5138: train loss 2.01047. lr 5.640815e-04:  31%|███▏      | 5139/16329 [43:16<1:32:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5139: train loss 2.04109. lr 5.640678e-04:  31%|███▏      | 5139/16329 [43:17<1:32:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5139: train loss 2.04109. lr 5.640678e-04:  31%|███▏      | 5140/16329 [43:17<1:32:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5140: train loss 2.04004. lr 5.640541e-04:  31%|███▏      | 5140/16329 [43:17<1:32:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5140: train loss 2.04004. lr 5.640541e-04:  31%|███▏      | 5141/16329 [43:17<1:34:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5141: train loss 2.00738. lr 5.640404e-04:  31%|███▏      | 5141/16329 [43:18<1:34:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5141: train loss 2.00738. lr 5.640404e-04:  31%|███▏      | 5142/16329 [43:18<1:35:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5142: train loss 2.03530. lr 5.640267e-04:  31%|███▏      | 5142/16329 [43:18<1:35:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5142: train loss 2.03530. lr 5.640267e-04:  31%|███▏      | 5143/16329 [43:18<1:35:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5143: train loss 2.01664. lr 5.640130e-04:  31%|███▏      | 5143/16329 [43:19<1:35:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5143: train loss 2.01664. lr 5.640130e-04:  32%|███▏      | 5144/16329 [43:19<1:35:06,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5144: train loss 2.05692. lr 5.639993e-04:  32%|███▏      | 5144/16329 [43:19<1:35:06,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5144: train loss 2.05692. lr 5.639993e-04:  32%|███▏      | 5145/16329 [43:19<1:34:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5145: train loss 2.01420. lr 5.639856e-04:  32%|███▏      | 5145/16329 [43:20<1:34:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5145: train loss 2.01420. lr 5.639856e-04:  32%|███▏      | 5146/16329 [43:20<1:34:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5146: train loss 2.02662. lr 5.639718e-04:  32%|███▏      | 5146/16329 [43:20<1:34:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5146: train loss 2.02662. lr 5.639718e-04:  32%|███▏      | 5147/16329 [43:20<1:33:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5147: train loss 2.04923. lr 5.639581e-04:  32%|███▏      | 5147/16329 [43:21<1:33:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5147: train loss 2.04923. lr 5.639581e-04:  32%|███▏      | 5148/16329 [43:21<1:33:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5148: train loss 2.00151. lr 5.639444e-04:  32%|███▏      | 5148/16329 [43:21<1:33:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5148: train loss 2.00151. lr 5.639444e-04:  32%|███▏      | 5149/16329 [43:21<1:33:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5149: train loss 2.02879. lr 5.639307e-04:  32%|███▏      | 5149/16329 [43:22<1:33:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5149: train loss 2.02879. lr 5.639307e-04:  32%|███▏      | 5150/16329 [43:22<1:42:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5150: train loss 2.03532. lr 5.639170e-04:  32%|███▏      | 5150/16329 [43:23<1:42:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5150: train loss 2.03532. lr 5.639170e-04:  32%|███▏      | 5151/16329 [43:23<1:39:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5151: train loss 2.06740. lr 5.639033e-04:  32%|███▏      | 5151/16329 [43:23<1:39:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5151: train loss 2.06740. lr 5.639033e-04:  32%|███▏      | 5152/16329 [43:23<1:37:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5152: train loss 1.99877. lr 5.638895e-04:  32%|███▏      | 5152/16329 [43:24<1:37:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5152: train loss 1.99877. lr 5.638895e-04:  32%|███▏      | 5153/16329 [43:24<1:35:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5153: train loss 1.99875. lr 5.638758e-04:  32%|███▏      | 5153/16329 [43:24<1:35:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5153: train loss 1.99875. lr 5.638758e-04:  32%|███▏      | 5154/16329 [43:24<1:35:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5154: train loss 2.00650. lr 5.638621e-04:  32%|███▏      | 5154/16329 [43:25<1:35:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5154: train loss 2.00650. lr 5.638621e-04:  32%|███▏      | 5155/16329 [43:25<1:34:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5155: train loss 2.05065. lr 5.638483e-04:  32%|███▏      | 5155/16329 [43:25<1:34:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5155: train loss 2.05065. lr 5.638483e-04:  32%|███▏      | 5156/16329 [43:25<1:34:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5156: train loss 1.96275. lr 5.638346e-04:  32%|███▏      | 5156/16329 [43:26<1:34:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5156: train loss 1.96275. lr 5.638346e-04:  32%|███▏      | 5157/16329 [43:26<1:33:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5157: train loss 2.03826. lr 5.638209e-04:  32%|███▏      | 5157/16329 [43:26<1:33:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5157: train loss 2.03826. lr 5.638209e-04:  32%|███▏      | 5158/16329 [43:26<1:33:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5158: train loss 2.01769. lr 5.638071e-04:  32%|███▏      | 5158/16329 [43:27<1:33:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5158: train loss 2.01769. lr 5.638071e-04:  32%|███▏      | 5159/16329 [43:27<1:33:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5159: train loss 1.98283. lr 5.637934e-04:  32%|███▏      | 5159/16329 [43:27<1:33:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5159: train loss 1.98283. lr 5.637934e-04:  32%|███▏      | 5160/16329 [43:27<1:33:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5160: train loss 2.07291. lr 5.637796e-04:  32%|███▏      | 5160/16329 [43:28<1:33:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5160: train loss 2.07291. lr 5.637796e-04:  32%|███▏      | 5161/16329 [43:28<1:32:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5161: train loss 2.01951. lr 5.637659e-04:  32%|███▏      | 5161/16329 [43:28<1:32:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5161: train loss 2.01951. lr 5.637659e-04:  32%|███▏      | 5162/16329 [43:28<1:32:35,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5162: train loss 2.05451. lr 5.637521e-04:  32%|███▏      | 5162/16329 [43:29<1:32:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5162: train loss 2.05451. lr 5.637521e-04:  32%|███▏      | 5163/16329 [43:29<1:32:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5163: train loss 2.04442. lr 5.637384e-04:  32%|███▏      | 5163/16329 [43:29<1:32:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5163: train loss 2.04442. lr 5.637384e-04:  32%|███▏      | 5164/16329 [43:29<1:32:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5164: train loss 2.01991. lr 5.637246e-04:  32%|███▏      | 5164/16329 [43:30<1:32:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5164: train loss 2.01991. lr 5.637246e-04:  32%|███▏      | 5165/16329 [43:30<1:32:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5165: train loss 1.97055. lr 5.637109e-04:  32%|███▏      | 5165/16329 [43:30<1:32:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5165: train loss 1.97055. lr 5.637109e-04:  32%|███▏      | 5166/16329 [43:30<1:33:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5166: train loss 2.03277. lr 5.636971e-04:  32%|███▏      | 5166/16329 [43:31<1:33:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5166: train loss 2.03277. lr 5.636971e-04:  32%|███▏      | 5167/16329 [43:31<1:33:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5167: train loss 2.01006. lr 5.636833e-04:  32%|███▏      | 5167/16329 [43:31<1:33:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5167: train loss 2.01006. lr 5.636833e-04:  32%|███▏      | 5168/16329 [43:31<1:33:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5168: train loss 2.03829. lr 5.636696e-04:  32%|███▏      | 5168/16329 [43:32<1:33:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5168: train loss 2.03829. lr 5.636696e-04:  32%|███▏      | 5169/16329 [43:32<1:34:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5169: train loss 1.99113. lr 5.636558e-04:  32%|███▏      | 5169/16329 [43:32<1:34:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5169: train loss 1.99113. lr 5.636558e-04:  32%|███▏      | 5170/16329 [43:32<1:33:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5170: train loss 2.03711. lr 5.636420e-04:  32%|███▏      | 5170/16329 [43:33<1:33:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5170: train loss 2.03711. lr 5.636420e-04:  32%|███▏      | 5171/16329 [43:33<1:33:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5171: train loss 2.01915. lr 5.636283e-04:  32%|███▏      | 5171/16329 [43:33<1:33:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5171: train loss 2.01915. lr 5.636283e-04:  32%|███▏      | 5172/16329 [43:33<1:32:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5172: train loss 2.05086. lr 5.636145e-04:  32%|███▏      | 5172/16329 [43:34<1:32:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5172: train loss 2.05086. lr 5.636145e-04:  32%|███▏      | 5173/16329 [43:34<1:32:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5173: train loss 2.06449. lr 5.636007e-04:  32%|███▏      | 5173/16329 [43:34<1:32:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5173: train loss 2.06449. lr 5.636007e-04:  32%|███▏      | 5174/16329 [43:34<1:32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5174: train loss 1.97983. lr 5.635869e-04:  32%|███▏      | 5174/16329 [43:35<1:32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5174: train loss 1.97983. lr 5.635869e-04:  32%|███▏      | 5175/16329 [43:35<1:42:13,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5175: train loss 2.03175. lr 5.635731e-04:  32%|███▏      | 5175/16329 [43:35<1:42:13,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5175: train loss 2.03175. lr 5.635731e-04:  32%|███▏      | 5176/16329 [43:35<1:39:11,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5176: train loss 2.03261. lr 5.635594e-04:  32%|███▏      | 5176/16329 [43:36<1:39:11,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5176: train loss 2.03261. lr 5.635594e-04:  32%|███▏      | 5177/16329 [43:36<1:37:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5177: train loss 2.05861. lr 5.635456e-04:  32%|███▏      | 5177/16329 [43:36<1:37:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5177: train loss 2.05861. lr 5.635456e-04:  32%|███▏      | 5178/16329 [43:36<1:35:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5178: train loss 1.97256. lr 5.635318e-04:  32%|███▏      | 5178/16329 [43:37<1:35:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5178: train loss 1.97256. lr 5.635318e-04:  32%|███▏      | 5179/16329 [43:37<1:34:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5179: train loss 2.05095. lr 5.635180e-04:  32%|███▏      | 5179/16329 [43:37<1:34:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5179: train loss 2.05095. lr 5.635180e-04:  32%|███▏      | 5180/16329 [43:37<1:33:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5180: train loss 1.99557. lr 5.635042e-04:  32%|███▏      | 5180/16329 [43:38<1:33:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5180: train loss 1.99557. lr 5.635042e-04:  32%|███▏      | 5181/16329 [43:38<1:33:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5181: train loss 2.00219. lr 5.634904e-04:  32%|███▏      | 5181/16329 [43:38<1:33:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5181: train loss 2.00219. lr 5.634904e-04:  32%|███▏      | 5182/16329 [43:38<1:33:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5182: train loss 2.02718. lr 5.634766e-04:  32%|███▏      | 5182/16329 [43:39<1:33:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5182: train loss 2.02718. lr 5.634766e-04:  32%|███▏      | 5183/16329 [43:39<1:32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5183: train loss 1.99065. lr 5.634628e-04:  32%|███▏      | 5183/16329 [43:39<1:32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5183: train loss 1.99065. lr 5.634628e-04:  32%|███▏      | 5184/16329 [43:39<1:32:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5184: train loss 2.02804. lr 5.634490e-04:  32%|███▏      | 5184/16329 [43:40<1:32:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5184: train loss 2.02804. lr 5.634490e-04:  32%|███▏      | 5185/16329 [43:40<1:32:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5185: train loss 2.00857. lr 5.634352e-04:  32%|███▏      | 5185/16329 [43:40<1:32:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5185: train loss 2.00857. lr 5.634352e-04:  32%|███▏      | 5186/16329 [43:40<1:32:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5186: train loss 2.00618. lr 5.634214e-04:  32%|███▏      | 5186/16329 [43:41<1:32:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5186: train loss 2.00618. lr 5.634214e-04:  32%|███▏      | 5187/16329 [43:41<1:32:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5187: train loss 2.02600. lr 5.634076e-04:  32%|███▏      | 5187/16329 [43:41<1:32:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5187: train loss 2.02600. lr 5.634076e-04:  32%|███▏      | 5188/16329 [43:41<1:32:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5188: train loss 2.02048. lr 5.633938e-04:  32%|███▏      | 5188/16329 [43:42<1:32:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5188: train loss 2.02048. lr 5.633938e-04:  32%|███▏      | 5189/16329 [43:42<1:32:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5189: train loss 2.05861. lr 5.633799e-04:  32%|███▏      | 5189/16329 [43:42<1:32:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5189: train loss 2.05861. lr 5.633799e-04:  32%|███▏      | 5190/16329 [43:42<1:32:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5190: train loss 2.00850. lr 5.633661e-04:  32%|███▏      | 5190/16329 [43:43<1:32:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5190: train loss 2.00850. lr 5.633661e-04:  32%|███▏      | 5191/16329 [43:43<1:32:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5191: train loss 2.03674. lr 5.633523e-04:  32%|███▏      | 5191/16329 [43:43<1:32:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5191: train loss 2.03674. lr 5.633523e-04:  32%|███▏      | 5192/16329 [43:43<1:31:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5192: train loss 2.00013. lr 5.633385e-04:  32%|███▏      | 5192/16329 [43:44<1:31:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5192: train loss 2.00013. lr 5.633385e-04:  32%|███▏      | 5193/16329 [43:44<1:32:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5193: train loss 2.00344. lr 5.633246e-04:  32%|███▏      | 5193/16329 [43:44<1:32:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5193: train loss 2.00344. lr 5.633246e-04:  32%|███▏      | 5194/16329 [43:44<1:32:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5194: train loss 2.05320. lr 5.633108e-04:  32%|███▏      | 5194/16329 [43:45<1:32:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5194: train loss 2.05320. lr 5.633108e-04:  32%|███▏      | 5195/16329 [43:45<1:32:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5195: train loss 2.01181. lr 5.632970e-04:  32%|███▏      | 5195/16329 [43:45<1:32:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5195: train loss 2.01181. lr 5.632970e-04:  32%|███▏      | 5196/16329 [43:45<1:32:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5196: train loss 2.00840. lr 5.632832e-04:  32%|███▏      | 5196/16329 [43:46<1:32:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5196: train loss 2.00840. lr 5.632832e-04:  32%|███▏      | 5197/16329 [43:46<1:31:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5197: train loss 2.03511. lr 5.632693e-04:  32%|███▏      | 5197/16329 [43:46<1:31:55,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5197: train loss 2.03511. lr 5.632693e-04:  32%|███▏      | 5198/16329 [43:46<1:31:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5198: train loss 2.03672. lr 5.632555e-04:  32%|███▏      | 5198/16329 [43:47<1:31:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5198: train loss 2.03672. lr 5.632555e-04:  32%|███▏      | 5199/16329 [43:47<1:31:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5199: train loss 1.99088. lr 5.632416e-04:  32%|███▏      | 5199/16329 [43:47<1:31:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5199: train loss 1.99088. lr 5.632416e-04:  32%|███▏      | 5200/16329 [43:47<1:32:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5200: train loss 1.95448. lr 5.632278e-04:  32%|███▏      | 5200/16329 [43:48<1:32:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5200: train loss 1.95448. lr 5.632278e-04:  32%|███▏      | 5201/16329 [43:48<1:31:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5201: train loss 1.98645. lr 5.632139e-04:  32%|███▏      | 5201/16329 [43:48<1:31:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5201: train loss 1.98645. lr 5.632139e-04:  32%|███▏      | 5202/16329 [43:48<1:41:03,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 5202: train loss 1.98042. lr 5.632001e-04:  32%|███▏      | 5202/16329 [43:49<1:41:03,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 5202: train loss 1.98042. lr 5.632001e-04:  32%|███▏      | 5203/16329 [43:49<1:38:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5203: train loss 2.02798. lr 5.631862e-04:  32%|███▏      | 5203/16329 [43:49<1:38:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5203: train loss 2.02798. lr 5.631862e-04:  32%|███▏      | 5204/16329 [43:49<1:37:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5204: train loss 2.00046. lr 5.631724e-04:  32%|███▏      | 5204/16329 [43:50<1:37:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5204: train loss 2.00046. lr 5.631724e-04:  32%|███▏      | 5205/16329 [43:50<1:36:24,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5205: train loss 2.00894. lr 5.631585e-04:  32%|███▏      | 5205/16329 [43:50<1:36:24,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5205: train loss 2.00894. lr 5.631585e-04:  32%|███▏      | 5206/16329 [43:50<1:34:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5206: train loss 1.99486. lr 5.631447e-04:  32%|███▏      | 5206/16329 [43:51<1:34:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5206: train loss 1.99486. lr 5.631447e-04:  32%|███▏      | 5207/16329 [43:51<1:33:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5207: train loss 2.02316. lr 5.631308e-04:  32%|███▏      | 5207/16329 [43:51<1:33:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5207: train loss 2.02316. lr 5.631308e-04:  32%|███▏      | 5208/16329 [43:51<1:33:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5208: train loss 1.98194. lr 5.631170e-04:  32%|███▏      | 5208/16329 [43:52<1:33:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5208: train loss 1.98194. lr 5.631170e-04:  32%|███▏      | 5209/16329 [43:52<1:32:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5209: train loss 1.99079. lr 5.631031e-04:  32%|███▏      | 5209/16329 [43:52<1:32:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5209: train loss 1.99079. lr 5.631031e-04:  32%|███▏      | 5210/16329 [43:52<1:32:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5210: train loss 1.98972. lr 5.630892e-04:  32%|███▏      | 5210/16329 [43:53<1:32:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5210: train loss 1.98972. lr 5.630892e-04:  32%|███▏      | 5211/16329 [43:53<1:32:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5211: train loss 2.04300. lr 5.630754e-04:  32%|███▏      | 5211/16329 [43:53<1:32:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5211: train loss 2.04300. lr 5.630754e-04:  32%|███▏      | 5212/16329 [43:53<1:32:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5212: train loss 2.02451. lr 5.630615e-04:  32%|███▏      | 5212/16329 [43:54<1:32:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5212: train loss 2.02451. lr 5.630615e-04:  32%|███▏      | 5213/16329 [43:54<1:32:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5213: train loss 2.04616. lr 5.630476e-04:  32%|███▏      | 5213/16329 [43:54<1:32:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5213: train loss 2.04616. lr 5.630476e-04:  32%|███▏      | 5214/16329 [43:54<1:32:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5214: train loss 2.03241. lr 5.630337e-04:  32%|███▏      | 5214/16329 [43:55<1:32:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5214: train loss 2.03241. lr 5.630337e-04:  32%|███▏      | 5215/16329 [43:55<1:32:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5215: train loss 1.99633. lr 5.630198e-04:  32%|███▏      | 5215/16329 [43:55<1:32:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5215: train loss 1.99633. lr 5.630198e-04:  32%|███▏      | 5216/16329 [43:55<1:31:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5216: train loss 1.97860. lr 5.630060e-04:  32%|███▏      | 5216/16329 [43:56<1:31:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5216: train loss 1.97860. lr 5.630060e-04:  32%|███▏      | 5217/16329 [43:56<1:32:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5217: train loss 2.04539. lr 5.629921e-04:  32%|███▏      | 5217/16329 [43:56<1:32:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5217: train loss 2.04539. lr 5.629921e-04:  32%|███▏      | 5218/16329 [43:56<1:33:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5218: train loss 2.04954. lr 5.629782e-04:  32%|███▏      | 5218/16329 [43:57<1:33:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5218: train loss 2.04954. lr 5.629782e-04:  32%|███▏      | 5219/16329 [43:57<1:34:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5219: train loss 2.00010. lr 5.629643e-04:  32%|███▏      | 5219/16329 [43:57<1:34:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5219: train loss 2.00010. lr 5.629643e-04:  32%|███▏      | 5220/16329 [43:57<1:34:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5220: train loss 2.02724. lr 5.629504e-04:  32%|███▏      | 5220/16329 [43:58<1:34:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5220: train loss 2.02724. lr 5.629504e-04:  32%|███▏      | 5221/16329 [43:58<1:33:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5221: train loss 2.06546. lr 5.629365e-04:  32%|███▏      | 5221/16329 [43:58<1:33:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5221: train loss 2.06546. lr 5.629365e-04:  32%|███▏      | 5222/16329 [43:58<1:33:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5222: train loss 1.94400. lr 5.629226e-04:  32%|███▏      | 5222/16329 [43:59<1:33:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5222: train loss 1.94400. lr 5.629226e-04:  32%|███▏      | 5223/16329 [43:59<1:33:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5223: train loss 1.96413. lr 5.629087e-04:  32%|███▏      | 5223/16329 [43:59<1:33:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5223: train loss 1.96413. lr 5.629087e-04:  32%|███▏      | 5224/16329 [43:59<1:32:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5224: train loss 1.99505. lr 5.628948e-04:  32%|███▏      | 5224/16329 [44:00<1:32:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5224: train loss 1.99505. lr 5.628948e-04:  32%|███▏      | 5225/16329 [44:00<1:32:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5225: train loss 2.02720. lr 5.628809e-04:  32%|███▏      | 5225/16329 [44:00<1:32:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5225: train loss 2.02720. lr 5.628809e-04:  32%|███▏      | 5226/16329 [44:00<1:32:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5226: train loss 1.95543. lr 5.628670e-04:  32%|███▏      | 5226/16329 [44:01<1:32:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5226: train loss 1.95543. lr 5.628670e-04:  32%|███▏      | 5227/16329 [44:01<1:32:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5227: train loss 1.98298. lr 5.628531e-04:  32%|███▏      | 5227/16329 [44:01<1:32:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5227: train loss 1.98298. lr 5.628531e-04:  32%|███▏      | 5228/16329 [44:01<1:32:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5228: train loss 2.06585. lr 5.628392e-04:  32%|███▏      | 5228/16329 [44:02<1:32:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5228: train loss 2.06585. lr 5.628392e-04:  32%|███▏      | 5229/16329 [44:02<1:32:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5229: train loss 1.94718. lr 5.628253e-04:  32%|███▏      | 5229/16329 [44:02<1:32:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5229: train loss 1.94718. lr 5.628253e-04:  32%|███▏      | 5230/16329 [44:02<1:32:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5230: train loss 1.99811. lr 5.628114e-04:  32%|███▏      | 5230/16329 [44:03<1:32:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5230: train loss 1.99811. lr 5.628114e-04:  32%|███▏      | 5231/16329 [44:03<1:32:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5231: train loss 2.03657. lr 5.627974e-04:  32%|███▏      | 5231/16329 [44:03<1:32:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5231: train loss 2.03657. lr 5.627974e-04:  32%|███▏      | 5232/16329 [44:03<1:31:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5232: train loss 2.03396. lr 5.627835e-04:  32%|███▏      | 5232/16329 [44:04<1:31:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5232: train loss 2.03396. lr 5.627835e-04:  32%|███▏      | 5233/16329 [44:04<1:31:57,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5233: train loss 2.01969. lr 5.627696e-04:  32%|███▏      | 5233/16329 [44:04<1:31:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5233: train loss 2.01969. lr 5.627696e-04:  32%|███▏      | 5234/16329 [44:04<1:31:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5234: train loss 2.05116. lr 5.627557e-04:  32%|███▏      | 5234/16329 [44:05<1:31:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5234: train loss 2.05116. lr 5.627557e-04:  32%|███▏      | 5235/16329 [44:05<1:32:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5235: train loss 1.96100. lr 5.627417e-04:  32%|███▏      | 5235/16329 [44:05<1:32:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5235: train loss 1.96100. lr 5.627417e-04:  32%|███▏      | 5236/16329 [44:05<1:32:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5236: train loss 2.07995. lr 5.627278e-04:  32%|███▏      | 5236/16329 [44:06<1:32:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5236: train loss 2.07995. lr 5.627278e-04:  32%|███▏      | 5237/16329 [44:06<1:32:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5237: train loss 2.00779. lr 5.627139e-04:  32%|███▏      | 5237/16329 [44:06<1:32:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5237: train loss 2.00779. lr 5.627139e-04:  32%|███▏      | 5238/16329 [44:06<1:31:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5238: train loss 1.98007. lr 5.626999e-04:  32%|███▏      | 5238/16329 [44:07<1:31:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5238: train loss 1.98007. lr 5.626999e-04:  32%|███▏      | 5239/16329 [44:07<1:31:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5239: train loss 2.01489. lr 5.626860e-04:  32%|███▏      | 5239/16329 [44:07<1:31:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5239: train loss 2.01489. lr 5.626860e-04:  32%|███▏      | 5240/16329 [44:07<1:31:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5240: train loss 1.94414. lr 5.626721e-04:  32%|███▏      | 5240/16329 [44:08<1:31:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5240: train loss 1.94414. lr 5.626721e-04:  32%|███▏      | 5241/16329 [44:08<1:31:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5241: train loss 2.03703. lr 5.626581e-04:  32%|███▏      | 5241/16329 [44:08<1:31:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5241: train loss 2.03703. lr 5.626581e-04:  32%|███▏      | 5242/16329 [44:08<1:41:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5242: train loss 2.04088. lr 5.626442e-04:  32%|███▏      | 5242/16329 [44:09<1:41:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5242: train loss 2.04088. lr 5.626442e-04:  32%|███▏      | 5243/16329 [44:09<1:38:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5243: train loss 1.99492. lr 5.626302e-04:  32%|███▏      | 5243/16329 [44:09<1:38:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5243: train loss 1.99492. lr 5.626302e-04:  32%|███▏      | 5244/16329 [44:09<1:36:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5244: train loss 2.06457. lr 5.626163e-04:  32%|███▏      | 5244/16329 [44:10<1:36:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5244: train loss 2.06457. lr 5.626163e-04:  32%|███▏      | 5245/16329 [44:10<1:34:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5245: train loss 2.00853. lr 5.626023e-04:  32%|███▏      | 5245/16329 [44:10<1:34:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5245: train loss 2.00853. lr 5.626023e-04:  32%|███▏      | 5246/16329 [44:10<1:33:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5246: train loss 2.01594. lr 5.625884e-04:  32%|███▏      | 5246/16329 [44:11<1:33:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5246: train loss 2.01594. lr 5.625884e-04:  32%|███▏      | 5247/16329 [44:11<1:33:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5247: train loss 1.97243. lr 5.625744e-04:  32%|███▏      | 5247/16329 [44:11<1:33:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5247: train loss 1.97243. lr 5.625744e-04:  32%|███▏      | 5248/16329 [44:11<1:32:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5248: train loss 2.00377. lr 5.625604e-04:  32%|███▏      | 5248/16329 [44:12<1:32:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5248: train loss 2.00377. lr 5.625604e-04:  32%|███▏      | 5249/16329 [44:12<1:32:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5249: train loss 1.99214. lr 5.625465e-04:  32%|███▏      | 5249/16329 [44:12<1:32:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5249: train loss 1.99214. lr 5.625465e-04:  32%|███▏      | 5250/16329 [44:12<1:32:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5250: train loss 1.99408. lr 5.625325e-04:  32%|███▏      | 5250/16329 [44:13<1:32:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5250: train loss 1.99408. lr 5.625325e-04:  32%|███▏      | 5251/16329 [44:13<1:31:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5251: train loss 1.98859. lr 5.625186e-04:  32%|███▏      | 5251/16329 [44:13<1:31:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5251: train loss 1.98859. lr 5.625186e-04:  32%|███▏      | 5252/16329 [44:13<1:31:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5252: train loss 2.02228. lr 5.625046e-04:  32%|███▏      | 5252/16329 [44:14<1:31:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5252: train loss 2.02228. lr 5.625046e-04:  32%|███▏      | 5253/16329 [44:14<1:31:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5253: train loss 1.96612. lr 5.624906e-04:  32%|███▏      | 5253/16329 [44:14<1:31:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5253: train loss 1.96612. lr 5.624906e-04:  32%|███▏      | 5254/16329 [44:14<1:31:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5254: train loss 2.00938. lr 5.624766e-04:  32%|███▏      | 5254/16329 [44:15<1:31:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5254: train loss 2.00938. lr 5.624766e-04:  32%|███▏      | 5255/16329 [44:15<1:31:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5255: train loss 1.99833. lr 5.624627e-04:  32%|███▏      | 5255/16329 [44:15<1:31:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5255: train loss 1.99833. lr 5.624627e-04:  32%|███▏      | 5256/16329 [44:15<1:31:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5256: train loss 1.97803. lr 5.624487e-04:  32%|███▏      | 5256/16329 [44:16<1:31:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5256: train loss 1.97803. lr 5.624487e-04:  32%|███▏      | 5257/16329 [44:16<1:31:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5257: train loss 1.99658. lr 5.624347e-04:  32%|███▏      | 5257/16329 [44:16<1:31:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5257: train loss 1.99658. lr 5.624347e-04:  32%|███▏      | 5258/16329 [44:16<1:31:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5258: train loss 2.00429. lr 5.624207e-04:  32%|███▏      | 5258/16329 [44:17<1:31:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5258: train loss 2.00429. lr 5.624207e-04:  32%|███▏      | 5259/16329 [44:17<1:32:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5259: train loss 2.01119. lr 5.624067e-04:  32%|███▏      | 5259/16329 [44:17<1:32:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5259: train loss 2.01119. lr 5.624067e-04:  32%|███▏      | 5260/16329 [44:17<1:32:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5260: train loss 1.99517. lr 5.623927e-04:  32%|███▏      | 5260/16329 [44:18<1:32:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5260: train loss 1.99517. lr 5.623927e-04:  32%|███▏      | 5261/16329 [44:18<1:32:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5261: train loss 2.01290. lr 5.623787e-04:  32%|███▏      | 5261/16329 [44:18<1:32:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5261: train loss 2.01290. lr 5.623787e-04:  32%|███▏      | 5262/16329 [44:18<1:31:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5262: train loss 2.00216. lr 5.623647e-04:  32%|███▏      | 5262/16329 [44:19<1:31:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5262: train loss 2.00216. lr 5.623647e-04:  32%|███▏      | 5263/16329 [44:19<1:31:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5263: train loss 2.04968. lr 5.623508e-04:  32%|███▏      | 5263/16329 [44:19<1:31:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5263: train loss 2.04968. lr 5.623508e-04:  32%|███▏      | 5264/16329 [44:19<1:31:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5264: train loss 1.98561. lr 5.623368e-04:  32%|███▏      | 5264/16329 [44:20<1:31:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5264: train loss 1.98561. lr 5.623368e-04:  32%|███▏      | 5265/16329 [44:20<1:31:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5265: train loss 2.00027. lr 5.623228e-04:  32%|███▏      | 5265/16329 [44:20<1:31:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5265: train loss 2.00027. lr 5.623228e-04:  32%|███▏      | 5266/16329 [44:20<1:32:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5266: train loss 2.01182. lr 5.623087e-04:  32%|███▏      | 5266/16329 [44:21<1:32:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5266: train loss 2.01182. lr 5.623087e-04:  32%|███▏      | 5267/16329 [44:21<1:31:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5267: train loss 2.00337. lr 5.622947e-04:  32%|███▏      | 5267/16329 [44:21<1:31:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5267: train loss 2.00337. lr 5.622947e-04:  32%|███▏      | 5268/16329 [44:21<1:32:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5268: train loss 1.96821. lr 5.622807e-04:  32%|███▏      | 5268/16329 [44:22<1:32:00,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5268: train loss 1.96821. lr 5.622807e-04:  32%|███▏      | 5269/16329 [44:22<1:31:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5269: train loss 1.98838. lr 5.622667e-04:  32%|███▏      | 5269/16329 [44:22<1:31:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5269: train loss 1.98838. lr 5.622667e-04:  32%|███▏      | 5270/16329 [44:22<1:31:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5270: train loss 2.00086. lr 5.622527e-04:  32%|███▏      | 5270/16329 [44:23<1:31:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5270: train loss 2.00086. lr 5.622527e-04:  32%|███▏      | 5271/16329 [44:23<1:31:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5271: train loss 1.98735. lr 5.622387e-04:  32%|███▏      | 5271/16329 [44:23<1:31:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5271: train loss 1.98735. lr 5.622387e-04:  32%|███▏      | 5272/16329 [44:23<1:31:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5272: train loss 2.00532. lr 5.622247e-04:  32%|███▏      | 5272/16329 [44:24<1:31:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5272: train loss 2.00532. lr 5.622247e-04:  32%|███▏      | 5273/16329 [44:24<1:31:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5273: train loss 1.97074. lr 5.622107e-04:  32%|███▏      | 5273/16329 [44:24<1:31:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5273: train loss 1.97074. lr 5.622107e-04:  32%|███▏      | 5274/16329 [44:24<1:31:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5274: train loss 2.04600. lr 5.621966e-04:  32%|███▏      | 5274/16329 [44:25<1:31:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5274: train loss 2.04600. lr 5.621966e-04:  32%|███▏      | 5275/16329 [44:25<1:31:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5275: train loss 2.00436. lr 5.621826e-04:  32%|███▏      | 5275/16329 [44:25<1:31:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5275: train loss 2.00436. lr 5.621826e-04:  32%|███▏      | 5276/16329 [44:25<1:31:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5276: train loss 2.01771. lr 5.621686e-04:  32%|███▏      | 5276/16329 [44:26<1:31:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5276: train loss 2.01771. lr 5.621686e-04:  32%|███▏      | 5277/16329 [44:26<1:40:28,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5277: train loss 2.04616. lr 5.621545e-04:  32%|███▏      | 5277/16329 [44:26<1:40:28,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5277: train loss 2.04616. lr 5.621545e-04:  32%|███▏      | 5278/16329 [44:26<1:37:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5278: train loss 1.95103. lr 5.621405e-04:  32%|███▏      | 5278/16329 [44:27<1:37:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5278: train loss 1.95103. lr 5.621405e-04:  32%|███▏      | 5279/16329 [44:27<1:35:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5279: train loss 2.01208. lr 5.621265e-04:  32%|███▏      | 5279/16329 [44:27<1:35:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5279: train loss 2.01208. lr 5.621265e-04:  32%|███▏      | 5280/16329 [44:27<1:34:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5280: train loss 1.97160. lr 5.621124e-04:  32%|███▏      | 5280/16329 [44:28<1:34:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5280: train loss 1.97160. lr 5.621124e-04:  32%|███▏      | 5281/16329 [44:28<1:33:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5281: train loss 1.94783. lr 5.620984e-04:  32%|███▏      | 5281/16329 [44:28<1:33:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5281: train loss 1.94783. lr 5.620984e-04:  32%|███▏      | 5282/16329 [44:28<1:32:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5282: train loss 1.99574. lr 5.620844e-04:  32%|███▏      | 5282/16329 [44:29<1:32:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5282: train loss 1.99574. lr 5.620844e-04:  32%|███▏      | 5283/16329 [44:29<1:32:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5283: train loss 2.01830. lr 5.620703e-04:  32%|███▏      | 5283/16329 [44:29<1:32:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5283: train loss 2.01830. lr 5.620703e-04:  32%|███▏      | 5284/16329 [44:29<1:31:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5284: train loss 2.05340. lr 5.620563e-04:  32%|███▏      | 5284/16329 [44:30<1:31:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5284: train loss 2.05340. lr 5.620563e-04:  32%|███▏      | 5285/16329 [44:30<1:31:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5285: train loss 2.02110. lr 5.620422e-04:  32%|███▏      | 5285/16329 [44:30<1:31:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5285: train loss 2.02110. lr 5.620422e-04:  32%|███▏      | 5286/16329 [44:30<1:31:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5286: train loss 2.02547. lr 5.620282e-04:  32%|███▏      | 5286/16329 [44:31<1:31:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5286: train loss 2.02547. lr 5.620282e-04:  32%|███▏      | 5287/16329 [44:31<1:31:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5287: train loss 1.99774. lr 5.620141e-04:  32%|███▏      | 5287/16329 [44:31<1:31:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5287: train loss 1.99774. lr 5.620141e-04:  32%|███▏      | 5288/16329 [44:31<1:31:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5288: train loss 1.97047. lr 5.620000e-04:  32%|███▏      | 5288/16329 [44:32<1:31:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5288: train loss 1.97047. lr 5.620000e-04:  32%|███▏      | 5289/16329 [44:32<1:31:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5289: train loss 2.03070. lr 5.619860e-04:  32%|███▏      | 5289/16329 [44:32<1:31:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5289: train loss 2.03070. lr 5.619860e-04:  32%|███▏      | 5290/16329 [44:32<1:33:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5290: train loss 1.99344. lr 5.619719e-04:  32%|███▏      | 5290/16329 [44:33<1:33:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5290: train loss 1.99344. lr 5.619719e-04:  32%|███▏      | 5291/16329 [44:33<1:34:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5291: train loss 2.09993. lr 5.619579e-04:  32%|███▏      | 5291/16329 [44:33<1:34:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5291: train loss 2.09993. lr 5.619579e-04:  32%|███▏      | 5292/16329 [44:33<1:35:32,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5292: train loss 1.99452. lr 5.619438e-04:  32%|███▏      | 5292/16329 [44:34<1:35:32,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5292: train loss 1.99452. lr 5.619438e-04:  32%|███▏      | 5293/16329 [44:34<1:35:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5293: train loss 2.02214. lr 5.619297e-04:  32%|███▏      | 5293/16329 [44:35<1:35:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5293: train loss 2.02214. lr 5.619297e-04:  32%|███▏      | 5294/16329 [44:35<1:36:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5294: train loss 1.95709. lr 5.619157e-04:  32%|███▏      | 5294/16329 [44:35<1:36:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5294: train loss 1.95709. lr 5.619157e-04:  32%|███▏      | 5295/16329 [44:35<1:36:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5295: train loss 1.97104. lr 5.619016e-04:  32%|███▏      | 5295/16329 [44:36<1:36:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5295: train loss 1.97104. lr 5.619016e-04:  32%|███▏      | 5296/16329 [44:36<1:36:41,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5296: train loss 1.93508. lr 5.618875e-04:  32%|███▏      | 5296/16329 [44:36<1:36:41,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5296: train loss 1.93508. lr 5.618875e-04:  32%|███▏      | 5297/16329 [44:36<1:35:44,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5297: train loss 1.95061. lr 5.618734e-04:  32%|███▏      | 5297/16329 [44:37<1:35:44,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5297: train loss 1.95061. lr 5.618734e-04:  32%|███▏      | 5298/16329 [44:37<1:35:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5298: train loss 1.95450. lr 5.618593e-04:  32%|███▏      | 5298/16329 [44:37<1:35:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5298: train loss 1.95450. lr 5.618593e-04:  32%|███▏      | 5299/16329 [44:37<1:34:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5299: train loss 1.98993. lr 5.618453e-04:  32%|███▏      | 5299/16329 [44:38<1:34:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5299: train loss 1.98993. lr 5.618453e-04:  32%|███▏      | 5300/16329 [44:38<1:33:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5300: train loss 1.94679. lr 5.618312e-04:  32%|███▏      | 5300/16329 [44:38<1:33:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5300: train loss 1.94679. lr 5.618312e-04:  32%|███▏      | 5301/16329 [44:38<1:33:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5301: train loss 1.94518. lr 5.618171e-04:  32%|███▏      | 5301/16329 [44:39<1:33:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5301: train loss 1.94518. lr 5.618171e-04:  32%|███▏      | 5302/16329 [44:39<1:44:23,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 5302: train loss 2.03710. lr 5.618030e-04:  32%|███▏      | 5302/16329 [44:39<1:44:23,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 5302: train loss 2.03710. lr 5.618030e-04:  32%|███▏      | 5303/16329 [44:39<1:40:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5303: train loss 1.96957. lr 5.617889e-04:  32%|███▏      | 5303/16329 [44:40<1:40:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5303: train loss 1.96957. lr 5.617889e-04:  32%|███▏      | 5304/16329 [44:40<1:37:39,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5304: train loss 1.98063. lr 5.617748e-04:  32%|███▏      | 5304/16329 [44:40<1:37:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5304: train loss 1.98063. lr 5.617748e-04:  32%|███▏      | 5305/16329 [44:40<1:35:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5305: train loss 1.99476. lr 5.617607e-04:  32%|███▏      | 5305/16329 [44:41<1:35:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5305: train loss 1.99476. lr 5.617607e-04:  32%|███▏      | 5306/16329 [44:41<1:34:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5306: train loss 2.01225. lr 5.617466e-04:  32%|███▏      | 5306/16329 [44:41<1:34:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5306: train loss 2.01225. lr 5.617466e-04:  33%|███▎      | 5307/16329 [44:41<1:33:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5307: train loss 2.02646. lr 5.617325e-04:  33%|███▎      | 5307/16329 [44:42<1:33:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5307: train loss 2.02646. lr 5.617325e-04:  33%|███▎      | 5308/16329 [44:42<1:32:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5308: train loss 1.94058. lr 5.617184e-04:  33%|███▎      | 5308/16329 [44:42<1:32:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5308: train loss 1.94058. lr 5.617184e-04:  33%|███▎      | 5309/16329 [44:42<1:32:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5309: train loss 1.96608. lr 5.617043e-04:  33%|███▎      | 5309/16329 [44:43<1:32:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5309: train loss 1.96608. lr 5.617043e-04:  33%|███▎      | 5310/16329 [44:43<1:32:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5310: train loss 1.97571. lr 5.616902e-04:  33%|███▎      | 5310/16329 [44:43<1:32:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5310: train loss 1.97571. lr 5.616902e-04:  33%|███▎      | 5311/16329 [44:43<1:31:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5311: train loss 1.97082. lr 5.616761e-04:  33%|███▎      | 5311/16329 [44:44<1:31:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5311: train loss 1.97082. lr 5.616761e-04:  33%|███▎      | 5312/16329 [44:44<1:31:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5312: train loss 2.04241. lr 5.616619e-04:  33%|███▎      | 5312/16329 [44:44<1:31:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5312: train loss 2.04241. lr 5.616619e-04:  33%|███▎      | 5313/16329 [44:44<1:31:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5313: train loss 2.01254. lr 5.616478e-04:  33%|███▎      | 5313/16329 [44:45<1:31:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5313: train loss 2.01254. lr 5.616478e-04:  33%|███▎      | 5314/16329 [44:45<1:31:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5314: train loss 1.94211. lr 5.616337e-04:  33%|███▎      | 5314/16329 [44:45<1:31:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5314: train loss 1.94211. lr 5.616337e-04:  33%|███▎      | 5315/16329 [44:45<1:31:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5315: train loss 2.01601. lr 5.616196e-04:  33%|███▎      | 5315/16329 [44:46<1:31:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5315: train loss 2.01601. lr 5.616196e-04:  33%|███▎      | 5316/16329 [44:46<1:31:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5316: train loss 1.97438. lr 5.616055e-04:  33%|███▎      | 5316/16329 [44:46<1:31:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5316: train loss 1.97438. lr 5.616055e-04:  33%|███▎      | 5317/16329 [44:46<1:31:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5317: train loss 1.95676. lr 5.615913e-04:  33%|███▎      | 5317/16329 [44:47<1:31:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5317: train loss 1.95676. lr 5.615913e-04:  33%|███▎      | 5318/16329 [44:47<1:31:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5318: train loss 1.97973. lr 5.615772e-04:  33%|███▎      | 5318/16329 [44:47<1:31:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5318: train loss 1.97973. lr 5.615772e-04:  33%|███▎      | 5319/16329 [44:47<1:31:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5319: train loss 2.01530. lr 5.615631e-04:  33%|███▎      | 5319/16329 [44:48<1:31:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5319: train loss 2.01530. lr 5.615631e-04:  33%|███▎      | 5320/16329 [44:48<1:31:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5320: train loss 2.00885. lr 5.615489e-04:  33%|███▎      | 5320/16329 [44:48<1:31:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5320: train loss 2.00885. lr 5.615489e-04:  33%|███▎      | 5321/16329 [44:48<1:30:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5321: train loss 2.00992. lr 5.615348e-04:  33%|███▎      | 5321/16329 [44:49<1:30:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5321: train loss 2.00992. lr 5.615348e-04:  33%|███▎      | 5322/16329 [44:49<1:31:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5322: train loss 2.03522. lr 5.615207e-04:  33%|███▎      | 5322/16329 [44:49<1:31:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5322: train loss 2.03522. lr 5.615207e-04:  33%|███▎      | 5323/16329 [44:49<1:31:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5323: train loss 1.93605. lr 5.615065e-04:  33%|███▎      | 5323/16329 [44:50<1:31:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5323: train loss 1.93605. lr 5.615065e-04:  33%|███▎      | 5324/16329 [44:50<1:31:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5324: train loss 1.94903. lr 5.614924e-04:  33%|███▎      | 5324/16329 [44:50<1:31:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5324: train loss 1.94903. lr 5.614924e-04:  33%|███▎      | 5325/16329 [44:50<1:31:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5325: train loss 2.02171. lr 5.614782e-04:  33%|███▎      | 5325/16329 [44:51<1:31:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5325: train loss 2.02171. lr 5.614782e-04:  33%|███▎      | 5326/16329 [44:51<1:31:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5326: train loss 1.93302. lr 5.614641e-04:  33%|███▎      | 5326/16329 [44:51<1:31:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5326: train loss 1.93302. lr 5.614641e-04:  33%|███▎      | 5327/16329 [44:51<1:31:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5327: train loss 1.98845. lr 5.614499e-04:  33%|███▎      | 5327/16329 [44:52<1:31:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5327: train loss 1.98845. lr 5.614499e-04:  33%|███▎      | 5328/16329 [44:52<1:30:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5328: train loss 1.97217. lr 5.614358e-04:  33%|███▎      | 5328/16329 [44:52<1:30:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5328: train loss 1.97217. lr 5.614358e-04:  33%|███▎      | 5329/16329 [44:52<1:43:40,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5329: train loss 1.93571. lr 5.614216e-04:  33%|███▎      | 5329/16329 [44:53<1:43:40,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5329: train loss 1.93571. lr 5.614216e-04:  33%|███▎      | 5330/16329 [44:53<1:41:14,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5330: train loss 2.01372. lr 5.614075e-04:  33%|███▎      | 5330/16329 [44:54<1:41:14,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5330: train loss 2.01372. lr 5.614075e-04:  33%|███▎      | 5331/16329 [44:54<1:38:39,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5331: train loss 1.98289. lr 5.613933e-04:  33%|███▎      | 5331/16329 [44:54<1:38:39,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5331: train loss 1.98289. lr 5.613933e-04:  33%|███▎      | 5332/16329 [44:54<1:36:59,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5332: train loss 2.02328. lr 5.613791e-04:  33%|███▎      | 5332/16329 [44:55<1:36:59,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5332: train loss 2.02328. lr 5.613791e-04:  33%|███▎      | 5333/16329 [44:55<1:37:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5333: train loss 2.06100. lr 5.613650e-04:  33%|███▎      | 5333/16329 [44:55<1:37:14,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5333: train loss 2.06100. lr 5.613650e-04:  33%|███▎      | 5334/16329 [44:55<1:37:44,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5334: train loss 1.99027. lr 5.613508e-04:  33%|███▎      | 5334/16329 [44:56<1:37:44,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5334: train loss 1.99027. lr 5.613508e-04:  33%|███▎      | 5335/16329 [44:56<1:37:25,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5335: train loss 2.01729. lr 5.613366e-04:  33%|███▎      | 5335/16329 [44:56<1:37:25,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5335: train loss 2.01729. lr 5.613366e-04:  33%|███▎      | 5336/16329 [44:56<1:36:47,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5336: train loss 2.01546. lr 5.613224e-04:  33%|███▎      | 5336/16329 [44:57<1:36:47,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5336: train loss 2.01546. lr 5.613224e-04:  33%|███▎      | 5337/16329 [44:57<1:36:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5337: train loss 1.95365. lr 5.613083e-04:  33%|███▎      | 5337/16329 [44:57<1:36:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5337: train loss 1.95365. lr 5.613083e-04:  33%|███▎      | 5338/16329 [44:57<1:35:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5338: train loss 1.97218. lr 5.612941e-04:  33%|███▎      | 5338/16329 [44:58<1:35:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5338: train loss 1.97218. lr 5.612941e-04:  33%|███▎      | 5339/16329 [44:58<1:34:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5339: train loss 1.98263. lr 5.612799e-04:  33%|███▎      | 5339/16329 [44:58<1:34:43,  1.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5339: train loss 1.98263. lr 5.612799e-04:  33%|███▎      | 5340/16329 [44:58<1:34:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5340: train loss 1.98221. lr 5.612657e-04:  33%|███▎      | 5340/16329 [44:59<1:34:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5340: train loss 1.98221. lr 5.612657e-04:  33%|███▎      | 5341/16329 [44:59<1:34:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5341: train loss 2.04355. lr 5.612515e-04:  33%|███▎      | 5341/16329 [44:59<1:34:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5341: train loss 2.04355. lr 5.612515e-04:  33%|███▎      | 5342/16329 [44:59<1:33:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5342: train loss 1.99894. lr 5.612374e-04:  33%|███▎      | 5342/16329 [45:00<1:33:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5342: train loss 1.99894. lr 5.612374e-04:  33%|███▎      | 5343/16329 [45:00<1:32:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5343: train loss 2.01143. lr 5.612232e-04:  33%|███▎      | 5343/16329 [45:00<1:32:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5343: train loss 2.01143. lr 5.612232e-04:  33%|███▎      | 5344/16329 [45:00<1:32:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5344: train loss 2.00482. lr 5.612090e-04:  33%|███▎      | 5344/16329 [45:01<1:32:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5344: train loss 2.00482. lr 5.612090e-04:  33%|███▎      | 5345/16329 [45:01<1:31:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5345: train loss 2.02379. lr 5.611948e-04:  33%|███▎      | 5345/16329 [45:01<1:31:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5345: train loss 2.02379. lr 5.611948e-04:  33%|███▎      | 5346/16329 [45:01<1:31:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5346: train loss 1.95064. lr 5.611806e-04:  33%|███▎      | 5346/16329 [45:02<1:31:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5346: train loss 1.95064. lr 5.611806e-04:  33%|███▎      | 5347/16329 [45:02<1:31:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5347: train loss 1.99436. lr 5.611664e-04:  33%|███▎      | 5347/16329 [45:02<1:31:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5347: train loss 1.99436. lr 5.611664e-04:  33%|███▎      | 5348/16329 [45:02<1:30:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5348: train loss 2.01152. lr 5.611522e-04:  33%|███▎      | 5348/16329 [45:03<1:30:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5348: train loss 2.01152. lr 5.611522e-04:  33%|███▎      | 5349/16329 [45:03<1:30:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5349: train loss 1.95652. lr 5.611380e-04:  33%|███▎      | 5349/16329 [45:03<1:30:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5349: train loss 1.95652. lr 5.611380e-04:  33%|███▎      | 5350/16329 [45:03<1:30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5350: train loss 1.99325. lr 5.611238e-04:  33%|███▎      | 5350/16329 [45:04<1:30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5350: train loss 1.99325. lr 5.611238e-04:  33%|███▎      | 5351/16329 [45:04<1:30:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5351: train loss 1.96099. lr 5.611096e-04:  33%|███▎      | 5351/16329 [45:04<1:30:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5351: train loss 1.96099. lr 5.611096e-04:  33%|███▎      | 5352/16329 [45:04<1:30:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5352: train loss 1.96463. lr 5.610953e-04:  33%|███▎      | 5352/16329 [45:05<1:30:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5352: train loss 1.96463. lr 5.610953e-04:  33%|███▎      | 5353/16329 [45:05<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5353: train loss 1.95488. lr 5.610811e-04:  33%|███▎      | 5353/16329 [45:05<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5353: train loss 1.95488. lr 5.610811e-04:  33%|███▎      | 5354/16329 [45:05<1:30:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5354: train loss 2.02441. lr 5.610669e-04:  33%|███▎      | 5354/16329 [45:06<1:30:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5354: train loss 2.02441. lr 5.610669e-04:  33%|███▎      | 5355/16329 [45:06<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5355: train loss 1.95182. lr 5.610527e-04:  33%|███▎      | 5355/16329 [45:06<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5355: train loss 1.95182. lr 5.610527e-04:  33%|███▎      | 5356/16329 [45:06<1:30:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5356: train loss 2.01658. lr 5.610385e-04:  33%|███▎      | 5356/16329 [45:07<1:30:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5356: train loss 2.01658. lr 5.610385e-04:  33%|███▎      | 5357/16329 [45:07<1:30:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5357: train loss 1.95126. lr 5.610242e-04:  33%|███▎      | 5357/16329 [45:07<1:30:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5357: train loss 1.95126. lr 5.610242e-04:  33%|███▎      | 5358/16329 [45:07<1:30:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5358: train loss 1.98116. lr 5.610100e-04:  33%|███▎      | 5358/16329 [45:08<1:30:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5358: train loss 1.98116. lr 5.610100e-04:  33%|███▎      | 5359/16329 [45:08<1:30:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5359: train loss 1.93586. lr 5.609958e-04:  33%|███▎      | 5359/16329 [45:08<1:30:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5359: train loss 1.93586. lr 5.609958e-04:  33%|███▎      | 5360/16329 [45:08<1:30:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5360: train loss 1.98814. lr 5.609816e-04:  33%|███▎      | 5360/16329 [45:09<1:30:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5360: train loss 1.98814. lr 5.609816e-04:  33%|███▎      | 5361/16329 [45:09<1:30:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5361: train loss 1.97899. lr 5.609673e-04:  33%|███▎      | 5361/16329 [45:09<1:30:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5361: train loss 1.97899. lr 5.609673e-04:  33%|███▎      | 5362/16329 [45:09<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5362: train loss 2.02661. lr 5.609531e-04:  33%|███▎      | 5362/16329 [45:10<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5362: train loss 2.02661. lr 5.609531e-04:  33%|███▎      | 5363/16329 [45:10<1:30:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5363: train loss 1.98461. lr 5.609388e-04:  33%|███▎      | 5363/16329 [45:10<1:30:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5363: train loss 1.98461. lr 5.609388e-04:  33%|███▎      | 5364/16329 [45:10<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5364: train loss 1.99461. lr 5.609246e-04:  33%|███▎      | 5364/16329 [45:11<1:30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5364: train loss 1.99461. lr 5.609246e-04:  33%|███▎      | 5365/16329 [45:11<1:30:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5365: train loss 1.95669. lr 5.609104e-04:  33%|███▎      | 5365/16329 [45:11<1:30:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5365: train loss 1.95669. lr 5.609104e-04:  33%|███▎      | 5366/16329 [45:11<1:30:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5366: train loss 1.95831. lr 5.608961e-04:  33%|███▎      | 5366/16329 [45:12<1:30:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5366: train loss 1.95831. lr 5.608961e-04:  33%|███▎      | 5367/16329 [45:12<1:30:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5367: train loss 1.90515. lr 5.608819e-04:  33%|███▎      | 5367/16329 [45:12<1:30:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5367: train loss 1.90515. lr 5.608819e-04:  33%|███▎      | 5368/16329 [45:12<1:30:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5368: train loss 1.97463. lr 5.608676e-04:  33%|███▎      | 5368/16329 [45:13<1:30:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5368: train loss 1.97463. lr 5.608676e-04:  33%|███▎      | 5369/16329 [45:13<1:40:35,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5369: train loss 1.99064. lr 5.608534e-04:  33%|███▎      | 5369/16329 [45:13<1:40:35,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5369: train loss 1.99064. lr 5.608534e-04:  33%|███▎      | 5370/16329 [45:13<1:37:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5370: train loss 1.99239. lr 5.608391e-04:  33%|███▎      | 5370/16329 [45:14<1:37:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5370: train loss 1.99239. lr 5.608391e-04:  33%|███▎      | 5371/16329 [45:14<1:35:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5371: train loss 1.97735. lr 5.608248e-04:  33%|███▎      | 5371/16329 [45:14<1:35:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5371: train loss 1.97735. lr 5.608248e-04:  33%|███▎      | 5372/16329 [45:14<1:34:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5372: train loss 1.96208. lr 5.608106e-04:  33%|███▎      | 5372/16329 [45:15<1:34:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5372: train loss 1.96208. lr 5.608106e-04:  33%|███▎      | 5373/16329 [45:15<1:33:08,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5373: train loss 1.96080. lr 5.607963e-04:  33%|███▎      | 5373/16329 [45:15<1:33:08,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5373: train loss 1.96080. lr 5.607963e-04:  33%|███▎      | 5374/16329 [45:15<1:32:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5374: train loss 1.95370. lr 5.607821e-04:  33%|███▎      | 5374/16329 [45:16<1:32:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5374: train loss 1.95370. lr 5.607821e-04:  33%|███▎      | 5375/16329 [45:16<1:31:32,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5375: train loss 2.01273. lr 5.607678e-04:  33%|███▎      | 5375/16329 [45:16<1:31:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5375: train loss 2.01273. lr 5.607678e-04:  33%|███▎      | 5376/16329 [45:16<1:31:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5376: train loss 1.93669. lr 5.607535e-04:  33%|███▎      | 5376/16329 [45:17<1:31:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5376: train loss 1.93669. lr 5.607535e-04:  33%|███▎      | 5377/16329 [45:17<1:30:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5377: train loss 1.92422. lr 5.607393e-04:  33%|███▎      | 5377/16329 [45:17<1:30:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5377: train loss 1.92422. lr 5.607393e-04:  33%|███▎      | 5378/16329 [45:17<1:31:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5378: train loss 1.96387. lr 5.607250e-04:  33%|███▎      | 5378/16329 [45:18<1:31:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5378: train loss 1.96387. lr 5.607250e-04:  33%|███▎      | 5379/16329 [45:18<1:30:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5379: train loss 1.94842. lr 5.607107e-04:  33%|███▎      | 5379/16329 [45:18<1:30:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5379: train loss 1.94842. lr 5.607107e-04:  33%|███▎      | 5380/16329 [45:18<1:30:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5380: train loss 2.02210. lr 5.606964e-04:  33%|███▎      | 5380/16329 [45:19<1:30:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5380: train loss 2.02210. lr 5.606964e-04:  33%|███▎      | 5381/16329 [45:19<1:30:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5381: train loss 1.93009. lr 5.606821e-04:  33%|███▎      | 5381/16329 [45:19<1:30:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5381: train loss 1.93009. lr 5.606821e-04:  33%|███▎      | 5382/16329 [45:19<1:30:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5382: train loss 1.96749. lr 5.606679e-04:  33%|███▎      | 5382/16329 [45:20<1:30:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5382: train loss 1.96749. lr 5.606679e-04:  33%|███▎      | 5383/16329 [45:20<1:30:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5383: train loss 1.96974. lr 5.606536e-04:  33%|███▎      | 5383/16329 [45:20<1:30:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5383: train loss 1.96974. lr 5.606536e-04:  33%|███▎      | 5384/16329 [45:20<1:30:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5384: train loss 1.97061. lr 5.606393e-04:  33%|███▎      | 5384/16329 [45:21<1:30:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5384: train loss 1.97061. lr 5.606393e-04:  33%|███▎      | 5385/16329 [45:21<1:30:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5385: train loss 1.99063. lr 5.606250e-04:  33%|███▎      | 5385/16329 [45:21<1:30:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5385: train loss 1.99063. lr 5.606250e-04:  33%|███▎      | 5386/16329 [45:21<1:30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5386: train loss 2.00322. lr 5.606107e-04:  33%|███▎      | 5386/16329 [45:22<1:30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5386: train loss 2.00322. lr 5.606107e-04:  33%|███▎      | 5387/16329 [45:22<1:30:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5387: train loss 1.97271. lr 5.605964e-04:  33%|███▎      | 5387/16329 [45:22<1:30:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5387: train loss 1.97271. lr 5.605964e-04:  33%|███▎      | 5388/16329 [45:22<1:30:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5388: train loss 1.98689. lr 5.605821e-04:  33%|███▎      | 5388/16329 [45:23<1:30:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5388: train loss 1.98689. lr 5.605821e-04:  33%|███▎      | 5389/16329 [45:23<1:30:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5389: train loss 1.92292. lr 5.605678e-04:  33%|███▎      | 5389/16329 [45:23<1:30:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5389: train loss 1.92292. lr 5.605678e-04:  33%|███▎      | 5390/16329 [45:23<1:30:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5390: train loss 1.94401. lr 5.605535e-04:  33%|███▎      | 5390/16329 [45:24<1:30:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5390: train loss 1.94401. lr 5.605535e-04:  33%|███▎      | 5391/16329 [45:24<1:31:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5391: train loss 2.01271. lr 5.605392e-04:  33%|███▎      | 5391/16329 [45:24<1:31:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5391: train loss 2.01271. lr 5.605392e-04:  33%|███▎      | 5392/16329 [45:24<1:31:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5392: train loss 1.98946. lr 5.605249e-04:  33%|███▎      | 5392/16329 [45:25<1:31:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5392: train loss 1.98946. lr 5.605249e-04:  33%|███▎      | 5393/16329 [45:25<1:31:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5393: train loss 2.05033. lr 5.605106e-04:  33%|███▎      | 5393/16329 [45:25<1:31:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5393: train loss 2.05033. lr 5.605106e-04:  33%|███▎      | 5394/16329 [45:25<1:30:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5394: train loss 1.96565. lr 5.604962e-04:  33%|███▎      | 5394/16329 [45:26<1:30:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5394: train loss 1.96565. lr 5.604962e-04:  33%|███▎      | 5395/16329 [45:26<1:30:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5395: train loss 1.96855. lr 5.604819e-04:  33%|███▎      | 5395/16329 [45:26<1:30:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5395: train loss 1.96855. lr 5.604819e-04:  33%|███▎      | 5396/16329 [45:26<1:30:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5396: train loss 1.97057. lr 5.604676e-04:  33%|███▎      | 5396/16329 [45:27<1:30:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5396: train loss 1.97057. lr 5.604676e-04:  33%|███▎      | 5397/16329 [45:27<1:30:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5397: train loss 1.98063. lr 5.604533e-04:  33%|███▎      | 5397/16329 [45:27<1:30:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5397: train loss 1.98063. lr 5.604533e-04:  33%|███▎      | 5398/16329 [45:27<1:30:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5398: train loss 1.96265. lr 5.604390e-04:  33%|███▎      | 5398/16329 [45:28<1:30:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5398: train loss 1.96265. lr 5.604390e-04:  33%|███▎      | 5399/16329 [45:28<1:30:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5399: train loss 1.99800. lr 5.604246e-04:  33%|███▎      | 5399/16329 [45:28<1:30:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5399: train loss 1.99800. lr 5.604246e-04:  33%|███▎      | 5400/16329 [45:28<1:30:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5400: train loss 1.98201. lr 5.604103e-04:  33%|███▎      | 5400/16329 [45:29<1:30:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5400: train loss 1.98201. lr 5.604103e-04:  33%|███▎      | 5401/16329 [45:29<1:30:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5401: train loss 1.94261. lr 5.603960e-04:  33%|███▎      | 5401/16329 [45:29<1:30:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5401: train loss 1.94261. lr 5.603960e-04:  33%|███▎      | 5402/16329 [45:29<1:30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5402: train loss 1.98905. lr 5.603817e-04:  33%|███▎      | 5402/16329 [45:30<1:30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5402: train loss 1.98905. lr 5.603817e-04:  33%|███▎      | 5403/16329 [45:30<1:30:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5403: train loss 1.96601. lr 5.603673e-04:  33%|███▎      | 5403/16329 [45:30<1:30:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5403: train loss 1.96601. lr 5.603673e-04:  33%|███▎      | 5404/16329 [45:30<1:40:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5404: train loss 1.93826. lr 5.603530e-04:  33%|███▎      | 5404/16329 [45:31<1:40:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5404: train loss 1.93826. lr 5.603530e-04:  33%|███▎      | 5405/16329 [45:31<1:37:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5405: train loss 1.95254. lr 5.603386e-04:  33%|███▎      | 5405/16329 [45:31<1:37:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5405: train loss 1.95254. lr 5.603386e-04:  33%|███▎      | 5406/16329 [45:31<1:34:55,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5406: train loss 1.97237. lr 5.603243e-04:  33%|███▎      | 5406/16329 [45:32<1:34:55,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5406: train loss 1.97237. lr 5.603243e-04:  33%|███▎      | 5407/16329 [45:32<1:33:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5407: train loss 1.99121. lr 5.603100e-04:  33%|███▎      | 5407/16329 [45:32<1:33:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5407: train loss 1.99121. lr 5.603100e-04:  33%|███▎      | 5408/16329 [45:32<1:32:26,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5408: train loss 1.95375. lr 5.602956e-04:  33%|███▎      | 5408/16329 [45:33<1:32:26,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5408: train loss 1.95375. lr 5.602956e-04:  33%|███▎      | 5409/16329 [45:33<1:32:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5409: train loss 1.96230. lr 5.602813e-04:  33%|███▎      | 5409/16329 [45:33<1:32:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5409: train loss 1.96230. lr 5.602813e-04:  33%|███▎      | 5410/16329 [45:33<1:31:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5410: train loss 1.98226. lr 5.602669e-04:  33%|███▎      | 5410/16329 [45:34<1:31:28,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5410: train loss 1.98226. lr 5.602669e-04:  33%|███▎      | 5411/16329 [45:34<1:31:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5411: train loss 1.98255. lr 5.602525e-04:  33%|███▎      | 5411/16329 [45:34<1:31:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5411: train loss 1.98255. lr 5.602525e-04:  33%|███▎      | 5412/16329 [45:34<1:30:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5412: train loss 1.97899. lr 5.602382e-04:  33%|███▎      | 5412/16329 [45:35<1:30:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5412: train loss 1.97899. lr 5.602382e-04:  33%|███▎      | 5413/16329 [45:35<1:30:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5413: train loss 1.99703. lr 5.602238e-04:  33%|███▎      | 5413/16329 [45:35<1:30:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5413: train loss 1.99703. lr 5.602238e-04:  33%|███▎      | 5414/16329 [45:35<1:30:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5414: train loss 1.99210. lr 5.602095e-04:  33%|███▎      | 5414/16329 [45:36<1:30:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5414: train loss 1.99210. lr 5.602095e-04:  33%|███▎      | 5415/16329 [45:36<1:30:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5415: train loss 1.95899. lr 5.601951e-04:  33%|███▎      | 5415/16329 [45:36<1:30:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5415: train loss 1.95899. lr 5.601951e-04:  33%|███▎      | 5416/16329 [45:36<1:30:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5416: train loss 1.94374. lr 5.601807e-04:  33%|███▎      | 5416/16329 [45:37<1:30:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5416: train loss 1.94374. lr 5.601807e-04:  33%|███▎      | 5417/16329 [45:37<1:31:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5417: train loss 1.97019. lr 5.601664e-04:  33%|███▎      | 5417/16329 [45:37<1:31:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5417: train loss 1.97019. lr 5.601664e-04:  33%|███▎      | 5418/16329 [45:37<1:32:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5418: train loss 2.00453. lr 5.601520e-04:  33%|███▎      | 5418/16329 [45:38<1:32:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5418: train loss 2.00453. lr 5.601520e-04:  33%|███▎      | 5419/16329 [45:38<1:32:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5419: train loss 1.98104. lr 5.601376e-04:  33%|███▎      | 5419/16329 [45:38<1:32:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5419: train loss 1.98104. lr 5.601376e-04:  33%|███▎      | 5420/16329 [45:38<1:32:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5420: train loss 2.00570. lr 5.601232e-04:  33%|███▎      | 5420/16329 [45:39<1:32:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5420: train loss 2.00570. lr 5.601232e-04:  33%|███▎      | 5421/16329 [45:39<1:31:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5421: train loss 1.94030. lr 5.601089e-04:  33%|███▎      | 5421/16329 [45:39<1:31:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5421: train loss 1.94030. lr 5.601089e-04:  33%|███▎      | 5422/16329 [45:39<1:31:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5422: train loss 1.98505. lr 5.600945e-04:  33%|███▎      | 5422/16329 [45:40<1:31:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5422: train loss 1.98505. lr 5.600945e-04:  33%|███▎      | 5423/16329 [45:40<1:31:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5423: train loss 1.97421. lr 5.600801e-04:  33%|███▎      | 5423/16329 [45:40<1:31:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5423: train loss 1.97421. lr 5.600801e-04:  33%|███▎      | 5424/16329 [45:40<1:30:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5424: train loss 1.99053. lr 5.600657e-04:  33%|███▎      | 5424/16329 [45:41<1:30:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5424: train loss 1.99053. lr 5.600657e-04:  33%|███▎      | 5425/16329 [45:41<1:30:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5425: train loss 1.97961. lr 5.600513e-04:  33%|███▎      | 5425/16329 [45:41<1:30:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5425: train loss 1.97961. lr 5.600513e-04:  33%|███▎      | 5426/16329 [45:41<1:30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5426: train loss 1.94900. lr 5.600369e-04:  33%|███▎      | 5426/16329 [45:42<1:30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5426: train loss 1.94900. lr 5.600369e-04:  33%|███▎      | 5427/16329 [45:42<1:30:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5427: train loss 1.93940. lr 5.600225e-04:  33%|███▎      | 5427/16329 [45:42<1:30:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5427: train loss 1.93940. lr 5.600225e-04:  33%|███▎      | 5428/16329 [45:42<1:30:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5428: train loss 2.02155. lr 5.600082e-04:  33%|███▎      | 5428/16329 [45:43<1:30:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5428: train loss 2.02155. lr 5.600082e-04:  33%|███▎      | 5429/16329 [45:43<1:46:17,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 5429: train loss 1.96805. lr 5.599938e-04:  33%|███▎      | 5429/16329 [45:44<1:46:17,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 5429: train loss 1.96805. lr 5.599938e-04:  33%|███▎      | 5430/16329 [45:44<1:41:08,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5430: train loss 1.90931. lr 5.599794e-04:  33%|███▎      | 5430/16329 [45:44<1:41:08,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5430: train loss 1.90931. lr 5.599794e-04:  33%|███▎      | 5431/16329 [45:44<1:37:54,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5431: train loss 1.94109. lr 5.599650e-04:  33%|███▎      | 5431/16329 [45:45<1:37:54,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5431: train loss 1.94109. lr 5.599650e-04:  33%|███▎      | 5432/16329 [45:45<1:35:18,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5432: train loss 1.98508. lr 5.599505e-04:  33%|███▎      | 5432/16329 [45:45<1:35:18,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5432: train loss 1.98508. lr 5.599505e-04:  33%|███▎      | 5433/16329 [45:45<1:34:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5433: train loss 1.93428. lr 5.599361e-04:  33%|███▎      | 5433/16329 [45:46<1:34:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5433: train loss 1.93428. lr 5.599361e-04:  33%|███▎      | 5434/16329 [45:46<1:32:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5434: train loss 2.00357. lr 5.599217e-04:  33%|███▎      | 5434/16329 [45:46<1:32:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5434: train loss 2.00357. lr 5.599217e-04:  33%|███▎      | 5435/16329 [45:46<1:32:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5435: train loss 1.98406. lr 5.599073e-04:  33%|███▎      | 5435/16329 [45:47<1:32:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5435: train loss 1.98406. lr 5.599073e-04:  33%|███▎      | 5436/16329 [45:47<1:31:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5436: train loss 1.99525. lr 5.598929e-04:  33%|███▎      | 5436/16329 [45:47<1:31:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5436: train loss 1.99525. lr 5.598929e-04:  33%|███▎      | 5437/16329 [45:47<1:30:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5437: train loss 1.98846. lr 5.598785e-04:  33%|███▎      | 5437/16329 [45:48<1:30:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5437: train loss 1.98846. lr 5.598785e-04:  33%|███▎      | 5438/16329 [45:48<1:30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5438: train loss 1.98774. lr 5.598641e-04:  33%|███▎      | 5438/16329 [45:48<1:30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5438: train loss 1.98774. lr 5.598641e-04:  33%|███▎      | 5439/16329 [45:48<1:30:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5439: train loss 1.98149. lr 5.598496e-04:  33%|███▎      | 5439/16329 [45:49<1:30:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5439: train loss 1.98149. lr 5.598496e-04:  33%|███▎      | 5440/16329 [45:49<1:30:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5440: train loss 1.96008. lr 5.598352e-04:  33%|███▎      | 5440/16329 [45:49<1:30:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5440: train loss 1.96008. lr 5.598352e-04:  33%|███▎      | 5441/16329 [45:49<1:30:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5441: train loss 1.92093. lr 5.598208e-04:  33%|███▎      | 5441/16329 [45:50<1:30:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5441: train loss 1.92093. lr 5.598208e-04:  33%|███▎      | 5442/16329 [45:50<1:30:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5442: train loss 1.95727. lr 5.598064e-04:  33%|███▎      | 5442/16329 [45:50<1:30:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5442: train loss 1.95727. lr 5.598064e-04:  33%|███▎      | 5443/16329 [45:50<1:30:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5443: train loss 1.96571. lr 5.597919e-04:  33%|███▎      | 5443/16329 [45:51<1:30:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5443: train loss 1.96571. lr 5.597919e-04:  33%|███▎      | 5444/16329 [45:51<1:30:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5444: train loss 1.95727. lr 5.597775e-04:  33%|███▎      | 5444/16329 [45:51<1:30:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5444: train loss 1.95727. lr 5.597775e-04:  33%|███▎      | 5445/16329 [45:51<1:30:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5445: train loss 1.97604. lr 5.597631e-04:  33%|███▎      | 5445/16329 [45:52<1:30:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5445: train loss 1.97604. lr 5.597631e-04:  33%|███▎      | 5446/16329 [45:52<1:30:06,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5446: train loss 1.97256. lr 5.597486e-04:  33%|███▎      | 5446/16329 [45:52<1:30:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5446: train loss 1.97256. lr 5.597486e-04:  33%|███▎      | 5447/16329 [45:52<1:30:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5447: train loss 1.96672. lr 5.597342e-04:  33%|███▎      | 5447/16329 [45:53<1:30:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5447: train loss 1.96672. lr 5.597342e-04:  33%|███▎      | 5448/16329 [45:53<1:30:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5448: train loss 1.93513. lr 5.597197e-04:  33%|███▎      | 5448/16329 [45:53<1:30:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5448: train loss 1.93513. lr 5.597197e-04:  33%|███▎      | 5449/16329 [45:53<1:29:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5449: train loss 1.97049. lr 5.597053e-04:  33%|███▎      | 5449/16329 [45:54<1:29:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5449: train loss 1.97049. lr 5.597053e-04:  33%|███▎      | 5450/16329 [45:54<1:30:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5450: train loss 1.94919. lr 5.596908e-04:  33%|███▎      | 5450/16329 [45:54<1:30:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5450: train loss 1.94919. lr 5.596908e-04:  33%|███▎      | 5451/16329 [45:54<1:29:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5451: train loss 1.95001. lr 5.596764e-04:  33%|███▎      | 5451/16329 [45:55<1:29:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5451: train loss 1.95001. lr 5.596764e-04:  33%|███▎      | 5452/16329 [45:55<1:30:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5452: train loss 1.89065. lr 5.596619e-04:  33%|███▎      | 5452/16329 [45:55<1:30:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5452: train loss 1.89065. lr 5.596619e-04:  33%|███▎      | 5453/16329 [45:55<1:29:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5453: train loss 1.98762. lr 5.596475e-04:  33%|███▎      | 5453/16329 [45:55<1:29:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5453: train loss 1.98762. lr 5.596475e-04:  33%|███▎      | 5454/16329 [45:55<1:30:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5454: train loss 1.94828. lr 5.596330e-04:  33%|███▎      | 5454/16329 [45:56<1:30:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5454: train loss 1.94828. lr 5.596330e-04:  33%|███▎      | 5455/16329 [45:56<1:29:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5455: train loss 1.99079. lr 5.596186e-04:  33%|███▎      | 5455/16329 [45:57<1:29:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5455: train loss 1.99079. lr 5.596186e-04:  33%|███▎      | 5456/16329 [45:57<1:42:23,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5456: train loss 2.01377. lr 5.596041e-04:  33%|███▎      | 5456/16329 [45:57<1:42:23,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5456: train loss 2.01377. lr 5.596041e-04:  33%|███▎      | 5457/16329 [45:57<1:38:40,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 5457: train loss 1.94843. lr 5.595896e-04:  33%|███▎      | 5457/16329 [45:58<1:38:40,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 5457: train loss 1.94843. lr 5.595896e-04:  33%|███▎      | 5458/16329 [45:58<1:35:49,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5458: train loss 1.95285. lr 5.595752e-04:  33%|███▎      | 5458/16329 [45:58<1:35:49,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5458: train loss 1.95285. lr 5.595752e-04:  33%|███▎      | 5459/16329 [45:58<1:34:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5459: train loss 1.93032. lr 5.595607e-04:  33%|███▎      | 5459/16329 [45:59<1:34:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5459: train loss 1.93032. lr 5.595607e-04:  33%|███▎      | 5460/16329 [45:59<1:32:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5460: train loss 1.91085. lr 5.595462e-04:  33%|███▎      | 5460/16329 [45:59<1:32:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5460: train loss 1.91085. lr 5.595462e-04:  33%|███▎      | 5461/16329 [45:59<1:32:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5461: train loss 1.95181. lr 5.595318e-04:  33%|███▎      | 5461/16329 [46:00<1:32:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5461: train loss 1.95181. lr 5.595318e-04:  33%|███▎      | 5462/16329 [46:00<1:31:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5462: train loss 1.99386. lr 5.595173e-04:  33%|███▎      | 5462/16329 [46:00<1:31:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5462: train loss 1.99386. lr 5.595173e-04:  33%|███▎      | 5463/16329 [46:00<1:31:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5463: train loss 1.97185. lr 5.595028e-04:  33%|███▎      | 5463/16329 [46:01<1:31:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5463: train loss 1.97185. lr 5.595028e-04:  33%|███▎      | 5464/16329 [46:01<1:30:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5464: train loss 1.94314. lr 5.594883e-04:  33%|███▎      | 5464/16329 [46:01<1:30:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5464: train loss 1.94314. lr 5.594883e-04:  33%|███▎      | 5465/16329 [46:01<1:30:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5465: train loss 1.94097. lr 5.594738e-04:  33%|███▎      | 5465/16329 [46:02<1:30:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5465: train loss 1.94097. lr 5.594738e-04:  33%|███▎      | 5466/16329 [46:02<1:30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5466: train loss 1.89955. lr 5.594593e-04:  33%|███▎      | 5466/16329 [46:02<1:30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5466: train loss 1.89955. lr 5.594593e-04:  33%|███▎      | 5467/16329 [46:02<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5467: train loss 1.95434. lr 5.594449e-04:  33%|███▎      | 5467/16329 [46:03<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5467: train loss 1.95434. lr 5.594449e-04:  33%|███▎      | 5468/16329 [46:03<1:30:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5468: train loss 1.98631. lr 5.594304e-04:  33%|███▎      | 5468/16329 [46:03<1:30:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5468: train loss 1.98631. lr 5.594304e-04:  33%|███▎      | 5469/16329 [46:03<1:29:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5469: train loss 1.95197. lr 5.594159e-04:  33%|███▎      | 5469/16329 [46:04<1:29:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5469: train loss 1.95197. lr 5.594159e-04:  33%|███▎      | 5470/16329 [46:04<1:29:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5470: train loss 1.98358. lr 5.594014e-04:  33%|███▎      | 5470/16329 [46:04<1:29:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5470: train loss 1.98358. lr 5.594014e-04:  34%|███▎      | 5471/16329 [46:04<1:29:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5471: train loss 1.94568. lr 5.593869e-04:  34%|███▎      | 5471/16329 [46:05<1:29:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5471: train loss 1.94568. lr 5.593869e-04:  34%|███▎      | 5472/16329 [46:05<1:29:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5472: train loss 1.93669. lr 5.593724e-04:  34%|███▎      | 5472/16329 [46:05<1:29:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5472: train loss 1.93669. lr 5.593724e-04:  34%|███▎      | 5473/16329 [46:05<1:29:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5473: train loss 1.99964. lr 5.593579e-04:  34%|███▎      | 5473/16329 [46:06<1:29:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5473: train loss 1.99964. lr 5.593579e-04:  34%|███▎      | 5474/16329 [46:06<1:29:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5474: train loss 1.94829. lr 5.593434e-04:  34%|███▎      | 5474/16329 [46:06<1:29:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5474: train loss 1.94829. lr 5.593434e-04:  34%|███▎      | 5475/16329 [46:06<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5475: train loss 1.93626. lr 5.593289e-04:  34%|███▎      | 5475/16329 [46:07<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5475: train loss 1.93626. lr 5.593289e-04:  34%|███▎      | 5476/16329 [46:07<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5476: train loss 1.92910. lr 5.593143e-04:  34%|███▎      | 5476/16329 [46:07<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5476: train loss 1.92910. lr 5.593143e-04:  34%|███▎      | 5477/16329 [46:07<1:29:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5477: train loss 1.93420. lr 5.592998e-04:  34%|███▎      | 5477/16329 [46:08<1:29:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5477: train loss 1.93420. lr 5.592998e-04:  34%|███▎      | 5478/16329 [46:08<1:29:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5478: train loss 1.94282. lr 5.592853e-04:  34%|███▎      | 5478/16329 [46:08<1:29:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5478: train loss 1.94282. lr 5.592853e-04:  34%|███▎      | 5479/16329 [46:08<1:29:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5479: train loss 1.92849. lr 5.592708e-04:  34%|███▎      | 5479/16329 [46:09<1:29:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5479: train loss 1.92849. lr 5.592708e-04:  34%|███▎      | 5480/16329 [46:09<1:29:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5480: train loss 1.95115. lr 5.592563e-04:  34%|███▎      | 5480/16329 [46:09<1:29:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5480: train loss 1.95115. lr 5.592563e-04:  34%|███▎      | 5481/16329 [46:09<1:30:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5481: train loss 1.96383. lr 5.592418e-04:  34%|███▎      | 5481/16329 [46:10<1:30:45,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5481: train loss 1.96383. lr 5.592418e-04:  34%|███▎      | 5482/16329 [46:10<1:31:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5482: train loss 1.95485. lr 5.592272e-04:  34%|███▎      | 5482/16329 [46:10<1:31:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5482: train loss 1.95485. lr 5.592272e-04:  34%|███▎      | 5483/16329 [46:10<1:31:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5483: train loss 1.97255. lr 5.592127e-04:  34%|███▎      | 5483/16329 [46:11<1:31:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5483: train loss 1.97255. lr 5.592127e-04:  34%|███▎      | 5484/16329 [46:11<1:31:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5484: train loss 1.93337. lr 5.591982e-04:  34%|███▎      | 5484/16329 [46:11<1:31:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5484: train loss 1.93337. lr 5.591982e-04:  34%|███▎      | 5485/16329 [46:11<1:30:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5485: train loss 1.94313. lr 5.591836e-04:  34%|███▎      | 5485/16329 [46:12<1:30:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5485: train loss 1.94313. lr 5.591836e-04:  34%|███▎      | 5486/16329 [46:12<1:30:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5486: train loss 1.98712. lr 5.591691e-04:  34%|███▎      | 5486/16329 [46:12<1:30:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5486: train loss 1.98712. lr 5.591691e-04:  34%|███▎      | 5487/16329 [46:12<1:30:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5487: train loss 1.95381. lr 5.591546e-04:  34%|███▎      | 5487/16329 [46:13<1:30:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5487: train loss 1.95381. lr 5.591546e-04:  34%|███▎      | 5488/16329 [46:13<1:29:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5488: train loss 1.94945. lr 5.591400e-04:  34%|███▎      | 5488/16329 [46:13<1:29:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5488: train loss 1.94945. lr 5.591400e-04:  34%|███▎      | 5489/16329 [46:13<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5489: train loss 1.86602. lr 5.591255e-04:  34%|███▎      | 5489/16329 [46:14<1:29:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5489: train loss 1.86602. lr 5.591255e-04:  34%|███▎      | 5490/16329 [46:14<1:30:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5490: train loss 1.93517. lr 5.591109e-04:  34%|███▎      | 5490/16329 [46:14<1:30:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5490: train loss 1.93517. lr 5.591109e-04:  34%|███▎      | 5491/16329 [46:14<1:29:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5491: train loss 2.00718. lr 5.590964e-04:  34%|███▎      | 5491/16329 [46:15<1:29:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5491: train loss 2.00718. lr 5.590964e-04:  34%|███▎      | 5492/16329 [46:15<1:29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5492: train loss 1.90913. lr 5.590818e-04:  34%|███▎      | 5492/16329 [46:15<1:29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5492: train loss 1.90913. lr 5.590818e-04:  34%|███▎      | 5493/16329 [46:15<1:29:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5493: train loss 1.98633. lr 5.590673e-04:  34%|███▎      | 5493/16329 [46:16<1:29:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5493: train loss 1.98633. lr 5.590673e-04:  34%|███▎      | 5494/16329 [46:16<1:29:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5494: train loss 1.93818. lr 5.590527e-04:  34%|███▎      | 5494/16329 [46:16<1:29:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5494: train loss 1.93818. lr 5.590527e-04:  34%|███▎      | 5495/16329 [46:16<1:29:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5495: train loss 1.92353. lr 5.590382e-04:  34%|███▎      | 5495/16329 [46:17<1:29:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5495: train loss 1.92353. lr 5.590382e-04:  34%|███▎      | 5496/16329 [46:17<1:39:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5496: train loss 1.98111. lr 5.590236e-04:  34%|███▎      | 5496/16329 [46:17<1:39:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5496: train loss 1.98111. lr 5.590236e-04:  34%|███▎      | 5497/16329 [46:17<1:36:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5497: train loss 1.99733. lr 5.590091e-04:  34%|███▎      | 5497/16329 [46:18<1:36:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5497: train loss 1.99733. lr 5.590091e-04:  34%|███▎      | 5498/16329 [46:18<1:33:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5498: train loss 1.93451. lr 5.589945e-04:  34%|███▎      | 5498/16329 [46:18<1:33:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5498: train loss 1.93451. lr 5.589945e-04:  34%|███▎      | 5499/16329 [46:18<1:32:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5499: train loss 1.93334. lr 5.589799e-04:  34%|███▎      | 5499/16329 [46:19<1:32:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5499: train loss 1.93334. lr 5.589799e-04:  34%|███▎      | 5500/16329 [46:19<1:31:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5500: train loss 1.84895. lr 5.589654e-04:  34%|███▎      | 5500/16329 [46:19<1:31:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5500: train loss 1.84895. lr 5.589654e-04:  34%|███▎      | 5501/16329 [46:19<1:31:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5501: train loss 1.88533. lr 5.589508e-04:  34%|███▎      | 5501/16329 [46:20<1:31:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5501: train loss 1.88533. lr 5.589508e-04:  34%|███▎      | 5502/16329 [46:20<1:30:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5502: train loss 1.96372. lr 5.589362e-04:  34%|███▎      | 5502/16329 [46:20<1:30:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5502: train loss 1.96372. lr 5.589362e-04:  34%|███▎      | 5503/16329 [46:20<1:30:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5503: train loss 1.99286. lr 5.589216e-04:  34%|███▎      | 5503/16329 [46:21<1:30:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5503: train loss 1.99286. lr 5.589216e-04:  34%|███▎      | 5504/16329 [46:21<1:29:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5504: train loss 1.91068. lr 5.589071e-04:  34%|███▎      | 5504/16329 [46:21<1:29:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5504: train loss 1.91068. lr 5.589071e-04:  34%|███▎      | 5505/16329 [46:21<1:29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5505: train loss 1.92739. lr 5.588925e-04:  34%|███▎      | 5505/16329 [46:22<1:29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5505: train loss 1.92739. lr 5.588925e-04:  34%|███▎      | 5506/16329 [46:22<1:29:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5506: train loss 1.97398. lr 5.588779e-04:  34%|███▎      | 5506/16329 [46:22<1:29:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5506: train loss 1.97398. lr 5.588779e-04:  34%|███▎      | 5507/16329 [46:22<1:29:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5507: train loss 1.92839. lr 5.588633e-04:  34%|███▎      | 5507/16329 [46:23<1:29:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5507: train loss 1.92839. lr 5.588633e-04:  34%|███▎      | 5508/16329 [46:23<1:29:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5508: train loss 1.92493. lr 5.588487e-04:  34%|███▎      | 5508/16329 [46:23<1:29:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5508: train loss 1.92493. lr 5.588487e-04:  34%|███▎      | 5509/16329 [46:23<1:29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5509: train loss 1.98808. lr 5.588341e-04:  34%|███▎      | 5509/16329 [46:24<1:29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5509: train loss 1.98808. lr 5.588341e-04:  34%|███▎      | 5510/16329 [46:24<1:29:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5510: train loss 1.94850. lr 5.588195e-04:  34%|███▎      | 5510/16329 [46:24<1:29:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5510: train loss 1.94850. lr 5.588195e-04:  34%|███▎      | 5511/16329 [46:24<1:29:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5511: train loss 1.93508. lr 5.588050e-04:  34%|███▎      | 5511/16329 [46:25<1:29:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5511: train loss 1.93508. lr 5.588050e-04:  34%|███▍      | 5512/16329 [46:25<1:29:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5512: train loss 1.96123. lr 5.587904e-04:  34%|███▍      | 5512/16329 [46:25<1:29:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5512: train loss 1.96123. lr 5.587904e-04:  34%|███▍      | 5513/16329 [46:25<1:29:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5513: train loss 1.96252. lr 5.587758e-04:  34%|███▍      | 5513/16329 [46:26<1:29:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5513: train loss 1.96252. lr 5.587758e-04:  34%|███▍      | 5514/16329 [46:26<1:29:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5514: train loss 1.93342. lr 5.587612e-04:  34%|███▍      | 5514/16329 [46:26<1:29:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5514: train loss 1.93342. lr 5.587612e-04:  34%|███▍      | 5515/16329 [46:26<1:29:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5515: train loss 1.88906. lr 5.587465e-04:  34%|███▍      | 5515/16329 [46:27<1:29:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5515: train loss 1.88906. lr 5.587465e-04:  34%|███▍      | 5516/16329 [46:27<1:29:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5516: train loss 1.94815. lr 5.587319e-04:  34%|███▍      | 5516/16329 [46:27<1:29:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5516: train loss 1.94815. lr 5.587319e-04:  34%|███▍      | 5517/16329 [46:27<1:29:32,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5517: train loss 1.99713. lr 5.587173e-04:  34%|███▍      | 5517/16329 [46:28<1:29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5517: train loss 1.99713. lr 5.587173e-04:  34%|███▍      | 5518/16329 [46:28<1:29:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5518: train loss 1.97784. lr 5.587027e-04:  34%|███▍      | 5518/16329 [46:28<1:29:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5518: train loss 1.97784. lr 5.587027e-04:  34%|███▍      | 5519/16329 [46:28<1:29:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5519: train loss 1.97082. lr 5.586881e-04:  34%|███▍      | 5519/16329 [46:29<1:29:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5519: train loss 1.97082. lr 5.586881e-04:  34%|███▍      | 5520/16329 [46:29<1:29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5520: train loss 1.97468. lr 5.586735e-04:  34%|███▍      | 5520/16329 [46:29<1:29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5520: train loss 1.97468. lr 5.586735e-04:  34%|███▍      | 5521/16329 [46:29<1:29:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5521: train loss 1.93353. lr 5.586589e-04:  34%|███▍      | 5521/16329 [46:30<1:29:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5521: train loss 1.93353. lr 5.586589e-04:  34%|███▍      | 5522/16329 [46:30<1:29:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5522: train loss 1.94307. lr 5.586443e-04:  34%|███▍      | 5522/16329 [46:30<1:29:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5522: train loss 1.94307. lr 5.586443e-04:  34%|███▍      | 5523/16329 [46:30<1:29:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5523: train loss 1.95488. lr 5.586296e-04:  34%|███▍      | 5523/16329 [46:31<1:29:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5523: train loss 1.95488. lr 5.586296e-04:  34%|███▍      | 5524/16329 [46:31<1:29:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5524: train loss 2.01240. lr 5.586150e-04:  34%|███▍      | 5524/16329 [46:31<1:29:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5524: train loss 2.01240. lr 5.586150e-04:  34%|███▍      | 5525/16329 [46:31<1:29:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5525: train loss 1.97446. lr 5.586004e-04:  34%|███▍      | 5525/16329 [46:32<1:29:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5525: train loss 1.97446. lr 5.586004e-04:  34%|███▍      | 5526/16329 [46:32<1:28:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5526: train loss 1.93191. lr 5.585857e-04:  34%|███▍      | 5526/16329 [46:32<1:28:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5526: train loss 1.93191. lr 5.585857e-04:  34%|███▍      | 5527/16329 [46:32<1:29:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5527: train loss 1.95936. lr 5.585711e-04:  34%|███▍      | 5527/16329 [46:33<1:29:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5527: train loss 1.95936. lr 5.585711e-04:  34%|███▍      | 5528/16329 [46:33<1:29:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5528: train loss 1.94837. lr 5.585565e-04:  34%|███▍      | 5528/16329 [46:33<1:29:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5528: train loss 1.94837. lr 5.585565e-04:  34%|███▍      | 5529/16329 [46:33<1:29:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5529: train loss 2.00349. lr 5.585418e-04:  34%|███▍      | 5529/16329 [46:34<1:29:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5529: train loss 2.00349. lr 5.585418e-04:  34%|███▍      | 5530/16329 [46:34<1:29:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5530: train loss 1.91239. lr 5.585272e-04:  34%|███▍      | 5530/16329 [46:34<1:29:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5530: train loss 1.91239. lr 5.585272e-04:  34%|███▍      | 5531/16329 [46:34<1:38:35,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5531: train loss 1.91836. lr 5.585126e-04:  34%|███▍      | 5531/16329 [46:35<1:38:35,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5531: train loss 1.91836. lr 5.585126e-04:  34%|███▍      | 5532/16329 [46:35<1:35:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5532: train loss 1.95972. lr 5.584979e-04:  34%|███▍      | 5532/16329 [46:35<1:35:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5532: train loss 1.95972. lr 5.584979e-04:  34%|███▍      | 5533/16329 [46:35<1:33:51,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5533: train loss 1.94643. lr 5.584833e-04:  34%|███▍      | 5533/16329 [46:36<1:33:51,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5533: train loss 1.94643. lr 5.584833e-04:  34%|███▍      | 5534/16329 [46:36<1:32:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5534: train loss 1.95540. lr 5.584686e-04:  34%|███▍      | 5534/16329 [46:36<1:32:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5534: train loss 1.95540. lr 5.584686e-04:  34%|███▍      | 5535/16329 [46:36<1:31:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5535: train loss 1.95806. lr 5.584540e-04:  34%|███▍      | 5535/16329 [46:37<1:31:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5535: train loss 1.95806. lr 5.584540e-04:  34%|███▍      | 5536/16329 [46:37<1:30:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5536: train loss 1.96107. lr 5.584393e-04:  34%|███▍      | 5536/16329 [46:37<1:30:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5536: train loss 1.96107. lr 5.584393e-04:  34%|███▍      | 5537/16329 [46:37<1:30:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5537: train loss 1.92644. lr 5.584246e-04:  34%|███▍      | 5537/16329 [46:38<1:30:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5537: train loss 1.92644. lr 5.584246e-04:  34%|███▍      | 5538/16329 [46:38<1:29:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5538: train loss 1.91974. lr 5.584100e-04:  34%|███▍      | 5538/16329 [46:38<1:29:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5538: train loss 1.91974. lr 5.584100e-04:  34%|███▍      | 5539/16329 [46:38<1:29:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5539: train loss 1.92772. lr 5.583953e-04:  34%|███▍      | 5539/16329 [46:39<1:29:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5539: train loss 1.92772. lr 5.583953e-04:  34%|███▍      | 5540/16329 [46:39<1:29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5540: train loss 1.94284. lr 5.583807e-04:  34%|███▍      | 5540/16329 [46:39<1:29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5540: train loss 1.94284. lr 5.583807e-04:  34%|███▍      | 5541/16329 [46:39<1:29:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5541: train loss 1.90291. lr 5.583660e-04:  34%|███▍      | 5541/16329 [46:40<1:29:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5541: train loss 1.90291. lr 5.583660e-04:  34%|███▍      | 5542/16329 [46:40<1:29:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5542: train loss 1.92036. lr 5.583513e-04:  34%|███▍      | 5542/16329 [46:40<1:29:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5542: train loss 1.92036. lr 5.583513e-04:  34%|███▍      | 5543/16329 [46:40<1:29:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5543: train loss 1.94673. lr 5.583367e-04:  34%|███▍      | 5543/16329 [46:41<1:29:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5543: train loss 1.94673. lr 5.583367e-04:  34%|███▍      | 5544/16329 [46:41<1:29:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5544: train loss 1.93116. lr 5.583220e-04:  34%|███▍      | 5544/16329 [46:41<1:29:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5544: train loss 1.93116. lr 5.583220e-04:  34%|███▍      | 5545/16329 [46:41<1:29:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5545: train loss 2.00590. lr 5.583073e-04:  34%|███▍      | 5545/16329 [46:42<1:29:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5545: train loss 2.00590. lr 5.583073e-04:  34%|███▍      | 5546/16329 [46:42<1:29:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5546: train loss 1.93200. lr 5.582926e-04:  34%|███▍      | 5546/16329 [46:42<1:29:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5546: train loss 1.93200. lr 5.582926e-04:  34%|███▍      | 5547/16329 [46:42<1:29:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5547: train loss 1.95105. lr 5.582779e-04:  34%|███▍      | 5547/16329 [46:43<1:29:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5547: train loss 1.95105. lr 5.582779e-04:  34%|███▍      | 5548/16329 [46:43<1:29:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5548: train loss 2.01771. lr 5.582633e-04:  34%|███▍      | 5548/16329 [46:43<1:29:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5548: train loss 2.01771. lr 5.582633e-04:  34%|███▍      | 5549/16329 [46:43<1:29:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5549: train loss 1.95242. lr 5.582486e-04:  34%|███▍      | 5549/16329 [46:44<1:29:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5549: train loss 1.95242. lr 5.582486e-04:  34%|███▍      | 5550/16329 [46:44<1:28:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5550: train loss 1.98929. lr 5.582339e-04:  34%|███▍      | 5550/16329 [46:44<1:28:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5550: train loss 1.98929. lr 5.582339e-04:  34%|███▍      | 5551/16329 [46:44<1:29:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5551: train loss 1.95500. lr 5.582192e-04:  34%|███▍      | 5551/16329 [46:45<1:29:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5551: train loss 1.95500. lr 5.582192e-04:  34%|███▍      | 5552/16329 [46:45<1:29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5552: train loss 1.93150. lr 5.582045e-04:  34%|███▍      | 5552/16329 [46:45<1:29:03,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5552: train loss 1.93150. lr 5.582045e-04:  34%|███▍      | 5553/16329 [46:45<1:28:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5553: train loss 1.98277. lr 5.581898e-04:  34%|███▍      | 5553/16329 [46:46<1:28:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5553: train loss 1.98277. lr 5.581898e-04:  34%|███▍      | 5554/16329 [46:46<1:29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5554: train loss 1.99680. lr 5.581751e-04:  34%|███▍      | 5554/16329 [46:46<1:29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5554: train loss 1.99680. lr 5.581751e-04:  34%|███▍      | 5555/16329 [46:46<1:28:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5555: train loss 1.95811. lr 5.581604e-04:  34%|███▍      | 5555/16329 [46:47<1:28:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5555: train loss 1.95811. lr 5.581604e-04:  34%|███▍      | 5556/16329 [46:47<1:44:29,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 5556: train loss 1.90496. lr 5.581457e-04:  34%|███▍      | 5556/16329 [46:48<1:44:29,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 5556: train loss 1.90496. lr 5.581457e-04:  34%|███▍      | 5557/16329 [46:48<1:39:52,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5557: train loss 1.90123. lr 5.581310e-04:  34%|███▍      | 5557/16329 [46:48<1:39:52,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5557: train loss 1.90123. lr 5.581310e-04:  34%|███▍      | 5558/16329 [46:48<1:36:31,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5558: train loss 1.94237. lr 5.581163e-04:  34%|███▍      | 5558/16329 [46:48<1:36:31,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5558: train loss 1.94237. lr 5.581163e-04:  34%|███▍      | 5559/16329 [46:48<1:34:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5559: train loss 1.96760. lr 5.581016e-04:  34%|███▍      | 5559/16329 [46:49<1:34:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5559: train loss 1.96760. lr 5.581016e-04:  34%|███▍      | 5560/16329 [46:49<1:32:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5560: train loss 1.91888. lr 5.580869e-04:  34%|███▍      | 5560/16329 [46:49<1:32:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5560: train loss 1.91888. lr 5.580869e-04:  34%|███▍      | 5561/16329 [46:49<1:31:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5561: train loss 1.90378. lr 5.580722e-04:  34%|███▍      | 5561/16329 [46:50<1:31:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5561: train loss 1.90378. lr 5.580722e-04:  34%|███▍      | 5562/16329 [46:50<1:30:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5562: train loss 1.90747. lr 5.580574e-04:  34%|███▍      | 5562/16329 [46:50<1:30:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5562: train loss 1.90747. lr 5.580574e-04:  34%|███▍      | 5563/16329 [46:50<1:30:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5563: train loss 1.92511. lr 5.580427e-04:  34%|███▍      | 5563/16329 [46:51<1:30:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5563: train loss 1.92511. lr 5.580427e-04:  34%|███▍      | 5564/16329 [46:51<1:29:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5564: train loss 1.95067. lr 5.580280e-04:  34%|███▍      | 5564/16329 [46:51<1:29:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5564: train loss 1.95067. lr 5.580280e-04:  34%|███▍      | 5565/16329 [46:51<1:29:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5565: train loss 1.95214. lr 5.580133e-04:  34%|███▍      | 5565/16329 [46:52<1:29:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5565: train loss 1.95214. lr 5.580133e-04:  34%|███▍      | 5566/16329 [46:52<1:29:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5566: train loss 1.93301. lr 5.579986e-04:  34%|███▍      | 5566/16329 [46:52<1:29:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5566: train loss 1.93301. lr 5.579986e-04:  34%|███▍      | 5567/16329 [46:52<1:29:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5567: train loss 2.00660. lr 5.579838e-04:  34%|███▍      | 5567/16329 [46:53<1:29:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5567: train loss 2.00660. lr 5.579838e-04:  34%|███▍      | 5568/16329 [46:53<1:29:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5568: train loss 1.98208. lr 5.579691e-04:  34%|███▍      | 5568/16329 [46:53<1:29:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5568: train loss 1.98208. lr 5.579691e-04:  34%|███▍      | 5569/16329 [46:53<1:29:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5569: train loss 1.91578. lr 5.579544e-04:  34%|███▍      | 5569/16329 [46:54<1:29:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5569: train loss 1.91578. lr 5.579544e-04:  34%|███▍      | 5570/16329 [46:54<1:29:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5570: train loss 1.96233. lr 5.579396e-04:  34%|███▍      | 5570/16329 [46:54<1:29:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5570: train loss 1.96233. lr 5.579396e-04:  34%|███▍      | 5571/16329 [46:54<1:29:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5571: train loss 1.98953. lr 5.579249e-04:  34%|███▍      | 5571/16329 [46:55<1:29:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5571: train loss 1.98953. lr 5.579249e-04:  34%|███▍      | 5572/16329 [46:55<1:29:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5572: train loss 1.89210. lr 5.579101e-04:  34%|███▍      | 5572/16329 [46:55<1:29:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5572: train loss 1.89210. lr 5.579101e-04:  34%|███▍      | 5573/16329 [46:55<1:28:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5573: train loss 1.93242. lr 5.578954e-04:  34%|███▍      | 5573/16329 [46:56<1:28:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5573: train loss 1.93242. lr 5.578954e-04:  34%|███▍      | 5574/16329 [46:56<1:29:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5574: train loss 1.94284. lr 5.578807e-04:  34%|███▍      | 5574/16329 [46:56<1:29:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5574: train loss 1.94284. lr 5.578807e-04:  34%|███▍      | 5575/16329 [46:56<1:28:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5575: train loss 1.91663. lr 5.578659e-04:  34%|███▍      | 5575/16329 [46:57<1:28:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5575: train loss 1.91663. lr 5.578659e-04:  34%|███▍      | 5576/16329 [46:57<1:29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5576: train loss 1.91530. lr 5.578512e-04:  34%|███▍      | 5576/16329 [46:57<1:29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5576: train loss 1.91530. lr 5.578512e-04:  34%|███▍      | 5577/16329 [46:57<1:29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5577: train loss 1.93887. lr 5.578364e-04:  34%|███▍      | 5577/16329 [46:58<1:29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5577: train loss 1.93887. lr 5.578364e-04:  34%|███▍      | 5578/16329 [46:58<1:28:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5578: train loss 1.93806. lr 5.578217e-04:  34%|███▍      | 5578/16329 [46:58<1:28:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5578: train loss 1.93806. lr 5.578217e-04:  34%|███▍      | 5579/16329 [46:58<1:29:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5579: train loss 1.95316. lr 5.578069e-04:  34%|███▍      | 5579/16329 [46:59<1:29:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5579: train loss 1.95316. lr 5.578069e-04:  34%|███▍      | 5580/16329 [46:59<1:28:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5580: train loss 1.93356. lr 5.577921e-04:  34%|███▍      | 5580/16329 [46:59<1:28:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5580: train loss 1.93356. lr 5.577921e-04:  34%|███▍      | 5581/16329 [46:59<1:29:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5581: train loss 2.03898. lr 5.577774e-04:  34%|███▍      | 5581/16329 [47:00<1:29:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5581: train loss 2.03898. lr 5.577774e-04:  34%|███▍      | 5582/16329 [47:00<1:28:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5582: train loss 1.91044. lr 5.577626e-04:  34%|███▍      | 5582/16329 [47:01<1:28:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5582: train loss 1.91044. lr 5.577626e-04:  34%|███▍      | 5583/16329 [47:01<1:41:21,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5583: train loss 1.87833. lr 5.577478e-04:  34%|███▍      | 5583/16329 [47:01<1:41:21,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 5583: train loss 1.87833. lr 5.577478e-04:  34%|███▍      | 5584/16329 [47:01<1:37:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5584: train loss 1.92205. lr 5.577331e-04:  34%|███▍      | 5584/16329 [47:02<1:37:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5584: train loss 1.92205. lr 5.577331e-04:  34%|███▍      | 5585/16329 [47:02<1:34:56,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5585: train loss 1.87933. lr 5.577183e-04:  34%|███▍      | 5585/16329 [47:02<1:34:56,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5585: train loss 1.87933. lr 5.577183e-04:  34%|███▍      | 5586/16329 [47:02<1:33:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5586: train loss 1.97386. lr 5.577035e-04:  34%|███▍      | 5586/16329 [47:03<1:33:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5586: train loss 1.97386. lr 5.577035e-04:  34%|███▍      | 5587/16329 [47:03<1:32:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5587: train loss 1.96609. lr 5.576888e-04:  34%|███▍      | 5587/16329 [47:03<1:32:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5587: train loss 1.96609. lr 5.576888e-04:  34%|███▍      | 5588/16329 [47:03<1:35:16,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5588: train loss 1.93770. lr 5.576740e-04:  34%|███▍      | 5588/16329 [47:04<1:35:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5588: train loss 1.93770. lr 5.576740e-04:  34%|███▍      | 5589/16329 [47:04<1:36:57,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 5589: train loss 1.90449. lr 5.576592e-04:  34%|███▍      | 5589/16329 [47:04<1:36:57,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 5589: train loss 1.90449. lr 5.576592e-04:  34%|███▍      | 5590/16329 [47:04<1:37:18,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 5590: train loss 1.99884. lr 5.576444e-04:  34%|███▍      | 5590/16329 [47:05<1:37:18,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 5590: train loss 1.99884. lr 5.576444e-04:  34%|███▍      | 5591/16329 [47:05<1:36:49,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 5591: train loss 1.93860. lr 5.576296e-04:  34%|███▍      | 5591/16329 [47:05<1:36:49,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 5591: train loss 1.93860. lr 5.576296e-04:  34%|███▍      | 5592/16329 [47:05<1:35:49,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5592: train loss 1.97351. lr 5.576148e-04:  34%|███▍      | 5592/16329 [47:06<1:35:49,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5592: train loss 1.97351. lr 5.576148e-04:  34%|███▍      | 5593/16329 [47:06<1:34:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5593: train loss 1.93075. lr 5.576000e-04:  34%|███▍      | 5593/16329 [47:06<1:34:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5593: train loss 1.93075. lr 5.576000e-04:  34%|███▍      | 5594/16329 [47:06<1:33:48,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5594: train loss 1.90877. lr 5.575852e-04:  34%|███▍      | 5594/16329 [47:07<1:33:48,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5594: train loss 1.90877. lr 5.575852e-04:  34%|███▍      | 5595/16329 [47:07<1:32:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5595: train loss 1.96367. lr 5.575705e-04:  34%|███▍      | 5595/16329 [47:07<1:32:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5595: train loss 1.96367. lr 5.575705e-04:  34%|███▍      | 5596/16329 [47:07<1:32:06,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5596: train loss 1.91902. lr 5.575557e-04:  34%|███▍      | 5596/16329 [47:08<1:32:06,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5596: train loss 1.91902. lr 5.575557e-04:  34%|███▍      | 5597/16329 [47:08<1:30:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5597: train loss 1.95490. lr 5.575409e-04:  34%|███▍      | 5597/16329 [47:08<1:30:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5597: train loss 1.95490. lr 5.575409e-04:  34%|███▍      | 5598/16329 [47:08<1:30:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5598: train loss 1.97126. lr 5.575261e-04:  34%|███▍      | 5598/16329 [47:09<1:30:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5598: train loss 1.97126. lr 5.575261e-04:  34%|███▍      | 5599/16329 [47:09<1:29:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5599: train loss 1.93104. lr 5.575112e-04:  34%|███▍      | 5599/16329 [47:09<1:29:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5599: train loss 1.93104. lr 5.575112e-04:  34%|███▍      | 5600/16329 [47:09<1:29:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5600: train loss 1.95282. lr 5.574964e-04:  34%|███▍      | 5600/16329 [47:10<1:29:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5600: train loss 1.95282. lr 5.574964e-04:  34%|███▍      | 5601/16329 [47:10<1:28:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5601: train loss 1.85638. lr 5.574816e-04:  34%|███▍      | 5601/16329 [47:10<1:28:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5601: train loss 1.85638. lr 5.574816e-04:  34%|███▍      | 5602/16329 [47:10<1:28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5602: train loss 1.90593. lr 5.574668e-04:  34%|███▍      | 5602/16329 [47:11<1:28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5602: train loss 1.90593. lr 5.574668e-04:  34%|███▍      | 5603/16329 [47:11<1:29:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5603: train loss 1.97205. lr 5.574520e-04:  34%|███▍      | 5603/16329 [47:11<1:29:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5603: train loss 1.97205. lr 5.574520e-04:  34%|███▍      | 5604/16329 [47:11<1:28:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5604: train loss 1.92319. lr 5.574372e-04:  34%|███▍      | 5604/16329 [47:12<1:28:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5604: train loss 1.92319. lr 5.574372e-04:  34%|███▍      | 5605/16329 [47:12<1:28:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5605: train loss 1.93114. lr 5.574224e-04:  34%|███▍      | 5605/16329 [47:12<1:28:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5605: train loss 1.93114. lr 5.574224e-04:  34%|███▍      | 5606/16329 [47:12<1:28:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5606: train loss 1.90139. lr 5.574075e-04:  34%|███▍      | 5606/16329 [47:13<1:28:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5606: train loss 1.90139. lr 5.574075e-04:  34%|███▍      | 5607/16329 [47:13<1:28:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5607: train loss 1.90745. lr 5.573927e-04:  34%|███▍      | 5607/16329 [47:13<1:28:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5607: train loss 1.90745. lr 5.573927e-04:  34%|███▍      | 5608/16329 [47:13<1:28:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5608: train loss 1.94986. lr 5.573779e-04:  34%|███▍      | 5608/16329 [47:14<1:28:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5608: train loss 1.94986. lr 5.573779e-04:  34%|███▍      | 5609/16329 [47:14<1:28:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5609: train loss 1.93929. lr 5.573631e-04:  34%|███▍      | 5609/16329 [47:14<1:28:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5609: train loss 1.93929. lr 5.573631e-04:  34%|███▍      | 5610/16329 [47:14<1:28:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5610: train loss 1.95179. lr 5.573482e-04:  34%|███▍      | 5610/16329 [47:15<1:28:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5610: train loss 1.95179. lr 5.573482e-04:  34%|███▍      | 5611/16329 [47:15<1:28:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5611: train loss 1.97488. lr 5.573334e-04:  34%|███▍      | 5611/16329 [47:15<1:28:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5611: train loss 1.97488. lr 5.573334e-04:  34%|███▍      | 5612/16329 [47:15<1:28:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5612: train loss 1.93381. lr 5.573186e-04:  34%|███▍      | 5612/16329 [47:16<1:28:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5612: train loss 1.93381. lr 5.573186e-04:  34%|███▍      | 5613/16329 [47:16<1:28:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5613: train loss 1.90108. lr 5.573037e-04:  34%|███▍      | 5613/16329 [47:16<1:28:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5613: train loss 1.90108. lr 5.573037e-04:  34%|███▍      | 5614/16329 [47:16<1:28:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5614: train loss 1.94349. lr 5.572889e-04:  34%|███▍      | 5614/16329 [47:17<1:28:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5614: train loss 1.94349. lr 5.572889e-04:  34%|███▍      | 5615/16329 [47:17<1:28:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5615: train loss 1.95534. lr 5.572740e-04:  34%|███▍      | 5615/16329 [47:17<1:28:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5615: train loss 1.95534. lr 5.572740e-04:  34%|███▍      | 5616/16329 [47:17<1:28:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5616: train loss 1.92857. lr 5.572592e-04:  34%|███▍      | 5616/16329 [47:18<1:28:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5616: train loss 1.92857. lr 5.572592e-04:  34%|███▍      | 5617/16329 [47:18<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5617: train loss 1.89223. lr 5.572444e-04:  34%|███▍      | 5617/16329 [47:18<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5617: train loss 1.89223. lr 5.572444e-04:  34%|███▍      | 5618/16329 [47:18<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5618: train loss 1.87765. lr 5.572295e-04:  34%|███▍      | 5618/16329 [47:19<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5618: train loss 1.87765. lr 5.572295e-04:  34%|███▍      | 5619/16329 [47:19<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5619: train loss 1.97482. lr 5.572146e-04:  34%|███▍      | 5619/16329 [47:19<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5619: train loss 1.97482. lr 5.572146e-04:  34%|███▍      | 5620/16329 [47:19<1:28:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5620: train loss 1.93274. lr 5.571998e-04:  34%|███▍      | 5620/16329 [47:20<1:28:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5620: train loss 1.93274. lr 5.571998e-04:  34%|███▍      | 5621/16329 [47:20<1:28:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5621: train loss 1.94846. lr 5.571849e-04:  34%|███▍      | 5621/16329 [47:20<1:28:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5621: train loss 1.94846. lr 5.571849e-04:  34%|███▍      | 5622/16329 [47:20<1:28:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5622: train loss 1.94978. lr 5.571701e-04:  34%|███▍      | 5622/16329 [47:21<1:28:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5622: train loss 1.94978. lr 5.571701e-04:  34%|███▍      | 5623/16329 [47:21<1:38:23,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5623: train loss 1.94967. lr 5.571552e-04:  34%|███▍      | 5623/16329 [47:21<1:38:23,  1.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5623: train loss 1.94967. lr 5.571552e-04:  34%|███▍      | 5624/16329 [47:21<1:35:11,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5624: train loss 1.91188. lr 5.571403e-04:  34%|███▍      | 5624/16329 [47:22<1:35:11,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5624: train loss 1.91188. lr 5.571403e-04:  34%|███▍      | 5625/16329 [47:22<1:33:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5625: train loss 1.91615. lr 5.571255e-04:  34%|███▍      | 5625/16329 [47:22<1:33:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5625: train loss 1.91615. lr 5.571255e-04:  34%|███▍      | 5626/16329 [47:22<1:31:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5626: train loss 1.88701. lr 5.571106e-04:  34%|███▍      | 5626/16329 [47:23<1:31:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5626: train loss 1.88701. lr 5.571106e-04:  34%|███▍      | 5627/16329 [47:23<1:30:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5627: train loss 1.92789. lr 5.570957e-04:  34%|███▍      | 5627/16329 [47:23<1:30:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5627: train loss 1.92789. lr 5.570957e-04:  34%|███▍      | 5628/16329 [47:23<1:30:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5628: train loss 1.92855. lr 5.570809e-04:  34%|███▍      | 5628/16329 [47:24<1:30:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5628: train loss 1.92855. lr 5.570809e-04:  34%|███▍      | 5629/16329 [47:24<1:29:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5629: train loss 1.93127. lr 5.570660e-04:  34%|███▍      | 5629/16329 [47:24<1:29:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5629: train loss 1.93127. lr 5.570660e-04:  34%|███▍      | 5630/16329 [47:24<1:29:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5630: train loss 1.86944. lr 5.570511e-04:  34%|███▍      | 5630/16329 [47:25<1:29:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5630: train loss 1.86944. lr 5.570511e-04:  34%|███▍      | 5631/16329 [47:25<1:28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5631: train loss 1.93679. lr 5.570362e-04:  34%|███▍      | 5631/16329 [47:25<1:28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5631: train loss 1.93679. lr 5.570362e-04:  34%|███▍      | 5632/16329 [47:25<1:29:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5632: train loss 1.92860. lr 5.570213e-04:  34%|███▍      | 5632/16329 [47:26<1:29:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5632: train loss 1.92860. lr 5.570213e-04:  34%|███▍      | 5633/16329 [47:26<1:28:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5633: train loss 1.93311. lr 5.570065e-04:  34%|███▍      | 5633/16329 [47:26<1:28:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5633: train loss 1.93311. lr 5.570065e-04:  35%|███▍      | 5634/16329 [47:26<1:28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5634: train loss 1.89316. lr 5.569916e-04:  35%|███▍      | 5634/16329 [47:27<1:28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5634: train loss 1.89316. lr 5.569916e-04:  35%|███▍      | 5635/16329 [47:27<1:28:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5635: train loss 1.95728. lr 5.569767e-04:  35%|███▍      | 5635/16329 [47:27<1:28:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5635: train loss 1.95728. lr 5.569767e-04:  35%|███▍      | 5636/16329 [47:27<1:28:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5636: train loss 1.93821. lr 5.569618e-04:  35%|███▍      | 5636/16329 [47:28<1:28:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5636: train loss 1.93821. lr 5.569618e-04:  35%|███▍      | 5637/16329 [47:28<1:28:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5637: train loss 1.89910. lr 5.569469e-04:  35%|███▍      | 5637/16329 [47:28<1:28:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5637: train loss 1.89910. lr 5.569469e-04:  35%|███▍      | 5638/16329 [47:28<1:28:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5638: train loss 1.94186. lr 5.569320e-04:  35%|███▍      | 5638/16329 [47:29<1:28:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5638: train loss 1.94186. lr 5.569320e-04:  35%|███▍      | 5639/16329 [47:29<1:28:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5639: train loss 1.88607. lr 5.569171e-04:  35%|███▍      | 5639/16329 [47:29<1:28:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5639: train loss 1.88607. lr 5.569171e-04:  35%|███▍      | 5640/16329 [47:29<1:28:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5640: train loss 1.93488. lr 5.569022e-04:  35%|███▍      | 5640/16329 [47:30<1:28:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5640: train loss 1.93488. lr 5.569022e-04:  35%|███▍      | 5641/16329 [47:30<1:28:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5641: train loss 1.92564. lr 5.568873e-04:  35%|███▍      | 5641/16329 [47:30<1:28:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5641: train loss 1.92564. lr 5.568873e-04:  35%|███▍      | 5642/16329 [47:30<1:28:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5642: train loss 1.92338. lr 5.568724e-04:  35%|███▍      | 5642/16329 [47:31<1:28:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5642: train loss 1.92338. lr 5.568724e-04:  35%|███▍      | 5643/16329 [47:31<1:28:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5643: train loss 1.92428. lr 5.568575e-04:  35%|███▍      | 5643/16329 [47:31<1:28:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5643: train loss 1.92428. lr 5.568575e-04:  35%|███▍      | 5644/16329 [47:31<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5644: train loss 1.88388. lr 5.568426e-04:  35%|███▍      | 5644/16329 [47:32<1:28:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5644: train loss 1.88388. lr 5.568426e-04:  35%|███▍      | 5645/16329 [47:32<1:28:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5645: train loss 1.92343. lr 5.568276e-04:  35%|███▍      | 5645/16329 [47:32<1:28:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5645: train loss 1.92343. lr 5.568276e-04:  35%|███▍      | 5646/16329 [47:32<1:28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5646: train loss 1.95857. lr 5.568127e-04:  35%|███▍      | 5646/16329 [47:33<1:28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5646: train loss 1.95857. lr 5.568127e-04:  35%|███▍      | 5647/16329 [47:33<1:28:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5647: train loss 1.96331. lr 5.567978e-04:  35%|███▍      | 5647/16329 [47:33<1:28:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5647: train loss 1.96331. lr 5.567978e-04:  35%|███▍      | 5648/16329 [47:33<1:28:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5648: train loss 1.88866. lr 5.567829e-04:  35%|███▍      | 5648/16329 [47:34<1:28:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5648: train loss 1.88866. lr 5.567829e-04:  35%|███▍      | 5649/16329 [47:34<1:28:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5649: train loss 1.94706. lr 5.567680e-04:  35%|███▍      | 5649/16329 [47:34<1:28:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5649: train loss 1.94706. lr 5.567680e-04:  35%|███▍      | 5650/16329 [47:34<1:28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5650: train loss 1.88680. lr 5.567530e-04:  35%|███▍      | 5650/16329 [47:35<1:28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5650: train loss 1.88680. lr 5.567530e-04:  35%|███▍      | 5651/16329 [47:35<1:32:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5651: train loss 1.89602. lr 5.567381e-04:  35%|███▍      | 5651/16329 [47:36<1:32:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5651: train loss 1.89602. lr 5.567381e-04:  35%|███▍      | 5652/16329 [47:36<1:34:37,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5652: train loss 1.89803. lr 5.567232e-04:  35%|███▍      | 5652/16329 [47:36<1:34:37,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5652: train loss 1.89803. lr 5.567232e-04:  35%|███▍      | 5653/16329 [47:36<1:34:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5653: train loss 1.89923. lr 5.567082e-04:  35%|███▍      | 5653/16329 [47:37<1:34:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5653: train loss 1.89923. lr 5.567082e-04:  35%|███▍      | 5654/16329 [47:37<1:33:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5654: train loss 1.91717. lr 5.566933e-04:  35%|███▍      | 5654/16329 [47:37<1:33:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5654: train loss 1.91717. lr 5.566933e-04:  35%|███▍      | 5655/16329 [47:37<1:33:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5655: train loss 1.85432. lr 5.566784e-04:  35%|███▍      | 5655/16329 [47:38<1:33:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5655: train loss 1.85432. lr 5.566784e-04:  35%|███▍      | 5656/16329 [47:38<1:32:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5656: train loss 1.95928. lr 5.566634e-04:  35%|███▍      | 5656/16329 [47:38<1:32:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5656: train loss 1.95928. lr 5.566634e-04:  35%|███▍      | 5657/16329 [47:38<1:31:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5657: train loss 1.92563. lr 5.566485e-04:  35%|███▍      | 5657/16329 [47:39<1:31:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5657: train loss 1.92563. lr 5.566485e-04:  35%|███▍      | 5658/16329 [47:39<1:42:57,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 5658: train loss 1.93172. lr 5.566335e-04:  35%|███▍      | 5658/16329 [47:39<1:42:57,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 5658: train loss 1.93172. lr 5.566335e-04:  35%|███▍      | 5659/16329 [47:39<1:38:41,  1.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5659: train loss 1.89818. lr 5.566186e-04:  35%|███▍      | 5659/16329 [47:40<1:38:41,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5659: train loss 1.89818. lr 5.566186e-04:  35%|███▍      | 5660/16329 [47:40<1:35:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5660: train loss 1.92218. lr 5.566036e-04:  35%|███▍      | 5660/16329 [47:40<1:35:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5660: train loss 1.92218. lr 5.566036e-04:  35%|███▍      | 5661/16329 [47:40<1:33:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5661: train loss 1.98676. lr 5.565887e-04:  35%|███▍      | 5661/16329 [47:41<1:33:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 5661: train loss 1.98676. lr 5.565887e-04:  35%|███▍      | 5662/16329 [47:41<1:35:00,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5662: train loss 1.93508. lr 5.565737e-04:  35%|███▍      | 5662/16329 [47:41<1:35:00,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5662: train loss 1.93508. lr 5.565737e-04:  35%|███▍      | 5663/16329 [47:41<1:34:51,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5663: train loss 1.93536. lr 5.565588e-04:  35%|███▍      | 5663/16329 [47:42<1:34:51,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5663: train loss 1.93536. lr 5.565588e-04:  35%|███▍      | 5664/16329 [47:42<1:33:51,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5664: train loss 1.90024. lr 5.565438e-04:  35%|███▍      | 5664/16329 [47:42<1:33:51,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5664: train loss 1.90024. lr 5.565438e-04:  35%|███▍      | 5665/16329 [47:42<1:33:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5665: train loss 1.90237. lr 5.565289e-04:  35%|███▍      | 5665/16329 [47:43<1:33:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5665: train loss 1.90237. lr 5.565289e-04:  35%|███▍      | 5666/16329 [47:43<1:32:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5666: train loss 1.89598. lr 5.565139e-04:  35%|███▍      | 5666/16329 [47:43<1:32:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5666: train loss 1.89598. lr 5.565139e-04:  35%|███▍      | 5667/16329 [47:43<1:31:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5667: train loss 1.92649. lr 5.564989e-04:  35%|███▍      | 5667/16329 [47:44<1:31:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5667: train loss 1.92649. lr 5.564989e-04:  35%|███▍      | 5668/16329 [47:44<1:30:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5668: train loss 1.91465. lr 5.564840e-04:  35%|███▍      | 5668/16329 [47:44<1:30:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5668: train loss 1.91465. lr 5.564840e-04:  35%|███▍      | 5669/16329 [47:44<1:30:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5669: train loss 1.94310. lr 5.564690e-04:  35%|███▍      | 5669/16329 [47:45<1:30:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5669: train loss 1.94310. lr 5.564690e-04:  35%|███▍      | 5670/16329 [47:45<1:29:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5670: train loss 1.93782. lr 5.564540e-04:  35%|███▍      | 5670/16329 [47:45<1:29:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5670: train loss 1.93782. lr 5.564540e-04:  35%|███▍      | 5671/16329 [47:45<1:29:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5671: train loss 1.88958. lr 5.564390e-04:  35%|███▍      | 5671/16329 [47:46<1:29:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5671: train loss 1.88958. lr 5.564390e-04:  35%|███▍      | 5672/16329 [47:46<1:28:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5672: train loss 1.93052. lr 5.564241e-04:  35%|███▍      | 5672/16329 [47:46<1:28:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5672: train loss 1.93052. lr 5.564241e-04:  35%|███▍      | 5673/16329 [47:46<1:29:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5673: train loss 1.90035. lr 5.564091e-04:  35%|███▍      | 5673/16329 [47:47<1:29:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5673: train loss 1.90035. lr 5.564091e-04:  35%|███▍      | 5674/16329 [47:47<1:29:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5674: train loss 1.98068. lr 5.563941e-04:  35%|███▍      | 5674/16329 [47:47<1:29:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5674: train loss 1.98068. lr 5.563941e-04:  35%|███▍      | 5675/16329 [47:47<1:28:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5675: train loss 1.92024. lr 5.563791e-04:  35%|███▍      | 5675/16329 [47:48<1:28:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5675: train loss 1.92024. lr 5.563791e-04:  35%|███▍      | 5676/16329 [47:48<1:28:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5676: train loss 1.95988. lr 5.563641e-04:  35%|███▍      | 5676/16329 [47:48<1:28:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5676: train loss 1.95988. lr 5.563641e-04:  35%|███▍      | 5677/16329 [47:48<1:28:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5677: train loss 1.94279. lr 5.563491e-04:  35%|███▍      | 5677/16329 [47:49<1:28:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5677: train loss 1.94279. lr 5.563491e-04:  35%|███▍      | 5678/16329 [47:49<1:27:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5678: train loss 1.93184. lr 5.563341e-04:  35%|███▍      | 5678/16329 [47:49<1:27:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5678: train loss 1.93184. lr 5.563341e-04:  35%|███▍      | 5679/16329 [47:49<1:27:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5679: train loss 1.92998. lr 5.563191e-04:  35%|███▍      | 5679/16329 [47:50<1:27:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5679: train loss 1.92998. lr 5.563191e-04:  35%|███▍      | 5680/16329 [47:50<1:27:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5680: train loss 1.90771. lr 5.563041e-04:  35%|███▍      | 5680/16329 [47:50<1:27:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5680: train loss 1.90771. lr 5.563041e-04:  35%|███▍      | 5681/16329 [47:50<1:27:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5681: train loss 1.93769. lr 5.562891e-04:  35%|███▍      | 5681/16329 [47:51<1:27:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5681: train loss 1.93769. lr 5.562891e-04:  35%|███▍      | 5682/16329 [47:51<1:27:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5682: train loss 1.92408. lr 5.562741e-04:  35%|███▍      | 5682/16329 [47:52<1:27:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5682: train loss 1.92408. lr 5.562741e-04:  35%|███▍      | 5683/16329 [47:52<1:43:06,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 5683: train loss 1.86993. lr 5.562591e-04:  35%|███▍      | 5683/16329 [47:52<1:43:06,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 5683: train loss 1.86993. lr 5.562591e-04:  35%|███▍      | 5684/16329 [47:52<1:38:27,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5684: train loss 1.93924. lr 5.562441e-04:  35%|███▍      | 5684/16329 [47:53<1:38:27,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5684: train loss 1.93924. lr 5.562441e-04:  35%|███▍      | 5685/16329 [47:53<1:35:25,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5685: train loss 1.89861. lr 5.562291e-04:  35%|███▍      | 5685/16329 [47:53<1:35:25,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5685: train loss 1.89861. lr 5.562291e-04:  35%|███▍      | 5686/16329 [47:53<1:32:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5686: train loss 1.93504. lr 5.562141e-04:  35%|███▍      | 5686/16329 [47:54<1:32:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5686: train loss 1.93504. lr 5.562141e-04:  35%|███▍      | 5687/16329 [47:54<1:31:35,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5687: train loss 1.92834. lr 5.561991e-04:  35%|███▍      | 5687/16329 [47:54<1:31:35,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5687: train loss 1.92834. lr 5.561991e-04:  35%|███▍      | 5688/16329 [47:54<1:30:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5688: train loss 1.89740. lr 5.561841e-04:  35%|███▍      | 5688/16329 [47:55<1:30:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5688: train loss 1.89740. lr 5.561841e-04:  35%|███▍      | 5689/16329 [47:55<1:29:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5689: train loss 1.90060. lr 5.561691e-04:  35%|███▍      | 5689/16329 [47:55<1:29:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5689: train loss 1.90060. lr 5.561691e-04:  35%|███▍      | 5690/16329 [47:55<1:28:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5690: train loss 1.89904. lr 5.561540e-04:  35%|███▍      | 5690/16329 [47:56<1:28:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5690: train loss 1.89904. lr 5.561540e-04:  35%|███▍      | 5691/16329 [47:56<1:28:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5691: train loss 1.89133. lr 5.561390e-04:  35%|███▍      | 5691/16329 [47:56<1:28:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5691: train loss 1.89133. lr 5.561390e-04:  35%|███▍      | 5692/16329 [47:56<1:28:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5692: train loss 1.88678. lr 5.561240e-04:  35%|███▍      | 5692/16329 [47:57<1:28:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5692: train loss 1.88678. lr 5.561240e-04:  35%|███▍      | 5693/16329 [47:57<1:28:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5693: train loss 1.91176. lr 5.561090e-04:  35%|███▍      | 5693/16329 [47:57<1:28:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5693: train loss 1.91176. lr 5.561090e-04:  35%|███▍      | 5694/16329 [47:57<1:28:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5694: train loss 1.88441. lr 5.560939e-04:  35%|███▍      | 5694/16329 [47:58<1:28:06,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5694: train loss 1.88441. lr 5.560939e-04:  35%|███▍      | 5695/16329 [47:58<1:28:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5695: train loss 1.94234. lr 5.560789e-04:  35%|███▍      | 5695/16329 [47:58<1:28:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5695: train loss 1.94234. lr 5.560789e-04:  35%|███▍      | 5696/16329 [47:58<1:27:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5696: train loss 1.93560. lr 5.560639e-04:  35%|███▍      | 5696/16329 [47:59<1:27:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5696: train loss 1.93560. lr 5.560639e-04:  35%|███▍      | 5697/16329 [47:59<1:28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5697: train loss 1.89513. lr 5.560488e-04:  35%|███▍      | 5697/16329 [47:59<1:28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5697: train loss 1.89513. lr 5.560488e-04:  35%|███▍      | 5698/16329 [47:59<1:28:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5698: train loss 1.91638. lr 5.560338e-04:  35%|███▍      | 5698/16329 [48:00<1:28:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5698: train loss 1.91638. lr 5.560338e-04:  35%|███▍      | 5699/16329 [48:00<1:28:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5699: train loss 1.93228. lr 5.560187e-04:  35%|███▍      | 5699/16329 [48:00<1:28:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5699: train loss 1.93228. lr 5.560187e-04:  35%|███▍      | 5700/16329 [48:00<1:28:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5700: train loss 1.85982. lr 5.560037e-04:  35%|███▍      | 5700/16329 [48:01<1:28:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5700: train loss 1.85982. lr 5.560037e-04:  35%|███▍      | 5701/16329 [48:01<1:28:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5701: train loss 1.91235. lr 5.559886e-04:  35%|███▍      | 5701/16329 [48:01<1:28:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5701: train loss 1.91235. lr 5.559886e-04:  35%|███▍      | 5702/16329 [48:01<1:28:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5702: train loss 1.93075. lr 5.559736e-04:  35%|███▍      | 5702/16329 [48:02<1:28:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5702: train loss 1.93075. lr 5.559736e-04:  35%|███▍      | 5703/16329 [48:02<1:28:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5703: train loss 1.88345. lr 5.559585e-04:  35%|███▍      | 5703/16329 [48:02<1:28:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5703: train loss 1.88345. lr 5.559585e-04:  35%|███▍      | 5704/16329 [48:02<1:28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5704: train loss 1.88721. lr 5.559435e-04:  35%|███▍      | 5704/16329 [48:03<1:28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5704: train loss 1.88721. lr 5.559435e-04:  35%|███▍      | 5705/16329 [48:03<1:27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5705: train loss 1.94125. lr 5.559284e-04:  35%|███▍      | 5705/16329 [48:03<1:27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5705: train loss 1.94125. lr 5.559284e-04:  35%|███▍      | 5706/16329 [48:03<1:28:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5706: train loss 1.94839. lr 5.559134e-04:  35%|███▍      | 5706/16329 [48:04<1:28:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5706: train loss 1.94839. lr 5.559134e-04:  35%|███▍      | 5707/16329 [48:04<1:28:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5707: train loss 1.92161. lr 5.558983e-04:  35%|███▍      | 5707/16329 [48:04<1:28:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5707: train loss 1.92161. lr 5.558983e-04:  35%|███▍      | 5708/16329 [48:04<1:27:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5708: train loss 1.86930. lr 5.558832e-04:  35%|███▍      | 5708/16329 [48:05<1:27:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5708: train loss 1.86930. lr 5.558832e-04:  35%|███▍      | 5709/16329 [48:05<1:28:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5709: train loss 1.93288. lr 5.558682e-04:  35%|███▍      | 5709/16329 [48:05<1:28:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5709: train loss 1.93288. lr 5.558682e-04:  35%|███▍      | 5710/16329 [48:05<1:40:59,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 5710: train loss 1.87517. lr 5.558531e-04:  35%|███▍      | 5710/16329 [48:06<1:40:59,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 5710: train loss 1.87517. lr 5.558531e-04:  35%|███▍      | 5711/16329 [48:06<1:36:53,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5711: train loss 1.91416. lr 5.558380e-04:  35%|███▍      | 5711/16329 [48:06<1:36:53,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5711: train loss 1.91416. lr 5.558380e-04:  35%|███▍      | 5712/16329 [48:06<1:33:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5712: train loss 1.95951. lr 5.558230e-04:  35%|███▍      | 5712/16329 [48:07<1:33:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5712: train loss 1.95951. lr 5.558230e-04:  35%|███▍      | 5713/16329 [48:07<1:32:05,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5713: train loss 1.89409. lr 5.558079e-04:  35%|███▍      | 5713/16329 [48:07<1:32:05,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5713: train loss 1.89409. lr 5.558079e-04:  35%|███▍      | 5714/16329 [48:07<1:30:36,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5714: train loss 1.92000. lr 5.557928e-04:  35%|███▍      | 5714/16329 [48:08<1:30:36,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5714: train loss 1.92000. lr 5.557928e-04:  35%|███▍      | 5715/16329 [48:08<1:29:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5715: train loss 1.88621. lr 5.557777e-04:  35%|███▍      | 5715/16329 [48:08<1:29:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5715: train loss 1.88621. lr 5.557777e-04:  35%|███▌      | 5716/16329 [48:08<1:29:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5716: train loss 1.90965. lr 5.557626e-04:  35%|███▌      | 5716/16329 [48:09<1:29:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5716: train loss 1.90965. lr 5.557626e-04:  35%|███▌      | 5717/16329 [48:09<1:28:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5717: train loss 1.93412. lr 5.557476e-04:  35%|███▌      | 5717/16329 [48:09<1:28:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5717: train loss 1.93412. lr 5.557476e-04:  35%|███▌      | 5718/16329 [48:09<1:31:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5718: train loss 1.88189. lr 5.557325e-04:  35%|███▌      | 5718/16329 [48:10<1:31:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5718: train loss 1.88189. lr 5.557325e-04:  35%|███▌      | 5719/16329 [48:10<1:34:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5719: train loss 1.87317. lr 5.557174e-04:  35%|███▌      | 5719/16329 [48:10<1:34:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5719: train loss 1.87317. lr 5.557174e-04:  35%|███▌      | 5720/16329 [48:10<1:34:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5720: train loss 1.87877. lr 5.557023e-04:  35%|███▌      | 5720/16329 [48:11<1:34:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5720: train loss 1.87877. lr 5.557023e-04:  35%|███▌      | 5721/16329 [48:11<1:34:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5721: train loss 1.81751. lr 5.556872e-04:  35%|███▌      | 5721/16329 [48:11<1:34:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5721: train loss 1.81751. lr 5.556872e-04:  35%|███▌      | 5722/16329 [48:11<1:33:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5722: train loss 1.93840. lr 5.556721e-04:  35%|███▌      | 5722/16329 [48:12<1:33:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5722: train loss 1.93840. lr 5.556721e-04:  35%|███▌      | 5723/16329 [48:12<1:32:28,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5723: train loss 1.92487. lr 5.556570e-04:  35%|███▌      | 5723/16329 [48:13<1:32:28,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5723: train loss 1.92487. lr 5.556570e-04:  35%|███▌      | 5724/16329 [48:13<1:31:34,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5724: train loss 1.89764. lr 5.556419e-04:  35%|███▌      | 5724/16329 [48:13<1:31:34,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5724: train loss 1.89764. lr 5.556419e-04:  35%|███▌      | 5725/16329 [48:13<1:30:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5725: train loss 1.92083. lr 5.556268e-04:  35%|███▌      | 5725/16329 [48:13<1:30:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5725: train loss 1.92083. lr 5.556268e-04:  35%|███▌      | 5726/16329 [48:13<1:29:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5726: train loss 1.90478. lr 5.556117e-04:  35%|███▌      | 5726/16329 [48:14<1:29:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5726: train loss 1.90478. lr 5.556117e-04:  35%|███▌      | 5727/16329 [48:14<1:28:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5727: train loss 1.88905. lr 5.555966e-04:  35%|███▌      | 5727/16329 [48:14<1:28:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5727: train loss 1.88905. lr 5.555966e-04:  35%|███▌      | 5728/16329 [48:14<1:28:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5728: train loss 1.89631. lr 5.555815e-04:  35%|███▌      | 5728/16329 [48:15<1:28:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5728: train loss 1.89631. lr 5.555815e-04:  35%|███▌      | 5729/16329 [48:15<1:28:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5729: train loss 1.91486. lr 5.555664e-04:  35%|███▌      | 5729/16329 [48:15<1:28:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5729: train loss 1.91486. lr 5.555664e-04:  35%|███▌      | 5730/16329 [48:15<1:27:44,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5730: train loss 1.90835. lr 5.555512e-04:  35%|███▌      | 5730/16329 [48:16<1:27:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5730: train loss 1.90835. lr 5.555512e-04:  35%|███▌      | 5731/16329 [48:16<1:27:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5731: train loss 1.89059. lr 5.555361e-04:  35%|███▌      | 5731/16329 [48:16<1:27:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5731: train loss 1.89059. lr 5.555361e-04:  35%|███▌      | 5732/16329 [48:16<1:27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5732: train loss 1.90500. lr 5.555210e-04:  35%|███▌      | 5732/16329 [48:17<1:27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5732: train loss 1.90500. lr 5.555210e-04:  35%|███▌      | 5733/16329 [48:17<1:27:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5733: train loss 1.89601. lr 5.555059e-04:  35%|███▌      | 5733/16329 [48:17<1:27:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5733: train loss 1.89601. lr 5.555059e-04:  35%|███▌      | 5734/16329 [48:17<1:27:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5734: train loss 1.90195. lr 5.554908e-04:  35%|███▌      | 5734/16329 [48:18<1:27:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5734: train loss 1.90195. lr 5.554908e-04:  35%|███▌      | 5735/16329 [48:18<1:27:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5735: train loss 1.92596. lr 5.554756e-04:  35%|███▌      | 5735/16329 [48:18<1:27:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5735: train loss 1.92596. lr 5.554756e-04:  35%|███▌      | 5736/16329 [48:18<1:27:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5736: train loss 1.90007. lr 5.554605e-04:  35%|███▌      | 5736/16329 [48:19<1:27:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5736: train loss 1.90007. lr 5.554605e-04:  35%|███▌      | 5737/16329 [48:19<1:27:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5737: train loss 1.86351. lr 5.554454e-04:  35%|███▌      | 5737/16329 [48:19<1:27:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5737: train loss 1.86351. lr 5.554454e-04:  35%|███▌      | 5738/16329 [48:19<1:27:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5738: train loss 1.83097. lr 5.554302e-04:  35%|███▌      | 5738/16329 [48:20<1:27:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5738: train loss 1.83097. lr 5.554302e-04:  35%|███▌      | 5739/16329 [48:20<1:27:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5739: train loss 1.87954. lr 5.554151e-04:  35%|███▌      | 5739/16329 [48:20<1:27:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5739: train loss 1.87954. lr 5.554151e-04:  35%|███▌      | 5740/16329 [48:20<1:27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5740: train loss 1.92703. lr 5.553999e-04:  35%|███▌      | 5740/16329 [48:21<1:27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5740: train loss 1.92703. lr 5.553999e-04:  35%|███▌      | 5741/16329 [48:21<1:27:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5741: train loss 1.90602. lr 5.553848e-04:  35%|███▌      | 5741/16329 [48:21<1:27:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5741: train loss 1.90602. lr 5.553848e-04:  35%|███▌      | 5742/16329 [48:21<1:27:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5742: train loss 1.92518. lr 5.553697e-04:  35%|███▌      | 5742/16329 [48:22<1:27:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5742: train loss 1.92518. lr 5.553697e-04:  35%|███▌      | 5743/16329 [48:22<1:27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5743: train loss 1.93084. lr 5.553545e-04:  35%|███▌      | 5743/16329 [48:22<1:27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5743: train loss 1.93084. lr 5.553545e-04:  35%|███▌      | 5744/16329 [48:22<1:27:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5744: train loss 1.93817. lr 5.553394e-04:  35%|███▌      | 5744/16329 [48:23<1:27:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5744: train loss 1.93817. lr 5.553394e-04:  35%|███▌      | 5745/16329 [48:23<1:27:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5745: train loss 1.91915. lr 5.553242e-04:  35%|███▌      | 5745/16329 [48:23<1:27:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5745: train loss 1.91915. lr 5.553242e-04:  35%|███▌      | 5746/16329 [48:23<1:28:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5746: train loss 1.89523. lr 5.553091e-04:  35%|███▌      | 5746/16329 [48:24<1:28:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5746: train loss 1.89523. lr 5.553091e-04:  35%|███▌      | 5747/16329 [48:24<1:28:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5747: train loss 1.84166. lr 5.552939e-04:  35%|███▌      | 5747/16329 [48:24<1:28:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5747: train loss 1.84166. lr 5.552939e-04:  35%|███▌      | 5748/16329 [48:24<1:28:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5748: train loss 1.88829. lr 5.552787e-04:  35%|███▌      | 5748/16329 [48:25<1:28:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5748: train loss 1.88829. lr 5.552787e-04:  35%|███▌      | 5749/16329 [48:25<1:27:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5749: train loss 1.91420. lr 5.552636e-04:  35%|███▌      | 5749/16329 [48:26<1:27:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5749: train loss 1.91420. lr 5.552636e-04:  35%|███▌      | 5750/16329 [48:26<1:36:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5750: train loss 1.89110. lr 5.552484e-04:  35%|███▌      | 5750/16329 [48:26<1:36:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5750: train loss 1.89110. lr 5.552484e-04:  35%|███▌      | 5751/16329 [48:26<1:34:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5751: train loss 1.91465. lr 5.552333e-04:  35%|███▌      | 5751/16329 [48:27<1:34:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5751: train loss 1.91465. lr 5.552333e-04:  35%|███▌      | 5752/16329 [48:27<1:31:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5752: train loss 1.92327. lr 5.552181e-04:  35%|███▌      | 5752/16329 [48:27<1:31:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5752: train loss 1.92327. lr 5.552181e-04:  35%|███▌      | 5753/16329 [48:27<1:30:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5753: train loss 1.92183. lr 5.552029e-04:  35%|███▌      | 5753/16329 [48:28<1:30:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5753: train loss 1.92183. lr 5.552029e-04:  35%|███▌      | 5754/16329 [48:28<1:29:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5754: train loss 1.93490. lr 5.551877e-04:  35%|███▌      | 5754/16329 [48:28<1:29:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5754: train loss 1.93490. lr 5.551877e-04:  35%|███▌      | 5755/16329 [48:28<1:28:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5755: train loss 1.90324. lr 5.551726e-04:  35%|███▌      | 5755/16329 [48:29<1:28:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5755: train loss 1.90324. lr 5.551726e-04:  35%|███▌      | 5756/16329 [48:29<1:28:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5756: train loss 1.88924. lr 5.551574e-04:  35%|███▌      | 5756/16329 [48:29<1:28:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5756: train loss 1.88924. lr 5.551574e-04:  35%|███▌      | 5757/16329 [48:29<1:27:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5757: train loss 1.79929. lr 5.551422e-04:  35%|███▌      | 5757/16329 [48:30<1:27:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5757: train loss 1.79929. lr 5.551422e-04:  35%|███▌      | 5758/16329 [48:30<1:27:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5758: train loss 1.93606. lr 5.551270e-04:  35%|███▌      | 5758/16329 [48:30<1:27:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5758: train loss 1.93606. lr 5.551270e-04:  35%|███▌      | 5759/16329 [48:30<1:27:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5759: train loss 1.87084. lr 5.551118e-04:  35%|███▌      | 5759/16329 [48:31<1:27:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5759: train loss 1.87084. lr 5.551118e-04:  35%|███▌      | 5760/16329 [48:31<1:27:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5760: train loss 1.85048. lr 5.550967e-04:  35%|███▌      | 5760/16329 [48:31<1:27:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5760: train loss 1.85048. lr 5.550967e-04:  35%|███▌      | 5761/16329 [48:31<1:27:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5761: train loss 1.89384. lr 5.550815e-04:  35%|███▌      | 5761/16329 [48:32<1:27:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5761: train loss 1.89384. lr 5.550815e-04:  35%|███▌      | 5762/16329 [48:32<1:27:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5762: train loss 1.87091. lr 5.550663e-04:  35%|███▌      | 5762/16329 [48:32<1:27:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5762: train loss 1.87091. lr 5.550663e-04:  35%|███▌      | 5763/16329 [48:32<1:27:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5763: train loss 1.94547. lr 5.550511e-04:  35%|███▌      | 5763/16329 [48:33<1:27:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5763: train loss 1.94547. lr 5.550511e-04:  35%|███▌      | 5764/16329 [48:33<1:27:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5764: train loss 1.85305. lr 5.550359e-04:  35%|███▌      | 5764/16329 [48:33<1:27:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5764: train loss 1.85305. lr 5.550359e-04:  35%|███▌      | 5765/16329 [48:33<1:27:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5765: train loss 1.88810. lr 5.550207e-04:  35%|███▌      | 5765/16329 [48:34<1:27:28,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5765: train loss 1.88810. lr 5.550207e-04:  35%|███▌      | 5766/16329 [48:34<1:27:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5766: train loss 1.89892. lr 5.550055e-04:  35%|███▌      | 5766/16329 [48:34<1:27:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5766: train loss 1.89892. lr 5.550055e-04:  35%|███▌      | 5767/16329 [48:34<1:27:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5767: train loss 1.91161. lr 5.549903e-04:  35%|███▌      | 5767/16329 [48:35<1:27:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5767: train loss 1.91161. lr 5.549903e-04:  35%|███▌      | 5768/16329 [48:35<1:27:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5768: train loss 1.87888. lr 5.549751e-04:  35%|███▌      | 5768/16329 [48:35<1:27:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5768: train loss 1.87888. lr 5.549751e-04:  35%|███▌      | 5769/16329 [48:35<1:27:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5769: train loss 1.91384. lr 5.549599e-04:  35%|███▌      | 5769/16329 [48:36<1:27:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5769: train loss 1.91384. lr 5.549599e-04:  35%|███▌      | 5770/16329 [48:36<1:27:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5770: train loss 1.88073. lr 5.549447e-04:  35%|███▌      | 5770/16329 [48:36<1:27:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5770: train loss 1.88073. lr 5.549447e-04:  35%|███▌      | 5771/16329 [48:36<1:27:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5771: train loss 1.85766. lr 5.549294e-04:  35%|███▌      | 5771/16329 [48:36<1:27:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5771: train loss 1.85766. lr 5.549294e-04:  35%|███▌      | 5772/16329 [48:36<1:27:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5772: train loss 1.90954. lr 5.549142e-04:  35%|███▌      | 5772/16329 [48:37<1:27:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5772: train loss 1.90954. lr 5.549142e-04:  35%|███▌      | 5773/16329 [48:37<1:27:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5773: train loss 1.88909. lr 5.548990e-04:  35%|███▌      | 5773/16329 [48:37<1:27:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5773: train loss 1.88909. lr 5.548990e-04:  35%|███▌      | 5774/16329 [48:37<1:27:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5774: train loss 1.86664. lr 5.548838e-04:  35%|███▌      | 5774/16329 [48:38<1:27:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5774: train loss 1.86664. lr 5.548838e-04:  35%|███▌      | 5775/16329 [48:38<1:27:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5775: train loss 1.91231. lr 5.548686e-04:  35%|███▌      | 5775/16329 [48:38<1:27:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5775: train loss 1.91231. lr 5.548686e-04:  35%|███▌      | 5776/16329 [48:38<1:26:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5776: train loss 1.89159. lr 5.548533e-04:  35%|███▌      | 5776/16329 [48:39<1:26:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5776: train loss 1.89159. lr 5.548533e-04:  35%|███▌      | 5777/16329 [48:39<1:27:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5777: train loss 1.88113. lr 5.548381e-04:  35%|███▌      | 5777/16329 [48:39<1:27:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5777: train loss 1.88113. lr 5.548381e-04:  35%|███▌      | 5778/16329 [48:39<1:26:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5778: train loss 1.92100. lr 5.548229e-04:  35%|███▌      | 5778/16329 [48:40<1:26:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 5778: train loss 1.92100. lr 5.548229e-04:  35%|███▌      | 5779/16329 [48:40<1:27:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5779: train loss 1.86948. lr 5.548077e-04:  35%|███▌      | 5779/16329 [48:40<1:27:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5779: train loss 1.86948. lr 5.548077e-04:  35%|███▌      | 5780/16329 [48:40<1:27:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5780: train loss 1.83425. lr 5.547924e-04:  35%|███▌      | 5780/16329 [48:41<1:27:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5780: train loss 1.83425. lr 5.547924e-04:  35%|███▌      | 5781/16329 [48:41<1:27:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5781: train loss 1.91144. lr 5.547772e-04:  35%|███▌      | 5781/16329 [48:41<1:27:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5781: train loss 1.91144. lr 5.547772e-04:  35%|███▌      | 5782/16329 [48:41<1:27:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5782: train loss 1.87917. lr 5.547620e-04:  35%|███▌      | 5782/16329 [48:42<1:27:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5782: train loss 1.87917. lr 5.547620e-04:  35%|███▌      | 5783/16329 [48:42<1:26:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5783: train loss 1.86825. lr 5.547467e-04:  35%|███▌      | 5783/16329 [48:42<1:26:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5783: train loss 1.86825. lr 5.547467e-04:  35%|███▌      | 5784/16329 [48:42<1:27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5784: train loss 1.92197. lr 5.547315e-04:  35%|███▌      | 5784/16329 [48:43<1:27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5784: train loss 1.92197. lr 5.547315e-04:  35%|███▌      | 5785/16329 [48:43<1:36:46,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5785: train loss 1.91365. lr 5.547162e-04:  35%|███▌      | 5785/16329 [48:44<1:36:46,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5785: train loss 1.91365. lr 5.547162e-04:  35%|███▌      | 5786/16329 [48:44<1:33:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5786: train loss 1.93825. lr 5.547010e-04:  35%|███▌      | 5786/16329 [48:44<1:33:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5786: train loss 1.93825. lr 5.547010e-04:  35%|███▌      | 5787/16329 [48:44<1:31:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5787: train loss 1.88637. lr 5.546857e-04:  35%|███▌      | 5787/16329 [48:45<1:31:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5787: train loss 1.88637. lr 5.546857e-04:  35%|███▌      | 5788/16329 [48:45<1:30:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5788: train loss 1.92714. lr 5.546705e-04:  35%|███▌      | 5788/16329 [48:45<1:30:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5788: train loss 1.92714. lr 5.546705e-04:  35%|███▌      | 5789/16329 [48:45<1:29:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5789: train loss 1.88160. lr 5.546552e-04:  35%|███▌      | 5789/16329 [48:46<1:29:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5789: train loss 1.88160. lr 5.546552e-04:  35%|███▌      | 5790/16329 [48:46<1:28:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5790: train loss 1.96154. lr 5.546400e-04:  35%|███▌      | 5790/16329 [48:46<1:28:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5790: train loss 1.96154. lr 5.546400e-04:  35%|███▌      | 5791/16329 [48:46<1:28:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5791: train loss 1.91400. lr 5.546247e-04:  35%|███▌      | 5791/16329 [48:47<1:28:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5791: train loss 1.91400. lr 5.546247e-04:  35%|███▌      | 5792/16329 [48:47<1:27:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5792: train loss 1.94182. lr 5.546094e-04:  35%|███▌      | 5792/16329 [48:47<1:27:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5792: train loss 1.94182. lr 5.546094e-04:  35%|███▌      | 5793/16329 [48:47<1:27:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5793: train loss 1.88759. lr 5.545942e-04:  35%|███▌      | 5793/16329 [48:48<1:27:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5793: train loss 1.88759. lr 5.545942e-04:  35%|███▌      | 5794/16329 [48:48<1:30:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5794: train loss 1.88832. lr 5.545789e-04:  35%|███▌      | 5794/16329 [48:48<1:30:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5794: train loss 1.88832. lr 5.545789e-04:  35%|███▌      | 5795/16329 [48:48<1:33:12,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5795: train loss 1.97015. lr 5.545636e-04:  35%|███▌      | 5795/16329 [48:49<1:33:12,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5795: train loss 1.97015. lr 5.545636e-04:  35%|███▌      | 5796/16329 [48:49<1:33:40,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5796: train loss 1.93964. lr 5.545484e-04:  35%|███▌      | 5796/16329 [48:49<1:33:40,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5796: train loss 1.93964. lr 5.545484e-04:  36%|███▌      | 5797/16329 [48:49<1:33:34,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5797: train loss 1.92505. lr 5.545331e-04:  36%|███▌      | 5797/16329 [48:50<1:33:34,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5797: train loss 1.92505. lr 5.545331e-04:  36%|███▌      | 5798/16329 [48:50<1:32:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5798: train loss 1.90773. lr 5.545178e-04:  36%|███▌      | 5798/16329 [48:50<1:32:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 5798: train loss 1.90773. lr 5.545178e-04:  36%|███▌      | 5799/16329 [48:50<1:31:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5799: train loss 1.87936. lr 5.545025e-04:  36%|███▌      | 5799/16329 [48:51<1:31:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5799: train loss 1.87936. lr 5.545025e-04:  36%|███▌      | 5800/16329 [48:51<1:31:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5800: train loss 1.86223. lr 5.544872e-04:  36%|███▌      | 5800/16329 [48:51<1:31:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5800: train loss 1.86223. lr 5.544872e-04:  36%|███▌      | 5801/16329 [48:51<1:29:47,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5801: train loss 1.90126. lr 5.544720e-04:  36%|███▌      | 5801/16329 [48:52<1:29:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5801: train loss 1.90126. lr 5.544720e-04:  36%|███▌      | 5802/16329 [48:52<1:28:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5802: train loss 1.90798. lr 5.544567e-04:  36%|███▌      | 5802/16329 [48:52<1:28:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5802: train loss 1.90798. lr 5.544567e-04:  36%|███▌      | 5803/16329 [48:52<1:28:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5803: train loss 1.90972. lr 5.544414e-04:  36%|███▌      | 5803/16329 [48:53<1:28:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5803: train loss 1.90972. lr 5.544414e-04:  36%|███▌      | 5804/16329 [48:53<1:27:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5804: train loss 1.90128. lr 5.544261e-04:  36%|███▌      | 5804/16329 [48:53<1:27:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5804: train loss 1.90128. lr 5.544261e-04:  36%|███▌      | 5805/16329 [48:53<1:27:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5805: train loss 1.90639. lr 5.544108e-04:  36%|███▌      | 5805/16329 [48:54<1:27:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5805: train loss 1.90639. lr 5.544108e-04:  36%|███▌      | 5806/16329 [48:54<1:27:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5806: train loss 1.84545. lr 5.543955e-04:  36%|███▌      | 5806/16329 [48:54<1:27:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5806: train loss 1.84545. lr 5.543955e-04:  36%|███▌      | 5807/16329 [48:54<1:27:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5807: train loss 1.84845. lr 5.543802e-04:  36%|███▌      | 5807/16329 [48:55<1:27:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5807: train loss 1.84845. lr 5.543802e-04:  36%|███▌      | 5808/16329 [48:55<1:27:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5808: train loss 1.87148. lr 5.543649e-04:  36%|███▌      | 5808/16329 [48:55<1:27:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5808: train loss 1.87148. lr 5.543649e-04:  36%|███▌      | 5809/16329 [48:55<1:27:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5809: train loss 1.92071. lr 5.543496e-04:  36%|███▌      | 5809/16329 [48:56<1:27:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5809: train loss 1.92071. lr 5.543496e-04:  36%|███▌      | 5810/16329 [48:56<1:41:48,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 5810: train loss 1.88845. lr 5.543343e-04:  36%|███▌      | 5810/16329 [48:57<1:41:48,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 5810: train loss 1.88845. lr 5.543343e-04:  36%|███▌      | 5811/16329 [48:57<1:37:23,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5811: train loss 1.90634. lr 5.543190e-04:  36%|███▌      | 5811/16329 [48:57<1:37:23,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5811: train loss 1.90634. lr 5.543190e-04:  36%|███▌      | 5812/16329 [48:57<1:34:03,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5812: train loss 1.88137. lr 5.543037e-04:  36%|███▌      | 5812/16329 [48:58<1:34:03,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5812: train loss 1.88137. lr 5.543037e-04:  36%|███▌      | 5813/16329 [48:58<1:31:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5813: train loss 1.90823. lr 5.542884e-04:  36%|███▌      | 5813/16329 [48:58<1:31:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5813: train loss 1.90823. lr 5.542884e-04:  36%|███▌      | 5814/16329 [48:58<1:30:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5814: train loss 1.87374. lr 5.542731e-04:  36%|███▌      | 5814/16329 [48:59<1:30:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5814: train loss 1.87374. lr 5.542731e-04:  36%|███▌      | 5815/16329 [48:59<1:28:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5815: train loss 1.88883. lr 5.542577e-04:  36%|███▌      | 5815/16329 [48:59<1:28:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5815: train loss 1.88883. lr 5.542577e-04:  36%|███▌      | 5816/16329 [48:59<1:28:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5816: train loss 1.90063. lr 5.542424e-04:  36%|███▌      | 5816/16329 [49:00<1:28:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5816: train loss 1.90063. lr 5.542424e-04:  36%|███▌      | 5817/16329 [49:00<1:27:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5817: train loss 1.88158. lr 5.542271e-04:  36%|███▌      | 5817/16329 [49:00<1:27:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5817: train loss 1.88158. lr 5.542271e-04:  36%|███▌      | 5818/16329 [49:00<1:27:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5818: train loss 1.94121. lr 5.542118e-04:  36%|███▌      | 5818/16329 [49:01<1:27:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5818: train loss 1.94121. lr 5.542118e-04:  36%|███▌      | 5819/16329 [49:01<1:27:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5819: train loss 1.87687. lr 5.541965e-04:  36%|███▌      | 5819/16329 [49:01<1:27:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5819: train loss 1.87687. lr 5.541965e-04:  36%|███▌      | 5820/16329 [49:01<1:27:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5820: train loss 1.92559. lr 5.541811e-04:  36%|███▌      | 5820/16329 [49:02<1:27:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5820: train loss 1.92559. lr 5.541811e-04:  36%|███▌      | 5821/16329 [49:02<1:27:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5821: train loss 1.87224. lr 5.541658e-04:  36%|███▌      | 5821/16329 [49:02<1:27:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5821: train loss 1.87224. lr 5.541658e-04:  36%|███▌      | 5822/16329 [49:02<1:27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5822: train loss 1.92845. lr 5.541505e-04:  36%|███▌      | 5822/16329 [49:02<1:27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5822: train loss 1.92845. lr 5.541505e-04:  36%|███▌      | 5823/16329 [49:03<1:27:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5823: train loss 1.86957. lr 5.541351e-04:  36%|███▌      | 5823/16329 [49:03<1:27:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5823: train loss 1.86957. lr 5.541351e-04:  36%|███▌      | 5824/16329 [49:03<1:27:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5824: train loss 1.87569. lr 5.541198e-04:  36%|███▌      | 5824/16329 [49:03<1:27:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5824: train loss 1.87569. lr 5.541198e-04:  36%|███▌      | 5825/16329 [49:03<1:27:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5825: train loss 1.91949. lr 5.541045e-04:  36%|███▌      | 5825/16329 [49:04<1:27:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5825: train loss 1.91949. lr 5.541045e-04:  36%|███▌      | 5826/16329 [49:04<1:27:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5826: train loss 1.87524. lr 5.540891e-04:  36%|███▌      | 5826/16329 [49:04<1:27:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5826: train loss 1.87524. lr 5.540891e-04:  36%|███▌      | 5827/16329 [49:04<1:26:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5827: train loss 1.86768. lr 5.540738e-04:  36%|███▌      | 5827/16329 [49:05<1:26:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5827: train loss 1.86768. lr 5.540738e-04:  36%|███▌      | 5828/16329 [49:05<1:27:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5828: train loss 1.88972. lr 5.540584e-04:  36%|███▌      | 5828/16329 [49:05<1:27:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5828: train loss 1.88972. lr 5.540584e-04:  36%|███▌      | 5829/16329 [49:05<1:27:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5829: train loss 1.86882. lr 5.540431e-04:  36%|███▌      | 5829/16329 [49:06<1:27:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5829: train loss 1.86882. lr 5.540431e-04:  36%|███▌      | 5830/16329 [49:06<1:27:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5830: train loss 1.89946. lr 5.540277e-04:  36%|███▌      | 5830/16329 [49:06<1:27:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5830: train loss 1.89946. lr 5.540277e-04:  36%|███▌      | 5831/16329 [49:06<1:27:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5831: train loss 1.84931. lr 5.540124e-04:  36%|███▌      | 5831/16329 [49:07<1:27:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5831: train loss 1.84931. lr 5.540124e-04:  36%|███▌      | 5832/16329 [49:07<1:27:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5832: train loss 1.89706. lr 5.539970e-04:  36%|███▌      | 5832/16329 [49:07<1:27:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5832: train loss 1.89706. lr 5.539970e-04:  36%|███▌      | 5833/16329 [49:07<1:27:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5833: train loss 1.87735. lr 5.539816e-04:  36%|███▌      | 5833/16329 [49:08<1:27:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5833: train loss 1.87735. lr 5.539816e-04:  36%|███▌      | 5834/16329 [49:08<1:27:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5834: train loss 1.88240. lr 5.539663e-04:  36%|███▌      | 5834/16329 [49:08<1:27:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5834: train loss 1.88240. lr 5.539663e-04:  36%|███▌      | 5835/16329 [49:08<1:27:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5835: train loss 1.87508. lr 5.539509e-04:  36%|███▌      | 5835/16329 [49:09<1:27:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5835: train loss 1.87508. lr 5.539509e-04:  36%|███▌      | 5836/16329 [49:09<1:26:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5836: train loss 1.87031. lr 5.539356e-04:  36%|███▌      | 5836/16329 [49:10<1:26:40,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5836: train loss 1.87031. lr 5.539356e-04:  36%|███▌      | 5837/16329 [49:10<1:39:19,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 5837: train loss 1.90576. lr 5.539202e-04:  36%|███▌      | 5837/16329 [49:10<1:39:19,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 5837: train loss 1.90576. lr 5.539202e-04:  36%|███▌      | 5838/16329 [49:10<1:35:24,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5838: train loss 1.85939. lr 5.539048e-04:  36%|███▌      | 5838/16329 [49:11<1:35:24,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5838: train loss 1.85939. lr 5.539048e-04:  36%|███▌      | 5839/16329 [49:11<1:33:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5839: train loss 1.90411. lr 5.538894e-04:  36%|███▌      | 5839/16329 [49:11<1:33:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5839: train loss 1.90411. lr 5.538894e-04:  36%|███▌      | 5840/16329 [49:11<1:31:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5840: train loss 1.90848. lr 5.538741e-04:  36%|███▌      | 5840/16329 [49:12<1:31:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 5840: train loss 1.90848. lr 5.538741e-04:  36%|███▌      | 5841/16329 [49:12<1:29:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5841: train loss 1.90228. lr 5.538587e-04:  36%|███▌      | 5841/16329 [49:12<1:29:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5841: train loss 1.90228. lr 5.538587e-04:  36%|███▌      | 5842/16329 [49:12<1:29:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5842: train loss 1.89467. lr 5.538433e-04:  36%|███▌      | 5842/16329 [49:13<1:29:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5842: train loss 1.89467. lr 5.538433e-04:  36%|███▌      | 5843/16329 [49:13<1:28:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5843: train loss 1.89631. lr 5.538279e-04:  36%|███▌      | 5843/16329 [49:13<1:28:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5843: train loss 1.89631. lr 5.538279e-04:  36%|███▌      | 5844/16329 [49:13<1:27:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5844: train loss 1.88475. lr 5.538125e-04:  36%|███▌      | 5844/16329 [49:14<1:27:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5844: train loss 1.88475. lr 5.538125e-04:  36%|███▌      | 5845/16329 [49:14<1:27:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5845: train loss 1.88516. lr 5.537972e-04:  36%|███▌      | 5845/16329 [49:14<1:27:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5845: train loss 1.88516. lr 5.537972e-04:  36%|███▌      | 5846/16329 [49:14<1:27:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5846: train loss 1.94223. lr 5.537818e-04:  36%|███▌      | 5846/16329 [49:15<1:27:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5846: train loss 1.94223. lr 5.537818e-04:  36%|███▌      | 5847/16329 [49:15<1:27:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5847: train loss 1.85553. lr 5.537664e-04:  36%|███▌      | 5847/16329 [49:15<1:27:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5847: train loss 1.85553. lr 5.537664e-04:  36%|███▌      | 5848/16329 [49:15<1:27:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5848: train loss 1.87640. lr 5.537510e-04:  36%|███▌      | 5848/16329 [49:16<1:27:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5848: train loss 1.87640. lr 5.537510e-04:  36%|███▌      | 5849/16329 [49:16<1:27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5849: train loss 1.93731. lr 5.537356e-04:  36%|███▌      | 5849/16329 [49:16<1:27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5849: train loss 1.93731. lr 5.537356e-04:  36%|███▌      | 5850/16329 [49:16<1:26:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5850: train loss 1.90105. lr 5.537202e-04:  36%|███▌      | 5850/16329 [49:17<1:26:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5850: train loss 1.90105. lr 5.537202e-04:  36%|███▌      | 5851/16329 [49:17<1:26:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5851: train loss 1.93220. lr 5.537048e-04:  36%|███▌      | 5851/16329 [49:17<1:26:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5851: train loss 1.93220. lr 5.537048e-04:  36%|███▌      | 5852/16329 [49:17<1:26:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5852: train loss 1.91442. lr 5.536894e-04:  36%|███▌      | 5852/16329 [49:18<1:26:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5852: train loss 1.91442. lr 5.536894e-04:  36%|███▌      | 5853/16329 [49:18<1:26:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5853: train loss 1.95129. lr 5.536740e-04:  36%|███▌      | 5853/16329 [49:18<1:26:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5853: train loss 1.95129. lr 5.536740e-04:  36%|███▌      | 5854/16329 [49:18<1:26:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5854: train loss 1.94657. lr 5.536586e-04:  36%|███▌      | 5854/16329 [49:19<1:26:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5854: train loss 1.94657. lr 5.536586e-04:  36%|███▌      | 5855/16329 [49:19<1:26:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5855: train loss 1.85512. lr 5.536432e-04:  36%|███▌      | 5855/16329 [49:19<1:26:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5855: train loss 1.85512. lr 5.536432e-04:  36%|███▌      | 5856/16329 [49:19<1:26:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5856: train loss 1.89257. lr 5.536277e-04:  36%|███▌      | 5856/16329 [49:20<1:26:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5856: train loss 1.89257. lr 5.536277e-04:  36%|███▌      | 5857/16329 [49:20<1:26:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5857: train loss 1.88002. lr 5.536123e-04:  36%|███▌      | 5857/16329 [49:20<1:26:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5857: train loss 1.88002. lr 5.536123e-04:  36%|███▌      | 5858/16329 [49:20<1:26:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5858: train loss 1.90878. lr 5.535969e-04:  36%|███▌      | 5858/16329 [49:21<1:26:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5858: train loss 1.90878. lr 5.535969e-04:  36%|███▌      | 5859/16329 [49:21<1:26:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5859: train loss 1.85599. lr 5.535815e-04:  36%|███▌      | 5859/16329 [49:21<1:26:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5859: train loss 1.85599. lr 5.535815e-04:  36%|███▌      | 5860/16329 [49:21<1:26:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5860: train loss 1.83570. lr 5.535661e-04:  36%|███▌      | 5860/16329 [49:22<1:26:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5860: train loss 1.83570. lr 5.535661e-04:  36%|███▌      | 5861/16329 [49:22<1:26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5861: train loss 1.91189. lr 5.535506e-04:  36%|███▌      | 5861/16329 [49:22<1:26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5861: train loss 1.91189. lr 5.535506e-04:  36%|███▌      | 5862/16329 [49:22<1:26:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5862: train loss 1.85372. lr 5.535352e-04:  36%|███▌      | 5862/16329 [49:23<1:26:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5862: train loss 1.85372. lr 5.535352e-04:  36%|███▌      | 5863/16329 [49:23<1:26:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5863: train loss 1.87577. lr 5.535198e-04:  36%|███▌      | 5863/16329 [49:23<1:26:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5863: train loss 1.87577. lr 5.535198e-04:  36%|███▌      | 5864/16329 [49:23<1:26:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5864: train loss 1.95668. lr 5.535044e-04:  36%|███▌      | 5864/16329 [49:24<1:26:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5864: train loss 1.95668. lr 5.535044e-04:  36%|███▌      | 5865/16329 [49:24<1:26:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5865: train loss 1.89614. lr 5.534889e-04:  36%|███▌      | 5865/16329 [49:24<1:26:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5865: train loss 1.89614. lr 5.534889e-04:  36%|███▌      | 5866/16329 [49:24<1:26:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5866: train loss 1.88314. lr 5.534735e-04:  36%|███▌      | 5866/16329 [49:25<1:26:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5866: train loss 1.88314. lr 5.534735e-04:  36%|███▌      | 5867/16329 [49:25<1:27:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5867: train loss 1.85355. lr 5.534580e-04:  36%|███▌      | 5867/16329 [49:25<1:27:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5867: train loss 1.85355. lr 5.534580e-04:  36%|███▌      | 5868/16329 [49:25<1:26:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5868: train loss 1.92333. lr 5.534426e-04:  36%|███▌      | 5868/16329 [49:26<1:26:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5868: train loss 1.92333. lr 5.534426e-04:  36%|███▌      | 5869/16329 [49:26<1:26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5869: train loss 1.91948. lr 5.534272e-04:  36%|███▌      | 5869/16329 [49:26<1:26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5869: train loss 1.91948. lr 5.534272e-04:  36%|███▌      | 5870/16329 [49:26<1:26:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5870: train loss 1.87916. lr 5.534117e-04:  36%|███▌      | 5870/16329 [49:27<1:26:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5870: train loss 1.87916. lr 5.534117e-04:  36%|███▌      | 5871/16329 [49:27<1:26:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5871: train loss 1.85807. lr 5.533963e-04:  36%|███▌      | 5871/16329 [49:27<1:26:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5871: train loss 1.85807. lr 5.533963e-04:  36%|███▌      | 5872/16329 [49:27<1:26:42,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5872: train loss 1.93762. lr 5.533808e-04:  36%|███▌      | 5872/16329 [49:28<1:26:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5872: train loss 1.93762. lr 5.533808e-04:  36%|███▌      | 5873/16329 [49:28<1:26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5873: train loss 1.86253. lr 5.533654e-04:  36%|███▌      | 5873/16329 [49:28<1:26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5873: train loss 1.86253. lr 5.533654e-04:  36%|███▌      | 5874/16329 [49:28<1:26:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5874: train loss 1.87318. lr 5.533499e-04:  36%|███▌      | 5874/16329 [49:29<1:26:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5874: train loss 1.87318. lr 5.533499e-04:  36%|███▌      | 5875/16329 [49:29<1:26:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5875: train loss 1.86418. lr 5.533345e-04:  36%|███▌      | 5875/16329 [49:29<1:26:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5875: train loss 1.86418. lr 5.533345e-04:  36%|███▌      | 5876/16329 [49:29<1:26:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5876: train loss 1.90143. lr 5.533190e-04:  36%|███▌      | 5876/16329 [49:30<1:26:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5876: train loss 1.90143. lr 5.533190e-04:  36%|███▌      | 5877/16329 [49:30<1:35:52,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5877: train loss 1.89166. lr 5.533035e-04:  36%|███▌      | 5877/16329 [49:30<1:35:52,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5877: train loss 1.89166. lr 5.533035e-04:  36%|███▌      | 5878/16329 [49:30<1:33:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5878: train loss 1.86231. lr 5.532881e-04:  36%|███▌      | 5878/16329 [49:31<1:33:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5878: train loss 1.86231. lr 5.532881e-04:  36%|███▌      | 5879/16329 [49:31<1:31:19,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5879: train loss 1.89735. lr 5.532726e-04:  36%|███▌      | 5879/16329 [49:31<1:31:19,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5879: train loss 1.89735. lr 5.532726e-04:  36%|███▌      | 5880/16329 [49:31<1:29:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5880: train loss 1.87777. lr 5.532571e-04:  36%|███▌      | 5880/16329 [49:32<1:29:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5880: train loss 1.87777. lr 5.532571e-04:  36%|███▌      | 5881/16329 [49:32<1:29:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5881: train loss 1.91385. lr 5.532417e-04:  36%|███▌      | 5881/16329 [49:32<1:29:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5881: train loss 1.91385. lr 5.532417e-04:  36%|███▌      | 5882/16329 [49:32<1:28:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5882: train loss 1.91439. lr 5.532262e-04:  36%|███▌      | 5882/16329 [49:33<1:28:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5882: train loss 1.91439. lr 5.532262e-04:  36%|███▌      | 5883/16329 [49:33<1:27:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5883: train loss 1.89806. lr 5.532107e-04:  36%|███▌      | 5883/16329 [49:33<1:27:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5883: train loss 1.89806. lr 5.532107e-04:  36%|███▌      | 5884/16329 [49:33<1:27:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5884: train loss 1.85834. lr 5.531952e-04:  36%|███▌      | 5884/16329 [49:34<1:27:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5884: train loss 1.85834. lr 5.531952e-04:  36%|███▌      | 5885/16329 [49:34<1:27:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5885: train loss 1.89057. lr 5.531797e-04:  36%|███▌      | 5885/16329 [49:34<1:27:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5885: train loss 1.89057. lr 5.531797e-04:  36%|███▌      | 5886/16329 [49:34<1:27:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5886: train loss 1.91593. lr 5.531643e-04:  36%|███▌      | 5886/16329 [49:35<1:27:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5886: train loss 1.91593. lr 5.531643e-04:  36%|███▌      | 5887/16329 [49:35<1:26:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5887: train loss 1.85006. lr 5.531488e-04:  36%|███▌      | 5887/16329 [49:35<1:26:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5887: train loss 1.85006. lr 5.531488e-04:  36%|███▌      | 5888/16329 [49:35<1:26:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5888: train loss 1.88566. lr 5.531333e-04:  36%|███▌      | 5888/16329 [49:36<1:26:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5888: train loss 1.88566. lr 5.531333e-04:  36%|███▌      | 5889/16329 [49:36<1:26:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5889: train loss 1.90002. lr 5.531178e-04:  36%|███▌      | 5889/16329 [49:36<1:26:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5889: train loss 1.90002. lr 5.531178e-04:  36%|███▌      | 5890/16329 [49:36<1:26:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5890: train loss 1.88902. lr 5.531023e-04:  36%|███▌      | 5890/16329 [49:37<1:26:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5890: train loss 1.88902. lr 5.531023e-04:  36%|███▌      | 5891/16329 [49:37<1:26:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5891: train loss 1.82567. lr 5.530868e-04:  36%|███▌      | 5891/16329 [49:37<1:26:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5891: train loss 1.82567. lr 5.530868e-04:  36%|███▌      | 5892/16329 [49:37<1:26:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5892: train loss 1.92506. lr 5.530713e-04:  36%|███▌      | 5892/16329 [49:38<1:26:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5892: train loss 1.92506. lr 5.530713e-04:  36%|███▌      | 5893/16329 [49:38<1:26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5893: train loss 1.83035. lr 5.530558e-04:  36%|███▌      | 5893/16329 [49:38<1:26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5893: train loss 1.83035. lr 5.530558e-04:  36%|███▌      | 5894/16329 [49:38<1:26:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5894: train loss 1.84413. lr 5.530403e-04:  36%|███▌      | 5894/16329 [49:39<1:26:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5894: train loss 1.84413. lr 5.530403e-04:  36%|███▌      | 5895/16329 [49:39<1:26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5895: train loss 1.86964. lr 5.530248e-04:  36%|███▌      | 5895/16329 [49:39<1:26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5895: train loss 1.86964. lr 5.530248e-04:  36%|███▌      | 5896/16329 [49:39<1:26:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5896: train loss 1.87586. lr 5.530093e-04:  36%|███▌      | 5896/16329 [49:40<1:26:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5896: train loss 1.87586. lr 5.530093e-04:  36%|███▌      | 5897/16329 [49:40<1:27:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5897: train loss 1.83601. lr 5.529938e-04:  36%|███▌      | 5897/16329 [49:40<1:27:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5897: train loss 1.83601. lr 5.529938e-04:  36%|███▌      | 5898/16329 [49:40<1:27:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5898: train loss 1.85821. lr 5.529783e-04:  36%|███▌      | 5898/16329 [49:41<1:27:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5898: train loss 1.85821. lr 5.529783e-04:  36%|███▌      | 5899/16329 [49:41<1:27:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5899: train loss 1.85534. lr 5.529628e-04:  36%|███▌      | 5899/16329 [49:41<1:27:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5899: train loss 1.85534. lr 5.529628e-04:  36%|███▌      | 5900/16329 [49:41<1:26:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5900: train loss 1.88362. lr 5.529473e-04:  36%|███▌      | 5900/16329 [49:42<1:26:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5900: train loss 1.88362. lr 5.529473e-04:  36%|███▌      | 5901/16329 [49:42<1:26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5901: train loss 1.88399. lr 5.529317e-04:  36%|███▌      | 5901/16329 [49:42<1:26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5901: train loss 1.88399. lr 5.529317e-04:  36%|███▌      | 5902/16329 [49:42<1:26:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5902: train loss 1.91068. lr 5.529162e-04:  36%|███▌      | 5902/16329 [49:43<1:26:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5902: train loss 1.91068. lr 5.529162e-04:  36%|███▌      | 5903/16329 [49:43<1:26:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5903: train loss 1.86636. lr 5.529007e-04:  36%|███▌      | 5903/16329 [49:43<1:26:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5903: train loss 1.86636. lr 5.529007e-04:  36%|███▌      | 5904/16329 [49:43<1:26:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5904: train loss 1.89011. lr 5.528852e-04:  36%|███▌      | 5904/16329 [49:44<1:26:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5904: train loss 1.89011. lr 5.528852e-04:  36%|███▌      | 5905/16329 [49:44<1:26:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5905: train loss 1.88750. lr 5.528696e-04:  36%|███▌      | 5905/16329 [49:44<1:26:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5905: train loss 1.88750. lr 5.528696e-04:  36%|███▌      | 5906/16329 [49:44<1:26:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5906: train loss 1.90093. lr 5.528541e-04:  36%|███▌      | 5906/16329 [49:45<1:26:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5906: train loss 1.90093. lr 5.528541e-04:  36%|███▌      | 5907/16329 [49:45<1:26:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5907: train loss 1.85297. lr 5.528386e-04:  36%|███▌      | 5907/16329 [49:45<1:26:25,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5907: train loss 1.85297. lr 5.528386e-04:  36%|███▌      | 5908/16329 [49:45<1:26:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5908: train loss 1.94361. lr 5.528230e-04:  36%|███▌      | 5908/16329 [49:46<1:26:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5908: train loss 1.94361. lr 5.528230e-04:  36%|███▌      | 5909/16329 [49:46<1:27:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5909: train loss 1.81251. lr 5.528075e-04:  36%|███▌      | 5909/16329 [49:46<1:27:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5909: train loss 1.81251. lr 5.528075e-04:  36%|███▌      | 5910/16329 [49:46<1:26:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5910: train loss 1.82180. lr 5.527920e-04:  36%|███▌      | 5910/16329 [49:47<1:26:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5910: train loss 1.82180. lr 5.527920e-04:  36%|███▌      | 5911/16329 [49:47<1:26:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5911: train loss 1.85736. lr 5.527764e-04:  36%|███▌      | 5911/16329 [49:47<1:26:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5911: train loss 1.85736. lr 5.527764e-04:  36%|███▌      | 5912/16329 [49:47<1:36:01,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5912: train loss 1.89276. lr 5.527609e-04:  36%|███▌      | 5912/16329 [49:48<1:36:01,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5912: train loss 1.89276. lr 5.527609e-04:  36%|███▌      | 5913/16329 [49:48<1:32:42,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5913: train loss 1.86967. lr 5.527453e-04:  36%|███▌      | 5913/16329 [49:48<1:32:42,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5913: train loss 1.86967. lr 5.527453e-04:  36%|███▌      | 5914/16329 [49:48<1:31:00,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5914: train loss 1.86293. lr 5.527298e-04:  36%|███▌      | 5914/16329 [49:49<1:31:00,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5914: train loss 1.86293. lr 5.527298e-04:  36%|███▌      | 5915/16329 [49:49<1:29:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5915: train loss 1.85436. lr 5.527142e-04:  36%|███▌      | 5915/16329 [49:49<1:29:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 5915: train loss 1.85436. lr 5.527142e-04:  36%|███▌      | 5916/16329 [49:49<1:28:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5916: train loss 1.85021. lr 5.526987e-04:  36%|███▌      | 5916/16329 [49:50<1:28:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5916: train loss 1.85021. lr 5.526987e-04:  36%|███▌      | 5917/16329 [49:50<1:28:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5917: train loss 1.87593. lr 5.526831e-04:  36%|███▌      | 5917/16329 [49:50<1:28:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5917: train loss 1.87593. lr 5.526831e-04:  36%|███▌      | 5918/16329 [49:50<1:27:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5918: train loss 1.82283. lr 5.526676e-04:  36%|███▌      | 5918/16329 [49:51<1:27:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5918: train loss 1.82283. lr 5.526676e-04:  36%|███▌      | 5919/16329 [49:51<1:27:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5919: train loss 1.89243. lr 5.526520e-04:  36%|███▌      | 5919/16329 [49:51<1:27:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5919: train loss 1.89243. lr 5.526520e-04:  36%|███▋      | 5920/16329 [49:51<1:26:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5920: train loss 1.86217. lr 5.526364e-04:  36%|███▋      | 5920/16329 [49:52<1:26:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5920: train loss 1.86217. lr 5.526364e-04:  36%|███▋      | 5921/16329 [49:52<1:26:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5921: train loss 1.82646. lr 5.526209e-04:  36%|███▋      | 5921/16329 [49:52<1:26:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5921: train loss 1.82646. lr 5.526209e-04:  36%|███▋      | 5922/16329 [49:52<1:26:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5922: train loss 1.85762. lr 5.526053e-04:  36%|███▋      | 5922/16329 [49:53<1:26:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5922: train loss 1.85762. lr 5.526053e-04:  36%|███▋      | 5923/16329 [49:53<1:26:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5923: train loss 1.92638. lr 5.525897e-04:  36%|███▋      | 5923/16329 [49:53<1:26:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5923: train loss 1.92638. lr 5.525897e-04:  36%|███▋      | 5924/16329 [49:53<1:26:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5924: train loss 1.84896. lr 5.525742e-04:  36%|███▋      | 5924/16329 [49:54<1:26:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5924: train loss 1.84896. lr 5.525742e-04:  36%|███▋      | 5925/16329 [49:54<1:26:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5925: train loss 1.86179. lr 5.525586e-04:  36%|███▋      | 5925/16329 [49:54<1:26:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5925: train loss 1.86179. lr 5.525586e-04:  36%|███▋      | 5926/16329 [49:54<1:26:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5926: train loss 1.87478. lr 5.525430e-04:  36%|███▋      | 5926/16329 [49:55<1:26:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5926: train loss 1.87478. lr 5.525430e-04:  36%|███▋      | 5927/16329 [49:55<1:26:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5927: train loss 1.87879. lr 5.525274e-04:  36%|███▋      | 5927/16329 [49:55<1:26:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5927: train loss 1.87879. lr 5.525274e-04:  36%|███▋      | 5928/16329 [49:55<1:26:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5928: train loss 1.83075. lr 5.525119e-04:  36%|███▋      | 5928/16329 [49:56<1:26:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5928: train loss 1.83075. lr 5.525119e-04:  36%|███▋      | 5929/16329 [49:56<1:26:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5929: train loss 1.90173. lr 5.524963e-04:  36%|███▋      | 5929/16329 [49:56<1:26:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5929: train loss 1.90173. lr 5.524963e-04:  36%|███▋      | 5930/16329 [49:56<1:26:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5930: train loss 1.86024. lr 5.524807e-04:  36%|███▋      | 5930/16329 [49:57<1:26:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5930: train loss 1.86024. lr 5.524807e-04:  36%|███▋      | 5931/16329 [49:57<1:26:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5931: train loss 1.87990. lr 5.524651e-04:  36%|███▋      | 5931/16329 [49:57<1:26:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5931: train loss 1.87990. lr 5.524651e-04:  36%|███▋      | 5932/16329 [49:57<1:25:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5932: train loss 1.86663. lr 5.524495e-04:  36%|███▋      | 5932/16329 [49:58<1:25:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5932: train loss 1.86663. lr 5.524495e-04:  36%|███▋      | 5933/16329 [49:58<1:26:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5933: train loss 1.86323. lr 5.524339e-04:  36%|███▋      | 5933/16329 [49:58<1:26:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5933: train loss 1.86323. lr 5.524339e-04:  36%|███▋      | 5934/16329 [49:58<1:25:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5934: train loss 1.85988. lr 5.524183e-04:  36%|███▋      | 5934/16329 [49:59<1:25:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5934: train loss 1.85988. lr 5.524183e-04:  36%|███▋      | 5935/16329 [49:59<1:26:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5935: train loss 1.90188. lr 5.524027e-04:  36%|███▋      | 5935/16329 [49:59<1:26:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5935: train loss 1.90188. lr 5.524027e-04:  36%|███▋      | 5936/16329 [49:59<1:26:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5936: train loss 1.91431. lr 5.523871e-04:  36%|███▋      | 5936/16329 [50:00<1:26:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5936: train loss 1.91431. lr 5.523871e-04:  36%|███▋      | 5937/16329 [50:00<1:41:11,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 5937: train loss 1.84913. lr 5.523715e-04:  36%|███▋      | 5937/16329 [50:01<1:41:11,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 5937: train loss 1.84913. lr 5.523715e-04:  36%|███▋      | 5938/16329 [50:01<1:36:11,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5938: train loss 1.85817. lr 5.523559e-04:  36%|███▋      | 5938/16329 [50:01<1:36:11,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 5938: train loss 1.85817. lr 5.523559e-04:  36%|███▋      | 5939/16329 [50:01<1:35:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5939: train loss 1.86339. lr 5.523403e-04:  36%|███▋      | 5939/16329 [50:02<1:35:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 5939: train loss 1.86339. lr 5.523403e-04:  36%|███▋      | 5940/16329 [50:02<1:34:22,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5940: train loss 1.92741. lr 5.523247e-04:  36%|███▋      | 5940/16329 [50:02<1:34:22,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 5940: train loss 1.92741. lr 5.523247e-04:  36%|███▋      | 5941/16329 [50:02<1:33:08,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5941: train loss 1.90324. lr 5.523091e-04:  36%|███▋      | 5941/16329 [50:03<1:33:08,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 5941: train loss 1.90324. lr 5.523091e-04:  36%|███▋      | 5942/16329 [50:03<1:32:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5942: train loss 1.87085. lr 5.522935e-04:  36%|███▋      | 5942/16329 [50:03<1:32:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 5942: train loss 1.87085. lr 5.522935e-04:  36%|███▋      | 5943/16329 [50:03<1:30:43,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5943: train loss 1.84418. lr 5.522779e-04:  36%|███▋      | 5943/16329 [50:04<1:30:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5943: train loss 1.84418. lr 5.522779e-04:  36%|███▋      | 5944/16329 [50:04<1:29:47,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5944: train loss 1.89284. lr 5.522622e-04:  36%|███▋      | 5944/16329 [50:04<1:29:47,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5944: train loss 1.89284. lr 5.522622e-04:  36%|███▋      | 5945/16329 [50:04<1:28:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5945: train loss 1.85495. lr 5.522466e-04:  36%|███▋      | 5945/16329 [50:05<1:28:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5945: train loss 1.85495. lr 5.522466e-04:  36%|███▋      | 5946/16329 [50:05<1:27:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5946: train loss 1.84134. lr 5.522310e-04:  36%|███▋      | 5946/16329 [50:05<1:27:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5946: train loss 1.84134. lr 5.522310e-04:  36%|███▋      | 5947/16329 [50:05<1:27:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5947: train loss 1.86489. lr 5.522154e-04:  36%|███▋      | 5947/16329 [50:06<1:27:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5947: train loss 1.86489. lr 5.522154e-04:  36%|███▋      | 5948/16329 [50:06<1:26:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5948: train loss 1.91461. lr 5.521997e-04:  36%|███▋      | 5948/16329 [50:06<1:26:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5948: train loss 1.91461. lr 5.521997e-04:  36%|███▋      | 5949/16329 [50:06<1:26:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5949: train loss 1.83179. lr 5.521841e-04:  36%|███▋      | 5949/16329 [50:07<1:26:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5949: train loss 1.83179. lr 5.521841e-04:  36%|███▋      | 5950/16329 [50:07<1:26:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5950: train loss 1.87342. lr 5.521685e-04:  36%|███▋      | 5950/16329 [50:07<1:26:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5950: train loss 1.87342. lr 5.521685e-04:  36%|███▋      | 5951/16329 [50:07<1:26:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5951: train loss 1.86108. lr 5.521528e-04:  36%|███▋      | 5951/16329 [50:08<1:26:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5951: train loss 1.86108. lr 5.521528e-04:  36%|███▋      | 5952/16329 [50:08<1:26:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5952: train loss 1.90698. lr 5.521372e-04:  36%|███▋      | 5952/16329 [50:08<1:26:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5952: train loss 1.90698. lr 5.521372e-04:  36%|███▋      | 5953/16329 [50:08<1:26:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5953: train loss 1.89515. lr 5.521216e-04:  36%|███▋      | 5953/16329 [50:09<1:26:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5953: train loss 1.89515. lr 5.521216e-04:  36%|███▋      | 5954/16329 [50:09<1:26:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5954: train loss 1.85433. lr 5.521059e-04:  36%|███▋      | 5954/16329 [50:09<1:26:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5954: train loss 1.85433. lr 5.521059e-04:  36%|███▋      | 5955/16329 [50:09<1:26:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5955: train loss 1.87947. lr 5.520903e-04:  36%|███▋      | 5955/16329 [50:10<1:26:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5955: train loss 1.87947. lr 5.520903e-04:  36%|███▋      | 5956/16329 [50:10<1:26:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5956: train loss 1.89035. lr 5.520746e-04:  36%|███▋      | 5956/16329 [50:10<1:26:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5956: train loss 1.89035. lr 5.520746e-04:  36%|███▋      | 5957/16329 [50:10<1:26:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5957: train loss 1.85962. lr 5.520590e-04:  36%|███▋      | 5957/16329 [50:11<1:26:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5957: train loss 1.85962. lr 5.520590e-04:  36%|███▋      | 5958/16329 [50:11<1:26:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5958: train loss 1.82119. lr 5.520433e-04:  36%|███▋      | 5958/16329 [50:11<1:26:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5958: train loss 1.82119. lr 5.520433e-04:  36%|███▋      | 5959/16329 [50:11<1:26:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5959: train loss 1.89241. lr 5.520277e-04:  36%|███▋      | 5959/16329 [50:12<1:26:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5959: train loss 1.89241. lr 5.520277e-04:  36%|███▋      | 5960/16329 [50:12<1:25:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5960: train loss 1.87679. lr 5.520120e-04:  36%|███▋      | 5960/16329 [50:12<1:25:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5960: train loss 1.87679. lr 5.520120e-04:  37%|███▋      | 5961/16329 [50:12<1:25:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5961: train loss 1.88787. lr 5.519964e-04:  37%|███▋      | 5961/16329 [50:13<1:25:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5961: train loss 1.88787. lr 5.519964e-04:  37%|███▋      | 5962/16329 [50:13<1:25:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5962: train loss 1.88409. lr 5.519807e-04:  37%|███▋      | 5962/16329 [50:13<1:25:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5962: train loss 1.88409. lr 5.519807e-04:  37%|███▋      | 5963/16329 [50:13<1:25:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5963: train loss 1.87184. lr 5.519650e-04:  37%|███▋      | 5963/16329 [50:14<1:25:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5963: train loss 1.87184. lr 5.519650e-04:  37%|███▋      | 5964/16329 [50:14<1:39:41,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 5964: train loss 1.90456. lr 5.519494e-04:  37%|███▋      | 5964/16329 [50:14<1:39:41,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 5964: train loss 1.90456. lr 5.519494e-04:  37%|███▋      | 5965/16329 [50:14<1:35:30,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5965: train loss 1.95633. lr 5.519337e-04:  37%|███▋      | 5965/16329 [50:15<1:35:30,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 5965: train loss 1.95633. lr 5.519337e-04:  37%|███▋      | 5966/16329 [50:15<1:32:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5966: train loss 1.86651. lr 5.519180e-04:  37%|███▋      | 5966/16329 [50:15<1:32:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 5966: train loss 1.86651. lr 5.519180e-04:  37%|███▋      | 5967/16329 [50:15<1:30:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5967: train loss 1.87126. lr 5.519024e-04:  37%|███▋      | 5967/16329 [50:16<1:30:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 5967: train loss 1.87126. lr 5.519024e-04:  37%|███▋      | 5968/16329 [50:16<1:29:17,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5968: train loss 1.86675. lr 5.518867e-04:  37%|███▋      | 5968/16329 [50:16<1:29:17,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 5968: train loss 1.86675. lr 5.518867e-04:  37%|███▋      | 5969/16329 [50:16<1:28:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5969: train loss 1.84601. lr 5.518710e-04:  37%|███▋      | 5969/16329 [50:17<1:28:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5969: train loss 1.84601. lr 5.518710e-04:  37%|███▋      | 5970/16329 [50:17<1:27:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5970: train loss 1.82756. lr 5.518553e-04:  37%|███▋      | 5970/16329 [50:17<1:27:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5970: train loss 1.82756. lr 5.518553e-04:  37%|███▋      | 5971/16329 [50:17<1:26:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5971: train loss 1.88386. lr 5.518396e-04:  37%|███▋      | 5971/16329 [50:18<1:26:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 5971: train loss 1.88386. lr 5.518396e-04:  37%|███▋      | 5972/16329 [50:18<1:26:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5972: train loss 1.85782. lr 5.518240e-04:  37%|███▋      | 5972/16329 [50:18<1:26:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5972: train loss 1.85782. lr 5.518240e-04:  37%|███▋      | 5973/16329 [50:18<1:26:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5973: train loss 1.84827. lr 5.518083e-04:  37%|███▋      | 5973/16329 [50:19<1:26:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5973: train loss 1.84827. lr 5.518083e-04:  37%|███▋      | 5974/16329 [50:19<1:26:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5974: train loss 1.85106. lr 5.517926e-04:  37%|███▋      | 5974/16329 [50:19<1:26:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5974: train loss 1.85106. lr 5.517926e-04:  37%|███▋      | 5975/16329 [50:19<1:25:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5975: train loss 1.90515. lr 5.517769e-04:  37%|███▋      | 5975/16329 [50:20<1:25:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5975: train loss 1.90515. lr 5.517769e-04:  37%|███▋      | 5976/16329 [50:20<1:25:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5976: train loss 1.90751. lr 5.517612e-04:  37%|███▋      | 5976/16329 [50:20<1:25:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5976: train loss 1.90751. lr 5.517612e-04:  37%|███▋      | 5977/16329 [50:20<1:25:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5977: train loss 1.85995. lr 5.517455e-04:  37%|███▋      | 5977/16329 [50:21<1:25:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5977: train loss 1.85995. lr 5.517455e-04:  37%|███▋      | 5978/16329 [50:21<1:25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5978: train loss 1.88668. lr 5.517298e-04:  37%|███▋      | 5978/16329 [50:21<1:25:22,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 5978: train loss 1.88668. lr 5.517298e-04:  37%|███▋      | 5979/16329 [50:21<1:25:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5979: train loss 1.86615. lr 5.517141e-04:  37%|███▋      | 5979/16329 [50:22<1:25:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5979: train loss 1.86615. lr 5.517141e-04:  37%|███▋      | 5980/16329 [50:22<1:27:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5980: train loss 1.89143. lr 5.516984e-04:  37%|███▋      | 5980/16329 [50:22<1:27:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5980: train loss 1.89143. lr 5.516984e-04:  37%|███▋      | 5981/16329 [50:22<1:28:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5981: train loss 1.84691. lr 5.516827e-04:  37%|███▋      | 5981/16329 [50:23<1:28:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5981: train loss 1.84691. lr 5.516827e-04:  37%|███▋      | 5982/16329 [50:23<1:28:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5982: train loss 1.84919. lr 5.516670e-04:  37%|███▋      | 5982/16329 [50:23<1:28:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5982: train loss 1.84919. lr 5.516670e-04:  37%|███▋      | 5983/16329 [50:23<1:28:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5983: train loss 1.78504. lr 5.516513e-04:  37%|███▋      | 5983/16329 [50:24<1:28:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 5983: train loss 1.78504. lr 5.516513e-04:  37%|███▋      | 5984/16329 [50:24<1:28:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5984: train loss 1.90698. lr 5.516356e-04:  37%|███▋      | 5984/16329 [50:24<1:28:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 5984: train loss 1.90698. lr 5.516356e-04:  37%|███▋      | 5985/16329 [50:24<1:27:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5985: train loss 1.87125. lr 5.516198e-04:  37%|███▋      | 5985/16329 [50:25<1:27:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 5985: train loss 1.87125. lr 5.516198e-04:  37%|███▋      | 5986/16329 [50:25<1:27:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5986: train loss 1.82010. lr 5.516041e-04:  37%|███▋      | 5986/16329 [50:25<1:27:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5986: train loss 1.82010. lr 5.516041e-04:  37%|███▋      | 5987/16329 [50:25<1:26:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5987: train loss 1.87050. lr 5.515884e-04:  37%|███▋      | 5987/16329 [50:26<1:26:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 5987: train loss 1.87050. lr 5.515884e-04:  37%|███▋      | 5988/16329 [50:26<1:26:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5988: train loss 1.90784. lr 5.515727e-04:  37%|███▋      | 5988/16329 [50:26<1:26:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5988: train loss 1.90784. lr 5.515727e-04:  37%|███▋      | 5989/16329 [50:26<1:26:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5989: train loss 1.86958. lr 5.515570e-04:  37%|███▋      | 5989/16329 [50:27<1:26:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 5989: train loss 1.86958. lr 5.515570e-04:  37%|███▋      | 5990/16329 [50:27<1:25:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5990: train loss 1.90414. lr 5.515412e-04:  37%|███▋      | 5990/16329 [50:27<1:25:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 5990: train loss 1.90414. lr 5.515412e-04:  37%|███▋      | 5991/16329 [50:27<1:25:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5991: train loss 1.86807. lr 5.515255e-04:  37%|███▋      | 5991/16329 [50:28<1:25:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5991: train loss 1.86807. lr 5.515255e-04:  37%|███▋      | 5992/16329 [50:28<1:25:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5992: train loss 1.82998. lr 5.515098e-04:  37%|███▋      | 5992/16329 [50:28<1:25:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5992: train loss 1.82998. lr 5.515098e-04:  37%|███▋      | 5993/16329 [50:28<1:25:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5993: train loss 1.86636. lr 5.514940e-04:  37%|███▋      | 5993/16329 [50:29<1:25:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5993: train loss 1.86636. lr 5.514940e-04:  37%|███▋      | 5994/16329 [50:29<1:25:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5994: train loss 1.88629. lr 5.514783e-04:  37%|███▋      | 5994/16329 [50:29<1:25:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5994: train loss 1.88629. lr 5.514783e-04:  37%|███▋      | 5995/16329 [50:29<1:25:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5995: train loss 1.87343. lr 5.514626e-04:  37%|███▋      | 5995/16329 [50:30<1:25:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5995: train loss 1.87343. lr 5.514626e-04:  37%|███▋      | 5996/16329 [50:30<1:25:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5996: train loss 1.88879. lr 5.514468e-04:  37%|███▋      | 5996/16329 [50:30<1:25:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5996: train loss 1.88879. lr 5.514468e-04:  37%|███▋      | 5997/16329 [50:30<1:25:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5997: train loss 1.86554. lr 5.514311e-04:  37%|███▋      | 5997/16329 [50:31<1:25:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5997: train loss 1.86554. lr 5.514311e-04:  37%|███▋      | 5998/16329 [50:31<1:25:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5998: train loss 1.86214. lr 5.514153e-04:  37%|███▋      | 5998/16329 [50:31<1:25:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5998: train loss 1.86214. lr 5.514153e-04:  37%|███▋      | 5999/16329 [50:31<1:25:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5999: train loss 1.88648. lr 5.513996e-04:  37%|███▋      | 5999/16329 [50:32<1:25:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 5999: train loss 1.88648. lr 5.513996e-04:  37%|███▋      | 6000/16329 [50:32<1:25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6000: train loss 1.83201. lr 5.513839e-04:  37%|███▋      | 6000/16329 [50:32<1:25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6000: train loss 1.83201. lr 5.513839e-04:  37%|███▋      | 6001/16329 [50:32<1:25:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6001: train loss 1.88918. lr 5.513681e-04:  37%|███▋      | 6001/16329 [50:33<1:25:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6001: train loss 1.88918. lr 5.513681e-04:  37%|███▋      | 6002/16329 [50:33<1:25:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6002: train loss 1.89438. lr 5.513523e-04:  37%|███▋      | 6002/16329 [50:33<1:25:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6002: train loss 1.89438. lr 5.513523e-04:  37%|███▋      | 6003/16329 [50:33<1:25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6003: train loss 1.85331. lr 5.513366e-04:  37%|███▋      | 6003/16329 [50:34<1:25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6003: train loss 1.85331. lr 5.513366e-04:  37%|███▋      | 6004/16329 [50:34<1:35:01,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6004: train loss 1.88307. lr 5.513208e-04:  37%|███▋      | 6004/16329 [50:35<1:35:01,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6004: train loss 1.88307. lr 5.513208e-04:  37%|███▋      | 6005/16329 [50:35<1:32:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6005: train loss 1.88778. lr 5.513051e-04:  37%|███▋      | 6005/16329 [50:35<1:32:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6005: train loss 1.88778. lr 5.513051e-04:  37%|███▋      | 6006/16329 [50:35<1:30:11,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6006: train loss 1.87719. lr 5.512893e-04:  37%|███▋      | 6006/16329 [50:36<1:30:11,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6006: train loss 1.87719. lr 5.512893e-04:  37%|███▋      | 6007/16329 [50:36<1:28:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6007: train loss 1.86871. lr 5.512735e-04:  37%|███▋      | 6007/16329 [50:36<1:28:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6007: train loss 1.86871. lr 5.512735e-04:  37%|███▋      | 6008/16329 [50:36<1:27:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6008: train loss 1.89758. lr 5.512578e-04:  37%|███▋      | 6008/16329 [50:37<1:27:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6008: train loss 1.89758. lr 5.512578e-04:  37%|███▋      | 6009/16329 [50:37<1:27:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6009: train loss 1.81268. lr 5.512420e-04:  37%|███▋      | 6009/16329 [50:37<1:27:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6009: train loss 1.81268. lr 5.512420e-04:  37%|███▋      | 6010/16329 [50:37<1:26:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6010: train loss 1.88820. lr 5.512262e-04:  37%|███▋      | 6010/16329 [50:38<1:26:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6010: train loss 1.88820. lr 5.512262e-04:  37%|███▋      | 6011/16329 [50:38<1:26:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6011: train loss 1.87532. lr 5.512105e-04:  37%|███▋      | 6011/16329 [50:38<1:26:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6011: train loss 1.87532. lr 5.512105e-04:  37%|███▋      | 6012/16329 [50:38<1:25:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6012: train loss 1.85041. lr 5.511947e-04:  37%|███▋      | 6012/16329 [50:39<1:25:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6012: train loss 1.85041. lr 5.511947e-04:  37%|███▋      | 6013/16329 [50:39<1:25:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6013: train loss 1.84311. lr 5.511789e-04:  37%|███▋      | 6013/16329 [50:39<1:25:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6013: train loss 1.84311. lr 5.511789e-04:  37%|███▋      | 6014/16329 [50:39<1:25:27,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6014: train loss 1.82686. lr 5.511631e-04:  37%|███▋      | 6014/16329 [50:40<1:25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6014: train loss 1.82686. lr 5.511631e-04:  37%|███▋      | 6015/16329 [50:40<1:25:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6015: train loss 1.89673. lr 5.511473e-04:  37%|███▋      | 6015/16329 [50:40<1:25:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6015: train loss 1.89673. lr 5.511473e-04:  37%|███▋      | 6016/16329 [50:40<1:25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6016: train loss 1.85224. lr 5.511315e-04:  37%|███▋      | 6016/16329 [50:41<1:25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6016: train loss 1.85224. lr 5.511315e-04:  37%|███▋      | 6017/16329 [50:41<1:25:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6017: train loss 1.89679. lr 5.511158e-04:  37%|███▋      | 6017/16329 [50:41<1:25:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6017: train loss 1.89679. lr 5.511158e-04:  37%|███▋      | 6018/16329 [50:41<1:25:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6018: train loss 1.80809. lr 5.511000e-04:  37%|███▋      | 6018/16329 [50:42<1:25:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6018: train loss 1.80809. lr 5.511000e-04:  37%|███▋      | 6019/16329 [50:42<1:25:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6019: train loss 1.84602. lr 5.510842e-04:  37%|███▋      | 6019/16329 [50:42<1:25:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6019: train loss 1.84602. lr 5.510842e-04:  37%|███▋      | 6020/16329 [50:42<1:25:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6020: train loss 1.75754. lr 5.510684e-04:  37%|███▋      | 6020/16329 [50:42<1:25:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6020: train loss 1.75754. lr 5.510684e-04:  37%|███▋      | 6021/16329 [50:43<1:25:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6021: train loss 1.88242. lr 5.510526e-04:  37%|███▋      | 6021/16329 [50:43<1:25:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6021: train loss 1.88242. lr 5.510526e-04:  37%|███▋      | 6022/16329 [50:43<1:25:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6022: train loss 1.86429. lr 5.510368e-04:  37%|███▋      | 6022/16329 [50:43<1:25:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6022: train loss 1.86429. lr 5.510368e-04:  37%|███▋      | 6023/16329 [50:43<1:25:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6023: train loss 1.90029. lr 5.510210e-04:  37%|███▋      | 6023/16329 [50:44<1:25:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6023: train loss 1.90029. lr 5.510210e-04:  37%|███▋      | 6024/16329 [50:44<1:25:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6024: train loss 1.81741. lr 5.510052e-04:  37%|███▋      | 6024/16329 [50:44<1:25:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6024: train loss 1.81741. lr 5.510052e-04:  37%|███▋      | 6025/16329 [50:44<1:25:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6025: train loss 1.83652. lr 5.509894e-04:  37%|███▋      | 6025/16329 [50:45<1:25:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6025: train loss 1.83652. lr 5.509894e-04:  37%|███▋      | 6026/16329 [50:45<1:25:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6026: train loss 1.86790. lr 5.509736e-04:  37%|███▋      | 6026/16329 [50:45<1:25:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6026: train loss 1.86790. lr 5.509736e-04:  37%|███▋      | 6027/16329 [50:45<1:25:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6027: train loss 1.84638. lr 5.509577e-04:  37%|███▋      | 6027/16329 [50:46<1:25:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6027: train loss 1.84638. lr 5.509577e-04:  37%|███▋      | 6028/16329 [50:46<1:25:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6028: train loss 1.84156. lr 5.509419e-04:  37%|███▋      | 6028/16329 [50:46<1:25:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6028: train loss 1.84156. lr 5.509419e-04:  37%|███▋      | 6029/16329 [50:46<1:24:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6029: train loss 1.86711. lr 5.509261e-04:  37%|███▋      | 6029/16329 [50:47<1:24:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6029: train loss 1.86711. lr 5.509261e-04:  37%|███▋      | 6030/16329 [50:47<1:25:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6030: train loss 1.89150. lr 5.509103e-04:  37%|███▋      | 6030/16329 [50:47<1:25:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6030: train loss 1.89150. lr 5.509103e-04:  37%|███▋      | 6031/16329 [50:47<1:24:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6031: train loss 1.82556. lr 5.508945e-04:  37%|███▋      | 6031/16329 [50:48<1:24:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6031: train loss 1.82556. lr 5.508945e-04:  37%|███▋      | 6032/16329 [50:48<1:25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6032: train loss 1.84138. lr 5.508786e-04:  37%|███▋      | 6032/16329 [50:48<1:25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6032: train loss 1.84138. lr 5.508786e-04:  37%|███▋      | 6033/16329 [50:48<1:25:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6033: train loss 1.83292. lr 5.508628e-04:  37%|███▋      | 6033/16329 [50:49<1:25:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6033: train loss 1.83292. lr 5.508628e-04:  37%|███▋      | 6034/16329 [50:49<1:24:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6034: train loss 1.89144. lr 5.508470e-04:  37%|███▋      | 6034/16329 [50:49<1:24:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6034: train loss 1.89144. lr 5.508470e-04:  37%|███▋      | 6035/16329 [50:49<1:25:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6035: train loss 1.83191. lr 5.508312e-04:  37%|███▋      | 6035/16329 [50:50<1:25:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6035: train loss 1.83191. lr 5.508312e-04:  37%|███▋      | 6036/16329 [50:50<1:25:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6036: train loss 1.82644. lr 5.508153e-04:  37%|███▋      | 6036/16329 [50:50<1:25:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6036: train loss 1.82644. lr 5.508153e-04:  37%|███▋      | 6037/16329 [50:50<1:25:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6037: train loss 1.84881. lr 5.507995e-04:  37%|███▋      | 6037/16329 [50:51<1:25:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6037: train loss 1.84881. lr 5.507995e-04:  37%|███▋      | 6038/16329 [50:51<1:25:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6038: train loss 1.80000. lr 5.507837e-04:  37%|███▋      | 6038/16329 [50:52<1:25:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6038: train loss 1.80000. lr 5.507837e-04:  37%|███▋      | 6039/16329 [50:52<1:35:37,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6039: train loss 1.85064. lr 5.507678e-04:  37%|███▋      | 6039/16329 [50:52<1:35:37,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6039: train loss 1.85064. lr 5.507678e-04:  37%|███▋      | 6040/16329 [50:52<1:32:45,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6040: train loss 1.88560. lr 5.507520e-04:  37%|███▋      | 6040/16329 [50:53<1:32:45,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6040: train loss 1.88560. lr 5.507520e-04:  37%|███▋      | 6041/16329 [50:53<1:30:45,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6041: train loss 1.85125. lr 5.507361e-04:  37%|███▋      | 6041/16329 [50:53<1:30:45,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6041: train loss 1.85125. lr 5.507361e-04:  37%|███▋      | 6042/16329 [50:53<1:29:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6042: train loss 1.90789. lr 5.507203e-04:  37%|███▋      | 6042/16329 [50:54<1:29:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6042: train loss 1.90789. lr 5.507203e-04:  37%|███▋      | 6043/16329 [50:54<1:27:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6043: train loss 1.83211. lr 5.507044e-04:  37%|███▋      | 6043/16329 [50:54<1:27:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6043: train loss 1.83211. lr 5.507044e-04:  37%|███▋      | 6044/16329 [50:54<1:27:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6044: train loss 1.81005. lr 5.506886e-04:  37%|███▋      | 6044/16329 [50:55<1:27:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6044: train loss 1.81005. lr 5.506886e-04:  37%|███▋      | 6045/16329 [50:55<1:26:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6045: train loss 1.91956. lr 5.506727e-04:  37%|███▋      | 6045/16329 [50:55<1:26:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6045: train loss 1.91956. lr 5.506727e-04:  37%|███▋      | 6046/16329 [50:55<1:26:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6046: train loss 1.83605. lr 5.506569e-04:  37%|███▋      | 6046/16329 [50:56<1:26:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6046: train loss 1.83605. lr 5.506569e-04:  37%|███▋      | 6047/16329 [50:56<1:25:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6047: train loss 1.84923. lr 5.506410e-04:  37%|███▋      | 6047/16329 [50:56<1:25:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6047: train loss 1.84923. lr 5.506410e-04:  37%|███▋      | 6048/16329 [50:56<1:25:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6048: train loss 1.88525. lr 5.506251e-04:  37%|███▋      | 6048/16329 [50:57<1:25:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6048: train loss 1.88525. lr 5.506251e-04:  37%|███▋      | 6049/16329 [50:57<1:25:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6049: train loss 1.83546. lr 5.506093e-04:  37%|███▋      | 6049/16329 [50:57<1:25:32,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6049: train loss 1.83546. lr 5.506093e-04:  37%|███▋      | 6050/16329 [50:57<1:25:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6050: train loss 1.86023. lr 5.505934e-04:  37%|███▋      | 6050/16329 [50:58<1:25:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6050: train loss 1.86023. lr 5.505934e-04:  37%|███▋      | 6051/16329 [50:58<1:25:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6051: train loss 1.79738. lr 5.505775e-04:  37%|███▋      | 6051/16329 [50:58<1:25:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6051: train loss 1.79738. lr 5.505775e-04:  37%|███▋      | 6052/16329 [50:58<1:25:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6052: train loss 1.91764. lr 5.505617e-04:  37%|███▋      | 6052/16329 [50:59<1:25:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6052: train loss 1.91764. lr 5.505617e-04:  37%|███▋      | 6053/16329 [50:59<1:25:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6053: train loss 1.83420. lr 5.505458e-04:  37%|███▋      | 6053/16329 [50:59<1:25:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6053: train loss 1.83420. lr 5.505458e-04:  37%|███▋      | 6054/16329 [50:59<1:25:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6054: train loss 1.78694. lr 5.505299e-04:  37%|███▋      | 6054/16329 [51:00<1:25:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6054: train loss 1.78694. lr 5.505299e-04:  37%|███▋      | 6055/16329 [51:00<1:24:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6055: train loss 1.90566. lr 5.505141e-04:  37%|███▋      | 6055/16329 [51:00<1:24:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6055: train loss 1.90566. lr 5.505141e-04:  37%|███▋      | 6056/16329 [51:00<1:24:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6056: train loss 1.81841. lr 5.504982e-04:  37%|███▋      | 6056/16329 [51:01<1:24:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6056: train loss 1.81841. lr 5.504982e-04:  37%|███▋      | 6057/16329 [51:01<1:24:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6057: train loss 1.89030. lr 5.504823e-04:  37%|███▋      | 6057/16329 [51:01<1:24:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6057: train loss 1.89030. lr 5.504823e-04:  37%|███▋      | 6058/16329 [51:01<1:24:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6058: train loss 1.83651. lr 5.504664e-04:  37%|███▋      | 6058/16329 [51:02<1:24:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6058: train loss 1.83651. lr 5.504664e-04:  37%|███▋      | 6059/16329 [51:02<1:24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6059: train loss 1.83352. lr 5.504505e-04:  37%|███▋      | 6059/16329 [51:02<1:24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6059: train loss 1.83352. lr 5.504505e-04:  37%|███▋      | 6060/16329 [51:02<1:25:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6060: train loss 1.85693. lr 5.504346e-04:  37%|███▋      | 6060/16329 [51:03<1:25:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6060: train loss 1.85693. lr 5.504346e-04:  37%|███▋      | 6061/16329 [51:03<1:24:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6061: train loss 1.80998. lr 5.504187e-04:  37%|███▋      | 6061/16329 [51:03<1:24:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6061: train loss 1.80998. lr 5.504187e-04:  37%|███▋      | 6062/16329 [51:03<1:24:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6062: train loss 1.86453. lr 5.504028e-04:  37%|███▋      | 6062/16329 [51:04<1:24:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6062: train loss 1.86453. lr 5.504028e-04:  37%|███▋      | 6063/16329 [51:04<1:24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6063: train loss 1.83788. lr 5.503870e-04:  37%|███▋      | 6063/16329 [51:04<1:24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6063: train loss 1.83788. lr 5.503870e-04:  37%|███▋      | 6064/16329 [51:04<1:33:27,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6064: train loss 1.84641. lr 5.503711e-04:  37%|███▋      | 6064/16329 [51:05<1:33:27,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6064: train loss 1.84641. lr 5.503711e-04:  37%|███▋      | 6065/16329 [51:05<1:30:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6065: train loss 1.84760. lr 5.503552e-04:  37%|███▋      | 6065/16329 [51:05<1:30:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6065: train loss 1.84760. lr 5.503552e-04:  37%|███▋      | 6066/16329 [51:05<1:29:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6066: train loss 1.81846. lr 5.503393e-04:  37%|███▋      | 6066/16329 [51:06<1:29:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6066: train loss 1.81846. lr 5.503393e-04:  37%|███▋      | 6067/16329 [51:06<1:28:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6067: train loss 1.82984. lr 5.503233e-04:  37%|███▋      | 6067/16329 [51:06<1:28:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6067: train loss 1.82984. lr 5.503233e-04:  37%|███▋      | 6068/16329 [51:06<1:27:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6068: train loss 1.85251. lr 5.503074e-04:  37%|███▋      | 6068/16329 [51:07<1:27:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6068: train loss 1.85251. lr 5.503074e-04:  37%|███▋      | 6069/16329 [51:07<1:26:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6069: train loss 1.86944. lr 5.502915e-04:  37%|███▋      | 6069/16329 [51:07<1:26:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6069: train loss 1.86944. lr 5.502915e-04:  37%|███▋      | 6070/16329 [51:07<1:26:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6070: train loss 1.88720. lr 5.502756e-04:  37%|███▋      | 6070/16329 [51:08<1:26:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6070: train loss 1.88720. lr 5.502756e-04:  37%|███▋      | 6071/16329 [51:08<1:25:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6071: train loss 1.84263. lr 5.502597e-04:  37%|███▋      | 6071/16329 [51:08<1:25:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6071: train loss 1.84263. lr 5.502597e-04:  37%|███▋      | 6072/16329 [51:08<1:25:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6072: train loss 1.86049. lr 5.502438e-04:  37%|███▋      | 6072/16329 [51:09<1:25:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6072: train loss 1.86049. lr 5.502438e-04:  37%|███▋      | 6073/16329 [51:09<1:25:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6073: train loss 1.79998. lr 5.502279e-04:  37%|███▋      | 6073/16329 [51:09<1:25:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6073: train loss 1.79998. lr 5.502279e-04:  37%|███▋      | 6074/16329 [51:09<1:24:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6074: train loss 1.85250. lr 5.502119e-04:  37%|███▋      | 6074/16329 [51:10<1:24:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6074: train loss 1.85250. lr 5.502119e-04:  37%|███▋      | 6075/16329 [51:10<1:25:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6075: train loss 1.89143. lr 5.501960e-04:  37%|███▋      | 6075/16329 [51:10<1:25:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6075: train loss 1.89143. lr 5.501960e-04:  37%|███▋      | 6076/16329 [51:10<1:25:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6076: train loss 1.87949. lr 5.501801e-04:  37%|███▋      | 6076/16329 [51:11<1:25:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6076: train loss 1.87949. lr 5.501801e-04:  37%|███▋      | 6077/16329 [51:11<1:25:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6077: train loss 1.89608. lr 5.501642e-04:  37%|███▋      | 6077/16329 [51:11<1:25:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6077: train loss 1.89608. lr 5.501642e-04:  37%|███▋      | 6078/16329 [51:11<1:24:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6078: train loss 1.84422. lr 5.501482e-04:  37%|███▋      | 6078/16329 [51:12<1:24:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6078: train loss 1.84422. lr 5.501482e-04:  37%|███▋      | 6079/16329 [51:12<1:24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6079: train loss 1.82479. lr 5.501323e-04:  37%|███▋      | 6079/16329 [51:12<1:24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6079: train loss 1.82479. lr 5.501323e-04:  37%|███▋      | 6080/16329 [51:12<1:24:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6080: train loss 1.83590. lr 5.501164e-04:  37%|███▋      | 6080/16329 [51:13<1:24:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6080: train loss 1.83590. lr 5.501164e-04:  37%|███▋      | 6081/16329 [51:13<1:24:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6081: train loss 1.81280. lr 5.501004e-04:  37%|███▋      | 6081/16329 [51:13<1:24:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6081: train loss 1.81280. lr 5.501004e-04:  37%|███▋      | 6082/16329 [51:13<1:24:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6082: train loss 1.84912. lr 5.500845e-04:  37%|███▋      | 6082/16329 [51:14<1:24:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6082: train loss 1.84912. lr 5.500845e-04:  37%|███▋      | 6083/16329 [51:14<1:24:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6083: train loss 1.84274. lr 5.500686e-04:  37%|███▋      | 6083/16329 [51:14<1:24:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6083: train loss 1.84274. lr 5.500686e-04:  37%|███▋      | 6084/16329 [51:14<1:24:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6084: train loss 1.84976. lr 5.500526e-04:  37%|███▋      | 6084/16329 [51:15<1:24:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6084: train loss 1.84976. lr 5.500526e-04:  37%|███▋      | 6085/16329 [51:15<1:24:45,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6085: train loss 1.84927. lr 5.500367e-04:  37%|███▋      | 6085/16329 [51:15<1:24:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6085: train loss 1.84927. lr 5.500367e-04:  37%|███▋      | 6086/16329 [51:15<1:24:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6086: train loss 1.81673. lr 5.500207e-04:  37%|███▋      | 6086/16329 [51:16<1:24:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6086: train loss 1.81673. lr 5.500207e-04:  37%|███▋      | 6087/16329 [51:16<1:24:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6087: train loss 1.87733. lr 5.500048e-04:  37%|███▋      | 6087/16329 [51:16<1:24:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6087: train loss 1.87733. lr 5.500048e-04:  37%|███▋      | 6088/16329 [51:16<1:24:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6088: train loss 1.87437. lr 5.499888e-04:  37%|███▋      | 6088/16329 [51:17<1:24:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6088: train loss 1.87437. lr 5.499888e-04:  37%|███▋      | 6089/16329 [51:17<1:24:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6089: train loss 1.81178. lr 5.499729e-04:  37%|███▋      | 6089/16329 [51:17<1:24:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6089: train loss 1.81178. lr 5.499729e-04:  37%|███▋      | 6090/16329 [51:17<1:24:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6090: train loss 1.82059. lr 5.499569e-04:  37%|███▋      | 6090/16329 [51:18<1:24:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6090: train loss 1.82059. lr 5.499569e-04:  37%|███▋      | 6091/16329 [51:18<1:33:23,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6091: train loss 1.82796. lr 5.499409e-04:  37%|███▋      | 6091/16329 [51:18<1:33:23,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6091: train loss 1.82796. lr 5.499409e-04:  37%|███▋      | 6092/16329 [51:18<1:33:20,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6092: train loss 1.87396. lr 5.499250e-04:  37%|███▋      | 6092/16329 [51:19<1:33:20,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6092: train loss 1.87396. lr 5.499250e-04:  37%|███▋      | 6093/16329 [51:19<1:32:35,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6093: train loss 1.86399. lr 5.499090e-04:  37%|███▋      | 6093/16329 [51:19<1:32:35,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6093: train loss 1.86399. lr 5.499090e-04:  37%|███▋      | 6094/16329 [51:19<1:31:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6094: train loss 1.86399. lr 5.498930e-04:  37%|███▋      | 6094/16329 [51:20<1:31:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6094: train loss 1.86399. lr 5.498930e-04:  37%|███▋      | 6095/16329 [51:20<1:30:34,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6095: train loss 1.86135. lr 5.498771e-04:  37%|███▋      | 6095/16329 [51:20<1:30:34,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6095: train loss 1.86135. lr 5.498771e-04:  37%|███▋      | 6096/16329 [51:20<1:29:19,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6096: train loss 1.83059. lr 5.498611e-04:  37%|███▋      | 6096/16329 [51:21<1:29:19,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6096: train loss 1.83059. lr 5.498611e-04:  37%|███▋      | 6097/16329 [51:21<1:28:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6097: train loss 1.80759. lr 5.498451e-04:  37%|███▋      | 6097/16329 [51:21<1:28:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6097: train loss 1.80759. lr 5.498451e-04:  37%|███▋      | 6098/16329 [51:21<1:27:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6098: train loss 1.84339. lr 5.498291e-04:  37%|███▋      | 6098/16329 [51:22<1:27:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6098: train loss 1.84339. lr 5.498291e-04:  37%|███▋      | 6099/16329 [51:22<1:26:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6099: train loss 1.80172. lr 5.498132e-04:  37%|███▋      | 6099/16329 [51:22<1:26:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6099: train loss 1.80172. lr 5.498132e-04:  37%|███▋      | 6100/16329 [51:22<1:26:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6100: train loss 1.82903. lr 5.497972e-04:  37%|███▋      | 6100/16329 [51:23<1:26:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6100: train loss 1.82903. lr 5.497972e-04:  37%|███▋      | 6101/16329 [51:23<1:25:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6101: train loss 1.85022. lr 5.497812e-04:  37%|███▋      | 6101/16329 [51:23<1:25:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6101: train loss 1.85022. lr 5.497812e-04:  37%|███▋      | 6102/16329 [51:23<1:25:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6102: train loss 1.86646. lr 5.497652e-04:  37%|███▋      | 6102/16329 [51:24<1:25:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6102: train loss 1.86646. lr 5.497652e-04:  37%|███▋      | 6103/16329 [51:24<1:24:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6103: train loss 1.81276. lr 5.497492e-04:  37%|███▋      | 6103/16329 [51:24<1:24:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6103: train loss 1.81276. lr 5.497492e-04:  37%|███▋      | 6104/16329 [51:24<1:25:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6104: train loss 1.87460. lr 5.497332e-04:  37%|███▋      | 6104/16329 [51:25<1:25:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6104: train loss 1.87460. lr 5.497332e-04:  37%|███▋      | 6105/16329 [51:25<1:24:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6105: train loss 1.83608. lr 5.497172e-04:  37%|███▋      | 6105/16329 [51:25<1:24:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6105: train loss 1.83608. lr 5.497172e-04:  37%|███▋      | 6106/16329 [51:25<1:24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6106: train loss 1.85068. lr 5.497012e-04:  37%|███▋      | 6106/16329 [51:26<1:24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6106: train loss 1.85068. lr 5.497012e-04:  37%|███▋      | 6107/16329 [51:26<1:24:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6107: train loss 1.83843. lr 5.496852e-04:  37%|███▋      | 6107/16329 [51:26<1:24:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6107: train loss 1.83843. lr 5.496852e-04:  37%|███▋      | 6108/16329 [51:26<1:24:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6108: train loss 1.86238. lr 5.496692e-04:  37%|███▋      | 6108/16329 [51:27<1:24:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6108: train loss 1.86238. lr 5.496692e-04:  37%|███▋      | 6109/16329 [51:27<1:24:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6109: train loss 1.83693. lr 5.496532e-04:  37%|███▋      | 6109/16329 [51:27<1:24:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6109: train loss 1.83693. lr 5.496532e-04:  37%|███▋      | 6110/16329 [51:27<1:24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6110: train loss 1.83922. lr 5.496372e-04:  37%|███▋      | 6110/16329 [51:28<1:24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6110: train loss 1.83922. lr 5.496372e-04:  37%|███▋      | 6111/16329 [51:28<1:24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6111: train loss 1.85374. lr 5.496212e-04:  37%|███▋      | 6111/16329 [51:28<1:24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6111: train loss 1.85374. lr 5.496212e-04:  37%|███▋      | 6112/16329 [51:28<1:24:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6112: train loss 1.82897. lr 5.496052e-04:  37%|███▋      | 6112/16329 [51:29<1:24:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6112: train loss 1.82897. lr 5.496052e-04:  37%|███▋      | 6113/16329 [51:29<1:24:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6113: train loss 1.85287. lr 5.495892e-04:  37%|███▋      | 6113/16329 [51:29<1:24:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6113: train loss 1.85287. lr 5.495892e-04:  37%|███▋      | 6114/16329 [51:29<1:24:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6114: train loss 1.86226. lr 5.495732e-04:  37%|███▋      | 6114/16329 [51:30<1:24:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6114: train loss 1.86226. lr 5.495732e-04:  37%|███▋      | 6115/16329 [51:30<1:24:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6115: train loss 1.82958. lr 5.495572e-04:  37%|███▋      | 6115/16329 [51:30<1:24:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6115: train loss 1.82958. lr 5.495572e-04:  37%|███▋      | 6116/16329 [51:30<1:24:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6116: train loss 1.87895. lr 5.495412e-04:  37%|███▋      | 6116/16329 [51:31<1:24:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6116: train loss 1.87895. lr 5.495412e-04:  37%|███▋      | 6117/16329 [51:31<1:24:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6117: train loss 1.86951. lr 5.495251e-04:  37%|███▋      | 6117/16329 [51:31<1:24:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6117: train loss 1.86951. lr 5.495251e-04:  37%|███▋      | 6118/16329 [51:31<1:24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6118: train loss 1.81125. lr 5.495091e-04:  37%|███▋      | 6118/16329 [51:32<1:24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6118: train loss 1.81125. lr 5.495091e-04:  37%|███▋      | 6119/16329 [51:32<1:24:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6119: train loss 1.85789. lr 5.494931e-04:  37%|███▋      | 6119/16329 [51:32<1:24:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6119: train loss 1.85789. lr 5.494931e-04:  37%|███▋      | 6120/16329 [51:32<1:24:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6120: train loss 1.86302. lr 5.494771e-04:  37%|███▋      | 6120/16329 [51:33<1:24:09,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6120: train loss 1.86302. lr 5.494771e-04:  37%|███▋      | 6121/16329 [51:33<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6121: train loss 1.84977. lr 5.494610e-04:  37%|███▋      | 6121/16329 [51:33<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6121: train loss 1.84977. lr 5.494610e-04:  37%|███▋      | 6122/16329 [51:33<1:24:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6122: train loss 1.75983. lr 5.494450e-04:  37%|███▋      | 6122/16329 [51:34<1:24:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6122: train loss 1.75983. lr 5.494450e-04:  37%|███▋      | 6123/16329 [51:34<1:24:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6123: train loss 1.82905. lr 5.494290e-04:  37%|███▋      | 6123/16329 [51:34<1:24:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6123: train loss 1.82905. lr 5.494290e-04:  38%|███▊      | 6124/16329 [51:34<1:24:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6124: train loss 1.80049. lr 5.494129e-04:  38%|███▊      | 6124/16329 [51:35<1:24:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6124: train loss 1.80049. lr 5.494129e-04:  38%|███▊      | 6125/16329 [51:35<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6125: train loss 1.84849. lr 5.493969e-04:  38%|███▊      | 6125/16329 [51:35<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6125: train loss 1.84849. lr 5.493969e-04:  38%|███▊      | 6126/16329 [51:35<1:24:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6126: train loss 1.87299. lr 5.493809e-04:  38%|███▊      | 6126/16329 [51:36<1:24:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6126: train loss 1.87299. lr 5.493809e-04:  38%|███▊      | 6127/16329 [51:36<1:24:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6127: train loss 1.86331. lr 5.493648e-04:  38%|███▊      | 6127/16329 [51:36<1:24:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6127: train loss 1.86331. lr 5.493648e-04:  38%|███▊      | 6128/16329 [51:36<1:24:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6128: train loss 1.84144. lr 5.493488e-04:  38%|███▊      | 6128/16329 [51:37<1:24:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6128: train loss 1.84144. lr 5.493488e-04:  38%|███▊      | 6129/16329 [51:37<1:24:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6129: train loss 1.84793. lr 5.493327e-04:  38%|███▊      | 6129/16329 [51:37<1:24:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6129: train loss 1.84793. lr 5.493327e-04:  38%|███▊      | 6130/16329 [51:37<1:24:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6130: train loss 1.84146. lr 5.493167e-04:  38%|███▊      | 6130/16329 [51:38<1:24:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6130: train loss 1.84146. lr 5.493167e-04:  38%|███▊      | 6131/16329 [51:38<1:33:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6131: train loss 1.81548. lr 5.493006e-04:  38%|███▊      | 6131/16329 [51:38<1:33:14,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6131: train loss 1.81548. lr 5.493006e-04:  38%|███▊      | 6132/16329 [51:38<1:30:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6132: train loss 1.83860. lr 5.492846e-04:  38%|███▊      | 6132/16329 [51:39<1:30:15,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6132: train loss 1.83860. lr 5.492846e-04:  38%|███▊      | 6133/16329 [51:39<1:28:43,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6133: train loss 1.83714. lr 5.492685e-04:  38%|███▊      | 6133/16329 [51:39<1:28:43,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6133: train loss 1.83714. lr 5.492685e-04:  38%|███▊      | 6134/16329 [51:39<1:27:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6134: train loss 1.79914. lr 5.492524e-04:  38%|███▊      | 6134/16329 [51:40<1:27:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6134: train loss 1.79914. lr 5.492524e-04:  38%|███▊      | 6135/16329 [51:40<1:26:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6135: train loss 1.80948. lr 5.492364e-04:  38%|███▊      | 6135/16329 [51:40<1:26:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6135: train loss 1.80948. lr 5.492364e-04:  38%|███▊      | 6136/16329 [51:40<1:25:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6136: train loss 1.86797. lr 5.492203e-04:  38%|███▊      | 6136/16329 [51:41<1:25:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6136: train loss 1.86797. lr 5.492203e-04:  38%|███▊      | 6137/16329 [51:41<1:25:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6137: train loss 1.83716. lr 5.492042e-04:  38%|███▊      | 6137/16329 [51:41<1:25:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6137: train loss 1.83716. lr 5.492042e-04:  38%|███▊      | 6138/16329 [51:41<1:27:16,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6138: train loss 1.83556. lr 5.491882e-04:  38%|███▊      | 6138/16329 [51:42<1:27:16,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6138: train loss 1.83556. lr 5.491882e-04:  38%|███▊      | 6139/16329 [51:42<1:28:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6139: train loss 1.82098. lr 5.491721e-04:  38%|███▊      | 6139/16329 [51:43<1:28:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6139: train loss 1.82098. lr 5.491721e-04:  38%|███▊      | 6140/16329 [51:43<1:28:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6140: train loss 1.86789. lr 5.491560e-04:  38%|███▊      | 6140/16329 [51:43<1:28:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6140: train loss 1.86789. lr 5.491560e-04:  38%|███▊      | 6141/16329 [51:43<1:28:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6141: train loss 1.86240. lr 5.491400e-04:  38%|███▊      | 6141/16329 [51:44<1:28:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6141: train loss 1.86240. lr 5.491400e-04:  38%|███▊      | 6142/16329 [51:44<1:27:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6142: train loss 1.82007. lr 5.491239e-04:  38%|███▊      | 6142/16329 [51:44<1:27:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6142: train loss 1.82007. lr 5.491239e-04:  38%|███▊      | 6143/16329 [51:44<1:27:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6143: train loss 1.81758. lr 5.491078e-04:  38%|███▊      | 6143/16329 [51:45<1:27:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6143: train loss 1.81758. lr 5.491078e-04:  38%|███▊      | 6144/16329 [51:45<1:26:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6144: train loss 1.85252. lr 5.490917e-04:  38%|███▊      | 6144/16329 [51:45<1:26:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6144: train loss 1.85252. lr 5.490917e-04:  38%|███▊      | 6145/16329 [51:45<1:25:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6145: train loss 1.85178. lr 5.490756e-04:  38%|███▊      | 6145/16329 [51:46<1:25:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6145: train loss 1.85178. lr 5.490756e-04:  38%|███▊      | 6146/16329 [51:46<1:25:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6146: train loss 1.81415. lr 5.490595e-04:  38%|███▊      | 6146/16329 [51:46<1:25:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6146: train loss 1.81415. lr 5.490595e-04:  38%|███▊      | 6147/16329 [51:46<1:25:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6147: train loss 1.83968. lr 5.490435e-04:  38%|███▊      | 6147/16329 [51:47<1:25:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6147: train loss 1.83968. lr 5.490435e-04:  38%|███▊      | 6148/16329 [51:47<1:25:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6148: train loss 1.81213. lr 5.490274e-04:  38%|███▊      | 6148/16329 [51:47<1:25:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6148: train loss 1.81213. lr 5.490274e-04:  38%|███▊      | 6149/16329 [51:47<1:24:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6149: train loss 1.85217. lr 5.490113e-04:  38%|███▊      | 6149/16329 [51:48<1:24:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6149: train loss 1.85217. lr 5.490113e-04:  38%|███▊      | 6150/16329 [51:48<1:24:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6150: train loss 1.89644. lr 5.489952e-04:  38%|███▊      | 6150/16329 [51:48<1:24:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6150: train loss 1.89644. lr 5.489952e-04:  38%|███▊      | 6151/16329 [51:48<1:24:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6151: train loss 1.80421. lr 5.489791e-04:  38%|███▊      | 6151/16329 [51:49<1:24:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6151: train loss 1.80421. lr 5.489791e-04:  38%|███▊      | 6152/16329 [51:49<1:24:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6152: train loss 1.87854. lr 5.489630e-04:  38%|███▊      | 6152/16329 [51:49<1:24:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6152: train loss 1.87854. lr 5.489630e-04:  38%|███▊      | 6153/16329 [51:49<1:24:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6153: train loss 1.87333. lr 5.489469e-04:  38%|███▊      | 6153/16329 [51:50<1:24:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6153: train loss 1.87333. lr 5.489469e-04:  38%|███▊      | 6154/16329 [51:50<1:24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6154: train loss 1.83300. lr 5.489308e-04:  38%|███▊      | 6154/16329 [51:50<1:24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6154: train loss 1.83300. lr 5.489308e-04:  38%|███▊      | 6155/16329 [51:50<1:24:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6155: train loss 1.78879. lr 5.489147e-04:  38%|███▊      | 6155/16329 [51:51<1:24:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6155: train loss 1.78879. lr 5.489147e-04:  38%|███▊      | 6156/16329 [51:51<1:24:05,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6156: train loss 1.83921. lr 5.488985e-04:  38%|███▊      | 6156/16329 [51:51<1:24:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6156: train loss 1.83921. lr 5.488985e-04:  38%|███▊      | 6157/16329 [51:51<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6157: train loss 1.82988. lr 5.488824e-04:  38%|███▊      | 6157/16329 [51:52<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6157: train loss 1.82988. lr 5.488824e-04:  38%|███▊      | 6158/16329 [51:52<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6158: train loss 1.87567. lr 5.488663e-04:  38%|███▊      | 6158/16329 [51:52<1:24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6158: train loss 1.87567. lr 5.488663e-04:  38%|███▊      | 6159/16329 [51:52<1:24:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6159: train loss 1.85602. lr 5.488502e-04:  38%|███▊      | 6159/16329 [51:53<1:24:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6159: train loss 1.85602. lr 5.488502e-04:  38%|███▊      | 6160/16329 [51:53<1:24:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6160: train loss 1.80886. lr 5.488341e-04:  38%|███▊      | 6160/16329 [51:53<1:24:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6160: train loss 1.80886. lr 5.488341e-04:  38%|███▊      | 6161/16329 [51:53<1:24:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6161: train loss 1.82465. lr 5.488180e-04:  38%|███▊      | 6161/16329 [51:54<1:24:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6161: train loss 1.82465. lr 5.488180e-04:  38%|███▊      | 6162/16329 [51:54<1:24:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6162: train loss 1.83581. lr 5.488018e-04:  38%|███▊      | 6162/16329 [51:54<1:24:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6162: train loss 1.83581. lr 5.488018e-04:  38%|███▊      | 6163/16329 [51:54<1:23:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6163: train loss 1.82707. lr 5.487857e-04:  38%|███▊      | 6163/16329 [51:55<1:23:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6163: train loss 1.82707. lr 5.487857e-04:  38%|███▊      | 6164/16329 [51:55<1:24:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6164: train loss 1.85687. lr 5.487696e-04:  38%|███▊      | 6164/16329 [51:55<1:24:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6164: train loss 1.85687. lr 5.487696e-04:  38%|███▊      | 6165/16329 [51:55<1:24:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6165: train loss 1.81095. lr 5.487534e-04:  38%|███▊      | 6165/16329 [51:56<1:24:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6165: train loss 1.81095. lr 5.487534e-04:  38%|███▊      | 6166/16329 [51:56<1:33:05,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6166: train loss 1.88629. lr 5.487373e-04:  38%|███▊      | 6166/16329 [51:56<1:33:05,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6166: train loss 1.88629. lr 5.487373e-04:  38%|███▊      | 6167/16329 [51:56<1:30:39,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6167: train loss 1.83880. lr 5.487212e-04:  38%|███▊      | 6167/16329 [51:57<1:30:39,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6167: train loss 1.83880. lr 5.487212e-04:  38%|███▊      | 6168/16329 [51:57<1:28:25,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6168: train loss 1.83726. lr 5.487050e-04:  38%|███▊      | 6168/16329 [51:57<1:28:25,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6168: train loss 1.83726. lr 5.487050e-04:  38%|███▊      | 6169/16329 [51:57<1:27:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6169: train loss 1.83121. lr 5.486889e-04:  38%|███▊      | 6169/16329 [51:58<1:27:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6169: train loss 1.83121. lr 5.486889e-04:  38%|███▊      | 6170/16329 [51:58<1:26:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6170: train loss 1.76890. lr 5.486728e-04:  38%|███▊      | 6170/16329 [51:58<1:26:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6170: train loss 1.76890. lr 5.486728e-04:  38%|███▊      | 6171/16329 [51:58<1:25:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6171: train loss 1.82549. lr 5.486566e-04:  38%|███▊      | 6171/16329 [51:59<1:25:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6171: train loss 1.82549. lr 5.486566e-04:  38%|███▊      | 6172/16329 [51:59<1:24:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6172: train loss 1.83321. lr 5.486405e-04:  38%|███▊      | 6172/16329 [51:59<1:24:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6172: train loss 1.83321. lr 5.486405e-04:  38%|███▊      | 6173/16329 [51:59<1:24:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6173: train loss 1.86545. lr 5.486243e-04:  38%|███▊      | 6173/16329 [52:00<1:24:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6173: train loss 1.86545. lr 5.486243e-04:  38%|███▊      | 6174/16329 [52:00<1:24:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6174: train loss 1.82804. lr 5.486082e-04:  38%|███▊      | 6174/16329 [52:00<1:24:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6174: train loss 1.82804. lr 5.486082e-04:  38%|███▊      | 6175/16329 [52:00<1:24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6175: train loss 1.82617. lr 5.485920e-04:  38%|███▊      | 6175/16329 [52:01<1:24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6175: train loss 1.82617. lr 5.485920e-04:  38%|███▊      | 6176/16329 [52:01<1:24:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6176: train loss 1.86503. lr 5.485758e-04:  38%|███▊      | 6176/16329 [52:01<1:24:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6176: train loss 1.86503. lr 5.485758e-04:  38%|███▊      | 6177/16329 [52:01<1:24:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6177: train loss 1.86108. lr 5.485597e-04:  38%|███▊      | 6177/16329 [52:02<1:24:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6177: train loss 1.86108. lr 5.485597e-04:  38%|███▊      | 6178/16329 [52:02<1:24:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6178: train loss 1.81712. lr 5.485435e-04:  38%|███▊      | 6178/16329 [52:02<1:24:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6178: train loss 1.81712. lr 5.485435e-04:  38%|███▊      | 6179/16329 [52:02<1:24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6179: train loss 1.87651. lr 5.485274e-04:  38%|███▊      | 6179/16329 [52:03<1:24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6179: train loss 1.87651. lr 5.485274e-04:  38%|███▊      | 6180/16329 [52:03<1:24:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6180: train loss 1.83903. lr 5.485112e-04:  38%|███▊      | 6180/16329 [52:03<1:24:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6180: train loss 1.83903. lr 5.485112e-04:  38%|███▊      | 6181/16329 [52:03<1:24:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6181: train loss 1.85802. lr 5.484950e-04:  38%|███▊      | 6181/16329 [52:04<1:24:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6181: train loss 1.85802. lr 5.484950e-04:  38%|███▊      | 6182/16329 [52:04<1:23:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6182: train loss 1.77960. lr 5.484789e-04:  38%|███▊      | 6182/16329 [52:04<1:23:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6182: train loss 1.77960. lr 5.484789e-04:  38%|███▊      | 6183/16329 [52:04<1:24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6183: train loss 1.86583. lr 5.484627e-04:  38%|███▊      | 6183/16329 [52:05<1:24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6183: train loss 1.86583. lr 5.484627e-04:  38%|███▊      | 6184/16329 [52:05<1:23:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6184: train loss 1.81397. lr 5.484465e-04:  38%|███▊      | 6184/16329 [52:05<1:23:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6184: train loss 1.81397. lr 5.484465e-04:  38%|███▊      | 6185/16329 [52:05<1:23:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6185: train loss 1.82420. lr 5.484303e-04:  38%|███▊      | 6185/16329 [52:06<1:23:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6185: train loss 1.82420. lr 5.484303e-04:  38%|███▊      | 6186/16329 [52:06<1:23:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6186: train loss 1.82099. lr 5.484142e-04:  38%|███▊      | 6186/16329 [52:06<1:23:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6186: train loss 1.82099. lr 5.484142e-04:  38%|███▊      | 6187/16329 [52:06<1:23:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6187: train loss 1.81041. lr 5.483980e-04:  38%|███▊      | 6187/16329 [52:07<1:23:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6187: train loss 1.81041. lr 5.483980e-04:  38%|███▊      | 6188/16329 [52:07<1:23:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6188: train loss 1.74748. lr 5.483818e-04:  38%|███▊      | 6188/16329 [52:07<1:23:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6188: train loss 1.74748. lr 5.483818e-04:  38%|███▊      | 6189/16329 [52:07<1:23:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6189: train loss 1.81639. lr 5.483656e-04:  38%|███▊      | 6189/16329 [52:08<1:23:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6189: train loss 1.81639. lr 5.483656e-04:  38%|███▊      | 6190/16329 [52:08<1:24:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6190: train loss 1.82106. lr 5.483494e-04:  38%|███▊      | 6190/16329 [52:08<1:24:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6190: train loss 1.82106. lr 5.483494e-04:  38%|███▊      | 6191/16329 [52:08<1:35:14,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 6191: train loss 1.82594. lr 5.483332e-04:  38%|███▊      | 6191/16329 [52:09<1:35:14,  1.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6191: train loss 1.82594. lr 5.483332e-04:  38%|███▊      | 6192/16329 [52:09<1:31:32,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6192: train loss 1.84626. lr 5.483170e-04:  38%|███▊      | 6192/16329 [52:09<1:31:32,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6192: train loss 1.84626. lr 5.483170e-04:  38%|███▊      | 6193/16329 [52:09<1:29:19,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6193: train loss 1.82887. lr 5.483008e-04:  38%|███▊      | 6193/16329 [52:10<1:29:19,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6193: train loss 1.82887. lr 5.483008e-04:  38%|███▊      | 6194/16329 [52:10<1:27:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6194: train loss 1.85333. lr 5.482846e-04:  38%|███▊      | 6194/16329 [52:10<1:27:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6194: train loss 1.85333. lr 5.482846e-04:  38%|███▊      | 6195/16329 [52:10<1:26:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6195: train loss 1.86641. lr 5.482684e-04:  38%|███▊      | 6195/16329 [52:11<1:26:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6195: train loss 1.86641. lr 5.482684e-04:  38%|███▊      | 6196/16329 [52:11<1:25:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6196: train loss 1.78827. lr 5.482522e-04:  38%|███▊      | 6196/16329 [52:11<1:25:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6196: train loss 1.78827. lr 5.482522e-04:  38%|███▊      | 6197/16329 [52:11<1:25:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6197: train loss 1.77745. lr 5.482360e-04:  38%|███▊      | 6197/16329 [52:12<1:25:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6197: train loss 1.77745. lr 5.482360e-04:  38%|███▊      | 6198/16329 [52:12<1:24:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6198: train loss 1.85097. lr 5.482198e-04:  38%|███▊      | 6198/16329 [52:12<1:24:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6198: train loss 1.85097. lr 5.482198e-04:  38%|███▊      | 6199/16329 [52:12<1:24:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6199: train loss 1.87971. lr 5.482036e-04:  38%|███▊      | 6199/16329 [52:13<1:24:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6199: train loss 1.87971. lr 5.482036e-04:  38%|███▊      | 6200/16329 [52:13<1:23:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6200: train loss 1.80408. lr 5.481874e-04:  38%|███▊      | 6200/16329 [52:13<1:23:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6200: train loss 1.80408. lr 5.481874e-04:  38%|███▊      | 6201/16329 [52:13<1:23:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6201: train loss 1.83170. lr 5.481712e-04:  38%|███▊      | 6201/16329 [52:14<1:23:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6201: train loss 1.83170. lr 5.481712e-04:  38%|███▊      | 6202/16329 [52:14<1:23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6202: train loss 1.84624. lr 5.481550e-04:  38%|███▊      | 6202/16329 [52:14<1:23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6202: train loss 1.84624. lr 5.481550e-04:  38%|███▊      | 6203/16329 [52:14<1:23:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6203: train loss 1.77840. lr 5.481387e-04:  38%|███▊      | 6203/16329 [52:15<1:23:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6203: train loss 1.77840. lr 5.481387e-04:  38%|███▊      | 6204/16329 [52:15<1:23:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6204: train loss 1.82336. lr 5.481225e-04:  38%|███▊      | 6204/16329 [52:15<1:23:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6204: train loss 1.82336. lr 5.481225e-04:  38%|███▊      | 6205/16329 [52:15<1:23:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6205: train loss 1.82223. lr 5.481063e-04:  38%|███▊      | 6205/16329 [52:16<1:23:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6205: train loss 1.82223. lr 5.481063e-04:  38%|███▊      | 6206/16329 [52:16<1:23:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6206: train loss 1.86198. lr 5.480901e-04:  38%|███▊      | 6206/16329 [52:16<1:23:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6206: train loss 1.86198. lr 5.480901e-04:  38%|███▊      | 6207/16329 [52:16<1:23:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6207: train loss 1.78373. lr 5.480739e-04:  38%|███▊      | 6207/16329 [52:17<1:23:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6207: train loss 1.78373. lr 5.480739e-04:  38%|███▊      | 6208/16329 [52:17<1:24:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6208: train loss 1.81034. lr 5.480576e-04:  38%|███▊      | 6208/16329 [52:17<1:24:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6208: train loss 1.81034. lr 5.480576e-04:  38%|███▊      | 6209/16329 [52:17<1:25:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6209: train loss 1.79102. lr 5.480414e-04:  38%|███▊      | 6209/16329 [52:18<1:25:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6209: train loss 1.79102. lr 5.480414e-04:  38%|███▊      | 6210/16329 [52:18<1:25:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6210: train loss 1.83246. lr 5.480252e-04:  38%|███▊      | 6210/16329 [52:18<1:25:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6210: train loss 1.83246. lr 5.480252e-04:  38%|███▊      | 6211/16329 [52:18<1:25:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6211: train loss 1.87391. lr 5.480089e-04:  38%|███▊      | 6211/16329 [52:19<1:25:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6211: train loss 1.87391. lr 5.480089e-04:  38%|███▊      | 6212/16329 [52:19<1:25:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6212: train loss 1.81919. lr 5.479927e-04:  38%|███▊      | 6212/16329 [52:19<1:25:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6212: train loss 1.81919. lr 5.479927e-04:  38%|███▊      | 6213/16329 [52:19<1:25:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6213: train loss 1.81038. lr 5.479764e-04:  38%|███▊      | 6213/16329 [52:20<1:25:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6213: train loss 1.81038. lr 5.479764e-04:  38%|███▊      | 6214/16329 [52:20<1:24:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6214: train loss 1.86871. lr 5.479602e-04:  38%|███▊      | 6214/16329 [52:20<1:24:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6214: train loss 1.86871. lr 5.479602e-04:  38%|███▊      | 6215/16329 [52:20<1:24:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6215: train loss 1.78641. lr 5.479439e-04:  38%|███▊      | 6215/16329 [52:21<1:24:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6215: train loss 1.78641. lr 5.479439e-04:  38%|███▊      | 6216/16329 [52:21<1:24:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6216: train loss 1.83725. lr 5.479277e-04:  38%|███▊      | 6216/16329 [52:21<1:24:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6216: train loss 1.83725. lr 5.479277e-04:  38%|███▊      | 6217/16329 [52:21<1:23:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6217: train loss 1.83333. lr 5.479114e-04:  38%|███▊      | 6217/16329 [52:22<1:23:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6217: train loss 1.83333. lr 5.479114e-04:  38%|███▊      | 6218/16329 [52:22<1:37:08,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 6218: train loss 1.83079. lr 5.478952e-04:  38%|███▊      | 6218/16329 [52:23<1:37:08,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 6218: train loss 1.83079. lr 5.478952e-04:  38%|███▊      | 6219/16329 [52:23<1:35:58,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 6219: train loss 1.84476. lr 5.478789e-04:  38%|███▊      | 6219/16329 [52:23<1:35:58,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 6219: train loss 1.84476. lr 5.478789e-04:  38%|███▊      | 6220/16329 [52:23<1:34:20,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6220: train loss 1.78751. lr 5.478627e-04:  38%|███▊      | 6220/16329 [52:24<1:34:20,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6220: train loss 1.78751. lr 5.478627e-04:  38%|███▊      | 6221/16329 [52:24<1:32:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6221: train loss 1.82249. lr 5.478464e-04:  38%|███▊      | 6221/16329 [52:24<1:32:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6221: train loss 1.82249. lr 5.478464e-04:  38%|███▊      | 6222/16329 [52:24<1:30:39,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6222: train loss 1.84860. lr 5.478302e-04:  38%|███▊      | 6222/16329 [52:25<1:30:39,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6222: train loss 1.84860. lr 5.478302e-04:  38%|███▊      | 6223/16329 [52:25<1:29:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6223: train loss 1.84407. lr 5.478139e-04:  38%|███▊      | 6223/16329 [52:25<1:29:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6223: train loss 1.84407. lr 5.478139e-04:  38%|███▊      | 6224/16329 [52:25<1:27:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6224: train loss 1.82106. lr 5.477976e-04:  38%|███▊      | 6224/16329 [52:26<1:27:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6224: train loss 1.82106. lr 5.477976e-04:  38%|███▊      | 6225/16329 [52:26<1:27:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6225: train loss 1.86149. lr 5.477814e-04:  38%|███▊      | 6225/16329 [52:26<1:27:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6225: train loss 1.86149. lr 5.477814e-04:  38%|███▊      | 6226/16329 [52:26<1:25:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6226: train loss 1.81669. lr 5.477651e-04:  38%|███▊      | 6226/16329 [52:27<1:25:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6226: train loss 1.81669. lr 5.477651e-04:  38%|███▊      | 6227/16329 [52:27<1:25:10,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6227: train loss 1.88360. lr 5.477488e-04:  38%|███▊      | 6227/16329 [52:27<1:25:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6227: train loss 1.88360. lr 5.477488e-04:  38%|███▊      | 6228/16329 [52:27<1:24:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6228: train loss 1.82598. lr 5.477325e-04:  38%|███▊      | 6228/16329 [52:28<1:24:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6228: train loss 1.82598. lr 5.477325e-04:  38%|███▊      | 6229/16329 [52:28<1:24:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6229: train loss 1.82181. lr 5.477163e-04:  38%|███▊      | 6229/16329 [52:28<1:24:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6229: train loss 1.82181. lr 5.477163e-04:  38%|███▊      | 6230/16329 [52:28<1:23:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6230: train loss 1.81665. lr 5.477000e-04:  38%|███▊      | 6230/16329 [52:29<1:23:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6230: train loss 1.81665. lr 5.477000e-04:  38%|███▊      | 6231/16329 [52:29<1:23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6231: train loss 1.82438. lr 5.476837e-04:  38%|███▊      | 6231/16329 [52:29<1:23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6231: train loss 1.82438. lr 5.476837e-04:  38%|███▊      | 6232/16329 [52:29<1:23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6232: train loss 1.82064. lr 5.476674e-04:  38%|███▊      | 6232/16329 [52:30<1:23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6232: train loss 1.82064. lr 5.476674e-04:  38%|███▊      | 6233/16329 [52:30<1:23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6233: train loss 1.77162. lr 5.476511e-04:  38%|███▊      | 6233/16329 [52:30<1:23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6233: train loss 1.77162. lr 5.476511e-04:  38%|███▊      | 6234/16329 [52:30<1:23:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6234: train loss 1.82146. lr 5.476348e-04:  38%|███▊      | 6234/16329 [52:31<1:23:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6234: train loss 1.82146. lr 5.476348e-04:  38%|███▊      | 6235/16329 [52:31<1:23:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6235: train loss 1.89320. lr 5.476185e-04:  38%|███▊      | 6235/16329 [52:31<1:23:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6235: train loss 1.89320. lr 5.476185e-04:  38%|███▊      | 6236/16329 [52:31<1:23:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6236: train loss 1.82941. lr 5.476022e-04:  38%|███▊      | 6236/16329 [52:32<1:23:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6236: train loss 1.82941. lr 5.476022e-04:  38%|███▊      | 6237/16329 [52:32<1:23:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6237: train loss 1.84977. lr 5.475859e-04:  38%|███▊      | 6237/16329 [52:32<1:23:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6237: train loss 1.84977. lr 5.475859e-04:  38%|███▊      | 6238/16329 [52:32<1:23:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6238: train loss 1.76068. lr 5.475696e-04:  38%|███▊      | 6238/16329 [52:33<1:23:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6238: train loss 1.76068. lr 5.475696e-04:  38%|███▊      | 6239/16329 [52:33<1:23:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6239: train loss 1.86882. lr 5.475533e-04:  38%|███▊      | 6239/16329 [52:33<1:23:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6239: train loss 1.86882. lr 5.475533e-04:  38%|███▊      | 6240/16329 [52:33<1:23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6240: train loss 1.77383. lr 5.475370e-04:  38%|███▊      | 6240/16329 [52:34<1:23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6240: train loss 1.77383. lr 5.475370e-04:  38%|███▊      | 6241/16329 [52:34<1:23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6241: train loss 1.77334. lr 5.475207e-04:  38%|███▊      | 6241/16329 [52:34<1:23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6241: train loss 1.77334. lr 5.475207e-04:  38%|███▊      | 6242/16329 [52:34<1:23:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6242: train loss 1.82792. lr 5.475044e-04:  38%|███▊      | 6242/16329 [52:35<1:23:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6242: train loss 1.82792. lr 5.475044e-04:  38%|███▊      | 6243/16329 [52:35<1:23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6243: train loss 1.84997. lr 5.474881e-04:  38%|███▊      | 6243/16329 [52:35<1:23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6243: train loss 1.84997. lr 5.474881e-04:  38%|███▊      | 6244/16329 [52:35<1:23:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6244: train loss 1.83519. lr 5.474718e-04:  38%|███▊      | 6244/16329 [52:36<1:23:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6244: train loss 1.83519. lr 5.474718e-04:  38%|███▊      | 6245/16329 [52:36<1:23:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6245: train loss 1.85572. lr 5.474555e-04:  38%|███▊      | 6245/16329 [52:36<1:23:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6245: train loss 1.85572. lr 5.474555e-04:  38%|███▊      | 6246/16329 [52:36<1:23:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6246: train loss 1.84459. lr 5.474392e-04:  38%|███▊      | 6246/16329 [52:37<1:23:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6246: train loss 1.84459. lr 5.474392e-04:  38%|███▊      | 6247/16329 [52:37<1:23:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6247: train loss 1.83515. lr 5.474229e-04:  38%|███▊      | 6247/16329 [52:37<1:23:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6247: train loss 1.83515. lr 5.474229e-04:  38%|███▊      | 6248/16329 [52:37<1:23:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6248: train loss 1.80967. lr 5.474065e-04:  38%|███▊      | 6248/16329 [52:38<1:23:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6248: train loss 1.80967. lr 5.474065e-04:  38%|███▊      | 6249/16329 [52:38<1:23:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6249: train loss 1.80485. lr 5.473902e-04:  38%|███▊      | 6249/16329 [52:38<1:23:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6249: train loss 1.80485. lr 5.473902e-04:  38%|███▊      | 6250/16329 [52:38<1:23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6250: train loss 1.83860. lr 5.473739e-04:  38%|███▊      | 6250/16329 [52:39<1:23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6250: train loss 1.83860. lr 5.473739e-04:  38%|███▊      | 6251/16329 [52:39<1:23:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6251: train loss 1.80942. lr 5.473576e-04:  38%|███▊      | 6251/16329 [52:39<1:23:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6251: train loss 1.80942. lr 5.473576e-04:  38%|███▊      | 6252/16329 [52:39<1:23:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6252: train loss 1.83838. lr 5.473412e-04:  38%|███▊      | 6252/16329 [52:40<1:23:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6252: train loss 1.83838. lr 5.473412e-04:  38%|███▊      | 6253/16329 [52:40<1:23:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6253: train loss 1.82586. lr 5.473249e-04:  38%|███▊      | 6253/16329 [52:40<1:23:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6253: train loss 1.82586. lr 5.473249e-04:  38%|███▊      | 6254/16329 [52:40<1:23:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6254: train loss 1.86201. lr 5.473086e-04:  38%|███▊      | 6254/16329 [52:41<1:23:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6254: train loss 1.86201. lr 5.473086e-04:  38%|███▊      | 6255/16329 [52:41<1:23:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6255: train loss 1.80754. lr 5.472922e-04:  38%|███▊      | 6255/16329 [52:41<1:23:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6255: train loss 1.80754. lr 5.472922e-04:  38%|███▊      | 6256/16329 [52:41<1:23:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6256: train loss 1.85311. lr 5.472759e-04:  38%|███▊      | 6256/16329 [52:42<1:23:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6256: train loss 1.85311. lr 5.472759e-04:  38%|███▊      | 6257/16329 [52:42<1:23:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6257: train loss 1.82297. lr 5.472595e-04:  38%|███▊      | 6257/16329 [52:42<1:23:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6257: train loss 1.82297. lr 5.472595e-04:  38%|███▊      | 6258/16329 [52:42<1:31:52,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6258: train loss 1.76592. lr 5.472432e-04:  38%|███▊      | 6258/16329 [52:43<1:31:52,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6258: train loss 1.76592. lr 5.472432e-04:  38%|███▊      | 6259/16329 [52:43<1:29:08,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6259: train loss 1.85356. lr 5.472268e-04:  38%|███▊      | 6259/16329 [52:43<1:29:08,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6259: train loss 1.85356. lr 5.472268e-04:  38%|███▊      | 6260/16329 [52:43<1:27:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6260: train loss 1.87836. lr 5.472105e-04:  38%|███▊      | 6260/16329 [52:44<1:27:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6260: train loss 1.87836. lr 5.472105e-04:  38%|███▊      | 6261/16329 [52:44<1:25:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6261: train loss 1.86104. lr 5.471941e-04:  38%|███▊      | 6261/16329 [52:44<1:25:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6261: train loss 1.86104. lr 5.471941e-04:  38%|███▊      | 6262/16329 [52:44<1:24:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6262: train loss 1.80869. lr 5.471778e-04:  38%|███▊      | 6262/16329 [52:45<1:24:41,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6262: train loss 1.80869. lr 5.471778e-04:  38%|███▊      | 6263/16329 [52:45<1:24:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6263: train loss 1.78335. lr 5.471614e-04:  38%|███▊      | 6263/16329 [52:45<1:24:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6263: train loss 1.78335. lr 5.471614e-04:  38%|███▊      | 6264/16329 [52:45<1:23:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6264: train loss 1.83402. lr 5.471451e-04:  38%|███▊      | 6264/16329 [52:46<1:23:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6264: train loss 1.83402. lr 5.471451e-04:  38%|███▊      | 6265/16329 [52:46<1:23:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6265: train loss 1.85076. lr 5.471287e-04:  38%|███▊      | 6265/16329 [52:46<1:23:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6265: train loss 1.85076. lr 5.471287e-04:  38%|███▊      | 6266/16329 [52:46<1:23:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6266: train loss 1.80958. lr 5.471123e-04:  38%|███▊      | 6266/16329 [52:47<1:23:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6266: train loss 1.80958. lr 5.471123e-04:  38%|███▊      | 6267/16329 [52:47<1:23:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6267: train loss 1.86777. lr 5.470960e-04:  38%|███▊      | 6267/16329 [52:47<1:23:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6267: train loss 1.86777. lr 5.470960e-04:  38%|███▊      | 6268/16329 [52:47<1:23:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6268: train loss 1.80599. lr 5.470796e-04:  38%|███▊      | 6268/16329 [52:48<1:23:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6268: train loss 1.80599. lr 5.470796e-04:  38%|███▊      | 6269/16329 [52:48<1:23:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6269: train loss 1.83961. lr 5.470632e-04:  38%|███▊      | 6269/16329 [52:48<1:23:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6269: train loss 1.83961. lr 5.470632e-04:  38%|███▊      | 6270/16329 [52:48<1:23:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6270: train loss 1.81792. lr 5.470469e-04:  38%|███▊      | 6270/16329 [52:49<1:23:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6270: train loss 1.81792. lr 5.470469e-04:  38%|███▊      | 6271/16329 [52:49<1:23:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6271: train loss 1.82675. lr 5.470305e-04:  38%|███▊      | 6271/16329 [52:49<1:23:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6271: train loss 1.82675. lr 5.470305e-04:  38%|███▊      | 6272/16329 [52:49<1:22:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6272: train loss 1.80154. lr 5.470141e-04:  38%|███▊      | 6272/16329 [52:50<1:22:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6272: train loss 1.80154. lr 5.470141e-04:  38%|███▊      | 6273/16329 [52:50<1:24:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6273: train loss 1.79714. lr 5.469977e-04:  38%|███▊      | 6273/16329 [52:50<1:24:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6273: train loss 1.79714. lr 5.469977e-04:  38%|███▊      | 6274/16329 [52:50<1:25:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6274: train loss 1.83440. lr 5.469814e-04:  38%|███▊      | 6274/16329 [52:51<1:25:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6274: train loss 1.83440. lr 5.469814e-04:  38%|███▊      | 6275/16329 [52:51<1:26:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6275: train loss 1.77272. lr 5.469650e-04:  38%|███▊      | 6275/16329 [52:51<1:26:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6275: train loss 1.77272. lr 5.469650e-04:  38%|███▊      | 6276/16329 [52:51<1:25:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6276: train loss 1.78684. lr 5.469486e-04:  38%|███▊      | 6276/16329 [52:52<1:25:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6276: train loss 1.78684. lr 5.469486e-04:  38%|███▊      | 6277/16329 [52:52<1:25:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6277: train loss 1.78622. lr 5.469322e-04:  38%|███▊      | 6277/16329 [52:52<1:25:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6277: train loss 1.78622. lr 5.469322e-04:  38%|███▊      | 6278/16329 [52:52<1:25:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6278: train loss 1.80010. lr 5.469158e-04:  38%|███▊      | 6278/16329 [52:53<1:25:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6278: train loss 1.80010. lr 5.469158e-04:  38%|███▊      | 6279/16329 [52:53<1:24:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6279: train loss 1.79868. lr 5.468994e-04:  38%|███▊      | 6279/16329 [52:53<1:24:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6279: train loss 1.79868. lr 5.468994e-04:  38%|███▊      | 6280/16329 [52:53<1:24:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6280: train loss 1.81428. lr 5.468830e-04:  38%|███▊      | 6280/16329 [52:54<1:24:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6280: train loss 1.81428. lr 5.468830e-04:  38%|███▊      | 6281/16329 [52:54<1:24:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6281: train loss 1.83042. lr 5.468666e-04:  38%|███▊      | 6281/16329 [52:54<1:24:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6281: train loss 1.83042. lr 5.468666e-04:  38%|███▊      | 6282/16329 [52:54<1:23:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6282: train loss 1.86015. lr 5.468502e-04:  38%|███▊      | 6282/16329 [52:55<1:23:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6282: train loss 1.86015. lr 5.468502e-04:  38%|███▊      | 6283/16329 [52:55<1:23:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6283: train loss 1.78960. lr 5.468338e-04:  38%|███▊      | 6283/16329 [52:55<1:23:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6283: train loss 1.78960. lr 5.468338e-04:  38%|███▊      | 6284/16329 [52:55<1:23:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6284: train loss 1.81343. lr 5.468174e-04:  38%|███▊      | 6284/16329 [52:56<1:23:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6284: train loss 1.81343. lr 5.468174e-04:  38%|███▊      | 6285/16329 [52:56<1:23:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6285: train loss 1.76731. lr 5.468010e-04:  38%|███▊      | 6285/16329 [52:56<1:23:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6285: train loss 1.76731. lr 5.468010e-04:  38%|███▊      | 6286/16329 [52:56<1:23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6286: train loss 1.84433. lr 5.467846e-04:  38%|███▊      | 6286/16329 [52:57<1:23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6286: train loss 1.84433. lr 5.467846e-04:  39%|███▊      | 6287/16329 [52:57<1:22:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6287: train loss 1.80061. lr 5.467682e-04:  39%|███▊      | 6287/16329 [52:57<1:22:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6287: train loss 1.80061. lr 5.467682e-04:  39%|███▊      | 6288/16329 [52:57<1:22:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6288: train loss 1.75922. lr 5.467518e-04:  39%|███▊      | 6288/16329 [52:58<1:22:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6288: train loss 1.75922. lr 5.467518e-04:  39%|███▊      | 6289/16329 [52:58<1:22:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6289: train loss 1.78646. lr 5.467354e-04:  39%|███▊      | 6289/16329 [52:58<1:22:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6289: train loss 1.78646. lr 5.467354e-04:  39%|███▊      | 6290/16329 [52:58<1:23:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6290: train loss 1.81643. lr 5.467189e-04:  39%|███▊      | 6290/16329 [52:59<1:23:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6290: train loss 1.81643. lr 5.467189e-04:  39%|███▊      | 6291/16329 [52:59<1:22:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6291: train loss 1.81845. lr 5.467025e-04:  39%|███▊      | 6291/16329 [52:59<1:22:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6291: train loss 1.81845. lr 5.467025e-04:  39%|███▊      | 6292/16329 [52:59<1:22:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6292: train loss 1.80405. lr 5.466861e-04:  39%|███▊      | 6292/16329 [53:00<1:22:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6292: train loss 1.80405. lr 5.466861e-04:  39%|███▊      | 6293/16329 [53:00<1:31:34,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6293: train loss 1.76985. lr 5.466697e-04:  39%|███▊      | 6293/16329 [53:00<1:31:34,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6293: train loss 1.76985. lr 5.466697e-04:  39%|███▊      | 6294/16329 [53:00<1:28:49,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6294: train loss 1.80420. lr 5.466533e-04:  39%|███▊      | 6294/16329 [53:01<1:28:49,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6294: train loss 1.80420. lr 5.466533e-04:  39%|███▊      | 6295/16329 [53:01<1:27:03,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6295: train loss 1.76062. lr 5.466368e-04:  39%|███▊      | 6295/16329 [53:01<1:27:03,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6295: train loss 1.76062. lr 5.466368e-04:  39%|███▊      | 6296/16329 [53:01<1:25:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6296: train loss 1.79455. lr 5.466204e-04:  39%|███▊      | 6296/16329 [53:02<1:25:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6296: train loss 1.79455. lr 5.466204e-04:  39%|███▊      | 6297/16329 [53:02<1:24:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6297: train loss 1.79809. lr 5.466040e-04:  39%|███▊      | 6297/16329 [53:02<1:24:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6297: train loss 1.79809. lr 5.466040e-04:  39%|███▊      | 6298/16329 [53:02<1:24:05,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6298: train loss 1.84208. lr 5.465875e-04:  39%|███▊      | 6298/16329 [53:03<1:24:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6298: train loss 1.84208. lr 5.465875e-04:  39%|███▊      | 6299/16329 [53:03<1:23:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6299: train loss 1.81325. lr 5.465711e-04:  39%|███▊      | 6299/16329 [53:03<1:23:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6299: train loss 1.81325. lr 5.465711e-04:  39%|███▊      | 6300/16329 [53:03<1:23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6300: train loss 1.84984. lr 5.465546e-04:  39%|███▊      | 6300/16329 [53:04<1:23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6300: train loss 1.84984. lr 5.465546e-04:  39%|███▊      | 6301/16329 [53:04<1:23:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6301: train loss 1.77927. lr 5.465382e-04:  39%|███▊      | 6301/16329 [53:04<1:23:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6301: train loss 1.77927. lr 5.465382e-04:  39%|███▊      | 6302/16329 [53:04<1:22:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6302: train loss 1.83005. lr 5.465218e-04:  39%|███▊      | 6302/16329 [53:05<1:22:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6302: train loss 1.83005. lr 5.465218e-04:  39%|███▊      | 6303/16329 [53:05<1:22:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6303: train loss 1.83455. lr 5.465053e-04:  39%|███▊      | 6303/16329 [53:05<1:22:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6303: train loss 1.83455. lr 5.465053e-04:  39%|███▊      | 6304/16329 [53:05<1:22:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6304: train loss 1.80524. lr 5.464889e-04:  39%|███▊      | 6304/16329 [53:06<1:22:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6304: train loss 1.80524. lr 5.464889e-04:  39%|███▊      | 6305/16329 [53:06<1:22:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6305: train loss 1.80160. lr 5.464724e-04:  39%|███▊      | 6305/16329 [53:06<1:22:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6305: train loss 1.80160. lr 5.464724e-04:  39%|███▊      | 6306/16329 [53:06<1:22:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6306: train loss 1.82551. lr 5.464560e-04:  39%|███▊      | 6306/16329 [53:07<1:22:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6306: train loss 1.82551. lr 5.464560e-04:  39%|███▊      | 6307/16329 [53:07<1:22:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6307: train loss 1.83018. lr 5.464395e-04:  39%|███▊      | 6307/16329 [53:07<1:22:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6307: train loss 1.83018. lr 5.464395e-04:  39%|███▊      | 6308/16329 [53:07<1:22:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6308: train loss 1.80394. lr 5.464230e-04:  39%|███▊      | 6308/16329 [53:08<1:22:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6308: train loss 1.80394. lr 5.464230e-04:  39%|███▊      | 6309/16329 [53:08<1:22:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6309: train loss 1.86469. lr 5.464066e-04:  39%|███▊      | 6309/16329 [53:08<1:22:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6309: train loss 1.86469. lr 5.464066e-04:  39%|███▊      | 6310/16329 [53:08<1:22:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6310: train loss 1.81006. lr 5.463901e-04:  39%|███▊      | 6310/16329 [53:09<1:22:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6310: train loss 1.81006. lr 5.463901e-04:  39%|███▊      | 6311/16329 [53:09<1:22:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6311: train loss 1.82627. lr 5.463736e-04:  39%|███▊      | 6311/16329 [53:09<1:22:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6311: train loss 1.82627. lr 5.463736e-04:  39%|███▊      | 6312/16329 [53:09<1:22:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6312: train loss 1.73887. lr 5.463572e-04:  39%|███▊      | 6312/16329 [53:10<1:22:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6312: train loss 1.73887. lr 5.463572e-04:  39%|███▊      | 6313/16329 [53:10<1:22:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6313: train loss 1.83498. lr 5.463407e-04:  39%|███▊      | 6313/16329 [53:10<1:22:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6313: train loss 1.83498. lr 5.463407e-04:  39%|███▊      | 6314/16329 [53:10<1:22:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6314: train loss 1.80093. lr 5.463242e-04:  39%|███▊      | 6314/16329 [53:11<1:22:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6314: train loss 1.80093. lr 5.463242e-04:  39%|███▊      | 6315/16329 [53:11<1:22:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6315: train loss 1.83703. lr 5.463078e-04:  39%|███▊      | 6315/16329 [53:11<1:22:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6315: train loss 1.83703. lr 5.463078e-04:  39%|███▊      | 6316/16329 [53:11<1:22:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6316: train loss 1.82734. lr 5.462913e-04:  39%|███▊      | 6316/16329 [53:12<1:22:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6316: train loss 1.82734. lr 5.462913e-04:  39%|███▊      | 6317/16329 [53:12<1:22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6317: train loss 1.79915. lr 5.462748e-04:  39%|███▊      | 6317/16329 [53:12<1:22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6317: train loss 1.79915. lr 5.462748e-04:  39%|███▊      | 6318/16329 [53:12<1:31:31,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6318: train loss 1.80534. lr 5.462583e-04:  39%|███▊      | 6318/16329 [53:13<1:31:31,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6318: train loss 1.80534. lr 5.462583e-04:  39%|███▊      | 6319/16329 [53:13<1:28:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6319: train loss 1.80269. lr 5.462418e-04:  39%|███▊      | 6319/16329 [53:13<1:28:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6319: train loss 1.80269. lr 5.462418e-04:  39%|███▊      | 6320/16329 [53:13<1:26:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6320: train loss 1.83957. lr 5.462254e-04:  39%|███▊      | 6320/16329 [53:14<1:26:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6320: train loss 1.83957. lr 5.462254e-04:  39%|███▊      | 6321/16329 [53:14<1:25:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6321: train loss 1.76101. lr 5.462089e-04:  39%|███▊      | 6321/16329 [53:14<1:25:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6321: train loss 1.76101. lr 5.462089e-04:  39%|███▊      | 6322/16329 [53:14<1:24:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6322: train loss 1.83318. lr 5.461924e-04:  39%|███▊      | 6322/16329 [53:15<1:24:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6322: train loss 1.83318. lr 5.461924e-04:  39%|███▊      | 6323/16329 [53:15<1:23:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6323: train loss 1.81928. lr 5.461759e-04:  39%|███▊      | 6323/16329 [53:15<1:23:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6323: train loss 1.81928. lr 5.461759e-04:  39%|███▊      | 6324/16329 [53:15<1:23:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6324: train loss 1.78172. lr 5.461594e-04:  39%|███▊      | 6324/16329 [53:16<1:23:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6324: train loss 1.78172. lr 5.461594e-04:  39%|███▊      | 6325/16329 [53:16<1:23:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6325: train loss 1.78292. lr 5.461429e-04:  39%|███▊      | 6325/16329 [53:16<1:23:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6325: train loss 1.78292. lr 5.461429e-04:  39%|███▊      | 6326/16329 [53:16<1:24:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6326: train loss 1.83207. lr 5.461264e-04:  39%|███▊      | 6326/16329 [53:17<1:24:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6326: train loss 1.83207. lr 5.461264e-04:  39%|███▊      | 6327/16329 [53:17<1:24:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6327: train loss 1.81117. lr 5.461099e-04:  39%|███▊      | 6327/16329 [53:17<1:24:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6327: train loss 1.81117. lr 5.461099e-04:  39%|███▉      | 6328/16329 [53:17<1:25:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6328: train loss 1.77543. lr 5.460934e-04:  39%|███▉      | 6328/16329 [53:18<1:25:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6328: train loss 1.77543. lr 5.460934e-04:  39%|███▉      | 6329/16329 [53:18<1:25:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6329: train loss 1.79796. lr 5.460769e-04:  39%|███▉      | 6329/16329 [53:18<1:25:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6329: train loss 1.79796. lr 5.460769e-04:  39%|███▉      | 6330/16329 [53:18<1:25:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6330: train loss 1.81779. lr 5.460604e-04:  39%|███▉      | 6330/16329 [53:19<1:25:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6330: train loss 1.81779. lr 5.460604e-04:  39%|███▉      | 6331/16329 [53:19<1:24:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6331: train loss 1.83574. lr 5.460439e-04:  39%|███▉      | 6331/16329 [53:19<1:24:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6331: train loss 1.83574. lr 5.460439e-04:  39%|███▉      | 6332/16329 [53:19<1:24:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6332: train loss 1.76746. lr 5.460273e-04:  39%|███▉      | 6332/16329 [53:20<1:24:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6332: train loss 1.76746. lr 5.460273e-04:  39%|███▉      | 6333/16329 [53:20<1:23:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6333: train loss 1.79781. lr 5.460108e-04:  39%|███▉      | 6333/16329 [53:20<1:23:53,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6333: train loss 1.79781. lr 5.460108e-04:  39%|███▉      | 6334/16329 [53:20<1:23:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6334: train loss 1.78920. lr 5.459943e-04:  39%|███▉      | 6334/16329 [53:21<1:23:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6334: train loss 1.78920. lr 5.459943e-04:  39%|███▉      | 6335/16329 [53:21<1:22:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6335: train loss 1.84766. lr 5.459778e-04:  39%|███▉      | 6335/16329 [53:21<1:22:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6335: train loss 1.84766. lr 5.459778e-04:  39%|███▉      | 6336/16329 [53:21<1:22:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6336: train loss 1.79143. lr 5.459613e-04:  39%|███▉      | 6336/16329 [53:22<1:22:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6336: train loss 1.79143. lr 5.459613e-04:  39%|███▉      | 6337/16329 [53:22<1:22:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6337: train loss 1.78146. lr 5.459447e-04:  39%|███▉      | 6337/16329 [53:22<1:22:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6337: train loss 1.78146. lr 5.459447e-04:  39%|███▉      | 6338/16329 [53:22<1:22:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6338: train loss 1.82482. lr 5.459282e-04:  39%|███▉      | 6338/16329 [53:23<1:22:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6338: train loss 1.82482. lr 5.459282e-04:  39%|███▉      | 6339/16329 [53:23<1:22:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6339: train loss 1.81440. lr 5.459117e-04:  39%|███▉      | 6339/16329 [53:23<1:22:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6339: train loss 1.81440. lr 5.459117e-04:  39%|███▉      | 6340/16329 [53:23<1:22:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6340: train loss 1.78205. lr 5.458951e-04:  39%|███▉      | 6340/16329 [53:24<1:22:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6340: train loss 1.78205. lr 5.458951e-04:  39%|███▉      | 6341/16329 [53:24<1:22:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6341: train loss 1.83235. lr 5.458786e-04:  39%|███▉      | 6341/16329 [53:24<1:22:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6341: train loss 1.83235. lr 5.458786e-04:  39%|███▉      | 6342/16329 [53:24<1:22:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6342: train loss 1.83020. lr 5.458621e-04:  39%|███▉      | 6342/16329 [53:25<1:22:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6342: train loss 1.83020. lr 5.458621e-04:  39%|███▉      | 6343/16329 [53:25<1:22:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6343: train loss 1.79503. lr 5.458455e-04:  39%|███▉      | 6343/16329 [53:25<1:22:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6343: train loss 1.79503. lr 5.458455e-04:  39%|███▉      | 6344/16329 [53:25<1:22:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6344: train loss 1.77355. lr 5.458290e-04:  39%|███▉      | 6344/16329 [53:26<1:22:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6344: train loss 1.77355. lr 5.458290e-04:  39%|███▉      | 6345/16329 [53:26<1:31:02,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6345: train loss 1.79339. lr 5.458125e-04:  39%|███▉      | 6345/16329 [53:27<1:31:02,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6345: train loss 1.79339. lr 5.458125e-04:  39%|███▉      | 6346/16329 [53:27<1:28:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6346: train loss 1.79467. lr 5.457959e-04:  39%|███▉      | 6346/16329 [53:27<1:28:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6346: train loss 1.79467. lr 5.457959e-04:  39%|███▉      | 6347/16329 [53:27<1:26:23,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6347: train loss 1.81889. lr 5.457794e-04:  39%|███▉      | 6347/16329 [53:28<1:26:23,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6347: train loss 1.81889. lr 5.457794e-04:  39%|███▉      | 6348/16329 [53:28<1:25:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6348: train loss 1.79010. lr 5.457628e-04:  39%|███▉      | 6348/16329 [53:28<1:25:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6348: train loss 1.79010. lr 5.457628e-04:  39%|███▉      | 6349/16329 [53:28<1:24:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6349: train loss 1.80171. lr 5.457463e-04:  39%|███▉      | 6349/16329 [53:28<1:24:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6349: train loss 1.80171. lr 5.457463e-04:  39%|███▉      | 6350/16329 [53:28<1:23:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6350: train loss 1.80356. lr 5.457297e-04:  39%|███▉      | 6350/16329 [53:29<1:23:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6350: train loss 1.80356. lr 5.457297e-04:  39%|███▉      | 6351/16329 [53:29<1:23:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6351: train loss 1.80745. lr 5.457131e-04:  39%|███▉      | 6351/16329 [53:29<1:23:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6351: train loss 1.80745. lr 5.457131e-04:  39%|███▉      | 6352/16329 [53:29<1:22:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6352: train loss 1.80192. lr 5.456966e-04:  39%|███▉      | 6352/16329 [53:30<1:22:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6352: train loss 1.80192. lr 5.456966e-04:  39%|███▉      | 6353/16329 [53:30<1:22:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6353: train loss 1.84935. lr 5.456800e-04:  39%|███▉      | 6353/16329 [53:30<1:22:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6353: train loss 1.84935. lr 5.456800e-04:  39%|███▉      | 6354/16329 [53:30<1:22:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6354: train loss 1.78174. lr 5.456635e-04:  39%|███▉      | 6354/16329 [53:31<1:22:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6354: train loss 1.78174. lr 5.456635e-04:  39%|███▉      | 6355/16329 [53:31<1:22:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6355: train loss 1.78918. lr 5.456469e-04:  39%|███▉      | 6355/16329 [53:31<1:22:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6355: train loss 1.78918. lr 5.456469e-04:  39%|███▉      | 6356/16329 [53:31<1:22:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6356: train loss 1.80534. lr 5.456303e-04:  39%|███▉      | 6356/16329 [53:32<1:22:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6356: train loss 1.80534. lr 5.456303e-04:  39%|███▉      | 6357/16329 [53:32<1:22:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6357: train loss 1.78748. lr 5.456138e-04:  39%|███▉      | 6357/16329 [53:32<1:22:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6357: train loss 1.78748. lr 5.456138e-04:  39%|███▉      | 6358/16329 [53:32<1:22:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6358: train loss 1.84475. lr 5.455972e-04:  39%|███▉      | 6358/16329 [53:33<1:22:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6358: train loss 1.84475. lr 5.455972e-04:  39%|███▉      | 6359/16329 [53:33<1:21:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6359: train loss 1.74983. lr 5.455806e-04:  39%|███▉      | 6359/16329 [53:33<1:21:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6359: train loss 1.74983. lr 5.455806e-04:  39%|███▉      | 6360/16329 [53:33<1:22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6360: train loss 1.78319. lr 5.455640e-04:  39%|███▉      | 6360/16329 [53:34<1:22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6360: train loss 1.78319. lr 5.455640e-04:  39%|███▉      | 6361/16329 [53:34<1:22:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6361: train loss 1.78043. lr 5.455475e-04:  39%|███▉      | 6361/16329 [53:34<1:22:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6361: train loss 1.78043. lr 5.455475e-04:  39%|███▉      | 6362/16329 [53:34<1:21:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6362: train loss 1.83481. lr 5.455309e-04:  39%|███▉      | 6362/16329 [53:35<1:21:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6362: train loss 1.83481. lr 5.455309e-04:  39%|███▉      | 6363/16329 [53:35<1:22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6363: train loss 1.77590. lr 5.455143e-04:  39%|███▉      | 6363/16329 [53:35<1:22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6363: train loss 1.77590. lr 5.455143e-04:  39%|███▉      | 6364/16329 [53:35<1:21:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6364: train loss 1.84797. lr 5.454977e-04:  39%|███▉      | 6364/16329 [53:36<1:21:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6364: train loss 1.84797. lr 5.454977e-04:  39%|███▉      | 6365/16329 [53:36<1:22:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6365: train loss 1.78166. lr 5.454811e-04:  39%|███▉      | 6365/16329 [53:36<1:22:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6365: train loss 1.78166. lr 5.454811e-04:  39%|███▉      | 6366/16329 [53:36<1:21:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6366: train loss 1.76474. lr 5.454645e-04:  39%|███▉      | 6366/16329 [53:37<1:21:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6366: train loss 1.76474. lr 5.454645e-04:  39%|███▉      | 6367/16329 [53:37<1:22:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6367: train loss 1.77532. lr 5.454479e-04:  39%|███▉      | 6367/16329 [53:37<1:22:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6367: train loss 1.77532. lr 5.454479e-04:  39%|███▉      | 6368/16329 [53:37<1:22:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6368: train loss 1.82512. lr 5.454313e-04:  39%|███▉      | 6368/16329 [53:38<1:22:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6368: train loss 1.82512. lr 5.454313e-04:  39%|███▉      | 6369/16329 [53:38<1:22:18,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6369: train loss 1.79958. lr 5.454147e-04:  39%|███▉      | 6369/16329 [53:38<1:22:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6369: train loss 1.79958. lr 5.454147e-04:  39%|███▉      | 6370/16329 [53:38<1:24:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6370: train loss 1.84857. lr 5.453981e-04:  39%|███▉      | 6370/16329 [53:39<1:24:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6370: train loss 1.84857. lr 5.453981e-04:  39%|███▉      | 6371/16329 [53:39<1:26:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6371: train loss 1.79417. lr 5.453815e-04:  39%|███▉      | 6371/16329 [53:40<1:26:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6371: train loss 1.79417. lr 5.453815e-04:  39%|███▉      | 6372/16329 [53:40<1:27:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6372: train loss 1.79134. lr 5.453649e-04:  39%|███▉      | 6372/16329 [53:40<1:27:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6372: train loss 1.79134. lr 5.453649e-04:  39%|███▉      | 6373/16329 [53:40<1:26:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6373: train loss 1.74043. lr 5.453483e-04:  39%|███▉      | 6373/16329 [53:41<1:26:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6373: train loss 1.74043. lr 5.453483e-04:  39%|███▉      | 6374/16329 [53:41<1:26:30,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6374: train loss 1.75845. lr 5.453317e-04:  39%|███▉      | 6374/16329 [53:41<1:26:30,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6374: train loss 1.75845. lr 5.453317e-04:  39%|███▉      | 6375/16329 [53:41<1:25:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6375: train loss 1.79059. lr 5.453151e-04:  39%|███▉      | 6375/16329 [53:42<1:25:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6375: train loss 1.79059. lr 5.453151e-04:  39%|███▉      | 6376/16329 [53:42<1:24:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6376: train loss 1.77971. lr 5.452985e-04:  39%|███▉      | 6376/16329 [53:42<1:24:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6376: train loss 1.77971. lr 5.452985e-04:  39%|███▉      | 6377/16329 [53:42<1:24:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6377: train loss 1.80384. lr 5.452819e-04:  39%|███▉      | 6377/16329 [53:43<1:24:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6377: train loss 1.80384. lr 5.452819e-04:  39%|███▉      | 6378/16329 [53:43<1:23:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6378: train loss 1.76094. lr 5.452652e-04:  39%|███▉      | 6378/16329 [53:43<1:23:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6378: train loss 1.76094. lr 5.452652e-04:  39%|███▉      | 6379/16329 [53:43<1:23:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6379: train loss 1.80245. lr 5.452486e-04:  39%|███▉      | 6379/16329 [53:44<1:23:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6379: train loss 1.80245. lr 5.452486e-04:  39%|███▉      | 6380/16329 [53:44<1:22:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6380: train loss 1.80611. lr 5.452320e-04:  39%|███▉      | 6380/16329 [53:44<1:22:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6380: train loss 1.80611. lr 5.452320e-04:  39%|███▉      | 6381/16329 [53:44<1:22:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6381: train loss 1.79581. lr 5.452154e-04:  39%|███▉      | 6381/16329 [53:45<1:22:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6381: train loss 1.79581. lr 5.452154e-04:  39%|███▉      | 6382/16329 [53:45<1:24:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6382: train loss 1.74531. lr 5.451988e-04:  39%|███▉      | 6382/16329 [53:45<1:24:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6382: train loss 1.74531. lr 5.451988e-04:  39%|███▉      | 6383/16329 [53:45<1:24:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6383: train loss 1.77834. lr 5.451821e-04:  39%|███▉      | 6383/16329 [53:46<1:24:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6383: train loss 1.77834. lr 5.451821e-04:  39%|███▉      | 6384/16329 [53:46<1:25:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6384: train loss 1.80600. lr 5.451655e-04:  39%|███▉      | 6384/16329 [53:46<1:25:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6384: train loss 1.80600. lr 5.451655e-04:  39%|███▉      | 6385/16329 [53:46<1:33:35,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 6385: train loss 1.82499. lr 5.451489e-04:  39%|███▉      | 6385/16329 [53:47<1:33:35,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 6385: train loss 1.82499. lr 5.451489e-04:  39%|███▉      | 6386/16329 [53:47<1:30:11,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6386: train loss 1.84695. lr 5.451322e-04:  39%|███▉      | 6386/16329 [53:47<1:30:11,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6386: train loss 1.84695. lr 5.451322e-04:  39%|███▉      | 6387/16329 [53:47<1:27:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6387: train loss 1.79788. lr 5.451156e-04:  39%|███▉      | 6387/16329 [53:48<1:27:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6387: train loss 1.79788. lr 5.451156e-04:  39%|███▉      | 6388/16329 [53:48<1:26:06,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6388: train loss 1.79491. lr 5.450989e-04:  39%|███▉      | 6388/16329 [53:48<1:26:06,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6388: train loss 1.79491. lr 5.450989e-04:  39%|███▉      | 6389/16329 [53:48<1:24:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6389: train loss 1.78454. lr 5.450823e-04:  39%|███▉      | 6389/16329 [53:49<1:24:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6389: train loss 1.78454. lr 5.450823e-04:  39%|███▉      | 6390/16329 [53:49<1:23:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6390: train loss 1.80141. lr 5.450657e-04:  39%|███▉      | 6390/16329 [53:49<1:23:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6390: train loss 1.80141. lr 5.450657e-04:  39%|███▉      | 6391/16329 [53:49<1:23:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6391: train loss 1.81253. lr 5.450490e-04:  39%|███▉      | 6391/16329 [53:50<1:23:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6391: train loss 1.81253. lr 5.450490e-04:  39%|███▉      | 6392/16329 [53:50<1:22:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6392: train loss 1.77908. lr 5.450324e-04:  39%|███▉      | 6392/16329 [53:50<1:22:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6392: train loss 1.77908. lr 5.450324e-04:  39%|███▉      | 6393/16329 [53:50<1:22:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6393: train loss 1.78384. lr 5.450157e-04:  39%|███▉      | 6393/16329 [53:51<1:22:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6393: train loss 1.78384. lr 5.450157e-04:  39%|███▉      | 6394/16329 [53:51<1:25:48,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6394: train loss 1.80353. lr 5.449990e-04:  39%|███▉      | 6394/16329 [53:51<1:25:48,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6394: train loss 1.80353. lr 5.449990e-04:  39%|███▉      | 6395/16329 [53:51<1:26:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6395: train loss 1.81889. lr 5.449824e-04:  39%|███▉      | 6395/16329 [53:52<1:26:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6395: train loss 1.81889. lr 5.449824e-04:  39%|███▉      | 6396/16329 [53:52<1:26:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6396: train loss 1.79752. lr 5.449657e-04:  39%|███▉      | 6396/16329 [53:52<1:26:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6396: train loss 1.79752. lr 5.449657e-04:  39%|███▉      | 6397/16329 [53:52<1:25:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6397: train loss 1.76562. lr 5.449491e-04:  39%|███▉      | 6397/16329 [53:53<1:25:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6397: train loss 1.76562. lr 5.449491e-04:  39%|███▉      | 6398/16329 [53:53<1:24:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6398: train loss 1.79473. lr 5.449324e-04:  39%|███▉      | 6398/16329 [53:53<1:24:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6398: train loss 1.79473. lr 5.449324e-04:  39%|███▉      | 6399/16329 [53:53<1:23:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6399: train loss 1.73946. lr 5.449157e-04:  39%|███▉      | 6399/16329 [53:54<1:23:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6399: train loss 1.73946. lr 5.449157e-04:  39%|███▉      | 6400/16329 [53:54<1:22:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6400: train loss 1.80994. lr 5.448991e-04:  39%|███▉      | 6400/16329 [53:54<1:22:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6400: train loss 1.80994. lr 5.448991e-04:  39%|███▉      | 6401/16329 [53:54<1:22:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6401: train loss 1.81911. lr 5.448824e-04:  39%|███▉      | 6401/16329 [53:55<1:22:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6401: train loss 1.81911. lr 5.448824e-04:  39%|███▉      | 6402/16329 [53:55<1:23:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6402: train loss 1.84998. lr 5.448657e-04:  39%|███▉      | 6402/16329 [53:55<1:23:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6402: train loss 1.84998. lr 5.448657e-04:  39%|███▉      | 6403/16329 [53:55<1:23:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6403: train loss 1.81279. lr 5.448491e-04:  39%|███▉      | 6403/16329 [53:56<1:23:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6403: train loss 1.81279. lr 5.448491e-04:  39%|███▉      | 6404/16329 [53:56<1:22:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6404: train loss 1.76044. lr 5.448324e-04:  39%|███▉      | 6404/16329 [53:56<1:22:58,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6404: train loss 1.76044. lr 5.448324e-04:  39%|███▉      | 6405/16329 [53:56<1:22:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6405: train loss 1.83657. lr 5.448157e-04:  39%|███▉      | 6405/16329 [53:57<1:22:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6405: train loss 1.83657. lr 5.448157e-04:  39%|███▉      | 6406/16329 [53:57<1:22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6406: train loss 1.77945. lr 5.447990e-04:  39%|███▉      | 6406/16329 [53:57<1:22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6406: train loss 1.77945. lr 5.447990e-04:  39%|███▉      | 6407/16329 [53:57<1:21:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6407: train loss 1.77672. lr 5.447823e-04:  39%|███▉      | 6407/16329 [53:58<1:21:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6407: train loss 1.77672. lr 5.447823e-04:  39%|███▉      | 6408/16329 [53:58<1:21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6408: train loss 1.83339. lr 5.447656e-04:  39%|███▉      | 6408/16329 [53:58<1:21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6408: train loss 1.83339. lr 5.447656e-04:  39%|███▉      | 6409/16329 [53:58<1:21:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6409: train loss 1.82834. lr 5.447490e-04:  39%|███▉      | 6409/16329 [53:59<1:21:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6409: train loss 1.82834. lr 5.447490e-04:  39%|███▉      | 6410/16329 [53:59<1:21:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6410: train loss 1.80030. lr 5.447323e-04:  39%|███▉      | 6410/16329 [53:59<1:21:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6410: train loss 1.80030. lr 5.447323e-04:  39%|███▉      | 6411/16329 [53:59<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6411: train loss 1.76387. lr 5.447156e-04:  39%|███▉      | 6411/16329 [54:00<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6411: train loss 1.76387. lr 5.447156e-04:  39%|███▉      | 6412/16329 [54:00<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6412: train loss 1.79268. lr 5.446989e-04:  39%|███▉      | 6412/16329 [54:00<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6412: train loss 1.79268. lr 5.446989e-04:  39%|███▉      | 6413/16329 [54:00<1:21:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6413: train loss 1.73520. lr 5.446822e-04:  39%|███▉      | 6413/16329 [54:01<1:21:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6413: train loss 1.73520. lr 5.446822e-04:  39%|███▉      | 6414/16329 [54:01<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6414: train loss 1.73969. lr 5.446655e-04:  39%|███▉      | 6414/16329 [54:01<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6414: train loss 1.73969. lr 5.446655e-04:  39%|███▉      | 6415/16329 [54:01<1:21:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6415: train loss 1.76143. lr 5.446488e-04:  39%|███▉      | 6415/16329 [54:02<1:21:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6415: train loss 1.76143. lr 5.446488e-04:  39%|███▉      | 6416/16329 [54:02<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6416: train loss 1.83042. lr 5.446321e-04:  39%|███▉      | 6416/16329 [54:02<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6416: train loss 1.83042. lr 5.446321e-04:  39%|███▉      | 6417/16329 [54:02<1:21:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6417: train loss 1.84551. lr 5.446154e-04:  39%|███▉      | 6417/16329 [54:03<1:21:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6417: train loss 1.84551. lr 5.446154e-04:  39%|███▉      | 6418/16329 [54:03<1:21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6418: train loss 1.83004. lr 5.445987e-04:  39%|███▉      | 6418/16329 [54:03<1:21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6418: train loss 1.83004. lr 5.445987e-04:  39%|███▉      | 6419/16329 [54:03<1:21:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6419: train loss 1.75405. lr 5.445819e-04:  39%|███▉      | 6419/16329 [54:04<1:21:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6419: train loss 1.75405. lr 5.445819e-04:  39%|███▉      | 6420/16329 [54:04<1:33:43,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 6420: train loss 1.79064. lr 5.445652e-04:  39%|███▉      | 6420/16329 [54:04<1:33:43,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 6420: train loss 1.79064. lr 5.445652e-04:  39%|███▉      | 6421/16329 [54:04<1:29:38,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6421: train loss 1.84883. lr 5.445485e-04:  39%|███▉      | 6421/16329 [54:05<1:29:38,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6421: train loss 1.84883. lr 5.445485e-04:  39%|███▉      | 6422/16329 [54:05<1:27:17,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6422: train loss 1.80897. lr 5.445318e-04:  39%|███▉      | 6422/16329 [54:05<1:27:17,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6422: train loss 1.80897. lr 5.445318e-04:  39%|███▉      | 6423/16329 [54:05<1:25:24,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6423: train loss 1.77911. lr 5.445151e-04:  39%|███▉      | 6423/16329 [54:06<1:25:24,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6423: train loss 1.77911. lr 5.445151e-04:  39%|███▉      | 6424/16329 [54:06<1:24:06,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6424: train loss 1.78235. lr 5.444984e-04:  39%|███▉      | 6424/16329 [54:06<1:24:06,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6424: train loss 1.78235. lr 5.444984e-04:  39%|███▉      | 6425/16329 [54:06<1:23:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6425: train loss 1.81190. lr 5.444816e-04:  39%|███▉      | 6425/16329 [54:07<1:23:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6425: train loss 1.81190. lr 5.444816e-04:  39%|███▉      | 6426/16329 [54:07<1:22:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6426: train loss 1.83206. lr 5.444649e-04:  39%|███▉      | 6426/16329 [54:07<1:22:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6426: train loss 1.83206. lr 5.444649e-04:  39%|███▉      | 6427/16329 [54:07<1:22:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6427: train loss 1.73356. lr 5.444482e-04:  39%|███▉      | 6427/16329 [54:08<1:22:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6427: train loss 1.73356. lr 5.444482e-04:  39%|███▉      | 6428/16329 [54:08<1:21:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6428: train loss 1.76104. lr 5.444314e-04:  39%|███▉      | 6428/16329 [54:08<1:21:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6428: train loss 1.76104. lr 5.444314e-04:  39%|███▉      | 6429/16329 [54:08<1:21:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6429: train loss 1.85476. lr 5.444147e-04:  39%|███▉      | 6429/16329 [54:09<1:21:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6429: train loss 1.85476. lr 5.444147e-04:  39%|███▉      | 6430/16329 [54:09<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6430: train loss 1.76829. lr 5.443980e-04:  39%|███▉      | 6430/16329 [54:09<1:21:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6430: train loss 1.76829. lr 5.443980e-04:  39%|███▉      | 6431/16329 [54:09<1:21:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6431: train loss 1.79202. lr 5.443812e-04:  39%|███▉      | 6431/16329 [54:10<1:21:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6431: train loss 1.79202. lr 5.443812e-04:  39%|███▉      | 6432/16329 [54:10<1:21:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6432: train loss 1.81742. lr 5.443645e-04:  39%|███▉      | 6432/16329 [54:10<1:21:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6432: train loss 1.81742. lr 5.443645e-04:  39%|███▉      | 6433/16329 [54:10<1:21:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6433: train loss 1.75532. lr 5.443478e-04:  39%|███▉      | 6433/16329 [54:11<1:21:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6433: train loss 1.75532. lr 5.443478e-04:  39%|███▉      | 6434/16329 [54:11<1:21:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6434: train loss 1.78712. lr 5.443310e-04:  39%|███▉      | 6434/16329 [54:11<1:21:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6434: train loss 1.78712. lr 5.443310e-04:  39%|███▉      | 6435/16329 [54:11<1:21:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6435: train loss 1.74114. lr 5.443143e-04:  39%|███▉      | 6435/16329 [54:12<1:21:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6435: train loss 1.74114. lr 5.443143e-04:  39%|███▉      | 6436/16329 [54:12<1:21:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6436: train loss 1.75502. lr 5.442975e-04:  39%|███▉      | 6436/16329 [54:12<1:21:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6436: train loss 1.75502. lr 5.442975e-04:  39%|███▉      | 6437/16329 [54:12<1:21:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6437: train loss 1.84618. lr 5.442808e-04:  39%|███▉      | 6437/16329 [54:13<1:21:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6437: train loss 1.84618. lr 5.442808e-04:  39%|███▉      | 6438/16329 [54:13<1:21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6438: train loss 1.77625. lr 5.442640e-04:  39%|███▉      | 6438/16329 [54:13<1:21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6438: train loss 1.77625. lr 5.442640e-04:  39%|███▉      | 6439/16329 [54:13<1:22:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6439: train loss 1.78231. lr 5.442472e-04:  39%|███▉      | 6439/16329 [54:14<1:22:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6439: train loss 1.78231. lr 5.442472e-04:  39%|███▉      | 6440/16329 [54:14<1:22:01,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6440: train loss 1.81552. lr 5.442305e-04:  39%|███▉      | 6440/16329 [54:14<1:22:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6440: train loss 1.81552. lr 5.442305e-04:  39%|███▉      | 6441/16329 [54:14<1:21:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6441: train loss 1.80004. lr 5.442137e-04:  39%|███▉      | 6441/16329 [54:15<1:21:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6441: train loss 1.80004. lr 5.442137e-04:  39%|███▉      | 6442/16329 [54:15<1:22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6442: train loss 1.76679. lr 5.441970e-04:  39%|███▉      | 6442/16329 [54:15<1:22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6442: train loss 1.76679. lr 5.441970e-04:  39%|███▉      | 6443/16329 [54:15<1:22:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6443: train loss 1.78918. lr 5.441802e-04:  39%|███▉      | 6443/16329 [54:16<1:22:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6443: train loss 1.78918. lr 5.441802e-04:  39%|███▉      | 6444/16329 [54:16<1:22:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6444: train loss 1.75843. lr 5.441634e-04:  39%|███▉      | 6444/16329 [54:17<1:22:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6444: train loss 1.75843. lr 5.441634e-04:  39%|███▉      | 6445/16329 [54:17<1:31:36,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6445: train loss 1.76014. lr 5.441467e-04:  39%|███▉      | 6445/16329 [54:17<1:31:36,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6445: train loss 1.76014. lr 5.441467e-04:  39%|███▉      | 6446/16329 [54:17<1:28:46,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6446: train loss 1.74237. lr 5.441299e-04:  39%|███▉      | 6446/16329 [54:18<1:28:46,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6446: train loss 1.74237. lr 5.441299e-04:  39%|███▉      | 6447/16329 [54:18<1:26:47,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6447: train loss 1.79735. lr 5.441131e-04:  39%|███▉      | 6447/16329 [54:18<1:26:47,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6447: train loss 1.79735. lr 5.441131e-04:  39%|███▉      | 6448/16329 [54:18<1:25:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6448: train loss 1.76626. lr 5.440963e-04:  39%|███▉      | 6448/16329 [54:19<1:25:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6448: train loss 1.76626. lr 5.440963e-04:  39%|███▉      | 6449/16329 [54:19<1:24:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6449: train loss 1.83084. lr 5.440796e-04:  39%|███▉      | 6449/16329 [54:19<1:24:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6449: train loss 1.83084. lr 5.440796e-04:  40%|███▉      | 6450/16329 [54:19<1:23:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6450: train loss 1.77696. lr 5.440628e-04:  40%|███▉      | 6450/16329 [54:20<1:23:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6450: train loss 1.77696. lr 5.440628e-04:  40%|███▉      | 6451/16329 [54:20<1:26:12,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6451: train loss 1.83356. lr 5.440460e-04:  40%|███▉      | 6451/16329 [54:20<1:26:12,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6451: train loss 1.83356. lr 5.440460e-04:  40%|███▉      | 6452/16329 [54:20<1:27:06,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6452: train loss 1.83149. lr 5.440292e-04:  40%|███▉      | 6452/16329 [54:21<1:27:06,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6452: train loss 1.83149. lr 5.440292e-04:  40%|███▉      | 6453/16329 [54:21<1:26:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6453: train loss 1.75968. lr 5.440124e-04:  40%|███▉      | 6453/16329 [54:21<1:26:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6453: train loss 1.75968. lr 5.440124e-04:  40%|███▉      | 6454/16329 [54:21<1:26:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6454: train loss 1.75136. lr 5.439956e-04:  40%|███▉      | 6454/16329 [54:22<1:26:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6454: train loss 1.75136. lr 5.439956e-04:  40%|███▉      | 6455/16329 [54:22<1:25:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6455: train loss 1.82589. lr 5.439788e-04:  40%|███▉      | 6455/16329 [54:22<1:25:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6455: train loss 1.82589. lr 5.439788e-04:  40%|███▉      | 6456/16329 [54:22<1:25:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6456: train loss 1.77485. lr 5.439620e-04:  40%|███▉      | 6456/16329 [54:23<1:25:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6456: train loss 1.77485. lr 5.439620e-04:  40%|███▉      | 6457/16329 [54:23<1:24:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6457: train loss 1.76996. lr 5.439452e-04:  40%|███▉      | 6457/16329 [54:23<1:24:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6457: train loss 1.76996. lr 5.439452e-04:  40%|███▉      | 6458/16329 [54:23<1:23:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6458: train loss 1.81933. lr 5.439284e-04:  40%|███▉      | 6458/16329 [54:24<1:23:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6458: train loss 1.81933. lr 5.439284e-04:  40%|███▉      | 6459/16329 [54:24<1:23:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6459: train loss 1.83464. lr 5.439116e-04:  40%|███▉      | 6459/16329 [54:24<1:23:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6459: train loss 1.83464. lr 5.439116e-04:  40%|███▉      | 6460/16329 [54:24<1:23:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6460: train loss 1.74407. lr 5.438948e-04:  40%|███▉      | 6460/16329 [54:25<1:23:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6460: train loss 1.74407. lr 5.438948e-04:  40%|███▉      | 6461/16329 [54:25<1:23:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6461: train loss 1.80304. lr 5.438780e-04:  40%|███▉      | 6461/16329 [54:25<1:23:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6461: train loss 1.80304. lr 5.438780e-04:  40%|███▉      | 6462/16329 [54:25<1:22:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6462: train loss 1.80754. lr 5.438612e-04:  40%|███▉      | 6462/16329 [54:26<1:22:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6462: train loss 1.80754. lr 5.438612e-04:  40%|███▉      | 6463/16329 [54:26<1:22:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6463: train loss 1.82675. lr 5.438444e-04:  40%|███▉      | 6463/16329 [54:26<1:22:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6463: train loss 1.82675. lr 5.438444e-04:  40%|███▉      | 6464/16329 [54:26<1:22:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6464: train loss 1.78452. lr 5.438276e-04:  40%|███▉      | 6464/16329 [54:27<1:22:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6464: train loss 1.78452. lr 5.438276e-04:  40%|███▉      | 6465/16329 [54:27<1:22:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6465: train loss 1.82046. lr 5.438108e-04:  40%|███▉      | 6465/16329 [54:27<1:22:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6465: train loss 1.82046. lr 5.438108e-04:  40%|███▉      | 6466/16329 [54:27<1:22:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6466: train loss 1.78827. lr 5.437940e-04:  40%|███▉      | 6466/16329 [54:28<1:22:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6466: train loss 1.78827. lr 5.437940e-04:  40%|███▉      | 6467/16329 [54:28<1:22:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6467: train loss 1.76179. lr 5.437772e-04:  40%|███▉      | 6467/16329 [54:28<1:22:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6467: train loss 1.76179. lr 5.437772e-04:  40%|███▉      | 6468/16329 [54:28<1:22:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6468: train loss 1.75871. lr 5.437603e-04:  40%|███▉      | 6468/16329 [54:29<1:22:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6468: train loss 1.75871. lr 5.437603e-04:  40%|███▉      | 6469/16329 [54:29<1:22:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6469: train loss 1.74981. lr 5.437435e-04:  40%|███▉      | 6469/16329 [54:29<1:22:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6469: train loss 1.74981. lr 5.437435e-04:  40%|███▉      | 6470/16329 [54:29<1:22:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6470: train loss 1.76466. lr 5.437267e-04:  40%|███▉      | 6470/16329 [54:30<1:22:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6470: train loss 1.76466. lr 5.437267e-04:  40%|███▉      | 6471/16329 [54:30<1:22:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6471: train loss 1.79853. lr 5.437099e-04:  40%|███▉      | 6471/16329 [54:30<1:22:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6471: train loss 1.79853. lr 5.437099e-04:  40%|███▉      | 6472/16329 [54:30<1:34:55,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 6472: train loss 1.79202. lr 5.436930e-04:  40%|███▉      | 6472/16329 [54:31<1:34:55,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 6472: train loss 1.79202. lr 5.436930e-04:  40%|███▉      | 6473/16329 [54:31<1:34:34,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 6473: train loss 1.82047. lr 5.436762e-04:  40%|███▉      | 6473/16329 [54:32<1:34:34,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 6473: train loss 1.82047. lr 5.436762e-04:  40%|███▉      | 6474/16329 [54:32<1:33:22,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 6474: train loss 1.76803. lr 5.436594e-04:  40%|███▉      | 6474/16329 [54:32<1:33:22,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 6474: train loss 1.76803. lr 5.436594e-04:  40%|███▉      | 6475/16329 [54:32<1:31:54,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6475: train loss 1.78830. lr 5.436425e-04:  40%|███▉      | 6475/16329 [54:33<1:31:54,  1.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6475: train loss 1.78830. lr 5.436425e-04:  40%|███▉      | 6476/16329 [54:33<1:29:14,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6476: train loss 1.82940. lr 5.436257e-04:  40%|███▉      | 6476/16329 [54:33<1:29:14,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6476: train loss 1.82940. lr 5.436257e-04:  40%|███▉      | 6477/16329 [54:33<1:27:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6477: train loss 1.79560. lr 5.436088e-04:  40%|███▉      | 6477/16329 [54:34<1:27:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6477: train loss 1.79560. lr 5.436088e-04:  40%|███▉      | 6478/16329 [54:34<1:25:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6478: train loss 1.81016. lr 5.435920e-04:  40%|███▉      | 6478/16329 [54:34<1:25:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6478: train loss 1.81016. lr 5.435920e-04:  40%|███▉      | 6479/16329 [54:34<1:24:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6479: train loss 1.70343. lr 5.435751e-04:  40%|███▉      | 6479/16329 [54:35<1:24:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6479: train loss 1.70343. lr 5.435751e-04:  40%|███▉      | 6480/16329 [54:35<1:23:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6480: train loss 1.83850. lr 5.435583e-04:  40%|███▉      | 6480/16329 [54:35<1:23:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6480: train loss 1.83850. lr 5.435583e-04:  40%|███▉      | 6481/16329 [54:35<1:23:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6481: train loss 1.79780. lr 5.435414e-04:  40%|███▉      | 6481/16329 [54:36<1:23:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6481: train loss 1.79780. lr 5.435414e-04:  40%|███▉      | 6482/16329 [54:36<1:22:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6482: train loss 1.75467. lr 5.435246e-04:  40%|███▉      | 6482/16329 [54:36<1:22:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6482: train loss 1.75467. lr 5.435246e-04:  40%|███▉      | 6483/16329 [54:36<1:22:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6483: train loss 1.82673. lr 5.435077e-04:  40%|███▉      | 6483/16329 [54:37<1:22:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6483: train loss 1.82673. lr 5.435077e-04:  40%|███▉      | 6484/16329 [54:37<1:22:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6484: train loss 1.82671. lr 5.434909e-04:  40%|███▉      | 6484/16329 [54:37<1:22:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6484: train loss 1.82671. lr 5.434909e-04:  40%|███▉      | 6485/16329 [54:37<1:22:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6485: train loss 1.77270. lr 5.434740e-04:  40%|███▉      | 6485/16329 [54:38<1:22:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6485: train loss 1.77270. lr 5.434740e-04:  40%|███▉      | 6486/16329 [54:38<1:22:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6486: train loss 1.75897. lr 5.434571e-04:  40%|███▉      | 6486/16329 [54:38<1:22:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6486: train loss 1.75897. lr 5.434571e-04:  40%|███▉      | 6487/16329 [54:38<1:22:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6487: train loss 1.79985. lr 5.434403e-04:  40%|███▉      | 6487/16329 [54:39<1:22:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6487: train loss 1.79985. lr 5.434403e-04:  40%|███▉      | 6488/16329 [54:39<1:22:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6488: train loss 1.75171. lr 5.434234e-04:  40%|███▉      | 6488/16329 [54:39<1:22:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6488: train loss 1.75171. lr 5.434234e-04:  40%|███▉      | 6489/16329 [54:39<1:22:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6489: train loss 1.81904. lr 5.434065e-04:  40%|███▉      | 6489/16329 [54:40<1:22:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6489: train loss 1.81904. lr 5.434065e-04:  40%|███▉      | 6490/16329 [54:40<1:21:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6490: train loss 1.81511. lr 5.433897e-04:  40%|███▉      | 6490/16329 [54:40<1:21:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6490: train loss 1.81511. lr 5.433897e-04:  40%|███▉      | 6491/16329 [54:40<1:21:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6491: train loss 1.80548. lr 5.433728e-04:  40%|███▉      | 6491/16329 [54:41<1:21:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6491: train loss 1.80548. lr 5.433728e-04:  40%|███▉      | 6492/16329 [54:41<1:21:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6492: train loss 1.77074. lr 5.433559e-04:  40%|███▉      | 6492/16329 [54:41<1:21:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6492: train loss 1.77074. lr 5.433559e-04:  40%|███▉      | 6493/16329 [54:41<1:21:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6493: train loss 1.75545. lr 5.433390e-04:  40%|███▉      | 6493/16329 [54:42<1:21:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6493: train loss 1.75545. lr 5.433390e-04:  40%|███▉      | 6494/16329 [54:42<1:21:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6494: train loss 1.80714. lr 5.433222e-04:  40%|███▉      | 6494/16329 [54:42<1:21:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6494: train loss 1.80714. lr 5.433222e-04:  40%|███▉      | 6495/16329 [54:42<1:21:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6495: train loss 1.77816. lr 5.433053e-04:  40%|███▉      | 6495/16329 [54:43<1:21:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6495: train loss 1.77816. lr 5.433053e-04:  40%|███▉      | 6496/16329 [54:43<1:21:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6496: train loss 1.72046. lr 5.432884e-04:  40%|███▉      | 6496/16329 [54:43<1:21:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6496: train loss 1.72046. lr 5.432884e-04:  40%|███▉      | 6497/16329 [54:43<1:21:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6497: train loss 1.74359. lr 5.432715e-04:  40%|███▉      | 6497/16329 [54:44<1:21:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6497: train loss 1.74359. lr 5.432715e-04:  40%|███▉      | 6498/16329 [54:44<1:21:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6498: train loss 1.88750. lr 5.432546e-04:  40%|███▉      | 6498/16329 [54:44<1:21:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6498: train loss 1.88750. lr 5.432546e-04:  40%|███▉      | 6499/16329 [54:44<1:25:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6499: train loss 1.78472. lr 5.432377e-04:  40%|███▉      | 6499/16329 [54:45<1:25:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6499: train loss 1.78472. lr 5.432377e-04:  40%|███▉      | 6500/16329 [54:45<1:27:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6500: train loss 1.75084. lr 5.432208e-04:  40%|███▉      | 6500/16329 [54:45<1:27:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6500: train loss 1.75084. lr 5.432208e-04:  40%|███▉      | 6501/16329 [54:45<1:27:59,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6501: train loss 1.78763. lr 5.432039e-04:  40%|███▉      | 6501/16329 [54:46<1:27:59,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6501: train loss 1.78763. lr 5.432039e-04:  40%|███▉      | 6502/16329 [54:46<1:27:41,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6502: train loss 1.78706. lr 5.431870e-04:  40%|███▉      | 6502/16329 [54:46<1:27:41,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6502: train loss 1.78706. lr 5.431870e-04:  40%|███▉      | 6503/16329 [54:46<1:27:02,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6503: train loss 1.75013. lr 5.431701e-04:  40%|███▉      | 6503/16329 [54:47<1:27:02,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6503: train loss 1.75013. lr 5.431701e-04:  40%|███▉      | 6504/16329 [54:47<1:25:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6504: train loss 1.79890. lr 5.431532e-04:  40%|███▉      | 6504/16329 [54:47<1:25:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6504: train loss 1.79890. lr 5.431532e-04:  40%|███▉      | 6505/16329 [54:47<1:24:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6505: train loss 1.77094. lr 5.431363e-04:  40%|███▉      | 6505/16329 [54:48<1:24:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6505: train loss 1.77094. lr 5.431363e-04:  40%|███▉      | 6506/16329 [54:48<1:23:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6506: train loss 1.78381. lr 5.431194e-04:  40%|███▉      | 6506/16329 [54:48<1:23:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6506: train loss 1.78381. lr 5.431194e-04:  40%|███▉      | 6507/16329 [54:48<1:22:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6507: train loss 1.75841. lr 5.431025e-04:  40%|███▉      | 6507/16329 [54:49<1:22:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6507: train loss 1.75841. lr 5.431025e-04:  40%|███▉      | 6508/16329 [54:49<1:22:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6508: train loss 1.79611. lr 5.430856e-04:  40%|███▉      | 6508/16329 [54:49<1:22:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6508: train loss 1.79611. lr 5.430856e-04:  40%|███▉      | 6509/16329 [54:49<1:21:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6509: train loss 1.76645. lr 5.430687e-04:  40%|███▉      | 6509/16329 [54:50<1:21:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6509: train loss 1.76645. lr 5.430687e-04:  40%|███▉      | 6510/16329 [54:50<1:21:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6510: train loss 1.83115. lr 5.430518e-04:  40%|███▉      | 6510/16329 [54:50<1:21:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6510: train loss 1.83115. lr 5.430518e-04:  40%|███▉      | 6511/16329 [54:50<1:21:31,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6511: train loss 1.75502. lr 5.430349e-04:  40%|███▉      | 6511/16329 [54:51<1:21:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6511: train loss 1.75502. lr 5.430349e-04:  40%|███▉      | 6512/16329 [54:51<1:30:04,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6512: train loss 1.74041. lr 5.430179e-04:  40%|███▉      | 6512/16329 [54:52<1:30:04,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6512: train loss 1.74041. lr 5.430179e-04:  40%|███▉      | 6513/16329 [54:52<1:27:37,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6513: train loss 1.76092. lr 5.430010e-04:  40%|███▉      | 6513/16329 [54:52<1:27:37,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6513: train loss 1.76092. lr 5.430010e-04:  40%|███▉      | 6514/16329 [54:52<1:25:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6514: train loss 1.81595. lr 5.429841e-04:  40%|███▉      | 6514/16329 [54:53<1:25:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6514: train loss 1.81595. lr 5.429841e-04:  40%|███▉      | 6515/16329 [54:53<1:24:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6515: train loss 1.79159. lr 5.429672e-04:  40%|███▉      | 6515/16329 [54:53<1:24:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6515: train loss 1.79159. lr 5.429672e-04:  40%|███▉      | 6516/16329 [54:53<1:23:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6516: train loss 1.75729. lr 5.429502e-04:  40%|███▉      | 6516/16329 [54:54<1:23:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6516: train loss 1.75729. lr 5.429502e-04:  40%|███▉      | 6517/16329 [54:54<1:23:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6517: train loss 1.81366. lr 5.429333e-04:  40%|███▉      | 6517/16329 [54:54<1:23:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6517: train loss 1.81366. lr 5.429333e-04:  40%|███▉      | 6518/16329 [54:54<1:22:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6518: train loss 1.79130. lr 5.429164e-04:  40%|███▉      | 6518/16329 [54:54<1:22:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6518: train loss 1.79130. lr 5.429164e-04:  40%|███▉      | 6519/16329 [54:54<1:21:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6519: train loss 1.78217. lr 5.428994e-04:  40%|███▉      | 6519/16329 [54:55<1:21:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6519: train loss 1.78217. lr 5.428994e-04:  40%|███▉      | 6520/16329 [54:55<1:21:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6520: train loss 1.77789. lr 5.428825e-04:  40%|███▉      | 6520/16329 [54:55<1:21:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6520: train loss 1.77789. lr 5.428825e-04:  40%|███▉      | 6521/16329 [54:55<1:21:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6521: train loss 1.70074. lr 5.428655e-04:  40%|███▉      | 6521/16329 [54:56<1:21:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6521: train loss 1.70074. lr 5.428655e-04:  40%|███▉      | 6522/16329 [54:56<1:21:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6522: train loss 1.80044. lr 5.428486e-04:  40%|███▉      | 6522/16329 [54:56<1:21:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6522: train loss 1.80044. lr 5.428486e-04:  40%|███▉      | 6523/16329 [54:56<1:21:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6523: train loss 1.81734. lr 5.428317e-04:  40%|███▉      | 6523/16329 [54:57<1:21:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6523: train loss 1.81734. lr 5.428317e-04:  40%|███▉      | 6524/16329 [54:57<1:21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6524: train loss 1.81426. lr 5.428147e-04:  40%|███▉      | 6524/16329 [54:57<1:21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6524: train loss 1.81426. lr 5.428147e-04:  40%|███▉      | 6525/16329 [54:57<1:21:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6525: train loss 1.81581. lr 5.427978e-04:  40%|███▉      | 6525/16329 [54:58<1:21:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6525: train loss 1.81581. lr 5.427978e-04:  40%|███▉      | 6526/16329 [54:58<1:21:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6526: train loss 1.77216. lr 5.427808e-04:  40%|███▉      | 6526/16329 [54:58<1:21:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6526: train loss 1.77216. lr 5.427808e-04:  40%|███▉      | 6527/16329 [54:59<1:22:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6527: train loss 1.80997. lr 5.427638e-04:  40%|███▉      | 6527/16329 [54:59<1:22:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6527: train loss 1.80997. lr 5.427638e-04:  40%|███▉      | 6528/16329 [54:59<1:24:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6528: train loss 1.74236. lr 5.427469e-04:  40%|███▉      | 6528/16329 [55:00<1:24:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6528: train loss 1.74236. lr 5.427469e-04:  40%|███▉      | 6529/16329 [55:00<1:24:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6529: train loss 1.77800. lr 5.427299e-04:  40%|███▉      | 6529/16329 [55:00<1:24:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6529: train loss 1.77800. lr 5.427299e-04:  40%|███▉      | 6530/16329 [55:00<1:24:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6530: train loss 1.79377. lr 5.427130e-04:  40%|███▉      | 6530/16329 [55:01<1:24:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6530: train loss 1.79377. lr 5.427130e-04:  40%|███▉      | 6531/16329 [55:01<1:23:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6531: train loss 1.75677. lr 5.426960e-04:  40%|███▉      | 6531/16329 [55:01<1:23:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6531: train loss 1.75677. lr 5.426960e-04:  40%|████      | 6532/16329 [55:01<1:23:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6532: train loss 1.79830. lr 5.426790e-04:  40%|████      | 6532/16329 [55:02<1:23:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6532: train loss 1.79830. lr 5.426790e-04:  40%|████      | 6533/16329 [55:02<1:22:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6533: train loss 1.78618. lr 5.426621e-04:  40%|████      | 6533/16329 [55:02<1:22:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6533: train loss 1.78618. lr 5.426621e-04:  40%|████      | 6534/16329 [55:02<1:22:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6534: train loss 1.79407. lr 5.426451e-04:  40%|████      | 6534/16329 [55:03<1:22:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6534: train loss 1.79407. lr 5.426451e-04:  40%|████      | 6535/16329 [55:03<1:22:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6535: train loss 1.84472. lr 5.426281e-04:  40%|████      | 6535/16329 [55:03<1:22:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6535: train loss 1.84472. lr 5.426281e-04:  40%|████      | 6536/16329 [55:03<1:21:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6536: train loss 1.77449. lr 5.426112e-04:  40%|████      | 6536/16329 [55:04<1:21:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6536: train loss 1.77449. lr 5.426112e-04:  40%|████      | 6537/16329 [55:04<1:21:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6537: train loss 1.79292. lr 5.425942e-04:  40%|████      | 6537/16329 [55:04<1:21:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6537: train loss 1.79292. lr 5.425942e-04:  40%|████      | 6538/16329 [55:04<1:21:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6538: train loss 1.75284. lr 5.425772e-04:  40%|████      | 6538/16329 [55:05<1:21:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6538: train loss 1.75284. lr 5.425772e-04:  40%|████      | 6539/16329 [55:05<1:21:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6539: train loss 1.80196. lr 5.425602e-04:  40%|████      | 6539/16329 [55:05<1:21:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6539: train loss 1.80196. lr 5.425602e-04:  40%|████      | 6540/16329 [55:05<1:21:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6540: train loss 1.69474. lr 5.425432e-04:  40%|████      | 6540/16329 [55:06<1:21:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6540: train loss 1.69474. lr 5.425432e-04:  40%|████      | 6541/16329 [55:06<1:21:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6541: train loss 1.77443. lr 5.425262e-04:  40%|████      | 6541/16329 [55:06<1:21:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6541: train loss 1.77443. lr 5.425262e-04:  40%|████      | 6542/16329 [55:06<1:21:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6542: train loss 1.74067. lr 5.425093e-04:  40%|████      | 6542/16329 [55:07<1:21:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6542: train loss 1.74067. lr 5.425093e-04:  40%|████      | 6543/16329 [55:07<1:21:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6543: train loss 1.77587. lr 5.424923e-04:  40%|████      | 6543/16329 [55:07<1:21:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6543: train loss 1.77587. lr 5.424923e-04:  40%|████      | 6544/16329 [55:07<1:21:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6544: train loss 1.82928. lr 5.424753e-04:  40%|████      | 6544/16329 [55:08<1:21:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6544: train loss 1.82928. lr 5.424753e-04:  40%|████      | 6545/16329 [55:08<1:21:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6545: train loss 1.75975. lr 5.424583e-04:  40%|████      | 6545/16329 [55:08<1:21:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6545: train loss 1.75975. lr 5.424583e-04:  40%|████      | 6546/16329 [55:08<1:21:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6546: train loss 1.78637. lr 5.424413e-04:  40%|████      | 6546/16329 [55:09<1:21:26,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6546: train loss 1.78637. lr 5.424413e-04:  40%|████      | 6547/16329 [55:09<1:30:05,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6547: train loss 1.75088. lr 5.424243e-04:  40%|████      | 6547/16329 [55:09<1:30:05,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6547: train loss 1.75088. lr 5.424243e-04:  40%|████      | 6548/16329 [55:09<1:27:12,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6548: train loss 1.73059. lr 5.424073e-04:  40%|████      | 6548/16329 [55:10<1:27:12,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6548: train loss 1.73059. lr 5.424073e-04:  40%|████      | 6549/16329 [55:10<1:25:24,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6549: train loss 1.74347. lr 5.423903e-04:  40%|████      | 6549/16329 [55:10<1:25:24,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6549: train loss 1.74347. lr 5.423903e-04:  40%|████      | 6550/16329 [55:10<1:23:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6550: train loss 1.72819. lr 5.423733e-04:  40%|████      | 6550/16329 [55:11<1:23:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6550: train loss 1.72819. lr 5.423733e-04:  40%|████      | 6551/16329 [55:11<1:23:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6551: train loss 1.73711. lr 5.423563e-04:  40%|████      | 6551/16329 [55:11<1:23:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6551: train loss 1.73711. lr 5.423563e-04:  40%|████      | 6552/16329 [55:11<1:22:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6552: train loss 1.76995. lr 5.423392e-04:  40%|████      | 6552/16329 [55:12<1:22:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6552: train loss 1.76995. lr 5.423392e-04:  40%|████      | 6553/16329 [55:12<1:21:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6553: train loss 1.75609. lr 5.423222e-04:  40%|████      | 6553/16329 [55:12<1:21:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6553: train loss 1.75609. lr 5.423222e-04:  40%|████      | 6554/16329 [55:12<1:21:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6554: train loss 1.79932. lr 5.423052e-04:  40%|████      | 6554/16329 [55:13<1:21:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6554: train loss 1.79932. lr 5.423052e-04:  40%|████      | 6555/16329 [55:13<1:21:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6555: train loss 1.76863. lr 5.422882e-04:  40%|████      | 6555/16329 [55:13<1:21:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6555: train loss 1.76863. lr 5.422882e-04:  40%|████      | 6556/16329 [55:13<1:21:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6556: train loss 1.82136. lr 5.422712e-04:  40%|████      | 6556/16329 [55:14<1:21:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6556: train loss 1.82136. lr 5.422712e-04:  40%|████      | 6557/16329 [55:14<1:21:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6557: train loss 1.74608. lr 5.422542e-04:  40%|████      | 6557/16329 [55:14<1:21:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6557: train loss 1.74608. lr 5.422542e-04:  40%|████      | 6558/16329 [55:14<1:21:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6558: train loss 1.76813. lr 5.422371e-04:  40%|████      | 6558/16329 [55:15<1:21:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6558: train loss 1.76813. lr 5.422371e-04:  40%|████      | 6559/16329 [55:15<1:21:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6559: train loss 1.78899. lr 5.422201e-04:  40%|████      | 6559/16329 [55:15<1:21:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6559: train loss 1.78899. lr 5.422201e-04:  40%|████      | 6560/16329 [55:15<1:21:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6560: train loss 1.82300. lr 5.422031e-04:  40%|████      | 6560/16329 [55:16<1:21:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6560: train loss 1.82300. lr 5.422031e-04:  40%|████      | 6561/16329 [55:16<1:21:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6561: train loss 1.80374. lr 5.421861e-04:  40%|████      | 6561/16329 [55:16<1:21:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6561: train loss 1.80374. lr 5.421861e-04:  40%|████      | 6562/16329 [55:16<1:21:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6562: train loss 1.75328. lr 5.421690e-04:  40%|████      | 6562/16329 [55:17<1:21:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6562: train loss 1.75328. lr 5.421690e-04:  40%|████      | 6563/16329 [55:17<1:21:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6563: train loss 1.76764. lr 5.421520e-04:  40%|████      | 6563/16329 [55:17<1:21:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6563: train loss 1.76764. lr 5.421520e-04:  40%|████      | 6564/16329 [55:17<1:20:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6564: train loss 1.75915. lr 5.421349e-04:  40%|████      | 6564/16329 [55:18<1:20:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6564: train loss 1.75915. lr 5.421349e-04:  40%|████      | 6565/16329 [55:18<1:21:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6565: train loss 1.80292. lr 5.421179e-04:  40%|████      | 6565/16329 [55:18<1:21:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6565: train loss 1.80292. lr 5.421179e-04:  40%|████      | 6566/16329 [55:18<1:20:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6566: train loss 1.79924. lr 5.421009e-04:  40%|████      | 6566/16329 [55:19<1:20:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6566: train loss 1.79924. lr 5.421009e-04:  40%|████      | 6567/16329 [55:19<1:20:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6567: train loss 1.83359. lr 5.420838e-04:  40%|████      | 6567/16329 [55:19<1:20:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6567: train loss 1.83359. lr 5.420838e-04:  40%|████      | 6568/16329 [55:19<1:20:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6568: train loss 1.76098. lr 5.420668e-04:  40%|████      | 6568/16329 [55:20<1:20:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6568: train loss 1.76098. lr 5.420668e-04:  40%|████      | 6569/16329 [55:20<1:20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6569: train loss 1.82029. lr 5.420497e-04:  40%|████      | 6569/16329 [55:20<1:20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6569: train loss 1.82029. lr 5.420497e-04:  40%|████      | 6570/16329 [55:20<1:22:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6570: train loss 1.79820. lr 5.420327e-04:  40%|████      | 6570/16329 [55:21<1:22:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6570: train loss 1.79820. lr 5.420327e-04:  40%|████      | 6571/16329 [55:21<1:23:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6571: train loss 1.79730. lr 5.420156e-04:  40%|████      | 6571/16329 [55:21<1:23:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6571: train loss 1.79730. lr 5.420156e-04:  40%|████      | 6572/16329 [55:21<1:34:02,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 6572: train loss 1.79044. lr 5.419986e-04:  40%|████      | 6572/16329 [55:22<1:34:02,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 6572: train loss 1.79044. lr 5.419986e-04:  40%|████      | 6573/16329 [55:22<1:30:24,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6573: train loss 1.75726. lr 5.419815e-04:  40%|████      | 6573/16329 [55:22<1:30:24,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6573: train loss 1.75726. lr 5.419815e-04:  40%|████      | 6574/16329 [55:22<1:27:52,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6574: train loss 1.77034. lr 5.419644e-04:  40%|████      | 6574/16329 [55:23<1:27:52,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6574: train loss 1.77034. lr 5.419644e-04:  40%|████      | 6575/16329 [55:23<1:26:05,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6575: train loss 1.75459. lr 5.419474e-04:  40%|████      | 6575/16329 [55:23<1:26:05,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6575: train loss 1.75459. lr 5.419474e-04:  40%|████      | 6576/16329 [55:23<1:24:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6576: train loss 1.78078. lr 5.419303e-04:  40%|████      | 6576/16329 [55:24<1:24:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6576: train loss 1.78078. lr 5.419303e-04:  40%|████      | 6577/16329 [55:24<1:23:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6577: train loss 1.76717. lr 5.419132e-04:  40%|████      | 6577/16329 [55:24<1:23:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6577: train loss 1.76717. lr 5.419132e-04:  40%|████      | 6578/16329 [55:24<1:22:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6578: train loss 1.75694. lr 5.418962e-04:  40%|████      | 6578/16329 [55:25<1:22:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6578: train loss 1.75694. lr 5.418962e-04:  40%|████      | 6579/16329 [55:25<1:22:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6579: train loss 1.75122. lr 5.418791e-04:  40%|████      | 6579/16329 [55:25<1:22:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6579: train loss 1.75122. lr 5.418791e-04:  40%|████      | 6580/16329 [55:25<1:21:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6580: train loss 1.79570. lr 5.418620e-04:  40%|████      | 6580/16329 [55:26<1:21:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6580: train loss 1.79570. lr 5.418620e-04:  40%|████      | 6581/16329 [55:26<1:21:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6581: train loss 1.78497. lr 5.418450e-04:  40%|████      | 6581/16329 [55:26<1:21:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6581: train loss 1.78497. lr 5.418450e-04:  40%|████      | 6582/16329 [55:26<1:21:17,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6582: train loss 1.80522. lr 5.418279e-04:  40%|████      | 6582/16329 [55:27<1:21:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6582: train loss 1.80522. lr 5.418279e-04:  40%|████      | 6583/16329 [55:27<1:21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6583: train loss 1.72127. lr 5.418108e-04:  40%|████      | 6583/16329 [55:27<1:21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6583: train loss 1.72127. lr 5.418108e-04:  40%|████      | 6584/16329 [55:27<1:20:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6584: train loss 1.74689. lr 5.417937e-04:  40%|████      | 6584/16329 [55:28<1:20:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6584: train loss 1.74689. lr 5.417937e-04:  40%|████      | 6585/16329 [55:28<1:20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6585: train loss 1.76890. lr 5.417766e-04:  40%|████      | 6585/16329 [55:28<1:20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6585: train loss 1.76890. lr 5.417766e-04:  40%|████      | 6586/16329 [55:28<1:20:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6586: train loss 1.78991. lr 5.417595e-04:  40%|████      | 6586/16329 [55:29<1:20:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6586: train loss 1.78991. lr 5.417595e-04:  40%|████      | 6587/16329 [55:29<1:20:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6587: train loss 1.80708. lr 5.417425e-04:  40%|████      | 6587/16329 [55:29<1:20:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6587: train loss 1.80708. lr 5.417425e-04:  40%|████      | 6588/16329 [55:29<1:20:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6588: train loss 1.74715. lr 5.417254e-04:  40%|████      | 6588/16329 [55:30<1:20:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6588: train loss 1.74715. lr 5.417254e-04:  40%|████      | 6589/16329 [55:30<1:20:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6589: train loss 1.83793. lr 5.417083e-04:  40%|████      | 6589/16329 [55:30<1:20:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6589: train loss 1.83793. lr 5.417083e-04:  40%|████      | 6590/16329 [55:30<1:20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6590: train loss 1.73038. lr 5.416912e-04:  40%|████      | 6590/16329 [55:31<1:20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6590: train loss 1.73038. lr 5.416912e-04:  40%|████      | 6591/16329 [55:31<1:20:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6591: train loss 1.75627. lr 5.416741e-04:  40%|████      | 6591/16329 [55:31<1:20:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6591: train loss 1.75627. lr 5.416741e-04:  40%|████      | 6592/16329 [55:31<1:20:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6592: train loss 1.77977. lr 5.416570e-04:  40%|████      | 6592/16329 [55:32<1:20:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6592: train loss 1.77977. lr 5.416570e-04:  40%|████      | 6593/16329 [55:32<1:20:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6593: train loss 1.75166. lr 5.416399e-04:  40%|████      | 6593/16329 [55:32<1:20:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6593: train loss 1.75166. lr 5.416399e-04:  40%|████      | 6594/16329 [55:32<1:20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6594: train loss 1.77007. lr 5.416228e-04:  40%|████      | 6594/16329 [55:33<1:20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6594: train loss 1.77007. lr 5.416228e-04:  40%|████      | 6595/16329 [55:33<1:20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6595: train loss 1.72694. lr 5.416057e-04:  40%|████      | 6595/16329 [55:33<1:20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6595: train loss 1.72694. lr 5.416057e-04:  40%|████      | 6596/16329 [55:33<1:20:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6596: train loss 1.75181. lr 5.415886e-04:  40%|████      | 6596/16329 [55:34<1:20:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6596: train loss 1.75181. lr 5.415886e-04:  40%|████      | 6597/16329 [55:34<1:20:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6597: train loss 1.71770. lr 5.415714e-04:  40%|████      | 6597/16329 [55:34<1:20:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6597: train loss 1.71770. lr 5.415714e-04:  40%|████      | 6598/16329 [55:34<1:20:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6598: train loss 1.74607. lr 5.415543e-04:  40%|████      | 6598/16329 [55:35<1:20:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6598: train loss 1.74607. lr 5.415543e-04:  40%|████      | 6599/16329 [55:35<1:29:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6599: train loss 1.77324. lr 5.415372e-04:  40%|████      | 6599/16329 [55:36<1:29:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6599: train loss 1.77324. lr 5.415372e-04:  40%|████      | 6600/16329 [55:36<1:26:27,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6600: train loss 1.78508. lr 5.415201e-04:  40%|████      | 6600/16329 [55:36<1:26:27,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6600: train loss 1.78508. lr 5.415201e-04:  40%|████      | 6601/16329 [55:36<1:24:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6601: train loss 1.80025. lr 5.415030e-04:  40%|████      | 6601/16329 [55:37<1:24:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6601: train loss 1.80025. lr 5.415030e-04:  40%|████      | 6602/16329 [55:37<1:23:25,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6602: train loss 1.80649. lr 5.414858e-04:  40%|████      | 6602/16329 [55:37<1:23:25,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6602: train loss 1.80649. lr 5.414858e-04:  40%|████      | 6603/16329 [55:37<1:22:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6603: train loss 1.71882. lr 5.414687e-04:  40%|████      | 6603/16329 [55:38<1:22:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6603: train loss 1.71882. lr 5.414687e-04:  40%|████      | 6604/16329 [55:38<1:22:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6604: train loss 1.78294. lr 5.414516e-04:  40%|████      | 6604/16329 [55:38<1:22:06,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6604: train loss 1.78294. lr 5.414516e-04:  40%|████      | 6605/16329 [55:38<1:21:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6605: train loss 1.77997. lr 5.414345e-04:  40%|████      | 6605/16329 [55:39<1:21:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6605: train loss 1.77997. lr 5.414345e-04:  40%|████      | 6606/16329 [55:39<1:21:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6606: train loss 1.80801. lr 5.414173e-04:  40%|████      | 6606/16329 [55:39<1:21:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6606: train loss 1.80801. lr 5.414173e-04:  40%|████      | 6607/16329 [55:39<1:21:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6607: train loss 1.76516. lr 5.414002e-04:  40%|████      | 6607/16329 [55:40<1:21:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6607: train loss 1.76516. lr 5.414002e-04:  40%|████      | 6608/16329 [55:40<1:21:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6608: train loss 1.81607. lr 5.413831e-04:  40%|████      | 6608/16329 [55:40<1:21:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6608: train loss 1.81607. lr 5.413831e-04:  40%|████      | 6609/16329 [55:40<1:21:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6609: train loss 1.74431. lr 5.413659e-04:  40%|████      | 6609/16329 [55:41<1:21:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6609: train loss 1.74431. lr 5.413659e-04:  40%|████      | 6610/16329 [55:41<1:20:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6610: train loss 1.78683. lr 5.413488e-04:  40%|████      | 6610/16329 [55:41<1:20:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6610: train loss 1.78683. lr 5.413488e-04:  40%|████      | 6611/16329 [55:41<1:22:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6611: train loss 1.77259. lr 5.413316e-04:  40%|████      | 6611/16329 [55:42<1:22:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6611: train loss 1.77259. lr 5.413316e-04:  40%|████      | 6612/16329 [55:42<1:23:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6612: train loss 1.78231. lr 5.413145e-04:  40%|████      | 6612/16329 [55:42<1:23:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6612: train loss 1.78231. lr 5.413145e-04:  40%|████      | 6613/16329 [55:42<1:24:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6613: train loss 1.77411. lr 5.412974e-04:  40%|████      | 6613/16329 [55:43<1:24:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6613: train loss 1.77411. lr 5.412974e-04:  41%|████      | 6614/16329 [55:43<1:23:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6614: train loss 1.76897. lr 5.412802e-04:  41%|████      | 6614/16329 [55:43<1:23:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6614: train loss 1.76897. lr 5.412802e-04:  41%|████      | 6615/16329 [55:43<1:22:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6615: train loss 1.80295. lr 5.412630e-04:  41%|████      | 6615/16329 [55:44<1:22:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6615: train loss 1.80295. lr 5.412630e-04:  41%|████      | 6616/16329 [55:44<1:22:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6616: train loss 1.79048. lr 5.412459e-04:  41%|████      | 6616/16329 [55:44<1:22:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6616: train loss 1.79048. lr 5.412459e-04:  41%|████      | 6617/16329 [55:44<1:21:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6617: train loss 1.73785. lr 5.412287e-04:  41%|████      | 6617/16329 [55:45<1:21:37,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6617: train loss 1.73785. lr 5.412287e-04:  41%|████      | 6618/16329 [55:45<1:21:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6618: train loss 1.82317. lr 5.412116e-04:  41%|████      | 6618/16329 [55:45<1:21:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6618: train loss 1.82317. lr 5.412116e-04:  41%|████      | 6619/16329 [55:45<1:24:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6619: train loss 1.77721. lr 5.411944e-04:  41%|████      | 6619/16329 [55:46<1:24:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6619: train loss 1.77721. lr 5.411944e-04:  41%|████      | 6620/16329 [55:46<1:26:49,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6620: train loss 1.72719. lr 5.411773e-04:  41%|████      | 6620/16329 [55:46<1:26:49,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6620: train loss 1.72719. lr 5.411773e-04:  41%|████      | 6621/16329 [55:46<1:27:21,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6621: train loss 1.79448. lr 5.411601e-04:  41%|████      | 6621/16329 [55:47<1:27:21,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6621: train loss 1.79448. lr 5.411601e-04:  41%|████      | 6622/16329 [55:47<1:27:14,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6622: train loss 1.72907. lr 5.411429e-04:  41%|████      | 6622/16329 [55:47<1:27:14,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6622: train loss 1.72907. lr 5.411429e-04:  41%|████      | 6623/16329 [55:47<1:26:29,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6623: train loss 1.77420. lr 5.411258e-04:  41%|████      | 6623/16329 [55:48<1:26:29,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6623: train loss 1.77420. lr 5.411258e-04:  41%|████      | 6624/16329 [55:48<1:25:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6624: train loss 1.73652. lr 5.411086e-04:  41%|████      | 6624/16329 [55:48<1:25:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6624: train loss 1.73652. lr 5.411086e-04:  41%|████      | 6625/16329 [55:48<1:24:58,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6625: train loss 1.77777. lr 5.410914e-04:  41%|████      | 6625/16329 [55:49<1:24:58,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6625: train loss 1.77777. lr 5.410914e-04:  41%|████      | 6626/16329 [55:49<1:24:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6626: train loss 1.76351. lr 5.410742e-04:  41%|████      | 6626/16329 [55:49<1:24:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6626: train loss 1.76351. lr 5.410742e-04:  41%|████      | 6627/16329 [55:49<1:23:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6627: train loss 1.77603. lr 5.410571e-04:  41%|████      | 6627/16329 [55:50<1:23:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6627: train loss 1.77603. lr 5.410571e-04:  41%|████      | 6628/16329 [55:50<1:22:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6628: train loss 1.73702. lr 5.410399e-04:  41%|████      | 6628/16329 [55:50<1:22:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6628: train loss 1.73702. lr 5.410399e-04:  41%|████      | 6629/16329 [55:50<1:21:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6629: train loss 1.77207. lr 5.410227e-04:  41%|████      | 6629/16329 [55:51<1:21:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6629: train loss 1.77207. lr 5.410227e-04:  41%|████      | 6630/16329 [55:51<1:21:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6630: train loss 1.75287. lr 5.410055e-04:  41%|████      | 6630/16329 [55:51<1:21:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6630: train loss 1.75287. lr 5.410055e-04:  41%|████      | 6631/16329 [55:51<1:20:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6631: train loss 1.71358. lr 5.409883e-04:  41%|████      | 6631/16329 [55:52<1:20:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6631: train loss 1.71358. lr 5.409883e-04:  41%|████      | 6632/16329 [55:52<1:20:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6632: train loss 1.72162. lr 5.409711e-04:  41%|████      | 6632/16329 [55:52<1:20:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6632: train loss 1.72162. lr 5.409711e-04:  41%|████      | 6633/16329 [55:52<1:20:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6633: train loss 1.81563. lr 5.409539e-04:  41%|████      | 6633/16329 [55:53<1:20:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6633: train loss 1.81563. lr 5.409539e-04:  41%|████      | 6634/16329 [55:53<1:20:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6634: train loss 1.79318. lr 5.409367e-04:  41%|████      | 6634/16329 [55:53<1:20:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6634: train loss 1.79318. lr 5.409367e-04:  41%|████      | 6635/16329 [55:53<1:20:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6635: train loss 1.77528. lr 5.409195e-04:  41%|████      | 6635/16329 [55:54<1:20:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6635: train loss 1.77528. lr 5.409195e-04:  41%|████      | 6636/16329 [55:54<1:20:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6636: train loss 1.81405. lr 5.409023e-04:  41%|████      | 6636/16329 [55:54<1:20:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6636: train loss 1.81405. lr 5.409023e-04:  41%|████      | 6637/16329 [55:54<1:20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6637: train loss 1.76605. lr 5.408851e-04:  41%|████      | 6637/16329 [55:55<1:20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6637: train loss 1.76605. lr 5.408851e-04:  41%|████      | 6638/16329 [55:55<1:20:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6638: train loss 1.70895. lr 5.408679e-04:  41%|████      | 6638/16329 [55:56<1:20:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6638: train loss 1.70895. lr 5.408679e-04:  41%|████      | 6639/16329 [55:56<1:30:25,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6639: train loss 1.73880. lr 5.408507e-04:  41%|████      | 6639/16329 [55:56<1:30:25,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 6639: train loss 1.73880. lr 5.408507e-04:  41%|████      | 6640/16329 [55:56<1:27:04,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6640: train loss 1.72666. lr 5.408335e-04:  41%|████      | 6640/16329 [55:57<1:27:04,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6640: train loss 1.72666. lr 5.408335e-04:  41%|████      | 6641/16329 [55:57<1:25:03,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6641: train loss 1.78316. lr 5.408163e-04:  41%|████      | 6641/16329 [55:57<1:25:03,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6641: train loss 1.78316. lr 5.408163e-04:  41%|████      | 6642/16329 [55:57<1:23:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6642: train loss 1.71297. lr 5.407991e-04:  41%|████      | 6642/16329 [55:58<1:23:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6642: train loss 1.71297. lr 5.407991e-04:  41%|████      | 6643/16329 [55:58<1:22:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6643: train loss 1.80859. lr 5.407819e-04:  41%|████      | 6643/16329 [55:58<1:22:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6643: train loss 1.80859. lr 5.407819e-04:  41%|████      | 6644/16329 [55:58<1:21:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6644: train loss 1.71167. lr 5.407647e-04:  41%|████      | 6644/16329 [55:59<1:21:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6644: train loss 1.71167. lr 5.407647e-04:  41%|████      | 6645/16329 [55:59<1:21:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6645: train loss 1.72069. lr 5.407475e-04:  41%|████      | 6645/16329 [55:59<1:21:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6645: train loss 1.72069. lr 5.407475e-04:  41%|████      | 6646/16329 [55:59<1:20:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6646: train loss 1.77199. lr 5.407302e-04:  41%|████      | 6646/16329 [56:00<1:20:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6646: train loss 1.77199. lr 5.407302e-04:  41%|████      | 6647/16329 [56:00<1:20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6647: train loss 1.76492. lr 5.407130e-04:  41%|████      | 6647/16329 [56:00<1:20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6647: train loss 1.76492. lr 5.407130e-04:  41%|████      | 6648/16329 [56:00<1:20:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6648: train loss 1.76390. lr 5.406958e-04:  41%|████      | 6648/16329 [56:01<1:20:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6648: train loss 1.76390. lr 5.406958e-04:  41%|████      | 6649/16329 [56:01<1:20:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6649: train loss 1.77013. lr 5.406786e-04:  41%|████      | 6649/16329 [56:01<1:20:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6649: train loss 1.77013. lr 5.406786e-04:  41%|████      | 6650/16329 [56:01<1:20:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6650: train loss 1.74062. lr 5.406613e-04:  41%|████      | 6650/16329 [56:02<1:20:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6650: train loss 1.74062. lr 5.406613e-04:  41%|████      | 6651/16329 [56:02<1:20:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6651: train loss 1.74136. lr 5.406441e-04:  41%|████      | 6651/16329 [56:02<1:20:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6651: train loss 1.74136. lr 5.406441e-04:  41%|████      | 6652/16329 [56:02<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6652: train loss 1.81600. lr 5.406269e-04:  41%|████      | 6652/16329 [56:03<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6652: train loss 1.81600. lr 5.406269e-04:  41%|████      | 6653/16329 [56:03<1:20:06,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6653: train loss 1.69253. lr 5.406096e-04:  41%|████      | 6653/16329 [56:03<1:20:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6653: train loss 1.69253. lr 5.406096e-04:  41%|████      | 6654/16329 [56:03<1:20:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6654: train loss 1.78479. lr 5.405924e-04:  41%|████      | 6654/16329 [56:04<1:20:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6654: train loss 1.78479. lr 5.405924e-04:  41%|████      | 6655/16329 [56:04<1:20:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6655: train loss 1.76346. lr 5.405751e-04:  41%|████      | 6655/16329 [56:04<1:20:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6655: train loss 1.76346. lr 5.405751e-04:  41%|████      | 6656/16329 [56:04<1:20:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6656: train loss 1.73513. lr 5.405579e-04:  41%|████      | 6656/16329 [56:05<1:20:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6656: train loss 1.73513. lr 5.405579e-04:  41%|████      | 6657/16329 [56:05<1:20:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6657: train loss 1.77278. lr 5.405407e-04:  41%|████      | 6657/16329 [56:05<1:20:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6657: train loss 1.77278. lr 5.405407e-04:  41%|████      | 6658/16329 [56:05<1:20:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6658: train loss 1.72885. lr 5.405234e-04:  41%|████      | 6658/16329 [56:06<1:20:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6658: train loss 1.72885. lr 5.405234e-04:  41%|████      | 6659/16329 [56:06<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6659: train loss 1.75326. lr 5.405062e-04:  41%|████      | 6659/16329 [56:06<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6659: train loss 1.75326. lr 5.405062e-04:  41%|████      | 6660/16329 [56:06<1:20:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6660: train loss 1.71105. lr 5.404889e-04:  41%|████      | 6660/16329 [56:07<1:20:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6660: train loss 1.71105. lr 5.404889e-04:  41%|████      | 6661/16329 [56:07<1:20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6661: train loss 1.76040. lr 5.404717e-04:  41%|████      | 6661/16329 [56:07<1:20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6661: train loss 1.76040. lr 5.404717e-04:  41%|████      | 6662/16329 [56:07<1:20:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6662: train loss 1.75460. lr 5.404544e-04:  41%|████      | 6662/16329 [56:08<1:20:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6662: train loss 1.75460. lr 5.404544e-04:  41%|████      | 6663/16329 [56:08<1:20:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6663: train loss 1.73812. lr 5.404371e-04:  41%|████      | 6663/16329 [56:08<1:20:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6663: train loss 1.73812. lr 5.404371e-04:  41%|████      | 6664/16329 [56:08<1:20:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6664: train loss 1.76079. lr 5.404199e-04:  41%|████      | 6664/16329 [56:09<1:20:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6664: train loss 1.76079. lr 5.404199e-04:  41%|████      | 6665/16329 [56:09<1:19:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6665: train loss 1.77301. lr 5.404026e-04:  41%|████      | 6665/16329 [56:09<1:19:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6665: train loss 1.77301. lr 5.404026e-04:  41%|████      | 6666/16329 [56:09<1:19:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6666: train loss 1.74706. lr 5.403853e-04:  41%|████      | 6666/16329 [56:10<1:19:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6666: train loss 1.74706. lr 5.403853e-04:  41%|████      | 6667/16329 [56:10<1:20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6667: train loss 1.75841. lr 5.403681e-04:  41%|████      | 6667/16329 [56:10<1:20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6667: train loss 1.75841. lr 5.403681e-04:  41%|████      | 6668/16329 [56:10<1:19:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6668: train loss 1.76292. lr 5.403508e-04:  41%|████      | 6668/16329 [56:11<1:19:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6668: train loss 1.76292. lr 5.403508e-04:  41%|████      | 6669/16329 [56:11<1:20:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6669: train loss 1.79124. lr 5.403335e-04:  41%|████      | 6669/16329 [56:11<1:20:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6669: train loss 1.79124. lr 5.403335e-04:  41%|████      | 6670/16329 [56:11<1:19:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6670: train loss 1.70744. lr 5.403163e-04:  41%|████      | 6670/16329 [56:12<1:19:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6670: train loss 1.70744. lr 5.403163e-04:  41%|████      | 6671/16329 [56:12<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6671: train loss 1.75788. lr 5.402990e-04:  41%|████      | 6671/16329 [56:12<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6671: train loss 1.75788. lr 5.402990e-04:  41%|████      | 6672/16329 [56:12<1:19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6672: train loss 1.71114. lr 5.402817e-04:  41%|████      | 6672/16329 [56:13<1:19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6672: train loss 1.71114. lr 5.402817e-04:  41%|████      | 6673/16329 [56:13<1:19:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6673: train loss 1.73692. lr 5.402644e-04:  41%|████      | 6673/16329 [56:13<1:19:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6673: train loss 1.73692. lr 5.402644e-04:  41%|████      | 6674/16329 [56:13<1:28:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6674: train loss 1.75568. lr 5.402471e-04:  41%|████      | 6674/16329 [56:14<1:28:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6674: train loss 1.75568. lr 5.402471e-04:  41%|████      | 6675/16329 [56:14<1:25:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6675: train loss 1.72197. lr 5.402299e-04:  41%|████      | 6675/16329 [56:14<1:25:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6675: train loss 1.72197. lr 5.402299e-04:  41%|████      | 6676/16329 [56:14<1:23:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6676: train loss 1.70680. lr 5.402126e-04:  41%|████      | 6676/16329 [56:15<1:23:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6676: train loss 1.70680. lr 5.402126e-04:  41%|████      | 6677/16329 [56:15<1:22:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6677: train loss 1.74289. lr 5.401953e-04:  41%|████      | 6677/16329 [56:15<1:22:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6677: train loss 1.74289. lr 5.401953e-04:  41%|████      | 6678/16329 [56:15<1:21:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6678: train loss 1.71292. lr 5.401780e-04:  41%|████      | 6678/16329 [56:16<1:21:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6678: train loss 1.71292. lr 5.401780e-04:  41%|████      | 6679/16329 [56:16<1:21:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6679: train loss 1.75954. lr 5.401607e-04:  41%|████      | 6679/16329 [56:16<1:21:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6679: train loss 1.75954. lr 5.401607e-04:  41%|████      | 6680/16329 [56:16<1:20:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6680: train loss 1.75242. lr 5.401434e-04:  41%|████      | 6680/16329 [56:17<1:20:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6680: train loss 1.75242. lr 5.401434e-04:  41%|████      | 6681/16329 [56:17<1:20:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6681: train loss 1.77381. lr 5.401261e-04:  41%|████      | 6681/16329 [56:17<1:20:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6681: train loss 1.77381. lr 5.401261e-04:  41%|████      | 6682/16329 [56:17<1:20:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6682: train loss 1.75512. lr 5.401088e-04:  41%|████      | 6682/16329 [56:18<1:20:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6682: train loss 1.75512. lr 5.401088e-04:  41%|████      | 6683/16329 [56:18<1:20:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6683: train loss 1.76048. lr 5.400915e-04:  41%|████      | 6683/16329 [56:18<1:20:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6683: train loss 1.76048. lr 5.400915e-04:  41%|████      | 6684/16329 [56:18<1:20:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6684: train loss 1.72414. lr 5.400742e-04:  41%|████      | 6684/16329 [56:19<1:20:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6684: train loss 1.72414. lr 5.400742e-04:  41%|████      | 6685/16329 [56:19<1:19:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6685: train loss 1.73127. lr 5.400569e-04:  41%|████      | 6685/16329 [56:19<1:19:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6685: train loss 1.73127. lr 5.400569e-04:  41%|████      | 6686/16329 [56:19<1:19:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6686: train loss 1.73304. lr 5.400396e-04:  41%|████      | 6686/16329 [56:20<1:19:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6686: train loss 1.73304. lr 5.400396e-04:  41%|████      | 6687/16329 [56:20<1:19:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6687: train loss 1.78824. lr 5.400223e-04:  41%|████      | 6687/16329 [56:20<1:19:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6687: train loss 1.78824. lr 5.400223e-04:  41%|████      | 6688/16329 [56:20<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6688: train loss 1.75444. lr 5.400049e-04:  41%|████      | 6688/16329 [56:21<1:20:02,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6688: train loss 1.75444. lr 5.400049e-04:  41%|████      | 6689/16329 [56:21<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6689: train loss 1.72691. lr 5.399876e-04:  41%|████      | 6689/16329 [56:21<1:20:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6689: train loss 1.72691. lr 5.399876e-04:  41%|████      | 6690/16329 [56:21<1:19:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6690: train loss 1.78764. lr 5.399703e-04:  41%|████      | 6690/16329 [56:22<1:19:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6690: train loss 1.78764. lr 5.399703e-04:  41%|████      | 6691/16329 [56:22<1:20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6691: train loss 1.73291. lr 5.399530e-04:  41%|████      | 6691/16329 [56:22<1:20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6691: train loss 1.73291. lr 5.399530e-04:  41%|████      | 6692/16329 [56:22<1:19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6692: train loss 1.71189. lr 5.399357e-04:  41%|████      | 6692/16329 [56:23<1:19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6692: train loss 1.71189. lr 5.399357e-04:  41%|████      | 6693/16329 [56:23<1:19:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6693: train loss 1.71848. lr 5.399183e-04:  41%|████      | 6693/16329 [56:23<1:19:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6693: train loss 1.71848. lr 5.399183e-04:  41%|████      | 6694/16329 [56:23<1:20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6694: train loss 1.77702. lr 5.399010e-04:  41%|████      | 6694/16329 [56:24<1:20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6694: train loss 1.77702. lr 5.399010e-04:  41%|████      | 6695/16329 [56:24<1:20:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6695: train loss 1.75402. lr 5.398837e-04:  41%|████      | 6695/16329 [56:24<1:20:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6695: train loss 1.75402. lr 5.398837e-04:  41%|████      | 6696/16329 [56:24<1:20:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6696: train loss 1.76231. lr 5.398663e-04:  41%|████      | 6696/16329 [56:25<1:20:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6696: train loss 1.76231. lr 5.398663e-04:  41%|████      | 6697/16329 [56:25<1:20:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6697: train loss 1.73516. lr 5.398490e-04:  41%|████      | 6697/16329 [56:25<1:20:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6697: train loss 1.73516. lr 5.398490e-04:  41%|████      | 6698/16329 [56:25<1:20:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6698: train loss 1.80386. lr 5.398317e-04:  41%|████      | 6698/16329 [56:26<1:20:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6698: train loss 1.80386. lr 5.398317e-04:  41%|████      | 6699/16329 [56:26<1:29:12,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6699: train loss 1.71702. lr 5.398143e-04:  41%|████      | 6699/16329 [56:26<1:29:12,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6699: train loss 1.71702. lr 5.398143e-04:  41%|████      | 6700/16329 [56:26<1:28:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6700: train loss 1.75507. lr 5.397970e-04:  41%|████      | 6700/16329 [56:27<1:28:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6700: train loss 1.75507. lr 5.397970e-04:  41%|████      | 6701/16329 [56:27<1:27:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6701: train loss 1.72355. lr 5.397797e-04:  41%|████      | 6701/16329 [56:27<1:27:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6701: train loss 1.72355. lr 5.397797e-04:  41%|████      | 6702/16329 [56:27<1:26:38,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6702: train loss 1.80345. lr 5.397623e-04:  41%|████      | 6702/16329 [56:28<1:26:38,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 6702: train loss 1.80345. lr 5.397623e-04:  41%|████      | 6703/16329 [56:28<1:25:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6703: train loss 1.74572. lr 5.397450e-04:  41%|████      | 6703/16329 [56:28<1:25:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6703: train loss 1.74572. lr 5.397450e-04:  41%|████      | 6704/16329 [56:28<1:23:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6704: train loss 1.73959. lr 5.397276e-04:  41%|████      | 6704/16329 [56:29<1:23:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6704: train loss 1.73959. lr 5.397276e-04:  41%|████      | 6705/16329 [56:29<1:22:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6705: train loss 1.78696. lr 5.397103e-04:  41%|████      | 6705/16329 [56:29<1:22:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6705: train loss 1.78696. lr 5.397103e-04:  41%|████      | 6706/16329 [56:29<1:21:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6706: train loss 1.76957. lr 5.396929e-04:  41%|████      | 6706/16329 [56:30<1:21:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6706: train loss 1.76957. lr 5.396929e-04:  41%|████      | 6707/16329 [56:30<1:20:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6707: train loss 1.75449. lr 5.396755e-04:  41%|████      | 6707/16329 [56:30<1:20:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6707: train loss 1.75449. lr 5.396755e-04:  41%|████      | 6708/16329 [56:30<1:20:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6708: train loss 1.77759. lr 5.396582e-04:  41%|████      | 6708/16329 [56:31<1:20:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6708: train loss 1.77759. lr 5.396582e-04:  41%|████      | 6709/16329 [56:31<1:20:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6709: train loss 1.74171. lr 5.396408e-04:  41%|████      | 6709/16329 [56:31<1:20:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6709: train loss 1.74171. lr 5.396408e-04:  41%|████      | 6710/16329 [56:31<1:20:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6710: train loss 1.73326. lr 5.396235e-04:  41%|████      | 6710/16329 [56:32<1:20:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6710: train loss 1.73326. lr 5.396235e-04:  41%|████      | 6711/16329 [56:32<1:19:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6711: train loss 1.75802. lr 5.396061e-04:  41%|████      | 6711/16329 [56:32<1:19:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6711: train loss 1.75802. lr 5.396061e-04:  41%|████      | 6712/16329 [56:32<1:19:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6712: train loss 1.70660. lr 5.395887e-04:  41%|████      | 6712/16329 [56:33<1:19:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6712: train loss 1.70660. lr 5.395887e-04:  41%|████      | 6713/16329 [56:33<1:19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6713: train loss 1.74574. lr 5.395714e-04:  41%|████      | 6713/16329 [56:33<1:19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6713: train loss 1.74574. lr 5.395714e-04:  41%|████      | 6714/16329 [56:33<1:19:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6714: train loss 1.75843. lr 5.395540e-04:  41%|████      | 6714/16329 [56:34<1:19:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6714: train loss 1.75843. lr 5.395540e-04:  41%|████      | 6715/16329 [56:34<1:19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6715: train loss 1.74279. lr 5.395366e-04:  41%|████      | 6715/16329 [56:34<1:19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6715: train loss 1.74279. lr 5.395366e-04:  41%|████      | 6716/16329 [56:34<1:19:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6716: train loss 1.71607. lr 5.395192e-04:  41%|████      | 6716/16329 [56:35<1:19:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6716: train loss 1.71607. lr 5.395192e-04:  41%|████      | 6717/16329 [56:35<1:19:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6717: train loss 1.67082. lr 5.395019e-04:  41%|████      | 6717/16329 [56:35<1:19:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6717: train loss 1.67082. lr 5.395019e-04:  41%|████      | 6718/16329 [56:35<1:19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6718: train loss 1.74314. lr 5.394845e-04:  41%|████      | 6718/16329 [56:36<1:19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6718: train loss 1.74314. lr 5.394845e-04:  41%|████      | 6719/16329 [56:36<1:19:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6719: train loss 1.74868. lr 5.394671e-04:  41%|████      | 6719/16329 [56:36<1:19:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6719: train loss 1.74868. lr 5.394671e-04:  41%|████      | 6720/16329 [56:36<1:19:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6720: train loss 1.77511. lr 5.394497e-04:  41%|████      | 6720/16329 [56:37<1:19:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6720: train loss 1.77511. lr 5.394497e-04:  41%|████      | 6721/16329 [56:37<1:19:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6721: train loss 1.75039. lr 5.394323e-04:  41%|████      | 6721/16329 [56:37<1:19:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6721: train loss 1.75039. lr 5.394323e-04:  41%|████      | 6722/16329 [56:37<1:19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6722: train loss 1.75611. lr 5.394149e-04:  41%|████      | 6722/16329 [56:38<1:19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6722: train loss 1.75611. lr 5.394149e-04:  41%|████      | 6723/16329 [56:38<1:19:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6723: train loss 1.75823. lr 5.393975e-04:  41%|████      | 6723/16329 [56:38<1:19:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6723: train loss 1.75823. lr 5.393975e-04:  41%|████      | 6724/16329 [56:38<1:19:55,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6724: train loss 1.77894. lr 5.393801e-04:  41%|████      | 6724/16329 [56:39<1:19:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6724: train loss 1.77894. lr 5.393801e-04:  41%|████      | 6725/16329 [56:39<1:19:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6725: train loss 1.71145. lr 5.393627e-04:  41%|████      | 6725/16329 [56:40<1:19:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6725: train loss 1.71145. lr 5.393627e-04:  41%|████      | 6726/16329 [56:40<1:28:02,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6726: train loss 1.70655. lr 5.393453e-04:  41%|████      | 6726/16329 [56:40<1:28:02,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6726: train loss 1.70655. lr 5.393453e-04:  41%|████      | 6727/16329 [56:40<1:28:00,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6727: train loss 1.71800. lr 5.393279e-04:  41%|████      | 6727/16329 [56:41<1:28:00,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6727: train loss 1.71800. lr 5.393279e-04:  41%|████      | 6728/16329 [56:41<1:27:10,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6728: train loss 1.79682. lr 5.393105e-04:  41%|████      | 6728/16329 [56:41<1:27:10,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6728: train loss 1.79682. lr 5.393105e-04:  41%|████      | 6729/16329 [56:41<1:25:57,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6729: train loss 1.74573. lr 5.392931e-04:  41%|████      | 6729/16329 [56:42<1:25:57,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6729: train loss 1.74573. lr 5.392931e-04:  41%|████      | 6730/16329 [56:42<1:24:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6730: train loss 1.71286. lr 5.392757e-04:  41%|████      | 6730/16329 [56:42<1:24:58,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6730: train loss 1.71286. lr 5.392757e-04:  41%|████      | 6731/16329 [56:42<1:23:54,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6731: train loss 1.73757. lr 5.392583e-04:  41%|████      | 6731/16329 [56:43<1:23:54,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6731: train loss 1.73757. lr 5.392583e-04:  41%|████      | 6732/16329 [56:43<1:23:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6732: train loss 1.77560. lr 5.392409e-04:  41%|████      | 6732/16329 [56:43<1:23:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6732: train loss 1.77560. lr 5.392409e-04:  41%|████      | 6733/16329 [56:43<1:22:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6733: train loss 1.76967. lr 5.392235e-04:  41%|████      | 6733/16329 [56:44<1:22:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6733: train loss 1.76967. lr 5.392235e-04:  41%|████      | 6734/16329 [56:44<1:21:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6734: train loss 1.72533. lr 5.392061e-04:  41%|████      | 6734/16329 [56:44<1:21:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6734: train loss 1.72533. lr 5.392061e-04:  41%|████      | 6735/16329 [56:44<1:20:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6735: train loss 1.74401. lr 5.391887e-04:  41%|████      | 6735/16329 [56:45<1:20:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6735: train loss 1.74401. lr 5.391887e-04:  41%|████▏     | 6736/16329 [56:45<1:20:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6736: train loss 1.74562. lr 5.391712e-04:  41%|████▏     | 6736/16329 [56:45<1:20:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6736: train loss 1.74562. lr 5.391712e-04:  41%|████▏     | 6737/16329 [56:45<1:21:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6737: train loss 1.75954. lr 5.391538e-04:  41%|████▏     | 6737/16329 [56:46<1:21:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6737: train loss 1.75954. lr 5.391538e-04:  41%|████▏     | 6738/16329 [56:46<1:22:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6738: train loss 1.74746. lr 5.391364e-04:  41%|████▏     | 6738/16329 [56:46<1:22:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6738: train loss 1.74746. lr 5.391364e-04:  41%|████▏     | 6739/16329 [56:46<1:22:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6739: train loss 1.75593. lr 5.391190e-04:  41%|████▏     | 6739/16329 [56:47<1:22:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6739: train loss 1.75593. lr 5.391190e-04:  41%|████▏     | 6740/16329 [56:47<1:22:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6740: train loss 1.73617. lr 5.391015e-04:  41%|████▏     | 6740/16329 [56:47<1:22:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6740: train loss 1.73617. lr 5.391015e-04:  41%|████▏     | 6741/16329 [56:47<1:21:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6741: train loss 1.71525. lr 5.390841e-04:  41%|████▏     | 6741/16329 [56:48<1:21:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6741: train loss 1.71525. lr 5.390841e-04:  41%|████▏     | 6742/16329 [56:48<1:21:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6742: train loss 1.74717. lr 5.390667e-04:  41%|████▏     | 6742/16329 [56:48<1:21:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6742: train loss 1.74717. lr 5.390667e-04:  41%|████▏     | 6743/16329 [56:48<1:21:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6743: train loss 1.75213. lr 5.390492e-04:  41%|████▏     | 6743/16329 [56:49<1:21:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6743: train loss 1.75213. lr 5.390492e-04:  41%|████▏     | 6744/16329 [56:49<1:20:53,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6744: train loss 1.73642. lr 5.390318e-04:  41%|████▏     | 6744/16329 [56:49<1:20:53,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6744: train loss 1.73642. lr 5.390318e-04:  41%|████▏     | 6745/16329 [56:49<1:20:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6745: train loss 1.75585. lr 5.390144e-04:  41%|████▏     | 6745/16329 [56:50<1:20:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6745: train loss 1.75585. lr 5.390144e-04:  41%|████▏     | 6746/16329 [56:50<1:20:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6746: train loss 1.75279. lr 5.389969e-04:  41%|████▏     | 6746/16329 [56:50<1:20:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6746: train loss 1.75279. lr 5.389969e-04:  41%|████▏     | 6747/16329 [56:50<1:20:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6747: train loss 1.74143. lr 5.389795e-04:  41%|████▏     | 6747/16329 [56:51<1:20:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6747: train loss 1.74143. lr 5.389795e-04:  41%|████▏     | 6748/16329 [56:51<1:22:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6748: train loss 1.74761. lr 5.389620e-04:  41%|████▏     | 6748/16329 [56:51<1:22:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6748: train loss 1.74761. lr 5.389620e-04:  41%|████▏     | 6749/16329 [56:51<1:22:42,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6749: train loss 1.71600. lr 5.389446e-04:  41%|████▏     | 6749/16329 [56:52<1:22:42,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6749: train loss 1.71600. lr 5.389446e-04:  41%|████▏     | 6750/16329 [56:52<1:22:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6750: train loss 1.75024. lr 5.389271e-04:  41%|████▏     | 6750/16329 [56:52<1:22:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6750: train loss 1.75024. lr 5.389271e-04:  41%|████▏     | 6751/16329 [56:52<1:22:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6751: train loss 1.72716. lr 5.389097e-04:  41%|████▏     | 6751/16329 [56:53<1:22:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6751: train loss 1.72716. lr 5.389097e-04:  41%|████▏     | 6752/16329 [56:53<1:22:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6752: train loss 1.79147. lr 5.388922e-04:  41%|████▏     | 6752/16329 [56:53<1:22:02,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6752: train loss 1.79147. lr 5.388922e-04:  41%|████▏     | 6753/16329 [56:53<1:21:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6753: train loss 1.75541. lr 5.388747e-04:  41%|████▏     | 6753/16329 [56:54<1:21:37,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6753: train loss 1.75541. lr 5.388747e-04:  41%|████▏     | 6754/16329 [56:54<1:21:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6754: train loss 1.73505. lr 5.388573e-04:  41%|████▏     | 6754/16329 [56:54<1:21:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6754: train loss 1.73505. lr 5.388573e-04:  41%|████▏     | 6755/16329 [56:54<1:21:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6755: train loss 1.74963. lr 5.388398e-04:  41%|████▏     | 6755/16329 [56:55<1:21:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6755: train loss 1.74963. lr 5.388398e-04:  41%|████▏     | 6756/16329 [56:55<1:20:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6756: train loss 1.73779. lr 5.388224e-04:  41%|████▏     | 6756/16329 [56:55<1:20:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6756: train loss 1.73779. lr 5.388224e-04:  41%|████▏     | 6757/16329 [56:55<1:20:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6757: train loss 1.74199. lr 5.388049e-04:  41%|████▏     | 6757/16329 [56:56<1:20:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6757: train loss 1.74199. lr 5.388049e-04:  41%|████▏     | 6758/16329 [56:56<1:20:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6758: train loss 1.72763. lr 5.387874e-04:  41%|████▏     | 6758/16329 [56:56<1:20:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6758: train loss 1.72763. lr 5.387874e-04:  41%|████▏     | 6759/16329 [56:56<1:19:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6759: train loss 1.72444. lr 5.387699e-04:  41%|████▏     | 6759/16329 [56:57<1:19:50,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6759: train loss 1.72444. lr 5.387699e-04:  41%|████▏     | 6760/16329 [56:57<1:19:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6760: train loss 1.73880. lr 5.387525e-04:  41%|████▏     | 6760/16329 [56:57<1:19:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6760: train loss 1.73880. lr 5.387525e-04:  41%|████▏     | 6761/16329 [56:57<1:19:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6761: train loss 1.71292. lr 5.387350e-04:  41%|████▏     | 6761/16329 [56:58<1:19:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6761: train loss 1.71292. lr 5.387350e-04:  41%|████▏     | 6762/16329 [56:58<1:18:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6762: train loss 1.73646. lr 5.387175e-04:  41%|████▏     | 6762/16329 [56:58<1:18:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6762: train loss 1.73646. lr 5.387175e-04:  41%|████▏     | 6763/16329 [56:58<1:18:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6763: train loss 1.69827. lr 5.387000e-04:  41%|████▏     | 6763/16329 [56:59<1:18:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6763: train loss 1.69827. lr 5.387000e-04:  41%|████▏     | 6764/16329 [56:59<1:18:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6764: train loss 1.72993. lr 5.386826e-04:  41%|████▏     | 6764/16329 [56:59<1:18:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6764: train loss 1.72993. lr 5.386826e-04:  41%|████▏     | 6765/16329 [56:59<1:18:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6765: train loss 1.70968. lr 5.386651e-04:  41%|████▏     | 6765/16329 [57:00<1:18:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6765: train loss 1.70968. lr 5.386651e-04:  41%|████▏     | 6766/16329 [57:00<1:26:38,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6766: train loss 1.77006. lr 5.386476e-04:  41%|████▏     | 6766/16329 [57:01<1:26:38,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 6766: train loss 1.77006. lr 5.386476e-04:  41%|████▏     | 6767/16329 [57:01<1:24:26,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6767: train loss 1.73111. lr 5.386301e-04:  41%|████▏     | 6767/16329 [57:01<1:24:26,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6767: train loss 1.73111. lr 5.386301e-04:  41%|████▏     | 6768/16329 [57:01<1:22:47,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6768: train loss 1.72856. lr 5.386126e-04:  41%|████▏     | 6768/16329 [57:01<1:22:47,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6768: train loss 1.72856. lr 5.386126e-04:  41%|████▏     | 6769/16329 [57:01<1:21:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6769: train loss 1.76798. lr 5.385951e-04:  41%|████▏     | 6769/16329 [57:02<1:21:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6769: train loss 1.76798. lr 5.385951e-04:  41%|████▏     | 6770/16329 [57:02<1:20:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6770: train loss 1.69230. lr 5.385776e-04:  41%|████▏     | 6770/16329 [57:02<1:20:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6770: train loss 1.69230. lr 5.385776e-04:  41%|████▏     | 6771/16329 [57:02<1:19:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6771: train loss 1.80117. lr 5.385601e-04:  41%|████▏     | 6771/16329 [57:03<1:19:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6771: train loss 1.80117. lr 5.385601e-04:  41%|████▏     | 6772/16329 [57:03<1:19:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6772: train loss 1.77442. lr 5.385426e-04:  41%|████▏     | 6772/16329 [57:03<1:19:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6772: train loss 1.77442. lr 5.385426e-04:  41%|████▏     | 6773/16329 [57:03<1:19:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6773: train loss 1.76283. lr 5.385251e-04:  41%|████▏     | 6773/16329 [57:04<1:19:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6773: train loss 1.76283. lr 5.385251e-04:  41%|████▏     | 6774/16329 [57:04<1:19:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6774: train loss 1.74575. lr 5.385076e-04:  41%|████▏     | 6774/16329 [57:04<1:19:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6774: train loss 1.74575. lr 5.385076e-04:  41%|████▏     | 6775/16329 [57:04<1:18:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6775: train loss 1.79394. lr 5.384901e-04:  41%|████▏     | 6775/16329 [57:05<1:18:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6775: train loss 1.79394. lr 5.384901e-04:  41%|████▏     | 6776/16329 [57:05<1:18:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6776: train loss 1.73263. lr 5.384726e-04:  41%|████▏     | 6776/16329 [57:05<1:18:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6776: train loss 1.73263. lr 5.384726e-04:  42%|████▏     | 6777/16329 [57:06<1:21:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6777: train loss 1.76501. lr 5.384551e-04:  42%|████▏     | 6777/16329 [57:06<1:21:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6777: train loss 1.76501. lr 5.384551e-04:  42%|████▏     | 6778/16329 [57:06<1:23:45,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6778: train loss 1.70085. lr 5.384376e-04:  42%|████▏     | 6778/16329 [57:07<1:23:45,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6778: train loss 1.70085. lr 5.384376e-04:  42%|████▏     | 6779/16329 [57:07<1:24:28,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6779: train loss 1.75870. lr 5.384201e-04:  42%|████▏     | 6779/16329 [57:07<1:24:28,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6779: train loss 1.75870. lr 5.384201e-04:  42%|████▏     | 6780/16329 [57:07<1:24:03,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6780: train loss 1.73338. lr 5.384025e-04:  42%|████▏     | 6780/16329 [57:08<1:24:03,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6780: train loss 1.73338. lr 5.384025e-04:  42%|████▏     | 6781/16329 [57:08<1:23:20,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6781: train loss 1.77832. lr 5.383850e-04:  42%|████▏     | 6781/16329 [57:08<1:23:20,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6781: train loss 1.77832. lr 5.383850e-04:  42%|████▏     | 6782/16329 [57:08<1:22:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6782: train loss 1.76823. lr 5.383675e-04:  42%|████▏     | 6782/16329 [57:09<1:22:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6782: train loss 1.76823. lr 5.383675e-04:  42%|████▏     | 6783/16329 [57:09<1:21:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6783: train loss 1.79883. lr 5.383500e-04:  42%|████▏     | 6783/16329 [57:09<1:21:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6783: train loss 1.79883. lr 5.383500e-04:  42%|████▏     | 6784/16329 [57:09<1:21:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6784: train loss 1.77003. lr 5.383324e-04:  42%|████▏     | 6784/16329 [57:10<1:21:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6784: train loss 1.77003. lr 5.383324e-04:  42%|████▏     | 6785/16329 [57:10<1:20:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6785: train loss 1.74065. lr 5.383149e-04:  42%|████▏     | 6785/16329 [57:10<1:20:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6785: train loss 1.74065. lr 5.383149e-04:  42%|████▏     | 6786/16329 [57:10<1:19:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6786: train loss 1.74221. lr 5.382974e-04:  42%|████▏     | 6786/16329 [57:11<1:19:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6786: train loss 1.74221. lr 5.382974e-04:  42%|████▏     | 6787/16329 [57:11<1:19:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6787: train loss 1.76204. lr 5.382798e-04:  42%|████▏     | 6787/16329 [57:11<1:19:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6787: train loss 1.76204. lr 5.382798e-04:  42%|████▏     | 6788/16329 [57:11<1:19:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6788: train loss 1.67006. lr 5.382623e-04:  42%|████▏     | 6788/16329 [57:12<1:19:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6788: train loss 1.67006. lr 5.382623e-04:  42%|████▏     | 6789/16329 [57:12<1:19:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6789: train loss 1.74373. lr 5.382448e-04:  42%|████▏     | 6789/16329 [57:12<1:19:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6789: train loss 1.74373. lr 5.382448e-04:  42%|████▏     | 6790/16329 [57:12<1:18:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6790: train loss 1.76345. lr 5.382272e-04:  42%|████▏     | 6790/16329 [57:13<1:18:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6790: train loss 1.76345. lr 5.382272e-04:  42%|████▏     | 6791/16329 [57:13<1:20:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6791: train loss 1.71977. lr 5.382097e-04:  42%|████▏     | 6791/16329 [57:13<1:20:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6791: train loss 1.71977. lr 5.382097e-04:  42%|████▏     | 6792/16329 [57:13<1:22:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6792: train loss 1.67946. lr 5.381921e-04:  42%|████▏     | 6792/16329 [57:14<1:22:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 6792: train loss 1.67946. lr 5.381921e-04:  42%|████▏     | 6793/16329 [57:14<1:22:55,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6793: train loss 1.76134. lr 5.381746e-04:  42%|████▏     | 6793/16329 [57:14<1:22:55,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6793: train loss 1.76134. lr 5.381746e-04:  42%|████▏     | 6794/16329 [57:14<1:22:51,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6794: train loss 1.75899. lr 5.381570e-04:  42%|████▏     | 6794/16329 [57:15<1:22:51,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6794: train loss 1.75899. lr 5.381570e-04:  42%|████▏     | 6795/16329 [57:15<1:22:39,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6795: train loss 1.75554. lr 5.381395e-04:  42%|████▏     | 6795/16329 [57:15<1:22:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6795: train loss 1.75554. lr 5.381395e-04:  42%|████▏     | 6796/16329 [57:15<1:22:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6796: train loss 1.74445. lr 5.381219e-04:  42%|████▏     | 6796/16329 [57:16<1:22:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6796: train loss 1.74445. lr 5.381219e-04:  42%|████▏     | 6797/16329 [57:16<1:21:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6797: train loss 1.69638. lr 5.381044e-04:  42%|████▏     | 6797/16329 [57:16<1:21:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6797: train loss 1.69638. lr 5.381044e-04:  42%|████▏     | 6798/16329 [57:16<1:20:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6798: train loss 1.72160. lr 5.380868e-04:  42%|████▏     | 6798/16329 [57:17<1:20:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6798: train loss 1.72160. lr 5.380868e-04:  42%|████▏     | 6799/16329 [57:17<1:20:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6799: train loss 1.74714. lr 5.380693e-04:  42%|████▏     | 6799/16329 [57:17<1:20:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6799: train loss 1.74714. lr 5.380693e-04:  42%|████▏     | 6800/16329 [57:17<1:19:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6800: train loss 1.76092. lr 5.380517e-04:  42%|████▏     | 6800/16329 [57:18<1:19:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6800: train loss 1.76092. lr 5.380517e-04:  42%|████▏     | 6801/16329 [57:18<1:27:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6801: train loss 1.77519. lr 5.380341e-04:  42%|████▏     | 6801/16329 [57:18<1:27:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6801: train loss 1.77519. lr 5.380341e-04:  42%|████▏     | 6802/16329 [57:18<1:24:51,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6802: train loss 1.72624. lr 5.380166e-04:  42%|████▏     | 6802/16329 [57:19<1:24:51,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6802: train loss 1.72624. lr 5.380166e-04:  42%|████▏     | 6803/16329 [57:19<1:22:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6803: train loss 1.75865. lr 5.379990e-04:  42%|████▏     | 6803/16329 [57:19<1:22:55,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6803: train loss 1.75865. lr 5.379990e-04:  42%|████▏     | 6804/16329 [57:19<1:21:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6804: train loss 1.72380. lr 5.379814e-04:  42%|████▏     | 6804/16329 [57:20<1:21:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6804: train loss 1.72380. lr 5.379814e-04:  42%|████▏     | 6805/16329 [57:20<1:20:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6805: train loss 1.71407. lr 5.379639e-04:  42%|████▏     | 6805/16329 [57:20<1:20:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6805: train loss 1.71407. lr 5.379639e-04:  42%|████▏     | 6806/16329 [57:20<1:19:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6806: train loss 1.69846. lr 5.379463e-04:  42%|████▏     | 6806/16329 [57:21<1:19:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6806: train loss 1.69846. lr 5.379463e-04:  42%|████▏     | 6807/16329 [57:21<1:19:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6807: train loss 1.71736. lr 5.379287e-04:  42%|████▏     | 6807/16329 [57:21<1:19:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6807: train loss 1.71736. lr 5.379287e-04:  42%|████▏     | 6808/16329 [57:21<1:18:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6808: train loss 1.74791. lr 5.379111e-04:  42%|████▏     | 6808/16329 [57:22<1:18:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6808: train loss 1.74791. lr 5.379111e-04:  42%|████▏     | 6809/16329 [57:22<1:18:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6809: train loss 1.71459. lr 5.378935e-04:  42%|████▏     | 6809/16329 [57:22<1:18:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6809: train loss 1.71459. lr 5.378935e-04:  42%|████▏     | 6810/16329 [57:22<1:18:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6810: train loss 1.75347. lr 5.378760e-04:  42%|████▏     | 6810/16329 [57:23<1:18:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6810: train loss 1.75347. lr 5.378760e-04:  42%|████▏     | 6811/16329 [57:23<1:18:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6811: train loss 1.77048. lr 5.378584e-04:  42%|████▏     | 6811/16329 [57:23<1:18:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6811: train loss 1.77048. lr 5.378584e-04:  42%|████▏     | 6812/16329 [57:23<1:18:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6812: train loss 1.72946. lr 5.378408e-04:  42%|████▏     | 6812/16329 [57:24<1:18:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6812: train loss 1.72946. lr 5.378408e-04:  42%|████▏     | 6813/16329 [57:24<1:18:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6813: train loss 1.73491. lr 5.378232e-04:  42%|████▏     | 6813/16329 [57:24<1:18:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6813: train loss 1.73491. lr 5.378232e-04:  42%|████▏     | 6814/16329 [57:24<1:18:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6814: train loss 1.73626. lr 5.378056e-04:  42%|████▏     | 6814/16329 [57:25<1:18:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6814: train loss 1.73626. lr 5.378056e-04:  42%|████▏     | 6815/16329 [57:25<1:18:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6815: train loss 1.73004. lr 5.377880e-04:  42%|████▏     | 6815/16329 [57:25<1:18:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6815: train loss 1.73004. lr 5.377880e-04:  42%|████▏     | 6816/16329 [57:25<1:18:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6816: train loss 1.71500. lr 5.377704e-04:  42%|████▏     | 6816/16329 [57:26<1:18:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6816: train loss 1.71500. lr 5.377704e-04:  42%|████▏     | 6817/16329 [57:26<1:17:46,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 6817: train loss 1.78396. lr 5.377528e-04:  42%|████▏     | 6817/16329 [57:26<1:17:46,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 6817: train loss 1.78396. lr 5.377528e-04:  42%|████▏     | 6818/16329 [57:26<1:18:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6818: train loss 1.73133. lr 5.377352e-04:  42%|████▏     | 6818/16329 [57:27<1:18:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6818: train loss 1.73133. lr 5.377352e-04:  42%|████▏     | 6819/16329 [57:27<1:18:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6819: train loss 1.75705. lr 5.377176e-04:  42%|████▏     | 6819/16329 [57:27<1:18:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6819: train loss 1.75705. lr 5.377176e-04:  42%|████▏     | 6820/16329 [57:27<1:17:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6820: train loss 1.71952. lr 5.377000e-04:  42%|████▏     | 6820/16329 [57:28<1:17:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6820: train loss 1.71952. lr 5.377000e-04:  42%|████▏     | 6821/16329 [57:28<1:18:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6821: train loss 1.76792. lr 5.376824e-04:  42%|████▏     | 6821/16329 [57:28<1:18:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6821: train loss 1.76792. lr 5.376824e-04:  42%|████▏     | 6822/16329 [57:28<1:17:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6822: train loss 1.71026. lr 5.376648e-04:  42%|████▏     | 6822/16329 [57:29<1:17:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6822: train loss 1.71026. lr 5.376648e-04:  42%|████▏     | 6823/16329 [57:29<1:18:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6823: train loss 1.71770. lr 5.376472e-04:  42%|████▏     | 6823/16329 [57:29<1:18:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6823: train loss 1.71770. lr 5.376472e-04:  42%|████▏     | 6824/16329 [57:29<1:18:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6824: train loss 1.80544. lr 5.376296e-04:  42%|████▏     | 6824/16329 [57:30<1:18:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6824: train loss 1.80544. lr 5.376296e-04:  42%|████▏     | 6825/16329 [57:30<1:18:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6825: train loss 1.69486. lr 5.376119e-04:  42%|████▏     | 6825/16329 [57:30<1:18:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6825: train loss 1.69486. lr 5.376119e-04:  42%|████▏     | 6826/16329 [57:30<1:26:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6826: train loss 1.74223. lr 5.375943e-04:  42%|████▏     | 6826/16329 [57:31<1:26:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6826: train loss 1.74223. lr 5.375943e-04:  42%|████▏     | 6827/16329 [57:31<1:24:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6827: train loss 1.77401. lr 5.375767e-04:  42%|████▏     | 6827/16329 [57:31<1:24:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6827: train loss 1.77401. lr 5.375767e-04:  42%|████▏     | 6828/16329 [57:31<1:22:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6828: train loss 1.74563. lr 5.375591e-04:  42%|████▏     | 6828/16329 [57:32<1:22:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6828: train loss 1.74563. lr 5.375591e-04:  42%|████▏     | 6829/16329 [57:32<1:20:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6829: train loss 1.71905. lr 5.375414e-04:  42%|████▏     | 6829/16329 [57:32<1:20:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6829: train loss 1.71905. lr 5.375414e-04:  42%|████▏     | 6830/16329 [57:32<1:19:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6830: train loss 1.74847. lr 5.375238e-04:  42%|████▏     | 6830/16329 [57:33<1:19:50,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6830: train loss 1.74847. lr 5.375238e-04:  42%|████▏     | 6831/16329 [57:33<1:19:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6831: train loss 1.74272. lr 5.375062e-04:  42%|████▏     | 6831/16329 [57:33<1:19:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6831: train loss 1.74272. lr 5.375062e-04:  42%|████▏     | 6832/16329 [57:33<1:18:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6832: train loss 1.77107. lr 5.374886e-04:  42%|████▏     | 6832/16329 [57:34<1:18:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6832: train loss 1.77107. lr 5.374886e-04:  42%|████▏     | 6833/16329 [57:34<1:18:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6833: train loss 1.76944. lr 5.374709e-04:  42%|████▏     | 6833/16329 [57:34<1:18:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6833: train loss 1.76944. lr 5.374709e-04:  42%|████▏     | 6834/16329 [57:34<1:18:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6834: train loss 1.70331. lr 5.374533e-04:  42%|████▏     | 6834/16329 [57:35<1:18:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6834: train loss 1.70331. lr 5.374533e-04:  42%|████▏     | 6835/16329 [57:35<1:18:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6835: train loss 1.77224. lr 5.374356e-04:  42%|████▏     | 6835/16329 [57:35<1:18:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6835: train loss 1.77224. lr 5.374356e-04:  42%|████▏     | 6836/16329 [57:35<1:18:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6836: train loss 1.72601. lr 5.374180e-04:  42%|████▏     | 6836/16329 [57:36<1:18:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6836: train loss 1.72601. lr 5.374180e-04:  42%|████▏     | 6837/16329 [57:36<1:18:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6837: train loss 1.68193. lr 5.374004e-04:  42%|████▏     | 6837/16329 [57:36<1:18:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6837: train loss 1.68193. lr 5.374004e-04:  42%|████▏     | 6838/16329 [57:36<1:18:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6838: train loss 1.74176. lr 5.373827e-04:  42%|████▏     | 6838/16329 [57:37<1:18:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6838: train loss 1.74176. lr 5.373827e-04:  42%|████▏     | 6839/16329 [57:37<1:18:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6839: train loss 1.73211. lr 5.373651e-04:  42%|████▏     | 6839/16329 [57:37<1:18:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6839: train loss 1.73211. lr 5.373651e-04:  42%|████▏     | 6840/16329 [57:37<1:18:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6840: train loss 1.73423. lr 5.373474e-04:  42%|████▏     | 6840/16329 [57:38<1:18:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6840: train loss 1.73423. lr 5.373474e-04:  42%|████▏     | 6841/16329 [57:38<1:18:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6841: train loss 1.73226. lr 5.373298e-04:  42%|████▏     | 6841/16329 [57:38<1:18:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6841: train loss 1.73226. lr 5.373298e-04:  42%|████▏     | 6842/16329 [57:38<1:18:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6842: train loss 1.70926. lr 5.373121e-04:  42%|████▏     | 6842/16329 [57:39<1:18:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6842: train loss 1.70926. lr 5.373121e-04:  42%|████▏     | 6843/16329 [57:39<1:21:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6843: train loss 1.72640. lr 5.372945e-04:  42%|████▏     | 6843/16329 [57:39<1:21:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6843: train loss 1.72640. lr 5.372945e-04:  42%|████▏     | 6844/16329 [57:39<1:22:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6844: train loss 1.74175. lr 5.372768e-04:  42%|████▏     | 6844/16329 [57:40<1:22:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6844: train loss 1.74175. lr 5.372768e-04:  42%|████▏     | 6845/16329 [57:40<1:23:30,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6845: train loss 1.77175. lr 5.372591e-04:  42%|████▏     | 6845/16329 [57:40<1:23:30,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6845: train loss 1.77175. lr 5.372591e-04:  42%|████▏     | 6846/16329 [57:40<1:23:25,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6846: train loss 1.71771. lr 5.372415e-04:  42%|████▏     | 6846/16329 [57:41<1:23:25,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 6846: train loss 1.71771. lr 5.372415e-04:  42%|████▏     | 6847/16329 [57:41<1:22:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6847: train loss 1.72985. lr 5.372238e-04:  42%|████▏     | 6847/16329 [57:42<1:22:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6847: train loss 1.72985. lr 5.372238e-04:  42%|████▏     | 6848/16329 [57:42<1:22:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6848: train loss 1.69414. lr 5.372061e-04:  42%|████▏     | 6848/16329 [57:42<1:22:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6848: train loss 1.69414. lr 5.372061e-04:  42%|████▏     | 6849/16329 [57:42<1:21:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6849: train loss 1.75507. lr 5.371885e-04:  42%|████▏     | 6849/16329 [57:43<1:21:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6849: train loss 1.75507. lr 5.371885e-04:  42%|████▏     | 6850/16329 [57:43<1:20:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6850: train loss 1.68805. lr 5.371708e-04:  42%|████▏     | 6850/16329 [57:43<1:20:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6850: train loss 1.68805. lr 5.371708e-04:  42%|████▏     | 6851/16329 [57:43<1:20:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6851: train loss 1.71968. lr 5.371531e-04:  42%|████▏     | 6851/16329 [57:44<1:20:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6851: train loss 1.71968. lr 5.371531e-04:  42%|████▏     | 6852/16329 [57:44<1:19:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6852: train loss 1.72429. lr 5.371354e-04:  42%|████▏     | 6852/16329 [57:44<1:19:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6852: train loss 1.72429. lr 5.371354e-04:  42%|████▏     | 6853/16329 [57:44<1:27:34,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6853: train loss 1.73188. lr 5.371178e-04:  42%|████▏     | 6853/16329 [57:45<1:27:34,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 6853: train loss 1.73188. lr 5.371178e-04:  42%|████▏     | 6854/16329 [57:45<1:24:39,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6854: train loss 1.72395. lr 5.371001e-04:  42%|████▏     | 6854/16329 [57:45<1:24:39,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6854: train loss 1.72395. lr 5.371001e-04:  42%|████▏     | 6855/16329 [57:45<1:22:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6855: train loss 1.73484. lr 5.370824e-04:  42%|████▏     | 6855/16329 [57:46<1:22:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6855: train loss 1.73484. lr 5.370824e-04:  42%|████▏     | 6856/16329 [57:46<1:21:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6856: train loss 1.70881. lr 5.370647e-04:  42%|████▏     | 6856/16329 [57:46<1:21:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6856: train loss 1.70881. lr 5.370647e-04:  42%|████▏     | 6857/16329 [57:46<1:20:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6857: train loss 1.75868. lr 5.370470e-04:  42%|████▏     | 6857/16329 [57:47<1:20:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6857: train loss 1.75868. lr 5.370470e-04:  42%|████▏     | 6858/16329 [57:47<1:19:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6858: train loss 1.65709. lr 5.370293e-04:  42%|████▏     | 6858/16329 [57:47<1:19:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6858: train loss 1.65709. lr 5.370293e-04:  42%|████▏     | 6859/16329 [57:47<1:18:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6859: train loss 1.71746. lr 5.370116e-04:  42%|████▏     | 6859/16329 [57:48<1:18:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6859: train loss 1.71746. lr 5.370116e-04:  42%|████▏     | 6860/16329 [57:48<1:18:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6860: train loss 1.73015. lr 5.369939e-04:  42%|████▏     | 6860/16329 [57:48<1:18:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6860: train loss 1.73015. lr 5.369939e-04:  42%|████▏     | 6861/16329 [57:48<1:18:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6861: train loss 1.69364. lr 5.369763e-04:  42%|████▏     | 6861/16329 [57:49<1:18:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6861: train loss 1.69364. lr 5.369763e-04:  42%|████▏     | 6862/16329 [57:49<1:18:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6862: train loss 1.74982. lr 5.369586e-04:  42%|████▏     | 6862/16329 [57:49<1:18:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6862: train loss 1.74982. lr 5.369586e-04:  42%|████▏     | 6863/16329 [57:49<1:17:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6863: train loss 1.74458. lr 5.369409e-04:  42%|████▏     | 6863/16329 [57:50<1:17:53,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6863: train loss 1.74458. lr 5.369409e-04:  42%|████▏     | 6864/16329 [57:50<1:17:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6864: train loss 1.74106. lr 5.369232e-04:  42%|████▏     | 6864/16329 [57:50<1:17:50,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6864: train loss 1.74106. lr 5.369232e-04:  42%|████▏     | 6865/16329 [57:50<1:17:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6865: train loss 1.72488. lr 5.369054e-04:  42%|████▏     | 6865/16329 [57:51<1:17:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6865: train loss 1.72488. lr 5.369054e-04:  42%|████▏     | 6866/16329 [57:51<1:17:41,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6866: train loss 1.72371. lr 5.368877e-04:  42%|████▏     | 6866/16329 [57:51<1:17:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6866: train loss 1.72371. lr 5.368877e-04:  42%|████▏     | 6867/16329 [57:51<1:17:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6867: train loss 1.74510. lr 5.368700e-04:  42%|████▏     | 6867/16329 [57:52<1:17:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6867: train loss 1.74510. lr 5.368700e-04:  42%|████▏     | 6868/16329 [57:52<1:17:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6868: train loss 1.75057. lr 5.368523e-04:  42%|████▏     | 6868/16329 [57:52<1:17:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6868: train loss 1.75057. lr 5.368523e-04:  42%|████▏     | 6869/16329 [57:52<1:17:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6869: train loss 1.73244. lr 5.368346e-04:  42%|████▏     | 6869/16329 [57:53<1:17:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6869: train loss 1.73244. lr 5.368346e-04:  42%|████▏     | 6870/16329 [57:53<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6870: train loss 1.66735. lr 5.368169e-04:  42%|████▏     | 6870/16329 [57:53<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6870: train loss 1.66735. lr 5.368169e-04:  42%|████▏     | 6871/16329 [57:53<1:17:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6871: train loss 1.72888. lr 5.367992e-04:  42%|████▏     | 6871/16329 [57:54<1:17:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6871: train loss 1.72888. lr 5.367992e-04:  42%|████▏     | 6872/16329 [57:54<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6872: train loss 1.76536. lr 5.367814e-04:  42%|████▏     | 6872/16329 [57:54<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6872: train loss 1.76536. lr 5.367814e-04:  42%|████▏     | 6873/16329 [57:54<1:17:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6873: train loss 1.76368. lr 5.367637e-04:  42%|████▏     | 6873/16329 [57:55<1:17:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6873: train loss 1.76368. lr 5.367637e-04:  42%|████▏     | 6874/16329 [57:55<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6874: train loss 1.72572. lr 5.367460e-04:  42%|████▏     | 6874/16329 [57:55<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6874: train loss 1.72572. lr 5.367460e-04:  42%|████▏     | 6875/16329 [57:55<1:17:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6875: train loss 1.70369. lr 5.367283e-04:  42%|████▏     | 6875/16329 [57:56<1:17:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6875: train loss 1.70369. lr 5.367283e-04:  42%|████▏     | 6876/16329 [57:56<1:17:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6876: train loss 1.70279. lr 5.367105e-04:  42%|████▏     | 6876/16329 [57:56<1:17:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6876: train loss 1.70279. lr 5.367105e-04:  42%|████▏     | 6877/16329 [57:56<1:17:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6877: train loss 1.73073. lr 5.366928e-04:  42%|████▏     | 6877/16329 [57:57<1:17:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6877: train loss 1.73073. lr 5.366928e-04:  42%|████▏     | 6878/16329 [57:57<1:17:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6878: train loss 1.72997. lr 5.366751e-04:  42%|████▏     | 6878/16329 [57:57<1:17:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6878: train loss 1.72997. lr 5.366751e-04:  42%|████▏     | 6879/16329 [57:57<1:17:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6879: train loss 1.75541. lr 5.366573e-04:  42%|████▏     | 6879/16329 [57:57<1:17:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6879: train loss 1.75541. lr 5.366573e-04:  42%|████▏     | 6880/16329 [57:58<1:17:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6880: train loss 1.70575. lr 5.366396e-04:  42%|████▏     | 6880/16329 [57:58<1:17:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6880: train loss 1.70575. lr 5.366396e-04:  42%|████▏     | 6881/16329 [57:58<1:17:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6881: train loss 1.70332. lr 5.366219e-04:  42%|████▏     | 6881/16329 [57:58<1:17:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6881: train loss 1.70332. lr 5.366219e-04:  42%|████▏     | 6882/16329 [57:58<1:17:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6882: train loss 1.77896. lr 5.366041e-04:  42%|████▏     | 6882/16329 [57:59<1:17:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6882: train loss 1.77896. lr 5.366041e-04:  42%|████▏     | 6883/16329 [57:59<1:17:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6883: train loss 1.68687. lr 5.365864e-04:  42%|████▏     | 6883/16329 [57:59<1:17:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6883: train loss 1.68687. lr 5.365864e-04:  42%|████▏     | 6884/16329 [57:59<1:17:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6884: train loss 1.72794. lr 5.365686e-04:  42%|████▏     | 6884/16329 [58:00<1:17:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6884: train loss 1.72794. lr 5.365686e-04:  42%|████▏     | 6885/16329 [58:00<1:17:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6885: train loss 1.68003. lr 5.365509e-04:  42%|████▏     | 6885/16329 [58:00<1:17:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6885: train loss 1.68003. lr 5.365509e-04:  42%|████▏     | 6886/16329 [58:00<1:17:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6886: train loss 1.79332. lr 5.365331e-04:  42%|████▏     | 6886/16329 [58:01<1:17:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6886: train loss 1.79332. lr 5.365331e-04:  42%|████▏     | 6887/16329 [58:01<1:17:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6887: train loss 1.75251. lr 5.365154e-04:  42%|████▏     | 6887/16329 [58:01<1:17:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6887: train loss 1.75251. lr 5.365154e-04:  42%|████▏     | 6888/16329 [58:01<1:17:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6888: train loss 1.73282. lr 5.364976e-04:  42%|████▏     | 6888/16329 [58:02<1:17:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6888: train loss 1.73282. lr 5.364976e-04:  42%|████▏     | 6889/16329 [58:02<1:17:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6889: train loss 1.74109. lr 5.364799e-04:  42%|████▏     | 6889/16329 [58:02<1:17:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6889: train loss 1.74109. lr 5.364799e-04:  42%|████▏     | 6890/16329 [58:02<1:17:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6890: train loss 1.80591. lr 5.364621e-04:  42%|████▏     | 6890/16329 [58:03<1:17:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6890: train loss 1.80591. lr 5.364621e-04:  42%|████▏     | 6891/16329 [58:03<1:18:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6891: train loss 1.72242. lr 5.364443e-04:  42%|████▏     | 6891/16329 [58:03<1:18:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6891: train loss 1.72242. lr 5.364443e-04:  42%|████▏     | 6892/16329 [58:03<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6892: train loss 1.73143. lr 5.364266e-04:  42%|████▏     | 6892/16329 [58:04<1:17:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6892: train loss 1.73143. lr 5.364266e-04:  42%|████▏     | 6893/16329 [58:04<1:26:10,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6893: train loss 1.75885. lr 5.364088e-04:  42%|████▏     | 6893/16329 [58:05<1:26:10,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 6893: train loss 1.75885. lr 5.364088e-04:  42%|████▏     | 6894/16329 [58:05<1:23:47,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6894: train loss 1.75032. lr 5.363910e-04:  42%|████▏     | 6894/16329 [58:05<1:23:47,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6894: train loss 1.75032. lr 5.363910e-04:  42%|████▏     | 6895/16329 [58:05<1:21:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6895: train loss 1.71779. lr 5.363733e-04:  42%|████▏     | 6895/16329 [58:06<1:21:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6895: train loss 1.71779. lr 5.363733e-04:  42%|████▏     | 6896/16329 [58:06<1:20:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6896: train loss 1.69042. lr 5.363555e-04:  42%|████▏     | 6896/16329 [58:06<1:20:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 6896: train loss 1.69042. lr 5.363555e-04:  42%|████▏     | 6897/16329 [58:06<1:19:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6897: train loss 1.69316. lr 5.363377e-04:  42%|████▏     | 6897/16329 [58:07<1:19:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6897: train loss 1.69316. lr 5.363377e-04:  42%|████▏     | 6898/16329 [58:07<1:18:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6898: train loss 1.72664. lr 5.363199e-04:  42%|████▏     | 6898/16329 [58:07<1:18:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6898: train loss 1.72664. lr 5.363199e-04:  42%|████▏     | 6899/16329 [58:07<1:18:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6899: train loss 1.74854. lr 5.363022e-04:  42%|████▏     | 6899/16329 [58:08<1:18:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6899: train loss 1.74854. lr 5.363022e-04:  42%|████▏     | 6900/16329 [58:08<1:18:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6900: train loss 1.75443. lr 5.362844e-04:  42%|████▏     | 6900/16329 [58:08<1:18:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6900: train loss 1.75443. lr 5.362844e-04:  42%|████▏     | 6901/16329 [58:08<1:18:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6901: train loss 1.70837. lr 5.362666e-04:  42%|████▏     | 6901/16329 [58:09<1:18:08,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6901: train loss 1.70837. lr 5.362666e-04:  42%|████▏     | 6902/16329 [58:09<1:17:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6902: train loss 1.77473. lr 5.362488e-04:  42%|████▏     | 6902/16329 [58:09<1:17:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6902: train loss 1.77473. lr 5.362488e-04:  42%|████▏     | 6903/16329 [58:09<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6903: train loss 1.69439. lr 5.362310e-04:  42%|████▏     | 6903/16329 [58:10<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6903: train loss 1.69439. lr 5.362310e-04:  42%|████▏     | 6904/16329 [58:10<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6904: train loss 1.73440. lr 5.362132e-04:  42%|████▏     | 6904/16329 [58:10<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6904: train loss 1.73440. lr 5.362132e-04:  42%|████▏     | 6905/16329 [58:10<1:17:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6905: train loss 1.73542. lr 5.361954e-04:  42%|████▏     | 6905/16329 [58:11<1:17:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6905: train loss 1.73542. lr 5.361954e-04:  42%|████▏     | 6906/16329 [58:11<1:17:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6906: train loss 1.71172. lr 5.361777e-04:  42%|████▏     | 6906/16329 [58:11<1:17:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6906: train loss 1.71172. lr 5.361777e-04:  42%|████▏     | 6907/16329 [58:11<1:17:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6907: train loss 1.70887. lr 5.361599e-04:  42%|████▏     | 6907/16329 [58:12<1:17:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6907: train loss 1.70887. lr 5.361599e-04:  42%|████▏     | 6908/16329 [58:12<1:17:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6908: train loss 1.68428. lr 5.361421e-04:  42%|████▏     | 6908/16329 [58:12<1:17:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6908: train loss 1.68428. lr 5.361421e-04:  42%|████▏     | 6909/16329 [58:12<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6909: train loss 1.73790. lr 5.361243e-04:  42%|████▏     | 6909/16329 [58:12<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6909: train loss 1.73790. lr 5.361243e-04:  42%|████▏     | 6910/16329 [58:12<1:17:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6910: train loss 1.66529. lr 5.361065e-04:  42%|████▏     | 6910/16329 [58:13<1:17:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6910: train loss 1.66529. lr 5.361065e-04:  42%|████▏     | 6911/16329 [58:13<1:17:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6911: train loss 1.70677. lr 5.360886e-04:  42%|████▏     | 6911/16329 [58:13<1:17:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6911: train loss 1.70677. lr 5.360886e-04:  42%|████▏     | 6912/16329 [58:13<1:17:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6912: train loss 1.70665. lr 5.360708e-04:  42%|████▏     | 6912/16329 [58:14<1:17:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6912: train loss 1.70665. lr 5.360708e-04:  42%|████▏     | 6913/16329 [58:14<1:17:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6913: train loss 1.70447. lr 5.360530e-04:  42%|████▏     | 6913/16329 [58:14<1:17:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6913: train loss 1.70447. lr 5.360530e-04:  42%|████▏     | 6914/16329 [58:14<1:17:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6914: train loss 1.64393. lr 5.360352e-04:  42%|████▏     | 6914/16329 [58:15<1:17:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6914: train loss 1.64393. lr 5.360352e-04:  42%|████▏     | 6915/16329 [58:15<1:18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6915: train loss 1.67441. lr 5.360174e-04:  42%|████▏     | 6915/16329 [58:15<1:18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6915: train loss 1.67441. lr 5.360174e-04:  42%|████▏     | 6916/16329 [58:15<1:18:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6916: train loss 1.74700. lr 5.359996e-04:  42%|████▏     | 6916/16329 [58:16<1:18:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6916: train loss 1.74700. lr 5.359996e-04:  42%|████▏     | 6917/16329 [58:16<1:17:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6917: train loss 1.74373. lr 5.359818e-04:  42%|████▏     | 6917/16329 [58:16<1:17:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6917: train loss 1.74373. lr 5.359818e-04:  42%|████▏     | 6918/16329 [58:16<1:17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6918: train loss 1.68355. lr 5.359639e-04:  42%|████▏     | 6918/16329 [58:17<1:17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6918: train loss 1.68355. lr 5.359639e-04:  42%|████▏     | 6919/16329 [58:17<1:17:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6919: train loss 1.72612. lr 5.359461e-04:  42%|████▏     | 6919/16329 [58:17<1:17:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6919: train loss 1.72612. lr 5.359461e-04:  42%|████▏     | 6920/16329 [58:17<1:17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6920: train loss 1.70030. lr 5.359283e-04:  42%|████▏     | 6920/16329 [58:18<1:17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6920: train loss 1.70030. lr 5.359283e-04:  42%|████▏     | 6921/16329 [58:18<1:18:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6921: train loss 1.78838. lr 5.359105e-04:  42%|████▏     | 6921/16329 [58:18<1:18:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6921: train loss 1.78838. lr 5.359105e-04:  42%|████▏     | 6922/16329 [58:18<1:18:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6922: train loss 1.75561. lr 5.358926e-04:  42%|████▏     | 6922/16329 [58:19<1:18:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6922: train loss 1.75561. lr 5.358926e-04:  42%|████▏     | 6923/16329 [58:19<1:18:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6923: train loss 1.70814. lr 5.358748e-04:  42%|████▏     | 6923/16329 [58:19<1:18:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6923: train loss 1.70814. lr 5.358748e-04:  42%|████▏     | 6924/16329 [58:19<1:18:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6924: train loss 1.70095. lr 5.358570e-04:  42%|████▏     | 6924/16329 [58:20<1:18:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6924: train loss 1.70095. lr 5.358570e-04:  42%|████▏     | 6925/16329 [58:20<1:18:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6925: train loss 1.68732. lr 5.358391e-04:  42%|████▏     | 6925/16329 [58:20<1:18:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6925: train loss 1.68732. lr 5.358391e-04:  42%|████▏     | 6926/16329 [58:20<1:19:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6926: train loss 1.67449. lr 5.358213e-04:  42%|████▏     | 6926/16329 [58:21<1:19:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6926: train loss 1.67449. lr 5.358213e-04:  42%|████▏     | 6927/16329 [58:21<1:19:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6927: train loss 1.68798. lr 5.358035e-04:  42%|████▏     | 6927/16329 [58:22<1:19:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6927: train loss 1.68798. lr 5.358035e-04:  42%|████▏     | 6928/16329 [58:22<1:29:41,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 6928: train loss 1.71440. lr 5.357856e-04:  42%|████▏     | 6928/16329 [58:22<1:29:41,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 6928: train loss 1.71440. lr 5.357856e-04:  42%|████▏     | 6929/16329 [58:22<1:26:18,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6929: train loss 1.74730. lr 5.357678e-04:  42%|████▏     | 6929/16329 [58:23<1:26:18,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6929: train loss 1.74730. lr 5.357678e-04:  42%|████▏     | 6930/16329 [58:23<1:24:11,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6930: train loss 1.74653. lr 5.357499e-04:  42%|████▏     | 6930/16329 [58:23<1:24:11,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 6930: train loss 1.74653. lr 5.357499e-04:  42%|████▏     | 6931/16329 [58:23<1:22:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6931: train loss 1.71031. lr 5.357321e-04:  42%|████▏     | 6931/16329 [58:24<1:22:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 6931: train loss 1.71031. lr 5.357321e-04:  42%|████▏     | 6932/16329 [58:24<1:20:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6932: train loss 1.66006. lr 5.357142e-04:  42%|████▏     | 6932/16329 [58:24<1:20:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6932: train loss 1.66006. lr 5.357142e-04:  42%|████▏     | 6933/16329 [58:24<1:19:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6933: train loss 1.68480. lr 5.356964e-04:  42%|████▏     | 6933/16329 [58:25<1:19:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 6933: train loss 1.68480. lr 5.356964e-04:  42%|████▏     | 6934/16329 [58:25<1:19:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6934: train loss 1.66462. lr 5.356785e-04:  42%|████▏     | 6934/16329 [58:25<1:19:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6934: train loss 1.66462. lr 5.356785e-04:  42%|████▏     | 6935/16329 [58:25<1:19:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6935: train loss 1.70387. lr 5.356607e-04:  42%|████▏     | 6935/16329 [58:26<1:19:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6935: train loss 1.70387. lr 5.356607e-04:  42%|████▏     | 6936/16329 [58:26<1:18:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6936: train loss 1.76935. lr 5.356428e-04:  42%|████▏     | 6936/16329 [58:26<1:18:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6936: train loss 1.76935. lr 5.356428e-04:  42%|████▏     | 6937/16329 [58:26<1:18:00,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6937: train loss 1.68077. lr 5.356249e-04:  42%|████▏     | 6937/16329 [58:27<1:18:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6937: train loss 1.68077. lr 5.356249e-04:  42%|████▏     | 6938/16329 [58:27<1:17:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6938: train loss 1.71789. lr 5.356071e-04:  42%|████▏     | 6938/16329 [58:27<1:17:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6938: train loss 1.71789. lr 5.356071e-04:  42%|████▏     | 6939/16329 [58:27<1:17:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6939: train loss 1.79735. lr 5.355892e-04:  42%|████▏     | 6939/16329 [58:28<1:17:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6939: train loss 1.79735. lr 5.355892e-04:  43%|████▎     | 6940/16329 [58:28<1:17:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6940: train loss 1.68115. lr 5.355713e-04:  43%|████▎     | 6940/16329 [58:28<1:17:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6940: train loss 1.68115. lr 5.355713e-04:  43%|████▎     | 6941/16329 [58:28<1:17:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6941: train loss 1.70683. lr 5.355535e-04:  43%|████▎     | 6941/16329 [58:29<1:17:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6941: train loss 1.70683. lr 5.355535e-04:  43%|████▎     | 6942/16329 [58:29<1:17:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6942: train loss 1.71520. lr 5.355356e-04:  43%|████▎     | 6942/16329 [58:29<1:17:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6942: train loss 1.71520. lr 5.355356e-04:  43%|████▎     | 6943/16329 [58:29<1:17:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6943: train loss 1.68414. lr 5.355177e-04:  43%|████▎     | 6943/16329 [58:30<1:17:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6943: train loss 1.68414. lr 5.355177e-04:  43%|████▎     | 6944/16329 [58:30<1:17:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6944: train loss 1.79564. lr 5.354998e-04:  43%|████▎     | 6944/16329 [58:30<1:17:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6944: train loss 1.79564. lr 5.354998e-04:  43%|████▎     | 6945/16329 [58:30<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6945: train loss 1.74781. lr 5.354820e-04:  43%|████▎     | 6945/16329 [58:31<1:17:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6945: train loss 1.74781. lr 5.354820e-04:  43%|████▎     | 6946/16329 [58:31<1:17:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6946: train loss 1.75251. lr 5.354641e-04:  43%|████▎     | 6946/16329 [58:31<1:17:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6946: train loss 1.75251. lr 5.354641e-04:  43%|████▎     | 6947/16329 [58:31<1:17:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6947: train loss 1.71397. lr 5.354462e-04:  43%|████▎     | 6947/16329 [58:32<1:17:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6947: train loss 1.71397. lr 5.354462e-04:  43%|████▎     | 6948/16329 [58:32<1:17:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6948: train loss 1.73753. lr 5.354283e-04:  43%|████▎     | 6948/16329 [58:32<1:17:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6948: train loss 1.73753. lr 5.354283e-04:  43%|████▎     | 6949/16329 [58:32<1:17:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6949: train loss 1.72211. lr 5.354104e-04:  43%|████▎     | 6949/16329 [58:33<1:17:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6949: train loss 1.72211. lr 5.354104e-04:  43%|████▎     | 6950/16329 [58:33<1:17:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6950: train loss 1.67236. lr 5.353925e-04:  43%|████▎     | 6950/16329 [58:33<1:17:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6950: train loss 1.67236. lr 5.353925e-04:  43%|████▎     | 6951/16329 [58:33<1:17:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6951: train loss 1.72230. lr 5.353746e-04:  43%|████▎     | 6951/16329 [58:34<1:17:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6951: train loss 1.72230. lr 5.353746e-04:  43%|████▎     | 6952/16329 [58:34<1:17:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6952: train loss 1.74291. lr 5.353567e-04:  43%|████▎     | 6952/16329 [58:34<1:17:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6952: train loss 1.74291. lr 5.353567e-04:  43%|████▎     | 6953/16329 [58:34<1:26:30,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6953: train loss 1.75882. lr 5.353388e-04:  43%|████▎     | 6953/16329 [58:35<1:26:30,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 6953: train loss 1.75882. lr 5.353388e-04:  43%|████▎     | 6954/16329 [58:35<1:23:26,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6954: train loss 1.77719. lr 5.353209e-04:  43%|████▎     | 6954/16329 [58:35<1:23:26,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 6954: train loss 1.77719. lr 5.353209e-04:  43%|████▎     | 6955/16329 [58:35<1:21:44,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6955: train loss 1.72440. lr 5.353030e-04:  43%|████▎     | 6955/16329 [58:36<1:21:44,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 6955: train loss 1.72440. lr 5.353030e-04:  43%|████▎     | 6956/16329 [58:36<1:20:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6956: train loss 1.69941. lr 5.352851e-04:  43%|████▎     | 6956/16329 [58:36<1:20:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6956: train loss 1.69941. lr 5.352851e-04:  43%|████▎     | 6957/16329 [58:36<1:19:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6957: train loss 1.71104. lr 5.352672e-04:  43%|████▎     | 6957/16329 [58:37<1:19:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6957: train loss 1.71104. lr 5.352672e-04:  43%|████▎     | 6958/16329 [58:37<1:18:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6958: train loss 1.71802. lr 5.352493e-04:  43%|████▎     | 6958/16329 [58:37<1:18:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6958: train loss 1.71802. lr 5.352493e-04:  43%|████▎     | 6959/16329 [58:37<1:18:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6959: train loss 1.68467. lr 5.352314e-04:  43%|████▎     | 6959/16329 [58:38<1:18:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6959: train loss 1.68467. lr 5.352314e-04:  43%|████▎     | 6960/16329 [58:38<1:18:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6960: train loss 1.71460. lr 5.352135e-04:  43%|████▎     | 6960/16329 [58:38<1:18:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6960: train loss 1.71460. lr 5.352135e-04:  43%|████▎     | 6961/16329 [58:38<1:17:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6961: train loss 1.71731. lr 5.351956e-04:  43%|████▎     | 6961/16329 [58:39<1:17:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6961: train loss 1.71731. lr 5.351956e-04:  43%|████▎     | 6962/16329 [58:39<1:17:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6962: train loss 1.71799. lr 5.351777e-04:  43%|████▎     | 6962/16329 [58:39<1:17:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6962: train loss 1.71799. lr 5.351777e-04:  43%|████▎     | 6963/16329 [58:39<1:17:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6963: train loss 1.71273. lr 5.351597e-04:  43%|████▎     | 6963/16329 [58:40<1:17:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6963: train loss 1.71273. lr 5.351597e-04:  43%|████▎     | 6964/16329 [58:40<1:17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6964: train loss 1.76348. lr 5.351418e-04:  43%|████▎     | 6964/16329 [58:40<1:17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6964: train loss 1.76348. lr 5.351418e-04:  43%|████▎     | 6965/16329 [58:40<1:17:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6965: train loss 1.70188. lr 5.351239e-04:  43%|████▎     | 6965/16329 [58:41<1:17:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6965: train loss 1.70188. lr 5.351239e-04:  43%|████▎     | 6966/16329 [58:41<1:17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6966: train loss 1.72766. lr 5.351060e-04:  43%|████▎     | 6966/16329 [58:41<1:17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6966: train loss 1.72766. lr 5.351060e-04:  43%|████▎     | 6967/16329 [58:41<1:17:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6967: train loss 1.73659. lr 5.350880e-04:  43%|████▎     | 6967/16329 [58:42<1:17:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6967: train loss 1.73659. lr 5.350880e-04:  43%|████▎     | 6968/16329 [58:42<1:17:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6968: train loss 1.62389. lr 5.350701e-04:  43%|████▎     | 6968/16329 [58:42<1:17:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6968: train loss 1.62389. lr 5.350701e-04:  43%|████▎     | 6969/16329 [58:42<1:17:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6969: train loss 1.77252. lr 5.350522e-04:  43%|████▎     | 6969/16329 [58:43<1:17:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6969: train loss 1.77252. lr 5.350522e-04:  43%|████▎     | 6970/16329 [58:43<1:17:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6970: train loss 1.73049. lr 5.350342e-04:  43%|████▎     | 6970/16329 [58:43<1:17:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6970: train loss 1.73049. lr 5.350342e-04:  43%|████▎     | 6971/16329 [58:43<1:16:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6971: train loss 1.71688. lr 5.350163e-04:  43%|████▎     | 6971/16329 [58:44<1:16:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6971: train loss 1.71688. lr 5.350163e-04:  43%|████▎     | 6972/16329 [58:44<1:17:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6972: train loss 1.72949. lr 5.349984e-04:  43%|████▎     | 6972/16329 [58:44<1:17:06,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 6972: train loss 1.72949. lr 5.349984e-04:  43%|████▎     | 6973/16329 [58:44<1:16:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6973: train loss 1.69796. lr 5.349804e-04:  43%|████▎     | 6973/16329 [58:45<1:16:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6973: train loss 1.69796. lr 5.349804e-04:  43%|████▎     | 6974/16329 [58:45<1:17:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6974: train loss 1.71992. lr 5.349625e-04:  43%|████▎     | 6974/16329 [58:45<1:17:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6974: train loss 1.71992. lr 5.349625e-04:  43%|████▎     | 6975/16329 [58:45<1:16:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6975: train loss 1.69895. lr 5.349445e-04:  43%|████▎     | 6975/16329 [58:46<1:16:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6975: train loss 1.69895. lr 5.349445e-04:  43%|████▎     | 6976/16329 [58:46<1:16:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6976: train loss 1.67295. lr 5.349266e-04:  43%|████▎     | 6976/16329 [58:46<1:16:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 6976: train loss 1.67295. lr 5.349266e-04:  43%|████▎     | 6977/16329 [58:46<1:17:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6977: train loss 1.66165. lr 5.349086e-04:  43%|████▎     | 6977/16329 [58:47<1:17:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6977: train loss 1.66165. lr 5.349086e-04:  43%|████▎     | 6978/16329 [58:47<1:16:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6978: train loss 1.72090. lr 5.348907e-04:  43%|████▎     | 6978/16329 [58:47<1:16:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6978: train loss 1.72090. lr 5.348907e-04:  43%|████▎     | 6979/16329 [58:47<1:17:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6979: train loss 1.72366. lr 5.348727e-04:  43%|████▎     | 6979/16329 [58:48<1:17:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6979: train loss 1.72366. lr 5.348727e-04:  43%|████▎     | 6980/16329 [58:48<1:25:42,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6980: train loss 1.73111. lr 5.348548e-04:  43%|████▎     | 6980/16329 [58:48<1:25:42,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 6980: train loss 1.73111. lr 5.348548e-04:  43%|████▎     | 6981/16329 [58:48<1:22:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6981: train loss 1.70470. lr 5.348368e-04:  43%|████▎     | 6981/16329 [58:49<1:22:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 6981: train loss 1.70470. lr 5.348368e-04:  43%|████▎     | 6982/16329 [58:49<1:21:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6982: train loss 1.73544. lr 5.348189e-04:  43%|████▎     | 6982/16329 [58:49<1:21:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 6982: train loss 1.73544. lr 5.348189e-04:  43%|████▎     | 6983/16329 [58:49<1:20:06,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6983: train loss 1.70524. lr 5.348009e-04:  43%|████▎     | 6983/16329 [58:50<1:20:06,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 6983: train loss 1.70524. lr 5.348009e-04:  43%|████▎     | 6984/16329 [58:50<1:19:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6984: train loss 1.71804. lr 5.347829e-04:  43%|████▎     | 6984/16329 [58:50<1:19:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6984: train loss 1.71804. lr 5.347829e-04:  43%|████▎     | 6985/16329 [58:50<1:18:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6985: train loss 1.73129. lr 5.347650e-04:  43%|████▎     | 6985/16329 [58:51<1:18:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6985: train loss 1.73129. lr 5.347650e-04:  43%|████▎     | 6986/16329 [58:51<1:17:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6986: train loss 1.66615. lr 5.347470e-04:  43%|████▎     | 6986/16329 [58:51<1:17:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6986: train loss 1.66615. lr 5.347470e-04:  43%|████▎     | 6987/16329 [58:51<1:17:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6987: train loss 1.75018. lr 5.347290e-04:  43%|████▎     | 6987/16329 [58:52<1:17:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6987: train loss 1.75018. lr 5.347290e-04:  43%|████▎     | 6988/16329 [58:52<1:18:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6988: train loss 1.72545. lr 5.347111e-04:  43%|████▎     | 6988/16329 [58:52<1:18:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6988: train loss 1.72545. lr 5.347111e-04:  43%|████▎     | 6989/16329 [58:52<1:19:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6989: train loss 1.69216. lr 5.346931e-04:  43%|████▎     | 6989/16329 [58:53<1:19:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6989: train loss 1.69216. lr 5.346931e-04:  43%|████▎     | 6990/16329 [58:53<1:19:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6990: train loss 1.74311. lr 5.346751e-04:  43%|████▎     | 6990/16329 [58:53<1:19:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6990: train loss 1.74311. lr 5.346751e-04:  43%|████▎     | 6991/16329 [58:53<1:18:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6991: train loss 1.74966. lr 5.346571e-04:  43%|████▎     | 6991/16329 [58:54<1:18:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 6991: train loss 1.74966. lr 5.346571e-04:  43%|████▎     | 6992/16329 [58:54<1:18:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6992: train loss 1.72852. lr 5.346391e-04:  43%|████▎     | 6992/16329 [58:54<1:18:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 6992: train loss 1.72852. lr 5.346391e-04:  43%|████▎     | 6993/16329 [58:54<1:18:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6993: train loss 1.72155. lr 5.346212e-04:  43%|████▎     | 6993/16329 [58:55<1:18:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 6993: train loss 1.72155. lr 5.346212e-04:  43%|████▎     | 6994/16329 [58:55<1:17:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6994: train loss 1.72274. lr 5.346032e-04:  43%|████▎     | 6994/16329 [58:55<1:17:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 6994: train loss 1.72274. lr 5.346032e-04:  43%|████▎     | 6995/16329 [58:55<1:17:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6995: train loss 1.69856. lr 5.345852e-04:  43%|████▎     | 6995/16329 [58:56<1:17:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6995: train loss 1.69856. lr 5.345852e-04:  43%|████▎     | 6996/16329 [58:56<1:17:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6996: train loss 1.76335. lr 5.345672e-04:  43%|████▎     | 6996/16329 [58:56<1:17:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6996: train loss 1.76335. lr 5.345672e-04:  43%|████▎     | 6997/16329 [58:56<1:17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6997: train loss 1.66847. lr 5.345492e-04:  43%|████▎     | 6997/16329 [58:57<1:17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6997: train loss 1.66847. lr 5.345492e-04:  43%|████▎     | 6998/16329 [58:57<1:17:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6998: train loss 1.70318. lr 5.345312e-04:  43%|████▎     | 6998/16329 [58:57<1:17:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 6998: train loss 1.70318. lr 5.345312e-04:  43%|████▎     | 6999/16329 [58:57<1:17:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6999: train loss 1.70511. lr 5.345132e-04:  43%|████▎     | 6999/16329 [58:58<1:17:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 6999: train loss 1.70511. lr 5.345132e-04:  43%|████▎     | 7000/16329 [58:58<1:17:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7000: train loss 1.70783. lr 5.344952e-04:  43%|████▎     | 7000/16329 [58:58<1:17:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7000: train loss 1.70783. lr 5.344952e-04:  43%|████▎     | 7001/16329 [58:58<1:17:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7001: train loss 1.70973. lr 5.344772e-04:  43%|████▎     | 7001/16329 [58:59<1:17:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7001: train loss 1.70973. lr 5.344772e-04:  43%|████▎     | 7002/16329 [58:59<1:17:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7002: train loss 1.70803. lr 5.344592e-04:  43%|████▎     | 7002/16329 [58:59<1:17:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7002: train loss 1.70803. lr 5.344592e-04:  43%|████▎     | 7003/16329 [58:59<1:17:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7003: train loss 1.70778. lr 5.344412e-04:  43%|████▎     | 7003/16329 [59:00<1:17:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7003: train loss 1.70778. lr 5.344412e-04:  43%|████▎     | 7004/16329 [59:00<1:17:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7004: train loss 1.67853. lr 5.344232e-04:  43%|████▎     | 7004/16329 [59:00<1:17:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7004: train loss 1.67853. lr 5.344232e-04:  43%|████▎     | 7005/16329 [59:00<1:17:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7005: train loss 1.75685. lr 5.344052e-04:  43%|████▎     | 7005/16329 [59:01<1:17:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7005: train loss 1.75685. lr 5.344052e-04:  43%|████▎     | 7006/16329 [59:01<1:17:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7006: train loss 1.75198. lr 5.343872e-04:  43%|████▎     | 7006/16329 [59:01<1:17:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7006: train loss 1.75198. lr 5.343872e-04:  43%|████▎     | 7007/16329 [59:01<1:17:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7007: train loss 1.68078. lr 5.343691e-04:  43%|████▎     | 7007/16329 [59:02<1:17:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7007: train loss 1.68078. lr 5.343691e-04:  43%|████▎     | 7008/16329 [59:02<1:17:08,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7008: train loss 1.69304. lr 5.343511e-04:  43%|████▎     | 7008/16329 [59:02<1:17:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7008: train loss 1.69304. lr 5.343511e-04:  43%|████▎     | 7009/16329 [59:02<1:16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7009: train loss 1.72716. lr 5.343331e-04:  43%|████▎     | 7009/16329 [59:03<1:16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7009: train loss 1.72716. lr 5.343331e-04:  43%|████▎     | 7010/16329 [59:03<1:17:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7010: train loss 1.70864. lr 5.343151e-04:  43%|████▎     | 7010/16329 [59:03<1:17:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7010: train loss 1.70864. lr 5.343151e-04:  43%|████▎     | 7011/16329 [59:03<1:16:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7011: train loss 1.69911. lr 5.342971e-04:  43%|████▎     | 7011/16329 [59:04<1:16:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7011: train loss 1.69911. lr 5.342971e-04:  43%|████▎     | 7012/16329 [59:04<1:16:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7012: train loss 1.67341. lr 5.342790e-04:  43%|████▎     | 7012/16329 [59:04<1:16:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7012: train loss 1.67341. lr 5.342790e-04:  43%|████▎     | 7013/16329 [59:04<1:16:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7013: train loss 1.71857. lr 5.342610e-04:  43%|████▎     | 7013/16329 [59:05<1:16:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7013: train loss 1.71857. lr 5.342610e-04:  43%|████▎     | 7014/16329 [59:05<1:16:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7014: train loss 1.72948. lr 5.342430e-04:  43%|████▎     | 7014/16329 [59:05<1:16:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7014: train loss 1.72948. lr 5.342430e-04:  43%|████▎     | 7015/16329 [59:05<1:17:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7015: train loss 1.69651. lr 5.342249e-04:  43%|████▎     | 7015/16329 [59:06<1:17:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7015: train loss 1.69651. lr 5.342249e-04:  43%|████▎     | 7016/16329 [59:06<1:17:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7016: train loss 1.73467. lr 5.342069e-04:  43%|████▎     | 7016/16329 [59:06<1:17:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7016: train loss 1.73467. lr 5.342069e-04:  43%|████▎     | 7017/16329 [59:06<1:17:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7017: train loss 1.71532. lr 5.341889e-04:  43%|████▎     | 7017/16329 [59:07<1:17:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7017: train loss 1.71532. lr 5.341889e-04:  43%|████▎     | 7018/16329 [59:07<1:17:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7018: train loss 1.70481. lr 5.341708e-04:  43%|████▎     | 7018/16329 [59:07<1:17:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7018: train loss 1.70481. lr 5.341708e-04:  43%|████▎     | 7019/16329 [59:07<1:17:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7019: train loss 1.69003. lr 5.341528e-04:  43%|████▎     | 7019/16329 [59:08<1:17:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7019: train loss 1.69003. lr 5.341528e-04:  43%|████▎     | 7020/16329 [59:08<1:25:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7020: train loss 1.68215. lr 5.341348e-04:  43%|████▎     | 7020/16329 [59:08<1:25:25,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7020: train loss 1.68215. lr 5.341348e-04:  43%|████▎     | 7021/16329 [59:08<1:22:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7021: train loss 1.69179. lr 5.341167e-04:  43%|████▎     | 7021/16329 [59:09<1:22:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7021: train loss 1.69179. lr 5.341167e-04:  43%|████▎     | 7022/16329 [59:09<1:20:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7022: train loss 1.72130. lr 5.340987e-04:  43%|████▎     | 7022/16329 [59:09<1:20:56,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7022: train loss 1.72130. lr 5.340987e-04:  43%|████▎     | 7023/16329 [59:09<1:19:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7023: train loss 1.73320. lr 5.340806e-04:  43%|████▎     | 7023/16329 [59:10<1:19:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7023: train loss 1.73320. lr 5.340806e-04:  43%|████▎     | 7024/16329 [59:10<1:18:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7024: train loss 1.69250. lr 5.340626e-04:  43%|████▎     | 7024/16329 [59:10<1:18:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7024: train loss 1.69250. lr 5.340626e-04:  43%|████▎     | 7025/16329 [59:10<1:18:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7025: train loss 1.75327. lr 5.340445e-04:  43%|████▎     | 7025/16329 [59:11<1:18:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7025: train loss 1.75327. lr 5.340445e-04:  43%|████▎     | 7026/16329 [59:11<1:17:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7026: train loss 1.67899. lr 5.340265e-04:  43%|████▎     | 7026/16329 [59:11<1:17:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7026: train loss 1.67899. lr 5.340265e-04:  43%|████▎     | 7027/16329 [59:11<1:17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7027: train loss 1.72453. lr 5.340084e-04:  43%|████▎     | 7027/16329 [59:12<1:17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7027: train loss 1.72453. lr 5.340084e-04:  43%|████▎     | 7028/16329 [59:12<1:16:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7028: train loss 1.64258. lr 5.339903e-04:  43%|████▎     | 7028/16329 [59:12<1:16:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7028: train loss 1.64258. lr 5.339903e-04:  43%|████▎     | 7029/16329 [59:12<1:17:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7029: train loss 1.71161. lr 5.339723e-04:  43%|████▎     | 7029/16329 [59:13<1:17:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7029: train loss 1.71161. lr 5.339723e-04:  43%|████▎     | 7030/16329 [59:13<1:17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7030: train loss 1.65927. lr 5.339542e-04:  43%|████▎     | 7030/16329 [59:13<1:17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7030: train loss 1.65927. lr 5.339542e-04:  43%|████▎     | 7031/16329 [59:13<1:17:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7031: train loss 1.72248. lr 5.339361e-04:  43%|████▎     | 7031/16329 [59:14<1:17:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7031: train loss 1.72248. lr 5.339361e-04:  43%|████▎     | 7032/16329 [59:14<1:17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7032: train loss 1.70265. lr 5.339181e-04:  43%|████▎     | 7032/16329 [59:14<1:17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7032: train loss 1.70265. lr 5.339181e-04:  43%|████▎     | 7033/16329 [59:14<1:17:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7033: train loss 1.69072. lr 5.339000e-04:  43%|████▎     | 7033/16329 [59:15<1:17:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7033: train loss 1.69072. lr 5.339000e-04:  43%|████▎     | 7034/16329 [59:15<1:16:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7034: train loss 1.72415. lr 5.338819e-04:  43%|████▎     | 7034/16329 [59:15<1:16:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7034: train loss 1.72415. lr 5.338819e-04:  43%|████▎     | 7035/16329 [59:15<1:16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7035: train loss 1.73336. lr 5.338639e-04:  43%|████▎     | 7035/16329 [59:16<1:16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7035: train loss 1.73336. lr 5.338639e-04:  43%|████▎     | 7036/16329 [59:16<1:16:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7036: train loss 1.69730. lr 5.338458e-04:  43%|████▎     | 7036/16329 [59:16<1:16:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7036: train loss 1.69730. lr 5.338458e-04:  43%|████▎     | 7037/16329 [59:16<1:17:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7037: train loss 1.74910. lr 5.338277e-04:  43%|████▎     | 7037/16329 [59:17<1:17:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7037: train loss 1.74910. lr 5.338277e-04:  43%|████▎     | 7038/16329 [59:17<1:17:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7038: train loss 1.68221. lr 5.338096e-04:  43%|████▎     | 7038/16329 [59:17<1:17:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7038: train loss 1.68221. lr 5.338096e-04:  43%|████▎     | 7039/16329 [59:17<1:17:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7039: train loss 1.75612. lr 5.337915e-04:  43%|████▎     | 7039/16329 [59:18<1:17:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7039: train loss 1.75612. lr 5.337915e-04:  43%|████▎     | 7040/16329 [59:18<1:17:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7040: train loss 1.68231. lr 5.337734e-04:  43%|████▎     | 7040/16329 [59:18<1:17:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7040: train loss 1.68231. lr 5.337734e-04:  43%|████▎     | 7041/16329 [59:18<1:17:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7041: train loss 1.73599. lr 5.337554e-04:  43%|████▎     | 7041/16329 [59:19<1:17:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7041: train loss 1.73599. lr 5.337554e-04:  43%|████▎     | 7042/16329 [59:19<1:17:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7042: train loss 1.75263. lr 5.337373e-04:  43%|████▎     | 7042/16329 [59:19<1:17:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7042: train loss 1.75263. lr 5.337373e-04:  43%|████▎     | 7043/16329 [59:19<1:17:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7043: train loss 1.65994. lr 5.337192e-04:  43%|████▎     | 7043/16329 [59:20<1:17:18,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7043: train loss 1.65994. lr 5.337192e-04:  43%|████▎     | 7044/16329 [59:20<1:17:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7044: train loss 1.71178. lr 5.337011e-04:  43%|████▎     | 7044/16329 [59:20<1:17:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7044: train loss 1.71178. lr 5.337011e-04:  43%|████▎     | 7045/16329 [59:20<1:17:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7045: train loss 1.72803. lr 5.336830e-04:  43%|████▎     | 7045/16329 [59:21<1:17:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7045: train loss 1.72803. lr 5.336830e-04:  43%|████▎     | 7046/16329 [59:21<1:16:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7046: train loss 1.68316. lr 5.336649e-04:  43%|████▎     | 7046/16329 [59:21<1:16:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7046: train loss 1.68316. lr 5.336649e-04:  43%|████▎     | 7047/16329 [59:21<1:16:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7047: train loss 1.76275. lr 5.336468e-04:  43%|████▎     | 7047/16329 [59:22<1:16:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7047: train loss 1.76275. lr 5.336468e-04:  43%|████▎     | 7048/16329 [59:22<1:16:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7048: train loss 1.73322. lr 5.336287e-04:  43%|████▎     | 7048/16329 [59:22<1:16:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7048: train loss 1.73322. lr 5.336287e-04:  43%|████▎     | 7049/16329 [59:22<1:17:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7049: train loss 1.69941. lr 5.336106e-04:  43%|████▎     | 7049/16329 [59:23<1:17:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7049: train loss 1.69941. lr 5.336106e-04:  43%|████▎     | 7050/16329 [59:23<1:17:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7050: train loss 1.67021. lr 5.335925e-04:  43%|████▎     | 7050/16329 [59:23<1:17:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7050: train loss 1.67021. lr 5.335925e-04:  43%|████▎     | 7051/16329 [59:23<1:16:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7051: train loss 1.70257. lr 5.335743e-04:  43%|████▎     | 7051/16329 [59:24<1:16:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7051: train loss 1.70257. lr 5.335743e-04:  43%|████▎     | 7052/16329 [59:24<1:16:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7052: train loss 1.72051. lr 5.335562e-04:  43%|████▎     | 7052/16329 [59:24<1:16:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7052: train loss 1.72051. lr 5.335562e-04:  43%|████▎     | 7053/16329 [59:24<1:16:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7053: train loss 1.67846. lr 5.335381e-04:  43%|████▎     | 7053/16329 [59:25<1:16:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7053: train loss 1.67846. lr 5.335381e-04:  43%|████▎     | 7054/16329 [59:25<1:16:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7054: train loss 1.75002. lr 5.335200e-04:  43%|████▎     | 7054/16329 [59:26<1:16:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7054: train loss 1.75002. lr 5.335200e-04:  43%|████▎     | 7055/16329 [59:26<1:25:02,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7055: train loss 1.73970. lr 5.335019e-04:  43%|████▎     | 7055/16329 [59:26<1:25:02,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7055: train loss 1.73970. lr 5.335019e-04:  43%|████▎     | 7056/16329 [59:26<1:22:08,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7056: train loss 1.71387. lr 5.334838e-04:  43%|████▎     | 7056/16329 [59:27<1:22:08,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7056: train loss 1.71387. lr 5.334838e-04:  43%|████▎     | 7057/16329 [59:27<1:20:38,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7057: train loss 1.68842. lr 5.334656e-04:  43%|████▎     | 7057/16329 [59:27<1:20:38,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7057: train loss 1.68842. lr 5.334656e-04:  43%|████▎     | 7058/16329 [59:27<1:19:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7058: train loss 1.72531. lr 5.334475e-04:  43%|████▎     | 7058/16329 [59:27<1:19:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7058: train loss 1.72531. lr 5.334475e-04:  43%|████▎     | 7059/16329 [59:28<1:18:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7059: train loss 1.69415. lr 5.334294e-04:  43%|████▎     | 7059/16329 [59:28<1:18:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7059: train loss 1.69415. lr 5.334294e-04:  43%|████▎     | 7060/16329 [59:28<1:17:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7060: train loss 1.72134. lr 5.334113e-04:  43%|████▎     | 7060/16329 [59:28<1:17:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7060: train loss 1.72134. lr 5.334113e-04:  43%|████▎     | 7061/16329 [59:28<1:17:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7061: train loss 1.75151. lr 5.333931e-04:  43%|████▎     | 7061/16329 [59:29<1:17:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7061: train loss 1.75151. lr 5.333931e-04:  43%|████▎     | 7062/16329 [59:29<1:17:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7062: train loss 1.67599. lr 5.333750e-04:  43%|████▎     | 7062/16329 [59:29<1:17:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7062: train loss 1.67599. lr 5.333750e-04:  43%|████▎     | 7063/16329 [59:29<1:16:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7063: train loss 1.72390. lr 5.333569e-04:  43%|████▎     | 7063/16329 [59:30<1:16:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7063: train loss 1.72390. lr 5.333569e-04:  43%|████▎     | 7064/16329 [59:30<1:16:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7064: train loss 1.68883. lr 5.333387e-04:  43%|████▎     | 7064/16329 [59:30<1:16:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7064: train loss 1.68883. lr 5.333387e-04:  43%|████▎     | 7065/16329 [59:30<1:16:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7065: train loss 1.68250. lr 5.333206e-04:  43%|████▎     | 7065/16329 [59:31<1:16:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7065: train loss 1.68250. lr 5.333206e-04:  43%|████▎     | 7066/16329 [59:31<1:16:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7066: train loss 1.69964. lr 5.333024e-04:  43%|████▎     | 7066/16329 [59:31<1:16:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7066: train loss 1.69964. lr 5.333024e-04:  43%|████▎     | 7067/16329 [59:31<1:16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7067: train loss 1.72045. lr 5.332843e-04:  43%|████▎     | 7067/16329 [59:32<1:16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7067: train loss 1.72045. lr 5.332843e-04:  43%|████▎     | 7068/16329 [59:32<1:16:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7068: train loss 1.73285. lr 5.332661e-04:  43%|████▎     | 7068/16329 [59:32<1:16:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7068: train loss 1.73285. lr 5.332661e-04:  43%|████▎     | 7069/16329 [59:32<1:16:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7069: train loss 1.72293. lr 5.332480e-04:  43%|████▎     | 7069/16329 [59:33<1:16:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7069: train loss 1.72293. lr 5.332480e-04:  43%|████▎     | 7070/16329 [59:33<1:16:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7070: train loss 1.62855. lr 5.332298e-04:  43%|████▎     | 7070/16329 [59:33<1:16:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7070: train loss 1.62855. lr 5.332298e-04:  43%|████▎     | 7071/16329 [59:33<1:16:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7071: train loss 1.69555. lr 5.332117e-04:  43%|████▎     | 7071/16329 [59:34<1:16:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7071: train loss 1.69555. lr 5.332117e-04:  43%|████▎     | 7072/16329 [59:34<1:16:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7072: train loss 1.74383. lr 5.331935e-04:  43%|████▎     | 7072/16329 [59:34<1:16:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7072: train loss 1.74383. lr 5.331935e-04:  43%|████▎     | 7073/16329 [59:34<1:16:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7073: train loss 1.70861. lr 5.331754e-04:  43%|████▎     | 7073/16329 [59:35<1:16:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7073: train loss 1.70861. lr 5.331754e-04:  43%|████▎     | 7074/16329 [59:35<1:16:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7074: train loss 1.75753. lr 5.331572e-04:  43%|████▎     | 7074/16329 [59:35<1:16:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7074: train loss 1.75753. lr 5.331572e-04:  43%|████▎     | 7075/16329 [59:35<1:16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7075: train loss 1.71357. lr 5.331391e-04:  43%|████▎     | 7075/16329 [59:36<1:16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7075: train loss 1.71357. lr 5.331391e-04:  43%|████▎     | 7076/16329 [59:36<1:16:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7076: train loss 1.67444. lr 5.331209e-04:  43%|████▎     | 7076/16329 [59:36<1:16:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7076: train loss 1.67444. lr 5.331209e-04:  43%|████▎     | 7077/16329 [59:36<1:16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7077: train loss 1.72341. lr 5.331027e-04:  43%|████▎     | 7077/16329 [59:37<1:16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7077: train loss 1.72341. lr 5.331027e-04:  43%|████▎     | 7078/16329 [59:37<1:16:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7078: train loss 1.64256. lr 5.330846e-04:  43%|████▎     | 7078/16329 [59:37<1:16:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7078: train loss 1.64256. lr 5.330846e-04:  43%|████▎     | 7079/16329 [59:37<1:16:25,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7079: train loss 1.71242. lr 5.330664e-04:  43%|████▎     | 7079/16329 [59:38<1:16:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7079: train loss 1.71242. lr 5.330664e-04:  43%|████▎     | 7080/16329 [59:38<1:24:11,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7080: train loss 1.67931. lr 5.330482e-04:  43%|████▎     | 7080/16329 [59:39<1:24:11,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7080: train loss 1.67931. lr 5.330482e-04:  43%|████▎     | 7081/16329 [59:39<1:22:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7081: train loss 1.71049. lr 5.330300e-04:  43%|████▎     | 7081/16329 [59:39<1:22:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7081: train loss 1.71049. lr 5.330300e-04:  43%|████▎     | 7082/16329 [59:39<1:20:28,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7082: train loss 1.65538. lr 5.330119e-04:  43%|████▎     | 7082/16329 [59:40<1:20:28,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7082: train loss 1.65538. lr 5.330119e-04:  43%|████▎     | 7083/16329 [59:40<1:19:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7083: train loss 1.72424. lr 5.329937e-04:  43%|████▎     | 7083/16329 [59:40<1:19:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7083: train loss 1.72424. lr 5.329937e-04:  43%|████▎     | 7084/16329 [59:40<1:18:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7084: train loss 1.68804. lr 5.329755e-04:  43%|████▎     | 7084/16329 [59:41<1:18:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7084: train loss 1.68804. lr 5.329755e-04:  43%|████▎     | 7085/16329 [59:41<1:17:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7085: train loss 1.72872. lr 5.329573e-04:  43%|████▎     | 7085/16329 [59:41<1:17:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7085: train loss 1.72872. lr 5.329573e-04:  43%|████▎     | 7086/16329 [59:41<1:17:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7086: train loss 1.70325. lr 5.329391e-04:  43%|████▎     | 7086/16329 [59:42<1:17:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7086: train loss 1.70325. lr 5.329391e-04:  43%|████▎     | 7087/16329 [59:42<1:16:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7087: train loss 1.66511. lr 5.329210e-04:  43%|████▎     | 7087/16329 [59:42<1:16:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7087: train loss 1.66511. lr 5.329210e-04:  43%|████▎     | 7088/16329 [59:42<1:16:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7088: train loss 1.66409. lr 5.329028e-04:  43%|████▎     | 7088/16329 [59:43<1:16:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7088: train loss 1.66409. lr 5.329028e-04:  43%|████▎     | 7089/16329 [59:43<1:16:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7089: train loss 1.72148. lr 5.328846e-04:  43%|████▎     | 7089/16329 [59:43<1:16:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7089: train loss 1.72148. lr 5.328846e-04:  43%|████▎     | 7090/16329 [59:43<1:16:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7090: train loss 1.72004. lr 5.328664e-04:  43%|████▎     | 7090/16329 [59:44<1:16:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7090: train loss 1.72004. lr 5.328664e-04:  43%|████▎     | 7091/16329 [59:44<1:16:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7091: train loss 1.70431. lr 5.328482e-04:  43%|████▎     | 7091/16329 [59:44<1:16:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7091: train loss 1.70431. lr 5.328482e-04:  43%|████▎     | 7092/16329 [59:44<1:16:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7092: train loss 1.70144. lr 5.328300e-04:  43%|████▎     | 7092/16329 [59:45<1:16:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7092: train loss 1.70144. lr 5.328300e-04:  43%|████▎     | 7093/16329 [59:45<1:16:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7093: train loss 1.67019. lr 5.328118e-04:  43%|████▎     | 7093/16329 [59:45<1:16:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7093: train loss 1.67019. lr 5.328118e-04:  43%|████▎     | 7094/16329 [59:45<1:16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7094: train loss 1.72967. lr 5.327936e-04:  43%|████▎     | 7094/16329 [59:46<1:16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7094: train loss 1.72967. lr 5.327936e-04:  43%|████▎     | 7095/16329 [59:46<1:16:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7095: train loss 1.69845. lr 5.327754e-04:  43%|████▎     | 7095/16329 [59:46<1:16:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7095: train loss 1.69845. lr 5.327754e-04:  43%|████▎     | 7096/16329 [59:46<1:16:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7096: train loss 1.69891. lr 5.327572e-04:  43%|████▎     | 7096/16329 [59:47<1:16:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7096: train loss 1.69891. lr 5.327572e-04:  43%|████▎     | 7097/16329 [59:47<1:16:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7097: train loss 1.66158. lr 5.327390e-04:  43%|████▎     | 7097/16329 [59:47<1:16:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7097: train loss 1.66158. lr 5.327390e-04:  43%|████▎     | 7098/16329 [59:47<1:16:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7098: train loss 1.71183. lr 5.327207e-04:  43%|████▎     | 7098/16329 [59:48<1:16:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7098: train loss 1.71183. lr 5.327207e-04:  43%|████▎     | 7099/16329 [59:48<1:16:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7099: train loss 1.70727. lr 5.327025e-04:  43%|████▎     | 7099/16329 [59:48<1:16:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7099: train loss 1.70727. lr 5.327025e-04:  43%|████▎     | 7100/16329 [59:48<1:16:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7100: train loss 1.67027. lr 5.326843e-04:  43%|████▎     | 7100/16329 [59:49<1:16:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7100: train loss 1.67027. lr 5.326843e-04:  43%|████▎     | 7101/16329 [59:49<1:16:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7101: train loss 1.70070. lr 5.326661e-04:  43%|████▎     | 7101/16329 [59:49<1:16:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7101: train loss 1.70070. lr 5.326661e-04:  43%|████▎     | 7102/16329 [59:49<1:16:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7102: train loss 1.72126. lr 5.326479e-04:  43%|████▎     | 7102/16329 [59:49<1:16:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7102: train loss 1.72126. lr 5.326479e-04:  43%|████▎     | 7103/16329 [59:49<1:16:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7103: train loss 1.69751. lr 5.326297e-04:  43%|████▎     | 7103/16329 [59:50<1:16:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7103: train loss 1.69751. lr 5.326297e-04:  44%|████▎     | 7104/16329 [59:50<1:16:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7104: train loss 1.68872. lr 5.326114e-04:  44%|████▎     | 7104/16329 [59:50<1:16:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7104: train loss 1.68872. lr 5.326114e-04:  44%|████▎     | 7105/16329 [59:50<1:16:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7105: train loss 1.69953. lr 5.325932e-04:  44%|████▎     | 7105/16329 [59:51<1:16:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7105: train loss 1.69953. lr 5.325932e-04:  44%|████▎     | 7106/16329 [59:51<1:16:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7106: train loss 1.66771. lr 5.325750e-04:  44%|████▎     | 7106/16329 [59:52<1:16:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7106: train loss 1.66771. lr 5.325750e-04:  44%|████▎     | 7107/16329 [59:52<1:25:04,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7107: train loss 1.72022. lr 5.325567e-04:  44%|████▎     | 7107/16329 [59:52<1:25:04,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7107: train loss 1.72022. lr 5.325567e-04:  44%|████▎     | 7108/16329 [59:52<1:22:38,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7108: train loss 1.72599. lr 5.325385e-04:  44%|████▎     | 7108/16329 [59:53<1:22:38,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7108: train loss 1.72599. lr 5.325385e-04:  44%|████▎     | 7109/16329 [59:53<1:20:56,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7109: train loss 1.65261. lr 5.325203e-04:  44%|████▎     | 7109/16329 [59:53<1:20:56,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7109: train loss 1.65261. lr 5.325203e-04:  44%|████▎     | 7110/16329 [59:53<1:19:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7110: train loss 1.64845. lr 5.325020e-04:  44%|████▎     | 7110/16329 [59:54<1:19:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7110: train loss 1.64845. lr 5.325020e-04:  44%|████▎     | 7111/16329 [59:54<1:18:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7111: train loss 1.73672. lr 5.324838e-04:  44%|████▎     | 7111/16329 [59:54<1:18:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7111: train loss 1.73672. lr 5.324838e-04:  44%|████▎     | 7112/16329 [59:54<1:17:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7112: train loss 1.68781. lr 5.324656e-04:  44%|████▎     | 7112/16329 [59:55<1:17:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7112: train loss 1.68781. lr 5.324656e-04:  44%|████▎     | 7113/16329 [59:55<1:17:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7113: train loss 1.71778. lr 5.324473e-04:  44%|████▎     | 7113/16329 [59:55<1:17:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7113: train loss 1.71778. lr 5.324473e-04:  44%|████▎     | 7114/16329 [59:55<1:16:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7114: train loss 1.68441. lr 5.324291e-04:  44%|████▎     | 7114/16329 [59:56<1:16:48,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7114: train loss 1.68441. lr 5.324291e-04:  44%|████▎     | 7115/16329 [59:56<1:16:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7115: train loss 1.73186. lr 5.324108e-04:  44%|████▎     | 7115/16329 [59:56<1:16:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7115: train loss 1.73186. lr 5.324108e-04:  44%|████▎     | 7116/16329 [59:56<1:16:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7116: train loss 1.66507. lr 5.323926e-04:  44%|████▎     | 7116/16329 [59:57<1:16:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7116: train loss 1.66507. lr 5.323926e-04:  44%|████▎     | 7117/16329 [59:57<1:16:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7117: train loss 1.69734. lr 5.323743e-04:  44%|████▎     | 7117/16329 [59:57<1:16:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7117: train loss 1.69734. lr 5.323743e-04:  44%|████▎     | 7118/16329 [59:57<1:16:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7118: train loss 1.70757. lr 5.323561e-04:  44%|████▎     | 7118/16329 [59:58<1:16:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7118: train loss 1.70757. lr 5.323561e-04:  44%|████▎     | 7119/16329 [59:58<1:16:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7119: train loss 1.68889. lr 5.323378e-04:  44%|████▎     | 7119/16329 [59:58<1:16:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7119: train loss 1.68889. lr 5.323378e-04:  44%|████▎     | 7120/16329 [59:58<1:16:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7120: train loss 1.68207. lr 5.323195e-04:  44%|████▎     | 7120/16329 [59:59<1:16:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7120: train loss 1.68207. lr 5.323195e-04:  44%|████▎     | 7121/16329 [59:59<1:15:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7121: train loss 1.74060. lr 5.323013e-04:  44%|████▎     | 7121/16329 [59:59<1:15:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7121: train loss 1.74060. lr 5.323013e-04:  44%|████▎     | 7122/16329 [59:59<1:19:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7122: train loss 1.70015. lr 5.322830e-04:  44%|████▎     | 7122/16329 [1:00:00<1:19:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7122: train loss 1.70015. lr 5.322830e-04:  44%|████▎     | 7123/16329 [1:00:00<1:21:18,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7123: train loss 1.73589. lr 5.322648e-04:  44%|████▎     | 7123/16329 [1:00:00<1:21:18,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7123: train loss 1.73589. lr 5.322648e-04:  44%|████▎     | 7124/16329 [1:00:00<1:22:08,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7124: train loss 1.69447. lr 5.322465e-04:  44%|████▎     | 7124/16329 [1:00:01<1:22:08,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7124: train loss 1.69447. lr 5.322465e-04:  44%|████▎     | 7125/16329 [1:00:01<1:21:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7125: train loss 1.75231. lr 5.322282e-04:  44%|████▎     | 7125/16329 [1:00:01<1:21:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7125: train loss 1.75231. lr 5.322282e-04:  44%|████▎     | 7126/16329 [1:00:01<1:21:12,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7126: train loss 1.71615. lr 5.322099e-04:  44%|████▎     | 7126/16329 [1:00:02<1:21:12,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7126: train loss 1.71615. lr 5.322099e-04:  44%|████▎     | 7127/16329 [1:00:02<1:19:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7127: train loss 1.68059. lr 5.321917e-04:  44%|████▎     | 7127/16329 [1:00:02<1:19:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7127: train loss 1.68059. lr 5.321917e-04:  44%|████▎     | 7128/16329 [1:00:02<1:18:36,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7128: train loss 1.70135. lr 5.321734e-04:  44%|████▎     | 7128/16329 [1:00:03<1:18:36,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7128: train loss 1.70135. lr 5.321734e-04:  44%|████▎     | 7129/16329 [1:00:03<1:17:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7129: train loss 1.70163. lr 5.321551e-04:  44%|████▎     | 7129/16329 [1:00:03<1:17:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7129: train loss 1.70163. lr 5.321551e-04:  44%|████▎     | 7130/16329 [1:00:03<1:16:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7130: train loss 1.66955. lr 5.321368e-04:  44%|████▎     | 7130/16329 [1:00:04<1:16:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7130: train loss 1.66955. lr 5.321368e-04:  44%|████▎     | 7131/16329 [1:00:04<1:16:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7131: train loss 1.70028. lr 5.321186e-04:  44%|████▎     | 7131/16329 [1:00:04<1:16:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7131: train loss 1.70028. lr 5.321186e-04:  44%|████▎     | 7132/16329 [1:00:04<1:16:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7132: train loss 1.74502. lr 5.321003e-04:  44%|████▎     | 7132/16329 [1:00:05<1:16:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7132: train loss 1.74502. lr 5.321003e-04:  44%|████▎     | 7133/16329 [1:00:05<1:16:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7133: train loss 1.69395. lr 5.320820e-04:  44%|████▎     | 7133/16329 [1:00:05<1:16:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7133: train loss 1.69395. lr 5.320820e-04:  44%|████▎     | 7134/16329 [1:00:05<1:16:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7134: train loss 1.69932. lr 5.320637e-04:  44%|████▎     | 7134/16329 [1:00:06<1:16:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7134: train loss 1.69932. lr 5.320637e-04:  44%|████▎     | 7135/16329 [1:00:06<1:15:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7135: train loss 1.66852. lr 5.320454e-04:  44%|████▎     | 7135/16329 [1:00:06<1:15:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7135: train loss 1.66852. lr 5.320454e-04:  44%|████▎     | 7136/16329 [1:00:06<1:15:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7136: train loss 1.68154. lr 5.320271e-04:  44%|████▎     | 7136/16329 [1:00:07<1:15:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7136: train loss 1.68154. lr 5.320271e-04:  44%|████▎     | 7137/16329 [1:00:07<1:15:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7137: train loss 1.63466. lr 5.320088e-04:  44%|████▎     | 7137/16329 [1:00:07<1:15:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7137: train loss 1.63466. lr 5.320088e-04:  44%|████▎     | 7138/16329 [1:00:07<1:15:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7138: train loss 1.64566. lr 5.319905e-04:  44%|████▎     | 7138/16329 [1:00:08<1:15:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7138: train loss 1.64566. lr 5.319905e-04:  44%|████▎     | 7139/16329 [1:00:08<1:15:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7139: train loss 1.71715. lr 5.319722e-04:  44%|████▎     | 7139/16329 [1:00:08<1:15:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7139: train loss 1.71715. lr 5.319722e-04:  44%|████▎     | 7140/16329 [1:00:08<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7140: train loss 1.70484. lr 5.319539e-04:  44%|████▎     | 7140/16329 [1:00:09<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7140: train loss 1.70484. lr 5.319539e-04:  44%|████▎     | 7141/16329 [1:00:09<1:15:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7141: train loss 1.69739. lr 5.319356e-04:  44%|████▎     | 7141/16329 [1:00:09<1:15:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7141: train loss 1.69739. lr 5.319356e-04:  44%|████▎     | 7142/16329 [1:00:09<1:15:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7142: train loss 1.71262. lr 5.319173e-04:  44%|████▎     | 7142/16329 [1:00:10<1:15:34,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7142: train loss 1.71262. lr 5.319173e-04:  44%|████▎     | 7143/16329 [1:00:10<1:15:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7143: train loss 1.64981. lr 5.318990e-04:  44%|████▎     | 7143/16329 [1:00:10<1:15:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7143: train loss 1.64981. lr 5.318990e-04:  44%|████▍     | 7144/16329 [1:00:10<1:15:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7144: train loss 1.67128. lr 5.318807e-04:  44%|████▍     | 7144/16329 [1:00:11<1:15:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7144: train loss 1.67128. lr 5.318807e-04:  44%|████▍     | 7145/16329 [1:00:11<1:16:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7145: train loss 1.65970. lr 5.318624e-04:  44%|████▍     | 7145/16329 [1:00:11<1:16:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7145: train loss 1.65970. lr 5.318624e-04:  44%|████▍     | 7146/16329 [1:00:11<1:15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7146: train loss 1.67141. lr 5.318441e-04:  44%|████▍     | 7146/16329 [1:00:12<1:15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7146: train loss 1.67141. lr 5.318441e-04:  44%|████▍     | 7147/16329 [1:00:12<1:23:31,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7147: train loss 1.72123. lr 5.318257e-04:  44%|████▍     | 7147/16329 [1:00:12<1:23:31,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7147: train loss 1.72123. lr 5.318257e-04:  44%|████▍     | 7148/16329 [1:00:12<1:21:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7148: train loss 1.72303. lr 5.318074e-04:  44%|████▍     | 7148/16329 [1:00:13<1:21:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7148: train loss 1.72303. lr 5.318074e-04:  44%|████▍     | 7149/16329 [1:00:13<1:19:37,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7149: train loss 1.68637. lr 5.317891e-04:  44%|████▍     | 7149/16329 [1:00:13<1:19:37,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7149: train loss 1.68637. lr 5.317891e-04:  44%|████▍     | 7150/16329 [1:00:13<1:18:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7150: train loss 1.65382. lr 5.317708e-04:  44%|████▍     | 7150/16329 [1:00:14<1:18:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7150: train loss 1.65382. lr 5.317708e-04:  44%|████▍     | 7151/16329 [1:00:14<1:17:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7151: train loss 1.71787. lr 5.317525e-04:  44%|████▍     | 7151/16329 [1:00:14<1:17:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7151: train loss 1.71787. lr 5.317525e-04:  44%|████▍     | 7152/16329 [1:00:14<1:16:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7152: train loss 1.72482. lr 5.317341e-04:  44%|████▍     | 7152/16329 [1:00:15<1:16:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7152: train loss 1.72482. lr 5.317341e-04:  44%|████▍     | 7153/16329 [1:00:15<1:16:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7153: train loss 1.73013. lr 5.317158e-04:  44%|████▍     | 7153/16329 [1:00:15<1:16:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7153: train loss 1.73013. lr 5.317158e-04:  44%|████▍     | 7154/16329 [1:00:15<1:16:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7154: train loss 1.70568. lr 5.316975e-04:  44%|████▍     | 7154/16329 [1:00:16<1:16:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7154: train loss 1.70568. lr 5.316975e-04:  44%|████▍     | 7155/16329 [1:00:16<1:16:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7155: train loss 1.65834. lr 5.316791e-04:  44%|████▍     | 7155/16329 [1:00:16<1:16:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7155: train loss 1.65834. lr 5.316791e-04:  44%|████▍     | 7156/16329 [1:00:16<1:16:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7156: train loss 1.70486. lr 5.316608e-04:  44%|████▍     | 7156/16329 [1:00:17<1:16:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7156: train loss 1.70486. lr 5.316608e-04:  44%|████▍     | 7157/16329 [1:00:17<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7157: train loss 1.71239. lr 5.316425e-04:  44%|████▍     | 7157/16329 [1:00:17<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7157: train loss 1.71239. lr 5.316425e-04:  44%|████▍     | 7158/16329 [1:00:17<1:15:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7158: train loss 1.66226. lr 5.316241e-04:  44%|████▍     | 7158/16329 [1:00:18<1:15:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7158: train loss 1.66226. lr 5.316241e-04:  44%|████▍     | 7159/16329 [1:00:18<1:15:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7159: train loss 1.74884. lr 5.316058e-04:  44%|████▍     | 7159/16329 [1:00:18<1:15:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7159: train loss 1.74884. lr 5.316058e-04:  44%|████▍     | 7160/16329 [1:00:18<1:15:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7160: train loss 1.70372. lr 5.315874e-04:  44%|████▍     | 7160/16329 [1:00:19<1:15:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7160: train loss 1.70372. lr 5.315874e-04:  44%|████▍     | 7161/16329 [1:00:19<1:15:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7161: train loss 1.67286. lr 5.315691e-04:  44%|████▍     | 7161/16329 [1:00:19<1:15:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7161: train loss 1.67286. lr 5.315691e-04:  44%|████▍     | 7162/16329 [1:00:19<1:15:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7162: train loss 1.72553. lr 5.315507e-04:  44%|████▍     | 7162/16329 [1:00:20<1:15:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7162: train loss 1.72553. lr 5.315507e-04:  44%|████▍     | 7163/16329 [1:00:20<1:15:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7163: train loss 1.65832. lr 5.315324e-04:  44%|████▍     | 7163/16329 [1:00:20<1:15:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7163: train loss 1.65832. lr 5.315324e-04:  44%|████▍     | 7164/16329 [1:00:20<1:15:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7164: train loss 1.62309. lr 5.315140e-04:  44%|████▍     | 7164/16329 [1:00:21<1:15:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7164: train loss 1.62309. lr 5.315140e-04:  44%|████▍     | 7165/16329 [1:00:21<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7165: train loss 1.65751. lr 5.314957e-04:  44%|████▍     | 7165/16329 [1:00:21<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7165: train loss 1.65751. lr 5.314957e-04:  44%|████▍     | 7166/16329 [1:00:21<1:15:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7166: train loss 1.66987. lr 5.314773e-04:  44%|████▍     | 7166/16329 [1:00:22<1:15:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7166: train loss 1.66987. lr 5.314773e-04:  44%|████▍     | 7167/16329 [1:00:22<1:15:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7167: train loss 1.70861. lr 5.314590e-04:  44%|████▍     | 7167/16329 [1:00:22<1:15:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7167: train loss 1.70861. lr 5.314590e-04:  44%|████▍     | 7168/16329 [1:00:22<1:15:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7168: train loss 1.74324. lr 5.314406e-04:  44%|████▍     | 7168/16329 [1:00:23<1:15:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7168: train loss 1.74324. lr 5.314406e-04:  44%|████▍     | 7169/16329 [1:00:23<1:15:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7169: train loss 1.70592. lr 5.314222e-04:  44%|████▍     | 7169/16329 [1:00:23<1:15:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7169: train loss 1.70592. lr 5.314222e-04:  44%|████▍     | 7170/16329 [1:00:23<1:15:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7170: train loss 1.68687. lr 5.314039e-04:  44%|████▍     | 7170/16329 [1:00:24<1:15:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7170: train loss 1.68687. lr 5.314039e-04:  44%|████▍     | 7171/16329 [1:00:24<1:15:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7171: train loss 1.65694. lr 5.313855e-04:  44%|████▍     | 7171/16329 [1:00:24<1:15:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7171: train loss 1.65694. lr 5.313855e-04:  44%|████▍     | 7172/16329 [1:00:24<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7172: train loss 1.72181. lr 5.313671e-04:  44%|████▍     | 7172/16329 [1:00:25<1:15:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7172: train loss 1.72181. lr 5.313671e-04:  44%|████▍     | 7173/16329 [1:00:25<1:15:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7173: train loss 1.70411. lr 5.313488e-04:  44%|████▍     | 7173/16329 [1:00:25<1:15:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7173: train loss 1.70411. lr 5.313488e-04:  44%|████▍     | 7174/16329 [1:00:25<1:15:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7174: train loss 1.65916. lr 5.313304e-04:  44%|████▍     | 7174/16329 [1:00:26<1:15:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7174: train loss 1.65916. lr 5.313304e-04:  44%|████▍     | 7175/16329 [1:00:26<1:15:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7175: train loss 1.65984. lr 5.313120e-04:  44%|████▍     | 7175/16329 [1:00:26<1:15:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7175: train loss 1.65984. lr 5.313120e-04:  44%|████▍     | 7176/16329 [1:00:26<1:15:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7176: train loss 1.70953. lr 5.312936e-04:  44%|████▍     | 7176/16329 [1:00:27<1:15:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7176: train loss 1.70953. lr 5.312936e-04:  44%|████▍     | 7177/16329 [1:00:27<1:15:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7177: train loss 1.69830. lr 5.312752e-04:  44%|████▍     | 7177/16329 [1:00:27<1:15:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7177: train loss 1.69830. lr 5.312752e-04:  44%|████▍     | 7178/16329 [1:00:27<1:16:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7178: train loss 1.72325. lr 5.312569e-04:  44%|████▍     | 7178/16329 [1:00:28<1:16:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7178: train loss 1.72325. lr 5.312569e-04:  44%|████▍     | 7179/16329 [1:00:28<1:16:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7179: train loss 1.67119. lr 5.312385e-04:  44%|████▍     | 7179/16329 [1:00:28<1:16:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7179: train loss 1.67119. lr 5.312385e-04:  44%|████▍     | 7180/16329 [1:00:28<1:17:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7180: train loss 1.70042. lr 5.312201e-04:  44%|████▍     | 7180/16329 [1:00:29<1:17:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7180: train loss 1.70042. lr 5.312201e-04:  44%|████▍     | 7181/16329 [1:00:29<1:18:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7181: train loss 1.70497. lr 5.312017e-04:  44%|████▍     | 7181/16329 [1:00:30<1:18:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7181: train loss 1.70497. lr 5.312017e-04:  44%|████▍     | 7182/16329 [1:00:30<1:26:17,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 7182: train loss 1.70540. lr 5.311833e-04:  44%|████▍     | 7182/16329 [1:00:30<1:26:17,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 7182: train loss 1.70540. lr 5.311833e-04:  44%|████▍     | 7183/16329 [1:00:30<1:23:35,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7183: train loss 1.69868. lr 5.311649e-04:  44%|████▍     | 7183/16329 [1:00:31<1:23:35,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7183: train loss 1.69868. lr 5.311649e-04:  44%|████▍     | 7184/16329 [1:00:31<1:21:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7184: train loss 1.69625. lr 5.311465e-04:  44%|████▍     | 7184/16329 [1:00:31<1:21:04,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7184: train loss 1.69625. lr 5.311465e-04:  44%|████▍     | 7185/16329 [1:00:31<1:19:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7185: train loss 1.65713. lr 5.311281e-04:  44%|████▍     | 7185/16329 [1:00:32<1:19:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7185: train loss 1.65713. lr 5.311281e-04:  44%|████▍     | 7186/16329 [1:00:32<1:18:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7186: train loss 1.71549. lr 5.311097e-04:  44%|████▍     | 7186/16329 [1:00:32<1:18:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7186: train loss 1.71549. lr 5.311097e-04:  44%|████▍     | 7187/16329 [1:00:32<1:17:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7187: train loss 1.69094. lr 5.310913e-04:  44%|████▍     | 7187/16329 [1:00:32<1:17:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7187: train loss 1.69094. lr 5.310913e-04:  44%|████▍     | 7188/16329 [1:00:32<1:17:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7188: train loss 1.68169. lr 5.310729e-04:  44%|████▍     | 7188/16329 [1:00:33<1:17:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7188: train loss 1.68169. lr 5.310729e-04:  44%|████▍     | 7189/16329 [1:00:33<1:16:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7189: train loss 1.69100. lr 5.310545e-04:  44%|████▍     | 7189/16329 [1:00:33<1:16:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7189: train loss 1.69100. lr 5.310545e-04:  44%|████▍     | 7190/16329 [1:00:33<1:16:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7190: train loss 1.65718. lr 5.310361e-04:  44%|████▍     | 7190/16329 [1:00:34<1:16:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7190: train loss 1.65718. lr 5.310361e-04:  44%|████▍     | 7191/16329 [1:00:34<1:16:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7191: train loss 1.66375. lr 5.310177e-04:  44%|████▍     | 7191/16329 [1:00:34<1:16:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7191: train loss 1.66375. lr 5.310177e-04:  44%|████▍     | 7192/16329 [1:00:34<1:16:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7192: train loss 1.70907. lr 5.309993e-04:  44%|████▍     | 7192/16329 [1:00:35<1:16:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7192: train loss 1.70907. lr 5.309993e-04:  44%|████▍     | 7193/16329 [1:00:35<1:15:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7193: train loss 1.72455. lr 5.309809e-04:  44%|████▍     | 7193/16329 [1:00:35<1:15:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7193: train loss 1.72455. lr 5.309809e-04:  44%|████▍     | 7194/16329 [1:00:35<1:15:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7194: train loss 1.68529. lr 5.309624e-04:  44%|████▍     | 7194/16329 [1:00:36<1:15:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7194: train loss 1.68529. lr 5.309624e-04:  44%|████▍     | 7195/16329 [1:00:36<1:15:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7195: train loss 1.68110. lr 5.309440e-04:  44%|████▍     | 7195/16329 [1:00:36<1:15:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7195: train loss 1.68110. lr 5.309440e-04:  44%|████▍     | 7196/16329 [1:00:36<1:15:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7196: train loss 1.69297. lr 5.309256e-04:  44%|████▍     | 7196/16329 [1:00:37<1:15:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7196: train loss 1.69297. lr 5.309256e-04:  44%|████▍     | 7197/16329 [1:00:37<1:15:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7197: train loss 1.64726. lr 5.309072e-04:  44%|████▍     | 7197/16329 [1:00:37<1:15:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7197: train loss 1.64726. lr 5.309072e-04:  44%|████▍     | 7198/16329 [1:00:37<1:15:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7198: train loss 1.74065. lr 5.308888e-04:  44%|████▍     | 7198/16329 [1:00:38<1:15:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7198: train loss 1.74065. lr 5.308888e-04:  44%|████▍     | 7199/16329 [1:00:38<1:15:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7199: train loss 1.69057. lr 5.308703e-04:  44%|████▍     | 7199/16329 [1:00:38<1:15:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7199: train loss 1.69057. lr 5.308703e-04:  44%|████▍     | 7200/16329 [1:00:38<1:15:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7200: train loss 1.69972. lr 5.308519e-04:  44%|████▍     | 7200/16329 [1:00:39<1:15:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7200: train loss 1.69972. lr 5.308519e-04:  44%|████▍     | 7201/16329 [1:00:39<1:14:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7201: train loss 1.71064. lr 5.308335e-04:  44%|████▍     | 7201/16329 [1:00:39<1:14:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7201: train loss 1.71064. lr 5.308335e-04:  44%|████▍     | 7202/16329 [1:00:39<1:15:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7202: train loss 1.73049. lr 5.308150e-04:  44%|████▍     | 7202/16329 [1:00:40<1:15:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7202: train loss 1.73049. lr 5.308150e-04:  44%|████▍     | 7203/16329 [1:00:40<1:15:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7203: train loss 1.66248. lr 5.307966e-04:  44%|████▍     | 7203/16329 [1:00:40<1:15:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7203: train loss 1.66248. lr 5.307966e-04:  44%|████▍     | 7204/16329 [1:00:40<1:15:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7204: train loss 1.65795. lr 5.307781e-04:  44%|████▍     | 7204/16329 [1:00:41<1:15:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7204: train loss 1.65795. lr 5.307781e-04:  44%|████▍     | 7205/16329 [1:00:41<1:15:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7205: train loss 1.68928. lr 5.307597e-04:  44%|████▍     | 7205/16329 [1:00:41<1:15:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7205: train loss 1.68928. lr 5.307597e-04:  44%|████▍     | 7206/16329 [1:00:41<1:15:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7206: train loss 1.68088. lr 5.307413e-04:  44%|████▍     | 7206/16329 [1:00:42<1:15:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7206: train loss 1.68088. lr 5.307413e-04:  44%|████▍     | 7207/16329 [1:00:42<1:23:02,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7207: train loss 1.67624. lr 5.307228e-04:  44%|████▍     | 7207/16329 [1:00:43<1:23:02,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7207: train loss 1.67624. lr 5.307228e-04:  44%|████▍     | 7208/16329 [1:00:43<1:20:42,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7208: train loss 1.70175. lr 5.307044e-04:  44%|████▍     | 7208/16329 [1:00:43<1:20:42,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7208: train loss 1.70175. lr 5.307044e-04:  44%|████▍     | 7209/16329 [1:00:43<1:18:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7209: train loss 1.64267. lr 5.306859e-04:  44%|████▍     | 7209/16329 [1:00:44<1:18:58,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7209: train loss 1.64267. lr 5.306859e-04:  44%|████▍     | 7210/16329 [1:00:44<1:17:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7210: train loss 1.64698. lr 5.306675e-04:  44%|████▍     | 7210/16329 [1:00:44<1:17:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7210: train loss 1.64698. lr 5.306675e-04:  44%|████▍     | 7211/16329 [1:00:44<1:16:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7211: train loss 1.67703. lr 5.306490e-04:  44%|████▍     | 7211/16329 [1:00:45<1:16:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7211: train loss 1.67703. lr 5.306490e-04:  44%|████▍     | 7212/16329 [1:00:45<1:16:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7212: train loss 1.71045. lr 5.306306e-04:  44%|████▍     | 7212/16329 [1:00:45<1:16:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7212: train loss 1.71045. lr 5.306306e-04:  44%|████▍     | 7213/16329 [1:00:45<1:16:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7213: train loss 1.67285. lr 5.306121e-04:  44%|████▍     | 7213/16329 [1:00:46<1:16:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7213: train loss 1.67285. lr 5.306121e-04:  44%|████▍     | 7214/16329 [1:00:46<1:15:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7214: train loss 1.69062. lr 5.305936e-04:  44%|████▍     | 7214/16329 [1:00:46<1:15:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7214: train loss 1.69062. lr 5.305936e-04:  44%|████▍     | 7215/16329 [1:00:46<1:15:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7215: train loss 1.68984. lr 5.305752e-04:  44%|████▍     | 7215/16329 [1:00:47<1:15:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7215: train loss 1.68984. lr 5.305752e-04:  44%|████▍     | 7216/16329 [1:00:47<1:15:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7216: train loss 1.68134. lr 5.305567e-04:  44%|████▍     | 7216/16329 [1:00:47<1:15:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7216: train loss 1.68134. lr 5.305567e-04:  44%|████▍     | 7217/16329 [1:00:47<1:15:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7217: train loss 1.66734. lr 5.305383e-04:  44%|████▍     | 7217/16329 [1:00:48<1:15:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7217: train loss 1.66734. lr 5.305383e-04:  44%|████▍     | 7218/16329 [1:00:48<1:17:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7218: train loss 1.68466. lr 5.305198e-04:  44%|████▍     | 7218/16329 [1:00:48<1:17:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7218: train loss 1.68466. lr 5.305198e-04:  44%|████▍     | 7219/16329 [1:00:48<1:18:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7219: train loss 1.69855. lr 5.305013e-04:  44%|████▍     | 7219/16329 [1:00:49<1:18:23,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7219: train loss 1.69855. lr 5.305013e-04:  44%|████▍     | 7220/16329 [1:00:49<1:18:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7220: train loss 1.63321. lr 5.304828e-04:  44%|████▍     | 7220/16329 [1:00:49<1:18:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7220: train loss 1.63321. lr 5.304828e-04:  44%|████▍     | 7221/16329 [1:00:49<1:18:18,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7221: train loss 1.70591. lr 5.304644e-04:  44%|████▍     | 7221/16329 [1:00:50<1:18:18,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7221: train loss 1.70591. lr 5.304644e-04:  44%|████▍     | 7222/16329 [1:00:50<1:17:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7222: train loss 1.66458. lr 5.304459e-04:  44%|████▍     | 7222/16329 [1:00:50<1:17:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7222: train loss 1.66458. lr 5.304459e-04:  44%|████▍     | 7223/16329 [1:00:50<1:17:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7223: train loss 1.65770. lr 5.304274e-04:  44%|████▍     | 7223/16329 [1:00:51<1:17:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7223: train loss 1.65770. lr 5.304274e-04:  44%|████▍     | 7224/16329 [1:00:51<1:17:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7224: train loss 1.65440. lr 5.304089e-04:  44%|████▍     | 7224/16329 [1:00:51<1:17:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7224: train loss 1.65440. lr 5.304089e-04:  44%|████▍     | 7225/16329 [1:00:51<1:16:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7225: train loss 1.67245. lr 5.303904e-04:  44%|████▍     | 7225/16329 [1:00:52<1:16:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7225: train loss 1.67245. lr 5.303904e-04:  44%|████▍     | 7226/16329 [1:00:52<1:16:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7226: train loss 1.66732. lr 5.303720e-04:  44%|████▍     | 7226/16329 [1:00:52<1:16:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7226: train loss 1.66732. lr 5.303720e-04:  44%|████▍     | 7227/16329 [1:00:52<1:16:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7227: train loss 1.67134. lr 5.303535e-04:  44%|████▍     | 7227/16329 [1:00:53<1:16:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7227: train loss 1.67134. lr 5.303535e-04:  44%|████▍     | 7228/16329 [1:00:53<1:15:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7228: train loss 1.65426. lr 5.303350e-04:  44%|████▍     | 7228/16329 [1:00:53<1:15:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7228: train loss 1.65426. lr 5.303350e-04:  44%|████▍     | 7229/16329 [1:00:53<1:15:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7229: train loss 1.64524. lr 5.303165e-04:  44%|████▍     | 7229/16329 [1:00:54<1:15:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7229: train loss 1.64524. lr 5.303165e-04:  44%|████▍     | 7230/16329 [1:00:54<1:15:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7230: train loss 1.74557. lr 5.302980e-04:  44%|████▍     | 7230/16329 [1:00:54<1:15:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7230: train loss 1.74557. lr 5.302980e-04:  44%|████▍     | 7231/16329 [1:00:54<1:15:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7231: train loss 1.68771. lr 5.302795e-04:  44%|████▍     | 7231/16329 [1:00:55<1:15:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7231: train loss 1.68771. lr 5.302795e-04:  44%|████▍     | 7232/16329 [1:00:55<1:14:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7232: train loss 1.65787. lr 5.302610e-04:  44%|████▍     | 7232/16329 [1:00:55<1:14:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7232: train loss 1.65787. lr 5.302610e-04:  44%|████▍     | 7233/16329 [1:00:55<1:15:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7233: train loss 1.71240. lr 5.302425e-04:  44%|████▍     | 7233/16329 [1:00:56<1:15:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7233: train loss 1.71240. lr 5.302425e-04:  44%|████▍     | 7234/16329 [1:00:56<1:24:45,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 7234: train loss 1.62766. lr 5.302240e-04:  44%|████▍     | 7234/16329 [1:00:56<1:24:45,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 7234: train loss 1.62766. lr 5.302240e-04:  44%|████▍     | 7235/16329 [1:00:56<1:21:41,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7235: train loss 1.62917. lr 5.302055e-04:  44%|████▍     | 7235/16329 [1:00:57<1:21:41,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7235: train loss 1.62917. lr 5.302055e-04:  44%|████▍     | 7236/16329 [1:00:57<1:19:33,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7236: train loss 1.66951. lr 5.301870e-04:  44%|████▍     | 7236/16329 [1:00:57<1:19:33,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7236: train loss 1.66951. lr 5.301870e-04:  44%|████▍     | 7237/16329 [1:00:57<1:18:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7237: train loss 1.68544. lr 5.301685e-04:  44%|████▍     | 7237/16329 [1:00:58<1:18:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7237: train loss 1.68544. lr 5.301685e-04:  44%|████▍     | 7238/16329 [1:00:58<1:16:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7238: train loss 1.69184. lr 5.301500e-04:  44%|████▍     | 7238/16329 [1:00:58<1:16:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7238: train loss 1.69184. lr 5.301500e-04:  44%|████▍     | 7239/16329 [1:00:58<1:16:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7239: train loss 1.64643. lr 5.301314e-04:  44%|████▍     | 7239/16329 [1:00:59<1:16:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7239: train loss 1.64643. lr 5.301314e-04:  44%|████▍     | 7240/16329 [1:00:59<1:16:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7240: train loss 1.73259. lr 5.301129e-04:  44%|████▍     | 7240/16329 [1:00:59<1:16:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7240: train loss 1.73259. lr 5.301129e-04:  44%|████▍     | 7241/16329 [1:00:59<1:15:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7241: train loss 1.67613. lr 5.300944e-04:  44%|████▍     | 7241/16329 [1:01:00<1:15:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7241: train loss 1.67613. lr 5.300944e-04:  44%|████▍     | 7242/16329 [1:01:00<1:15:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7242: train loss 1.67643. lr 5.300759e-04:  44%|████▍     | 7242/16329 [1:01:00<1:15:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7242: train loss 1.67643. lr 5.300759e-04:  44%|████▍     | 7243/16329 [1:01:00<1:15:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7243: train loss 1.69573. lr 5.300574e-04:  44%|████▍     | 7243/16329 [1:01:01<1:15:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7243: train loss 1.69573. lr 5.300574e-04:  44%|████▍     | 7244/16329 [1:01:01<1:14:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7244: train loss 1.59931. lr 5.300388e-04:  44%|████▍     | 7244/16329 [1:01:01<1:14:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7244: train loss 1.59931. lr 5.300388e-04:  44%|████▍     | 7245/16329 [1:01:01<1:14:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7245: train loss 1.71192. lr 5.300203e-04:  44%|████▍     | 7245/16329 [1:01:02<1:14:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7245: train loss 1.71192. lr 5.300203e-04:  44%|████▍     | 7246/16329 [1:01:02<1:14:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7246: train loss 1.69250. lr 5.300018e-04:  44%|████▍     | 7246/16329 [1:01:02<1:14:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7246: train loss 1.69250. lr 5.300018e-04:  44%|████▍     | 7247/16329 [1:01:02<1:14:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7247: train loss 1.74217. lr 5.299833e-04:  44%|████▍     | 7247/16329 [1:01:03<1:14:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7247: train loss 1.74217. lr 5.299833e-04:  44%|████▍     | 7248/16329 [1:01:03<1:14:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7248: train loss 1.67677. lr 5.299647e-04:  44%|████▍     | 7248/16329 [1:01:03<1:14:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7248: train loss 1.67677. lr 5.299647e-04:  44%|████▍     | 7249/16329 [1:01:03<1:17:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7249: train loss 1.68149. lr 5.299462e-04:  44%|████▍     | 7249/16329 [1:01:04<1:17:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7249: train loss 1.68149. lr 5.299462e-04:  44%|████▍     | 7250/16329 [1:01:04<1:20:09,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7250: train loss 1.66879. lr 5.299277e-04:  44%|████▍     | 7250/16329 [1:01:04<1:20:09,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7250: train loss 1.66879. lr 5.299277e-04:  44%|████▍     | 7251/16329 [1:01:04<1:20:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7251: train loss 1.67057. lr 5.299091e-04:  44%|████▍     | 7251/16329 [1:01:05<1:20:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7251: train loss 1.67057. lr 5.299091e-04:  44%|████▍     | 7252/16329 [1:01:05<1:20:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7252: train loss 1.72854. lr 5.298906e-04:  44%|████▍     | 7252/16329 [1:01:05<1:20:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7252: train loss 1.72854. lr 5.298906e-04:  44%|████▍     | 7253/16329 [1:01:05<1:19:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7253: train loss 1.68257. lr 5.298720e-04:  44%|████▍     | 7253/16329 [1:01:06<1:19:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7253: train loss 1.68257. lr 5.298720e-04:  44%|████▍     | 7254/16329 [1:01:06<1:18:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7254: train loss 1.66629. lr 5.298535e-04:  44%|████▍     | 7254/16329 [1:01:06<1:18:57,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7254: train loss 1.66629. lr 5.298535e-04:  44%|████▍     | 7255/16329 [1:01:06<1:18:11,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7255: train loss 1.67652. lr 5.298349e-04:  44%|████▍     | 7255/16329 [1:01:07<1:18:11,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7255: train loss 1.67652. lr 5.298349e-04:  44%|████▍     | 7256/16329 [1:01:07<1:17:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7256: train loss 1.67923. lr 5.298164e-04:  44%|████▍     | 7256/16329 [1:01:07<1:17:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7256: train loss 1.67923. lr 5.298164e-04:  44%|████▍     | 7257/16329 [1:01:07<1:16:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7257: train loss 1.67893. lr 5.297978e-04:  44%|████▍     | 7257/16329 [1:01:08<1:16:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7257: train loss 1.67893. lr 5.297978e-04:  44%|████▍     | 7258/16329 [1:01:08<1:16:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7258: train loss 1.68867. lr 5.297793e-04:  44%|████▍     | 7258/16329 [1:01:08<1:16:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7258: train loss 1.68867. lr 5.297793e-04:  44%|████▍     | 7259/16329 [1:01:08<1:15:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7259: train loss 1.63808. lr 5.297607e-04:  44%|████▍     | 7259/16329 [1:01:09<1:15:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7259: train loss 1.63808. lr 5.297607e-04:  44%|████▍     | 7260/16329 [1:01:09<1:15:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7260: train loss 1.64658. lr 5.297422e-04:  44%|████▍     | 7260/16329 [1:01:09<1:15:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7260: train loss 1.64658. lr 5.297422e-04:  44%|████▍     | 7261/16329 [1:01:09<1:15:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7261: train loss 1.70543. lr 5.297236e-04:  44%|████▍     | 7261/16329 [1:01:10<1:15:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7261: train loss 1.70543. lr 5.297236e-04:  44%|████▍     | 7262/16329 [1:01:10<1:15:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7262: train loss 1.64241. lr 5.297051e-04:  44%|████▍     | 7262/16329 [1:01:10<1:15:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7262: train loss 1.64241. lr 5.297051e-04:  44%|████▍     | 7263/16329 [1:01:10<1:14:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7263: train loss 1.70361. lr 5.296865e-04:  44%|████▍     | 7263/16329 [1:01:11<1:14:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7263: train loss 1.70361. lr 5.296865e-04:  44%|████▍     | 7264/16329 [1:01:11<1:14:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7264: train loss 1.71373. lr 5.296679e-04:  44%|████▍     | 7264/16329 [1:01:11<1:14:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7264: train loss 1.71373. lr 5.296679e-04:  44%|████▍     | 7265/16329 [1:01:11<1:14:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7265: train loss 1.68000. lr 5.296494e-04:  44%|████▍     | 7265/16329 [1:01:12<1:14:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7265: train loss 1.68000. lr 5.296494e-04:  44%|████▍     | 7266/16329 [1:01:12<1:14:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7266: train loss 1.61972. lr 5.296308e-04:  44%|████▍     | 7266/16329 [1:01:12<1:14:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7266: train loss 1.61972. lr 5.296308e-04:  45%|████▍     | 7267/16329 [1:01:12<1:14:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7267: train loss 1.62592. lr 5.296122e-04:  45%|████▍     | 7267/16329 [1:01:13<1:14:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7267: train loss 1.62592. lr 5.296122e-04:  45%|████▍     | 7268/16329 [1:01:13<1:14:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7268: train loss 1.69672. lr 5.295936e-04:  45%|████▍     | 7268/16329 [1:01:13<1:14:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7268: train loss 1.69672. lr 5.295936e-04:  45%|████▍     | 7269/16329 [1:01:13<1:14:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7269: train loss 1.67391. lr 5.295751e-04:  45%|████▍     | 7269/16329 [1:01:14<1:14:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7269: train loss 1.67391. lr 5.295751e-04:  45%|████▍     | 7270/16329 [1:01:14<1:17:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7270: train loss 1.68297. lr 5.295565e-04:  45%|████▍     | 7270/16329 [1:01:14<1:17:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7270: train loss 1.68297. lr 5.295565e-04:  45%|████▍     | 7271/16329 [1:01:14<1:18:44,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7271: train loss 1.72101. lr 5.295379e-04:  45%|████▍     | 7271/16329 [1:01:15<1:18:44,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7271: train loss 1.72101. lr 5.295379e-04:  45%|████▍     | 7272/16329 [1:01:15<1:19:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7272: train loss 1.65122. lr 5.295193e-04:  45%|████▍     | 7272/16329 [1:01:16<1:19:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7272: train loss 1.65122. lr 5.295193e-04:  45%|████▍     | 7273/16329 [1:01:16<1:19:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7273: train loss 1.66056. lr 5.295007e-04:  45%|████▍     | 7273/16329 [1:01:16<1:19:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7273: train loss 1.66056. lr 5.295007e-04:  45%|████▍     | 7274/16329 [1:01:16<1:27:54,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 7274: train loss 1.61665. lr 5.294821e-04:  45%|████▍     | 7274/16329 [1:01:17<1:27:54,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 7274: train loss 1.61665. lr 5.294821e-04:  45%|████▍     | 7275/16329 [1:01:17<1:24:27,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 7275: train loss 1.65282. lr 5.294635e-04:  45%|████▍     | 7275/16329 [1:01:17<1:24:27,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 7275: train loss 1.65282. lr 5.294635e-04:  45%|████▍     | 7276/16329 [1:01:17<1:21:43,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 7276: train loss 1.71360. lr 5.294450e-04:  45%|████▍     | 7276/16329 [1:01:18<1:21:43,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 7276: train loss 1.71360. lr 5.294450e-04:  45%|████▍     | 7277/16329 [1:01:18<1:19:51,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7277: train loss 1.64479. lr 5.294264e-04:  45%|████▍     | 7277/16329 [1:01:18<1:19:51,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7277: train loss 1.64479. lr 5.294264e-04:  45%|████▍     | 7278/16329 [1:01:18<1:18:20,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7278: train loss 1.67427. lr 5.294078e-04:  45%|████▍     | 7278/16329 [1:01:19<1:18:20,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7278: train loss 1.67427. lr 5.294078e-04:  45%|████▍     | 7279/16329 [1:01:19<1:17:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7279: train loss 1.64832. lr 5.293892e-04:  45%|████▍     | 7279/16329 [1:01:19<1:17:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7279: train loss 1.64832. lr 5.293892e-04:  45%|████▍     | 7280/16329 [1:01:19<1:16:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7280: train loss 1.69151. lr 5.293706e-04:  45%|████▍     | 7280/16329 [1:01:20<1:16:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7280: train loss 1.69151. lr 5.293706e-04:  45%|████▍     | 7281/16329 [1:01:20<1:15:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7281: train loss 1.67604. lr 5.293520e-04:  45%|████▍     | 7281/16329 [1:01:20<1:15:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7281: train loss 1.67604. lr 5.293520e-04:  45%|████▍     | 7282/16329 [1:01:20<1:15:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7282: train loss 1.61688. lr 5.293334e-04:  45%|████▍     | 7282/16329 [1:01:21<1:15:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7282: train loss 1.61688. lr 5.293334e-04:  45%|████▍     | 7283/16329 [1:01:21<1:14:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7283: train loss 1.70975. lr 5.293147e-04:  45%|████▍     | 7283/16329 [1:01:21<1:14:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7283: train loss 1.70975. lr 5.293147e-04:  45%|████▍     | 7284/16329 [1:01:21<1:14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7284: train loss 1.65274. lr 5.292961e-04:  45%|████▍     | 7284/16329 [1:01:22<1:14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7284: train loss 1.65274. lr 5.292961e-04:  45%|████▍     | 7285/16329 [1:01:22<1:14:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7285: train loss 1.67115. lr 5.292775e-04:  45%|████▍     | 7285/16329 [1:01:22<1:14:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7285: train loss 1.67115. lr 5.292775e-04:  45%|████▍     | 7286/16329 [1:01:22<1:14:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7286: train loss 1.67469. lr 5.292589e-04:  45%|████▍     | 7286/16329 [1:01:23<1:14:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7286: train loss 1.67469. lr 5.292589e-04:  45%|████▍     | 7287/16329 [1:01:23<1:14:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7287: train loss 1.65708. lr 5.292403e-04:  45%|████▍     | 7287/16329 [1:01:23<1:14:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7287: train loss 1.65708. lr 5.292403e-04:  45%|████▍     | 7288/16329 [1:01:23<1:14:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7288: train loss 1.67314. lr 5.292217e-04:  45%|████▍     | 7288/16329 [1:01:24<1:14:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7288: train loss 1.67314. lr 5.292217e-04:  45%|████▍     | 7289/16329 [1:01:24<1:14:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7289: train loss 1.66565. lr 5.292031e-04:  45%|████▍     | 7289/16329 [1:01:24<1:14:22,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7289: train loss 1.66565. lr 5.292031e-04:  45%|████▍     | 7290/16329 [1:01:24<1:14:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7290: train loss 1.67309. lr 5.291844e-04:  45%|████▍     | 7290/16329 [1:01:25<1:14:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7290: train loss 1.67309. lr 5.291844e-04:  45%|████▍     | 7291/16329 [1:01:25<1:14:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7291: train loss 1.64901. lr 5.291658e-04:  45%|████▍     | 7291/16329 [1:01:25<1:14:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7291: train loss 1.64901. lr 5.291658e-04:  45%|████▍     | 7292/16329 [1:01:25<1:14:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7292: train loss 1.64690. lr 5.291472e-04:  45%|████▍     | 7292/16329 [1:01:26<1:14:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7292: train loss 1.64690. lr 5.291472e-04:  45%|████▍     | 7293/16329 [1:01:26<1:13:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 7293: train loss 1.65209. lr 5.291286e-04:  45%|████▍     | 7293/16329 [1:01:26<1:13:59,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 7293: train loss 1.65209. lr 5.291286e-04:  45%|████▍     | 7294/16329 [1:01:26<1:14:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7294: train loss 1.68428. lr 5.291099e-04:  45%|████▍     | 7294/16329 [1:01:27<1:14:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7294: train loss 1.68428. lr 5.291099e-04:  45%|████▍     | 7295/16329 [1:01:27<1:14:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7295: train loss 1.66732. lr 5.290913e-04:  45%|████▍     | 7295/16329 [1:01:27<1:14:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7295: train loss 1.66732. lr 5.290913e-04:  45%|████▍     | 7296/16329 [1:01:27<1:14:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7296: train loss 1.69534. lr 5.290727e-04:  45%|████▍     | 7296/16329 [1:01:28<1:14:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7296: train loss 1.69534. lr 5.290727e-04:  45%|████▍     | 7297/16329 [1:01:28<1:14:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7297: train loss 1.62281. lr 5.290540e-04:  45%|████▍     | 7297/16329 [1:01:28<1:14:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7297: train loss 1.62281. lr 5.290540e-04:  45%|████▍     | 7298/16329 [1:01:28<1:14:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7298: train loss 1.68392. lr 5.290354e-04:  45%|████▍     | 7298/16329 [1:01:29<1:14:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7298: train loss 1.68392. lr 5.290354e-04:  45%|████▍     | 7299/16329 [1:01:29<1:14:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7299: train loss 1.61297. lr 5.290167e-04:  45%|████▍     | 7299/16329 [1:01:29<1:14:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7299: train loss 1.61297. lr 5.290167e-04:  45%|████▍     | 7300/16329 [1:01:29<1:14:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7300: train loss 1.68566. lr 5.289981e-04:  45%|████▍     | 7300/16329 [1:01:30<1:14:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7300: train loss 1.68566. lr 5.289981e-04:  45%|████▍     | 7301/16329 [1:01:30<1:15:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7301: train loss 1.66013. lr 5.289795e-04:  45%|████▍     | 7301/16329 [1:01:30<1:15:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7301: train loss 1.66013. lr 5.289795e-04:  45%|████▍     | 7302/16329 [1:01:30<1:14:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7302: train loss 1.65991. lr 5.289608e-04:  45%|████▍     | 7302/16329 [1:01:31<1:14:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7302: train loss 1.65991. lr 5.289608e-04:  45%|████▍     | 7303/16329 [1:01:31<1:14:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7303: train loss 1.68295. lr 5.289422e-04:  45%|████▍     | 7303/16329 [1:01:31<1:14:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7303: train loss 1.68295. lr 5.289422e-04:  45%|████▍     | 7304/16329 [1:01:31<1:14:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7304: train loss 1.67323. lr 5.289235e-04:  45%|████▍     | 7304/16329 [1:01:32<1:14:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7304: train loss 1.67323. lr 5.289235e-04:  45%|████▍     | 7305/16329 [1:01:32<1:14:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7305: train loss 1.69851. lr 5.289049e-04:  45%|████▍     | 7305/16329 [1:01:32<1:14:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7305: train loss 1.69851. lr 5.289049e-04:  45%|████▍     | 7306/16329 [1:01:32<1:14:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7306: train loss 1.68252. lr 5.288862e-04:  45%|████▍     | 7306/16329 [1:01:33<1:14:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7306: train loss 1.68252. lr 5.288862e-04:  45%|████▍     | 7307/16329 [1:01:33<1:15:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7307: train loss 1.66042. lr 5.288675e-04:  45%|████▍     | 7307/16329 [1:01:33<1:15:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7307: train loss 1.66042. lr 5.288675e-04:  45%|████▍     | 7308/16329 [1:01:33<1:15:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7308: train loss 1.68043. lr 5.288489e-04:  45%|████▍     | 7308/16329 [1:01:34<1:15:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7308: train loss 1.68043. lr 5.288489e-04:  45%|████▍     | 7309/16329 [1:01:34<1:23:34,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 7309: train loss 1.70641. lr 5.288302e-04:  45%|████▍     | 7309/16329 [1:01:34<1:23:34,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 7309: train loss 1.70641. lr 5.288302e-04:  45%|████▍     | 7310/16329 [1:01:34<1:21:09,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 7310: train loss 1.65742. lr 5.288116e-04:  45%|████▍     | 7310/16329 [1:01:35<1:21:09,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 7310: train loss 1.65742. lr 5.288116e-04:  45%|████▍     | 7311/16329 [1:01:35<1:19:06,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7311: train loss 1.65738. lr 5.287929e-04:  45%|████▍     | 7311/16329 [1:01:35<1:19:06,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7311: train loss 1.65738. lr 5.287929e-04:  45%|████▍     | 7312/16329 [1:01:35<1:17:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7312: train loss 1.65592. lr 5.287742e-04:  45%|████▍     | 7312/16329 [1:01:36<1:17:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7312: train loss 1.65592. lr 5.287742e-04:  45%|████▍     | 7313/16329 [1:01:36<1:16:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7313: train loss 1.65653. lr 5.287556e-04:  45%|████▍     | 7313/16329 [1:01:36<1:16:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7313: train loss 1.65653. lr 5.287556e-04:  45%|████▍     | 7314/16329 [1:01:36<1:15:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7314: train loss 1.72131. lr 5.287369e-04:  45%|████▍     | 7314/16329 [1:01:37<1:15:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7314: train loss 1.72131. lr 5.287369e-04:  45%|████▍     | 7315/16329 [1:01:37<1:15:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7315: train loss 1.68046. lr 5.287182e-04:  45%|████▍     | 7315/16329 [1:01:37<1:15:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7315: train loss 1.68046. lr 5.287182e-04:  45%|████▍     | 7316/16329 [1:01:37<1:14:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7316: train loss 1.60612. lr 5.286995e-04:  45%|████▍     | 7316/16329 [1:01:38<1:14:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7316: train loss 1.60612. lr 5.286995e-04:  45%|████▍     | 7317/16329 [1:01:38<1:14:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7317: train loss 1.64878. lr 5.286808e-04:  45%|████▍     | 7317/16329 [1:01:38<1:14:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7317: train loss 1.64878. lr 5.286808e-04:  45%|████▍     | 7318/16329 [1:01:38<1:14:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7318: train loss 1.66529. lr 5.286622e-04:  45%|████▍     | 7318/16329 [1:01:39<1:14:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7318: train loss 1.66529. lr 5.286622e-04:  45%|████▍     | 7319/16329 [1:01:39<1:14:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7319: train loss 1.68648. lr 5.286435e-04:  45%|████▍     | 7319/16329 [1:01:39<1:14:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7319: train loss 1.68648. lr 5.286435e-04:  45%|████▍     | 7320/16329 [1:01:39<1:14:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7320: train loss 1.66849. lr 5.286248e-04:  45%|████▍     | 7320/16329 [1:01:40<1:14:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7320: train loss 1.66849. lr 5.286248e-04:  45%|████▍     | 7321/16329 [1:01:40<1:14:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7321: train loss 1.70582. lr 5.286061e-04:  45%|████▍     | 7321/16329 [1:01:40<1:14:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7321: train loss 1.70582. lr 5.286061e-04:  45%|████▍     | 7322/16329 [1:01:40<1:14:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7322: train loss 1.65300. lr 5.285874e-04:  45%|████▍     | 7322/16329 [1:01:41<1:14:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7322: train loss 1.65300. lr 5.285874e-04:  45%|████▍     | 7323/16329 [1:01:41<1:14:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7323: train loss 1.68534. lr 5.285687e-04:  45%|████▍     | 7323/16329 [1:01:41<1:14:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7323: train loss 1.68534. lr 5.285687e-04:  45%|████▍     | 7324/16329 [1:01:41<1:14:05,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7324: train loss 1.69642. lr 5.285500e-04:  45%|████▍     | 7324/16329 [1:01:42<1:14:05,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7324: train loss 1.69642. lr 5.285500e-04:  45%|████▍     | 7325/16329 [1:01:42<1:14:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7325: train loss 1.66612. lr 5.285313e-04:  45%|████▍     | 7325/16329 [1:01:42<1:14:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7325: train loss 1.66612. lr 5.285313e-04:  45%|████▍     | 7326/16329 [1:01:42<1:14:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7326: train loss 1.63759. lr 5.285126e-04:  45%|████▍     | 7326/16329 [1:01:43<1:14:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7326: train loss 1.63759. lr 5.285126e-04:  45%|████▍     | 7327/16329 [1:01:43<1:13:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7327: train loss 1.69989. lr 5.284939e-04:  45%|████▍     | 7327/16329 [1:01:43<1:13:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7327: train loss 1.69989. lr 5.284939e-04:  45%|████▍     | 7328/16329 [1:01:43<1:13:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7328: train loss 1.68636. lr 5.284752e-04:  45%|████▍     | 7328/16329 [1:01:44<1:13:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7328: train loss 1.68636. lr 5.284752e-04:  45%|████▍     | 7329/16329 [1:01:44<1:13:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7329: train loss 1.64999. lr 5.284565e-04:  45%|████▍     | 7329/16329 [1:01:44<1:13:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7329: train loss 1.64999. lr 5.284565e-04:  45%|████▍     | 7330/16329 [1:01:44<1:14:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7330: train loss 1.66479. lr 5.284378e-04:  45%|████▍     | 7330/16329 [1:01:45<1:14:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7330: train loss 1.66479. lr 5.284378e-04:  45%|████▍     | 7331/16329 [1:01:45<1:14:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7331: train loss 1.69831. lr 5.284191e-04:  45%|████▍     | 7331/16329 [1:01:45<1:14:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7331: train loss 1.69831. lr 5.284191e-04:  45%|████▍     | 7332/16329 [1:01:45<1:14:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7332: train loss 1.71116. lr 5.284004e-04:  45%|████▍     | 7332/16329 [1:01:46<1:14:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7332: train loss 1.71116. lr 5.284004e-04:  45%|████▍     | 7333/16329 [1:01:46<1:14:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7333: train loss 1.61719. lr 5.283817e-04:  45%|████▍     | 7333/16329 [1:01:46<1:14:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7333: train loss 1.61719. lr 5.283817e-04:  45%|████▍     | 7334/16329 [1:01:46<1:21:40,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 7334: train loss 1.65632. lr 5.283630e-04:  45%|████▍     | 7334/16329 [1:01:47<1:21:40,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 7334: train loss 1.65632. lr 5.283630e-04:  45%|████▍     | 7335/16329 [1:01:47<1:19:25,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7335: train loss 1.63427. lr 5.283443e-04:  45%|████▍     | 7335/16329 [1:01:47<1:19:25,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7335: train loss 1.63427. lr 5.283443e-04:  45%|████▍     | 7336/16329 [1:01:47<1:17:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7336: train loss 1.66913. lr 5.283255e-04:  45%|████▍     | 7336/16329 [1:01:48<1:17:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7336: train loss 1.66913. lr 5.283255e-04:  45%|████▍     | 7337/16329 [1:01:48<1:16:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7337: train loss 1.64691. lr 5.283068e-04:  45%|████▍     | 7337/16329 [1:01:48<1:16:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7337: train loss 1.64691. lr 5.283068e-04:  45%|████▍     | 7338/16329 [1:01:48<1:15:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7338: train loss 1.68185. lr 5.282881e-04:  45%|████▍     | 7338/16329 [1:01:49<1:15:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7338: train loss 1.68185. lr 5.282881e-04:  45%|████▍     | 7339/16329 [1:01:49<1:14:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7339: train loss 1.68437. lr 5.282694e-04:  45%|████▍     | 7339/16329 [1:01:49<1:14:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7339: train loss 1.68437. lr 5.282694e-04:  45%|████▍     | 7340/16329 [1:01:49<1:14:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7340: train loss 1.66579. lr 5.282506e-04:  45%|████▍     | 7340/16329 [1:01:50<1:14:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7340: train loss 1.66579. lr 5.282506e-04:  45%|████▍     | 7341/16329 [1:01:50<1:14:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7341: train loss 1.66566. lr 5.282319e-04:  45%|████▍     | 7341/16329 [1:01:50<1:14:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7341: train loss 1.66566. lr 5.282319e-04:  45%|████▍     | 7342/16329 [1:01:50<1:14:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7342: train loss 1.67581. lr 5.282132e-04:  45%|████▍     | 7342/16329 [1:01:51<1:14:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7342: train loss 1.67581. lr 5.282132e-04:  45%|████▍     | 7343/16329 [1:01:51<1:14:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7343: train loss 1.67468. lr 5.281945e-04:  45%|████▍     | 7343/16329 [1:01:51<1:14:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7343: train loss 1.67468. lr 5.281945e-04:  45%|████▍     | 7344/16329 [1:01:51<1:14:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7344: train loss 1.65892. lr 5.281757e-04:  45%|████▍     | 7344/16329 [1:01:52<1:14:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7344: train loss 1.65892. lr 5.281757e-04:  45%|████▍     | 7345/16329 [1:01:52<1:14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7345: train loss 1.67186. lr 5.281570e-04:  45%|████▍     | 7345/16329 [1:01:52<1:14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7345: train loss 1.67186. lr 5.281570e-04:  45%|████▍     | 7346/16329 [1:01:52<1:14:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7346: train loss 1.70477. lr 5.281382e-04:  45%|████▍     | 7346/16329 [1:01:53<1:14:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7346: train loss 1.70477. lr 5.281382e-04:  45%|████▍     | 7347/16329 [1:01:53<1:14:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7347: train loss 1.65197. lr 5.281195e-04:  45%|████▍     | 7347/16329 [1:01:53<1:14:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7347: train loss 1.65197. lr 5.281195e-04:  45%|████▍     | 7348/16329 [1:01:53<1:14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7348: train loss 1.65527. lr 5.281007e-04:  45%|████▍     | 7348/16329 [1:01:54<1:14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7348: train loss 1.65527. lr 5.281007e-04:  45%|████▌     | 7349/16329 [1:01:54<1:14:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7349: train loss 1.63816. lr 5.280820e-04:  45%|████▌     | 7349/16329 [1:01:54<1:14:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7349: train loss 1.63816. lr 5.280820e-04:  45%|████▌     | 7350/16329 [1:01:54<1:14:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7350: train loss 1.68278. lr 5.280633e-04:  45%|████▌     | 7350/16329 [1:01:55<1:14:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7350: train loss 1.68278. lr 5.280633e-04:  45%|████▌     | 7351/16329 [1:01:55<1:14:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7351: train loss 1.66217. lr 5.280445e-04:  45%|████▌     | 7351/16329 [1:01:55<1:14:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7351: train loss 1.66217. lr 5.280445e-04:  45%|████▌     | 7352/16329 [1:01:55<1:14:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7352: train loss 1.65536. lr 5.280258e-04:  45%|████▌     | 7352/16329 [1:01:56<1:14:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7352: train loss 1.65536. lr 5.280258e-04:  45%|████▌     | 7353/16329 [1:01:56<1:14:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7353: train loss 1.70486. lr 5.280070e-04:  45%|████▌     | 7353/16329 [1:01:56<1:14:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7353: train loss 1.70486. lr 5.280070e-04:  45%|████▌     | 7354/16329 [1:01:56<1:14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7354: train loss 1.68588. lr 5.279882e-04:  45%|████▌     | 7354/16329 [1:01:57<1:14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7354: train loss 1.68588. lr 5.279882e-04:  45%|████▌     | 7355/16329 [1:01:57<1:14:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7355: train loss 1.68105. lr 5.279695e-04:  45%|████▌     | 7355/16329 [1:01:57<1:14:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7355: train loss 1.68105. lr 5.279695e-04:  45%|████▌     | 7356/16329 [1:01:57<1:14:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7356: train loss 1.64947. lr 5.279507e-04:  45%|████▌     | 7356/16329 [1:01:58<1:14:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7356: train loss 1.64947. lr 5.279507e-04:  45%|████▌     | 7357/16329 [1:01:58<1:13:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7357: train loss 1.65849. lr 5.279320e-04:  45%|████▌     | 7357/16329 [1:01:58<1:13:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7357: train loss 1.65849. lr 5.279320e-04:  45%|████▌     | 7358/16329 [1:01:58<1:13:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7358: train loss 1.63752. lr 5.279132e-04:  45%|████▌     | 7358/16329 [1:01:59<1:13:48,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7358: train loss 1.63752. lr 5.279132e-04:  45%|████▌     | 7359/16329 [1:01:59<1:14:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7359: train loss 1.63380. lr 5.278944e-04:  45%|████▌     | 7359/16329 [1:01:59<1:14:06,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7359: train loss 1.63380. lr 5.278944e-04:  45%|████▌     | 7360/16329 [1:01:59<1:14:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7360: train loss 1.67234. lr 5.278757e-04:  45%|████▌     | 7360/16329 [1:02:00<1:14:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7360: train loss 1.67234. lr 5.278757e-04:  45%|████▌     | 7361/16329 [1:02:00<1:21:41,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7361: train loss 1.68284. lr 5.278569e-04:  45%|████▌     | 7361/16329 [1:02:00<1:21:41,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7361: train loss 1.68284. lr 5.278569e-04:  45%|████▌     | 7362/16329 [1:02:00<1:19:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7362: train loss 1.66698. lr 5.278381e-04:  45%|████▌     | 7362/16329 [1:02:01<1:19:35,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7362: train loss 1.66698. lr 5.278381e-04:  45%|████▌     | 7363/16329 [1:02:01<1:19:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7363: train loss 1.66755. lr 5.278193e-04:  45%|████▌     | 7363/16329 [1:02:01<1:19:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7363: train loss 1.66755. lr 5.278193e-04:  45%|████▌     | 7364/16329 [1:02:01<1:18:34,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7364: train loss 1.64143. lr 5.278005e-04:  45%|████▌     | 7364/16329 [1:02:02<1:18:34,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7364: train loss 1.64143. lr 5.278005e-04:  45%|████▌     | 7365/16329 [1:02:02<1:17:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7365: train loss 1.67423. lr 5.277818e-04:  45%|████▌     | 7365/16329 [1:02:02<1:17:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7365: train loss 1.67423. lr 5.277818e-04:  45%|████▌     | 7366/16329 [1:02:02<1:17:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7366: train loss 1.65027. lr 5.277630e-04:  45%|████▌     | 7366/16329 [1:02:03<1:17:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7366: train loss 1.65027. lr 5.277630e-04:  45%|████▌     | 7367/16329 [1:02:03<1:16:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7367: train loss 1.64933. lr 5.277442e-04:  45%|████▌     | 7367/16329 [1:02:03<1:16:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7367: train loss 1.64933. lr 5.277442e-04:  45%|████▌     | 7368/16329 [1:02:03<1:15:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7368: train loss 1.65088. lr 5.277254e-04:  45%|████▌     | 7368/16329 [1:02:04<1:15:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7368: train loss 1.65088. lr 5.277254e-04:  45%|████▌     | 7369/16329 [1:02:04<1:15:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7369: train loss 1.69368. lr 5.277066e-04:  45%|████▌     | 7369/16329 [1:02:04<1:15:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7369: train loss 1.69368. lr 5.277066e-04:  45%|████▌     | 7370/16329 [1:02:04<1:15:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7370: train loss 1.65061. lr 5.276878e-04:  45%|████▌     | 7370/16329 [1:02:05<1:15:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7370: train loss 1.65061. lr 5.276878e-04:  45%|████▌     | 7371/16329 [1:02:05<1:14:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7371: train loss 1.63088. lr 5.276690e-04:  45%|████▌     | 7371/16329 [1:02:05<1:14:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7371: train loss 1.63088. lr 5.276690e-04:  45%|████▌     | 7372/16329 [1:02:05<1:14:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7372: train loss 1.70352. lr 5.276502e-04:  45%|████▌     | 7372/16329 [1:02:06<1:14:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7372: train loss 1.70352. lr 5.276502e-04:  45%|████▌     | 7373/16329 [1:02:06<1:17:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7373: train loss 1.67053. lr 5.276314e-04:  45%|████▌     | 7373/16329 [1:02:07<1:17:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7373: train loss 1.67053. lr 5.276314e-04:  45%|████▌     | 7374/16329 [1:02:07<1:19:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7374: train loss 1.66494. lr 5.276127e-04:  45%|████▌     | 7374/16329 [1:02:07<1:19:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7374: train loss 1.66494. lr 5.276127e-04:  45%|████▌     | 7375/16329 [1:02:07<1:20:07,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7375: train loss 1.64983. lr 5.275938e-04:  45%|████▌     | 7375/16329 [1:02:08<1:20:07,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7375: train loss 1.64983. lr 5.275938e-04:  45%|████▌     | 7376/16329 [1:02:08<1:19:33,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7376: train loss 1.62317. lr 5.275750e-04:  45%|████▌     | 7376/16329 [1:02:08<1:19:33,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7376: train loss 1.62317. lr 5.275750e-04:  45%|████▌     | 7377/16329 [1:02:08<1:18:47,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7377: train loss 1.65008. lr 5.275562e-04:  45%|████▌     | 7377/16329 [1:02:09<1:18:47,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7377: train loss 1.65008. lr 5.275562e-04:  45%|████▌     | 7378/16329 [1:02:09<1:17:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7378: train loss 1.65390. lr 5.275374e-04:  45%|████▌     | 7378/16329 [1:02:09<1:17:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7378: train loss 1.65390. lr 5.275374e-04:  45%|████▌     | 7379/16329 [1:02:09<1:16:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7379: train loss 1.64817. lr 5.275186e-04:  45%|████▌     | 7379/16329 [1:02:10<1:16:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7379: train loss 1.64817. lr 5.275186e-04:  45%|████▌     | 7380/16329 [1:02:10<1:15:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7380: train loss 1.65348. lr 5.274998e-04:  45%|████▌     | 7380/16329 [1:02:10<1:15:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7380: train loss 1.65348. lr 5.274998e-04:  45%|████▌     | 7381/16329 [1:02:10<1:14:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7381: train loss 1.67088. lr 5.274810e-04:  45%|████▌     | 7381/16329 [1:02:11<1:14:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7381: train loss 1.67088. lr 5.274810e-04:  45%|████▌     | 7382/16329 [1:02:11<1:14:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7382: train loss 1.63892. lr 5.274622e-04:  45%|████▌     | 7382/16329 [1:02:11<1:14:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7382: train loss 1.63892. lr 5.274622e-04:  45%|████▌     | 7383/16329 [1:02:11<1:14:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7383: train loss 1.71030. lr 5.274434e-04:  45%|████▌     | 7383/16329 [1:02:12<1:14:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7383: train loss 1.71030. lr 5.274434e-04:  45%|████▌     | 7384/16329 [1:02:12<1:14:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7384: train loss 1.65605. lr 5.274245e-04:  45%|████▌     | 7384/16329 [1:02:12<1:14:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7384: train loss 1.65605. lr 5.274245e-04:  45%|████▌     | 7385/16329 [1:02:12<1:14:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7385: train loss 1.67484. lr 5.274057e-04:  45%|████▌     | 7385/16329 [1:02:13<1:14:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7385: train loss 1.67484. lr 5.274057e-04:  45%|████▌     | 7386/16329 [1:02:13<1:14:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7386: train loss 1.66904. lr 5.273869e-04:  45%|████▌     | 7386/16329 [1:02:13<1:14:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7386: train loss 1.66904. lr 5.273869e-04:  45%|████▌     | 7387/16329 [1:02:13<1:14:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7387: train loss 1.66330. lr 5.273681e-04:  45%|████▌     | 7387/16329 [1:02:14<1:14:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7387: train loss 1.66330. lr 5.273681e-04:  45%|████▌     | 7388/16329 [1:02:14<1:13:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7388: train loss 1.64403. lr 5.273492e-04:  45%|████▌     | 7388/16329 [1:02:14<1:13:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7388: train loss 1.64403. lr 5.273492e-04:  45%|████▌     | 7389/16329 [1:02:14<1:14:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7389: train loss 1.66145. lr 5.273304e-04:  45%|████▌     | 7389/16329 [1:02:15<1:14:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7389: train loss 1.66145. lr 5.273304e-04:  45%|████▌     | 7390/16329 [1:02:15<1:13:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7390: train loss 1.66520. lr 5.273116e-04:  45%|████▌     | 7390/16329 [1:02:15<1:13:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7390: train loss 1.66520. lr 5.273116e-04:  45%|████▌     | 7391/16329 [1:02:15<1:14:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7391: train loss 1.68833. lr 5.272927e-04:  45%|████▌     | 7391/16329 [1:02:16<1:14:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7391: train loss 1.68833. lr 5.272927e-04:  45%|████▌     | 7392/16329 [1:02:16<1:14:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7392: train loss 1.69157. lr 5.272739e-04:  45%|████▌     | 7392/16329 [1:02:16<1:14:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7392: train loss 1.69157. lr 5.272739e-04:  45%|████▌     | 7393/16329 [1:02:16<1:13:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7393: train loss 1.67977. lr 5.272551e-04:  45%|████▌     | 7393/16329 [1:02:17<1:13:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7393: train loss 1.67977. lr 5.272551e-04:  45%|████▌     | 7394/16329 [1:02:17<1:13:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7394: train loss 1.61718. lr 5.272362e-04:  45%|████▌     | 7394/16329 [1:02:17<1:13:45,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7394: train loss 1.61718. lr 5.272362e-04:  45%|████▌     | 7395/16329 [1:02:17<1:13:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7395: train loss 1.71836. lr 5.272174e-04:  45%|████▌     | 7395/16329 [1:02:18<1:13:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7395: train loss 1.71836. lr 5.272174e-04:  45%|████▌     | 7396/16329 [1:02:18<1:13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7396: train loss 1.68708. lr 5.271985e-04:  45%|████▌     | 7396/16329 [1:02:18<1:13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7396: train loss 1.68708. lr 5.271985e-04:  45%|████▌     | 7397/16329 [1:02:18<1:13:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7397: train loss 1.65808. lr 5.271797e-04:  45%|████▌     | 7397/16329 [1:02:19<1:13:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7397: train loss 1.65808. lr 5.271797e-04:  45%|████▌     | 7398/16329 [1:02:19<1:13:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7398: train loss 1.62732. lr 5.271608e-04:  45%|████▌     | 7398/16329 [1:02:19<1:13:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7398: train loss 1.62732. lr 5.271608e-04:  45%|████▌     | 7399/16329 [1:02:19<1:13:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7399: train loss 1.59177. lr 5.271420e-04:  45%|████▌     | 7399/16329 [1:02:19<1:13:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7399: train loss 1.59177. lr 5.271420e-04:  45%|████▌     | 7400/16329 [1:02:19<1:13:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7400: train loss 1.75088. lr 5.271231e-04:  45%|████▌     | 7400/16329 [1:02:20<1:13:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7400: train loss 1.75088. lr 5.271231e-04:  45%|████▌     | 7401/16329 [1:02:20<1:21:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7401: train loss 1.67144. lr 5.271043e-04:  45%|████▌     | 7401/16329 [1:02:21<1:21:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7401: train loss 1.67144. lr 5.271043e-04:  45%|████▌     | 7402/16329 [1:02:21<1:19:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7402: train loss 1.66808. lr 5.270854e-04:  45%|████▌     | 7402/16329 [1:02:21<1:19:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7402: train loss 1.66808. lr 5.270854e-04:  45%|████▌     | 7403/16329 [1:02:21<1:17:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7403: train loss 1.65560. lr 5.270666e-04:  45%|████▌     | 7403/16329 [1:02:22<1:17:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7403: train loss 1.65560. lr 5.270666e-04:  45%|████▌     | 7404/16329 [1:02:22<1:16:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7404: train loss 1.63491. lr 5.270477e-04:  45%|████▌     | 7404/16329 [1:02:22<1:16:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7404: train loss 1.63491. lr 5.270477e-04:  45%|████▌     | 7405/16329 [1:02:22<1:15:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7405: train loss 1.68956. lr 5.270288e-04:  45%|████▌     | 7405/16329 [1:02:23<1:15:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7405: train loss 1.68956. lr 5.270288e-04:  45%|████▌     | 7406/16329 [1:02:23<1:15:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7406: train loss 1.64091. lr 5.270100e-04:  45%|████▌     | 7406/16329 [1:02:23<1:15:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7406: train loss 1.64091. lr 5.270100e-04:  45%|████▌     | 7407/16329 [1:02:23<1:14:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7407: train loss 1.62838. lr 5.269911e-04:  45%|████▌     | 7407/16329 [1:02:24<1:14:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7407: train loss 1.62838. lr 5.269911e-04:  45%|████▌     | 7408/16329 [1:02:24<1:14:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7408: train loss 1.64356. lr 5.269722e-04:  45%|████▌     | 7408/16329 [1:02:24<1:14:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7408: train loss 1.64356. lr 5.269722e-04:  45%|████▌     | 7409/16329 [1:02:24<1:14:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7409: train loss 1.65067. lr 5.269533e-04:  45%|████▌     | 7409/16329 [1:02:25<1:14:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7409: train loss 1.65067. lr 5.269533e-04:  45%|████▌     | 7410/16329 [1:02:25<1:13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7410: train loss 1.67508. lr 5.269345e-04:  45%|████▌     | 7410/16329 [1:02:25<1:13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7410: train loss 1.67508. lr 5.269345e-04:  45%|████▌     | 7411/16329 [1:02:25<1:14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7411: train loss 1.65299. lr 5.269156e-04:  45%|████▌     | 7411/16329 [1:02:26<1:14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7411: train loss 1.65299. lr 5.269156e-04:  45%|████▌     | 7412/16329 [1:02:26<1:13:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7412: train loss 1.65017. lr 5.268967e-04:  45%|████▌     | 7412/16329 [1:02:26<1:13:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7412: train loss 1.65017. lr 5.268967e-04:  45%|████▌     | 7413/16329 [1:02:26<1:13:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7413: train loss 1.66390. lr 5.268778e-04:  45%|████▌     | 7413/16329 [1:02:27<1:13:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7413: train loss 1.66390. lr 5.268778e-04:  45%|████▌     | 7414/16329 [1:02:27<1:13:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7414: train loss 1.66243. lr 5.268589e-04:  45%|████▌     | 7414/16329 [1:02:27<1:13:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7414: train loss 1.66243. lr 5.268589e-04:  45%|████▌     | 7415/16329 [1:02:27<1:13:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7415: train loss 1.67307. lr 5.268401e-04:  45%|████▌     | 7415/16329 [1:02:28<1:13:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7415: train loss 1.67307. lr 5.268401e-04:  45%|████▌     | 7416/16329 [1:02:28<1:13:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7416: train loss 1.64933. lr 5.268212e-04:  45%|████▌     | 7416/16329 [1:02:28<1:13:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7416: train loss 1.64933. lr 5.268212e-04:  45%|████▌     | 7417/16329 [1:02:28<1:13:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7417: train loss 1.64569. lr 5.268023e-04:  45%|████▌     | 7417/16329 [1:02:29<1:13:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7417: train loss 1.64569. lr 5.268023e-04:  45%|████▌     | 7418/16329 [1:02:29<1:13:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7418: train loss 1.66172. lr 5.267834e-04:  45%|████▌     | 7418/16329 [1:02:29<1:13:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7418: train loss 1.66172. lr 5.267834e-04:  45%|████▌     | 7419/16329 [1:02:29<1:13:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7419: train loss 1.60155. lr 5.267645e-04:  45%|████▌     | 7419/16329 [1:02:30<1:13:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7419: train loss 1.60155. lr 5.267645e-04:  45%|████▌     | 7420/16329 [1:02:30<1:13:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7420: train loss 1.61860. lr 5.267456e-04:  45%|████▌     | 7420/16329 [1:02:30<1:13:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7420: train loss 1.61860. lr 5.267456e-04:  45%|████▌     | 7421/16329 [1:02:30<1:13:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7421: train loss 1.66938. lr 5.267267e-04:  45%|████▌     | 7421/16329 [1:02:31<1:13:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7421: train loss 1.66938. lr 5.267267e-04:  45%|████▌     | 7422/16329 [1:02:31<1:13:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7422: train loss 1.59521. lr 5.267078e-04:  45%|████▌     | 7422/16329 [1:02:31<1:13:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7422: train loss 1.59521. lr 5.267078e-04:  45%|████▌     | 7423/16329 [1:02:31<1:13:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7423: train loss 1.64746. lr 5.266889e-04:  45%|████▌     | 7423/16329 [1:02:32<1:13:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7423: train loss 1.64746. lr 5.266889e-04:  45%|████▌     | 7424/16329 [1:02:32<1:13:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7424: train loss 1.64049. lr 5.266700e-04:  45%|████▌     | 7424/16329 [1:02:32<1:13:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7424: train loss 1.64049. lr 5.266700e-04:  45%|████▌     | 7425/16329 [1:02:32<1:13:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7425: train loss 1.68011. lr 5.266511e-04:  45%|████▌     | 7425/16329 [1:02:33<1:13:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7425: train loss 1.68011. lr 5.266511e-04:  45%|████▌     | 7426/16329 [1:02:33<1:14:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7426: train loss 1.68103. lr 5.266322e-04:  45%|████▌     | 7426/16329 [1:02:33<1:14:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7426: train loss 1.68103. lr 5.266322e-04:  45%|████▌     | 7427/16329 [1:02:33<1:14:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7427: train loss 1.62980. lr 5.266133e-04:  45%|████▌     | 7427/16329 [1:02:34<1:14:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7427: train loss 1.62980. lr 5.266133e-04:  45%|████▌     | 7428/16329 [1:02:34<1:14:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7428: train loss 1.66096. lr 5.265944e-04:  45%|████▌     | 7428/16329 [1:02:34<1:14:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7428: train loss 1.66096. lr 5.265944e-04:  45%|████▌     | 7429/16329 [1:02:34<1:14:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7429: train loss 1.69830. lr 5.265754e-04:  45%|████▌     | 7429/16329 [1:02:35<1:14:18,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7429: train loss 1.69830. lr 5.265754e-04:  46%|████▌     | 7430/16329 [1:02:35<1:13:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7430: train loss 1.64921. lr 5.265565e-04:  46%|████▌     | 7430/16329 [1:02:35<1:13:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7430: train loss 1.64921. lr 5.265565e-04:  46%|████▌     | 7431/16329 [1:02:35<1:13:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7431: train loss 1.65224. lr 5.265376e-04:  46%|████▌     | 7431/16329 [1:02:36<1:13:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7431: train loss 1.65224. lr 5.265376e-04:  46%|████▌     | 7432/16329 [1:02:36<1:16:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7432: train loss 1.64697. lr 5.265187e-04:  46%|████▌     | 7432/16329 [1:02:36<1:16:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7432: train loss 1.64697. lr 5.265187e-04:  46%|████▌     | 7433/16329 [1:02:36<1:17:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7433: train loss 1.63662. lr 5.264998e-04:  46%|████▌     | 7433/16329 [1:02:37<1:17:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7433: train loss 1.63662. lr 5.264998e-04:  46%|████▌     | 7434/16329 [1:02:37<1:18:19,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7434: train loss 1.63925. lr 5.264808e-04:  46%|████▌     | 7434/16329 [1:02:37<1:18:19,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7434: train loss 1.63925. lr 5.264808e-04:  46%|████▌     | 7435/16329 [1:02:37<1:18:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7435: train loss 1.65450. lr 5.264619e-04:  46%|████▌     | 7435/16329 [1:02:38<1:18:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7435: train loss 1.65450. lr 5.264619e-04:  46%|████▌     | 7436/16329 [1:02:38<1:25:11,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 7436: train loss 1.66250. lr 5.264430e-04:  46%|████▌     | 7436/16329 [1:02:38<1:25:11,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 7436: train loss 1.66250. lr 5.264430e-04:  46%|████▌     | 7437/16329 [1:02:38<1:22:06,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 7437: train loss 1.64517. lr 5.264240e-04:  46%|████▌     | 7437/16329 [1:02:39<1:22:06,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 7437: train loss 1.64517. lr 5.264240e-04:  46%|████▌     | 7438/16329 [1:02:39<1:19:51,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7438: train loss 1.64511. lr 5.264051e-04:  46%|████▌     | 7438/16329 [1:02:39<1:19:51,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7438: train loss 1.64511. lr 5.264051e-04:  46%|████▌     | 7439/16329 [1:02:39<1:18:09,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7439: train loss 1.67608. lr 5.263862e-04:  46%|████▌     | 7439/16329 [1:02:40<1:18:09,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7439: train loss 1.67608. lr 5.263862e-04:  46%|████▌     | 7440/16329 [1:02:40<1:16:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7440: train loss 1.65940. lr 5.263672e-04:  46%|████▌     | 7440/16329 [1:02:40<1:16:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7440: train loss 1.65940. lr 5.263672e-04:  46%|████▌     | 7441/16329 [1:02:40<1:15:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7441: train loss 1.67431. lr 5.263483e-04:  46%|████▌     | 7441/16329 [1:02:41<1:15:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7441: train loss 1.67431. lr 5.263483e-04:  46%|████▌     | 7442/16329 [1:02:41<1:14:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7442: train loss 1.65767. lr 5.263294e-04:  46%|████▌     | 7442/16329 [1:02:41<1:14:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7442: train loss 1.65767. lr 5.263294e-04:  46%|████▌     | 7443/16329 [1:02:41<1:14:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7443: train loss 1.65904. lr 5.263104e-04:  46%|████▌     | 7443/16329 [1:02:42<1:14:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7443: train loss 1.65904. lr 5.263104e-04:  46%|████▌     | 7444/16329 [1:02:42<1:14:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7444: train loss 1.71776. lr 5.262915e-04:  46%|████▌     | 7444/16329 [1:02:42<1:14:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7444: train loss 1.71776. lr 5.262915e-04:  46%|████▌     | 7445/16329 [1:02:42<1:13:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7445: train loss 1.63244. lr 5.262725e-04:  46%|████▌     | 7445/16329 [1:02:43<1:13:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7445: train loss 1.63244. lr 5.262725e-04:  46%|████▌     | 7446/16329 [1:02:43<1:13:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7446: train loss 1.64592. lr 5.262536e-04:  46%|████▌     | 7446/16329 [1:02:43<1:13:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7446: train loss 1.64592. lr 5.262536e-04:  46%|████▌     | 7447/16329 [1:02:43<1:13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7447: train loss 1.66907. lr 5.262346e-04:  46%|████▌     | 7447/16329 [1:02:44<1:13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7447: train loss 1.66907. lr 5.262346e-04:  46%|████▌     | 7448/16329 [1:02:44<1:13:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7448: train loss 1.67802. lr 5.262157e-04:  46%|████▌     | 7448/16329 [1:02:44<1:13:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7448: train loss 1.67802. lr 5.262157e-04:  46%|████▌     | 7449/16329 [1:02:44<1:13:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7449: train loss 1.66187. lr 5.261967e-04:  46%|████▌     | 7449/16329 [1:02:45<1:13:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7449: train loss 1.66187. lr 5.261967e-04:  46%|████▌     | 7450/16329 [1:02:45<1:13:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7450: train loss 1.72302. lr 5.261777e-04:  46%|████▌     | 7450/16329 [1:02:45<1:13:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7450: train loss 1.72302. lr 5.261777e-04:  46%|████▌     | 7451/16329 [1:02:45<1:13:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7451: train loss 1.63755. lr 5.261588e-04:  46%|████▌     | 7451/16329 [1:02:46<1:13:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7451: train loss 1.63755. lr 5.261588e-04:  46%|████▌     | 7452/16329 [1:02:46<1:13:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7452: train loss 1.69173. lr 5.261398e-04:  46%|████▌     | 7452/16329 [1:02:46<1:13:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7452: train loss 1.69173. lr 5.261398e-04:  46%|████▌     | 7453/16329 [1:02:46<1:13:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7453: train loss 1.65483. lr 5.261209e-04:  46%|████▌     | 7453/16329 [1:02:47<1:13:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7453: train loss 1.65483. lr 5.261209e-04:  46%|████▌     | 7454/16329 [1:02:47<1:13:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7454: train loss 1.64397. lr 5.261019e-04:  46%|████▌     | 7454/16329 [1:02:47<1:13:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7454: train loss 1.64397. lr 5.261019e-04:  46%|████▌     | 7455/16329 [1:02:47<1:13:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7455: train loss 1.65872. lr 5.260829e-04:  46%|████▌     | 7455/16329 [1:02:48<1:13:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7455: train loss 1.65872. lr 5.260829e-04:  46%|████▌     | 7456/16329 [1:02:48<1:13:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7456: train loss 1.64783. lr 5.260639e-04:  46%|████▌     | 7456/16329 [1:02:48<1:13:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7456: train loss 1.64783. lr 5.260639e-04:  46%|████▌     | 7457/16329 [1:02:48<1:13:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7457: train loss 1.61153. lr 5.260450e-04:  46%|████▌     | 7457/16329 [1:02:49<1:13:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7457: train loss 1.61153. lr 5.260450e-04:  46%|████▌     | 7458/16329 [1:02:49<1:13:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7458: train loss 1.64107. lr 5.260260e-04:  46%|████▌     | 7458/16329 [1:02:49<1:13:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7458: train loss 1.64107. lr 5.260260e-04:  46%|████▌     | 7459/16329 [1:02:49<1:13:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7459: train loss 1.70982. lr 5.260070e-04:  46%|████▌     | 7459/16329 [1:02:50<1:13:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7459: train loss 1.70982. lr 5.260070e-04:  46%|████▌     | 7460/16329 [1:02:50<1:13:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7460: train loss 1.69952. lr 5.259880e-04:  46%|████▌     | 7460/16329 [1:02:51<1:13:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7460: train loss 1.69952. lr 5.259880e-04:  46%|████▌     | 7461/16329 [1:02:51<1:21:08,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7461: train loss 1.65124. lr 5.259691e-04:  46%|████▌     | 7461/16329 [1:02:51<1:21:08,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7461: train loss 1.65124. lr 5.259691e-04:  46%|████▌     | 7462/16329 [1:02:51<1:18:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7462: train loss 1.63778. lr 5.259501e-04:  46%|████▌     | 7462/16329 [1:02:52<1:18:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7462: train loss 1.63778. lr 5.259501e-04:  46%|████▌     | 7463/16329 [1:02:52<1:17:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7463: train loss 1.67172. lr 5.259311e-04:  46%|████▌     | 7463/16329 [1:02:52<1:17:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7463: train loss 1.67172. lr 5.259311e-04:  46%|████▌     | 7464/16329 [1:02:52<1:15:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7464: train loss 1.67779. lr 5.259121e-04:  46%|████▌     | 7464/16329 [1:02:52<1:15:56,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7464: train loss 1.67779. lr 5.259121e-04:  46%|████▌     | 7465/16329 [1:02:52<1:15:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7465: train loss 1.64127. lr 5.258931e-04:  46%|████▌     | 7465/16329 [1:02:53<1:15:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7465: train loss 1.64127. lr 5.258931e-04:  46%|████▌     | 7466/16329 [1:02:53<1:14:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7466: train loss 1.68301. lr 5.258741e-04:  46%|████▌     | 7466/16329 [1:02:53<1:14:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7466: train loss 1.68301. lr 5.258741e-04:  46%|████▌     | 7467/16329 [1:02:53<1:13:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7467: train loss 1.67431. lr 5.258551e-04:  46%|████▌     | 7467/16329 [1:02:54<1:13:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7467: train loss 1.67431. lr 5.258551e-04:  46%|████▌     | 7468/16329 [1:02:54<1:13:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7468: train loss 1.64866. lr 5.258361e-04:  46%|████▌     | 7468/16329 [1:02:54<1:13:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7468: train loss 1.64866. lr 5.258361e-04:  46%|████▌     | 7469/16329 [1:02:54<1:13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7469: train loss 1.62785. lr 5.258171e-04:  46%|████▌     | 7469/16329 [1:02:55<1:13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7469: train loss 1.62785. lr 5.258171e-04:  46%|████▌     | 7470/16329 [1:02:55<1:13:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7470: train loss 1.70760. lr 5.257981e-04:  46%|████▌     | 7470/16329 [1:02:55<1:13:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7470: train loss 1.70760. lr 5.257981e-04:  46%|████▌     | 7471/16329 [1:02:55<1:13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7471: train loss 1.62733. lr 5.257791e-04:  46%|████▌     | 7471/16329 [1:02:56<1:13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7471: train loss 1.62733. lr 5.257791e-04:  46%|████▌     | 7472/16329 [1:02:56<1:13:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7472: train loss 1.62539. lr 5.257601e-04:  46%|████▌     | 7472/16329 [1:02:57<1:13:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7472: train loss 1.62539. lr 5.257601e-04:  46%|████▌     | 7473/16329 [1:02:57<1:16:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7473: train loss 1.68035. lr 5.257411e-04:  46%|████▌     | 7473/16329 [1:02:57<1:16:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7473: train loss 1.68035. lr 5.257411e-04:  46%|████▌     | 7474/16329 [1:02:57<1:18:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7474: train loss 1.61147. lr 5.257221e-04:  46%|████▌     | 7474/16329 [1:02:58<1:18:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7474: train loss 1.61147. lr 5.257221e-04:  46%|████▌     | 7475/16329 [1:02:58<1:19:17,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7475: train loss 1.63779. lr 5.257031e-04:  46%|████▌     | 7475/16329 [1:02:58<1:19:17,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7475: train loss 1.63779. lr 5.257031e-04:  46%|████▌     | 7476/16329 [1:02:58<1:19:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7476: train loss 1.65978. lr 5.256841e-04:  46%|████▌     | 7476/16329 [1:02:59<1:19:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7476: train loss 1.65978. lr 5.256841e-04:  46%|████▌     | 7477/16329 [1:02:59<1:18:33,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7477: train loss 1.61391. lr 5.256651e-04:  46%|████▌     | 7477/16329 [1:02:59<1:18:33,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7477: train loss 1.61391. lr 5.256651e-04:  46%|████▌     | 7478/16329 [1:02:59<1:17:56,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7478: train loss 1.70897. lr 5.256460e-04:  46%|████▌     | 7478/16329 [1:03:00<1:17:56,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7478: train loss 1.70897. lr 5.256460e-04:  46%|████▌     | 7479/16329 [1:03:00<1:17:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7479: train loss 1.63869. lr 5.256270e-04:  46%|████▌     | 7479/16329 [1:03:00<1:17:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7479: train loss 1.63869. lr 5.256270e-04:  46%|████▌     | 7480/16329 [1:03:00<1:16:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7480: train loss 1.66900. lr 5.256080e-04:  46%|████▌     | 7480/16329 [1:03:01<1:16:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7480: train loss 1.66900. lr 5.256080e-04:  46%|████▌     | 7481/16329 [1:03:01<1:15:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7481: train loss 1.62594. lr 5.255890e-04:  46%|████▌     | 7481/16329 [1:03:01<1:15:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7481: train loss 1.62594. lr 5.255890e-04:  46%|████▌     | 7482/16329 [1:03:01<1:14:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7482: train loss 1.64927. lr 5.255700e-04:  46%|████▌     | 7482/16329 [1:03:02<1:14:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7482: train loss 1.64927. lr 5.255700e-04:  46%|████▌     | 7483/16329 [1:03:02<1:14:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7483: train loss 1.69350. lr 5.255509e-04:  46%|████▌     | 7483/16329 [1:03:02<1:14:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7483: train loss 1.69350. lr 5.255509e-04:  46%|████▌     | 7484/16329 [1:03:02<1:13:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7484: train loss 1.68664. lr 5.255319e-04:  46%|████▌     | 7484/16329 [1:03:03<1:13:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7484: train loss 1.68664. lr 5.255319e-04:  46%|████▌     | 7485/16329 [1:03:03<1:13:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7485: train loss 1.66143. lr 5.255129e-04:  46%|████▌     | 7485/16329 [1:03:03<1:13:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7485: train loss 1.66143. lr 5.255129e-04:  46%|████▌     | 7486/16329 [1:03:03<1:13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7486: train loss 1.63144. lr 5.254938e-04:  46%|████▌     | 7486/16329 [1:03:04<1:13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7486: train loss 1.63144. lr 5.254938e-04:  46%|████▌     | 7487/16329 [1:03:04<1:13:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7487: train loss 1.65650. lr 5.254748e-04:  46%|████▌     | 7487/16329 [1:03:04<1:13:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7487: train loss 1.65650. lr 5.254748e-04:  46%|████▌     | 7488/16329 [1:03:04<1:21:05,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7488: train loss 1.63904. lr 5.254558e-04:  46%|████▌     | 7488/16329 [1:03:05<1:21:05,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7488: train loss 1.63904. lr 5.254558e-04:  46%|████▌     | 7489/16329 [1:03:05<1:18:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7489: train loss 1.64940. lr 5.254367e-04:  46%|████▌     | 7489/16329 [1:03:05<1:18:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7489: train loss 1.64940. lr 5.254367e-04:  46%|████▌     | 7490/16329 [1:03:05<1:16:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7490: train loss 1.62866. lr 5.254177e-04:  46%|████▌     | 7490/16329 [1:03:06<1:16:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7490: train loss 1.62866. lr 5.254177e-04:  46%|████▌     | 7491/16329 [1:03:06<1:15:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7491: train loss 1.64246. lr 5.253986e-04:  46%|████▌     | 7491/16329 [1:03:06<1:15:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7491: train loss 1.64246. lr 5.253986e-04:  46%|████▌     | 7492/16329 [1:03:06<1:14:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7492: train loss 1.63706. lr 5.253796e-04:  46%|████▌     | 7492/16329 [1:03:07<1:14:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7492: train loss 1.63706. lr 5.253796e-04:  46%|████▌     | 7493/16329 [1:03:07<1:14:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7493: train loss 1.63657. lr 5.253605e-04:  46%|████▌     | 7493/16329 [1:03:07<1:14:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7493: train loss 1.63657. lr 5.253605e-04:  46%|████▌     | 7494/16329 [1:03:07<1:13:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7494: train loss 1.63366. lr 5.253415e-04:  46%|████▌     | 7494/16329 [1:03:08<1:13:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7494: train loss 1.63366. lr 5.253415e-04:  46%|████▌     | 7495/16329 [1:03:08<1:13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7495: train loss 1.64789. lr 5.253224e-04:  46%|████▌     | 7495/16329 [1:03:08<1:13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7495: train loss 1.64789. lr 5.253224e-04:  46%|████▌     | 7496/16329 [1:03:08<1:13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7496: train loss 1.64018. lr 5.253034e-04:  46%|████▌     | 7496/16329 [1:03:09<1:13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7496: train loss 1.64018. lr 5.253034e-04:  46%|████▌     | 7497/16329 [1:03:09<1:12:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7497: train loss 1.64870. lr 5.252843e-04:  46%|████▌     | 7497/16329 [1:03:09<1:12:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7497: train loss 1.64870. lr 5.252843e-04:  46%|████▌     | 7498/16329 [1:03:09<1:13:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7498: train loss 1.62736. lr 5.252653e-04:  46%|████▌     | 7498/16329 [1:03:10<1:13:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7498: train loss 1.62736. lr 5.252653e-04:  46%|████▌     | 7499/16329 [1:03:10<1:13:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7499: train loss 1.65168. lr 5.252462e-04:  46%|████▌     | 7499/16329 [1:03:10<1:13:11,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7499: train loss 1.65168. lr 5.252462e-04:  46%|████▌     | 7500/16329 [1:03:10<1:13:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7500: train loss 1.65749. lr 5.252271e-04:  46%|████▌     | 7500/16329 [1:03:11<1:13:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7500: train loss 1.65749. lr 5.252271e-04:  46%|████▌     | 7501/16329 [1:03:11<1:13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7501: train loss 1.63556. lr 5.252081e-04:  46%|████▌     | 7501/16329 [1:03:11<1:13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7501: train loss 1.63556. lr 5.252081e-04:  46%|████▌     | 7502/16329 [1:03:11<1:12:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7502: train loss 1.61037. lr 5.251890e-04:  46%|████▌     | 7502/16329 [1:03:12<1:12:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7502: train loss 1.61037. lr 5.251890e-04:  46%|████▌     | 7503/16329 [1:03:12<1:15:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7503: train loss 1.62295. lr 5.251699e-04:  46%|████▌     | 7503/16329 [1:03:12<1:15:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7503: train loss 1.62295. lr 5.251699e-04:  46%|████▌     | 7504/16329 [1:03:12<1:17:38,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7504: train loss 1.68376. lr 5.251509e-04:  46%|████▌     | 7504/16329 [1:03:13<1:17:38,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7504: train loss 1.68376. lr 5.251509e-04:  46%|████▌     | 7505/16329 [1:03:13<1:18:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7505: train loss 1.65875. lr 5.251318e-04:  46%|████▌     | 7505/16329 [1:03:13<1:18:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7505: train loss 1.65875. lr 5.251318e-04:  46%|████▌     | 7506/16329 [1:03:13<1:17:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7506: train loss 1.62124. lr 5.251127e-04:  46%|████▌     | 7506/16329 [1:03:14<1:17:37,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7506: train loss 1.62124. lr 5.251127e-04:  46%|████▌     | 7507/16329 [1:03:14<1:16:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7507: train loss 1.59112. lr 5.250936e-04:  46%|████▌     | 7507/16329 [1:03:15<1:16:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7507: train loss 1.59112. lr 5.250936e-04:  46%|████▌     | 7508/16329 [1:03:15<1:16:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7508: train loss 1.70556. lr 5.250745e-04:  46%|████▌     | 7508/16329 [1:03:15<1:16:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7508: train loss 1.70556. lr 5.250745e-04:  46%|████▌     | 7509/16329 [1:03:15<1:15:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7509: train loss 1.65177. lr 5.250555e-04:  46%|████▌     | 7509/16329 [1:03:16<1:15:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7509: train loss 1.65177. lr 5.250555e-04:  46%|████▌     | 7510/16329 [1:03:16<1:14:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7510: train loss 1.67000. lr 5.250364e-04:  46%|████▌     | 7510/16329 [1:03:16<1:14:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7510: train loss 1.67000. lr 5.250364e-04:  46%|████▌     | 7511/16329 [1:03:16<1:14:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7511: train loss 1.62294. lr 5.250173e-04:  46%|████▌     | 7511/16329 [1:03:17<1:14:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7511: train loss 1.62294. lr 5.250173e-04:  46%|████▌     | 7512/16329 [1:03:17<1:13:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7512: train loss 1.66666. lr 5.249982e-04:  46%|████▌     | 7512/16329 [1:03:17<1:13:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7512: train loss 1.66666. lr 5.249982e-04:  46%|████▌     | 7513/16329 [1:03:17<1:13:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7513: train loss 1.65790. lr 5.249791e-04:  46%|████▌     | 7513/16329 [1:03:18<1:13:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7513: train loss 1.65790. lr 5.249791e-04:  46%|████▌     | 7514/16329 [1:03:18<1:13:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7514: train loss 1.60426. lr 5.249600e-04:  46%|████▌     | 7514/16329 [1:03:18<1:13:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7514: train loss 1.60426. lr 5.249600e-04:  46%|████▌     | 7515/16329 [1:03:18<1:13:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7515: train loss 1.60890. lr 5.249409e-04:  46%|████▌     | 7515/16329 [1:03:18<1:13:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7515: train loss 1.60890. lr 5.249409e-04:  46%|████▌     | 7516/16329 [1:03:18<1:12:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7516: train loss 1.66055. lr 5.249218e-04:  46%|████▌     | 7516/16329 [1:03:19<1:12:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7516: train loss 1.66055. lr 5.249218e-04:  46%|████▌     | 7517/16329 [1:03:19<1:13:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7517: train loss 1.65441. lr 5.249027e-04:  46%|████▌     | 7517/16329 [1:03:19<1:13:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7517: train loss 1.65441. lr 5.249027e-04:  46%|████▌     | 7518/16329 [1:03:19<1:12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7518: train loss 1.65386. lr 5.248836e-04:  46%|████▌     | 7518/16329 [1:03:20<1:12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7518: train loss 1.65386. lr 5.248836e-04:  46%|████▌     | 7519/16329 [1:03:20<1:12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7519: train loss 1.70078. lr 5.248645e-04:  46%|████▌     | 7519/16329 [1:03:20<1:12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7519: train loss 1.70078. lr 5.248645e-04:  46%|████▌     | 7520/16329 [1:03:20<1:12:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7520: train loss 1.66511. lr 5.248454e-04:  46%|████▌     | 7520/16329 [1:03:21<1:12:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7520: train loss 1.66511. lr 5.248454e-04:  46%|████▌     | 7521/16329 [1:03:21<1:12:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7521: train loss 1.64186. lr 5.248263e-04:  46%|████▌     | 7521/16329 [1:03:21<1:12:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7521: train loss 1.64186. lr 5.248263e-04:  46%|████▌     | 7522/16329 [1:03:21<1:12:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7522: train loss 1.59519. lr 5.248072e-04:  46%|████▌     | 7522/16329 [1:03:22<1:12:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7522: train loss 1.59519. lr 5.248072e-04:  46%|████▌     | 7523/16329 [1:03:22<1:12:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7523: train loss 1.63552. lr 5.247881e-04:  46%|████▌     | 7523/16329 [1:03:22<1:12:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7523: train loss 1.63552. lr 5.247881e-04:  46%|████▌     | 7524/16329 [1:03:22<1:12:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7524: train loss 1.65729. lr 5.247690e-04:  46%|████▌     | 7524/16329 [1:03:23<1:12:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7524: train loss 1.65729. lr 5.247690e-04:  46%|████▌     | 7525/16329 [1:03:23<1:12:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7525: train loss 1.64288. lr 5.247499e-04:  46%|████▌     | 7525/16329 [1:03:23<1:12:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7525: train loss 1.64288. lr 5.247499e-04:  46%|████▌     | 7526/16329 [1:03:23<1:12:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7526: train loss 1.62133. lr 5.247307e-04:  46%|████▌     | 7526/16329 [1:03:24<1:12:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7526: train loss 1.62133. lr 5.247307e-04:  46%|████▌     | 7527/16329 [1:03:24<1:12:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7527: train loss 1.64739. lr 5.247116e-04:  46%|████▌     | 7527/16329 [1:03:25<1:12:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7527: train loss 1.64739. lr 5.247116e-04:  46%|████▌     | 7528/16329 [1:03:25<1:20:06,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7528: train loss 1.60517. lr 5.246925e-04:  46%|████▌     | 7528/16329 [1:03:25<1:20:06,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 7528: train loss 1.60517. lr 5.246925e-04:  46%|████▌     | 7529/16329 [1:03:25<1:18:00,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7529: train loss 1.67364. lr 5.246734e-04:  46%|████▌     | 7529/16329 [1:03:26<1:18:00,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7529: train loss 1.67364. lr 5.246734e-04:  46%|████▌     | 7530/16329 [1:03:26<1:16:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7530: train loss 1.63055. lr 5.246543e-04:  46%|████▌     | 7530/16329 [1:03:26<1:16:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7530: train loss 1.63055. lr 5.246543e-04:  46%|████▌     | 7531/16329 [1:03:26<1:15:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7531: train loss 1.65478. lr 5.246351e-04:  46%|████▌     | 7531/16329 [1:03:27<1:15:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7531: train loss 1.65478. lr 5.246351e-04:  46%|████▌     | 7532/16329 [1:03:27<1:14:25,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7532: train loss 1.69937. lr 5.246160e-04:  46%|████▌     | 7532/16329 [1:03:27<1:14:25,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7532: train loss 1.69937. lr 5.246160e-04:  46%|████▌     | 7533/16329 [1:03:27<1:13:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7533: train loss 1.62035. lr 5.245969e-04:  46%|████▌     | 7533/16329 [1:03:28<1:13:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7533: train loss 1.62035. lr 5.245969e-04:  46%|████▌     | 7534/16329 [1:03:28<1:13:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7534: train loss 1.63461. lr 5.245777e-04:  46%|████▌     | 7534/16329 [1:03:28<1:13:28,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7534: train loss 1.63461. lr 5.245777e-04:  46%|████▌     | 7535/16329 [1:03:28<1:13:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7535: train loss 1.64858. lr 5.245586e-04:  46%|████▌     | 7535/16329 [1:03:29<1:13:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7535: train loss 1.64858. lr 5.245586e-04:  46%|████▌     | 7536/16329 [1:03:29<1:13:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7536: train loss 1.64796. lr 5.245395e-04:  46%|████▌     | 7536/16329 [1:03:29<1:13:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7536: train loss 1.64796. lr 5.245395e-04:  46%|████▌     | 7537/16329 [1:03:29<1:12:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7537: train loss 1.66700. lr 5.245203e-04:  46%|████▌     | 7537/16329 [1:03:30<1:12:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7537: train loss 1.66700. lr 5.245203e-04:  46%|████▌     | 7538/16329 [1:03:30<1:12:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7538: train loss 1.68293. lr 5.245012e-04:  46%|████▌     | 7538/16329 [1:03:30<1:12:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7538: train loss 1.68293. lr 5.245012e-04:  46%|████▌     | 7539/16329 [1:03:30<1:12:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7539: train loss 1.67046. lr 5.244820e-04:  46%|████▌     | 7539/16329 [1:03:31<1:12:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7539: train loss 1.67046. lr 5.244820e-04:  46%|████▌     | 7540/16329 [1:03:31<1:12:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7540: train loss 1.63774. lr 5.244629e-04:  46%|████▌     | 7540/16329 [1:03:31<1:12:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7540: train loss 1.63774. lr 5.244629e-04:  46%|████▌     | 7541/16329 [1:03:31<1:12:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7541: train loss 1.61823. lr 5.244437e-04:  46%|████▌     | 7541/16329 [1:03:32<1:12:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7541: train loss 1.61823. lr 5.244437e-04:  46%|████▌     | 7542/16329 [1:03:32<1:12:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7542: train loss 1.65467. lr 5.244246e-04:  46%|████▌     | 7542/16329 [1:03:32<1:12:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7542: train loss 1.65467. lr 5.244246e-04:  46%|████▌     | 7543/16329 [1:03:32<1:12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7543: train loss 1.67729. lr 5.244054e-04:  46%|████▌     | 7543/16329 [1:03:33<1:12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7543: train loss 1.67729. lr 5.244054e-04:  46%|████▌     | 7544/16329 [1:03:33<1:12:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7544: train loss 1.66543. lr 5.243863e-04:  46%|████▌     | 7544/16329 [1:03:33<1:12:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7544: train loss 1.66543. lr 5.243863e-04:  46%|████▌     | 7545/16329 [1:03:33<1:12:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7545: train loss 1.68335. lr 5.243671e-04:  46%|████▌     | 7545/16329 [1:03:34<1:12:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7545: train loss 1.68335. lr 5.243671e-04:  46%|████▌     | 7546/16329 [1:03:34<1:12:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7546: train loss 1.62989. lr 5.243480e-04:  46%|████▌     | 7546/16329 [1:03:34<1:12:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7546: train loss 1.62989. lr 5.243480e-04:  46%|████▌     | 7547/16329 [1:03:34<1:12:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7547: train loss 1.59322. lr 5.243288e-04:  46%|████▌     | 7547/16329 [1:03:35<1:12:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7547: train loss 1.59322. lr 5.243288e-04:  46%|████▌     | 7548/16329 [1:03:35<1:12:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7548: train loss 1.61961. lr 5.243096e-04:  46%|████▌     | 7548/16329 [1:03:35<1:12:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7548: train loss 1.61961. lr 5.243096e-04:  46%|████▌     | 7549/16329 [1:03:35<1:12:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7549: train loss 1.62690. lr 5.242905e-04:  46%|████▌     | 7549/16329 [1:03:36<1:12:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7549: train loss 1.62690. lr 5.242905e-04:  46%|████▌     | 7550/16329 [1:03:36<1:12:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7550: train loss 1.61000. lr 5.242713e-04:  46%|████▌     | 7550/16329 [1:03:36<1:12:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7550: train loss 1.61000. lr 5.242713e-04:  46%|████▌     | 7551/16329 [1:03:36<1:12:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7551: train loss 1.63978. lr 5.242521e-04:  46%|████▌     | 7551/16329 [1:03:36<1:12:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7551: train loss 1.63978. lr 5.242521e-04:  46%|████▌     | 7552/16329 [1:03:36<1:12:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7552: train loss 1.63270. lr 5.242330e-04:  46%|████▌     | 7552/16329 [1:03:37<1:12:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7552: train loss 1.63270. lr 5.242330e-04:  46%|████▋     | 7553/16329 [1:03:37<1:12:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7553: train loss 1.63041. lr 5.242138e-04:  46%|████▋     | 7553/16329 [1:03:37<1:12:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7553: train loss 1.63041. lr 5.242138e-04:  46%|████▋     | 7554/16329 [1:03:38<1:13:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7554: train loss 1.68103. lr 5.241946e-04:  46%|████▋     | 7554/16329 [1:03:38<1:13:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7554: train loss 1.68103. lr 5.241946e-04:  46%|████▋     | 7555/16329 [1:03:38<1:13:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7555: train loss 1.61464. lr 5.241754e-04:  46%|████▋     | 7555/16329 [1:03:38<1:13:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7555: train loss 1.61464. lr 5.241754e-04:  46%|████▋     | 7556/16329 [1:03:39<1:13:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7556: train loss 1.66700. lr 5.241563e-04:  46%|████▋     | 7556/16329 [1:03:39<1:13:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7556: train loss 1.66700. lr 5.241563e-04:  46%|████▋     | 7557/16329 [1:03:39<1:13:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7557: train loss 1.63737. lr 5.241371e-04:  46%|████▋     | 7557/16329 [1:03:39<1:13:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7557: train loss 1.63737. lr 5.241371e-04:  46%|████▋     | 7558/16329 [1:03:39<1:12:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7558: train loss 1.64363. lr 5.241179e-04:  46%|████▋     | 7558/16329 [1:03:40<1:12:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7558: train loss 1.64363. lr 5.241179e-04:  46%|████▋     | 7559/16329 [1:03:40<1:12:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7559: train loss 1.62338. lr 5.240987e-04:  46%|████▋     | 7559/16329 [1:03:41<1:12:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7559: train loss 1.62338. lr 5.240987e-04:  46%|████▋     | 7560/16329 [1:03:41<1:13:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7560: train loss 1.63948. lr 5.240795e-04:  46%|████▋     | 7560/16329 [1:03:41<1:13:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7560: train loss 1.63948. lr 5.240795e-04:  46%|████▋     | 7561/16329 [1:03:41<1:12:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7561: train loss 1.67072. lr 5.240603e-04:  46%|████▋     | 7561/16329 [1:03:41<1:12:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7561: train loss 1.67072. lr 5.240603e-04:  46%|████▋     | 7562/16329 [1:03:41<1:12:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7562: train loss 1.64388. lr 5.240411e-04:  46%|████▋     | 7562/16329 [1:03:42<1:12:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7562: train loss 1.64388. lr 5.240411e-04:  46%|████▋     | 7563/16329 [1:03:42<1:20:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7563: train loss 1.64298. lr 5.240219e-04:  46%|████▋     | 7563/16329 [1:03:43<1:20:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7563: train loss 1.64298. lr 5.240219e-04:  46%|████▋     | 7564/16329 [1:03:43<1:17:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7564: train loss 1.66129. lr 5.240027e-04:  46%|████▋     | 7564/16329 [1:03:43<1:17:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7564: train loss 1.66129. lr 5.240027e-04:  46%|████▋     | 7565/16329 [1:03:43<1:16:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7565: train loss 1.61017. lr 5.239835e-04:  46%|████▋     | 7565/16329 [1:03:44<1:16:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7565: train loss 1.61017. lr 5.239835e-04:  46%|████▋     | 7566/16329 [1:03:44<1:14:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7566: train loss 1.60407. lr 5.239643e-04:  46%|████▋     | 7566/16329 [1:03:44<1:14:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7566: train loss 1.60407. lr 5.239643e-04:  46%|████▋     | 7567/16329 [1:03:44<1:14:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7567: train loss 1.66354. lr 5.239451e-04:  46%|████▋     | 7567/16329 [1:03:45<1:14:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7567: train loss 1.66354. lr 5.239451e-04:  46%|████▋     | 7568/16329 [1:03:45<1:13:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7568: train loss 1.65383. lr 5.239259e-04:  46%|████▋     | 7568/16329 [1:03:45<1:13:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7568: train loss 1.65383. lr 5.239259e-04:  46%|████▋     | 7569/16329 [1:03:45<1:13:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7569: train loss 1.61165. lr 5.239067e-04:  46%|████▋     | 7569/16329 [1:03:46<1:13:04,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7569: train loss 1.61165. lr 5.239067e-04:  46%|████▋     | 7570/16329 [1:03:46<1:12:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7570: train loss 1.67611. lr 5.238875e-04:  46%|████▋     | 7570/16329 [1:03:46<1:12:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7570: train loss 1.67611. lr 5.238875e-04:  46%|████▋     | 7571/16329 [1:03:46<1:12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7571: train loss 1.62983. lr 5.238683e-04:  46%|████▋     | 7571/16329 [1:03:47<1:12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7571: train loss 1.62983. lr 5.238683e-04:  46%|████▋     | 7572/16329 [1:03:47<1:12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7572: train loss 1.66663. lr 5.238491e-04:  46%|████▋     | 7572/16329 [1:03:47<1:12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7572: train loss 1.66663. lr 5.238491e-04:  46%|████▋     | 7573/16329 [1:03:47<1:12:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7573: train loss 1.69458. lr 5.238299e-04:  46%|████▋     | 7573/16329 [1:03:48<1:12:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7573: train loss 1.69458. lr 5.238299e-04:  46%|████▋     | 7574/16329 [1:03:48<1:12:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7574: train loss 1.65386. lr 5.238107e-04:  46%|████▋     | 7574/16329 [1:03:48<1:12:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7574: train loss 1.65386. lr 5.238107e-04:  46%|████▋     | 7575/16329 [1:03:48<1:12:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7575: train loss 1.68801. lr 5.237914e-04:  46%|████▋     | 7575/16329 [1:03:49<1:12:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7575: train loss 1.68801. lr 5.237914e-04:  46%|████▋     | 7576/16329 [1:03:49<1:12:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7576: train loss 1.64933. lr 5.237722e-04:  46%|████▋     | 7576/16329 [1:03:49<1:12:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7576: train loss 1.64933. lr 5.237722e-04:  46%|████▋     | 7577/16329 [1:03:49<1:12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7577: train loss 1.64653. lr 5.237530e-04:  46%|████▋     | 7577/16329 [1:03:50<1:12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7577: train loss 1.64653. lr 5.237530e-04:  46%|████▋     | 7578/16329 [1:03:50<1:12:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7578: train loss 1.61331. lr 5.237338e-04:  46%|████▋     | 7578/16329 [1:03:50<1:12:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7578: train loss 1.61331. lr 5.237338e-04:  46%|████▋     | 7579/16329 [1:03:50<1:12:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7579: train loss 1.62854. lr 5.237145e-04:  46%|████▋     | 7579/16329 [1:03:51<1:12:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7579: train loss 1.62854. lr 5.237145e-04:  46%|████▋     | 7580/16329 [1:03:51<1:12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7580: train loss 1.63926. lr 5.236953e-04:  46%|████▋     | 7580/16329 [1:03:51<1:12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7580: train loss 1.63926. lr 5.236953e-04:  46%|████▋     | 7581/16329 [1:03:51<1:12:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7581: train loss 1.62284. lr 5.236761e-04:  46%|████▋     | 7581/16329 [1:03:52<1:12:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7581: train loss 1.62284. lr 5.236761e-04:  46%|████▋     | 7582/16329 [1:03:52<1:12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7582: train loss 1.62126. lr 5.236568e-04:  46%|████▋     | 7582/16329 [1:03:52<1:12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7582: train loss 1.62126. lr 5.236568e-04:  46%|████▋     | 7583/16329 [1:03:52<1:12:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7583: train loss 1.63110. lr 5.236376e-04:  46%|████▋     | 7583/16329 [1:03:53<1:12:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7583: train loss 1.63110. lr 5.236376e-04:  46%|████▋     | 7584/16329 [1:03:53<1:12:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7584: train loss 1.61622. lr 5.236184e-04:  46%|████▋     | 7584/16329 [1:03:53<1:12:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7584: train loss 1.61622. lr 5.236184e-04:  46%|████▋     | 7585/16329 [1:03:53<1:12:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7585: train loss 1.65033. lr 5.235991e-04:  46%|████▋     | 7585/16329 [1:03:54<1:12:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7585: train loss 1.65033. lr 5.235991e-04:  46%|████▋     | 7586/16329 [1:03:54<1:12:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7586: train loss 1.64862. lr 5.235799e-04:  46%|████▋     | 7586/16329 [1:03:54<1:12:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7586: train loss 1.64862. lr 5.235799e-04:  46%|████▋     | 7587/16329 [1:03:54<1:12:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7587: train loss 1.64245. lr 5.235606e-04:  46%|████▋     | 7587/16329 [1:03:55<1:12:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7587: train loss 1.64245. lr 5.235606e-04:  46%|████▋     | 7588/16329 [1:03:55<1:19:54,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7588: train loss 1.66698. lr 5.235414e-04:  46%|████▋     | 7588/16329 [1:03:55<1:19:54,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7588: train loss 1.66698. lr 5.235414e-04:  46%|████▋     | 7589/16329 [1:03:55<1:17:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7589: train loss 1.61458. lr 5.235222e-04:  46%|████▋     | 7589/16329 [1:03:56<1:17:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7589: train loss 1.61458. lr 5.235222e-04:  46%|████▋     | 7590/16329 [1:03:56<1:15:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7590: train loss 1.68351. lr 5.235029e-04:  46%|████▋     | 7590/16329 [1:03:56<1:15:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7590: train loss 1.68351. lr 5.235029e-04:  46%|████▋     | 7591/16329 [1:03:56<1:14:53,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7591: train loss 1.63855. lr 5.234837e-04:  46%|████▋     | 7591/16329 [1:03:57<1:14:53,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7591: train loss 1.63855. lr 5.234837e-04:  46%|████▋     | 7592/16329 [1:03:57<1:13:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7592: train loss 1.64675. lr 5.234644e-04:  46%|████▋     | 7592/16329 [1:03:57<1:13:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7592: train loss 1.64675. lr 5.234644e-04:  47%|████▋     | 7593/16329 [1:03:57<1:13:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7593: train loss 1.58070. lr 5.234451e-04:  47%|████▋     | 7593/16329 [1:03:58<1:13:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7593: train loss 1.58070. lr 5.234451e-04:  47%|████▋     | 7594/16329 [1:03:58<1:12:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7594: train loss 1.60176. lr 5.234259e-04:  47%|████▋     | 7594/16329 [1:03:58<1:12:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7594: train loss 1.60176. lr 5.234259e-04:  47%|████▋     | 7595/16329 [1:03:58<1:12:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7595: train loss 1.67471. lr 5.234066e-04:  47%|████▋     | 7595/16329 [1:03:59<1:12:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7595: train loss 1.67471. lr 5.234066e-04:  47%|████▋     | 7596/16329 [1:03:59<1:12:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7596: train loss 1.65299. lr 5.233874e-04:  47%|████▋     | 7596/16329 [1:03:59<1:12:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7596: train loss 1.65299. lr 5.233874e-04:  47%|████▋     | 7597/16329 [1:03:59<1:12:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7597: train loss 1.63973. lr 5.233681e-04:  47%|████▋     | 7597/16329 [1:04:00<1:12:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7597: train loss 1.63973. lr 5.233681e-04:  47%|████▋     | 7598/16329 [1:04:00<1:12:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7598: train loss 1.63302. lr 5.233488e-04:  47%|████▋     | 7598/16329 [1:04:00<1:12:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7598: train loss 1.63302. lr 5.233488e-04:  47%|████▋     | 7599/16329 [1:04:00<1:12:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7599: train loss 1.65761. lr 5.233296e-04:  47%|████▋     | 7599/16329 [1:04:01<1:12:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7599: train loss 1.65761. lr 5.233296e-04:  47%|████▋     | 7600/16329 [1:04:01<1:11:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7600: train loss 1.63390. lr 5.233103e-04:  47%|████▋     | 7600/16329 [1:04:01<1:11:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7600: train loss 1.63390. lr 5.233103e-04:  47%|████▋     | 7601/16329 [1:04:01<1:12:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7601: train loss 1.64672. lr 5.232910e-04:  47%|████▋     | 7601/16329 [1:04:02<1:12:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7601: train loss 1.64672. lr 5.232910e-04:  47%|████▋     | 7602/16329 [1:04:02<1:12:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7602: train loss 1.59911. lr 5.232717e-04:  47%|████▋     | 7602/16329 [1:04:02<1:12:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7602: train loss 1.59911. lr 5.232717e-04:  47%|████▋     | 7603/16329 [1:04:02<1:12:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7603: train loss 1.63516. lr 5.232525e-04:  47%|████▋     | 7603/16329 [1:04:03<1:12:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7603: train loss 1.63516. lr 5.232525e-04:  47%|████▋     | 7604/16329 [1:04:03<1:12:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7604: train loss 1.61026. lr 5.232332e-04:  47%|████▋     | 7604/16329 [1:04:03<1:12:07,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7604: train loss 1.61026. lr 5.232332e-04:  47%|████▋     | 7605/16329 [1:04:03<1:11:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7605: train loss 1.62868. lr 5.232139e-04:  47%|████▋     | 7605/16329 [1:04:04<1:11:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7605: train loss 1.62868. lr 5.232139e-04:  47%|████▋     | 7606/16329 [1:04:04<1:11:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7606: train loss 1.64894. lr 5.231946e-04:  47%|████▋     | 7606/16329 [1:04:04<1:11:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7606: train loss 1.64894. lr 5.231946e-04:  47%|████▋     | 7607/16329 [1:04:04<1:11:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7607: train loss 1.64929. lr 5.231753e-04:  47%|████▋     | 7607/16329 [1:04:05<1:11:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7607: train loss 1.64929. lr 5.231753e-04:  47%|████▋     | 7608/16329 [1:04:05<1:12:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7608: train loss 1.61454. lr 5.231560e-04:  47%|████▋     | 7608/16329 [1:04:05<1:12:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7608: train loss 1.61454. lr 5.231560e-04:  47%|████▋     | 7609/16329 [1:04:05<1:11:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7609: train loss 1.66408. lr 5.231368e-04:  47%|████▋     | 7609/16329 [1:04:06<1:11:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7609: train loss 1.66408. lr 5.231368e-04:  47%|████▋     | 7610/16329 [1:04:06<1:11:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7610: train loss 1.62195. lr 5.231175e-04:  47%|████▋     | 7610/16329 [1:04:06<1:11:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7610: train loss 1.62195. lr 5.231175e-04:  47%|████▋     | 7611/16329 [1:04:06<1:12:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7611: train loss 1.61199. lr 5.230982e-04:  47%|████▋     | 7611/16329 [1:04:07<1:12:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7611: train loss 1.61199. lr 5.230982e-04:  47%|████▋     | 7612/16329 [1:04:07<1:11:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7612: train loss 1.62509. lr 5.230789e-04:  47%|████▋     | 7612/16329 [1:04:07<1:11:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7612: train loss 1.62509. lr 5.230789e-04:  47%|████▋     | 7613/16329 [1:04:07<1:12:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7613: train loss 1.61844. lr 5.230596e-04:  47%|████▋     | 7613/16329 [1:04:08<1:12:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7613: train loss 1.61844. lr 5.230596e-04:  47%|████▋     | 7614/16329 [1:04:08<1:12:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7614: train loss 1.64729. lr 5.230403e-04:  47%|████▋     | 7614/16329 [1:04:08<1:12:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7614: train loss 1.64729. lr 5.230403e-04:  47%|████▋     | 7615/16329 [1:04:08<1:19:39,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7615: train loss 1.66128. lr 5.230210e-04:  47%|████▋     | 7615/16329 [1:04:09<1:19:39,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7615: train loss 1.66128. lr 5.230210e-04:  47%|████▋     | 7616/16329 [1:04:09<1:17:27,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7616: train loss 1.61320. lr 5.230017e-04:  47%|████▋     | 7616/16329 [1:04:09<1:17:27,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7616: train loss 1.61320. lr 5.230017e-04:  47%|████▋     | 7617/16329 [1:04:09<1:15:40,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7617: train loss 1.64108. lr 5.229824e-04:  47%|████▋     | 7617/16329 [1:04:10<1:15:40,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7617: train loss 1.64108. lr 5.229824e-04:  47%|████▋     | 7618/16329 [1:04:10<1:14:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7618: train loss 1.65160. lr 5.229631e-04:  47%|████▋     | 7618/16329 [1:04:10<1:14:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7618: train loss 1.65160. lr 5.229631e-04:  47%|████▋     | 7619/16329 [1:04:10<1:14:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7619: train loss 1.60066. lr 5.229437e-04:  47%|████▋     | 7619/16329 [1:04:11<1:14:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7619: train loss 1.60066. lr 5.229437e-04:  47%|████▋     | 7620/16329 [1:04:11<1:14:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7620: train loss 1.65066. lr 5.229244e-04:  47%|████▋     | 7620/16329 [1:04:11<1:14:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7620: train loss 1.65066. lr 5.229244e-04:  47%|████▋     | 7621/16329 [1:04:11<1:13:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7621: train loss 1.65069. lr 5.229051e-04:  47%|████▋     | 7621/16329 [1:04:12<1:13:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7621: train loss 1.65069. lr 5.229051e-04:  47%|████▋     | 7622/16329 [1:04:12<1:12:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7622: train loss 1.63509. lr 5.228858e-04:  47%|████▋     | 7622/16329 [1:04:12<1:12:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7622: train loss 1.63509. lr 5.228858e-04:  47%|████▋     | 7623/16329 [1:04:12<1:12:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7623: train loss 1.60059. lr 5.228665e-04:  47%|████▋     | 7623/16329 [1:04:13<1:12:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7623: train loss 1.60059. lr 5.228665e-04:  47%|████▋     | 7624/16329 [1:04:13<1:12:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7624: train loss 1.64297. lr 5.228472e-04:  47%|████▋     | 7624/16329 [1:04:13<1:12:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7624: train loss 1.64297. lr 5.228472e-04:  47%|████▋     | 7625/16329 [1:04:13<1:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7625: train loss 1.64757. lr 5.228278e-04:  47%|████▋     | 7625/16329 [1:04:14<1:12:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7625: train loss 1.64757. lr 5.228278e-04:  47%|████▋     | 7626/16329 [1:04:14<1:12:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7626: train loss 1.66861. lr 5.228085e-04:  47%|████▋     | 7626/16329 [1:04:14<1:12:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7626: train loss 1.66861. lr 5.228085e-04:  47%|████▋     | 7627/16329 [1:04:14<1:12:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7627: train loss 1.64983. lr 5.227892e-04:  47%|████▋     | 7627/16329 [1:04:15<1:12:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7627: train loss 1.64983. lr 5.227892e-04:  47%|████▋     | 7628/16329 [1:04:15<1:11:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7628: train loss 1.61679. lr 5.227699e-04:  47%|████▋     | 7628/16329 [1:04:15<1:11:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7628: train loss 1.61679. lr 5.227699e-04:  47%|████▋     | 7629/16329 [1:04:15<1:11:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7629: train loss 1.64023. lr 5.227505e-04:  47%|████▋     | 7629/16329 [1:04:16<1:11:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7629: train loss 1.64023. lr 5.227505e-04:  47%|████▋     | 7630/16329 [1:04:16<1:12:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7630: train loss 1.60465. lr 5.227312e-04:  47%|████▋     | 7630/16329 [1:04:16<1:12:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7630: train loss 1.60465. lr 5.227312e-04:  47%|████▋     | 7631/16329 [1:04:16<1:11:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7631: train loss 1.62805. lr 5.227119e-04:  47%|████▋     | 7631/16329 [1:04:17<1:11:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7631: train loss 1.62805. lr 5.227119e-04:  47%|████▋     | 7632/16329 [1:04:17<1:11:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7632: train loss 1.64733. lr 5.226925e-04:  47%|████▋     | 7632/16329 [1:04:17<1:11:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7632: train loss 1.64733. lr 5.226925e-04:  47%|████▋     | 7633/16329 [1:04:17<1:11:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7633: train loss 1.65019. lr 5.226732e-04:  47%|████▋     | 7633/16329 [1:04:18<1:11:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7633: train loss 1.65019. lr 5.226732e-04:  47%|████▋     | 7634/16329 [1:04:18<1:12:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7634: train loss 1.64686. lr 5.226538e-04:  47%|████▋     | 7634/16329 [1:04:18<1:12:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7634: train loss 1.64686. lr 5.226538e-04:  47%|████▋     | 7635/16329 [1:04:18<1:12:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7635: train loss 1.67608. lr 5.226345e-04:  47%|████▋     | 7635/16329 [1:04:19<1:12:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7635: train loss 1.67608. lr 5.226345e-04:  47%|████▋     | 7636/16329 [1:04:19<1:11:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7636: train loss 1.62382. lr 5.226152e-04:  47%|████▋     | 7636/16329 [1:04:19<1:11:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7636: train loss 1.62382. lr 5.226152e-04:  47%|████▋     | 7637/16329 [1:04:19<1:11:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7637: train loss 1.60910. lr 5.225958e-04:  47%|████▋     | 7637/16329 [1:04:20<1:11:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7637: train loss 1.60910. lr 5.225958e-04:  47%|████▋     | 7638/16329 [1:04:20<1:11:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7638: train loss 1.57188. lr 5.225765e-04:  47%|████▋     | 7638/16329 [1:04:20<1:11:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7638: train loss 1.57188. lr 5.225765e-04:  47%|████▋     | 7639/16329 [1:04:20<1:12:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7639: train loss 1.63058. lr 5.225571e-04:  47%|████▋     | 7639/16329 [1:04:21<1:12:06,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7639: train loss 1.63058. lr 5.225571e-04:  47%|████▋     | 7640/16329 [1:04:21<1:11:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7640: train loss 1.62727. lr 5.225378e-04:  47%|████▋     | 7640/16329 [1:04:21<1:11:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7640: train loss 1.62727. lr 5.225378e-04:  47%|████▋     | 7641/16329 [1:04:21<1:12:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7641: train loss 1.60765. lr 5.225184e-04:  47%|████▋     | 7641/16329 [1:04:22<1:12:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7641: train loss 1.60765. lr 5.225184e-04:  47%|████▋     | 7642/16329 [1:04:22<1:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7642: train loss 1.67776. lr 5.224990e-04:  47%|████▋     | 7642/16329 [1:04:22<1:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7642: train loss 1.67776. lr 5.224990e-04:  47%|████▋     | 7643/16329 [1:04:22<1:12:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7643: train loss 1.67013. lr 5.224797e-04:  47%|████▋     | 7643/16329 [1:04:23<1:12:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7643: train loss 1.67013. lr 5.224797e-04:  47%|████▋     | 7644/16329 [1:04:23<1:12:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7644: train loss 1.63981. lr 5.224603e-04:  47%|████▋     | 7644/16329 [1:04:23<1:12:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7644: train loss 1.63981. lr 5.224603e-04:  47%|████▋     | 7645/16329 [1:04:23<1:12:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7645: train loss 1.62381. lr 5.224410e-04:  47%|████▋     | 7645/16329 [1:04:24<1:12:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7645: train loss 1.62381. lr 5.224410e-04:  47%|████▋     | 7646/16329 [1:04:24<1:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7646: train loss 1.66544. lr 5.224216e-04:  47%|████▋     | 7646/16329 [1:04:24<1:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7646: train loss 1.66544. lr 5.224216e-04:  47%|████▋     | 7647/16329 [1:04:24<1:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7647: train loss 1.60800. lr 5.224022e-04:  47%|████▋     | 7647/16329 [1:04:25<1:12:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7647: train loss 1.60800. lr 5.224022e-04:  47%|████▋     | 7648/16329 [1:04:25<1:12:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7648: train loss 1.62201. lr 5.223829e-04:  47%|████▋     | 7648/16329 [1:04:25<1:12:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7648: train loss 1.62201. lr 5.223829e-04:  47%|████▋     | 7649/16329 [1:04:25<1:12:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7649: train loss 1.66000. lr 5.223635e-04:  47%|████▋     | 7649/16329 [1:04:26<1:12:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7649: train loss 1.66000. lr 5.223635e-04:  47%|████▋     | 7650/16329 [1:04:26<1:11:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7650: train loss 1.63443. lr 5.223441e-04:  47%|████▋     | 7650/16329 [1:04:26<1:11:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7650: train loss 1.63443. lr 5.223441e-04:  47%|████▋     | 7651/16329 [1:04:26<1:11:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7651: train loss 1.58288. lr 5.223247e-04:  47%|████▋     | 7651/16329 [1:04:27<1:11:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7651: train loss 1.58288. lr 5.223247e-04:  47%|████▋     | 7652/16329 [1:04:27<1:11:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7652: train loss 1.61238. lr 5.223053e-04:  47%|████▋     | 7652/16329 [1:04:27<1:11:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7652: train loss 1.61238. lr 5.223053e-04:  47%|████▋     | 7653/16329 [1:04:27<1:11:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7653: train loss 1.64880. lr 5.222860e-04:  47%|████▋     | 7653/16329 [1:04:28<1:11:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7653: train loss 1.64880. lr 5.222860e-04:  47%|████▋     | 7654/16329 [1:04:28<1:11:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7654: train loss 1.63184. lr 5.222666e-04:  47%|████▋     | 7654/16329 [1:04:28<1:11:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7654: train loss 1.63184. lr 5.222666e-04:  47%|████▋     | 7655/16329 [1:04:28<1:21:10,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 7655: train loss 1.60704. lr 5.222472e-04:  47%|████▋     | 7655/16329 [1:04:29<1:21:10,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 7655: train loss 1.60704. lr 5.222472e-04:  47%|████▋     | 7656/16329 [1:04:29<1:18:13,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 7656: train loss 1.65811. lr 5.222278e-04:  47%|████▋     | 7656/16329 [1:04:29<1:18:13,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 7656: train loss 1.65811. lr 5.222278e-04:  47%|████▋     | 7657/16329 [1:04:29<1:16:13,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7657: train loss 1.60902. lr 5.222084e-04:  47%|████▋     | 7657/16329 [1:04:30<1:16:13,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7657: train loss 1.60902. lr 5.222084e-04:  47%|████▋     | 7658/16329 [1:04:30<1:14:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7658: train loss 1.65340. lr 5.221890e-04:  47%|████▋     | 7658/16329 [1:04:30<1:14:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7658: train loss 1.65340. lr 5.221890e-04:  47%|████▋     | 7659/16329 [1:04:30<1:13:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7659: train loss 1.64065. lr 5.221696e-04:  47%|████▋     | 7659/16329 [1:04:31<1:13:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7659: train loss 1.64065. lr 5.221696e-04:  47%|████▋     | 7660/16329 [1:04:31<1:13:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7660: train loss 1.59092. lr 5.221502e-04:  47%|████▋     | 7660/16329 [1:04:31<1:13:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7660: train loss 1.59092. lr 5.221502e-04:  47%|████▋     | 7661/16329 [1:04:31<1:13:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7661: train loss 1.59070. lr 5.221309e-04:  47%|████▋     | 7661/16329 [1:04:32<1:13:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7661: train loss 1.59070. lr 5.221309e-04:  47%|████▋     | 7662/16329 [1:04:32<1:12:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7662: train loss 1.62062. lr 5.221115e-04:  47%|████▋     | 7662/16329 [1:04:32<1:12:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7662: train loss 1.62062. lr 5.221115e-04:  47%|████▋     | 7663/16329 [1:04:32<1:12:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7663: train loss 1.64853. lr 5.220921e-04:  47%|████▋     | 7663/16329 [1:04:33<1:12:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7663: train loss 1.64853. lr 5.220921e-04:  47%|████▋     | 7664/16329 [1:04:33<1:12:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7664: train loss 1.66088. lr 5.220727e-04:  47%|████▋     | 7664/16329 [1:04:33<1:12:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7664: train loss 1.66088. lr 5.220727e-04:  47%|████▋     | 7665/16329 [1:04:33<1:12:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7665: train loss 1.63195. lr 5.220532e-04:  47%|████▋     | 7665/16329 [1:04:34<1:12:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7665: train loss 1.63195. lr 5.220532e-04:  47%|████▋     | 7666/16329 [1:04:34<1:11:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7666: train loss 1.59515. lr 5.220338e-04:  47%|████▋     | 7666/16329 [1:04:34<1:11:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7666: train loss 1.59515. lr 5.220338e-04:  47%|████▋     | 7667/16329 [1:04:34<1:11:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7667: train loss 1.58116. lr 5.220144e-04:  47%|████▋     | 7667/16329 [1:04:35<1:11:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7667: train loss 1.58116. lr 5.220144e-04:  47%|████▋     | 7668/16329 [1:04:35<1:11:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7668: train loss 1.64532. lr 5.219950e-04:  47%|████▋     | 7668/16329 [1:04:35<1:11:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7668: train loss 1.64532. lr 5.219950e-04:  47%|████▋     | 7669/16329 [1:04:35<1:11:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7669: train loss 1.60580. lr 5.219756e-04:  47%|████▋     | 7669/16329 [1:04:36<1:11:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7669: train loss 1.60580. lr 5.219756e-04:  47%|████▋     | 7670/16329 [1:04:36<1:11:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7670: train loss 1.60372. lr 5.219562e-04:  47%|████▋     | 7670/16329 [1:04:36<1:11:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7670: train loss 1.60372. lr 5.219562e-04:  47%|████▋     | 7671/16329 [1:04:36<1:11:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7671: train loss 1.66818. lr 5.219368e-04:  47%|████▋     | 7671/16329 [1:04:37<1:11:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7671: train loss 1.66818. lr 5.219368e-04:  47%|████▋     | 7672/16329 [1:04:37<1:11:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7672: train loss 1.63919. lr 5.219174e-04:  47%|████▋     | 7672/16329 [1:04:37<1:11:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7672: train loss 1.63919. lr 5.219174e-04:  47%|████▋     | 7673/16329 [1:04:37<1:11:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7673: train loss 1.62502. lr 5.218979e-04:  47%|████▋     | 7673/16329 [1:04:38<1:11:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7673: train loss 1.62502. lr 5.218979e-04:  47%|████▋     | 7674/16329 [1:04:38<1:11:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7674: train loss 1.65579. lr 5.218785e-04:  47%|████▋     | 7674/16329 [1:04:38<1:11:58,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7674: train loss 1.65579. lr 5.218785e-04:  47%|████▋     | 7675/16329 [1:04:38<1:11:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7675: train loss 1.58845. lr 5.218591e-04:  47%|████▋     | 7675/16329 [1:04:39<1:11:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7675: train loss 1.58845. lr 5.218591e-04:  47%|████▋     | 7676/16329 [1:04:39<1:11:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7676: train loss 1.62084. lr 5.218397e-04:  47%|████▋     | 7676/16329 [1:04:39<1:11:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7676: train loss 1.62084. lr 5.218397e-04:  47%|████▋     | 7677/16329 [1:04:39<1:11:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7677: train loss 1.61193. lr 5.218202e-04:  47%|████▋     | 7677/16329 [1:04:40<1:11:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7677: train loss 1.61193. lr 5.218202e-04:  47%|████▋     | 7678/16329 [1:04:40<1:11:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7678: train loss 1.65553. lr 5.218008e-04:  47%|████▋     | 7678/16329 [1:04:40<1:11:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7678: train loss 1.65553. lr 5.218008e-04:  47%|████▋     | 7679/16329 [1:04:40<1:11:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7679: train loss 1.62761. lr 5.217814e-04:  47%|████▋     | 7679/16329 [1:04:41<1:11:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7679: train loss 1.62761. lr 5.217814e-04:  47%|████▋     | 7680/16329 [1:04:41<1:11:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7680: train loss 1.61531. lr 5.217619e-04:  47%|████▋     | 7680/16329 [1:04:41<1:11:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7680: train loss 1.61531. lr 5.217619e-04:  47%|████▋     | 7681/16329 [1:04:41<1:11:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7681: train loss 1.67590. lr 5.217425e-04:  47%|████▋     | 7681/16329 [1:04:42<1:11:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7681: train loss 1.67590. lr 5.217425e-04:  47%|████▋     | 7682/16329 [1:04:42<1:11:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7682: train loss 1.62687. lr 5.217230e-04:  47%|████▋     | 7682/16329 [1:04:42<1:11:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7682: train loss 1.62687. lr 5.217230e-04:  47%|████▋     | 7683/16329 [1:04:42<1:11:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7683: train loss 1.58572. lr 5.217036e-04:  47%|████▋     | 7683/16329 [1:04:43<1:11:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7683: train loss 1.58572. lr 5.217036e-04:  47%|████▋     | 7684/16329 [1:04:43<1:11:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7684: train loss 1.62354. lr 5.216842e-04:  47%|████▋     | 7684/16329 [1:04:43<1:11:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7684: train loss 1.62354. lr 5.216842e-04:  47%|████▋     | 7685/16329 [1:04:43<1:11:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7685: train loss 1.65521. lr 5.216647e-04:  47%|████▋     | 7685/16329 [1:04:44<1:11:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7685: train loss 1.65521. lr 5.216647e-04:  47%|████▋     | 7686/16329 [1:04:44<1:11:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7686: train loss 1.60432. lr 5.216453e-04:  47%|████▋     | 7686/16329 [1:04:44<1:11:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7686: train loss 1.60432. lr 5.216453e-04:  47%|████▋     | 7687/16329 [1:04:44<1:11:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7687: train loss 1.63466. lr 5.216258e-04:  47%|████▋     | 7687/16329 [1:04:45<1:11:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7687: train loss 1.63466. lr 5.216258e-04:  47%|████▋     | 7688/16329 [1:04:45<1:11:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7688: train loss 1.66753. lr 5.216064e-04:  47%|████▋     | 7688/16329 [1:04:45<1:11:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7688: train loss 1.66753. lr 5.216064e-04:  47%|████▋     | 7689/16329 [1:04:45<1:11:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7689: train loss 1.60782. lr 5.215869e-04:  47%|████▋     | 7689/16329 [1:04:46<1:11:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7689: train loss 1.60782. lr 5.215869e-04:  47%|████▋     | 7690/16329 [1:04:46<1:19:09,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7690: train loss 1.61027. lr 5.215675e-04:  47%|████▋     | 7690/16329 [1:04:46<1:19:09,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7690: train loss 1.61027. lr 5.215675e-04:  47%|████▋     | 7691/16329 [1:04:46<1:16:58,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7691: train loss 1.61552. lr 5.215480e-04:  47%|████▋     | 7691/16329 [1:04:47<1:16:58,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7691: train loss 1.61552. lr 5.215480e-04:  47%|████▋     | 7692/16329 [1:04:47<1:15:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7692: train loss 1.62370. lr 5.215285e-04:  47%|████▋     | 7692/16329 [1:04:47<1:15:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7692: train loss 1.62370. lr 5.215285e-04:  47%|████▋     | 7693/16329 [1:04:47<1:14:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7693: train loss 1.62242. lr 5.215091e-04:  47%|████▋     | 7693/16329 [1:04:48<1:14:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7693: train loss 1.62242. lr 5.215091e-04:  47%|████▋     | 7694/16329 [1:04:48<1:13:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7694: train loss 1.64707. lr 5.214896e-04:  47%|████▋     | 7694/16329 [1:04:48<1:13:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7694: train loss 1.64707. lr 5.214896e-04:  47%|████▋     | 7695/16329 [1:04:48<1:13:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7695: train loss 1.64032. lr 5.214701e-04:  47%|████▋     | 7695/16329 [1:04:49<1:13:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7695: train loss 1.64032. lr 5.214701e-04:  47%|████▋     | 7696/16329 [1:04:49<1:12:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7696: train loss 1.60837. lr 5.214507e-04:  47%|████▋     | 7696/16329 [1:04:49<1:12:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7696: train loss 1.60837. lr 5.214507e-04:  47%|████▋     | 7697/16329 [1:04:49<1:12:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7697: train loss 1.65594. lr 5.214312e-04:  47%|████▋     | 7697/16329 [1:04:50<1:12:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7697: train loss 1.65594. lr 5.214312e-04:  47%|████▋     | 7698/16329 [1:04:50<1:11:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7698: train loss 1.64128. lr 5.214117e-04:  47%|████▋     | 7698/16329 [1:04:50<1:11:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7698: train loss 1.64128. lr 5.214117e-04:  47%|████▋     | 7699/16329 [1:04:50<1:11:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7699: train loss 1.66620. lr 5.213923e-04:  47%|████▋     | 7699/16329 [1:04:51<1:11:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7699: train loss 1.66620. lr 5.213923e-04:  47%|████▋     | 7700/16329 [1:04:51<1:11:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7700: train loss 1.67720. lr 5.213728e-04:  47%|████▋     | 7700/16329 [1:04:51<1:11:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7700: train loss 1.67720. lr 5.213728e-04:  47%|████▋     | 7701/16329 [1:04:51<1:11:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7701: train loss 1.59771. lr 5.213533e-04:  47%|████▋     | 7701/16329 [1:04:52<1:11:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7701: train loss 1.59771. lr 5.213533e-04:  47%|████▋     | 7702/16329 [1:04:52<1:11:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7702: train loss 1.65657. lr 5.213338e-04:  47%|████▋     | 7702/16329 [1:04:52<1:11:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7702: train loss 1.65657. lr 5.213338e-04:  47%|████▋     | 7703/16329 [1:04:52<1:11:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7703: train loss 1.60650. lr 5.213143e-04:  47%|████▋     | 7703/16329 [1:04:53<1:11:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7703: train loss 1.60650. lr 5.213143e-04:  47%|████▋     | 7704/16329 [1:04:53<1:11:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7704: train loss 1.63007. lr 5.212948e-04:  47%|████▋     | 7704/16329 [1:04:53<1:11:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7704: train loss 1.63007. lr 5.212948e-04:  47%|████▋     | 7705/16329 [1:04:53<1:11:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7705: train loss 1.65993. lr 5.212754e-04:  47%|████▋     | 7705/16329 [1:04:54<1:11:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7705: train loss 1.65993. lr 5.212754e-04:  47%|████▋     | 7706/16329 [1:04:54<1:11:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7706: train loss 1.64957. lr 5.212559e-04:  47%|████▋     | 7706/16329 [1:04:54<1:11:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7706: train loss 1.64957. lr 5.212559e-04:  47%|████▋     | 7707/16329 [1:04:54<1:11:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7707: train loss 1.61946. lr 5.212364e-04:  47%|████▋     | 7707/16329 [1:04:55<1:11:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7707: train loss 1.61946. lr 5.212364e-04:  47%|████▋     | 7708/16329 [1:04:55<1:11:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7708: train loss 1.62999. lr 5.212169e-04:  47%|████▋     | 7708/16329 [1:04:55<1:11:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7708: train loss 1.62999. lr 5.212169e-04:  47%|████▋     | 7709/16329 [1:04:55<1:11:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7709: train loss 1.61397. lr 5.211974e-04:  47%|████▋     | 7709/16329 [1:04:56<1:11:27,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7709: train loss 1.61397. lr 5.211974e-04:  47%|████▋     | 7710/16329 [1:04:56<1:11:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7710: train loss 1.61140. lr 5.211779e-04:  47%|████▋     | 7710/16329 [1:04:56<1:11:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7710: train loss 1.61140. lr 5.211779e-04:  47%|████▋     | 7711/16329 [1:04:56<1:11:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7711: train loss 1.59767. lr 5.211584e-04:  47%|████▋     | 7711/16329 [1:04:57<1:11:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7711: train loss 1.59767. lr 5.211584e-04:  47%|████▋     | 7712/16329 [1:04:57<1:14:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7712: train loss 1.63841. lr 5.211389e-04:  47%|████▋     | 7712/16329 [1:04:58<1:14:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7712: train loss 1.63841. lr 5.211389e-04:  47%|████▋     | 7713/16329 [1:04:58<1:16:08,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7713: train loss 1.62197. lr 5.211194e-04:  47%|████▋     | 7713/16329 [1:04:58<1:16:08,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7713: train loss 1.62197. lr 5.211194e-04:  47%|████▋     | 7714/16329 [1:04:58<1:16:52,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7714: train loss 1.64440. lr 5.210999e-04:  47%|████▋     | 7714/16329 [1:04:59<1:16:52,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7714: train loss 1.64440. lr 5.210999e-04:  47%|████▋     | 7715/16329 [1:04:59<1:25:10,  1.69it/s]\u001b[A\n",
      "epoch 1 iter 7715: train loss 1.63782. lr 5.210804e-04:  47%|████▋     | 7715/16329 [1:04:59<1:25:10,  1.69it/s]\u001b[A\n",
      "epoch 1 iter 7715: train loss 1.63782. lr 5.210804e-04:  47%|████▋     | 7716/16329 [1:04:59<1:21:43,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 7716: train loss 1.69485. lr 5.210609e-04:  47%|████▋     | 7716/16329 [1:05:00<1:21:43,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 7716: train loss 1.69485. lr 5.210609e-04:  47%|████▋     | 7717/16329 [1:05:00<1:19:05,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7717: train loss 1.63898. lr 5.210414e-04:  47%|████▋     | 7717/16329 [1:05:00<1:19:05,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7717: train loss 1.63898. lr 5.210414e-04:  47%|████▋     | 7718/16329 [1:05:00<1:16:58,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7718: train loss 1.60250. lr 5.210218e-04:  47%|████▋     | 7718/16329 [1:05:01<1:16:58,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 7718: train loss 1.60250. lr 5.210218e-04:  47%|████▋     | 7719/16329 [1:05:01<1:15:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7719: train loss 1.59384. lr 5.210023e-04:  47%|████▋     | 7719/16329 [1:05:01<1:15:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7719: train loss 1.59384. lr 5.210023e-04:  47%|████▋     | 7720/16329 [1:05:01<1:14:11,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7720: train loss 1.62028. lr 5.209828e-04:  47%|████▋     | 7720/16329 [1:05:02<1:14:11,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7720: train loss 1.62028. lr 5.209828e-04:  47%|████▋     | 7721/16329 [1:05:02<1:13:36,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7721: train loss 1.62437. lr 5.209633e-04:  47%|████▋     | 7721/16329 [1:05:02<1:13:36,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7721: train loss 1.62437. lr 5.209633e-04:  47%|████▋     | 7722/16329 [1:05:02<1:12:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7722: train loss 1.65451. lr 5.209438e-04:  47%|████▋     | 7722/16329 [1:05:03<1:12:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7722: train loss 1.65451. lr 5.209438e-04:  47%|████▋     | 7723/16329 [1:05:03<1:12:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7723: train loss 1.57705. lr 5.209242e-04:  47%|████▋     | 7723/16329 [1:05:03<1:12:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7723: train loss 1.57705. lr 5.209242e-04:  47%|████▋     | 7724/16329 [1:05:03<1:11:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7724: train loss 1.60356. lr 5.209047e-04:  47%|████▋     | 7724/16329 [1:05:04<1:11:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7724: train loss 1.60356. lr 5.209047e-04:  47%|████▋     | 7725/16329 [1:05:04<1:11:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7725: train loss 1.63293. lr 5.208852e-04:  47%|████▋     | 7725/16329 [1:05:04<1:11:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7725: train loss 1.63293. lr 5.208852e-04:  47%|████▋     | 7726/16329 [1:05:04<1:11:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7726: train loss 1.64235. lr 5.208657e-04:  47%|████▋     | 7726/16329 [1:05:05<1:11:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7726: train loss 1.64235. lr 5.208657e-04:  47%|████▋     | 7727/16329 [1:05:05<1:10:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7727: train loss 1.62667. lr 5.208461e-04:  47%|████▋     | 7727/16329 [1:05:05<1:10:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7727: train loss 1.62667. lr 5.208461e-04:  47%|████▋     | 7728/16329 [1:05:05<1:10:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7728: train loss 1.61094. lr 5.208266e-04:  47%|████▋     | 7728/16329 [1:05:06<1:10:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7728: train loss 1.61094. lr 5.208266e-04:  47%|████▋     | 7729/16329 [1:05:06<1:10:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7729: train loss 1.62884. lr 5.208071e-04:  47%|████▋     | 7729/16329 [1:05:06<1:10:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7729: train loss 1.62884. lr 5.208071e-04:  47%|████▋     | 7730/16329 [1:05:06<1:11:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7730: train loss 1.61973. lr 5.207875e-04:  47%|████▋     | 7730/16329 [1:05:07<1:11:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7730: train loss 1.61973. lr 5.207875e-04:  47%|████▋     | 7731/16329 [1:05:07<1:10:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7731: train loss 1.61006. lr 5.207680e-04:  47%|████▋     | 7731/16329 [1:05:07<1:10:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7731: train loss 1.61006. lr 5.207680e-04:  47%|████▋     | 7732/16329 [1:05:07<1:10:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7732: train loss 1.64866. lr 5.207484e-04:  47%|████▋     | 7732/16329 [1:05:08<1:10:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7732: train loss 1.64866. lr 5.207484e-04:  47%|████▋     | 7733/16329 [1:05:08<1:10:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7733: train loss 1.57563. lr 5.207289e-04:  47%|████▋     | 7733/16329 [1:05:08<1:10:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7733: train loss 1.57563. lr 5.207289e-04:  47%|████▋     | 7734/16329 [1:05:08<1:10:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7734: train loss 1.62191. lr 5.207093e-04:  47%|████▋     | 7734/16329 [1:05:09<1:10:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7734: train loss 1.62191. lr 5.207093e-04:  47%|████▋     | 7735/16329 [1:05:09<1:11:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7735: train loss 1.64287. lr 5.206898e-04:  47%|████▋     | 7735/16329 [1:05:09<1:11:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7735: train loss 1.64287. lr 5.206898e-04:  47%|████▋     | 7736/16329 [1:05:09<1:11:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7736: train loss 1.63849. lr 5.206702e-04:  47%|████▋     | 7736/16329 [1:05:10<1:11:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7736: train loss 1.63849. lr 5.206702e-04:  47%|████▋     | 7737/16329 [1:05:10<1:11:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7737: train loss 1.60540. lr 5.206507e-04:  47%|████▋     | 7737/16329 [1:05:10<1:11:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7737: train loss 1.60540. lr 5.206507e-04:  47%|████▋     | 7738/16329 [1:05:10<1:11:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7738: train loss 1.61785. lr 5.206311e-04:  47%|████▋     | 7738/16329 [1:05:11<1:11:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7738: train loss 1.61785. lr 5.206311e-04:  47%|████▋     | 7739/16329 [1:05:11<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7739: train loss 1.62894. lr 5.206116e-04:  47%|████▋     | 7739/16329 [1:05:11<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7739: train loss 1.62894. lr 5.206116e-04:  47%|████▋     | 7740/16329 [1:05:11<1:11:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7740: train loss 1.61051. lr 5.205920e-04:  47%|████▋     | 7740/16329 [1:05:12<1:11:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7740: train loss 1.61051. lr 5.205920e-04:  47%|████▋     | 7741/16329 [1:05:12<1:10:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7741: train loss 1.57685. lr 5.205725e-04:  47%|████▋     | 7741/16329 [1:05:12<1:10:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7741: train loss 1.57685. lr 5.205725e-04:  47%|████▋     | 7742/16329 [1:05:12<1:18:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7742: train loss 1.59447. lr 5.205529e-04:  47%|████▋     | 7742/16329 [1:05:13<1:18:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7742: train loss 1.59447. lr 5.205529e-04:  47%|████▋     | 7743/16329 [1:05:13<1:16:09,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7743: train loss 1.63973. lr 5.205333e-04:  47%|████▋     | 7743/16329 [1:05:13<1:16:09,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7743: train loss 1.63973. lr 5.205333e-04:  47%|████▋     | 7744/16329 [1:05:13<1:14:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7744: train loss 1.58285. lr 5.205138e-04:  47%|████▋     | 7744/16329 [1:05:14<1:14:21,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7744: train loss 1.58285. lr 5.205138e-04:  47%|████▋     | 7745/16329 [1:05:14<1:13:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7745: train loss 1.60467. lr 5.204942e-04:  47%|████▋     | 7745/16329 [1:05:14<1:13:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7745: train loss 1.60467. lr 5.204942e-04:  47%|████▋     | 7746/16329 [1:05:14<1:12:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7746: train loss 1.65920. lr 5.204746e-04:  47%|████▋     | 7746/16329 [1:05:15<1:12:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7746: train loss 1.65920. lr 5.204746e-04:  47%|████▋     | 7747/16329 [1:05:15<1:12:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7747: train loss 1.65922. lr 5.204551e-04:  47%|████▋     | 7747/16329 [1:05:15<1:12:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7747: train loss 1.65922. lr 5.204551e-04:  47%|████▋     | 7748/16329 [1:05:15<1:11:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7748: train loss 1.63471. lr 5.204355e-04:  47%|████▋     | 7748/16329 [1:05:16<1:11:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7748: train loss 1.63471. lr 5.204355e-04:  47%|████▋     | 7749/16329 [1:05:16<1:11:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7749: train loss 1.63184. lr 5.204159e-04:  47%|████▋     | 7749/16329 [1:05:16<1:11:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7749: train loss 1.63184. lr 5.204159e-04:  47%|████▋     | 7750/16329 [1:05:16<1:11:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7750: train loss 1.59353. lr 5.203963e-04:  47%|████▋     | 7750/16329 [1:05:17<1:11:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7750: train loss 1.59353. lr 5.203963e-04:  47%|████▋     | 7751/16329 [1:05:17<1:11:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7751: train loss 1.64854. lr 5.203767e-04:  47%|████▋     | 7751/16329 [1:05:17<1:11:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7751: train loss 1.64854. lr 5.203767e-04:  47%|████▋     | 7752/16329 [1:05:17<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7752: train loss 1.58432. lr 5.203572e-04:  47%|████▋     | 7752/16329 [1:05:18<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7752: train loss 1.58432. lr 5.203572e-04:  47%|████▋     | 7753/16329 [1:05:18<1:11:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7753: train loss 1.64417. lr 5.203376e-04:  47%|████▋     | 7753/16329 [1:05:18<1:11:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7753: train loss 1.64417. lr 5.203376e-04:  47%|████▋     | 7754/16329 [1:05:18<1:12:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7754: train loss 1.62099. lr 5.203180e-04:  47%|████▋     | 7754/16329 [1:05:19<1:12:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7754: train loss 1.62099. lr 5.203180e-04:  47%|████▋     | 7755/16329 [1:05:19<1:11:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7755: train loss 1.65935. lr 5.202984e-04:  47%|████▋     | 7755/16329 [1:05:19<1:11:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7755: train loss 1.65935. lr 5.202984e-04:  47%|████▋     | 7756/16329 [1:05:19<1:11:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7756: train loss 1.57640. lr 5.202788e-04:  47%|████▋     | 7756/16329 [1:05:20<1:11:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7756: train loss 1.57640. lr 5.202788e-04:  48%|████▊     | 7757/16329 [1:05:20<1:11:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7757: train loss 1.61028. lr 5.202592e-04:  48%|████▊     | 7757/16329 [1:05:20<1:11:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7757: train loss 1.61028. lr 5.202592e-04:  48%|████▊     | 7758/16329 [1:05:20<1:11:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7758: train loss 1.64135. lr 5.202396e-04:  48%|████▊     | 7758/16329 [1:05:21<1:11:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7758: train loss 1.64135. lr 5.202396e-04:  48%|████▊     | 7759/16329 [1:05:21<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7759: train loss 1.70090. lr 5.202200e-04:  48%|████▊     | 7759/16329 [1:05:21<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7759: train loss 1.70090. lr 5.202200e-04:  48%|████▊     | 7760/16329 [1:05:21<1:10:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7760: train loss 1.53647. lr 5.202004e-04:  48%|████▊     | 7760/16329 [1:05:22<1:10:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7760: train loss 1.53647. lr 5.202004e-04:  48%|████▊     | 7761/16329 [1:05:22<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7761: train loss 1.65561. lr 5.201808e-04:  48%|████▊     | 7761/16329 [1:05:22<1:11:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7761: train loss 1.65561. lr 5.201808e-04:  48%|████▊     | 7762/16329 [1:05:22<1:12:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7762: train loss 1.60696. lr 5.201612e-04:  48%|████▊     | 7762/16329 [1:05:23<1:12:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7762: train loss 1.60696. lr 5.201612e-04:  48%|████▊     | 7763/16329 [1:05:23<1:13:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7763: train loss 1.62548. lr 5.201416e-04:  48%|████▊     | 7763/16329 [1:05:23<1:13:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7763: train loss 1.62548. lr 5.201416e-04:  48%|████▊     | 7764/16329 [1:05:23<1:13:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7764: train loss 1.59227. lr 5.201220e-04:  48%|████▊     | 7764/16329 [1:05:24<1:13:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7764: train loss 1.59227. lr 5.201220e-04:  48%|████▊     | 7765/16329 [1:05:24<1:13:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7765: train loss 1.60761. lr 5.201024e-04:  48%|████▊     | 7765/16329 [1:05:24<1:13:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7765: train loss 1.60761. lr 5.201024e-04:  48%|████▊     | 7766/16329 [1:05:24<1:12:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7766: train loss 1.62821. lr 5.200828e-04:  48%|████▊     | 7766/16329 [1:05:25<1:12:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7766: train loss 1.62821. lr 5.200828e-04:  48%|████▊     | 7767/16329 [1:05:25<1:12:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7767: train loss 1.57689. lr 5.200632e-04:  48%|████▊     | 7767/16329 [1:05:25<1:12:28,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7767: train loss 1.57689. lr 5.200632e-04:  48%|████▊     | 7768/16329 [1:05:25<1:11:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7768: train loss 1.63523. lr 5.200436e-04:  48%|████▊     | 7768/16329 [1:05:26<1:11:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7768: train loss 1.63523. lr 5.200436e-04:  48%|████▊     | 7769/16329 [1:05:26<1:11:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7769: train loss 1.60417. lr 5.200239e-04:  48%|████▊     | 7769/16329 [1:05:26<1:11:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7769: train loss 1.60417. lr 5.200239e-04:  48%|████▊     | 7770/16329 [1:05:26<1:11:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7770: train loss 1.65383. lr 5.200043e-04:  48%|████▊     | 7770/16329 [1:05:27<1:11:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7770: train loss 1.65383. lr 5.200043e-04:  48%|████▊     | 7771/16329 [1:05:27<1:10:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7771: train loss 1.61157. lr 5.199847e-04:  48%|████▊     | 7771/16329 [1:05:27<1:10:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7771: train loss 1.61157. lr 5.199847e-04:  48%|████▊     | 7772/16329 [1:05:27<1:10:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7772: train loss 1.60769. lr 5.199651e-04:  48%|████▊     | 7772/16329 [1:05:28<1:10:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7772: train loss 1.60769. lr 5.199651e-04:  48%|████▊     | 7773/16329 [1:05:28<1:10:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7773: train loss 1.63761. lr 5.199454e-04:  48%|████▊     | 7773/16329 [1:05:28<1:10:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7773: train loss 1.63761. lr 5.199454e-04:  48%|████▊     | 7774/16329 [1:05:28<1:10:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7774: train loss 1.62403. lr 5.199258e-04:  48%|████▊     | 7774/16329 [1:05:29<1:10:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7774: train loss 1.62403. lr 5.199258e-04:  48%|████▊     | 7775/16329 [1:05:29<1:10:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7775: train loss 1.62670. lr 5.199062e-04:  48%|████▊     | 7775/16329 [1:05:29<1:10:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7775: train loss 1.62670. lr 5.199062e-04:  48%|████▊     | 7776/16329 [1:05:29<1:10:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7776: train loss 1.60564. lr 5.198866e-04:  48%|████▊     | 7776/16329 [1:05:30<1:10:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7776: train loss 1.60564. lr 5.198866e-04:  48%|████▊     | 7777/16329 [1:05:30<1:10:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7777: train loss 1.61283. lr 5.198669e-04:  48%|████▊     | 7777/16329 [1:05:30<1:10:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7777: train loss 1.61283. lr 5.198669e-04:  48%|████▊     | 7778/16329 [1:05:30<1:10:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7778: train loss 1.57842. lr 5.198473e-04:  48%|████▊     | 7778/16329 [1:05:31<1:10:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7778: train loss 1.57842. lr 5.198473e-04:  48%|████▊     | 7779/16329 [1:05:31<1:10:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7779: train loss 1.62298. lr 5.198277e-04:  48%|████▊     | 7779/16329 [1:05:31<1:10:49,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7779: train loss 1.62298. lr 5.198277e-04:  48%|████▊     | 7780/16329 [1:05:31<1:10:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7780: train loss 1.64926. lr 5.198080e-04:  48%|████▊     | 7780/16329 [1:05:32<1:10:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7780: train loss 1.64926. lr 5.198080e-04:  48%|████▊     | 7781/16329 [1:05:32<1:10:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7781: train loss 1.58205. lr 5.197884e-04:  48%|████▊     | 7781/16329 [1:05:33<1:10:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7781: train loss 1.58205. lr 5.197884e-04:  48%|████▊     | 7782/16329 [1:05:33<1:18:39,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7782: train loss 1.63699. lr 5.197687e-04:  48%|████▊     | 7782/16329 [1:05:33<1:18:39,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7782: train loss 1.63699. lr 5.197687e-04:  48%|████▊     | 7783/16329 [1:05:33<1:16:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7783: train loss 1.62674. lr 5.197491e-04:  48%|████▊     | 7783/16329 [1:05:34<1:16:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7783: train loss 1.62674. lr 5.197491e-04:  48%|████▊     | 7784/16329 [1:05:34<1:14:30,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7784: train loss 1.63510. lr 5.197294e-04:  48%|████▊     | 7784/16329 [1:05:34<1:14:30,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7784: train loss 1.63510. lr 5.197294e-04:  48%|████▊     | 7785/16329 [1:05:34<1:13:14,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7785: train loss 1.59946. lr 5.197098e-04:  48%|████▊     | 7785/16329 [1:05:35<1:13:14,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7785: train loss 1.59946. lr 5.197098e-04:  48%|████▊     | 7786/16329 [1:05:35<1:12:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7786: train loss 1.63428. lr 5.196901e-04:  48%|████▊     | 7786/16329 [1:05:35<1:12:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7786: train loss 1.63428. lr 5.196901e-04:  48%|████▊     | 7787/16329 [1:05:35<1:12:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7787: train loss 1.58360. lr 5.196705e-04:  48%|████▊     | 7787/16329 [1:05:36<1:12:11,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7787: train loss 1.58360. lr 5.196705e-04:  48%|████▊     | 7788/16329 [1:05:36<1:11:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7788: train loss 1.55424. lr 5.196508e-04:  48%|████▊     | 7788/16329 [1:05:36<1:11:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7788: train loss 1.55424. lr 5.196508e-04:  48%|████▊     | 7789/16329 [1:05:36<1:11:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7789: train loss 1.60529. lr 5.196312e-04:  48%|████▊     | 7789/16329 [1:05:37<1:11:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7789: train loss 1.60529. lr 5.196312e-04:  48%|████▊     | 7790/16329 [1:05:37<1:11:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7790: train loss 1.61398. lr 5.196115e-04:  48%|████▊     | 7790/16329 [1:05:37<1:11:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7790: train loss 1.61398. lr 5.196115e-04:  48%|████▊     | 7791/16329 [1:05:37<1:10:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7791: train loss 1.62092. lr 5.195918e-04:  48%|████▊     | 7791/16329 [1:05:38<1:10:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7791: train loss 1.62092. lr 5.195918e-04:  48%|████▊     | 7792/16329 [1:05:38<1:10:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7792: train loss 1.67341. lr 5.195722e-04:  48%|████▊     | 7792/16329 [1:05:38<1:10:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7792: train loss 1.67341. lr 5.195722e-04:  48%|████▊     | 7793/16329 [1:05:38<1:10:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7793: train loss 1.58516. lr 5.195525e-04:  48%|████▊     | 7793/16329 [1:05:39<1:10:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7793: train loss 1.58516. lr 5.195525e-04:  48%|████▊     | 7794/16329 [1:05:39<1:10:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7794: train loss 1.67463. lr 5.195328e-04:  48%|████▊     | 7794/16329 [1:05:39<1:10:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7794: train loss 1.67463. lr 5.195328e-04:  48%|████▊     | 7795/16329 [1:05:39<1:10:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7795: train loss 1.58677. lr 5.195132e-04:  48%|████▊     | 7795/16329 [1:05:40<1:10:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7795: train loss 1.58677. lr 5.195132e-04:  48%|████▊     | 7796/16329 [1:05:40<1:10:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7796: train loss 1.60255. lr 5.194935e-04:  48%|████▊     | 7796/16329 [1:05:40<1:10:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7796: train loss 1.60255. lr 5.194935e-04:  48%|████▊     | 7797/16329 [1:05:40<1:10:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7797: train loss 1.62219. lr 5.194738e-04:  48%|████▊     | 7797/16329 [1:05:40<1:10:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7797: train loss 1.62219. lr 5.194738e-04:  48%|████▊     | 7798/16329 [1:05:40<1:10:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7798: train loss 1.61087. lr 5.194541e-04:  48%|████▊     | 7798/16329 [1:05:41<1:10:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7798: train loss 1.61087. lr 5.194541e-04:  48%|████▊     | 7799/16329 [1:05:41<1:10:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7799: train loss 1.57273. lr 5.194345e-04:  48%|████▊     | 7799/16329 [1:05:41<1:10:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7799: train loss 1.57273. lr 5.194345e-04:  48%|████▊     | 7800/16329 [1:05:41<1:10:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7800: train loss 1.64256. lr 5.194148e-04:  48%|████▊     | 7800/16329 [1:05:42<1:10:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7800: train loss 1.64256. lr 5.194148e-04:  48%|████▊     | 7801/16329 [1:05:42<1:10:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7801: train loss 1.57856. lr 5.193951e-04:  48%|████▊     | 7801/16329 [1:05:42<1:10:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7801: train loss 1.57856. lr 5.193951e-04:  48%|████▊     | 7802/16329 [1:05:42<1:10:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7802: train loss 1.63889. lr 5.193754e-04:  48%|████▊     | 7802/16329 [1:05:43<1:10:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7802: train loss 1.63889. lr 5.193754e-04:  48%|████▊     | 7803/16329 [1:05:43<1:10:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7803: train loss 1.62352. lr 5.193557e-04:  48%|████▊     | 7803/16329 [1:05:43<1:10:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7803: train loss 1.62352. lr 5.193557e-04:  48%|████▊     | 7804/16329 [1:05:43<1:10:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7804: train loss 1.65179. lr 5.193360e-04:  48%|████▊     | 7804/16329 [1:05:44<1:10:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7804: train loss 1.65179. lr 5.193360e-04:  48%|████▊     | 7805/16329 [1:05:44<1:10:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7805: train loss 1.54830. lr 5.193163e-04:  48%|████▊     | 7805/16329 [1:05:44<1:10:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7805: train loss 1.54830. lr 5.193163e-04:  48%|████▊     | 7806/16329 [1:05:44<1:10:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7806: train loss 1.61195. lr 5.192967e-04:  48%|████▊     | 7806/16329 [1:05:45<1:10:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7806: train loss 1.61195. lr 5.192967e-04:  48%|████▊     | 7807/16329 [1:05:45<1:10:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7807: train loss 1.63954. lr 5.192770e-04:  48%|████▊     | 7807/16329 [1:05:45<1:10:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7807: train loss 1.63954. lr 5.192770e-04:  48%|████▊     | 7808/16329 [1:05:45<1:10:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7808: train loss 1.61416. lr 5.192573e-04:  48%|████▊     | 7808/16329 [1:05:46<1:10:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7808: train loss 1.61416. lr 5.192573e-04:  48%|████▊     | 7809/16329 [1:05:46<1:10:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7809: train loss 1.62250. lr 5.192376e-04:  48%|████▊     | 7809/16329 [1:05:46<1:10:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7809: train loss 1.62250. lr 5.192376e-04:  48%|████▊     | 7810/16329 [1:05:46<1:10:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7810: train loss 1.63356. lr 5.192179e-04:  48%|████▊     | 7810/16329 [1:05:47<1:10:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7810: train loss 1.63356. lr 5.192179e-04:  48%|████▊     | 7811/16329 [1:05:47<1:10:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7811: train loss 1.63912. lr 5.191982e-04:  48%|████▊     | 7811/16329 [1:05:47<1:10:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7811: train loss 1.63912. lr 5.191982e-04:  48%|████▊     | 7812/16329 [1:05:47<1:10:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7812: train loss 1.58522. lr 5.191785e-04:  48%|████▊     | 7812/16329 [1:05:48<1:10:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7812: train loss 1.58522. lr 5.191785e-04:  48%|████▊     | 7813/16329 [1:05:48<1:10:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7813: train loss 1.57128. lr 5.191587e-04:  48%|████▊     | 7813/16329 [1:05:48<1:10:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7813: train loss 1.57128. lr 5.191587e-04:  48%|████▊     | 7814/16329 [1:05:48<1:10:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7814: train loss 1.62660. lr 5.191390e-04:  48%|████▊     | 7814/16329 [1:05:49<1:10:39,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7814: train loss 1.62660. lr 5.191390e-04:  48%|████▊     | 7815/16329 [1:05:49<1:10:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7815: train loss 1.62593. lr 5.191193e-04:  48%|████▊     | 7815/16329 [1:05:49<1:10:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7815: train loss 1.62593. lr 5.191193e-04:  48%|████▊     | 7816/16329 [1:05:49<1:10:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7816: train loss 1.60238. lr 5.190996e-04:  48%|████▊     | 7816/16329 [1:05:50<1:10:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7816: train loss 1.60238. lr 5.190996e-04:  48%|████▊     | 7817/16329 [1:05:50<1:17:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7817: train loss 1.57684. lr 5.190799e-04:  48%|████▊     | 7817/16329 [1:05:51<1:17:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7817: train loss 1.57684. lr 5.190799e-04:  48%|████▊     | 7818/16329 [1:05:51<1:15:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7818: train loss 1.63773. lr 5.190602e-04:  48%|████▊     | 7818/16329 [1:05:51<1:15:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7818: train loss 1.63773. lr 5.190602e-04:  48%|████▊     | 7819/16329 [1:05:51<1:14:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7819: train loss 1.61957. lr 5.190405e-04:  48%|████▊     | 7819/16329 [1:05:52<1:14:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7819: train loss 1.61957. lr 5.190405e-04:  48%|████▊     | 7820/16329 [1:05:52<1:12:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7820: train loss 1.59225. lr 5.190207e-04:  48%|████▊     | 7820/16329 [1:05:52<1:12:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7820: train loss 1.59225. lr 5.190207e-04:  48%|████▊     | 7821/16329 [1:05:52<1:12:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7821: train loss 1.68392. lr 5.190010e-04:  48%|████▊     | 7821/16329 [1:05:53<1:12:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7821: train loss 1.68392. lr 5.190010e-04:  48%|████▊     | 7822/16329 [1:05:53<1:11:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7822: train loss 1.58873. lr 5.189813e-04:  48%|████▊     | 7822/16329 [1:05:53<1:11:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7822: train loss 1.58873. lr 5.189813e-04:  48%|████▊     | 7823/16329 [1:05:53<1:10:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7823: train loss 1.57733. lr 5.189616e-04:  48%|████▊     | 7823/16329 [1:05:54<1:10:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7823: train loss 1.57733. lr 5.189616e-04:  48%|████▊     | 7824/16329 [1:05:54<1:10:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7824: train loss 1.65347. lr 5.189418e-04:  48%|████▊     | 7824/16329 [1:05:54<1:10:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7824: train loss 1.65347. lr 5.189418e-04:  48%|████▊     | 7825/16329 [1:05:54<1:10:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7825: train loss 1.62010. lr 5.189221e-04:  48%|████▊     | 7825/16329 [1:05:55<1:10:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7825: train loss 1.62010. lr 5.189221e-04:  48%|████▊     | 7826/16329 [1:05:55<1:10:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7826: train loss 1.59724. lr 5.189024e-04:  48%|████▊     | 7826/16329 [1:05:55<1:10:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7826: train loss 1.59724. lr 5.189024e-04:  48%|████▊     | 7827/16329 [1:05:55<1:10:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7827: train loss 1.58738. lr 5.188826e-04:  48%|████▊     | 7827/16329 [1:05:56<1:10:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7827: train loss 1.58738. lr 5.188826e-04:  48%|████▊     | 7828/16329 [1:05:56<1:10:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7828: train loss 1.60116. lr 5.188629e-04:  48%|████▊     | 7828/16329 [1:05:56<1:10:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7828: train loss 1.60116. lr 5.188629e-04:  48%|████▊     | 7829/16329 [1:05:56<1:10:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7829: train loss 1.56905. lr 5.188432e-04:  48%|████▊     | 7829/16329 [1:05:57<1:10:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7829: train loss 1.56905. lr 5.188432e-04:  48%|████▊     | 7830/16329 [1:05:57<1:10:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7830: train loss 1.62708. lr 5.188234e-04:  48%|████▊     | 7830/16329 [1:05:57<1:10:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7830: train loss 1.62708. lr 5.188234e-04:  48%|████▊     | 7831/16329 [1:05:57<1:10:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7831: train loss 1.64608. lr 5.188037e-04:  48%|████▊     | 7831/16329 [1:05:58<1:10:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7831: train loss 1.64608. lr 5.188037e-04:  48%|████▊     | 7832/16329 [1:05:58<1:10:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7832: train loss 1.59973. lr 5.187839e-04:  48%|████▊     | 7832/16329 [1:05:58<1:10:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7832: train loss 1.59973. lr 5.187839e-04:  48%|████▊     | 7833/16329 [1:05:58<1:10:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7833: train loss 1.59890. lr 5.187642e-04:  48%|████▊     | 7833/16329 [1:05:59<1:10:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7833: train loss 1.59890. lr 5.187642e-04:  48%|████▊     | 7834/16329 [1:05:59<1:10:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7834: train loss 1.61693. lr 5.187444e-04:  48%|████▊     | 7834/16329 [1:05:59<1:10:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7834: train loss 1.61693. lr 5.187444e-04:  48%|████▊     | 7835/16329 [1:05:59<1:10:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7835: train loss 1.61164. lr 5.187247e-04:  48%|████▊     | 7835/16329 [1:06:00<1:10:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7835: train loss 1.61164. lr 5.187247e-04:  48%|████▊     | 7836/16329 [1:06:00<1:10:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7836: train loss 1.63660. lr 5.187049e-04:  48%|████▊     | 7836/16329 [1:06:00<1:10:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7836: train loss 1.63660. lr 5.187049e-04:  48%|████▊     | 7837/16329 [1:06:00<1:10:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7837: train loss 1.60586. lr 5.186852e-04:  48%|████▊     | 7837/16329 [1:06:01<1:10:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7837: train loss 1.60586. lr 5.186852e-04:  48%|████▊     | 7838/16329 [1:06:01<1:10:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7838: train loss 1.61306. lr 5.186654e-04:  48%|████▊     | 7838/16329 [1:06:01<1:10:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7838: train loss 1.61306. lr 5.186654e-04:  48%|████▊     | 7839/16329 [1:06:01<1:10:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7839: train loss 1.57582. lr 5.186456e-04:  48%|████▊     | 7839/16329 [1:06:02<1:10:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7839: train loss 1.57582. lr 5.186456e-04:  48%|████▊     | 7840/16329 [1:06:02<1:09:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7840: train loss 1.59260. lr 5.186259e-04:  48%|████▊     | 7840/16329 [1:06:02<1:09:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7840: train loss 1.59260. lr 5.186259e-04:  48%|████▊     | 7841/16329 [1:06:02<1:09:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7841: train loss 1.59665. lr 5.186061e-04:  48%|████▊     | 7841/16329 [1:06:03<1:09:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7841: train loss 1.59665. lr 5.186061e-04:  48%|████▊     | 7842/16329 [1:06:03<1:17:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7842: train loss 1.58341. lr 5.185864e-04:  48%|████▊     | 7842/16329 [1:06:03<1:17:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7842: train loss 1.58341. lr 5.185864e-04:  48%|████▊     | 7843/16329 [1:06:03<1:15:29,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7843: train loss 1.60505. lr 5.185666e-04:  48%|████▊     | 7843/16329 [1:06:04<1:15:29,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7843: train loss 1.60505. lr 5.185666e-04:  48%|████▊     | 7844/16329 [1:06:04<1:13:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7844: train loss 1.57962. lr 5.185468e-04:  48%|████▊     | 7844/16329 [1:06:04<1:13:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7844: train loss 1.57962. lr 5.185468e-04:  48%|████▊     | 7845/16329 [1:06:04<1:12:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7845: train loss 1.64419. lr 5.185270e-04:  48%|████▊     | 7845/16329 [1:06:05<1:12:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7845: train loss 1.64419. lr 5.185270e-04:  48%|████▊     | 7846/16329 [1:06:05<1:11:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7846: train loss 1.60886. lr 5.185073e-04:  48%|████▊     | 7846/16329 [1:06:05<1:11:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7846: train loss 1.60886. lr 5.185073e-04:  48%|████▊     | 7847/16329 [1:06:05<1:11:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7847: train loss 1.64079. lr 5.184875e-04:  48%|████▊     | 7847/16329 [1:06:06<1:11:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7847: train loss 1.64079. lr 5.184875e-04:  48%|████▊     | 7848/16329 [1:06:06<1:10:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7848: train loss 1.64464. lr 5.184677e-04:  48%|████▊     | 7848/16329 [1:06:06<1:10:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7848: train loss 1.64464. lr 5.184677e-04:  48%|████▊     | 7849/16329 [1:06:06<1:10:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7849: train loss 1.57505. lr 5.184479e-04:  48%|████▊     | 7849/16329 [1:06:07<1:10:34,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7849: train loss 1.57505. lr 5.184479e-04:  48%|████▊     | 7850/16329 [1:06:07<1:10:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7850: train loss 1.63388. lr 5.184282e-04:  48%|████▊     | 7850/16329 [1:06:07<1:10:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7850: train loss 1.63388. lr 5.184282e-04:  48%|████▊     | 7851/16329 [1:06:07<1:11:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7851: train loss 1.62310. lr 5.184084e-04:  48%|████▊     | 7851/16329 [1:06:08<1:11:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7851: train loss 1.62310. lr 5.184084e-04:  48%|████▊     | 7852/16329 [1:06:08<1:12:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7852: train loss 1.59601. lr 5.183886e-04:  48%|████▊     | 7852/16329 [1:06:08<1:12:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7852: train loss 1.59601. lr 5.183886e-04:  48%|████▊     | 7853/16329 [1:06:08<1:12:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7853: train loss 1.58483. lr 5.183688e-04:  48%|████▊     | 7853/16329 [1:06:09<1:12:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7853: train loss 1.58483. lr 5.183688e-04:  48%|████▊     | 7854/16329 [1:06:09<1:12:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7854: train loss 1.59271. lr 5.183490e-04:  48%|████▊     | 7854/16329 [1:06:09<1:12:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7854: train loss 1.59271. lr 5.183490e-04:  48%|████▊     | 7855/16329 [1:06:09<1:11:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7855: train loss 1.61056. lr 5.183292e-04:  48%|████▊     | 7855/16329 [1:06:10<1:11:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7855: train loss 1.61056. lr 5.183292e-04:  48%|████▊     | 7856/16329 [1:06:10<1:11:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7856: train loss 1.61808. lr 5.183094e-04:  48%|████▊     | 7856/16329 [1:06:10<1:11:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7856: train loss 1.61808. lr 5.183094e-04:  48%|████▊     | 7857/16329 [1:06:10<1:11:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7857: train loss 1.57376. lr 5.182896e-04:  48%|████▊     | 7857/16329 [1:06:11<1:11:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7857: train loss 1.57376. lr 5.182896e-04:  48%|████▊     | 7858/16329 [1:06:11<1:10:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7858: train loss 1.67258. lr 5.182698e-04:  48%|████▊     | 7858/16329 [1:06:11<1:10:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7858: train loss 1.67258. lr 5.182698e-04:  48%|████▊     | 7859/16329 [1:06:11<1:10:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7859: train loss 1.65735. lr 5.182500e-04:  48%|████▊     | 7859/16329 [1:06:12<1:10:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7859: train loss 1.65735. lr 5.182500e-04:  48%|████▊     | 7860/16329 [1:06:12<1:10:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7860: train loss 1.59684. lr 5.182302e-04:  48%|████▊     | 7860/16329 [1:06:12<1:10:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7860: train loss 1.59684. lr 5.182302e-04:  48%|████▊     | 7861/16329 [1:06:12<1:10:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7861: train loss 1.65791. lr 5.182104e-04:  48%|████▊     | 7861/16329 [1:06:13<1:10:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7861: train loss 1.65791. lr 5.182104e-04:  48%|████▊     | 7862/16329 [1:06:13<1:10:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7862: train loss 1.60837. lr 5.181906e-04:  48%|████▊     | 7862/16329 [1:06:13<1:10:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7862: train loss 1.60837. lr 5.181906e-04:  48%|████▊     | 7863/16329 [1:06:13<1:10:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7863: train loss 1.62567. lr 5.181708e-04:  48%|████▊     | 7863/16329 [1:06:14<1:10:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7863: train loss 1.62567. lr 5.181708e-04:  48%|████▊     | 7864/16329 [1:06:14<1:09:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7864: train loss 1.57799. lr 5.181510e-04:  48%|████▊     | 7864/16329 [1:06:14<1:09:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7864: train loss 1.57799. lr 5.181510e-04:  48%|████▊     | 7865/16329 [1:06:14<1:10:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7865: train loss 1.59983. lr 5.181312e-04:  48%|████▊     | 7865/16329 [1:06:15<1:10:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7865: train loss 1.59983. lr 5.181312e-04:  48%|████▊     | 7866/16329 [1:06:15<1:10:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7866: train loss 1.60057. lr 5.181114e-04:  48%|████▊     | 7866/16329 [1:06:15<1:10:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7866: train loss 1.60057. lr 5.181114e-04:  48%|████▊     | 7867/16329 [1:06:15<1:09:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7867: train loss 1.60634. lr 5.180916e-04:  48%|████▊     | 7867/16329 [1:06:16<1:09:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7867: train loss 1.60634. lr 5.180916e-04:  48%|████▊     | 7868/16329 [1:06:16<1:09:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7868: train loss 1.59346. lr 5.180717e-04:  48%|████▊     | 7868/16329 [1:06:16<1:09:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7868: train loss 1.59346. lr 5.180717e-04:  48%|████▊     | 7869/16329 [1:06:16<1:17:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7869: train loss 1.58202. lr 5.180519e-04:  48%|████▊     | 7869/16329 [1:06:17<1:17:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7869: train loss 1.58202. lr 5.180519e-04:  48%|████▊     | 7870/16329 [1:06:17<1:14:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7870: train loss 1.64249. lr 5.180321e-04:  48%|████▊     | 7870/16329 [1:06:17<1:14:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7870: train loss 1.64249. lr 5.180321e-04:  48%|████▊     | 7871/16329 [1:06:17<1:13:24,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7871: train loss 1.59229. lr 5.180123e-04:  48%|████▊     | 7871/16329 [1:06:18<1:13:24,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7871: train loss 1.59229. lr 5.180123e-04:  48%|████▊     | 7872/16329 [1:06:18<1:12:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7872: train loss 1.64059. lr 5.179924e-04:  48%|████▊     | 7872/16329 [1:06:18<1:12:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7872: train loss 1.64059. lr 5.179924e-04:  48%|████▊     | 7873/16329 [1:06:18<1:11:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7873: train loss 1.57621. lr 5.179726e-04:  48%|████▊     | 7873/16329 [1:06:19<1:11:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7873: train loss 1.57621. lr 5.179726e-04:  48%|████▊     | 7874/16329 [1:06:19<1:10:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7874: train loss 1.58049. lr 5.179528e-04:  48%|████▊     | 7874/16329 [1:06:19<1:10:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7874: train loss 1.58049. lr 5.179528e-04:  48%|████▊     | 7875/16329 [1:06:19<1:10:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7875: train loss 1.62783. lr 5.179329e-04:  48%|████▊     | 7875/16329 [1:06:20<1:10:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7875: train loss 1.62783. lr 5.179329e-04:  48%|████▊     | 7876/16329 [1:06:20<1:10:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7876: train loss 1.55891. lr 5.179131e-04:  48%|████▊     | 7876/16329 [1:06:20<1:10:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7876: train loss 1.55891. lr 5.179131e-04:  48%|████▊     | 7877/16329 [1:06:20<1:09:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7877: train loss 1.61224. lr 5.178933e-04:  48%|████▊     | 7877/16329 [1:06:21<1:09:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7877: train loss 1.61224. lr 5.178933e-04:  48%|████▊     | 7878/16329 [1:06:21<1:09:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7878: train loss 1.58143. lr 5.178734e-04:  48%|████▊     | 7878/16329 [1:06:21<1:09:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7878: train loss 1.58143. lr 5.178734e-04:  48%|████▊     | 7879/16329 [1:06:21<1:10:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7879: train loss 1.58376. lr 5.178536e-04:  48%|████▊     | 7879/16329 [1:06:22<1:10:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7879: train loss 1.58376. lr 5.178536e-04:  48%|████▊     | 7880/16329 [1:06:22<1:11:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7880: train loss 1.64343. lr 5.178338e-04:  48%|████▊     | 7880/16329 [1:06:22<1:11:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7880: train loss 1.64343. lr 5.178338e-04:  48%|████▊     | 7881/16329 [1:06:22<1:11:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7881: train loss 1.61572. lr 5.178139e-04:  48%|████▊     | 7881/16329 [1:06:23<1:11:21,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7881: train loss 1.61572. lr 5.178139e-04:  48%|████▊     | 7882/16329 [1:06:23<1:11:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7882: train loss 1.61902. lr 5.177941e-04:  48%|████▊     | 7882/16329 [1:06:23<1:11:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7882: train loss 1.61902. lr 5.177941e-04:  48%|████▊     | 7883/16329 [1:06:23<1:12:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7883: train loss 1.54763. lr 5.177742e-04:  48%|████▊     | 7883/16329 [1:06:24<1:12:40,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7883: train loss 1.54763. lr 5.177742e-04:  48%|████▊     | 7884/16329 [1:06:24<1:13:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7884: train loss 1.57958. lr 5.177544e-04:  48%|████▊     | 7884/16329 [1:06:24<1:13:45,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7884: train loss 1.57958. lr 5.177544e-04:  48%|████▊     | 7885/16329 [1:06:24<1:14:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7885: train loss 1.60102. lr 5.177345e-04:  48%|████▊     | 7885/16329 [1:06:25<1:14:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 7885: train loss 1.60102. lr 5.177345e-04:  48%|████▊     | 7886/16329 [1:06:25<1:13:40,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7886: train loss 1.57205. lr 5.177147e-04:  48%|████▊     | 7886/16329 [1:06:25<1:13:40,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7886: train loss 1.57205. lr 5.177147e-04:  48%|████▊     | 7887/16329 [1:06:25<1:13:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7887: train loss 1.62119. lr 5.176948e-04:  48%|████▊     | 7887/16329 [1:06:26<1:13:26,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7887: train loss 1.62119. lr 5.176948e-04:  48%|████▊     | 7888/16329 [1:06:26<1:12:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7888: train loss 1.58518. lr 5.176749e-04:  48%|████▊     | 7888/16329 [1:06:26<1:12:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7888: train loss 1.58518. lr 5.176749e-04:  48%|████▊     | 7889/16329 [1:06:26<1:12:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7889: train loss 1.61921. lr 5.176551e-04:  48%|████▊     | 7889/16329 [1:06:27<1:12:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7889: train loss 1.61921. lr 5.176551e-04:  48%|████▊     | 7890/16329 [1:06:27<1:11:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7890: train loss 1.64092. lr 5.176352e-04:  48%|████▊     | 7890/16329 [1:06:27<1:11:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7890: train loss 1.64092. lr 5.176352e-04:  48%|████▊     | 7891/16329 [1:06:27<1:10:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7891: train loss 1.54669. lr 5.176154e-04:  48%|████▊     | 7891/16329 [1:06:28<1:10:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7891: train loss 1.54669. lr 5.176154e-04:  48%|████▊     | 7892/16329 [1:06:28<1:10:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7892: train loss 1.58712. lr 5.175955e-04:  48%|████▊     | 7892/16329 [1:06:28<1:10:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7892: train loss 1.58712. lr 5.175955e-04:  48%|████▊     | 7893/16329 [1:06:28<1:09:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7893: train loss 1.60258. lr 5.175756e-04:  48%|████▊     | 7893/16329 [1:06:29<1:09:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7893: train loss 1.60258. lr 5.175756e-04:  48%|████▊     | 7894/16329 [1:06:29<1:09:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7894: train loss 1.61897. lr 5.175557e-04:  48%|████▊     | 7894/16329 [1:06:29<1:09:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7894: train loss 1.61897. lr 5.175557e-04:  48%|████▊     | 7895/16329 [1:06:29<1:09:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7895: train loss 1.61483. lr 5.175359e-04:  48%|████▊     | 7895/16329 [1:06:30<1:09:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7895: train loss 1.61483. lr 5.175359e-04:  48%|████▊     | 7896/16329 [1:06:30<1:09:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7896: train loss 1.58706. lr 5.175160e-04:  48%|████▊     | 7896/16329 [1:06:30<1:09:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7896: train loss 1.58706. lr 5.175160e-04:  48%|████▊     | 7897/16329 [1:06:30<1:09:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7897: train loss 1.61045. lr 5.174961e-04:  48%|████▊     | 7897/16329 [1:06:31<1:09:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7897: train loss 1.61045. lr 5.174961e-04:  48%|████▊     | 7898/16329 [1:06:31<1:09:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7898: train loss 1.63793. lr 5.174762e-04:  48%|████▊     | 7898/16329 [1:06:31<1:09:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7898: train loss 1.63793. lr 5.174762e-04:  48%|████▊     | 7899/16329 [1:06:31<1:09:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7899: train loss 1.61375. lr 5.174564e-04:  48%|████▊     | 7899/16329 [1:06:32<1:09:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7899: train loss 1.61375. lr 5.174564e-04:  48%|████▊     | 7900/16329 [1:06:32<1:09:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7900: train loss 1.60546. lr 5.174365e-04:  48%|████▊     | 7900/16329 [1:06:32<1:09:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7900: train loss 1.60546. lr 5.174365e-04:  48%|████▊     | 7901/16329 [1:06:32<1:09:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7901: train loss 1.59107. lr 5.174166e-04:  48%|████▊     | 7901/16329 [1:06:33<1:09:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7901: train loss 1.59107. lr 5.174166e-04:  48%|████▊     | 7902/16329 [1:06:33<1:09:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7902: train loss 1.61384. lr 5.173967e-04:  48%|████▊     | 7902/16329 [1:06:33<1:09:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7902: train loss 1.61384. lr 5.173967e-04:  48%|████▊     | 7903/16329 [1:06:33<1:09:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7903: train loss 1.58142. lr 5.173768e-04:  48%|████▊     | 7903/16329 [1:06:34<1:09:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7903: train loss 1.58142. lr 5.173768e-04:  48%|████▊     | 7904/16329 [1:06:34<1:09:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7904: train loss 1.57724. lr 5.173569e-04:  48%|████▊     | 7904/16329 [1:06:34<1:09:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7904: train loss 1.57724. lr 5.173569e-04:  48%|████▊     | 7905/16329 [1:06:34<1:09:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7905: train loss 1.61066. lr 5.173370e-04:  48%|████▊     | 7905/16329 [1:06:35<1:09:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7905: train loss 1.61066. lr 5.173370e-04:  48%|████▊     | 7906/16329 [1:06:35<1:09:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7906: train loss 1.61739. lr 5.173171e-04:  48%|████▊     | 7906/16329 [1:06:35<1:09:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7906: train loss 1.61739. lr 5.173171e-04:  48%|████▊     | 7907/16329 [1:06:35<1:09:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7907: train loss 1.58281. lr 5.172972e-04:  48%|████▊     | 7907/16329 [1:06:36<1:09:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7907: train loss 1.58281. lr 5.172972e-04:  48%|████▊     | 7908/16329 [1:06:36<1:09:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7908: train loss 1.54560. lr 5.172773e-04:  48%|████▊     | 7908/16329 [1:06:36<1:09:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7908: train loss 1.54560. lr 5.172773e-04:  48%|████▊     | 7909/16329 [1:06:37<1:16:23,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 7909: train loss 1.61107. lr 5.172574e-04:  48%|████▊     | 7909/16329 [1:06:37<1:16:23,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 7909: train loss 1.61107. lr 5.172574e-04:  48%|████▊     | 7910/16329 [1:06:37<1:14:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7910: train loss 1.60371. lr 5.172375e-04:  48%|████▊     | 7910/16329 [1:06:37<1:14:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 7910: train loss 1.60371. lr 5.172375e-04:  48%|████▊     | 7911/16329 [1:06:37<1:12:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7911: train loss 1.61199. lr 5.172176e-04:  48%|████▊     | 7911/16329 [1:06:38<1:12:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 7911: train loss 1.61199. lr 5.172176e-04:  48%|████▊     | 7912/16329 [1:06:38<1:11:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7912: train loss 1.64986. lr 5.171977e-04:  48%|████▊     | 7912/16329 [1:06:38<1:11:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7912: train loss 1.64986. lr 5.171977e-04:  48%|████▊     | 7913/16329 [1:06:38<1:10:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7913: train loss 1.63868. lr 5.171778e-04:  48%|████▊     | 7913/16329 [1:06:39<1:10:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7913: train loss 1.63868. lr 5.171778e-04:  48%|████▊     | 7914/16329 [1:06:39<1:10:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7914: train loss 1.60975. lr 5.171579e-04:  48%|████▊     | 7914/16329 [1:06:39<1:10:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7914: train loss 1.60975. lr 5.171579e-04:  48%|████▊     | 7915/16329 [1:06:39<1:09:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7915: train loss 1.64703. lr 5.171380e-04:  48%|████▊     | 7915/16329 [1:06:40<1:09:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7915: train loss 1.64703. lr 5.171380e-04:  48%|████▊     | 7916/16329 [1:06:40<1:09:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7916: train loss 1.57133. lr 5.171181e-04:  48%|████▊     | 7916/16329 [1:06:40<1:09:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7916: train loss 1.57133. lr 5.171181e-04:  48%|████▊     | 7917/16329 [1:06:40<1:09:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7917: train loss 1.60532. lr 5.170982e-04:  48%|████▊     | 7917/16329 [1:06:41<1:09:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7917: train loss 1.60532. lr 5.170982e-04:  48%|████▊     | 7918/16329 [1:06:41<1:09:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7918: train loss 1.53730. lr 5.170782e-04:  48%|████▊     | 7918/16329 [1:06:41<1:09:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7918: train loss 1.53730. lr 5.170782e-04:  48%|████▊     | 7919/16329 [1:06:41<1:08:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7919: train loss 1.59534. lr 5.170583e-04:  48%|████▊     | 7919/16329 [1:06:42<1:08:57,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7919: train loss 1.59534. lr 5.170583e-04:  49%|████▊     | 7920/16329 [1:06:42<1:09:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7920: train loss 1.58833. lr 5.170384e-04:  49%|████▊     | 7920/16329 [1:06:42<1:09:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7920: train loss 1.58833. lr 5.170384e-04:  49%|████▊     | 7921/16329 [1:06:42<1:09:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7921: train loss 1.60737. lr 5.170185e-04:  49%|████▊     | 7921/16329 [1:06:43<1:09:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7921: train loss 1.60737. lr 5.170185e-04:  49%|████▊     | 7922/16329 [1:06:43<1:08:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7922: train loss 1.57021. lr 5.169985e-04:  49%|████▊     | 7922/16329 [1:06:43<1:08:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7922: train loss 1.57021. lr 5.169985e-04:  49%|████▊     | 7923/16329 [1:06:43<1:09:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7923: train loss 1.63589. lr 5.169786e-04:  49%|████▊     | 7923/16329 [1:06:44<1:09:07,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7923: train loss 1.63589. lr 5.169786e-04:  49%|████▊     | 7924/16329 [1:06:44<1:09:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7924: train loss 1.56207. lr 5.169587e-04:  49%|████▊     | 7924/16329 [1:06:44<1:09:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 7924: train loss 1.56207. lr 5.169587e-04:  49%|████▊     | 7925/16329 [1:06:44<1:09:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7925: train loss 1.60013. lr 5.169388e-04:  49%|████▊     | 7925/16329 [1:06:45<1:09:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7925: train loss 1.60013. lr 5.169388e-04:  49%|████▊     | 7926/16329 [1:06:45<1:09:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7926: train loss 1.60125. lr 5.169188e-04:  49%|████▊     | 7926/16329 [1:06:45<1:09:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7926: train loss 1.60125. lr 5.169188e-04:  49%|████▊     | 7927/16329 [1:06:45<1:09:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7927: train loss 1.60726. lr 5.168989e-04:  49%|████▊     | 7927/16329 [1:06:46<1:09:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7927: train loss 1.60726. lr 5.168989e-04:  49%|████▊     | 7928/16329 [1:06:46<1:09:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7928: train loss 1.62121. lr 5.168789e-04:  49%|████▊     | 7928/16329 [1:06:46<1:09:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7928: train loss 1.62121. lr 5.168789e-04:  49%|████▊     | 7929/16329 [1:06:46<1:09:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7929: train loss 1.61651. lr 5.168590e-04:  49%|████▊     | 7929/16329 [1:06:47<1:09:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7929: train loss 1.61651. lr 5.168590e-04:  49%|████▊     | 7930/16329 [1:06:47<1:09:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7930: train loss 1.64894. lr 5.168391e-04:  49%|████▊     | 7930/16329 [1:06:47<1:09:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7930: train loss 1.64894. lr 5.168391e-04:  49%|████▊     | 7931/16329 [1:06:47<1:09:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7931: train loss 1.55639. lr 5.168191e-04:  49%|████▊     | 7931/16329 [1:06:48<1:09:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7931: train loss 1.55639. lr 5.168191e-04:  49%|████▊     | 7932/16329 [1:06:48<1:09:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7932: train loss 1.61291. lr 5.167992e-04:  49%|████▊     | 7932/16329 [1:06:48<1:09:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7932: train loss 1.61291. lr 5.167992e-04:  49%|████▊     | 7933/16329 [1:06:48<1:09:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7933: train loss 1.65818. lr 5.167792e-04:  49%|████▊     | 7933/16329 [1:06:49<1:09:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7933: train loss 1.65818. lr 5.167792e-04:  49%|████▊     | 7934/16329 [1:06:49<1:09:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7934: train loss 1.60199. lr 5.167593e-04:  49%|████▊     | 7934/16329 [1:06:49<1:09:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7934: train loss 1.60199. lr 5.167593e-04:  49%|████▊     | 7935/16329 [1:06:49<1:09:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7935: train loss 1.59503. lr 5.167393e-04:  49%|████▊     | 7935/16329 [1:06:50<1:09:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7935: train loss 1.59503. lr 5.167393e-04:  49%|████▊     | 7936/16329 [1:06:50<1:09:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7936: train loss 1.56125. lr 5.167194e-04:  49%|████▊     | 7936/16329 [1:06:50<1:09:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7936: train loss 1.56125. lr 5.167194e-04:  49%|████▊     | 7937/16329 [1:06:50<1:09:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7937: train loss 1.61403. lr 5.166994e-04:  49%|████▊     | 7937/16329 [1:06:51<1:09:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7937: train loss 1.61403. lr 5.166994e-04:  49%|████▊     | 7938/16329 [1:06:51<1:09:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7938: train loss 1.59466. lr 5.166794e-04:  49%|████▊     | 7938/16329 [1:06:51<1:09:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7938: train loss 1.59466. lr 5.166794e-04:  49%|████▊     | 7939/16329 [1:06:51<1:09:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7939: train loss 1.61331. lr 5.166595e-04:  49%|████▊     | 7939/16329 [1:06:52<1:09:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7939: train loss 1.61331. lr 5.166595e-04:  49%|████▊     | 7940/16329 [1:06:52<1:10:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7940: train loss 1.56443. lr 5.166395e-04:  49%|████▊     | 7940/16329 [1:06:52<1:10:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7940: train loss 1.56443. lr 5.166395e-04:  49%|████▊     | 7941/16329 [1:06:52<1:10:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7941: train loss 1.59662. lr 5.166196e-04:  49%|████▊     | 7941/16329 [1:06:53<1:10:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7941: train loss 1.59662. lr 5.166196e-04:  49%|████▊     | 7942/16329 [1:06:53<1:09:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7942: train loss 1.61247. lr 5.165996e-04:  49%|████▊     | 7942/16329 [1:06:53<1:09:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7942: train loss 1.61247. lr 5.165996e-04:  49%|████▊     | 7943/16329 [1:06:53<1:09:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7943: train loss 1.56587. lr 5.165796e-04:  49%|████▊     | 7943/16329 [1:06:54<1:09:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7943: train loss 1.56587. lr 5.165796e-04:  49%|████▊     | 7944/16329 [1:06:54<1:17:06,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7944: train loss 1.62843. lr 5.165596e-04:  49%|████▊     | 7944/16329 [1:06:55<1:17:06,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 7944: train loss 1.62843. lr 5.165596e-04:  49%|████▊     | 7945/16329 [1:06:55<1:14:40,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7945: train loss 1.60128. lr 5.165397e-04:  49%|████▊     | 7945/16329 [1:06:55<1:14:40,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 7945: train loss 1.60128. lr 5.165397e-04:  49%|████▊     | 7946/16329 [1:06:55<1:13:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7946: train loss 1.62194. lr 5.165197e-04:  49%|████▊     | 7946/16329 [1:06:56<1:13:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7946: train loss 1.62194. lr 5.165197e-04:  49%|████▊     | 7947/16329 [1:06:56<1:11:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7947: train loss 1.62357. lr 5.164997e-04:  49%|████▊     | 7947/16329 [1:06:56<1:11:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7947: train loss 1.62357. lr 5.164997e-04:  49%|████▊     | 7948/16329 [1:06:56<1:11:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7948: train loss 1.61545. lr 5.164797e-04:  49%|████▊     | 7948/16329 [1:06:57<1:11:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7948: train loss 1.61545. lr 5.164797e-04:  49%|████▊     | 7949/16329 [1:06:57<1:10:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7949: train loss 1.56167. lr 5.164598e-04:  49%|████▊     | 7949/16329 [1:06:57<1:10:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7949: train loss 1.56167. lr 5.164598e-04:  49%|████▊     | 7950/16329 [1:06:57<1:10:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7950: train loss 1.59099. lr 5.164398e-04:  49%|████▊     | 7950/16329 [1:06:57<1:10:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7950: train loss 1.59099. lr 5.164398e-04:  49%|████▊     | 7951/16329 [1:06:57<1:10:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7951: train loss 1.60720. lr 5.164198e-04:  49%|████▊     | 7951/16329 [1:06:58<1:10:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7951: train loss 1.60720. lr 5.164198e-04:  49%|████▊     | 7952/16329 [1:06:58<1:09:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7952: train loss 1.62009. lr 5.163998e-04:  49%|████▊     | 7952/16329 [1:06:58<1:09:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7952: train loss 1.62009. lr 5.163998e-04:  49%|████▊     | 7953/16329 [1:06:58<1:09:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7953: train loss 1.54342. lr 5.163798e-04:  49%|████▊     | 7953/16329 [1:06:59<1:09:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7953: train loss 1.54342. lr 5.163798e-04:  49%|████▊     | 7954/16329 [1:06:59<1:09:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7954: train loss 1.60619. lr 5.163598e-04:  49%|████▊     | 7954/16329 [1:06:59<1:09:34,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7954: train loss 1.60619. lr 5.163598e-04:  49%|████▊     | 7955/16329 [1:06:59<1:09:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7955: train loss 1.61057. lr 5.163398e-04:  49%|████▊     | 7955/16329 [1:07:00<1:09:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7955: train loss 1.61057. lr 5.163398e-04:  49%|████▊     | 7956/16329 [1:07:00<1:09:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7956: train loss 1.63583. lr 5.163198e-04:  49%|████▊     | 7956/16329 [1:07:00<1:09:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7956: train loss 1.63583. lr 5.163198e-04:  49%|████▊     | 7957/16329 [1:07:00<1:08:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7957: train loss 1.58449. lr 5.162998e-04:  49%|████▊     | 7957/16329 [1:07:01<1:08:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7957: train loss 1.58449. lr 5.162998e-04:  49%|████▊     | 7958/16329 [1:07:01<1:09:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7958: train loss 1.59938. lr 5.162798e-04:  49%|████▊     | 7958/16329 [1:07:01<1:09:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7958: train loss 1.59938. lr 5.162798e-04:  49%|████▊     | 7959/16329 [1:07:01<1:09:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7959: train loss 1.59892. lr 5.162598e-04:  49%|████▊     | 7959/16329 [1:07:02<1:09:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7959: train loss 1.59892. lr 5.162598e-04:  49%|████▊     | 7960/16329 [1:07:02<1:09:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7960: train loss 1.56759. lr 5.162398e-04:  49%|████▊     | 7960/16329 [1:07:02<1:09:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7960: train loss 1.56759. lr 5.162398e-04:  49%|████▉     | 7961/16329 [1:07:02<1:09:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7961: train loss 1.61059. lr 5.162198e-04:  49%|████▉     | 7961/16329 [1:07:03<1:09:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7961: train loss 1.61059. lr 5.162198e-04:  49%|████▉     | 7962/16329 [1:07:03<1:09:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7962: train loss 1.58340. lr 5.161998e-04:  49%|████▉     | 7962/16329 [1:07:03<1:09:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7962: train loss 1.58340. lr 5.161998e-04:  49%|████▉     | 7963/16329 [1:07:03<1:09:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7963: train loss 1.60506. lr 5.161798e-04:  49%|████▉     | 7963/16329 [1:07:04<1:09:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7963: train loss 1.60506. lr 5.161798e-04:  49%|████▉     | 7964/16329 [1:07:04<1:09:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7964: train loss 1.58258. lr 5.161598e-04:  49%|████▉     | 7964/16329 [1:07:04<1:09:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7964: train loss 1.58258. lr 5.161598e-04:  49%|████▉     | 7965/16329 [1:07:04<1:09:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7965: train loss 1.61387. lr 5.161398e-04:  49%|████▉     | 7965/16329 [1:07:05<1:09:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7965: train loss 1.61387. lr 5.161398e-04:  49%|████▉     | 7966/16329 [1:07:05<1:09:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7966: train loss 1.59274. lr 5.161198e-04:  49%|████▉     | 7966/16329 [1:07:05<1:09:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7966: train loss 1.59274. lr 5.161198e-04:  49%|████▉     | 7967/16329 [1:07:05<1:09:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7967: train loss 1.59356. lr 5.160997e-04:  49%|████▉     | 7967/16329 [1:07:06<1:09:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7967: train loss 1.59356. lr 5.160997e-04:  49%|████▉     | 7968/16329 [1:07:06<1:09:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7968: train loss 1.59921. lr 5.160797e-04:  49%|████▉     | 7968/16329 [1:07:07<1:09:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7968: train loss 1.59921. lr 5.160797e-04:  49%|████▉     | 7969/16329 [1:07:07<1:16:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7969: train loss 1.59922. lr 5.160597e-04:  49%|████▉     | 7969/16329 [1:07:07<1:16:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7969: train loss 1.59922. lr 5.160597e-04:  49%|████▉     | 7970/16329 [1:07:07<1:14:12,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7970: train loss 1.59070. lr 5.160397e-04:  49%|████▉     | 7970/16329 [1:07:08<1:14:12,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7970: train loss 1.59070. lr 5.160397e-04:  49%|████▉     | 7971/16329 [1:07:08<1:12:41,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7971: train loss 1.54507. lr 5.160197e-04:  49%|████▉     | 7971/16329 [1:07:08<1:12:41,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 7971: train loss 1.54507. lr 5.160197e-04:  49%|████▉     | 7972/16329 [1:07:08<1:11:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7972: train loss 1.55533. lr 5.159996e-04:  49%|████▉     | 7972/16329 [1:07:09<1:11:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7972: train loss 1.55533. lr 5.159996e-04:  49%|████▉     | 7973/16329 [1:07:09<1:10:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7973: train loss 1.61979. lr 5.159796e-04:  49%|████▉     | 7973/16329 [1:07:09<1:10:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7973: train loss 1.61979. lr 5.159796e-04:  49%|████▉     | 7974/16329 [1:07:09<1:10:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7974: train loss 1.57619. lr 5.159596e-04:  49%|████▉     | 7974/16329 [1:07:10<1:10:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7974: train loss 1.57619. lr 5.159596e-04:  49%|████▉     | 7975/16329 [1:07:10<1:11:16,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7975: train loss 1.59458. lr 5.159395e-04:  49%|████▉     | 7975/16329 [1:07:10<1:11:16,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7975: train loss 1.59458. lr 5.159395e-04:  49%|████▉     | 7976/16329 [1:07:10<1:11:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7976: train loss 1.58180. lr 5.159195e-04:  49%|████▉     | 7976/16329 [1:07:11<1:11:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 7976: train loss 1.58180. lr 5.159195e-04:  49%|████▉     | 7977/16329 [1:07:11<1:11:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7977: train loss 1.58916. lr 5.158995e-04:  49%|████▉     | 7977/16329 [1:07:11<1:11:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7977: train loss 1.58916. lr 5.158995e-04:  49%|████▉     | 7978/16329 [1:07:11<1:11:16,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7978: train loss 1.63413. lr 5.158794e-04:  49%|████▉     | 7978/16329 [1:07:12<1:11:16,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7978: train loss 1.63413. lr 5.158794e-04:  49%|████▉     | 7979/16329 [1:07:12<1:10:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7979: train loss 1.54455. lr 5.158594e-04:  49%|████▉     | 7979/16329 [1:07:12<1:10:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 7979: train loss 1.54455. lr 5.158594e-04:  49%|████▉     | 7980/16329 [1:07:12<1:10:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7980: train loss 1.52723. lr 5.158393e-04:  49%|████▉     | 7980/16329 [1:07:13<1:10:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 7980: train loss 1.52723. lr 5.158393e-04:  49%|████▉     | 7981/16329 [1:07:13<1:10:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7981: train loss 1.62897. lr 5.158193e-04:  49%|████▉     | 7981/16329 [1:07:13<1:10:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 7981: train loss 1.62897. lr 5.158193e-04:  49%|████▉     | 7982/16329 [1:07:13<1:09:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7982: train loss 1.59429. lr 5.157992e-04:  49%|████▉     | 7982/16329 [1:07:14<1:09:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7982: train loss 1.59429. lr 5.157992e-04:  49%|████▉     | 7983/16329 [1:07:14<1:09:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7983: train loss 1.60376. lr 5.157792e-04:  49%|████▉     | 7983/16329 [1:07:14<1:09:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 7983: train loss 1.60376. lr 5.157792e-04:  49%|████▉     | 7984/16329 [1:07:14<1:09:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7984: train loss 1.56932. lr 5.157591e-04:  49%|████▉     | 7984/16329 [1:07:15<1:09:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7984: train loss 1.56932. lr 5.157591e-04:  49%|████▉     | 7985/16329 [1:07:15<1:09:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7985: train loss 1.58875. lr 5.157391e-04:  49%|████▉     | 7985/16329 [1:07:15<1:09:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7985: train loss 1.58875. lr 5.157391e-04:  49%|████▉     | 7986/16329 [1:07:15<1:09:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7986: train loss 1.57803. lr 5.157190e-04:  49%|████▉     | 7986/16329 [1:07:16<1:09:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 7986: train loss 1.57803. lr 5.157190e-04:  49%|████▉     | 7987/16329 [1:07:16<1:09:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7987: train loss 1.56944. lr 5.156990e-04:  49%|████▉     | 7987/16329 [1:07:16<1:09:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7987: train loss 1.56944. lr 5.156990e-04:  49%|████▉     | 7988/16329 [1:07:16<1:09:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7988: train loss 1.62279. lr 5.156789e-04:  49%|████▉     | 7988/16329 [1:07:17<1:09:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7988: train loss 1.62279. lr 5.156789e-04:  49%|████▉     | 7989/16329 [1:07:17<1:08:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7989: train loss 1.55030. lr 5.156589e-04:  49%|████▉     | 7989/16329 [1:07:17<1:08:53,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 7989: train loss 1.55030. lr 5.156589e-04:  49%|████▉     | 7990/16329 [1:07:17<1:08:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7990: train loss 1.55824. lr 5.156388e-04:  49%|████▉     | 7990/16329 [1:07:18<1:08:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7990: train loss 1.55824. lr 5.156388e-04:  49%|████▉     | 7991/16329 [1:07:18<1:08:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7991: train loss 1.63125. lr 5.156187e-04:  49%|████▉     | 7991/16329 [1:07:18<1:08:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7991: train loss 1.63125. lr 5.156187e-04:  49%|████▉     | 7992/16329 [1:07:18<1:08:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7992: train loss 1.61448. lr 5.155987e-04:  49%|████▉     | 7992/16329 [1:07:19<1:08:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7992: train loss 1.61448. lr 5.155987e-04:  49%|████▉     | 7993/16329 [1:07:19<1:08:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7993: train loss 1.59084. lr 5.155786e-04:  49%|████▉     | 7993/16329 [1:07:19<1:08:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7993: train loss 1.59084. lr 5.155786e-04:  49%|████▉     | 7994/16329 [1:07:19<1:08:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7994: train loss 1.57971. lr 5.155585e-04:  49%|████▉     | 7994/16329 [1:07:20<1:08:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 7994: train loss 1.57971. lr 5.155585e-04:  49%|████▉     | 7995/16329 [1:07:20<1:08:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7995: train loss 1.58021. lr 5.155385e-04:  49%|████▉     | 7995/16329 [1:07:20<1:08:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 7995: train loss 1.58021. lr 5.155385e-04:  49%|████▉     | 7996/16329 [1:07:20<1:16:19,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7996: train loss 1.58789. lr 5.155184e-04:  49%|████▉     | 7996/16329 [1:07:21<1:16:19,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 7996: train loss 1.58789. lr 5.155184e-04:  49%|████▉     | 7997/16329 [1:07:21<1:14:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7997: train loss 1.56376. lr 5.154983e-04:  49%|████▉     | 7997/16329 [1:07:21<1:14:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 7997: train loss 1.56376. lr 5.154983e-04:  49%|████▉     | 7998/16329 [1:07:21<1:12:35,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7998: train loss 1.59546. lr 5.154782e-04:  49%|████▉     | 7998/16329 [1:07:22<1:12:35,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 7998: train loss 1.59546. lr 5.154782e-04:  49%|████▉     | 7999/16329 [1:07:22<1:11:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7999: train loss 1.52859. lr 5.154581e-04:  49%|████▉     | 7999/16329 [1:07:22<1:11:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 7999: train loss 1.52859. lr 5.154581e-04:  49%|████▉     | 8000/16329 [1:07:22<1:10:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8000: train loss 1.56487. lr 5.154381e-04:  49%|████▉     | 8000/16329 [1:07:23<1:10:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8000: train loss 1.56487. lr 5.154381e-04:  49%|████▉     | 8001/16329 [1:07:23<1:10:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8001: train loss 1.57888. lr 5.154180e-04:  49%|████▉     | 8001/16329 [1:07:23<1:10:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8001: train loss 1.57888. lr 5.154180e-04:  49%|████▉     | 8002/16329 [1:07:23<1:09:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8002: train loss 1.63752. lr 5.153979e-04:  49%|████▉     | 8002/16329 [1:07:24<1:09:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8002: train loss 1.63752. lr 5.153979e-04:  49%|████▉     | 8003/16329 [1:07:24<1:09:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8003: train loss 1.61505. lr 5.153778e-04:  49%|████▉     | 8003/16329 [1:07:24<1:09:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8003: train loss 1.61505. lr 5.153778e-04:  49%|████▉     | 8004/16329 [1:07:24<1:09:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8004: train loss 1.59496. lr 5.153577e-04:  49%|████▉     | 8004/16329 [1:07:25<1:09:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8004: train loss 1.59496. lr 5.153577e-04:  49%|████▉     | 8005/16329 [1:07:25<1:11:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8005: train loss 1.56187. lr 5.153376e-04:  49%|████▉     | 8005/16329 [1:07:25<1:11:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8005: train loss 1.56187. lr 5.153376e-04:  49%|████▉     | 8006/16329 [1:07:25<1:12:49,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8006: train loss 1.59538. lr 5.153175e-04:  49%|████▉     | 8006/16329 [1:07:26<1:12:49,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8006: train loss 1.59538. lr 5.153175e-04:  49%|████▉     | 8007/16329 [1:07:26<1:13:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8007: train loss 1.60254. lr 5.152974e-04:  49%|████▉     | 8007/16329 [1:07:26<1:13:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8007: train loss 1.60254. lr 5.152974e-04:  49%|████▉     | 8008/16329 [1:07:26<1:13:18,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8008: train loss 1.56668. lr 5.152773e-04:  49%|████▉     | 8008/16329 [1:07:27<1:13:18,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8008: train loss 1.56668. lr 5.152773e-04:  49%|████▉     | 8009/16329 [1:07:27<1:12:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8009: train loss 1.56847. lr 5.152572e-04:  49%|████▉     | 8009/16329 [1:07:27<1:12:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8009: train loss 1.56847. lr 5.152572e-04:  49%|████▉     | 8010/16329 [1:07:27<1:12:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8010: train loss 1.63283. lr 5.152371e-04:  49%|████▉     | 8010/16329 [1:07:28<1:12:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8010: train loss 1.63283. lr 5.152371e-04:  49%|████▉     | 8011/16329 [1:07:28<1:11:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8011: train loss 1.59080. lr 5.152170e-04:  49%|████▉     | 8011/16329 [1:07:28<1:11:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8011: train loss 1.59080. lr 5.152170e-04:  49%|████▉     | 8012/16329 [1:07:28<1:11:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8012: train loss 1.54168. lr 5.151969e-04:  49%|████▉     | 8012/16329 [1:07:29<1:11:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8012: train loss 1.54168. lr 5.151969e-04:  49%|████▉     | 8013/16329 [1:07:29<1:10:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8013: train loss 1.61276. lr 5.151768e-04:  49%|████▉     | 8013/16329 [1:07:29<1:10:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8013: train loss 1.61276. lr 5.151768e-04:  49%|████▉     | 8014/16329 [1:07:29<1:10:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8014: train loss 1.58880. lr 5.151567e-04:  49%|████▉     | 8014/16329 [1:07:30<1:10:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8014: train loss 1.58880. lr 5.151567e-04:  49%|████▉     | 8015/16329 [1:07:30<1:09:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8015: train loss 1.60543. lr 5.151366e-04:  49%|████▉     | 8015/16329 [1:07:30<1:09:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8015: train loss 1.60543. lr 5.151366e-04:  49%|████▉     | 8016/16329 [1:07:30<1:09:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8016: train loss 1.62112. lr 5.151165e-04:  49%|████▉     | 8016/16329 [1:07:31<1:09:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8016: train loss 1.62112. lr 5.151165e-04:  49%|████▉     | 8017/16329 [1:07:31<1:09:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8017: train loss 1.58619. lr 5.150963e-04:  49%|████▉     | 8017/16329 [1:07:31<1:09:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8017: train loss 1.58619. lr 5.150963e-04:  49%|████▉     | 8018/16329 [1:07:31<1:08:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8018: train loss 1.55740. lr 5.150762e-04:  49%|████▉     | 8018/16329 [1:07:32<1:08:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8018: train loss 1.55740. lr 5.150762e-04:  49%|████▉     | 8019/16329 [1:07:32<1:08:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8019: train loss 1.62068. lr 5.150561e-04:  49%|████▉     | 8019/16329 [1:07:32<1:08:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8019: train loss 1.62068. lr 5.150561e-04:  49%|████▉     | 8020/16329 [1:07:32<1:08:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8020: train loss 1.55083. lr 5.150360e-04:  49%|████▉     | 8020/16329 [1:07:33<1:08:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8020: train loss 1.55083. lr 5.150360e-04:  49%|████▉     | 8021/16329 [1:07:33<1:08:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8021: train loss 1.60202. lr 5.150158e-04:  49%|████▉     | 8021/16329 [1:07:33<1:08:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8021: train loss 1.60202. lr 5.150158e-04:  49%|████▉     | 8022/16329 [1:07:33<1:08:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8022: train loss 1.61489. lr 5.149957e-04:  49%|████▉     | 8022/16329 [1:07:34<1:08:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8022: train loss 1.61489. lr 5.149957e-04:  49%|████▉     | 8023/16329 [1:07:34<1:08:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8023: train loss 1.61396. lr 5.149756e-04:  49%|████▉     | 8023/16329 [1:07:34<1:08:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8023: train loss 1.61396. lr 5.149756e-04:  49%|████▉     | 8024/16329 [1:07:34<1:08:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8024: train loss 1.58504. lr 5.149555e-04:  49%|████▉     | 8024/16329 [1:07:35<1:08:35,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8024: train loss 1.58504. lr 5.149555e-04:  49%|████▉     | 8025/16329 [1:07:35<1:08:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8025: train loss 1.62437. lr 5.149353e-04:  49%|████▉     | 8025/16329 [1:07:35<1:08:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8025: train loss 1.62437. lr 5.149353e-04:  49%|████▉     | 8026/16329 [1:07:35<1:08:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8026: train loss 1.58081. lr 5.149152e-04:  49%|████▉     | 8026/16329 [1:07:36<1:08:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8026: train loss 1.58081. lr 5.149152e-04:  49%|████▉     | 8027/16329 [1:07:36<1:08:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8027: train loss 1.51549. lr 5.148951e-04:  49%|████▉     | 8027/16329 [1:07:36<1:08:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8027: train loss 1.51549. lr 5.148951e-04:  49%|████▉     | 8028/16329 [1:07:36<1:08:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8028: train loss 1.63288. lr 5.148749e-04:  49%|████▉     | 8028/16329 [1:07:37<1:08:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8028: train loss 1.63288. lr 5.148749e-04:  49%|████▉     | 8029/16329 [1:07:37<1:08:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8029: train loss 1.62581. lr 5.148548e-04:  49%|████▉     | 8029/16329 [1:07:37<1:08:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8029: train loss 1.62581. lr 5.148548e-04:  49%|████▉     | 8030/16329 [1:07:37<1:08:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8030: train loss 1.58354. lr 5.148346e-04:  49%|████▉     | 8030/16329 [1:07:38<1:08:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8030: train loss 1.58354. lr 5.148346e-04:  49%|████▉     | 8031/16329 [1:07:38<1:08:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8031: train loss 1.61975. lr 5.148145e-04:  49%|████▉     | 8031/16329 [1:07:38<1:08:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8031: train loss 1.61975. lr 5.148145e-04:  49%|████▉     | 8032/16329 [1:07:38<1:08:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8032: train loss 1.58543. lr 5.147943e-04:  49%|████▉     | 8032/16329 [1:07:39<1:08:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8032: train loss 1.58543. lr 5.147943e-04:  49%|████▉     | 8033/16329 [1:07:39<1:08:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8033: train loss 1.61802. lr 5.147742e-04:  49%|████▉     | 8033/16329 [1:07:39<1:08:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8033: train loss 1.61802. lr 5.147742e-04:  49%|████▉     | 8034/16329 [1:07:39<1:08:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8034: train loss 1.57225. lr 5.147540e-04:  49%|████▉     | 8034/16329 [1:07:40<1:08:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8034: train loss 1.57225. lr 5.147540e-04:  49%|████▉     | 8035/16329 [1:07:40<1:08:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8035: train loss 1.59816. lr 5.147339e-04:  49%|████▉     | 8035/16329 [1:07:41<1:08:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8035: train loss 1.59816. lr 5.147339e-04:  49%|████▉     | 8036/16329 [1:07:41<1:15:51,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8036: train loss 1.63622. lr 5.147137e-04:  49%|████▉     | 8036/16329 [1:07:41<1:15:51,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8036: train loss 1.63622. lr 5.147137e-04:  49%|████▉     | 8037/16329 [1:07:41<1:13:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8037: train loss 1.56556. lr 5.146936e-04:  49%|████▉     | 8037/16329 [1:07:42<1:13:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8037: train loss 1.56556. lr 5.146936e-04:  49%|████▉     | 8038/16329 [1:07:42<1:12:08,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8038: train loss 1.59881. lr 5.146734e-04:  49%|████▉     | 8038/16329 [1:07:42<1:12:08,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8038: train loss 1.59881. lr 5.146734e-04:  49%|████▉     | 8039/16329 [1:07:42<1:11:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8039: train loss 1.57875. lr 5.146533e-04:  49%|████▉     | 8039/16329 [1:07:43<1:11:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8039: train loss 1.57875. lr 5.146533e-04:  49%|████▉     | 8040/16329 [1:07:43<1:10:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8040: train loss 1.54614. lr 5.146331e-04:  49%|████▉     | 8040/16329 [1:07:43<1:10:27,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8040: train loss 1.54614. lr 5.146331e-04:  49%|████▉     | 8041/16329 [1:07:43<1:09:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8041: train loss 1.62218. lr 5.146129e-04:  49%|████▉     | 8041/16329 [1:07:44<1:09:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8041: train loss 1.62218. lr 5.146129e-04:  49%|████▉     | 8042/16329 [1:07:44<1:09:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8042: train loss 1.57833. lr 5.145928e-04:  49%|████▉     | 8042/16329 [1:07:44<1:09:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8042: train loss 1.57833. lr 5.145928e-04:  49%|████▉     | 8043/16329 [1:07:44<1:09:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8043: train loss 1.56090. lr 5.145726e-04:  49%|████▉     | 8043/16329 [1:07:44<1:09:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8043: train loss 1.56090. lr 5.145726e-04:  49%|████▉     | 8044/16329 [1:07:44<1:08:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8044: train loss 1.60079. lr 5.145524e-04:  49%|████▉     | 8044/16329 [1:07:45<1:08:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8044: train loss 1.60079. lr 5.145524e-04:  49%|████▉     | 8045/16329 [1:07:45<1:08:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8045: train loss 1.58892. lr 5.145322e-04:  49%|████▉     | 8045/16329 [1:07:45<1:08:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8045: train loss 1.58892. lr 5.145322e-04:  49%|████▉     | 8046/16329 [1:07:45<1:08:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8046: train loss 1.55045. lr 5.145121e-04:  49%|████▉     | 8046/16329 [1:07:46<1:08:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8046: train loss 1.55045. lr 5.145121e-04:  49%|████▉     | 8047/16329 [1:07:46<1:08:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8047: train loss 1.56518. lr 5.144919e-04:  49%|████▉     | 8047/16329 [1:07:46<1:08:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8047: train loss 1.56518. lr 5.144919e-04:  49%|████▉     | 8048/16329 [1:07:46<1:08:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8048: train loss 1.55510. lr 5.144717e-04:  49%|████▉     | 8048/16329 [1:07:47<1:08:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8048: train loss 1.55510. lr 5.144717e-04:  49%|████▉     | 8049/16329 [1:07:47<1:08:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8049: train loss 1.60446. lr 5.144515e-04:  49%|████▉     | 8049/16329 [1:07:47<1:08:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8049: train loss 1.60446. lr 5.144515e-04:  49%|████▉     | 8050/16329 [1:07:47<1:08:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8050: train loss 1.52320. lr 5.144314e-04:  49%|████▉     | 8050/16329 [1:07:48<1:08:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8050: train loss 1.52320. lr 5.144314e-04:  49%|████▉     | 8051/16329 [1:07:48<1:08:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8051: train loss 1.56583. lr 5.144112e-04:  49%|████▉     | 8051/16329 [1:07:48<1:08:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8051: train loss 1.56583. lr 5.144112e-04:  49%|████▉     | 8052/16329 [1:07:48<1:08:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8052: train loss 1.58311. lr 5.143910e-04:  49%|████▉     | 8052/16329 [1:07:49<1:08:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8052: train loss 1.58311. lr 5.143910e-04:  49%|████▉     | 8053/16329 [1:07:49<1:08:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8053: train loss 1.58538. lr 5.143708e-04:  49%|████▉     | 8053/16329 [1:07:49<1:08:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8053: train loss 1.58538. lr 5.143708e-04:  49%|████▉     | 8054/16329 [1:07:49<1:08:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8054: train loss 1.55668. lr 5.143506e-04:  49%|████▉     | 8054/16329 [1:07:50<1:08:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8054: train loss 1.55668. lr 5.143506e-04:  49%|████▉     | 8055/16329 [1:07:50<1:08:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8055: train loss 1.55727. lr 5.143304e-04:  49%|████▉     | 8055/16329 [1:07:50<1:08:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8055: train loss 1.55727. lr 5.143304e-04:  49%|████▉     | 8056/16329 [1:07:50<1:08:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8056: train loss 1.59892. lr 5.143102e-04:  49%|████▉     | 8056/16329 [1:07:51<1:08:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8056: train loss 1.59892. lr 5.143102e-04:  49%|████▉     | 8057/16329 [1:07:51<1:10:21,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8057: train loss 1.60917. lr 5.142900e-04:  49%|████▉     | 8057/16329 [1:07:52<1:10:21,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8057: train loss 1.60917. lr 5.142900e-04:  49%|████▉     | 8058/16329 [1:07:52<1:11:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8058: train loss 1.57569. lr 5.142698e-04:  49%|████▉     | 8058/16329 [1:07:52<1:11:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8058: train loss 1.57569. lr 5.142698e-04:  49%|████▉     | 8059/16329 [1:07:52<1:11:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8059: train loss 1.59687. lr 5.142496e-04:  49%|████▉     | 8059/16329 [1:07:53<1:11:21,  1.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8059: train loss 1.59687. lr 5.142496e-04:  49%|████▉     | 8060/16329 [1:07:53<1:11:20,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8060: train loss 1.63657. lr 5.142294e-04:  49%|████▉     | 8060/16329 [1:07:53<1:11:20,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8060: train loss 1.63657. lr 5.142294e-04:  49%|████▉     | 8061/16329 [1:07:53<1:10:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8061: train loss 1.55454. lr 5.142092e-04:  49%|████▉     | 8061/16329 [1:07:54<1:10:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8061: train loss 1.55454. lr 5.142092e-04:  49%|████▉     | 8062/16329 [1:07:54<1:10:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8062: train loss 1.57566. lr 5.141890e-04:  49%|████▉     | 8062/16329 [1:07:54<1:10:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8062: train loss 1.57566. lr 5.141890e-04:  49%|████▉     | 8063/16329 [1:07:54<1:09:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8063: train loss 1.55125. lr 5.141688e-04:  49%|████▉     | 8063/16329 [1:07:55<1:09:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8063: train loss 1.55125. lr 5.141688e-04:  49%|████▉     | 8064/16329 [1:07:55<1:09:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8064: train loss 1.55294. lr 5.141486e-04:  49%|████▉     | 8064/16329 [1:07:55<1:09:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8064: train loss 1.55294. lr 5.141486e-04:  49%|████▉     | 8065/16329 [1:07:55<1:09:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8065: train loss 1.54688. lr 5.141284e-04:  49%|████▉     | 8065/16329 [1:07:56<1:09:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8065: train loss 1.54688. lr 5.141284e-04:  49%|████▉     | 8066/16329 [1:07:56<1:09:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8066: train loss 1.55893. lr 5.141082e-04:  49%|████▉     | 8066/16329 [1:07:56<1:09:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8066: train loss 1.55893. lr 5.141082e-04:  49%|████▉     | 8067/16329 [1:07:56<1:08:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8067: train loss 1.56912. lr 5.140879e-04:  49%|████▉     | 8067/16329 [1:07:57<1:08:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8067: train loss 1.56912. lr 5.140879e-04:  49%|████▉     | 8068/16329 [1:07:57<1:08:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8068: train loss 1.61162. lr 5.140677e-04:  49%|████▉     | 8068/16329 [1:07:57<1:08:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8068: train loss 1.61162. lr 5.140677e-04:  49%|████▉     | 8069/16329 [1:07:57<1:08:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8069: train loss 1.57015. lr 5.140475e-04:  49%|████▉     | 8069/16329 [1:07:58<1:08:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8069: train loss 1.57015. lr 5.140475e-04:  49%|████▉     | 8070/16329 [1:07:58<1:08:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8070: train loss 1.60685. lr 5.140273e-04:  49%|████▉     | 8070/16329 [1:07:58<1:08:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8070: train loss 1.60685. lr 5.140273e-04:  49%|████▉     | 8071/16329 [1:07:58<1:18:14,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 8071: train loss 1.55803. lr 5.140071e-04:  49%|████▉     | 8071/16329 [1:07:59<1:18:14,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 8071: train loss 1.55803. lr 5.140071e-04:  49%|████▉     | 8072/16329 [1:07:59<1:15:10,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8072: train loss 1.64230. lr 5.139868e-04:  49%|████▉     | 8072/16329 [1:07:59<1:15:10,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8072: train loss 1.64230. lr 5.139868e-04:  49%|████▉     | 8073/16329 [1:07:59<1:12:56,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8073: train loss 1.54763. lr 5.139666e-04:  49%|████▉     | 8073/16329 [1:08:00<1:12:56,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8073: train loss 1.54763. lr 5.139666e-04:  49%|████▉     | 8074/16329 [1:08:00<1:11:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8074: train loss 1.63184. lr 5.139464e-04:  49%|████▉     | 8074/16329 [1:08:00<1:11:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8074: train loss 1.63184. lr 5.139464e-04:  49%|████▉     | 8075/16329 [1:08:00<1:10:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8075: train loss 1.57982. lr 5.139261e-04:  49%|████▉     | 8075/16329 [1:08:01<1:10:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8075: train loss 1.57982. lr 5.139261e-04:  49%|████▉     | 8076/16329 [1:08:01<1:09:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8076: train loss 1.55581. lr 5.139059e-04:  49%|████▉     | 8076/16329 [1:08:01<1:09:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8076: train loss 1.55581. lr 5.139059e-04:  49%|████▉     | 8077/16329 [1:08:01<1:09:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8077: train loss 1.60766. lr 5.138857e-04:  49%|████▉     | 8077/16329 [1:08:02<1:09:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8077: train loss 1.60766. lr 5.138857e-04:  49%|████▉     | 8078/16329 [1:08:02<1:08:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8078: train loss 1.60440. lr 5.138654e-04:  49%|████▉     | 8078/16329 [1:08:02<1:08:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8078: train loss 1.60440. lr 5.138654e-04:  49%|████▉     | 8079/16329 [1:08:02<1:08:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8079: train loss 1.60632. lr 5.138452e-04:  49%|████▉     | 8079/16329 [1:08:03<1:08:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8079: train loss 1.60632. lr 5.138452e-04:  49%|████▉     | 8080/16329 [1:08:03<1:08:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8080: train loss 1.58740. lr 5.138250e-04:  49%|████▉     | 8080/16329 [1:08:03<1:08:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8080: train loss 1.58740. lr 5.138250e-04:  49%|████▉     | 8081/16329 [1:08:03<1:08:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8081: train loss 1.57632. lr 5.138047e-04:  49%|████▉     | 8081/16329 [1:08:04<1:08:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8081: train loss 1.57632. lr 5.138047e-04:  49%|████▉     | 8082/16329 [1:08:04<1:08:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8082: train loss 1.57580. lr 5.137845e-04:  49%|████▉     | 8082/16329 [1:08:04<1:08:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8082: train loss 1.57580. lr 5.137845e-04:  50%|████▉     | 8083/16329 [1:08:04<1:08:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8083: train loss 1.59110. lr 5.137642e-04:  50%|████▉     | 8083/16329 [1:08:05<1:08:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8083: train loss 1.59110. lr 5.137642e-04:  50%|████▉     | 8084/16329 [1:08:05<1:08:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8084: train loss 1.56770. lr 5.137440e-04:  50%|████▉     | 8084/16329 [1:08:05<1:08:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8084: train loss 1.56770. lr 5.137440e-04:  50%|████▉     | 8085/16329 [1:08:05<1:08:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8085: train loss 1.60474. lr 5.137237e-04:  50%|████▉     | 8085/16329 [1:08:06<1:08:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8085: train loss 1.60474. lr 5.137237e-04:  50%|████▉     | 8086/16329 [1:08:06<1:08:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8086: train loss 1.58084. lr 5.137035e-04:  50%|████▉     | 8086/16329 [1:08:06<1:08:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8086: train loss 1.58084. lr 5.137035e-04:  50%|████▉     | 8087/16329 [1:08:06<1:08:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8087: train loss 1.60588. lr 5.136832e-04:  50%|████▉     | 8087/16329 [1:08:07<1:08:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8087: train loss 1.60588. lr 5.136832e-04:  50%|████▉     | 8088/16329 [1:08:07<1:08:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8088: train loss 1.56523. lr 5.136629e-04:  50%|████▉     | 8088/16329 [1:08:07<1:08:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8088: train loss 1.56523. lr 5.136629e-04:  50%|████▉     | 8089/16329 [1:08:07<1:08:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8089: train loss 1.61850. lr 5.136427e-04:  50%|████▉     | 8089/16329 [1:08:08<1:08:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8089: train loss 1.61850. lr 5.136427e-04:  50%|████▉     | 8090/16329 [1:08:08<1:08:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8090: train loss 1.58654. lr 5.136224e-04:  50%|████▉     | 8090/16329 [1:08:08<1:08:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8090: train loss 1.58654. lr 5.136224e-04:  50%|████▉     | 8091/16329 [1:08:08<1:08:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8091: train loss 1.55584. lr 5.136022e-04:  50%|████▉     | 8091/16329 [1:08:09<1:08:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8091: train loss 1.55584. lr 5.136022e-04:  50%|████▉     | 8092/16329 [1:08:09<1:08:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8092: train loss 1.56305. lr 5.135819e-04:  50%|████▉     | 8092/16329 [1:08:09<1:08:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8092: train loss 1.56305. lr 5.135819e-04:  50%|████▉     | 8093/16329 [1:08:09<1:08:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8093: train loss 1.62687. lr 5.135616e-04:  50%|████▉     | 8093/16329 [1:08:10<1:08:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8093: train loss 1.62687. lr 5.135616e-04:  50%|████▉     | 8094/16329 [1:08:10<1:08:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8094: train loss 1.51910. lr 5.135414e-04:  50%|████▉     | 8094/16329 [1:08:10<1:08:00,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8094: train loss 1.51910. lr 5.135414e-04:  50%|████▉     | 8095/16329 [1:08:10<1:08:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8095: train loss 1.55576. lr 5.135211e-04:  50%|████▉     | 8095/16329 [1:08:11<1:08:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8095: train loss 1.55576. lr 5.135211e-04:  50%|████▉     | 8096/16329 [1:08:11<1:15:20,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8096: train loss 1.54514. lr 5.135008e-04:  50%|████▉     | 8096/16329 [1:08:11<1:15:20,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8096: train loss 1.54514. lr 5.135008e-04:  50%|████▉     | 8097/16329 [1:08:11<1:13:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8097: train loss 1.55855. lr 5.134805e-04:  50%|████▉     | 8097/16329 [1:08:12<1:13:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8097: train loss 1.55855. lr 5.134805e-04:  50%|████▉     | 8098/16329 [1:08:12<1:11:48,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8098: train loss 1.51293. lr 5.134603e-04:  50%|████▉     | 8098/16329 [1:08:12<1:11:48,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8098: train loss 1.51293. lr 5.134603e-04:  50%|████▉     | 8099/16329 [1:08:12<1:10:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8099: train loss 1.61769. lr 5.134400e-04:  50%|████▉     | 8099/16329 [1:08:13<1:10:26,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8099: train loss 1.61769. lr 5.134400e-04:  50%|████▉     | 8100/16329 [1:08:13<1:09:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8100: train loss 1.57456. lr 5.134197e-04:  50%|████▉     | 8100/16329 [1:08:13<1:09:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8100: train loss 1.57456. lr 5.134197e-04:  50%|████▉     | 8101/16329 [1:08:13<1:09:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8101: train loss 1.54460. lr 5.133994e-04:  50%|████▉     | 8101/16329 [1:08:14<1:09:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8101: train loss 1.54460. lr 5.133994e-04:  50%|████▉     | 8102/16329 [1:08:14<1:09:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8102: train loss 1.59633. lr 5.133791e-04:  50%|████▉     | 8102/16329 [1:08:14<1:09:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8102: train loss 1.59633. lr 5.133791e-04:  50%|████▉     | 8103/16329 [1:08:14<1:08:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8103: train loss 1.54057. lr 5.133588e-04:  50%|████▉     | 8103/16329 [1:08:15<1:08:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8103: train loss 1.54057. lr 5.133588e-04:  50%|████▉     | 8104/16329 [1:08:15<1:08:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8104: train loss 1.58039. lr 5.133385e-04:  50%|████▉     | 8104/16329 [1:08:15<1:08:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8104: train loss 1.58039. lr 5.133385e-04:  50%|████▉     | 8105/16329 [1:08:15<1:08:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8105: train loss 1.59334. lr 5.133183e-04:  50%|████▉     | 8105/16329 [1:08:16<1:08:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8105: train loss 1.59334. lr 5.133183e-04:  50%|████▉     | 8106/16329 [1:08:16<1:08:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8106: train loss 1.57619. lr 5.132980e-04:  50%|████▉     | 8106/16329 [1:08:16<1:08:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8106: train loss 1.57619. lr 5.132980e-04:  50%|████▉     | 8107/16329 [1:08:16<1:08:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8107: train loss 1.56584. lr 5.132777e-04:  50%|████▉     | 8107/16329 [1:08:17<1:08:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8107: train loss 1.56584. lr 5.132777e-04:  50%|████▉     | 8108/16329 [1:08:17<1:08:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8108: train loss 1.58903. lr 5.132574e-04:  50%|████▉     | 8108/16329 [1:08:17<1:08:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8108: train loss 1.58903. lr 5.132574e-04:  50%|████▉     | 8109/16329 [1:08:17<1:08:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8109: train loss 1.64285. lr 5.132371e-04:  50%|████▉     | 8109/16329 [1:08:18<1:08:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8109: train loss 1.64285. lr 5.132371e-04:  50%|████▉     | 8110/16329 [1:08:18<1:08:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8110: train loss 1.60404. lr 5.132168e-04:  50%|████▉     | 8110/16329 [1:08:18<1:08:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8110: train loss 1.60404. lr 5.132168e-04:  50%|████▉     | 8111/16329 [1:08:18<1:08:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8111: train loss 1.55515. lr 5.131965e-04:  50%|████▉     | 8111/16329 [1:08:19<1:08:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8111: train loss 1.55515. lr 5.131965e-04:  50%|████▉     | 8112/16329 [1:08:19<1:08:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8112: train loss 1.53041. lr 5.131762e-04:  50%|████▉     | 8112/16329 [1:08:19<1:08:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8112: train loss 1.53041. lr 5.131762e-04:  50%|████▉     | 8113/16329 [1:08:19<1:07:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8113: train loss 1.58724. lr 5.131559e-04:  50%|████▉     | 8113/16329 [1:08:20<1:07:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8113: train loss 1.58724. lr 5.131559e-04:  50%|████▉     | 8114/16329 [1:08:20<1:08:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8114: train loss 1.64632. lr 5.131355e-04:  50%|████▉     | 8114/16329 [1:08:20<1:08:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8114: train loss 1.64632. lr 5.131355e-04:  50%|████▉     | 8115/16329 [1:08:20<1:08:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8115: train loss 1.61789. lr 5.131152e-04:  50%|████▉     | 8115/16329 [1:08:21<1:08:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8115: train loss 1.61789. lr 5.131152e-04:  50%|████▉     | 8116/16329 [1:08:21<1:08:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8116: train loss 1.58966. lr 5.130949e-04:  50%|████▉     | 8116/16329 [1:08:21<1:08:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8116: train loss 1.58966. lr 5.130949e-04:  50%|████▉     | 8117/16329 [1:08:21<1:08:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8117: train loss 1.56959. lr 5.130746e-04:  50%|████▉     | 8117/16329 [1:08:22<1:08:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8117: train loss 1.56959. lr 5.130746e-04:  50%|████▉     | 8118/16329 [1:08:22<1:08:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8118: train loss 1.55141. lr 5.130543e-04:  50%|████▉     | 8118/16329 [1:08:22<1:08:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8118: train loss 1.55141. lr 5.130543e-04:  50%|████▉     | 8119/16329 [1:08:22<1:08:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8119: train loss 1.57515. lr 5.130340e-04:  50%|████▉     | 8119/16329 [1:08:23<1:08:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8119: train loss 1.57515. lr 5.130340e-04:  50%|████▉     | 8120/16329 [1:08:23<1:08:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8120: train loss 1.51077. lr 5.130136e-04:  50%|████▉     | 8120/16329 [1:08:23<1:08:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8120: train loss 1.51077. lr 5.130136e-04:  50%|████▉     | 8121/16329 [1:08:23<1:08:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8121: train loss 1.53996. lr 5.129933e-04:  50%|████▉     | 8121/16329 [1:08:24<1:08:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8121: train loss 1.53996. lr 5.129933e-04:  50%|████▉     | 8122/16329 [1:08:24<1:07:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8122: train loss 1.51846. lr 5.129730e-04:  50%|████▉     | 8122/16329 [1:08:24<1:07:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8122: train loss 1.51846. lr 5.129730e-04:  50%|████▉     | 8123/16329 [1:08:24<1:15:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8123: train loss 1.55723. lr 5.129527e-04:  50%|████▉     | 8123/16329 [1:08:25<1:15:11,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8123: train loss 1.55723. lr 5.129527e-04:  50%|████▉     | 8124/16329 [1:08:25<1:12:48,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8124: train loss 1.58612. lr 5.129323e-04:  50%|████▉     | 8124/16329 [1:08:25<1:12:48,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8124: train loss 1.58612. lr 5.129323e-04:  50%|████▉     | 8125/16329 [1:08:25<1:11:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8125: train loss 1.60450. lr 5.129120e-04:  50%|████▉     | 8125/16329 [1:08:26<1:11:00,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8125: train loss 1.60450. lr 5.129120e-04:  50%|████▉     | 8126/16329 [1:08:26<1:10:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8126: train loss 1.55236. lr 5.128917e-04:  50%|████▉     | 8126/16329 [1:08:26<1:10:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8126: train loss 1.55236. lr 5.128917e-04:  50%|████▉     | 8127/16329 [1:08:26<1:09:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8127: train loss 1.56409. lr 5.128713e-04:  50%|████▉     | 8127/16329 [1:08:27<1:09:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8127: train loss 1.56409. lr 5.128713e-04:  50%|████▉     | 8128/16329 [1:08:27<1:09:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8128: train loss 1.53768. lr 5.128510e-04:  50%|████▉     | 8128/16329 [1:08:27<1:09:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8128: train loss 1.53768. lr 5.128510e-04:  50%|████▉     | 8129/16329 [1:08:27<1:08:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8129: train loss 1.56539. lr 5.128307e-04:  50%|████▉     | 8129/16329 [1:08:28<1:08:45,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8129: train loss 1.56539. lr 5.128307e-04:  50%|████▉     | 8130/16329 [1:08:28<1:08:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8130: train loss 1.57161. lr 5.128103e-04:  50%|████▉     | 8130/16329 [1:08:28<1:08:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8130: train loss 1.57161. lr 5.128103e-04:  50%|████▉     | 8131/16329 [1:08:28<1:08:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8131: train loss 1.60288. lr 5.127900e-04:  50%|████▉     | 8131/16329 [1:08:29<1:08:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8131: train loss 1.60288. lr 5.127900e-04:  50%|████▉     | 8132/16329 [1:08:29<1:07:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8132: train loss 1.59622. lr 5.127696e-04:  50%|████▉     | 8132/16329 [1:08:29<1:07:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8132: train loss 1.59622. lr 5.127696e-04:  50%|████▉     | 8133/16329 [1:08:29<1:07:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8133: train loss 1.59642. lr 5.127493e-04:  50%|████▉     | 8133/16329 [1:08:30<1:07:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8133: train loss 1.59642. lr 5.127493e-04:  50%|████▉     | 8134/16329 [1:08:30<1:07:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8134: train loss 1.56220. lr 5.127289e-04:  50%|████▉     | 8134/16329 [1:08:30<1:07:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8134: train loss 1.56220. lr 5.127289e-04:  50%|████▉     | 8135/16329 [1:08:30<1:07:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8135: train loss 1.54529. lr 5.127086e-04:  50%|████▉     | 8135/16329 [1:08:31<1:07:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8135: train loss 1.54529. lr 5.127086e-04:  50%|████▉     | 8136/16329 [1:08:31<1:07:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8136: train loss 1.54408. lr 5.126882e-04:  50%|████▉     | 8136/16329 [1:08:31<1:07:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8136: train loss 1.54408. lr 5.126882e-04:  50%|████▉     | 8137/16329 [1:08:31<1:07:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8137: train loss 1.56918. lr 5.126679e-04:  50%|████▉     | 8137/16329 [1:08:32<1:07:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8137: train loss 1.56918. lr 5.126679e-04:  50%|████▉     | 8138/16329 [1:08:32<1:07:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8138: train loss 1.60296. lr 5.126475e-04:  50%|████▉     | 8138/16329 [1:08:32<1:07:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8138: train loss 1.60296. lr 5.126475e-04:  50%|████▉     | 8139/16329 [1:08:32<1:07:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8139: train loss 1.60542. lr 5.126272e-04:  50%|████▉     | 8139/16329 [1:08:33<1:07:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8139: train loss 1.60542. lr 5.126272e-04:  50%|████▉     | 8140/16329 [1:08:33<1:07:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8140: train loss 1.59583. lr 5.126068e-04:  50%|████▉     | 8140/16329 [1:08:33<1:07:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8140: train loss 1.59583. lr 5.126068e-04:  50%|████▉     | 8141/16329 [1:08:33<1:07:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8141: train loss 1.62558. lr 5.125864e-04:  50%|████▉     | 8141/16329 [1:08:34<1:07:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8141: train loss 1.62558. lr 5.125864e-04:  50%|████▉     | 8142/16329 [1:08:34<1:07:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8142: train loss 1.56322. lr 5.125661e-04:  50%|████▉     | 8142/16329 [1:08:34<1:07:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8142: train loss 1.56322. lr 5.125661e-04:  50%|████▉     | 8143/16329 [1:08:34<1:07:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8143: train loss 1.58629. lr 5.125457e-04:  50%|████▉     | 8143/16329 [1:08:35<1:07:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8143: train loss 1.58629. lr 5.125457e-04:  50%|████▉     | 8144/16329 [1:08:35<1:07:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8144: train loss 1.59520. lr 5.125253e-04:  50%|████▉     | 8144/16329 [1:08:35<1:07:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8144: train loss 1.59520. lr 5.125253e-04:  50%|████▉     | 8145/16329 [1:08:35<1:07:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8145: train loss 1.55138. lr 5.125050e-04:  50%|████▉     | 8145/16329 [1:08:36<1:07:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8145: train loss 1.55138. lr 5.125050e-04:  50%|████▉     | 8146/16329 [1:08:36<1:07:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8146: train loss 1.57065. lr 5.124846e-04:  50%|████▉     | 8146/16329 [1:08:36<1:07:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8146: train loss 1.57065. lr 5.124846e-04:  50%|████▉     | 8147/16329 [1:08:36<1:07:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8147: train loss 1.60506. lr 5.124642e-04:  50%|████▉     | 8147/16329 [1:08:37<1:07:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8147: train loss 1.60506. lr 5.124642e-04:  50%|████▉     | 8148/16329 [1:08:37<1:07:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8148: train loss 1.57403. lr 5.124439e-04:  50%|████▉     | 8148/16329 [1:08:37<1:07:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8148: train loss 1.57403. lr 5.124439e-04:  50%|████▉     | 8149/16329 [1:08:37<1:07:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8149: train loss 1.63049. lr 5.124235e-04:  50%|████▉     | 8149/16329 [1:08:38<1:07:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8149: train loss 1.63049. lr 5.124235e-04:  50%|████▉     | 8150/16329 [1:08:38<1:07:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8150: train loss 1.56860. lr 5.124031e-04:  50%|████▉     | 8150/16329 [1:08:38<1:07:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8150: train loss 1.56860. lr 5.124031e-04:  50%|████▉     | 8151/16329 [1:08:38<1:07:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8151: train loss 1.55263. lr 5.123827e-04:  50%|████▉     | 8151/16329 [1:08:39<1:07:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8151: train loss 1.55263. lr 5.123827e-04:  50%|████▉     | 8152/16329 [1:08:39<1:08:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8152: train loss 1.58728. lr 5.123623e-04:  50%|████▉     | 8152/16329 [1:08:39<1:08:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8152: train loss 1.58728. lr 5.123623e-04:  50%|████▉     | 8153/16329 [1:08:39<1:07:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8153: train loss 1.60665. lr 5.123419e-04:  50%|████▉     | 8153/16329 [1:08:40<1:07:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8153: train loss 1.60665. lr 5.123419e-04:  50%|████▉     | 8154/16329 [1:08:40<1:07:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8154: train loss 1.56959. lr 5.123216e-04:  50%|████▉     | 8154/16329 [1:08:40<1:07:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8154: train loss 1.56959. lr 5.123216e-04:  50%|████▉     | 8155/16329 [1:08:40<1:07:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8155: train loss 1.56304. lr 5.123012e-04:  50%|████▉     | 8155/16329 [1:08:41<1:07:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8155: train loss 1.56304. lr 5.123012e-04:  50%|████▉     | 8156/16329 [1:08:41<1:07:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8156: train loss 1.61513. lr 5.122808e-04:  50%|████▉     | 8156/16329 [1:08:41<1:07:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8156: train loss 1.61513. lr 5.122808e-04:  50%|████▉     | 8157/16329 [1:08:41<1:07:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8157: train loss 1.55840. lr 5.122604e-04:  50%|████▉     | 8157/16329 [1:08:42<1:07:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8157: train loss 1.55840. lr 5.122604e-04:  50%|████▉     | 8158/16329 [1:08:42<1:07:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8158: train loss 1.56492. lr 5.122400e-04:  50%|████▉     | 8158/16329 [1:08:42<1:07:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8158: train loss 1.56492. lr 5.122400e-04:  50%|████▉     | 8159/16329 [1:08:42<1:07:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8159: train loss 1.57943. lr 5.122196e-04:  50%|████▉     | 8159/16329 [1:08:43<1:07:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8159: train loss 1.57943. lr 5.122196e-04:  50%|████▉     | 8160/16329 [1:08:43<1:07:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8160: train loss 1.56845. lr 5.121992e-04:  50%|████▉     | 8160/16329 [1:08:43<1:07:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8160: train loss 1.56845. lr 5.121992e-04:  50%|████▉     | 8161/16329 [1:08:43<1:07:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8161: train loss 1.56902. lr 5.121788e-04:  50%|████▉     | 8161/16329 [1:08:44<1:07:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8161: train loss 1.56902. lr 5.121788e-04:  50%|████▉     | 8162/16329 [1:08:44<1:08:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8162: train loss 1.57587. lr 5.121584e-04:  50%|████▉     | 8162/16329 [1:08:45<1:08:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8162: train loss 1.57587. lr 5.121584e-04:  50%|████▉     | 8163/16329 [1:08:45<1:16:46,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 8163: train loss 1.57075. lr 5.121380e-04:  50%|████▉     | 8163/16329 [1:08:45<1:16:46,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 8163: train loss 1.57075. lr 5.121380e-04:  50%|████▉     | 8164/16329 [1:08:45<1:15:07,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 8164: train loss 1.53461. lr 5.121176e-04:  50%|████▉     | 8164/16329 [1:08:46<1:15:07,  1.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8164: train loss 1.53461. lr 5.121176e-04:  50%|█████     | 8165/16329 [1:08:46<1:13:32,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 8165: train loss 1.56449. lr 5.120972e-04:  50%|█████     | 8165/16329 [1:08:46<1:13:32,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 8165: train loss 1.56449. lr 5.120972e-04:  50%|█████     | 8166/16329 [1:08:46<1:12:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8166: train loss 1.57879. lr 5.120767e-04:  50%|█████     | 8166/16329 [1:08:47<1:12:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8166: train loss 1.57879. lr 5.120767e-04:  50%|█████     | 8167/16329 [1:08:47<1:10:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8167: train loss 1.53569. lr 5.120563e-04:  50%|█████     | 8167/16329 [1:08:47<1:10:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8167: train loss 1.53569. lr 5.120563e-04:  50%|█████     | 8168/16329 [1:08:47<1:10:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8168: train loss 1.55282. lr 5.120359e-04:  50%|█████     | 8168/16329 [1:08:48<1:10:11,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8168: train loss 1.55282. lr 5.120359e-04:  50%|█████     | 8169/16329 [1:08:48<1:09:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8169: train loss 1.56744. lr 5.120155e-04:  50%|█████     | 8169/16329 [1:08:48<1:09:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8169: train loss 1.56744. lr 5.120155e-04:  50%|█████     | 8170/16329 [1:08:48<1:08:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8170: train loss 1.61128. lr 5.119951e-04:  50%|█████     | 8170/16329 [1:08:49<1:08:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8170: train loss 1.61128. lr 5.119951e-04:  50%|█████     | 8171/16329 [1:08:49<1:08:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8171: train loss 1.53240. lr 5.119747e-04:  50%|█████     | 8171/16329 [1:08:49<1:08:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8171: train loss 1.53240. lr 5.119747e-04:  50%|█████     | 8172/16329 [1:08:49<1:08:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8172: train loss 1.58264. lr 5.119542e-04:  50%|█████     | 8172/16329 [1:08:50<1:08:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8172: train loss 1.58264. lr 5.119542e-04:  50%|█████     | 8173/16329 [1:08:50<1:07:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8173: train loss 1.62886. lr 5.119338e-04:  50%|█████     | 8173/16329 [1:08:50<1:07:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8173: train loss 1.62886. lr 5.119338e-04:  50%|█████     | 8174/16329 [1:08:50<1:07:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8174: train loss 1.61422. lr 5.119134e-04:  50%|█████     | 8174/16329 [1:08:51<1:07:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8174: train loss 1.61422. lr 5.119134e-04:  50%|█████     | 8175/16329 [1:08:51<1:07:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8175: train loss 1.56711. lr 5.118930e-04:  50%|█████     | 8175/16329 [1:08:51<1:07:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8175: train loss 1.56711. lr 5.118930e-04:  50%|█████     | 8176/16329 [1:08:51<1:07:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8176: train loss 1.57806. lr 5.118725e-04:  50%|█████     | 8176/16329 [1:08:52<1:07:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8176: train loss 1.57806. lr 5.118725e-04:  50%|█████     | 8177/16329 [1:08:52<1:07:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8177: train loss 1.57120. lr 5.118521e-04:  50%|█████     | 8177/16329 [1:08:52<1:07:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8177: train loss 1.57120. lr 5.118521e-04:  50%|█████     | 8178/16329 [1:08:52<1:07:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8178: train loss 1.56385. lr 5.118317e-04:  50%|█████     | 8178/16329 [1:08:53<1:07:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8178: train loss 1.56385. lr 5.118317e-04:  50%|█████     | 8179/16329 [1:08:53<1:07:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8179: train loss 1.58450. lr 5.118112e-04:  50%|█████     | 8179/16329 [1:08:53<1:07:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8179: train loss 1.58450. lr 5.118112e-04:  50%|█████     | 8180/16329 [1:08:53<1:07:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8180: train loss 1.54021. lr 5.117908e-04:  50%|█████     | 8180/16329 [1:08:54<1:07:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8180: train loss 1.54021. lr 5.117908e-04:  50%|█████     | 8181/16329 [1:08:54<1:07:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8181: train loss 1.55493. lr 5.117703e-04:  50%|█████     | 8181/16329 [1:08:54<1:07:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8181: train loss 1.55493. lr 5.117703e-04:  50%|█████     | 8182/16329 [1:08:54<1:07:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8182: train loss 1.57819. lr 5.117499e-04:  50%|█████     | 8182/16329 [1:08:55<1:07:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8182: train loss 1.57819. lr 5.117499e-04:  50%|█████     | 8183/16329 [1:08:55<1:09:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8183: train loss 1.61642. lr 5.117294e-04:  50%|█████     | 8183/16329 [1:08:55<1:09:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8183: train loss 1.61642. lr 5.117294e-04:  50%|█████     | 8184/16329 [1:08:55<1:09:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8184: train loss 1.57422. lr 5.117090e-04:  50%|█████     | 8184/16329 [1:08:56<1:09:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8184: train loss 1.57422. lr 5.117090e-04:  50%|█████     | 8185/16329 [1:08:56<1:09:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8185: train loss 1.63044. lr 5.116885e-04:  50%|█████     | 8185/16329 [1:08:56<1:09:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8185: train loss 1.63044. lr 5.116885e-04:  50%|█████     | 8186/16329 [1:08:56<1:09:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8186: train loss 1.56543. lr 5.116681e-04:  50%|█████     | 8186/16329 [1:08:57<1:09:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8186: train loss 1.56543. lr 5.116681e-04:  50%|█████     | 8187/16329 [1:08:57<1:08:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8187: train loss 1.54601. lr 5.116476e-04:  50%|█████     | 8187/16329 [1:08:57<1:08:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8187: train loss 1.54601. lr 5.116476e-04:  50%|█████     | 8188/16329 [1:08:57<1:08:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8188: train loss 1.60789. lr 5.116272e-04:  50%|█████     | 8188/16329 [1:08:58<1:08:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8188: train loss 1.60789. lr 5.116272e-04:  50%|█████     | 8189/16329 [1:08:58<1:08:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8189: train loss 1.49742. lr 5.116067e-04:  50%|█████     | 8189/16329 [1:08:58<1:08:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8189: train loss 1.49742. lr 5.116067e-04:  50%|█████     | 8190/16329 [1:08:58<1:07:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8190: train loss 1.51740. lr 5.115863e-04:  50%|█████     | 8190/16329 [1:08:59<1:07:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8190: train loss 1.51740. lr 5.115863e-04:  50%|█████     | 8191/16329 [1:08:59<1:07:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8191: train loss 1.59784. lr 5.115658e-04:  50%|█████     | 8191/16329 [1:08:59<1:07:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8191: train loss 1.59784. lr 5.115658e-04:  50%|█████     | 8192/16329 [1:08:59<1:07:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8192: train loss 1.58861. lr 5.115454e-04:  50%|█████     | 8192/16329 [1:09:00<1:07:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8192: train loss 1.58861. lr 5.115454e-04:  50%|█████     | 8193/16329 [1:09:00<1:07:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8193: train loss 1.54318. lr 5.115249e-04:  50%|█████     | 8193/16329 [1:09:00<1:07:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8193: train loss 1.54318. lr 5.115249e-04:  50%|█████     | 8194/16329 [1:09:00<1:06:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8194: train loss 1.56874. lr 5.115044e-04:  50%|█████     | 8194/16329 [1:09:01<1:06:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8194: train loss 1.56874. lr 5.115044e-04:  50%|█████     | 8195/16329 [1:09:01<1:07:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8195: train loss 1.57545. lr 5.114840e-04:  50%|█████     | 8195/16329 [1:09:01<1:07:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8195: train loss 1.57545. lr 5.114840e-04:  50%|█████     | 8196/16329 [1:09:01<1:06:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8196: train loss 1.56662. lr 5.114635e-04:  50%|█████     | 8196/16329 [1:09:02<1:06:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8196: train loss 1.56662. lr 5.114635e-04:  50%|█████     | 8197/16329 [1:09:02<1:06:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8197: train loss 1.56597. lr 5.114430e-04:  50%|█████     | 8197/16329 [1:09:02<1:06:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8197: train loss 1.56597. lr 5.114430e-04:  50%|█████     | 8198/16329 [1:09:02<1:14:02,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8198: train loss 1.62588. lr 5.114225e-04:  50%|█████     | 8198/16329 [1:09:03<1:14:02,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8198: train loss 1.62588. lr 5.114225e-04:  50%|█████     | 8199/16329 [1:09:03<1:12:07,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8199: train loss 1.58210. lr 5.114021e-04:  50%|█████     | 8199/16329 [1:09:03<1:12:07,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8199: train loss 1.58210. lr 5.114021e-04:  50%|█████     | 8200/16329 [1:09:03<1:10:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8200: train loss 1.59769. lr 5.113816e-04:  50%|█████     | 8200/16329 [1:09:04<1:10:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8200: train loss 1.59769. lr 5.113816e-04:  50%|█████     | 8201/16329 [1:09:04<1:09:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8201: train loss 1.54294. lr 5.113611e-04:  50%|█████     | 8201/16329 [1:09:04<1:09:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8201: train loss 1.54294. lr 5.113611e-04:  50%|█████     | 8202/16329 [1:09:04<1:08:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8202: train loss 1.55604. lr 5.113406e-04:  50%|█████     | 8202/16329 [1:09:05<1:08:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8202: train loss 1.55604. lr 5.113406e-04:  50%|█████     | 8203/16329 [1:09:05<1:08:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8203: train loss 1.59799. lr 5.113201e-04:  50%|█████     | 8203/16329 [1:09:05<1:08:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8203: train loss 1.59799. lr 5.113201e-04:  50%|█████     | 8204/16329 [1:09:05<1:07:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8204: train loss 1.55952. lr 5.112996e-04:  50%|█████     | 8204/16329 [1:09:06<1:07:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8204: train loss 1.55952. lr 5.112996e-04:  50%|█████     | 8205/16329 [1:09:06<1:07:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8205: train loss 1.56990. lr 5.112792e-04:  50%|█████     | 8205/16329 [1:09:06<1:07:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8205: train loss 1.56990. lr 5.112792e-04:  50%|█████     | 8206/16329 [1:09:06<1:07:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8206: train loss 1.55073. lr 5.112587e-04:  50%|█████     | 8206/16329 [1:09:07<1:07:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8206: train loss 1.55073. lr 5.112587e-04:  50%|█████     | 8207/16329 [1:09:07<1:07:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8207: train loss 1.55515. lr 5.112382e-04:  50%|█████     | 8207/16329 [1:09:07<1:07:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8207: train loss 1.55515. lr 5.112382e-04:  50%|█████     | 8208/16329 [1:09:07<1:07:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8208: train loss 1.52503. lr 5.112177e-04:  50%|█████     | 8208/16329 [1:09:08<1:07:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8208: train loss 1.52503. lr 5.112177e-04:  50%|█████     | 8209/16329 [1:09:08<1:06:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8209: train loss 1.55525. lr 5.111972e-04:  50%|█████     | 8209/16329 [1:09:08<1:06:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8209: train loss 1.55525. lr 5.111972e-04:  50%|█████     | 8210/16329 [1:09:08<1:07:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8210: train loss 1.57912. lr 5.111767e-04:  50%|█████     | 8210/16329 [1:09:09<1:07:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8210: train loss 1.57912. lr 5.111767e-04:  50%|█████     | 8211/16329 [1:09:09<1:06:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8211: train loss 1.56145. lr 5.111562e-04:  50%|█████     | 8211/16329 [1:09:09<1:06:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8211: train loss 1.56145. lr 5.111562e-04:  50%|█████     | 8212/16329 [1:09:09<1:06:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8212: train loss 1.54798. lr 5.111357e-04:  50%|█████     | 8212/16329 [1:09:10<1:06:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8212: train loss 1.54798. lr 5.111357e-04:  50%|█████     | 8213/16329 [1:09:10<1:06:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8213: train loss 1.57722. lr 5.111152e-04:  50%|█████     | 8213/16329 [1:09:10<1:06:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8213: train loss 1.57722. lr 5.111152e-04:  50%|█████     | 8214/16329 [1:09:10<1:06:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8214: train loss 1.55756. lr 5.110947e-04:  50%|█████     | 8214/16329 [1:09:11<1:06:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8214: train loss 1.55756. lr 5.110947e-04:  50%|█████     | 8215/16329 [1:09:11<1:07:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8215: train loss 1.54366. lr 5.110742e-04:  50%|█████     | 8215/16329 [1:09:11<1:07:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8215: train loss 1.54366. lr 5.110742e-04:  50%|█████     | 8216/16329 [1:09:11<1:06:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8216: train loss 1.55047. lr 5.110537e-04:  50%|█████     | 8216/16329 [1:09:12<1:06:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8216: train loss 1.55047. lr 5.110537e-04:  50%|█████     | 8217/16329 [1:09:12<1:07:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8217: train loss 1.58194. lr 5.110332e-04:  50%|█████     | 8217/16329 [1:09:12<1:07:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8217: train loss 1.58194. lr 5.110332e-04:  50%|█████     | 8218/16329 [1:09:12<1:06:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8218: train loss 1.53471. lr 5.110126e-04:  50%|█████     | 8218/16329 [1:09:13<1:06:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8218: train loss 1.53471. lr 5.110126e-04:  50%|█████     | 8219/16329 [1:09:13<1:06:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8219: train loss 1.56474. lr 5.109921e-04:  50%|█████     | 8219/16329 [1:09:13<1:06:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8219: train loss 1.56474. lr 5.109921e-04:  50%|█████     | 8220/16329 [1:09:13<1:07:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8220: train loss 1.57384. lr 5.109716e-04:  50%|█████     | 8220/16329 [1:09:14<1:07:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8220: train loss 1.57384. lr 5.109716e-04:  50%|█████     | 8221/16329 [1:09:14<1:06:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8221: train loss 1.59503. lr 5.109511e-04:  50%|█████     | 8221/16329 [1:09:14<1:06:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8221: train loss 1.59503. lr 5.109511e-04:  50%|█████     | 8222/16329 [1:09:14<1:07:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8222: train loss 1.57213. lr 5.109306e-04:  50%|█████     | 8222/16329 [1:09:15<1:07:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8222: train loss 1.57213. lr 5.109306e-04:  50%|█████     | 8223/16329 [1:09:15<1:14:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8223: train loss 1.55726. lr 5.109100e-04:  50%|█████     | 8223/16329 [1:09:15<1:14:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8223: train loss 1.55726. lr 5.109100e-04:  50%|█████     | 8224/16329 [1:09:15<1:12:13,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8224: train loss 1.56939. lr 5.108895e-04:  50%|█████     | 8224/16329 [1:09:16<1:12:13,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8224: train loss 1.56939. lr 5.108895e-04:  50%|█████     | 8225/16329 [1:09:16<1:10:41,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8225: train loss 1.56027. lr 5.108690e-04:  50%|█████     | 8225/16329 [1:09:16<1:10:41,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8225: train loss 1.56027. lr 5.108690e-04:  50%|█████     | 8226/16329 [1:09:16<1:09:29,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8226: train loss 1.54944. lr 5.108485e-04:  50%|█████     | 8226/16329 [1:09:17<1:09:29,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8226: train loss 1.54944. lr 5.108485e-04:  50%|█████     | 8227/16329 [1:09:17<1:08:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8227: train loss 1.58958. lr 5.108279e-04:  50%|█████     | 8227/16329 [1:09:17<1:08:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8227: train loss 1.58958. lr 5.108279e-04:  50%|█████     | 8228/16329 [1:09:17<1:08:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8228: train loss 1.54423. lr 5.108074e-04:  50%|█████     | 8228/16329 [1:09:18<1:08:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8228: train loss 1.54423. lr 5.108074e-04:  50%|█████     | 8229/16329 [1:09:18<1:07:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8229: train loss 1.58854. lr 5.107869e-04:  50%|█████     | 8229/16329 [1:09:18<1:07:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8229: train loss 1.58854. lr 5.107869e-04:  50%|█████     | 8230/16329 [1:09:18<1:07:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8230: train loss 1.57818. lr 5.107663e-04:  50%|█████     | 8230/16329 [1:09:19<1:07:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8230: train loss 1.57818. lr 5.107663e-04:  50%|█████     | 8231/16329 [1:09:19<1:07:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8231: train loss 1.54766. lr 5.107458e-04:  50%|█████     | 8231/16329 [1:09:19<1:07:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8231: train loss 1.54766. lr 5.107458e-04:  50%|█████     | 8232/16329 [1:09:19<1:07:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8232: train loss 1.54887. lr 5.107252e-04:  50%|█████     | 8232/16329 [1:09:20<1:07:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8232: train loss 1.54887. lr 5.107252e-04:  50%|█████     | 8233/16329 [1:09:20<1:06:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8233: train loss 1.60628. lr 5.107047e-04:  50%|█████     | 8233/16329 [1:09:20<1:06:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8233: train loss 1.60628. lr 5.107047e-04:  50%|█████     | 8234/16329 [1:09:20<1:06:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8234: train loss 1.60030. lr 5.106842e-04:  50%|█████     | 8234/16329 [1:09:21<1:06:58,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8234: train loss 1.60030. lr 5.106842e-04:  50%|█████     | 8235/16329 [1:09:21<1:06:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8235: train loss 1.57419. lr 5.106636e-04:  50%|█████     | 8235/16329 [1:09:21<1:06:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8235: train loss 1.57419. lr 5.106636e-04:  50%|█████     | 8236/16329 [1:09:21<1:06:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8236: train loss 1.60258. lr 5.106431e-04:  50%|█████     | 8236/16329 [1:09:22<1:06:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8236: train loss 1.60258. lr 5.106431e-04:  50%|█████     | 8237/16329 [1:09:22<1:06:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8237: train loss 1.58851. lr 5.106225e-04:  50%|█████     | 8237/16329 [1:09:22<1:06:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8237: train loss 1.58851. lr 5.106225e-04:  50%|█████     | 8238/16329 [1:09:22<1:06:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8238: train loss 1.57945. lr 5.106020e-04:  50%|█████     | 8238/16329 [1:09:23<1:06:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8238: train loss 1.57945. lr 5.106020e-04:  50%|█████     | 8239/16329 [1:09:23<1:06:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8239: train loss 1.59577. lr 5.105814e-04:  50%|█████     | 8239/16329 [1:09:23<1:06:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8239: train loss 1.59577. lr 5.105814e-04:  50%|█████     | 8240/16329 [1:09:23<1:06:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8240: train loss 1.57475. lr 5.105608e-04:  50%|█████     | 8240/16329 [1:09:24<1:06:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8240: train loss 1.57475. lr 5.105608e-04:  50%|█████     | 8241/16329 [1:09:24<1:06:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8241: train loss 1.54160. lr 5.105403e-04:  50%|█████     | 8241/16329 [1:09:24<1:06:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8241: train loss 1.54160. lr 5.105403e-04:  50%|█████     | 8242/16329 [1:09:24<1:06:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8242: train loss 1.53315. lr 5.105197e-04:  50%|█████     | 8242/16329 [1:09:25<1:06:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8242: train loss 1.53315. lr 5.105197e-04:  50%|█████     | 8243/16329 [1:09:25<1:06:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8243: train loss 1.59800. lr 5.104992e-04:  50%|█████     | 8243/16329 [1:09:25<1:06:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8243: train loss 1.59800. lr 5.104992e-04:  50%|█████     | 8244/16329 [1:09:25<1:06:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8244: train loss 1.58610. lr 5.104786e-04:  50%|█████     | 8244/16329 [1:09:26<1:06:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8244: train loss 1.58610. lr 5.104786e-04:  50%|█████     | 8245/16329 [1:09:26<1:06:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8245: train loss 1.51787. lr 5.104580e-04:  50%|█████     | 8245/16329 [1:09:26<1:06:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8245: train loss 1.51787. lr 5.104580e-04:  50%|█████     | 8246/16329 [1:09:26<1:06:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8246: train loss 1.55523. lr 5.104375e-04:  50%|█████     | 8246/16329 [1:09:27<1:06:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8246: train loss 1.55523. lr 5.104375e-04:  51%|█████     | 8247/16329 [1:09:27<1:06:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8247: train loss 1.52787. lr 5.104169e-04:  51%|█████     | 8247/16329 [1:09:27<1:06:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8247: train loss 1.52787. lr 5.104169e-04:  51%|█████     | 8248/16329 [1:09:27<1:06:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8248: train loss 1.56567. lr 5.103963e-04:  51%|█████     | 8248/16329 [1:09:28<1:06:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8248: train loss 1.56567. lr 5.103963e-04:  51%|█████     | 8249/16329 [1:09:28<1:06:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8249: train loss 1.55851. lr 5.103758e-04:  51%|█████     | 8249/16329 [1:09:28<1:06:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8249: train loss 1.55851. lr 5.103758e-04:  51%|█████     | 8250/16329 [1:09:28<1:14:04,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8250: train loss 1.59890. lr 5.103552e-04:  51%|█████     | 8250/16329 [1:09:29<1:14:04,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8250: train loss 1.59890. lr 5.103552e-04:  51%|█████     | 8251/16329 [1:09:29<1:12:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8251: train loss 1.57232. lr 5.103346e-04:  51%|█████     | 8251/16329 [1:09:29<1:12:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8251: train loss 1.57232. lr 5.103346e-04:  51%|█████     | 8252/16329 [1:09:29<1:10:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8252: train loss 1.53764. lr 5.103140e-04:  51%|█████     | 8252/16329 [1:09:30<1:10:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8252: train loss 1.53764. lr 5.103140e-04:  51%|█████     | 8253/16329 [1:09:30<1:09:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8253: train loss 1.57058. lr 5.102934e-04:  51%|█████     | 8253/16329 [1:09:30<1:09:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8253: train loss 1.57058. lr 5.102934e-04:  51%|█████     | 8254/16329 [1:09:30<1:08:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8254: train loss 1.59892. lr 5.102729e-04:  51%|█████     | 8254/16329 [1:09:31<1:08:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8254: train loss 1.59892. lr 5.102729e-04:  51%|█████     | 8255/16329 [1:09:31<1:07:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8255: train loss 1.55251. lr 5.102523e-04:  51%|█████     | 8255/16329 [1:09:31<1:07:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8255: train loss 1.55251. lr 5.102523e-04:  51%|█████     | 8256/16329 [1:09:31<1:07:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8256: train loss 1.57350. lr 5.102317e-04:  51%|█████     | 8256/16329 [1:09:32<1:07:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8256: train loss 1.57350. lr 5.102317e-04:  51%|█████     | 8257/16329 [1:09:32<1:07:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8257: train loss 1.57277. lr 5.102111e-04:  51%|█████     | 8257/16329 [1:09:32<1:07:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8257: train loss 1.57277. lr 5.102111e-04:  51%|█████     | 8258/16329 [1:09:32<1:07:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8258: train loss 1.59450. lr 5.101905e-04:  51%|█████     | 8258/16329 [1:09:33<1:07:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8258: train loss 1.59450. lr 5.101905e-04:  51%|█████     | 8259/16329 [1:09:33<1:06:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8259: train loss 1.54729. lr 5.101699e-04:  51%|█████     | 8259/16329 [1:09:33<1:06:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8259: train loss 1.54729. lr 5.101699e-04:  51%|█████     | 8260/16329 [1:09:33<1:06:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8260: train loss 1.49914. lr 5.101493e-04:  51%|█████     | 8260/16329 [1:09:34<1:06:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8260: train loss 1.49914. lr 5.101493e-04:  51%|█████     | 8261/16329 [1:09:34<1:06:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8261: train loss 1.54128. lr 5.101287e-04:  51%|█████     | 8261/16329 [1:09:34<1:06:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8261: train loss 1.54128. lr 5.101287e-04:  51%|█████     | 8262/16329 [1:09:34<1:06:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8262: train loss 1.54717. lr 5.101081e-04:  51%|█████     | 8262/16329 [1:09:35<1:06:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8262: train loss 1.54717. lr 5.101081e-04:  51%|█████     | 8263/16329 [1:09:35<1:06:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8263: train loss 1.58417. lr 5.100875e-04:  51%|█████     | 8263/16329 [1:09:35<1:06:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8263: train loss 1.58417. lr 5.100875e-04:  51%|█████     | 8264/16329 [1:09:35<1:06:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8264: train loss 1.59936. lr 5.100669e-04:  51%|█████     | 8264/16329 [1:09:36<1:06:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8264: train loss 1.59936. lr 5.100669e-04:  51%|█████     | 8265/16329 [1:09:36<1:06:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8265: train loss 1.58667. lr 5.100463e-04:  51%|█████     | 8265/16329 [1:09:36<1:06:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8265: train loss 1.58667. lr 5.100463e-04:  51%|█████     | 8266/16329 [1:09:36<1:06:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8266: train loss 1.53761. lr 5.100257e-04:  51%|█████     | 8266/16329 [1:09:37<1:06:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8266: train loss 1.53761. lr 5.100257e-04:  51%|█████     | 8267/16329 [1:09:37<1:06:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8267: train loss 1.56312. lr 5.100051e-04:  51%|█████     | 8267/16329 [1:09:37<1:06:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8267: train loss 1.56312. lr 5.100051e-04:  51%|█████     | 8268/16329 [1:09:37<1:06:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8268: train loss 1.57476. lr 5.099845e-04:  51%|█████     | 8268/16329 [1:09:38<1:06:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8268: train loss 1.57476. lr 5.099845e-04:  51%|█████     | 8269/16329 [1:09:38<1:06:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8269: train loss 1.57609. lr 5.099639e-04:  51%|█████     | 8269/16329 [1:09:38<1:06:18,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8269: train loss 1.57609. lr 5.099639e-04:  51%|█████     | 8270/16329 [1:09:38<1:06:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8270: train loss 1.58368. lr 5.099433e-04:  51%|█████     | 8270/16329 [1:09:39<1:06:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8270: train loss 1.58368. lr 5.099433e-04:  51%|█████     | 8271/16329 [1:09:39<1:06:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8271: train loss 1.56833. lr 5.099226e-04:  51%|█████     | 8271/16329 [1:09:39<1:06:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8271: train loss 1.56833. lr 5.099226e-04:  51%|█████     | 8272/16329 [1:09:39<1:06:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8272: train loss 1.58463. lr 5.099020e-04:  51%|█████     | 8272/16329 [1:09:40<1:06:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8272: train loss 1.58463. lr 5.099020e-04:  51%|█████     | 8273/16329 [1:09:40<1:06:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8273: train loss 1.56628. lr 5.098814e-04:  51%|█████     | 8273/16329 [1:09:40<1:06:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8273: train loss 1.56628. lr 5.098814e-04:  51%|█████     | 8274/16329 [1:09:40<1:06:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8274: train loss 1.59788. lr 5.098608e-04:  51%|█████     | 8274/16329 [1:09:41<1:06:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8274: train loss 1.59788. lr 5.098608e-04:  51%|█████     | 8275/16329 [1:09:41<1:07:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8275: train loss 1.56319. lr 5.098401e-04:  51%|█████     | 8275/16329 [1:09:41<1:07:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8275: train loss 1.56319. lr 5.098401e-04:  51%|█████     | 8276/16329 [1:09:41<1:06:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8276: train loss 1.56704. lr 5.098195e-04:  51%|█████     | 8276/16329 [1:09:42<1:06:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8276: train loss 1.56704. lr 5.098195e-04:  51%|█████     | 8277/16329 [1:09:42<1:06:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8277: train loss 1.53955. lr 5.097989e-04:  51%|█████     | 8277/16329 [1:09:42<1:06:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8277: train loss 1.53955. lr 5.097989e-04:  51%|█████     | 8278/16329 [1:09:42<1:06:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8278: train loss 1.57266. lr 5.097783e-04:  51%|█████     | 8278/16329 [1:09:43<1:06:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8278: train loss 1.57266. lr 5.097783e-04:  51%|█████     | 8279/16329 [1:09:43<1:06:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8279: train loss 1.57956. lr 5.097576e-04:  51%|█████     | 8279/16329 [1:09:43<1:06:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8279: train loss 1.57956. lr 5.097576e-04:  51%|█████     | 8280/16329 [1:09:43<1:06:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8280: train loss 1.56953. lr 5.097370e-04:  51%|█████     | 8280/16329 [1:09:44<1:06:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8280: train loss 1.56953. lr 5.097370e-04:  51%|█████     | 8281/16329 [1:09:44<1:06:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8281: train loss 1.51109. lr 5.097164e-04:  51%|█████     | 8281/16329 [1:09:44<1:06:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8281: train loss 1.51109. lr 5.097164e-04:  51%|█████     | 8282/16329 [1:09:44<1:06:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8282: train loss 1.57716. lr 5.096957e-04:  51%|█████     | 8282/16329 [1:09:45<1:06:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8282: train loss 1.57716. lr 5.096957e-04:  51%|█████     | 8283/16329 [1:09:45<1:06:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8283: train loss 1.57089. lr 5.096751e-04:  51%|█████     | 8283/16329 [1:09:45<1:06:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8283: train loss 1.57089. lr 5.096751e-04:  51%|█████     | 8284/16329 [1:09:45<1:06:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8284: train loss 1.52355. lr 5.096544e-04:  51%|█████     | 8284/16329 [1:09:46<1:06:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8284: train loss 1.52355. lr 5.096544e-04:  51%|█████     | 8285/16329 [1:09:46<1:06:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8285: train loss 1.55374. lr 5.096338e-04:  51%|█████     | 8285/16329 [1:09:46<1:06:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8285: train loss 1.55374. lr 5.096338e-04:  51%|█████     | 8286/16329 [1:09:46<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8286: train loss 1.55429. lr 5.096132e-04:  51%|█████     | 8286/16329 [1:09:47<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8286: train loss 1.55429. lr 5.096132e-04:  51%|█████     | 8287/16329 [1:09:47<1:06:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8287: train loss 1.55843. lr 5.095925e-04:  51%|█████     | 8287/16329 [1:09:47<1:06:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8287: train loss 1.55843. lr 5.095925e-04:  51%|█████     | 8288/16329 [1:09:47<1:06:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8288: train loss 1.57331. lr 5.095719e-04:  51%|█████     | 8288/16329 [1:09:48<1:06:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8288: train loss 1.57331. lr 5.095719e-04:  51%|█████     | 8289/16329 [1:09:48<1:06:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8289: train loss 1.58931. lr 5.095512e-04:  51%|█████     | 8289/16329 [1:09:48<1:06:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8289: train loss 1.58931. lr 5.095512e-04:  51%|█████     | 8290/16329 [1:09:48<1:15:44,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 8290: train loss 1.52378. lr 5.095305e-04:  51%|█████     | 8290/16329 [1:09:49<1:15:44,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 8290: train loss 1.52378. lr 5.095305e-04:  51%|█████     | 8291/16329 [1:09:49<1:13:08,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8291: train loss 1.56446. lr 5.095099e-04:  51%|█████     | 8291/16329 [1:09:49<1:13:08,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8291: train loss 1.56446. lr 5.095099e-04:  51%|█████     | 8292/16329 [1:09:49<1:11:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8292: train loss 1.60667. lr 5.094892e-04:  51%|█████     | 8292/16329 [1:09:50<1:11:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8292: train loss 1.60667. lr 5.094892e-04:  51%|█████     | 8293/16329 [1:09:50<1:09:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8293: train loss 1.54146. lr 5.094686e-04:  51%|█████     | 8293/16329 [1:09:50<1:09:45,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8293: train loss 1.54146. lr 5.094686e-04:  51%|█████     | 8294/16329 [1:09:50<1:08:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8294: train loss 1.61468. lr 5.094479e-04:  51%|█████     | 8294/16329 [1:09:51<1:08:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8294: train loss 1.61468. lr 5.094479e-04:  51%|█████     | 8295/16329 [1:09:51<1:07:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8295: train loss 1.53936. lr 5.094273e-04:  51%|█████     | 8295/16329 [1:09:51<1:07:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8295: train loss 1.53936. lr 5.094273e-04:  51%|█████     | 8296/16329 [1:09:51<1:07:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8296: train loss 1.55818. lr 5.094066e-04:  51%|█████     | 8296/16329 [1:09:52<1:07:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8296: train loss 1.55818. lr 5.094066e-04:  51%|█████     | 8297/16329 [1:09:52<1:06:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8297: train loss 1.50195. lr 5.093859e-04:  51%|█████     | 8297/16329 [1:09:52<1:06:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8297: train loss 1.50195. lr 5.093859e-04:  51%|█████     | 8298/16329 [1:09:52<1:06:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8298: train loss 1.53955. lr 5.093652e-04:  51%|█████     | 8298/16329 [1:09:53<1:06:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8298: train loss 1.53955. lr 5.093652e-04:  51%|█████     | 8299/16329 [1:09:53<1:06:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8299: train loss 1.53853. lr 5.093446e-04:  51%|█████     | 8299/16329 [1:09:53<1:06:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8299: train loss 1.53853. lr 5.093446e-04:  51%|█████     | 8300/16329 [1:09:53<1:06:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8300: train loss 1.60096. lr 5.093239e-04:  51%|█████     | 8300/16329 [1:09:54<1:06:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8300: train loss 1.60096. lr 5.093239e-04:  51%|█████     | 8301/16329 [1:09:54<1:06:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8301: train loss 1.49922. lr 5.093032e-04:  51%|█████     | 8301/16329 [1:09:54<1:06:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8301: train loss 1.49922. lr 5.093032e-04:  51%|█████     | 8302/16329 [1:09:54<1:06:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8302: train loss 1.58627. lr 5.092826e-04:  51%|█████     | 8302/16329 [1:09:55<1:06:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8302: train loss 1.58627. lr 5.092826e-04:  51%|█████     | 8303/16329 [1:09:55<1:06:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8303: train loss 1.56904. lr 5.092619e-04:  51%|█████     | 8303/16329 [1:09:55<1:06:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8303: train loss 1.56904. lr 5.092619e-04:  51%|█████     | 8304/16329 [1:09:55<1:06:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8304: train loss 1.54805. lr 5.092412e-04:  51%|█████     | 8304/16329 [1:09:56<1:06:17,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8304: train loss 1.54805. lr 5.092412e-04:  51%|█████     | 8305/16329 [1:09:56<1:06:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8305: train loss 1.55897. lr 5.092205e-04:  51%|█████     | 8305/16329 [1:09:56<1:06:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8305: train loss 1.55897. lr 5.092205e-04:  51%|█████     | 8306/16329 [1:09:56<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8306: train loss 1.52368. lr 5.091998e-04:  51%|█████     | 8306/16329 [1:09:57<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8306: train loss 1.52368. lr 5.091998e-04:  51%|█████     | 8307/16329 [1:09:57<1:06:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8307: train loss 1.56628. lr 5.091791e-04:  51%|█████     | 8307/16329 [1:09:57<1:06:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8307: train loss 1.56628. lr 5.091791e-04:  51%|█████     | 8308/16329 [1:09:57<1:06:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8308: train loss 1.51785. lr 5.091585e-04:  51%|█████     | 8308/16329 [1:09:58<1:06:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8308: train loss 1.51785. lr 5.091585e-04:  51%|█████     | 8309/16329 [1:09:58<1:06:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8309: train loss 1.60827. lr 5.091378e-04:  51%|█████     | 8309/16329 [1:09:58<1:06:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8309: train loss 1.60827. lr 5.091378e-04:  51%|█████     | 8310/16329 [1:09:58<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8310: train loss 1.53802. lr 5.091171e-04:  51%|█████     | 8310/16329 [1:09:59<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8310: train loss 1.53802. lr 5.091171e-04:  51%|█████     | 8311/16329 [1:09:59<1:06:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8311: train loss 1.53858. lr 5.090964e-04:  51%|█████     | 8311/16329 [1:09:59<1:06:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8311: train loss 1.53858. lr 5.090964e-04:  51%|█████     | 8312/16329 [1:09:59<1:06:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8312: train loss 1.54453. lr 5.090757e-04:  51%|█████     | 8312/16329 [1:10:00<1:06:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8312: train loss 1.54453. lr 5.090757e-04:  51%|█████     | 8313/16329 [1:10:00<1:06:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8313: train loss 1.56399. lr 5.090550e-04:  51%|█████     | 8313/16329 [1:10:00<1:06:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8313: train loss 1.56399. lr 5.090550e-04:  51%|█████     | 8314/16329 [1:10:00<1:05:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8314: train loss 1.58594. lr 5.090343e-04:  51%|█████     | 8314/16329 [1:10:01<1:05:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8314: train loss 1.58594. lr 5.090343e-04:  51%|█████     | 8315/16329 [1:10:01<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8315: train loss 1.56555. lr 5.090136e-04:  51%|█████     | 8315/16329 [1:10:01<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8315: train loss 1.56555. lr 5.090136e-04:  51%|█████     | 8316/16329 [1:10:01<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8316: train loss 1.58595. lr 5.089929e-04:  51%|█████     | 8316/16329 [1:10:02<1:06:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8316: train loss 1.58595. lr 5.089929e-04:  51%|█████     | 8317/16329 [1:10:02<1:06:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8317: train loss 1.50491. lr 5.089722e-04:  51%|█████     | 8317/16329 [1:10:02<1:06:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8317: train loss 1.50491. lr 5.089722e-04:  51%|█████     | 8318/16329 [1:10:02<1:06:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8318: train loss 1.53453. lr 5.089515e-04:  51%|█████     | 8318/16329 [1:10:03<1:06:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8318: train loss 1.53453. lr 5.089515e-04:  51%|█████     | 8319/16329 [1:10:03<1:06:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8319: train loss 1.55432. lr 5.089308e-04:  51%|█████     | 8319/16329 [1:10:03<1:06:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8319: train loss 1.55432. lr 5.089308e-04:  51%|█████     | 8320/16329 [1:10:03<1:06:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8320: train loss 1.52461. lr 5.089100e-04:  51%|█████     | 8320/16329 [1:10:04<1:06:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8320: train loss 1.52461. lr 5.089100e-04:  51%|█████     | 8321/16329 [1:10:04<1:05:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8321: train loss 1.55449. lr 5.088893e-04:  51%|█████     | 8321/16329 [1:10:04<1:05:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8321: train loss 1.55449. lr 5.088893e-04:  51%|█████     | 8322/16329 [1:10:04<1:06:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8322: train loss 1.54750. lr 5.088686e-04:  51%|█████     | 8322/16329 [1:10:05<1:06:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8322: train loss 1.54750. lr 5.088686e-04:  51%|█████     | 8323/16329 [1:10:05<1:06:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8323: train loss 1.55952. lr 5.088479e-04:  51%|█████     | 8323/16329 [1:10:05<1:06:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8323: train loss 1.55952. lr 5.088479e-04:  51%|█████     | 8324/16329 [1:10:05<1:05:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8324: train loss 1.52909. lr 5.088272e-04:  51%|█████     | 8324/16329 [1:10:06<1:05:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8324: train loss 1.52909. lr 5.088272e-04:  51%|█████     | 8325/16329 [1:10:06<1:12:55,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8325: train loss 1.56131. lr 5.088065e-04:  51%|█████     | 8325/16329 [1:10:06<1:12:55,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8325: train loss 1.56131. lr 5.088065e-04:  51%|█████     | 8326/16329 [1:10:06<1:10:44,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8326: train loss 1.56017. lr 5.087857e-04:  51%|█████     | 8326/16329 [1:10:07<1:10:44,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8326: train loss 1.56017. lr 5.087857e-04:  51%|█████     | 8327/16329 [1:10:07<1:09:29,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8327: train loss 1.53396. lr 5.087650e-04:  51%|█████     | 8327/16329 [1:10:07<1:09:29,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8327: train loss 1.53396. lr 5.087650e-04:  51%|█████     | 8328/16329 [1:10:07<1:08:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8328: train loss 1.54749. lr 5.087443e-04:  51%|█████     | 8328/16329 [1:10:08<1:08:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8328: train loss 1.54749. lr 5.087443e-04:  51%|█████     | 8329/16329 [1:10:08<1:07:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8329: train loss 1.51547. lr 5.087235e-04:  51%|█████     | 8329/16329 [1:10:08<1:07:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8329: train loss 1.51547. lr 5.087235e-04:  51%|█████     | 8330/16329 [1:10:08<1:07:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8330: train loss 1.54415. lr 5.087028e-04:  51%|█████     | 8330/16329 [1:10:09<1:07:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8330: train loss 1.54415. lr 5.087028e-04:  51%|█████     | 8331/16329 [1:10:09<1:06:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8331: train loss 1.55180. lr 5.086821e-04:  51%|█████     | 8331/16329 [1:10:09<1:06:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8331: train loss 1.55180. lr 5.086821e-04:  51%|█████     | 8332/16329 [1:10:09<1:06:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8332: train loss 1.56389. lr 5.086613e-04:  51%|█████     | 8332/16329 [1:10:10<1:06:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8332: train loss 1.56389. lr 5.086613e-04:  51%|█████     | 8333/16329 [1:10:10<1:06:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8333: train loss 1.58033. lr 5.086406e-04:  51%|█████     | 8333/16329 [1:10:10<1:06:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8333: train loss 1.58033. lr 5.086406e-04:  51%|█████     | 8334/16329 [1:10:10<1:06:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8334: train loss 1.56575. lr 5.086199e-04:  51%|█████     | 8334/16329 [1:10:11<1:06:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8334: train loss 1.56575. lr 5.086199e-04:  51%|█████     | 8335/16329 [1:10:11<1:06:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8335: train loss 1.60902. lr 5.085991e-04:  51%|█████     | 8335/16329 [1:10:11<1:06:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8335: train loss 1.60902. lr 5.085991e-04:  51%|█████     | 8336/16329 [1:10:11<1:05:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8336: train loss 1.55128. lr 5.085784e-04:  51%|█████     | 8336/16329 [1:10:12<1:05:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8336: train loss 1.55128. lr 5.085784e-04:  51%|█████     | 8337/16329 [1:10:12<1:06:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8337: train loss 1.56634. lr 5.085576e-04:  51%|█████     | 8337/16329 [1:10:12<1:06:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8337: train loss 1.56634. lr 5.085576e-04:  51%|█████     | 8338/16329 [1:10:12<1:06:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8338: train loss 1.53085. lr 5.085369e-04:  51%|█████     | 8338/16329 [1:10:13<1:06:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8338: train loss 1.53085. lr 5.085369e-04:  51%|█████     | 8339/16329 [1:10:13<1:06:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8339: train loss 1.55129. lr 5.085162e-04:  51%|█████     | 8339/16329 [1:10:13<1:06:44,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8339: train loss 1.55129. lr 5.085162e-04:  51%|█████     | 8340/16329 [1:10:13<1:06:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8340: train loss 1.56896. lr 5.084954e-04:  51%|█████     | 8340/16329 [1:10:14<1:06:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8340: train loss 1.56896. lr 5.084954e-04:  51%|█████     | 8341/16329 [1:10:14<1:06:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8341: train loss 1.53329. lr 5.084746e-04:  51%|█████     | 8341/16329 [1:10:14<1:06:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8341: train loss 1.53329. lr 5.084746e-04:  51%|█████     | 8342/16329 [1:10:14<1:06:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8342: train loss 1.56255. lr 5.084539e-04:  51%|█████     | 8342/16329 [1:10:15<1:06:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8342: train loss 1.56255. lr 5.084539e-04:  51%|█████     | 8343/16329 [1:10:15<1:05:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8343: train loss 1.60639. lr 5.084331e-04:  51%|█████     | 8343/16329 [1:10:15<1:05:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8343: train loss 1.60639. lr 5.084331e-04:  51%|█████     | 8344/16329 [1:10:15<1:05:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8344: train loss 1.57495. lr 5.084124e-04:  51%|█████     | 8344/16329 [1:10:16<1:05:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8344: train loss 1.57495. lr 5.084124e-04:  51%|█████     | 8345/16329 [1:10:16<1:06:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8345: train loss 1.55516. lr 5.083916e-04:  51%|█████     | 8345/16329 [1:10:16<1:06:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8345: train loss 1.55516. lr 5.083916e-04:  51%|█████     | 8346/16329 [1:10:16<1:06:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8346: train loss 1.52253. lr 5.083709e-04:  51%|█████     | 8346/16329 [1:10:17<1:06:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8346: train loss 1.52253. lr 5.083709e-04:  51%|█████     | 8347/16329 [1:10:17<1:06:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8347: train loss 1.54325. lr 5.083501e-04:  51%|█████     | 8347/16329 [1:10:17<1:06:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8347: train loss 1.54325. lr 5.083501e-04:  51%|█████     | 8348/16329 [1:10:17<1:05:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8348: train loss 1.54873. lr 5.083293e-04:  51%|█████     | 8348/16329 [1:10:18<1:05:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8348: train loss 1.54873. lr 5.083293e-04:  51%|█████     | 8349/16329 [1:10:18<1:05:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8349: train loss 1.54807. lr 5.083086e-04:  51%|█████     | 8349/16329 [1:10:18<1:05:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8349: train loss 1.54807. lr 5.083086e-04:  51%|█████     | 8350/16329 [1:10:18<1:12:38,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8350: train loss 1.54772. lr 5.082878e-04:  51%|█████     | 8350/16329 [1:10:19<1:12:38,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8350: train loss 1.54772. lr 5.082878e-04:  51%|█████     | 8351/16329 [1:10:19<1:10:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8351: train loss 1.56880. lr 5.082670e-04:  51%|█████     | 8351/16329 [1:10:19<1:10:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8351: train loss 1.56880. lr 5.082670e-04:  51%|█████     | 8352/16329 [1:10:19<1:09:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8352: train loss 1.53967. lr 5.082462e-04:  51%|█████     | 8352/16329 [1:10:20<1:09:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8352: train loss 1.53967. lr 5.082462e-04:  51%|█████     | 8353/16329 [1:10:20<1:08:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8353: train loss 1.54643. lr 5.082255e-04:  51%|█████     | 8353/16329 [1:10:20<1:08:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8353: train loss 1.54643. lr 5.082255e-04:  51%|█████     | 8354/16329 [1:10:20<1:07:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8354: train loss 1.52538. lr 5.082047e-04:  51%|█████     | 8354/16329 [1:10:21<1:07:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8354: train loss 1.52538. lr 5.082047e-04:  51%|█████     | 8355/16329 [1:10:21<1:06:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8355: train loss 1.58089. lr 5.081839e-04:  51%|█████     | 8355/16329 [1:10:21<1:06:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8355: train loss 1.58089. lr 5.081839e-04:  51%|█████     | 8356/16329 [1:10:21<1:06:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8356: train loss 1.57092. lr 5.081631e-04:  51%|█████     | 8356/16329 [1:10:22<1:06:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8356: train loss 1.57092. lr 5.081631e-04:  51%|█████     | 8357/16329 [1:10:22<1:06:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8357: train loss 1.57794. lr 5.081424e-04:  51%|█████     | 8357/16329 [1:10:22<1:06:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8357: train loss 1.57794. lr 5.081424e-04:  51%|█████     | 8358/16329 [1:10:22<1:06:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8358: train loss 1.52585. lr 5.081216e-04:  51%|█████     | 8358/16329 [1:10:23<1:06:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8358: train loss 1.52585. lr 5.081216e-04:  51%|█████     | 8359/16329 [1:10:23<1:05:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8359: train loss 1.54351. lr 5.081008e-04:  51%|█████     | 8359/16329 [1:10:23<1:05:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8359: train loss 1.54351. lr 5.081008e-04:  51%|█████     | 8360/16329 [1:10:23<1:05:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8360: train loss 1.57510. lr 5.080800e-04:  51%|█████     | 8360/16329 [1:10:24<1:05:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8360: train loss 1.57510. lr 5.080800e-04:  51%|█████     | 8361/16329 [1:10:24<1:05:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8361: train loss 1.55868. lr 5.080592e-04:  51%|█████     | 8361/16329 [1:10:24<1:05:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8361: train loss 1.55868. lr 5.080592e-04:  51%|█████     | 8362/16329 [1:10:24<1:05:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8362: train loss 1.56356. lr 5.080384e-04:  51%|█████     | 8362/16329 [1:10:25<1:05:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8362: train loss 1.56356. lr 5.080384e-04:  51%|█████     | 8363/16329 [1:10:25<1:05:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8363: train loss 1.52512. lr 5.080176e-04:  51%|█████     | 8363/16329 [1:10:25<1:05:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8363: train loss 1.52512. lr 5.080176e-04:  51%|█████     | 8364/16329 [1:10:25<1:05:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8364: train loss 1.55145. lr 5.079968e-04:  51%|█████     | 8364/16329 [1:10:26<1:05:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8364: train loss 1.55145. lr 5.079968e-04:  51%|█████     | 8365/16329 [1:10:26<1:05:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8365: train loss 1.54770. lr 5.079760e-04:  51%|█████     | 8365/16329 [1:10:26<1:05:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8365: train loss 1.54770. lr 5.079760e-04:  51%|█████     | 8366/16329 [1:10:26<1:05:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8366: train loss 1.54535. lr 5.079552e-04:  51%|█████     | 8366/16329 [1:10:27<1:05:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8366: train loss 1.54535. lr 5.079552e-04:  51%|█████     | 8367/16329 [1:10:27<1:05:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8367: train loss 1.56059. lr 5.079344e-04:  51%|█████     | 8367/16329 [1:10:27<1:05:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8367: train loss 1.56059. lr 5.079344e-04:  51%|█████     | 8368/16329 [1:10:27<1:05:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8368: train loss 1.55747. lr 5.079136e-04:  51%|█████     | 8368/16329 [1:10:28<1:05:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8368: train loss 1.55747. lr 5.079136e-04:  51%|█████▏    | 8369/16329 [1:10:28<1:05:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8369: train loss 1.55272. lr 5.078928e-04:  51%|█████▏    | 8369/16329 [1:10:28<1:05:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8369: train loss 1.55272. lr 5.078928e-04:  51%|█████▏    | 8370/16329 [1:10:28<1:05:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8370: train loss 1.57444. lr 5.078720e-04:  51%|█████▏    | 8370/16329 [1:10:29<1:05:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8370: train loss 1.57444. lr 5.078720e-04:  51%|█████▏    | 8371/16329 [1:10:29<1:05:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8371: train loss 1.54748. lr 5.078512e-04:  51%|█████▏    | 8371/16329 [1:10:29<1:05:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8371: train loss 1.54748. lr 5.078512e-04:  51%|█████▏    | 8372/16329 [1:10:29<1:05:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8372: train loss 1.57229. lr 5.078304e-04:  51%|█████▏    | 8372/16329 [1:10:30<1:05:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8372: train loss 1.57229. lr 5.078304e-04:  51%|█████▏    | 8373/16329 [1:10:30<1:05:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8373: train loss 1.55380. lr 5.078096e-04:  51%|█████▏    | 8373/16329 [1:10:30<1:05:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8373: train loss 1.55380. lr 5.078096e-04:  51%|█████▏    | 8374/16329 [1:10:30<1:05:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8374: train loss 1.52640. lr 5.077887e-04:  51%|█████▏    | 8374/16329 [1:10:31<1:05:24,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8374: train loss 1.52640. lr 5.077887e-04:  51%|█████▏    | 8375/16329 [1:10:31<1:05:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8375: train loss 1.56468. lr 5.077679e-04:  51%|█████▏    | 8375/16329 [1:10:31<1:05:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8375: train loss 1.56468. lr 5.077679e-04:  51%|█████▏    | 8376/16329 [1:10:31<1:05:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8376: train loss 1.57599. lr 5.077471e-04:  51%|█████▏    | 8376/16329 [1:10:32<1:05:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8376: train loss 1.57599. lr 5.077471e-04:  51%|█████▏    | 8377/16329 [1:10:32<1:12:25,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8377: train loss 1.55824. lr 5.077263e-04:  51%|█████▏    | 8377/16329 [1:10:33<1:12:25,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8377: train loss 1.55824. lr 5.077263e-04:  51%|█████▏    | 8378/16329 [1:10:33<1:10:29,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8378: train loss 1.51041. lr 5.077055e-04:  51%|█████▏    | 8378/16329 [1:10:33<1:10:29,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8378: train loss 1.51041. lr 5.077055e-04:  51%|█████▏    | 8379/16329 [1:10:33<1:08:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8379: train loss 1.54769. lr 5.076846e-04:  51%|█████▏    | 8379/16329 [1:10:33<1:08:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8379: train loss 1.54769. lr 5.076846e-04:  51%|█████▏    | 8380/16329 [1:10:33<1:07:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8380: train loss 1.55306. lr 5.076638e-04:  51%|█████▏    | 8380/16329 [1:10:34<1:07:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8380: train loss 1.55306. lr 5.076638e-04:  51%|█████▏    | 8381/16329 [1:10:34<1:06:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8381: train loss 1.53263. lr 5.076430e-04:  51%|█████▏    | 8381/16329 [1:10:34<1:06:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8381: train loss 1.53263. lr 5.076430e-04:  51%|█████▏    | 8382/16329 [1:10:34<1:06:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8382: train loss 1.54728. lr 5.076221e-04:  51%|█████▏    | 8382/16329 [1:10:35<1:06:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8382: train loss 1.54728. lr 5.076221e-04:  51%|█████▏    | 8383/16329 [1:10:35<1:06:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8383: train loss 1.54633. lr 5.076013e-04:  51%|█████▏    | 8383/16329 [1:10:35<1:06:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8383: train loss 1.54633. lr 5.076013e-04:  51%|█████▏    | 8384/16329 [1:10:35<1:05:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8384: train loss 1.59447. lr 5.075805e-04:  51%|█████▏    | 8384/16329 [1:10:36<1:05:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8384: train loss 1.59447. lr 5.075805e-04:  51%|█████▏    | 8385/16329 [1:10:36<1:05:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8385: train loss 1.51954. lr 5.075596e-04:  51%|█████▏    | 8385/16329 [1:10:36<1:05:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8385: train loss 1.51954. lr 5.075596e-04:  51%|█████▏    | 8386/16329 [1:10:36<1:05:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8386: train loss 1.52822. lr 5.075388e-04:  51%|█████▏    | 8386/16329 [1:10:37<1:05:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8386: train loss 1.52822. lr 5.075388e-04:  51%|█████▏    | 8387/16329 [1:10:37<1:05:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8387: train loss 1.54750. lr 5.075180e-04:  51%|█████▏    | 8387/16329 [1:10:37<1:05:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8387: train loss 1.54750. lr 5.075180e-04:  51%|█████▏    | 8388/16329 [1:10:37<1:05:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8388: train loss 1.57571. lr 5.074971e-04:  51%|█████▏    | 8388/16329 [1:10:38<1:05:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8388: train loss 1.57571. lr 5.074971e-04:  51%|█████▏    | 8389/16329 [1:10:38<1:05:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8389: train loss 1.58312. lr 5.074763e-04:  51%|█████▏    | 8389/16329 [1:10:38<1:05:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8389: train loss 1.58312. lr 5.074763e-04:  51%|█████▏    | 8390/16329 [1:10:38<1:05:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8390: train loss 1.56111. lr 5.074554e-04:  51%|█████▏    | 8390/16329 [1:10:39<1:05:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8390: train loss 1.56111. lr 5.074554e-04:  51%|█████▏    | 8391/16329 [1:10:39<1:05:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8391: train loss 1.58194. lr 5.074346e-04:  51%|█████▏    | 8391/16329 [1:10:39<1:05:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8391: train loss 1.58194. lr 5.074346e-04:  51%|█████▏    | 8392/16329 [1:10:39<1:05:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8392: train loss 1.52359. lr 5.074137e-04:  51%|█████▏    | 8392/16329 [1:10:40<1:05:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8392: train loss 1.52359. lr 5.074137e-04:  51%|█████▏    | 8393/16329 [1:10:40<1:05:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8393: train loss 1.55378. lr 5.073929e-04:  51%|█████▏    | 8393/16329 [1:10:40<1:05:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8393: train loss 1.55378. lr 5.073929e-04:  51%|█████▏    | 8394/16329 [1:10:40<1:05:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8394: train loss 1.56664. lr 5.073720e-04:  51%|█████▏    | 8394/16329 [1:10:41<1:05:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8394: train loss 1.56664. lr 5.073720e-04:  51%|█████▏    | 8395/16329 [1:10:41<1:05:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8395: train loss 1.54051. lr 5.073512e-04:  51%|█████▏    | 8395/16329 [1:10:41<1:05:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8395: train loss 1.54051. lr 5.073512e-04:  51%|█████▏    | 8396/16329 [1:10:41<1:05:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8396: train loss 1.57971. lr 5.073303e-04:  51%|█████▏    | 8396/16329 [1:10:42<1:05:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8396: train loss 1.57971. lr 5.073303e-04:  51%|█████▏    | 8397/16329 [1:10:42<1:05:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8397: train loss 1.54014. lr 5.073094e-04:  51%|█████▏    | 8397/16329 [1:10:42<1:05:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8397: train loss 1.54014. lr 5.073094e-04:  51%|█████▏    | 8398/16329 [1:10:42<1:07:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8398: train loss 1.55435. lr 5.072886e-04:  51%|█████▏    | 8398/16329 [1:10:43<1:07:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8398: train loss 1.55435. lr 5.072886e-04:  51%|█████▏    | 8399/16329 [1:10:43<1:08:40,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8399: train loss 1.54198. lr 5.072677e-04:  51%|█████▏    | 8399/16329 [1:10:43<1:08:40,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8399: train loss 1.54198. lr 5.072677e-04:  51%|█████▏    | 8400/16329 [1:10:43<1:08:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8400: train loss 1.57440. lr 5.072469e-04:  51%|█████▏    | 8400/16329 [1:10:44<1:08:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8400: train loss 1.57440. lr 5.072469e-04:  51%|█████▏    | 8401/16329 [1:10:44<1:08:47,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8401: train loss 1.61821. lr 5.072260e-04:  51%|█████▏    | 8401/16329 [1:10:45<1:08:47,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8401: train loss 1.61821. lr 5.072260e-04:  51%|█████▏    | 8402/16329 [1:10:45<1:08:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8402: train loss 1.53781. lr 5.072051e-04:  51%|█████▏    | 8402/16329 [1:10:45<1:08:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8402: train loss 1.53781. lr 5.072051e-04:  51%|█████▏    | 8403/16329 [1:10:45<1:07:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8403: train loss 1.54409. lr 5.071842e-04:  51%|█████▏    | 8403/16329 [1:10:46<1:07:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8403: train loss 1.54409. lr 5.071842e-04:  51%|█████▏    | 8404/16329 [1:10:46<1:07:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8404: train loss 1.57077. lr 5.071634e-04:  51%|█████▏    | 8404/16329 [1:10:46<1:07:14,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8404: train loss 1.57077. lr 5.071634e-04:  51%|█████▏    | 8405/16329 [1:10:46<1:06:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8405: train loss 1.57273. lr 5.071425e-04:  51%|█████▏    | 8405/16329 [1:10:47<1:06:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8405: train loss 1.57273. lr 5.071425e-04:  51%|█████▏    | 8406/16329 [1:10:47<1:06:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8406: train loss 1.55440. lr 5.071216e-04:  51%|█████▏    | 8406/16329 [1:10:47<1:06:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8406: train loss 1.55440. lr 5.071216e-04:  51%|█████▏    | 8407/16329 [1:10:47<1:05:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8407: train loss 1.55361. lr 5.071007e-04:  51%|█████▏    | 8407/16329 [1:10:48<1:05:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8407: train loss 1.55361. lr 5.071007e-04:  51%|█████▏    | 8408/16329 [1:10:48<1:05:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8408: train loss 1.56674. lr 5.070799e-04:  51%|█████▏    | 8408/16329 [1:10:48<1:05:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8408: train loss 1.56674. lr 5.070799e-04:  51%|█████▏    | 8409/16329 [1:10:48<1:05:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8409: train loss 1.58559. lr 5.070590e-04:  51%|█████▏    | 8409/16329 [1:10:48<1:05:19,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8409: train loss 1.58559. lr 5.070590e-04:  52%|█████▏    | 8410/16329 [1:10:48<1:05:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8410: train loss 1.61080. lr 5.070381e-04:  52%|█████▏    | 8410/16329 [1:10:49<1:05:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8410: train loss 1.61080. lr 5.070381e-04:  52%|█████▏    | 8411/16329 [1:10:49<1:05:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8411: train loss 1.54025. lr 5.070172e-04:  52%|█████▏    | 8411/16329 [1:10:49<1:05:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8411: train loss 1.54025. lr 5.070172e-04:  52%|█████▏    | 8412/16329 [1:10:49<1:05:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8412: train loss 1.55493. lr 5.069963e-04:  52%|█████▏    | 8412/16329 [1:10:50<1:05:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8412: train loss 1.55493. lr 5.069963e-04:  52%|█████▏    | 8413/16329 [1:10:50<1:05:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8413: train loss 1.49304. lr 5.069754e-04:  52%|█████▏    | 8413/16329 [1:10:50<1:05:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8413: train loss 1.49304. lr 5.069754e-04:  52%|█████▏    | 8414/16329 [1:10:50<1:05:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8414: train loss 1.56829. lr 5.069545e-04:  52%|█████▏    | 8414/16329 [1:10:51<1:05:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8414: train loss 1.56829. lr 5.069545e-04:  52%|█████▏    | 8415/16329 [1:10:51<1:05:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8415: train loss 1.54941. lr 5.069336e-04:  52%|█████▏    | 8415/16329 [1:10:51<1:05:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8415: train loss 1.54941. lr 5.069336e-04:  52%|█████▏    | 8416/16329 [1:10:51<1:05:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8416: train loss 1.54313. lr 5.069127e-04:  52%|█████▏    | 8416/16329 [1:10:52<1:05:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8416: train loss 1.54313. lr 5.069127e-04:  52%|█████▏    | 8417/16329 [1:10:52<1:11:59,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8417: train loss 1.53172. lr 5.068918e-04:  52%|█████▏    | 8417/16329 [1:10:53<1:11:59,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8417: train loss 1.53172. lr 5.068918e-04:  52%|█████▏    | 8418/16329 [1:10:53<1:10:00,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8418: train loss 1.55278. lr 5.068709e-04:  52%|█████▏    | 8418/16329 [1:10:53<1:10:00,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8418: train loss 1.55278. lr 5.068709e-04:  52%|█████▏    | 8419/16329 [1:10:53<1:08:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8419: train loss 1.56520. lr 5.068500e-04:  52%|█████▏    | 8419/16329 [1:10:54<1:08:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8419: train loss 1.56520. lr 5.068500e-04:  52%|█████▏    | 8420/16329 [1:10:54<1:07:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8420: train loss 1.61020. lr 5.068291e-04:  52%|█████▏    | 8420/16329 [1:10:54<1:07:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8420: train loss 1.61020. lr 5.068291e-04:  52%|█████▏    | 8421/16329 [1:10:54<1:06:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8421: train loss 1.57064. lr 5.068082e-04:  52%|█████▏    | 8421/16329 [1:10:55<1:06:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8421: train loss 1.57064. lr 5.068082e-04:  52%|█████▏    | 8422/16329 [1:10:55<1:06:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8422: train loss 1.51606. lr 5.067873e-04:  52%|█████▏    | 8422/16329 [1:10:55<1:06:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8422: train loss 1.51606. lr 5.067873e-04:  52%|█████▏    | 8423/16329 [1:10:55<1:05:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8423: train loss 1.52293. lr 5.067664e-04:  52%|█████▏    | 8423/16329 [1:10:56<1:05:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8423: train loss 1.52293. lr 5.067664e-04:  52%|█████▏    | 8424/16329 [1:10:56<1:05:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8424: train loss 1.51134. lr 5.067455e-04:  52%|█████▏    | 8424/16329 [1:10:56<1:05:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8424: train loss 1.51134. lr 5.067455e-04:  52%|█████▏    | 8425/16329 [1:10:56<1:05:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8425: train loss 1.51905. lr 5.067246e-04:  52%|█████▏    | 8425/16329 [1:10:57<1:05:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8425: train loss 1.51905. lr 5.067246e-04:  52%|█████▏    | 8426/16329 [1:10:57<1:05:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8426: train loss 1.57766. lr 5.067037e-04:  52%|█████▏    | 8426/16329 [1:10:57<1:05:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8426: train loss 1.57766. lr 5.067037e-04:  52%|█████▏    | 8427/16329 [1:10:57<1:05:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8427: train loss 1.56972. lr 5.066828e-04:  52%|█████▏    | 8427/16329 [1:10:58<1:05:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8427: train loss 1.56972. lr 5.066828e-04:  52%|█████▏    | 8428/16329 [1:10:58<1:05:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8428: train loss 1.50048. lr 5.066618e-04:  52%|█████▏    | 8428/16329 [1:10:58<1:05:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8428: train loss 1.50048. lr 5.066618e-04:  52%|█████▏    | 8429/16329 [1:10:58<1:05:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8429: train loss 1.50159. lr 5.066409e-04:  52%|█████▏    | 8429/16329 [1:10:59<1:05:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8429: train loss 1.50159. lr 5.066409e-04:  52%|█████▏    | 8430/16329 [1:10:59<1:08:13,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8430: train loss 1.53193. lr 5.066200e-04:  52%|█████▏    | 8430/16329 [1:10:59<1:08:13,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8430: train loss 1.53193. lr 5.066200e-04:  52%|█████▏    | 8431/16329 [1:10:59<1:09:53,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8431: train loss 1.57528. lr 5.065991e-04:  52%|█████▏    | 8431/16329 [1:11:00<1:09:53,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8431: train loss 1.57528. lr 5.065991e-04:  52%|█████▏    | 8432/16329 [1:11:00<1:10:37,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8432: train loss 1.55135. lr 5.065781e-04:  52%|█████▏    | 8432/16329 [1:11:00<1:10:37,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8432: train loss 1.55135. lr 5.065781e-04:  52%|█████▏    | 8433/16329 [1:11:00<1:10:16,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8433: train loss 1.51243. lr 5.065572e-04:  52%|█████▏    | 8433/16329 [1:11:01<1:10:16,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8433: train loss 1.51243. lr 5.065572e-04:  52%|█████▏    | 8434/16329 [1:11:01<1:09:35,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8434: train loss 1.55671. lr 5.065363e-04:  52%|█████▏    | 8434/16329 [1:11:01<1:09:35,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8434: train loss 1.55671. lr 5.065363e-04:  52%|█████▏    | 8435/16329 [1:11:01<1:08:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8435: train loss 1.58883. lr 5.065154e-04:  52%|█████▏    | 8435/16329 [1:11:02<1:08:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8435: train loss 1.58883. lr 5.065154e-04:  52%|█████▏    | 8436/16329 [1:11:02<1:07:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8436: train loss 1.56302. lr 5.064944e-04:  52%|█████▏    | 8436/16329 [1:11:02<1:07:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8436: train loss 1.56302. lr 5.064944e-04:  52%|█████▏    | 8437/16329 [1:11:02<1:06:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8437: train loss 1.51385. lr 5.064735e-04:  52%|█████▏    | 8437/16329 [1:11:03<1:06:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8437: train loss 1.51385. lr 5.064735e-04:  52%|█████▏    | 8438/16329 [1:11:03<1:05:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8438: train loss 1.56379. lr 5.064525e-04:  52%|█████▏    | 8438/16329 [1:11:03<1:05:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8438: train loss 1.56379. lr 5.064525e-04:  52%|█████▏    | 8439/16329 [1:11:03<1:05:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8439: train loss 1.57190. lr 5.064316e-04:  52%|█████▏    | 8439/16329 [1:11:04<1:05:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8439: train loss 1.57190. lr 5.064316e-04:  52%|█████▏    | 8440/16329 [1:11:04<1:05:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8440: train loss 1.57149. lr 5.064107e-04:  52%|█████▏    | 8440/16329 [1:11:04<1:05:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8440: train loss 1.57149. lr 5.064107e-04:  52%|█████▏    | 8441/16329 [1:11:04<1:05:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8441: train loss 1.55235. lr 5.063897e-04:  52%|█████▏    | 8441/16329 [1:11:05<1:05:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8441: train loss 1.55235. lr 5.063897e-04:  52%|█████▏    | 8442/16329 [1:11:05<1:05:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8442: train loss 1.52963. lr 5.063688e-04:  52%|█████▏    | 8442/16329 [1:11:05<1:05:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8442: train loss 1.52963. lr 5.063688e-04:  52%|█████▏    | 8443/16329 [1:11:05<1:05:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8443: train loss 1.54213. lr 5.063478e-04:  52%|█████▏    | 8443/16329 [1:11:06<1:05:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8443: train loss 1.54213. lr 5.063478e-04:  52%|█████▏    | 8444/16329 [1:11:06<1:05:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8444: train loss 1.52444. lr 5.063269e-04:  52%|█████▏    | 8444/16329 [1:11:06<1:05:13,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8444: train loss 1.52444. lr 5.063269e-04:  52%|█████▏    | 8445/16329 [1:11:06<1:05:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8445: train loss 1.55564. lr 5.063059e-04:  52%|█████▏    | 8445/16329 [1:11:07<1:05:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8445: train loss 1.55564. lr 5.063059e-04:  52%|█████▏    | 8446/16329 [1:11:07<1:05:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8446: train loss 1.51211. lr 5.062850e-04:  52%|█████▏    | 8446/16329 [1:11:07<1:05:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8446: train loss 1.51211. lr 5.062850e-04:  52%|█████▏    | 8447/16329 [1:11:07<1:05:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8447: train loss 1.54777. lr 5.062640e-04:  52%|█████▏    | 8447/16329 [1:11:08<1:05:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8447: train loss 1.54777. lr 5.062640e-04:  52%|█████▏    | 8448/16329 [1:11:08<1:05:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8448: train loss 1.51250. lr 5.062431e-04:  52%|█████▏    | 8448/16329 [1:11:08<1:05:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8448: train loss 1.51250. lr 5.062431e-04:  52%|█████▏    | 8449/16329 [1:11:08<1:05:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8449: train loss 1.56753. lr 5.062221e-04:  52%|█████▏    | 8449/16329 [1:11:09<1:05:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8449: train loss 1.56753. lr 5.062221e-04:  52%|█████▏    | 8450/16329 [1:11:09<1:04:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8450: train loss 1.54641. lr 5.062011e-04:  52%|█████▏    | 8450/16329 [1:11:09<1:04:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8450: train loss 1.54641. lr 5.062011e-04:  52%|█████▏    | 8451/16329 [1:11:09<1:04:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8451: train loss 1.54997. lr 5.061802e-04:  52%|█████▏    | 8451/16329 [1:11:10<1:04:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8451: train loss 1.54997. lr 5.061802e-04:  52%|█████▏    | 8452/16329 [1:11:10<1:11:43,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8452: train loss 1.60295. lr 5.061592e-04:  52%|█████▏    | 8452/16329 [1:11:10<1:11:43,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8452: train loss 1.60295. lr 5.061592e-04:  52%|█████▏    | 8453/16329 [1:11:10<1:09:38,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8453: train loss 1.57223. lr 5.061382e-04:  52%|█████▏    | 8453/16329 [1:11:11<1:09:38,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8453: train loss 1.57223. lr 5.061382e-04:  52%|█████▏    | 8454/16329 [1:11:11<1:08:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8454: train loss 1.51044. lr 5.061173e-04:  52%|█████▏    | 8454/16329 [1:11:11<1:08:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8454: train loss 1.51044. lr 5.061173e-04:  52%|█████▏    | 8455/16329 [1:11:11<1:07:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8455: train loss 1.55903. lr 5.060963e-04:  52%|█████▏    | 8455/16329 [1:11:12<1:07:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8455: train loss 1.55903. lr 5.060963e-04:  52%|█████▏    | 8456/16329 [1:11:12<1:06:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8456: train loss 1.53217. lr 5.060753e-04:  52%|█████▏    | 8456/16329 [1:11:12<1:06:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8456: train loss 1.53217. lr 5.060753e-04:  52%|█████▏    | 8457/16329 [1:11:12<1:06:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8457: train loss 1.59661. lr 5.060543e-04:  52%|█████▏    | 8457/16329 [1:11:13<1:06:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8457: train loss 1.59661. lr 5.060543e-04:  52%|█████▏    | 8458/16329 [1:11:13<1:06:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8458: train loss 1.54730. lr 5.060334e-04:  52%|█████▏    | 8458/16329 [1:11:13<1:06:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8458: train loss 1.54730. lr 5.060334e-04:  52%|█████▏    | 8459/16329 [1:11:13<1:05:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8459: train loss 1.51424. lr 5.060124e-04:  52%|█████▏    | 8459/16329 [1:11:14<1:05:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8459: train loss 1.51424. lr 5.060124e-04:  52%|█████▏    | 8460/16329 [1:11:14<1:05:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8460: train loss 1.54704. lr 5.059914e-04:  52%|█████▏    | 8460/16329 [1:11:14<1:05:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8460: train loss 1.54704. lr 5.059914e-04:  52%|█████▏    | 8461/16329 [1:11:14<1:05:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8461: train loss 1.52650. lr 5.059704e-04:  52%|█████▏    | 8461/16329 [1:11:15<1:05:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8461: train loss 1.52650. lr 5.059704e-04:  52%|█████▏    | 8462/16329 [1:11:15<1:05:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8462: train loss 1.54530. lr 5.059494e-04:  52%|█████▏    | 8462/16329 [1:11:15<1:05:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8462: train loss 1.54530. lr 5.059494e-04:  52%|█████▏    | 8463/16329 [1:11:15<1:05:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8463: train loss 1.51240. lr 5.059285e-04:  52%|█████▏    | 8463/16329 [1:11:16<1:05:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8463: train loss 1.51240. lr 5.059285e-04:  52%|█████▏    | 8464/16329 [1:11:16<1:05:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8464: train loss 1.52097. lr 5.059075e-04:  52%|█████▏    | 8464/16329 [1:11:16<1:05:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8464: train loss 1.52097. lr 5.059075e-04:  52%|█████▏    | 8465/16329 [1:11:16<1:04:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8465: train loss 1.54401. lr 5.058865e-04:  52%|█████▏    | 8465/16329 [1:11:17<1:04:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8465: train loss 1.54401. lr 5.058865e-04:  52%|█████▏    | 8466/16329 [1:11:17<1:05:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8466: train loss 1.50608. lr 5.058655e-04:  52%|█████▏    | 8466/16329 [1:11:17<1:05:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8466: train loss 1.50608. lr 5.058655e-04:  52%|█████▏    | 8467/16329 [1:11:17<1:05:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8467: train loss 1.56388. lr 5.058445e-04:  52%|█████▏    | 8467/16329 [1:11:18<1:05:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8467: train loss 1.56388. lr 5.058445e-04:  52%|█████▏    | 8468/16329 [1:11:18<1:05:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8468: train loss 1.51761. lr 5.058235e-04:  52%|█████▏    | 8468/16329 [1:11:18<1:05:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8468: train loss 1.51761. lr 5.058235e-04:  52%|█████▏    | 8469/16329 [1:11:18<1:05:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8469: train loss 1.54137. lr 5.058025e-04:  52%|█████▏    | 8469/16329 [1:11:19<1:05:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8469: train loss 1.54137. lr 5.058025e-04:  52%|█████▏    | 8470/16329 [1:11:19<1:05:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8470: train loss 1.55528. lr 5.057815e-04:  52%|█████▏    | 8470/16329 [1:11:19<1:05:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8470: train loss 1.55528. lr 5.057815e-04:  52%|█████▏    | 8471/16329 [1:11:19<1:05:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8471: train loss 1.49169. lr 5.057605e-04:  52%|█████▏    | 8471/16329 [1:11:20<1:05:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8471: train loss 1.49169. lr 5.057605e-04:  52%|█████▏    | 8472/16329 [1:11:20<1:05:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8472: train loss 1.55653. lr 5.057395e-04:  52%|█████▏    | 8472/16329 [1:11:20<1:05:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8472: train loss 1.55653. lr 5.057395e-04:  52%|█████▏    | 8473/16329 [1:11:20<1:04:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8473: train loss 1.52224. lr 5.057185e-04:  52%|█████▏    | 8473/16329 [1:11:21<1:04:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8473: train loss 1.52224. lr 5.057185e-04:  52%|█████▏    | 8474/16329 [1:11:21<1:04:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8474: train loss 1.54739. lr 5.056975e-04:  52%|█████▏    | 8474/16329 [1:11:21<1:04:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8474: train loss 1.54739. lr 5.056975e-04:  52%|█████▏    | 8475/16329 [1:11:21<1:04:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8475: train loss 1.52158. lr 5.056765e-04:  52%|█████▏    | 8475/16329 [1:11:22<1:04:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8475: train loss 1.52158. lr 5.056765e-04:  52%|█████▏    | 8476/16329 [1:11:22<1:04:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8476: train loss 1.54144. lr 5.056555e-04:  52%|█████▏    | 8476/16329 [1:11:22<1:04:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8476: train loss 1.54144. lr 5.056555e-04:  52%|█████▏    | 8477/16329 [1:11:22<1:13:23,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 8477: train loss 1.52229. lr 5.056345e-04:  52%|█████▏    | 8477/16329 [1:11:23<1:13:23,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 8477: train loss 1.52229. lr 5.056345e-04:  52%|█████▏    | 8478/16329 [1:11:23<1:10:45,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 8478: train loss 1.55083. lr 5.056134e-04:  52%|█████▏    | 8478/16329 [1:11:23<1:10:45,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 8478: train loss 1.55083. lr 5.056134e-04:  52%|█████▏    | 8479/16329 [1:11:23<1:09:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8479: train loss 1.52616. lr 5.055924e-04:  52%|█████▏    | 8479/16329 [1:11:24<1:09:02,  1.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8479: train loss 1.52616. lr 5.055924e-04:  52%|█████▏    | 8480/16329 [1:11:24<1:07:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8480: train loss 1.55999. lr 5.055714e-04:  52%|█████▏    | 8480/16329 [1:11:24<1:07:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8480: train loss 1.55999. lr 5.055714e-04:  52%|█████▏    | 8481/16329 [1:11:24<1:06:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8481: train loss 1.56162. lr 5.055504e-04:  52%|█████▏    | 8481/16329 [1:11:25<1:06:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8481: train loss 1.56162. lr 5.055504e-04:  52%|█████▏    | 8482/16329 [1:11:25<1:06:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8482: train loss 1.55815. lr 5.055294e-04:  52%|█████▏    | 8482/16329 [1:11:25<1:06:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8482: train loss 1.55815. lr 5.055294e-04:  52%|█████▏    | 8483/16329 [1:11:25<1:06:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8483: train loss 1.55676. lr 5.055083e-04:  52%|█████▏    | 8483/16329 [1:11:26<1:06:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8483: train loss 1.55676. lr 5.055083e-04:  52%|█████▏    | 8484/16329 [1:11:26<1:06:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8484: train loss 1.56070. lr 5.054873e-04:  52%|█████▏    | 8484/16329 [1:11:26<1:06:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8484: train loss 1.56070. lr 5.054873e-04:  52%|█████▏    | 8485/16329 [1:11:26<1:05:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8485: train loss 1.55452. lr 5.054663e-04:  52%|█████▏    | 8485/16329 [1:11:27<1:05:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8485: train loss 1.55452. lr 5.054663e-04:  52%|█████▏    | 8486/16329 [1:11:27<1:05:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8486: train loss 1.54832. lr 5.054452e-04:  52%|█████▏    | 8486/16329 [1:11:27<1:05:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8486: train loss 1.54832. lr 5.054452e-04:  52%|█████▏    | 8487/16329 [1:11:27<1:05:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8487: train loss 1.53103. lr 5.054242e-04:  52%|█████▏    | 8487/16329 [1:11:28<1:05:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8487: train loss 1.53103. lr 5.054242e-04:  52%|█████▏    | 8488/16329 [1:11:28<1:05:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8488: train loss 1.51562. lr 5.054032e-04:  52%|█████▏    | 8488/16329 [1:11:28<1:05:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8488: train loss 1.51562. lr 5.054032e-04:  52%|█████▏    | 8489/16329 [1:11:28<1:04:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8489: train loss 1.51409. lr 5.053821e-04:  52%|█████▏    | 8489/16329 [1:11:29<1:04:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8489: train loss 1.51409. lr 5.053821e-04:  52%|█████▏    | 8490/16329 [1:11:29<1:04:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8490: train loss 1.57430. lr 5.053611e-04:  52%|█████▏    | 8490/16329 [1:11:29<1:04:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8490: train loss 1.57430. lr 5.053611e-04:  52%|█████▏    | 8491/16329 [1:11:29<1:04:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8491: train loss 1.52179. lr 5.053401e-04:  52%|█████▏    | 8491/16329 [1:11:30<1:04:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8491: train loss 1.52179. lr 5.053401e-04:  52%|█████▏    | 8492/16329 [1:11:30<1:04:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8492: train loss 1.55555. lr 5.053190e-04:  52%|█████▏    | 8492/16329 [1:11:30<1:04:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8492: train loss 1.55555. lr 5.053190e-04:  52%|█████▏    | 8493/16329 [1:11:30<1:04:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8493: train loss 1.54827. lr 5.052980e-04:  52%|█████▏    | 8493/16329 [1:11:31<1:04:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8493: train loss 1.54827. lr 5.052980e-04:  52%|█████▏    | 8494/16329 [1:11:31<1:04:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8494: train loss 1.58082. lr 5.052769e-04:  52%|█████▏    | 8494/16329 [1:11:31<1:04:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8494: train loss 1.58082. lr 5.052769e-04:  52%|█████▏    | 8495/16329 [1:11:31<1:04:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8495: train loss 1.56179. lr 5.052559e-04:  52%|█████▏    | 8495/16329 [1:11:32<1:04:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8495: train loss 1.56179. lr 5.052559e-04:  52%|█████▏    | 8496/16329 [1:11:32<1:04:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8496: train loss 1.57611. lr 5.052348e-04:  52%|█████▏    | 8496/16329 [1:11:32<1:04:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8496: train loss 1.57611. lr 5.052348e-04:  52%|█████▏    | 8497/16329 [1:11:32<1:04:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8497: train loss 1.57537. lr 5.052138e-04:  52%|█████▏    | 8497/16329 [1:11:33<1:04:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8497: train loss 1.57537. lr 5.052138e-04:  52%|█████▏    | 8498/16329 [1:11:33<1:04:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8498: train loss 1.51071. lr 5.051927e-04:  52%|█████▏    | 8498/16329 [1:11:33<1:04:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8498: train loss 1.51071. lr 5.051927e-04:  52%|█████▏    | 8499/16329 [1:11:33<1:04:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8499: train loss 1.53484. lr 5.051717e-04:  52%|█████▏    | 8499/16329 [1:11:34<1:04:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8499: train loss 1.53484. lr 5.051717e-04:  52%|█████▏    | 8500/16329 [1:11:34<1:04:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8500: train loss 1.54348. lr 5.051506e-04:  52%|█████▏    | 8500/16329 [1:11:34<1:04:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8500: train loss 1.54348. lr 5.051506e-04:  52%|█████▏    | 8501/16329 [1:11:34<1:04:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8501: train loss 1.56494. lr 5.051296e-04:  52%|█████▏    | 8501/16329 [1:11:35<1:04:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8501: train loss 1.56494. lr 5.051296e-04:  52%|█████▏    | 8502/16329 [1:11:35<1:04:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8502: train loss 1.51278. lr 5.051085e-04:  52%|█████▏    | 8502/16329 [1:11:35<1:04:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8502: train loss 1.51278. lr 5.051085e-04:  52%|█████▏    | 8503/16329 [1:11:35<1:04:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8503: train loss 1.52086. lr 5.050874e-04:  52%|█████▏    | 8503/16329 [1:11:36<1:04:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8503: train loss 1.52086. lr 5.050874e-04:  52%|█████▏    | 8504/16329 [1:11:36<1:11:29,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8504: train loss 1.54470. lr 5.050664e-04:  52%|█████▏    | 8504/16329 [1:11:37<1:11:29,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8504: train loss 1.54470. lr 5.050664e-04:  52%|█████▏    | 8505/16329 [1:11:37<1:09:06,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8505: train loss 1.55062. lr 5.050453e-04:  52%|█████▏    | 8505/16329 [1:11:37<1:09:06,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8505: train loss 1.55062. lr 5.050453e-04:  52%|█████▏    | 8506/16329 [1:11:37<1:07:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8506: train loss 1.53722. lr 5.050243e-04:  52%|█████▏    | 8506/16329 [1:11:38<1:07:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8506: train loss 1.53722. lr 5.050243e-04:  52%|█████▏    | 8507/16329 [1:11:38<1:06:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8507: train loss 1.54146. lr 5.050032e-04:  52%|█████▏    | 8507/16329 [1:11:38<1:06:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8507: train loss 1.54146. lr 5.050032e-04:  52%|█████▏    | 8508/16329 [1:11:38<1:05:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8508: train loss 1.55938. lr 5.049821e-04:  52%|█████▏    | 8508/16329 [1:11:39<1:05:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8508: train loss 1.55938. lr 5.049821e-04:  52%|█████▏    | 8509/16329 [1:11:39<1:05:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8509: train loss 1.56033. lr 5.049610e-04:  52%|█████▏    | 8509/16329 [1:11:39<1:05:37,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8509: train loss 1.56033. lr 5.049610e-04:  52%|█████▏    | 8510/16329 [1:11:39<1:05:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8510: train loss 1.54300. lr 5.049400e-04:  52%|█████▏    | 8510/16329 [1:11:40<1:05:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8510: train loss 1.54300. lr 5.049400e-04:  52%|█████▏    | 8511/16329 [1:11:40<1:05:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8511: train loss 1.48220. lr 5.049189e-04:  52%|█████▏    | 8511/16329 [1:11:40<1:05:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8511: train loss 1.48220. lr 5.049189e-04:  52%|█████▏    | 8512/16329 [1:11:40<1:04:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8512: train loss 1.55278. lr 5.048978e-04:  52%|█████▏    | 8512/16329 [1:11:40<1:04:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8512: train loss 1.55278. lr 5.048978e-04:  52%|█████▏    | 8513/16329 [1:11:40<1:04:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8513: train loss 1.54433. lr 5.048767e-04:  52%|█████▏    | 8513/16329 [1:11:41<1:04:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8513: train loss 1.54433. lr 5.048767e-04:  52%|█████▏    | 8514/16329 [1:11:41<1:04:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8514: train loss 1.55461. lr 5.048556e-04:  52%|█████▏    | 8514/16329 [1:11:41<1:04:54,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8514: train loss 1.55461. lr 5.048556e-04:  52%|█████▏    | 8515/16329 [1:11:41<1:04:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8515: train loss 1.52945. lr 5.048346e-04:  52%|█████▏    | 8515/16329 [1:11:42<1:04:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8515: train loss 1.52945. lr 5.048346e-04:  52%|█████▏    | 8516/16329 [1:11:42<1:04:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8516: train loss 1.54229. lr 5.048135e-04:  52%|█████▏    | 8516/16329 [1:11:42<1:04:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8516: train loss 1.54229. lr 5.048135e-04:  52%|█████▏    | 8517/16329 [1:11:42<1:04:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8517: train loss 1.48202. lr 5.047924e-04:  52%|█████▏    | 8517/16329 [1:11:43<1:04:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8517: train loss 1.48202. lr 5.047924e-04:  52%|█████▏    | 8518/16329 [1:11:43<1:04:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8518: train loss 1.52118. lr 5.047713e-04:  52%|█████▏    | 8518/16329 [1:11:43<1:04:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8518: train loss 1.52118. lr 5.047713e-04:  52%|█████▏    | 8519/16329 [1:11:43<1:04:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8519: train loss 1.51689. lr 5.047502e-04:  52%|█████▏    | 8519/16329 [1:11:44<1:04:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8519: train loss 1.51689. lr 5.047502e-04:  52%|█████▏    | 8520/16329 [1:11:44<1:04:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8520: train loss 1.53141. lr 5.047291e-04:  52%|█████▏    | 8520/16329 [1:11:44<1:04:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8520: train loss 1.53141. lr 5.047291e-04:  52%|█████▏    | 8521/16329 [1:11:44<1:04:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8521: train loss 1.58864. lr 5.047080e-04:  52%|█████▏    | 8521/16329 [1:11:45<1:04:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8521: train loss 1.58864. lr 5.047080e-04:  52%|█████▏    | 8522/16329 [1:11:45<1:04:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8522: train loss 1.55811. lr 5.046869e-04:  52%|█████▏    | 8522/16329 [1:11:45<1:04:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8522: train loss 1.55811. lr 5.046869e-04:  52%|█████▏    | 8523/16329 [1:11:45<1:04:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8523: train loss 1.51112. lr 5.046658e-04:  52%|█████▏    | 8523/16329 [1:11:46<1:04:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8523: train loss 1.51112. lr 5.046658e-04:  52%|█████▏    | 8524/16329 [1:11:46<1:04:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8524: train loss 1.54724. lr 5.046447e-04:  52%|█████▏    | 8524/16329 [1:11:46<1:04:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8524: train loss 1.54724. lr 5.046447e-04:  52%|█████▏    | 8525/16329 [1:11:46<1:04:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8525: train loss 1.56589. lr 5.046236e-04:  52%|█████▏    | 8525/16329 [1:11:47<1:04:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8525: train loss 1.56589. lr 5.046236e-04:  52%|█████▏    | 8526/16329 [1:11:47<1:04:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8526: train loss 1.57958. lr 5.046025e-04:  52%|█████▏    | 8526/16329 [1:11:47<1:04:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8526: train loss 1.57958. lr 5.046025e-04:  52%|█████▏    | 8527/16329 [1:11:47<1:04:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8527: train loss 1.54442. lr 5.045814e-04:  52%|█████▏    | 8527/16329 [1:11:48<1:04:10,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8527: train loss 1.54442. lr 5.045814e-04:  52%|█████▏    | 8528/16329 [1:11:48<1:07:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8528: train loss 1.52968. lr 5.045603e-04:  52%|█████▏    | 8528/16329 [1:11:49<1:07:12,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8528: train loss 1.52968. lr 5.045603e-04:  52%|█████▏    | 8529/16329 [1:11:49<1:08:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8529: train loss 1.54692. lr 5.045392e-04:  52%|█████▏    | 8529/16329 [1:11:49<1:08:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8529: train loss 1.54692. lr 5.045392e-04:  52%|█████▏    | 8530/16329 [1:11:49<1:08:55,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8530: train loss 1.53987. lr 5.045181e-04:  52%|█████▏    | 8530/16329 [1:11:50<1:08:55,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8530: train loss 1.53987. lr 5.045181e-04:  52%|█████▏    | 8531/16329 [1:11:50<1:08:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8531: train loss 1.53917. lr 5.044969e-04:  52%|█████▏    | 8531/16329 [1:11:50<1:08:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8531: train loss 1.53917. lr 5.044969e-04:  52%|█████▏    | 8532/16329 [1:11:50<1:07:52,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8532: train loss 1.53315. lr 5.044758e-04:  52%|█████▏    | 8532/16329 [1:11:51<1:07:52,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8532: train loss 1.53315. lr 5.044758e-04:  52%|█████▏    | 8533/16329 [1:11:51<1:07:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8533: train loss 1.52283. lr 5.044547e-04:  52%|█████▏    | 8533/16329 [1:11:51<1:07:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8533: train loss 1.52283. lr 5.044547e-04:  52%|█████▏    | 8534/16329 [1:11:51<1:06:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8534: train loss 1.51240. lr 5.044336e-04:  52%|█████▏    | 8534/16329 [1:11:52<1:06:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8534: train loss 1.51240. lr 5.044336e-04:  52%|█████▏    | 8535/16329 [1:11:52<1:05:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8535: train loss 1.58040. lr 5.044125e-04:  52%|█████▏    | 8535/16329 [1:11:52<1:05:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8535: train loss 1.58040. lr 5.044125e-04:  52%|█████▏    | 8536/16329 [1:11:52<1:05:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8536: train loss 1.52848. lr 5.043913e-04:  52%|█████▏    | 8536/16329 [1:11:53<1:05:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8536: train loss 1.52848. lr 5.043913e-04:  52%|█████▏    | 8537/16329 [1:11:53<1:05:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8537: train loss 1.56742. lr 5.043702e-04:  52%|█████▏    | 8537/16329 [1:11:53<1:05:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8537: train loss 1.56742. lr 5.043702e-04:  52%|█████▏    | 8538/16329 [1:11:53<1:04:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8538: train loss 1.52689. lr 5.043491e-04:  52%|█████▏    | 8538/16329 [1:11:54<1:04:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8538: train loss 1.52689. lr 5.043491e-04:  52%|█████▏    | 8539/16329 [1:11:54<1:04:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8539: train loss 1.53246. lr 5.043279e-04:  52%|█████▏    | 8539/16329 [1:11:54<1:04:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8539: train loss 1.53246. lr 5.043279e-04:  52%|█████▏    | 8540/16329 [1:11:54<1:04:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8540: train loss 1.57121. lr 5.043068e-04:  52%|█████▏    | 8540/16329 [1:11:55<1:04:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8540: train loss 1.57121. lr 5.043068e-04:  52%|█████▏    | 8541/16329 [1:11:55<1:04:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8541: train loss 1.49565. lr 5.042857e-04:  52%|█████▏    | 8541/16329 [1:11:55<1:04:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8541: train loss 1.49565. lr 5.042857e-04:  52%|█████▏    | 8542/16329 [1:11:55<1:04:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8542: train loss 1.54496. lr 5.042645e-04:  52%|█████▏    | 8542/16329 [1:11:56<1:04:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8542: train loss 1.54496. lr 5.042645e-04:  52%|█████▏    | 8543/16329 [1:11:56<1:04:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8543: train loss 1.55185. lr 5.042434e-04:  52%|█████▏    | 8543/16329 [1:11:56<1:04:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8543: train loss 1.55185. lr 5.042434e-04:  52%|█████▏    | 8544/16329 [1:11:56<1:12:10,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 8544: train loss 1.54572. lr 5.042223e-04:  52%|█████▏    | 8544/16329 [1:11:57<1:12:10,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 8544: train loss 1.54572. lr 5.042223e-04:  52%|█████▏    | 8545/16329 [1:11:57<1:09:42,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8545: train loss 1.49351. lr 5.042011e-04:  52%|█████▏    | 8545/16329 [1:11:57<1:09:42,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8545: train loss 1.49351. lr 5.042011e-04:  52%|█████▏    | 8546/16329 [1:11:57<1:07:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8546: train loss 1.59425. lr 5.041800e-04:  52%|█████▏    | 8546/16329 [1:11:58<1:07:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8546: train loss 1.59425. lr 5.041800e-04:  52%|█████▏    | 8547/16329 [1:11:58<1:07:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8547: train loss 1.56259. lr 5.041588e-04:  52%|█████▏    | 8547/16329 [1:11:58<1:07:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8547: train loss 1.56259. lr 5.041588e-04:  52%|█████▏    | 8548/16329 [1:11:58<1:05:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8548: train loss 1.56520. lr 5.041377e-04:  52%|█████▏    | 8548/16329 [1:11:59<1:05:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8548: train loss 1.56520. lr 5.041377e-04:  52%|█████▏    | 8549/16329 [1:11:59<1:05:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8549: train loss 1.48109. lr 5.041165e-04:  52%|█████▏    | 8549/16329 [1:11:59<1:05:36,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8549: train loss 1.48109. lr 5.041165e-04:  52%|█████▏    | 8550/16329 [1:11:59<1:05:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8550: train loss 1.53846. lr 5.040954e-04:  52%|█████▏    | 8550/16329 [1:12:00<1:05:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8550: train loss 1.53846. lr 5.040954e-04:  52%|█████▏    | 8551/16329 [1:12:00<1:04:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8551: train loss 1.51763. lr 5.040742e-04:  52%|█████▏    | 8551/16329 [1:12:00<1:04:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8551: train loss 1.51763. lr 5.040742e-04:  52%|█████▏    | 8552/16329 [1:12:00<1:04:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8552: train loss 1.50970. lr 5.040531e-04:  52%|█████▏    | 8552/16329 [1:12:01<1:04:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8552: train loss 1.50970. lr 5.040531e-04:  52%|█████▏    | 8553/16329 [1:12:01<1:04:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8553: train loss 1.54979. lr 5.040319e-04:  52%|█████▏    | 8553/16329 [1:12:01<1:04:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8553: train loss 1.54979. lr 5.040319e-04:  52%|█████▏    | 8554/16329 [1:12:01<1:04:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8554: train loss 1.51470. lr 5.040108e-04:  52%|█████▏    | 8554/16329 [1:12:02<1:04:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8554: train loss 1.51470. lr 5.040108e-04:  52%|█████▏    | 8555/16329 [1:12:02<1:04:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8555: train loss 1.51717. lr 5.039896e-04:  52%|█████▏    | 8555/16329 [1:12:02<1:04:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8555: train loss 1.51717. lr 5.039896e-04:  52%|█████▏    | 8556/16329 [1:12:02<1:04:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8556: train loss 1.57513. lr 5.039684e-04:  52%|█████▏    | 8556/16329 [1:12:03<1:04:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8556: train loss 1.57513. lr 5.039684e-04:  52%|█████▏    | 8557/16329 [1:12:03<1:04:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8557: train loss 1.53935. lr 5.039473e-04:  52%|█████▏    | 8557/16329 [1:12:03<1:04:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8557: train loss 1.53935. lr 5.039473e-04:  52%|█████▏    | 8558/16329 [1:12:03<1:04:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8558: train loss 1.53181. lr 5.039261e-04:  52%|█████▏    | 8558/16329 [1:12:04<1:04:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8558: train loss 1.53181. lr 5.039261e-04:  52%|█████▏    | 8559/16329 [1:12:04<1:04:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8559: train loss 1.53691. lr 5.039049e-04:  52%|█████▏    | 8559/16329 [1:12:04<1:04:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8559: train loss 1.53691. lr 5.039049e-04:  52%|█████▏    | 8560/16329 [1:12:04<1:04:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8560: train loss 1.51376. lr 5.038838e-04:  52%|█████▏    | 8560/16329 [1:12:05<1:04:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8560: train loss 1.51376. lr 5.038838e-04:  52%|█████▏    | 8561/16329 [1:12:05<1:04:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8561: train loss 1.56756. lr 5.038626e-04:  52%|█████▏    | 8561/16329 [1:12:05<1:04:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8561: train loss 1.56756. lr 5.038626e-04:  52%|█████▏    | 8562/16329 [1:12:05<1:04:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8562: train loss 1.56404. lr 5.038414e-04:  52%|█████▏    | 8562/16329 [1:12:06<1:04:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8562: train loss 1.56404. lr 5.038414e-04:  52%|█████▏    | 8563/16329 [1:12:06<1:04:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8563: train loss 1.50670. lr 5.038202e-04:  52%|█████▏    | 8563/16329 [1:12:06<1:04:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8563: train loss 1.50670. lr 5.038202e-04:  52%|█████▏    | 8564/16329 [1:12:06<1:04:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8564: train loss 1.52727. lr 5.037991e-04:  52%|█████▏    | 8564/16329 [1:12:07<1:04:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8564: train loss 1.52727. lr 5.037991e-04:  52%|█████▏    | 8565/16329 [1:12:07<1:04:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8565: train loss 1.55233. lr 5.037779e-04:  52%|█████▏    | 8565/16329 [1:12:07<1:04:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8565: train loss 1.55233. lr 5.037779e-04:  52%|█████▏    | 8566/16329 [1:12:07<1:04:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8566: train loss 1.55378. lr 5.037567e-04:  52%|█████▏    | 8566/16329 [1:12:08<1:04:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8566: train loss 1.55378. lr 5.037567e-04:  52%|█████▏    | 8567/16329 [1:12:08<1:04:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8567: train loss 1.56259. lr 5.037355e-04:  52%|█████▏    | 8567/16329 [1:12:08<1:04:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8567: train loss 1.56259. lr 5.037355e-04:  52%|█████▏    | 8568/16329 [1:12:08<1:04:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8568: train loss 1.56180. lr 5.037143e-04:  52%|█████▏    | 8568/16329 [1:12:09<1:04:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8568: train loss 1.56180. lr 5.037143e-04:  52%|█████▏    | 8569/16329 [1:12:09<1:04:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8569: train loss 1.58550. lr 5.036932e-04:  52%|█████▏    | 8569/16329 [1:12:09<1:04:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8569: train loss 1.58550. lr 5.036932e-04:  52%|█████▏    | 8570/16329 [1:12:09<1:04:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8570: train loss 1.52616. lr 5.036720e-04:  52%|█████▏    | 8570/16329 [1:12:10<1:04:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8570: train loss 1.52616. lr 5.036720e-04:  52%|█████▏    | 8571/16329 [1:12:10<1:04:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8571: train loss 1.51904. lr 5.036508e-04:  52%|█████▏    | 8571/16329 [1:12:10<1:04:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8571: train loss 1.51904. lr 5.036508e-04:  52%|█████▏    | 8572/16329 [1:12:10<1:03:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8572: train loss 1.55377. lr 5.036296e-04:  52%|█████▏    | 8572/16329 [1:12:11<1:03:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8572: train loss 1.55377. lr 5.036296e-04:  53%|█████▎    | 8573/16329 [1:12:11<1:03:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8573: train loss 1.53027. lr 5.036084e-04:  53%|█████▎    | 8573/16329 [1:12:11<1:03:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8573: train loss 1.53027. lr 5.036084e-04:  53%|█████▎    | 8574/16329 [1:12:11<1:04:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8574: train loss 1.51128. lr 5.035872e-04:  53%|█████▎    | 8574/16329 [1:12:12<1:04:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8574: train loss 1.51128. lr 5.035872e-04:  53%|█████▎    | 8575/16329 [1:12:12<1:04:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8575: train loss 1.54832. lr 5.035660e-04:  53%|█████▎    | 8575/16329 [1:12:12<1:04:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8575: train loss 1.54832. lr 5.035660e-04:  53%|█████▎    | 8576/16329 [1:12:12<1:04:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8576: train loss 1.50606. lr 5.035448e-04:  53%|█████▎    | 8576/16329 [1:12:13<1:04:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8576: train loss 1.50606. lr 5.035448e-04:  53%|█████▎    | 8577/16329 [1:12:13<1:04:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8577: train loss 1.57578. lr 5.035236e-04:  53%|█████▎    | 8577/16329 [1:12:13<1:04:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8577: train loss 1.57578. lr 5.035236e-04:  53%|█████▎    | 8578/16329 [1:12:13<1:04:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8578: train loss 1.54196. lr 5.035024e-04:  53%|█████▎    | 8578/16329 [1:12:14<1:04:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8578: train loss 1.54196. lr 5.035024e-04:  53%|█████▎    | 8579/16329 [1:12:14<1:10:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8579: train loss 1.58811. lr 5.034812e-04:  53%|█████▎    | 8579/16329 [1:12:14<1:10:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8579: train loss 1.58811. lr 5.034812e-04:  53%|█████▎    | 8580/16329 [1:12:14<1:09:01,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8580: train loss 1.52887. lr 5.034600e-04:  53%|█████▎    | 8580/16329 [1:12:15<1:09:01,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8580: train loss 1.52887. lr 5.034600e-04:  53%|█████▎    | 8581/16329 [1:12:15<1:07:33,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8581: train loss 1.50564. lr 5.034388e-04:  53%|█████▎    | 8581/16329 [1:12:15<1:07:33,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8581: train loss 1.50564. lr 5.034388e-04:  53%|█████▎    | 8582/16329 [1:12:15<1:06:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8582: train loss 1.51663. lr 5.034175e-04:  53%|█████▎    | 8582/16329 [1:12:16<1:06:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8582: train loss 1.51663. lr 5.034175e-04:  53%|█████▎    | 8583/16329 [1:12:16<1:05:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8583: train loss 1.51947. lr 5.033963e-04:  53%|█████▎    | 8583/16329 [1:12:16<1:05:37,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8583: train loss 1.51947. lr 5.033963e-04:  53%|█████▎    | 8584/16329 [1:12:16<1:04:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8584: train loss 1.49246. lr 5.033751e-04:  53%|█████▎    | 8584/16329 [1:12:17<1:04:59,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8584: train loss 1.49246. lr 5.033751e-04:  53%|█████▎    | 8585/16329 [1:12:17<1:04:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8585: train loss 1.51845. lr 5.033539e-04:  53%|█████▎    | 8585/16329 [1:12:17<1:04:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8585: train loss 1.51845. lr 5.033539e-04:  53%|█████▎    | 8586/16329 [1:12:17<1:05:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8586: train loss 1.53241. lr 5.033327e-04:  53%|█████▎    | 8586/16329 [1:12:18<1:05:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8586: train loss 1.53241. lr 5.033327e-04:  53%|█████▎    | 8587/16329 [1:12:18<1:05:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8587: train loss 1.54220. lr 5.033115e-04:  53%|█████▎    | 8587/16329 [1:12:18<1:05:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8587: train loss 1.54220. lr 5.033115e-04:  53%|█████▎    | 8588/16329 [1:12:18<1:04:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8588: train loss 1.52404. lr 5.032902e-04:  53%|█████▎    | 8588/16329 [1:12:19<1:04:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8588: train loss 1.52404. lr 5.032902e-04:  53%|█████▎    | 8589/16329 [1:12:19<1:04:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8589: train loss 1.53896. lr 5.032690e-04:  53%|█████▎    | 8589/16329 [1:12:19<1:04:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8589: train loss 1.53896. lr 5.032690e-04:  53%|█████▎    | 8590/16329 [1:12:19<1:04:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8590: train loss 1.56043. lr 5.032478e-04:  53%|█████▎    | 8590/16329 [1:12:20<1:04:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8590: train loss 1.56043. lr 5.032478e-04:  53%|█████▎    | 8591/16329 [1:12:20<1:04:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8591: train loss 1.55222. lr 5.032266e-04:  53%|█████▎    | 8591/16329 [1:12:20<1:04:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8591: train loss 1.55222. lr 5.032266e-04:  53%|█████▎    | 8592/16329 [1:12:20<1:04:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8592: train loss 1.56425. lr 5.032053e-04:  53%|█████▎    | 8592/16329 [1:12:21<1:04:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8592: train loss 1.56425. lr 5.032053e-04:  53%|█████▎    | 8593/16329 [1:12:21<1:04:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8593: train loss 1.56155. lr 5.031841e-04:  53%|█████▎    | 8593/16329 [1:12:21<1:04:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8593: train loss 1.56155. lr 5.031841e-04:  53%|█████▎    | 8594/16329 [1:12:21<1:04:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8594: train loss 1.54633. lr 5.031629e-04:  53%|█████▎    | 8594/16329 [1:12:22<1:04:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8594: train loss 1.54633. lr 5.031629e-04:  53%|█████▎    | 8595/16329 [1:12:22<1:04:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8595: train loss 1.54514. lr 5.031416e-04:  53%|█████▎    | 8595/16329 [1:12:22<1:04:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8595: train loss 1.54514. lr 5.031416e-04:  53%|█████▎    | 8596/16329 [1:12:22<1:04:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8596: train loss 1.55219. lr 5.031204e-04:  53%|█████▎    | 8596/16329 [1:12:23<1:04:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8596: train loss 1.55219. lr 5.031204e-04:  53%|█████▎    | 8597/16329 [1:12:23<1:04:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8597: train loss 1.54799. lr 5.030991e-04:  53%|█████▎    | 8597/16329 [1:12:23<1:04:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8597: train loss 1.54799. lr 5.030991e-04:  53%|█████▎    | 8598/16329 [1:12:23<1:03:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8598: train loss 1.55967. lr 5.030779e-04:  53%|█████▎    | 8598/16329 [1:12:24<1:03:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8598: train loss 1.55967. lr 5.030779e-04:  53%|█████▎    | 8599/16329 [1:12:24<1:04:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8599: train loss 1.49518. lr 5.030567e-04:  53%|█████▎    | 8599/16329 [1:12:24<1:04:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8599: train loss 1.49518. lr 5.030567e-04:  53%|█████▎    | 8600/16329 [1:12:24<1:03:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8600: train loss 1.52836. lr 5.030354e-04:  53%|█████▎    | 8600/16329 [1:12:25<1:03:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8600: train loss 1.52836. lr 5.030354e-04:  53%|█████▎    | 8601/16329 [1:12:25<1:03:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8601: train loss 1.53196. lr 5.030142e-04:  53%|█████▎    | 8601/16329 [1:12:25<1:03:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8601: train loss 1.53196. lr 5.030142e-04:  53%|█████▎    | 8602/16329 [1:12:25<1:03:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8602: train loss 1.51800. lr 5.029929e-04:  53%|█████▎    | 8602/16329 [1:12:26<1:03:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8602: train loss 1.51800. lr 5.029929e-04:  53%|█████▎    | 8603/16329 [1:12:26<1:03:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8603: train loss 1.56073. lr 5.029717e-04:  53%|█████▎    | 8603/16329 [1:12:26<1:03:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8603: train loss 1.56073. lr 5.029717e-04:  53%|█████▎    | 8604/16329 [1:12:26<1:10:37,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8604: train loss 1.54693. lr 5.029504e-04:  53%|█████▎    | 8604/16329 [1:12:27<1:10:37,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8604: train loss 1.54693. lr 5.029504e-04:  53%|█████▎    | 8605/16329 [1:12:27<1:08:17,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8605: train loss 1.48041. lr 5.029292e-04:  53%|█████▎    | 8605/16329 [1:12:27<1:08:17,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8605: train loss 1.48041. lr 5.029292e-04:  53%|█████▎    | 8606/16329 [1:12:27<1:07:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8606: train loss 1.52255. lr 5.029079e-04:  53%|█████▎    | 8606/16329 [1:12:28<1:07:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8606: train loss 1.52255. lr 5.029079e-04:  53%|█████▎    | 8607/16329 [1:12:28<1:06:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8607: train loss 1.53259. lr 5.028866e-04:  53%|█████▎    | 8607/16329 [1:12:28<1:06:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8607: train loss 1.53259. lr 5.028866e-04:  53%|█████▎    | 8608/16329 [1:12:28<1:05:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8608: train loss 1.49532. lr 5.028654e-04:  53%|█████▎    | 8608/16329 [1:12:29<1:05:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8608: train loss 1.49532. lr 5.028654e-04:  53%|█████▎    | 8609/16329 [1:12:29<1:04:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8609: train loss 1.57453. lr 5.028441e-04:  53%|█████▎    | 8609/16329 [1:12:29<1:04:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8609: train loss 1.57453. lr 5.028441e-04:  53%|█████▎    | 8610/16329 [1:12:29<1:04:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8610: train loss 1.49632. lr 5.028229e-04:  53%|█████▎    | 8610/16329 [1:12:30<1:04:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8610: train loss 1.49632. lr 5.028229e-04:  53%|█████▎    | 8611/16329 [1:12:30<1:04:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8611: train loss 1.50986. lr 5.028016e-04:  53%|█████▎    | 8611/16329 [1:12:30<1:04:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8611: train loss 1.50986. lr 5.028016e-04:  53%|█████▎    | 8612/16329 [1:12:30<1:04:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8612: train loss 1.53955. lr 5.027803e-04:  53%|█████▎    | 8612/16329 [1:12:31<1:04:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8612: train loss 1.53955. lr 5.027803e-04:  53%|█████▎    | 8613/16329 [1:12:31<1:04:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8613: train loss 1.49986. lr 5.027591e-04:  53%|█████▎    | 8613/16329 [1:12:31<1:04:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8613: train loss 1.49986. lr 5.027591e-04:  53%|█████▎    | 8614/16329 [1:12:31<1:03:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8614: train loss 1.57039. lr 5.027378e-04:  53%|█████▎    | 8614/16329 [1:12:32<1:03:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8614: train loss 1.57039. lr 5.027378e-04:  53%|█████▎    | 8615/16329 [1:12:32<1:03:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8615: train loss 1.52991. lr 5.027165e-04:  53%|█████▎    | 8615/16329 [1:12:32<1:03:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8615: train loss 1.52991. lr 5.027165e-04:  53%|█████▎    | 8616/16329 [1:12:32<1:06:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8616: train loss 1.56658. lr 5.026952e-04:  53%|█████▎    | 8616/16329 [1:12:33<1:06:41,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8616: train loss 1.56658. lr 5.026952e-04:  53%|█████▎    | 8617/16329 [1:12:33<1:08:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8617: train loss 1.51753. lr 5.026740e-04:  53%|█████▎    | 8617/16329 [1:12:34<1:08:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8617: train loss 1.51753. lr 5.026740e-04:  53%|█████▎    | 8618/16329 [1:12:34<1:08:52,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8618: train loss 1.55564. lr 5.026527e-04:  53%|█████▎    | 8618/16329 [1:12:34<1:08:52,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8618: train loss 1.55564. lr 5.026527e-04:  53%|█████▎    | 8619/16329 [1:12:34<1:08:45,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8619: train loss 1.53923. lr 5.026314e-04:  53%|█████▎    | 8619/16329 [1:12:35<1:08:45,  1.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8619: train loss 1.53923. lr 5.026314e-04:  53%|█████▎    | 8620/16329 [1:12:35<1:08:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8620: train loss 1.46324. lr 5.026101e-04:  53%|█████▎    | 8620/16329 [1:12:35<1:08:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8620: train loss 1.46324. lr 5.026101e-04:  53%|█████▎    | 8621/16329 [1:12:35<1:07:43,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8621: train loss 1.49049. lr 5.025888e-04:  53%|█████▎    | 8621/16329 [1:12:36<1:07:43,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8621: train loss 1.49049. lr 5.025888e-04:  53%|█████▎    | 8622/16329 [1:12:36<1:06:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8622: train loss 1.49698. lr 5.025675e-04:  53%|█████▎    | 8622/16329 [1:12:36<1:06:57,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8622: train loss 1.49698. lr 5.025675e-04:  53%|█████▎    | 8623/16329 [1:12:36<1:06:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8623: train loss 1.50050. lr 5.025463e-04:  53%|█████▎    | 8623/16329 [1:12:37<1:06:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8623: train loss 1.50050. lr 5.025463e-04:  53%|█████▎    | 8624/16329 [1:12:37<1:05:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8624: train loss 1.53748. lr 5.025250e-04:  53%|█████▎    | 8624/16329 [1:12:37<1:05:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8624: train loss 1.53748. lr 5.025250e-04:  53%|█████▎    | 8625/16329 [1:12:37<1:05:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8625: train loss 1.50197. lr 5.025037e-04:  53%|█████▎    | 8625/16329 [1:12:38<1:05:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8625: train loss 1.50197. lr 5.025037e-04:  53%|█████▎    | 8626/16329 [1:12:38<1:04:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8626: train loss 1.51771. lr 5.024824e-04:  53%|█████▎    | 8626/16329 [1:12:38<1:04:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8626: train loss 1.51771. lr 5.024824e-04:  53%|█████▎    | 8627/16329 [1:12:38<1:04:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8627: train loss 1.55572. lr 5.024611e-04:  53%|█████▎    | 8627/16329 [1:12:39<1:04:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8627: train loss 1.55572. lr 5.024611e-04:  53%|█████▎    | 8628/16329 [1:12:39<1:03:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8628: train loss 1.49583. lr 5.024398e-04:  53%|█████▎    | 8628/16329 [1:12:39<1:03:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8628: train loss 1.49583. lr 5.024398e-04:  53%|█████▎    | 8629/16329 [1:12:39<1:03:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8629: train loss 1.59184. lr 5.024185e-04:  53%|█████▎    | 8629/16329 [1:12:40<1:03:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8629: train loss 1.59184. lr 5.024185e-04:  53%|█████▎    | 8630/16329 [1:12:40<1:04:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8630: train loss 1.57617. lr 5.023972e-04:  53%|█████▎    | 8630/16329 [1:12:40<1:04:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8630: train loss 1.57617. lr 5.023972e-04:  53%|█████▎    | 8631/16329 [1:12:40<1:11:50,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 8631: train loss 1.46171. lr 5.023759e-04:  53%|█████▎    | 8631/16329 [1:12:41<1:11:50,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 8631: train loss 1.46171. lr 5.023759e-04:  53%|█████▎    | 8632/16329 [1:12:41<1:09:44,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 8632: train loss 1.52367. lr 5.023546e-04:  53%|█████▎    | 8632/16329 [1:12:41<1:09:44,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 8632: train loss 1.52367. lr 5.023546e-04:  53%|█████▎    | 8633/16329 [1:12:41<1:08:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8633: train loss 1.52094. lr 5.023333e-04:  53%|█████▎    | 8633/16329 [1:12:42<1:08:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8633: train loss 1.52094. lr 5.023333e-04:  53%|█████▎    | 8634/16329 [1:12:42<1:07:12,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8634: train loss 1.49621. lr 5.023120e-04:  53%|█████▎    | 8634/16329 [1:12:42<1:07:12,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8634: train loss 1.49621. lr 5.023120e-04:  53%|█████▎    | 8635/16329 [1:12:42<1:06:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8635: train loss 1.50448. lr 5.022906e-04:  53%|█████▎    | 8635/16329 [1:12:43<1:06:27,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8635: train loss 1.50448. lr 5.022906e-04:  53%|█████▎    | 8636/16329 [1:12:43<1:05:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8636: train loss 1.54525. lr 5.022693e-04:  53%|█████▎    | 8636/16329 [1:12:43<1:05:32,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8636: train loss 1.54525. lr 5.022693e-04:  53%|█████▎    | 8637/16329 [1:12:43<1:04:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8637: train loss 1.49719. lr 5.022480e-04:  53%|█████▎    | 8637/16329 [1:12:44<1:04:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8637: train loss 1.49719. lr 5.022480e-04:  53%|█████▎    | 8638/16329 [1:12:44<1:04:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8638: train loss 1.53786. lr 5.022267e-04:  53%|█████▎    | 8638/16329 [1:12:44<1:04:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8638: train loss 1.53786. lr 5.022267e-04:  53%|█████▎    | 8639/16329 [1:12:44<1:04:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8639: train loss 1.54593. lr 5.022054e-04:  53%|█████▎    | 8639/16329 [1:12:45<1:04:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8639: train loss 1.54593. lr 5.022054e-04:  53%|█████▎    | 8640/16329 [1:12:45<1:04:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8640: train loss 1.51034. lr 5.021841e-04:  53%|█████▎    | 8640/16329 [1:12:45<1:04:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8640: train loss 1.51034. lr 5.021841e-04:  53%|█████▎    | 8641/16329 [1:12:45<1:03:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8641: train loss 1.53534. lr 5.021627e-04:  53%|█████▎    | 8641/16329 [1:12:46<1:03:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8641: train loss 1.53534. lr 5.021627e-04:  53%|█████▎    | 8642/16329 [1:12:46<1:03:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8642: train loss 1.54206. lr 5.021414e-04:  53%|█████▎    | 8642/16329 [1:12:46<1:03:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8642: train loss 1.54206. lr 5.021414e-04:  53%|█████▎    | 8643/16329 [1:12:46<1:03:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8643: train loss 1.54210. lr 5.021201e-04:  53%|█████▎    | 8643/16329 [1:12:47<1:03:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8643: train loss 1.54210. lr 5.021201e-04:  53%|█████▎    | 8644/16329 [1:12:47<1:03:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8644: train loss 1.52971. lr 5.020988e-04:  53%|█████▎    | 8644/16329 [1:12:47<1:03:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8644: train loss 1.52971. lr 5.020988e-04:  53%|█████▎    | 8645/16329 [1:12:47<1:03:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8645: train loss 1.47466. lr 5.020774e-04:  53%|█████▎    | 8645/16329 [1:12:48<1:03:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8645: train loss 1.47466. lr 5.020774e-04:  53%|█████▎    | 8646/16329 [1:12:48<1:03:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8646: train loss 1.50340. lr 5.020561e-04:  53%|█████▎    | 8646/16329 [1:12:48<1:03:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8646: train loss 1.50340. lr 5.020561e-04:  53%|█████▎    | 8647/16329 [1:12:48<1:03:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8647: train loss 1.53548. lr 5.020348e-04:  53%|█████▎    | 8647/16329 [1:12:49<1:03:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8647: train loss 1.53548. lr 5.020348e-04:  53%|█████▎    | 8648/16329 [1:12:49<1:03:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8648: train loss 1.53027. lr 5.020134e-04:  53%|█████▎    | 8648/16329 [1:12:49<1:03:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8648: train loss 1.53027. lr 5.020134e-04:  53%|█████▎    | 8649/16329 [1:12:49<1:03:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8649: train loss 1.51655. lr 5.019921e-04:  53%|█████▎    | 8649/16329 [1:12:50<1:03:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8649: train loss 1.51655. lr 5.019921e-04:  53%|█████▎    | 8650/16329 [1:12:50<1:03:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8650: train loss 1.52006. lr 5.019708e-04:  53%|█████▎    | 8650/16329 [1:12:50<1:03:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8650: train loss 1.52006. lr 5.019708e-04:  53%|█████▎    | 8651/16329 [1:12:50<1:03:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8651: train loss 1.52440. lr 5.019494e-04:  53%|█████▎    | 8651/16329 [1:12:51<1:03:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8651: train loss 1.52440. lr 5.019494e-04:  53%|█████▎    | 8652/16329 [1:12:51<1:03:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8652: train loss 1.53890. lr 5.019281e-04:  53%|█████▎    | 8652/16329 [1:12:51<1:03:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8652: train loss 1.53890. lr 5.019281e-04:  53%|█████▎    | 8653/16329 [1:12:51<1:03:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8653: train loss 1.53056. lr 5.019067e-04:  53%|█████▎    | 8653/16329 [1:12:52<1:03:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8653: train loss 1.53056. lr 5.019067e-04:  53%|█████▎    | 8654/16329 [1:12:52<1:03:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8654: train loss 1.52407. lr 5.018854e-04:  53%|█████▎    | 8654/16329 [1:12:52<1:03:15,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8654: train loss 1.52407. lr 5.018854e-04:  53%|█████▎    | 8655/16329 [1:12:52<1:03:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8655: train loss 1.52527. lr 5.018640e-04:  53%|█████▎    | 8655/16329 [1:12:53<1:03:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8655: train loss 1.52527. lr 5.018640e-04:  53%|█████▎    | 8656/16329 [1:12:53<1:03:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8656: train loss 1.51621. lr 5.018427e-04:  53%|█████▎    | 8656/16329 [1:12:53<1:03:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8656: train loss 1.51621. lr 5.018427e-04:  53%|█████▎    | 8657/16329 [1:12:53<1:03:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8657: train loss 1.52907. lr 5.018213e-04:  53%|█████▎    | 8657/16329 [1:12:54<1:03:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8657: train loss 1.52907. lr 5.018213e-04:  53%|█████▎    | 8658/16329 [1:12:54<1:03:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8658: train loss 1.54737. lr 5.018000e-04:  53%|█████▎    | 8658/16329 [1:12:54<1:03:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8658: train loss 1.54737. lr 5.018000e-04:  53%|█████▎    | 8659/16329 [1:12:54<1:03:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8659: train loss 1.51486. lr 5.017786e-04:  53%|█████▎    | 8659/16329 [1:12:55<1:03:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8659: train loss 1.51486. lr 5.017786e-04:  53%|█████▎    | 8660/16329 [1:12:55<1:03:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8660: train loss 1.50913. lr 5.017573e-04:  53%|█████▎    | 8660/16329 [1:12:55<1:03:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8660: train loss 1.50913. lr 5.017573e-04:  53%|█████▎    | 8661/16329 [1:12:55<1:02:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8661: train loss 1.53170. lr 5.017359e-04:  53%|█████▎    | 8661/16329 [1:12:56<1:02:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8661: train loss 1.53170. lr 5.017359e-04:  53%|█████▎    | 8662/16329 [1:12:56<1:02:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8662: train loss 1.51845. lr 5.017145e-04:  53%|█████▎    | 8662/16329 [1:12:56<1:02:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8662: train loss 1.51845. lr 5.017145e-04:  53%|█████▎    | 8663/16329 [1:12:56<1:02:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8663: train loss 1.51225. lr 5.016932e-04:  53%|█████▎    | 8663/16329 [1:12:57<1:02:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8663: train loss 1.51225. lr 5.016932e-04:  53%|█████▎    | 8664/16329 [1:12:57<1:03:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8664: train loss 1.56636. lr 5.016718e-04:  53%|█████▎    | 8664/16329 [1:12:57<1:03:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8664: train loss 1.56636. lr 5.016718e-04:  53%|█████▎    | 8665/16329 [1:12:57<1:03:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8665: train loss 1.55676. lr 5.016504e-04:  53%|█████▎    | 8665/16329 [1:12:58<1:03:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8665: train loss 1.55676. lr 5.016504e-04:  53%|█████▎    | 8666/16329 [1:12:58<1:03:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8666: train loss 1.52823. lr 5.016291e-04:  53%|█████▎    | 8666/16329 [1:12:58<1:03:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8666: train loss 1.52823. lr 5.016291e-04:  53%|█████▎    | 8667/16329 [1:12:58<1:03:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8667: train loss 1.49221. lr 5.016077e-04:  53%|█████▎    | 8667/16329 [1:12:59<1:03:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8667: train loss 1.49221. lr 5.016077e-04:  53%|█████▎    | 8668/16329 [1:12:59<1:03:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8668: train loss 1.51520. lr 5.015863e-04:  53%|█████▎    | 8668/16329 [1:12:59<1:03:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8668: train loss 1.51520. lr 5.015863e-04:  53%|█████▎    | 8669/16329 [1:12:59<1:03:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8669: train loss 1.55807. lr 5.015650e-04:  53%|█████▎    | 8669/16329 [1:13:00<1:03:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8669: train loss 1.55807. lr 5.015650e-04:  53%|█████▎    | 8670/16329 [1:13:00<1:02:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8670: train loss 1.49971. lr 5.015436e-04:  53%|█████▎    | 8670/16329 [1:13:00<1:02:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 8670: train loss 1.49971. lr 5.015436e-04:  53%|█████▎    | 8671/16329 [1:13:00<1:09:29,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 8671: train loss 1.52093. lr 5.015222e-04:  53%|█████▎    | 8671/16329 [1:13:01<1:09:29,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 8671: train loss 1.52093. lr 5.015222e-04:  53%|█████▎    | 8672/16329 [1:13:01<1:07:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8672: train loss 1.52276. lr 5.015008e-04:  53%|█████▎    | 8672/16329 [1:13:01<1:07:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8672: train loss 1.52276. lr 5.015008e-04:  53%|█████▎    | 8673/16329 [1:13:01<1:10:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8673: train loss 1.52637. lr 5.014794e-04:  53%|█████▎    | 8673/16329 [1:13:02<1:10:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8673: train loss 1.52637. lr 5.014794e-04:  53%|█████▎    | 8674/16329 [1:13:02<1:10:15,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8674: train loss 1.51868. lr 5.014581e-04:  53%|█████▎    | 8674/16329 [1:13:02<1:10:15,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8674: train loss 1.51868. lr 5.014581e-04:  53%|█████▎    | 8675/16329 [1:13:02<1:09:36,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8675: train loss 1.47351. lr 5.014367e-04:  53%|█████▎    | 8675/16329 [1:13:03<1:09:36,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8675: train loss 1.47351. lr 5.014367e-04:  53%|█████▎    | 8676/16329 [1:13:03<1:08:33,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8676: train loss 1.54067. lr 5.014153e-04:  53%|█████▎    | 8676/16329 [1:13:04<1:08:33,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8676: train loss 1.54067. lr 5.014153e-04:  53%|█████▎    | 8677/16329 [1:13:04<1:07:46,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8677: train loss 1.52221. lr 5.013939e-04:  53%|█████▎    | 8677/16329 [1:13:04<1:07:46,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8677: train loss 1.52221. lr 5.013939e-04:  53%|█████▎    | 8678/16329 [1:13:04<1:06:48,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8678: train loss 1.52888. lr 5.013725e-04:  53%|█████▎    | 8678/16329 [1:13:05<1:06:48,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8678: train loss 1.52888. lr 5.013725e-04:  53%|█████▎    | 8679/16329 [1:13:05<1:06:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8679: train loss 1.49046. lr 5.013511e-04:  53%|█████▎    | 8679/16329 [1:13:05<1:06:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8679: train loss 1.49046. lr 5.013511e-04:  53%|█████▎    | 8680/16329 [1:13:05<1:05:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8680: train loss 1.51153. lr 5.013297e-04:  53%|█████▎    | 8680/16329 [1:13:06<1:05:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8680: train loss 1.51153. lr 5.013297e-04:  53%|█████▎    | 8681/16329 [1:13:06<1:04:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8681: train loss 1.51653. lr 5.013083e-04:  53%|█████▎    | 8681/16329 [1:13:06<1:04:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8681: train loss 1.51653. lr 5.013083e-04:  53%|█████▎    | 8682/16329 [1:13:06<1:04:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8682: train loss 1.51097. lr 5.012869e-04:  53%|█████▎    | 8682/16329 [1:13:07<1:04:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8682: train loss 1.51097. lr 5.012869e-04:  53%|█████▎    | 8683/16329 [1:13:07<1:04:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8683: train loss 1.51706. lr 5.012655e-04:  53%|█████▎    | 8683/16329 [1:13:07<1:04:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8683: train loss 1.51706. lr 5.012655e-04:  53%|█████▎    | 8684/16329 [1:13:07<1:03:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8684: train loss 1.49522. lr 5.012441e-04:  53%|█████▎    | 8684/16329 [1:13:08<1:03:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8684: train loss 1.49522. lr 5.012441e-04:  53%|█████▎    | 8685/16329 [1:13:08<1:03:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8685: train loss 1.53219. lr 5.012227e-04:  53%|█████▎    | 8685/16329 [1:13:08<1:03:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8685: train loss 1.53219. lr 5.012227e-04:  53%|█████▎    | 8686/16329 [1:13:08<1:03:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8686: train loss 1.54984. lr 5.012013e-04:  53%|█████▎    | 8686/16329 [1:13:08<1:03:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8686: train loss 1.54984. lr 5.012013e-04:  53%|█████▎    | 8687/16329 [1:13:08<1:03:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8687: train loss 1.49000. lr 5.011799e-04:  53%|█████▎    | 8687/16329 [1:13:09<1:03:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8687: train loss 1.49000. lr 5.011799e-04:  53%|█████▎    | 8688/16329 [1:13:09<1:03:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8688: train loss 1.49396. lr 5.011585e-04:  53%|█████▎    | 8688/16329 [1:13:09<1:03:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8688: train loss 1.49396. lr 5.011585e-04:  53%|█████▎    | 8689/16329 [1:13:09<1:03:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8689: train loss 1.50307. lr 5.011371e-04:  53%|█████▎    | 8689/16329 [1:13:10<1:03:03,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8689: train loss 1.50307. lr 5.011371e-04:  53%|█████▎    | 8690/16329 [1:13:10<1:03:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8690: train loss 1.53415. lr 5.011157e-04:  53%|█████▎    | 8690/16329 [1:13:10<1:03:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8690: train loss 1.53415. lr 5.011157e-04:  53%|█████▎    | 8691/16329 [1:13:10<1:03:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8691: train loss 1.53596. lr 5.010942e-04:  53%|█████▎    | 8691/16329 [1:13:11<1:03:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8691: train loss 1.53596. lr 5.010942e-04:  53%|█████▎    | 8692/16329 [1:13:11<1:03:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8692: train loss 1.53515. lr 5.010728e-04:  53%|█████▎    | 8692/16329 [1:13:11<1:03:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8692: train loss 1.53515. lr 5.010728e-04:  53%|█████▎    | 8693/16329 [1:13:11<1:03:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8693: train loss 1.48772. lr 5.010514e-04:  53%|█████▎    | 8693/16329 [1:13:12<1:03:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8693: train loss 1.48772. lr 5.010514e-04:  53%|█████▎    | 8694/16329 [1:13:12<1:03:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8694: train loss 1.47751. lr 5.010300e-04:  53%|█████▎    | 8694/16329 [1:13:12<1:03:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8694: train loss 1.47751. lr 5.010300e-04:  53%|█████▎    | 8695/16329 [1:13:12<1:03:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8695: train loss 1.46867. lr 5.010086e-04:  53%|█████▎    | 8695/16329 [1:13:13<1:03:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8695: train loss 1.46867. lr 5.010086e-04:  53%|█████▎    | 8696/16329 [1:13:13<1:03:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8696: train loss 1.51836. lr 5.009871e-04:  53%|█████▎    | 8696/16329 [1:13:13<1:03:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8696: train loss 1.51836. lr 5.009871e-04:  53%|█████▎    | 8697/16329 [1:13:13<1:03:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8697: train loss 1.54640. lr 5.009657e-04:  53%|█████▎    | 8697/16329 [1:13:14<1:03:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8697: train loss 1.54640. lr 5.009657e-04:  53%|█████▎    | 8698/16329 [1:13:14<1:03:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8698: train loss 1.52274. lr 5.009443e-04:  53%|█████▎    | 8698/16329 [1:13:14<1:03:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8698: train loss 1.52274. lr 5.009443e-04:  53%|█████▎    | 8699/16329 [1:13:14<1:03:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8699: train loss 1.52058. lr 5.009228e-04:  53%|█████▎    | 8699/16329 [1:13:15<1:03:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8699: train loss 1.52058. lr 5.009228e-04:  53%|█████▎    | 8700/16329 [1:13:15<1:03:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8700: train loss 1.58127. lr 5.009014e-04:  53%|█████▎    | 8700/16329 [1:13:15<1:03:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8700: train loss 1.58127. lr 5.009014e-04:  53%|█████▎    | 8701/16329 [1:13:15<1:03:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8701: train loss 1.53987. lr 5.008800e-04:  53%|█████▎    | 8701/16329 [1:13:16<1:03:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8701: train loss 1.53987. lr 5.008800e-04:  53%|█████▎    | 8702/16329 [1:13:16<1:03:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8702: train loss 1.52982. lr 5.008585e-04:  53%|█████▎    | 8702/16329 [1:13:16<1:03:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8702: train loss 1.52982. lr 5.008585e-04:  53%|█████▎    | 8703/16329 [1:13:16<1:03:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8703: train loss 1.52034. lr 5.008371e-04:  53%|█████▎    | 8703/16329 [1:13:17<1:03:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8703: train loss 1.52034. lr 5.008371e-04:  53%|█████▎    | 8704/16329 [1:13:17<1:03:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8704: train loss 1.50596. lr 5.008157e-04:  53%|█████▎    | 8704/16329 [1:13:17<1:03:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8704: train loss 1.50596. lr 5.008157e-04:  53%|█████▎    | 8705/16329 [1:13:17<1:02:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8705: train loss 1.51413. lr 5.007942e-04:  53%|█████▎    | 8705/16329 [1:13:18<1:02:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8705: train loss 1.51413. lr 5.007942e-04:  53%|█████▎    | 8706/16329 [1:13:18<1:09:31,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8706: train loss 1.50129. lr 5.007728e-04:  53%|█████▎    | 8706/16329 [1:13:19<1:09:31,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8706: train loss 1.50129. lr 5.007728e-04:  53%|█████▎    | 8707/16329 [1:13:19<1:07:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8707: train loss 1.50615. lr 5.007513e-04:  53%|█████▎    | 8707/16329 [1:13:19<1:07:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8707: train loss 1.50615. lr 5.007513e-04:  53%|█████▎    | 8708/16329 [1:13:19<1:06:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8708: train loss 1.55866. lr 5.007299e-04:  53%|█████▎    | 8708/16329 [1:13:20<1:06:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8708: train loss 1.55866. lr 5.007299e-04:  53%|█████▎    | 8709/16329 [1:13:20<1:05:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8709: train loss 1.52500. lr 5.007084e-04:  53%|█████▎    | 8709/16329 [1:13:20<1:05:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8709: train loss 1.52500. lr 5.007084e-04:  53%|█████▎    | 8710/16329 [1:13:20<1:04:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8710: train loss 1.47196. lr 5.006870e-04:  53%|█████▎    | 8710/16329 [1:13:21<1:04:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8710: train loss 1.47196. lr 5.006870e-04:  53%|█████▎    | 8711/16329 [1:13:21<1:04:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8711: train loss 1.51250. lr 5.006655e-04:  53%|█████▎    | 8711/16329 [1:13:21<1:04:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8711: train loss 1.51250. lr 5.006655e-04:  53%|█████▎    | 8712/16329 [1:13:21<1:03:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8712: train loss 1.51255. lr 5.006441e-04:  53%|█████▎    | 8712/16329 [1:13:22<1:03:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8712: train loss 1.51255. lr 5.006441e-04:  53%|█████▎    | 8713/16329 [1:13:22<1:03:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8713: train loss 1.50881. lr 5.006226e-04:  53%|█████▎    | 8713/16329 [1:13:22<1:03:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8713: train loss 1.50881. lr 5.006226e-04:  53%|█████▎    | 8714/16329 [1:13:22<1:03:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8714: train loss 1.49992. lr 5.006012e-04:  53%|█████▎    | 8714/16329 [1:13:23<1:03:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8714: train loss 1.49992. lr 5.006012e-04:  53%|█████▎    | 8715/16329 [1:13:23<1:03:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8715: train loss 1.52879. lr 5.005797e-04:  53%|█████▎    | 8715/16329 [1:13:23<1:03:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8715: train loss 1.52879. lr 5.005797e-04:  53%|█████▎    | 8716/16329 [1:13:23<1:03:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8716: train loss 1.55340. lr 5.005582e-04:  53%|█████▎    | 8716/16329 [1:13:24<1:03:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8716: train loss 1.55340. lr 5.005582e-04:  53%|█████▎    | 8717/16329 [1:13:24<1:03:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8717: train loss 1.52285. lr 5.005368e-04:  53%|█████▎    | 8717/16329 [1:13:24<1:03:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8717: train loss 1.52285. lr 5.005368e-04:  53%|█████▎    | 8718/16329 [1:13:24<1:03:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8718: train loss 1.54690. lr 5.005153e-04:  53%|█████▎    | 8718/16329 [1:13:25<1:03:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8718: train loss 1.54690. lr 5.005153e-04:  53%|█████▎    | 8719/16329 [1:13:25<1:03:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8719: train loss 1.47004. lr 5.004938e-04:  53%|█████▎    | 8719/16329 [1:13:25<1:03:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8719: train loss 1.47004. lr 5.004938e-04:  53%|█████▎    | 8720/16329 [1:13:25<1:03:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8720: train loss 1.53657. lr 5.004724e-04:  53%|█████▎    | 8720/16329 [1:13:26<1:03:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8720: train loss 1.53657. lr 5.004724e-04:  53%|█████▎    | 8721/16329 [1:13:26<1:03:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8721: train loss 1.48296. lr 5.004509e-04:  53%|█████▎    | 8721/16329 [1:13:26<1:03:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8721: train loss 1.48296. lr 5.004509e-04:  53%|█████▎    | 8722/16329 [1:13:26<1:03:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8722: train loss 1.52246. lr 5.004294e-04:  53%|█████▎    | 8722/16329 [1:13:27<1:03:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8722: train loss 1.52246. lr 5.004294e-04:  53%|█████▎    | 8723/16329 [1:13:27<1:03:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8723: train loss 1.50841. lr 5.004080e-04:  53%|█████▎    | 8723/16329 [1:13:27<1:03:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8723: train loss 1.50841. lr 5.004080e-04:  53%|█████▎    | 8724/16329 [1:13:27<1:03:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8724: train loss 1.56483. lr 5.003865e-04:  53%|█████▎    | 8724/16329 [1:13:28<1:03:01,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8724: train loss 1.56483. lr 5.003865e-04:  53%|█████▎    | 8725/16329 [1:13:28<1:02:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8725: train loss 1.51334. lr 5.003650e-04:  53%|█████▎    | 8725/16329 [1:13:28<1:02:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8725: train loss 1.51334. lr 5.003650e-04:  53%|█████▎    | 8726/16329 [1:13:28<1:02:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8726: train loss 1.53374. lr 5.003435e-04:  53%|█████▎    | 8726/16329 [1:13:29<1:02:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8726: train loss 1.53374. lr 5.003435e-04:  53%|█████▎    | 8727/16329 [1:13:29<1:02:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8727: train loss 1.54926. lr 5.003220e-04:  53%|█████▎    | 8727/16329 [1:13:29<1:02:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8727: train loss 1.54926. lr 5.003220e-04:  53%|█████▎    | 8728/16329 [1:13:29<1:03:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8728: train loss 1.53191. lr 5.003006e-04:  53%|█████▎    | 8728/16329 [1:13:30<1:03:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8728: train loss 1.53191. lr 5.003006e-04:  53%|█████▎    | 8729/16329 [1:13:30<1:02:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8729: train loss 1.52346. lr 5.002791e-04:  53%|█████▎    | 8729/16329 [1:13:30<1:02:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8729: train loss 1.52346. lr 5.002791e-04:  53%|█████▎    | 8730/16329 [1:13:30<1:02:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8730: train loss 1.50871. lr 5.002576e-04:  53%|█████▎    | 8730/16329 [1:13:31<1:02:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8730: train loss 1.50871. lr 5.002576e-04:  53%|█████▎    | 8731/16329 [1:13:31<1:09:35,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8731: train loss 1.57074. lr 5.002361e-04:  53%|█████▎    | 8731/16329 [1:13:31<1:09:35,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8731: train loss 1.57074. lr 5.002361e-04:  53%|█████▎    | 8732/16329 [1:13:31<1:07:29,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8732: train loss 1.53926. lr 5.002146e-04:  53%|█████▎    | 8732/16329 [1:13:32<1:07:29,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8732: train loss 1.53926. lr 5.002146e-04:  53%|█████▎    | 8733/16329 [1:13:32<1:06:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8733: train loss 1.46270. lr 5.001931e-04:  53%|█████▎    | 8733/16329 [1:13:32<1:06:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8733: train loss 1.46270. lr 5.001931e-04:  53%|█████▎    | 8734/16329 [1:13:32<1:05:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8734: train loss 1.52741. lr 5.001716e-04:  53%|█████▎    | 8734/16329 [1:13:33<1:05:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8734: train loss 1.52741. lr 5.001716e-04:  53%|█████▎    | 8735/16329 [1:13:33<1:04:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8735: train loss 1.49996. lr 5.001501e-04:  53%|█████▎    | 8735/16329 [1:13:33<1:04:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8735: train loss 1.49996. lr 5.001501e-04:  53%|█████▎    | 8736/16329 [1:13:33<1:03:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8736: train loss 1.54458. lr 5.001286e-04:  53%|█████▎    | 8736/16329 [1:13:34<1:03:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8736: train loss 1.54458. lr 5.001286e-04:  54%|█████▎    | 8737/16329 [1:13:34<1:03:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8737: train loss 1.51981. lr 5.001071e-04:  54%|█████▎    | 8737/16329 [1:13:34<1:03:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8737: train loss 1.51981. lr 5.001071e-04:  54%|█████▎    | 8738/16329 [1:13:34<1:03:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8738: train loss 1.54823. lr 5.000856e-04:  54%|█████▎    | 8738/16329 [1:13:35<1:03:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8738: train loss 1.54823. lr 5.000856e-04:  54%|█████▎    | 8739/16329 [1:13:35<1:03:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8739: train loss 1.50739. lr 5.000641e-04:  54%|█████▎    | 8739/16329 [1:13:35<1:03:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8739: train loss 1.50739. lr 5.000641e-04:  54%|█████▎    | 8740/16329 [1:13:35<1:02:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8740: train loss 1.55262. lr 5.000426e-04:  54%|█████▎    | 8740/16329 [1:13:36<1:02:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8740: train loss 1.55262. lr 5.000426e-04:  54%|█████▎    | 8741/16329 [1:13:36<1:02:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8741: train loss 1.51263. lr 5.000211e-04:  54%|█████▎    | 8741/16329 [1:13:36<1:02:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8741: train loss 1.51263. lr 5.000211e-04:  54%|█████▎    | 8742/16329 [1:13:36<1:02:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8742: train loss 1.51539. lr 4.999996e-04:  54%|█████▎    | 8742/16329 [1:13:37<1:02:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8742: train loss 1.51539. lr 4.999996e-04:  54%|█████▎    | 8743/16329 [1:13:37<1:02:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8743: train loss 1.53131. lr 4.999781e-04:  54%|█████▎    | 8743/16329 [1:13:37<1:02:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8743: train loss 1.53131. lr 4.999781e-04:  54%|█████▎    | 8744/16329 [1:13:37<1:02:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8744: train loss 1.54115. lr 4.999566e-04:  54%|█████▎    | 8744/16329 [1:13:38<1:02:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8744: train loss 1.54115. lr 4.999566e-04:  54%|█████▎    | 8745/16329 [1:13:38<1:02:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8745: train loss 1.50786. lr 4.999350e-04:  54%|█████▎    | 8745/16329 [1:13:38<1:02:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8745: train loss 1.50786. lr 4.999350e-04:  54%|█████▎    | 8746/16329 [1:13:38<1:02:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8746: train loss 1.54884. lr 4.999135e-04:  54%|█████▎    | 8746/16329 [1:13:39<1:02:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8746: train loss 1.54884. lr 4.999135e-04:  54%|█████▎    | 8747/16329 [1:13:39<1:02:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8747: train loss 1.56136. lr 4.998920e-04:  54%|█████▎    | 8747/16329 [1:13:39<1:02:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8747: train loss 1.56136. lr 4.998920e-04:  54%|█████▎    | 8748/16329 [1:13:39<1:02:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8748: train loss 1.51591. lr 4.998705e-04:  54%|█████▎    | 8748/16329 [1:13:40<1:02:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8748: train loss 1.51591. lr 4.998705e-04:  54%|█████▎    | 8749/16329 [1:13:40<1:02:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8749: train loss 1.54196. lr 4.998490e-04:  54%|█████▎    | 8749/16329 [1:13:40<1:02:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8749: train loss 1.54196. lr 4.998490e-04:  54%|█████▎    | 8750/16329 [1:13:40<1:02:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8750: train loss 1.51375. lr 4.998274e-04:  54%|█████▎    | 8750/16329 [1:13:41<1:02:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8750: train loss 1.51375. lr 4.998274e-04:  54%|█████▎    | 8751/16329 [1:13:41<1:02:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8751: train loss 1.50286. lr 4.998059e-04:  54%|█████▎    | 8751/16329 [1:13:41<1:02:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8751: train loss 1.50286. lr 4.998059e-04:  54%|█████▎    | 8752/16329 [1:13:41<1:02:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8752: train loss 1.51419. lr 4.997844e-04:  54%|█████▎    | 8752/16329 [1:13:42<1:02:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8752: train loss 1.51419. lr 4.997844e-04:  54%|█████▎    | 8753/16329 [1:13:42<1:02:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8753: train loss 1.51819. lr 4.997628e-04:  54%|█████▎    | 8753/16329 [1:13:42<1:02:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8753: train loss 1.51819. lr 4.997628e-04:  54%|█████▎    | 8754/16329 [1:13:42<1:02:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8754: train loss 1.48563. lr 4.997413e-04:  54%|█████▎    | 8754/16329 [1:13:43<1:02:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8754: train loss 1.48563. lr 4.997413e-04:  54%|█████▎    | 8755/16329 [1:13:43<1:02:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8755: train loss 1.48887. lr 4.997198e-04:  54%|█████▎    | 8755/16329 [1:13:43<1:02:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8755: train loss 1.48887. lr 4.997198e-04:  54%|█████▎    | 8756/16329 [1:13:43<1:02:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8756: train loss 1.53599. lr 4.996982e-04:  54%|█████▎    | 8756/16329 [1:13:44<1:02:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8756: train loss 1.53599. lr 4.996982e-04:  54%|█████▎    | 8757/16329 [1:13:44<1:02:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8757: train loss 1.53560. lr 4.996767e-04:  54%|█████▎    | 8757/16329 [1:13:44<1:02:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8757: train loss 1.53560. lr 4.996767e-04:  54%|█████▎    | 8758/16329 [1:13:44<1:09:10,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8758: train loss 1.53764. lr 4.996552e-04:  54%|█████▎    | 8758/16329 [1:13:45<1:09:10,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8758: train loss 1.53764. lr 4.996552e-04:  54%|█████▎    | 8759/16329 [1:13:45<1:07:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8759: train loss 1.48739. lr 4.996336e-04:  54%|█████▎    | 8759/16329 [1:13:45<1:07:04,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8759: train loss 1.48739. lr 4.996336e-04:  54%|█████▎    | 8760/16329 [1:13:45<1:07:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8760: train loss 1.48760. lr 4.996121e-04:  54%|█████▎    | 8760/16329 [1:13:46<1:07:16,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8760: train loss 1.48760. lr 4.996121e-04:  54%|█████▎    | 8761/16329 [1:13:46<1:07:29,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8761: train loss 1.49817. lr 4.995905e-04:  54%|█████▎    | 8761/16329 [1:13:46<1:07:29,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8761: train loss 1.49817. lr 4.995905e-04:  54%|█████▎    | 8762/16329 [1:13:46<1:07:12,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8762: train loss 1.49553. lr 4.995690e-04:  54%|█████▎    | 8762/16329 [1:13:47<1:07:12,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8762: train loss 1.49553. lr 4.995690e-04:  54%|█████▎    | 8763/16329 [1:13:47<1:06:35,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8763: train loss 1.49632. lr 4.995474e-04:  54%|█████▎    | 8763/16329 [1:13:47<1:06:35,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8763: train loss 1.49632. lr 4.995474e-04:  54%|█████▎    | 8764/16329 [1:13:47<1:06:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8764: train loss 1.49403. lr 4.995259e-04:  54%|█████▎    | 8764/16329 [1:13:48<1:06:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8764: train loss 1.49403. lr 4.995259e-04:  54%|█████▎    | 8765/16329 [1:13:48<1:05:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8765: train loss 1.48594. lr 4.995043e-04:  54%|█████▎    | 8765/16329 [1:13:48<1:05:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8765: train loss 1.48594. lr 4.995043e-04:  54%|█████▎    | 8766/16329 [1:13:48<1:04:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8766: train loss 1.49110. lr 4.994828e-04:  54%|█████▎    | 8766/16329 [1:13:49<1:04:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8766: train loss 1.49110. lr 4.994828e-04:  54%|█████▎    | 8767/16329 [1:13:49<1:04:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8767: train loss 1.49824. lr 4.994612e-04:  54%|█████▎    | 8767/16329 [1:13:49<1:04:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8767: train loss 1.49824. lr 4.994612e-04:  54%|█████▎    | 8768/16329 [1:13:49<1:03:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8768: train loss 1.51623. lr 4.994397e-04:  54%|█████▎    | 8768/16329 [1:13:50<1:03:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8768: train loss 1.51623. lr 4.994397e-04:  54%|█████▎    | 8769/16329 [1:13:50<1:02:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8769: train loss 1.51803. lr 4.994181e-04:  54%|█████▎    | 8769/16329 [1:13:50<1:02:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8769: train loss 1.51803. lr 4.994181e-04:  54%|█████▎    | 8770/16329 [1:13:50<1:02:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8770: train loss 1.50231. lr 4.993965e-04:  54%|█████▎    | 8770/16329 [1:13:51<1:02:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8770: train loss 1.50231. lr 4.993965e-04:  54%|█████▎    | 8771/16329 [1:13:51<1:02:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8771: train loss 1.52434. lr 4.993750e-04:  54%|█████▎    | 8771/16329 [1:13:51<1:02:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8771: train loss 1.52434. lr 4.993750e-04:  54%|█████▎    | 8772/16329 [1:13:51<1:02:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8772: train loss 1.49906. lr 4.993534e-04:  54%|█████▎    | 8772/16329 [1:13:52<1:02:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8772: train loss 1.49906. lr 4.993534e-04:  54%|█████▎    | 8773/16329 [1:13:52<1:02:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8773: train loss 1.53191. lr 4.993318e-04:  54%|█████▎    | 8773/16329 [1:13:52<1:02:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8773: train loss 1.53191. lr 4.993318e-04:  54%|█████▎    | 8774/16329 [1:13:52<1:02:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8774: train loss 1.50063. lr 4.993103e-04:  54%|█████▎    | 8774/16329 [1:13:53<1:02:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8774: train loss 1.50063. lr 4.993103e-04:  54%|█████▎    | 8775/16329 [1:13:53<1:02:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8775: train loss 1.45720. lr 4.992887e-04:  54%|█████▎    | 8775/16329 [1:13:53<1:02:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8775: train loss 1.45720. lr 4.992887e-04:  54%|█████▎    | 8776/16329 [1:13:53<1:02:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8776: train loss 1.54050. lr 4.992671e-04:  54%|█████▎    | 8776/16329 [1:13:54<1:02:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8776: train loss 1.54050. lr 4.992671e-04:  54%|█████▍    | 8777/16329 [1:13:54<1:02:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8777: train loss 1.51831. lr 4.992456e-04:  54%|█████▍    | 8777/16329 [1:13:54<1:02:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8777: train loss 1.51831. lr 4.992456e-04:  54%|█████▍    | 8778/16329 [1:13:54<1:02:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8778: train loss 1.49716. lr 4.992240e-04:  54%|█████▍    | 8778/16329 [1:13:55<1:02:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8778: train loss 1.49716. lr 4.992240e-04:  54%|█████▍    | 8779/16329 [1:13:55<1:02:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8779: train loss 1.47689. lr 4.992024e-04:  54%|█████▍    | 8779/16329 [1:13:55<1:02:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8779: train loss 1.47689. lr 4.992024e-04:  54%|█████▍    | 8780/16329 [1:13:55<1:02:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8780: train loss 1.47528. lr 4.991808e-04:  54%|█████▍    | 8780/16329 [1:13:56<1:02:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8780: train loss 1.47528. lr 4.991808e-04:  54%|█████▍    | 8781/16329 [1:13:56<1:02:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8781: train loss 1.49403. lr 4.991592e-04:  54%|█████▍    | 8781/16329 [1:13:56<1:02:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8781: train loss 1.49403. lr 4.991592e-04:  54%|█████▍    | 8782/16329 [1:13:56<1:02:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8782: train loss 1.46140. lr 4.991376e-04:  54%|█████▍    | 8782/16329 [1:13:57<1:02:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8782: train loss 1.46140. lr 4.991376e-04:  54%|█████▍    | 8783/16329 [1:13:57<1:02:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8783: train loss 1.48727. lr 4.991161e-04:  54%|█████▍    | 8783/16329 [1:13:57<1:02:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8783: train loss 1.48727. lr 4.991161e-04:  54%|█████▍    | 8784/16329 [1:13:57<1:02:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8784: train loss 1.55891. lr 4.990945e-04:  54%|█████▍    | 8784/16329 [1:13:58<1:02:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8784: train loss 1.55891. lr 4.990945e-04:  54%|█████▍    | 8785/16329 [1:13:58<1:02:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8785: train loss 1.46172. lr 4.990729e-04:  54%|█████▍    | 8785/16329 [1:13:58<1:02:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8785: train loss 1.46172. lr 4.990729e-04:  54%|█████▍    | 8786/16329 [1:13:58<1:02:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8786: train loss 1.47813. lr 4.990513e-04:  54%|█████▍    | 8786/16329 [1:13:59<1:02:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8786: train loss 1.47813. lr 4.990513e-04:  54%|█████▍    | 8787/16329 [1:13:59<1:02:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8787: train loss 1.45825. lr 4.990297e-04:  54%|█████▍    | 8787/16329 [1:13:59<1:02:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8787: train loss 1.45825. lr 4.990297e-04:  54%|█████▍    | 8788/16329 [1:13:59<1:02:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8788: train loss 1.50778. lr 4.990081e-04:  54%|█████▍    | 8788/16329 [1:14:00<1:02:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8788: train loss 1.50778. lr 4.990081e-04:  54%|█████▍    | 8789/16329 [1:14:00<1:03:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8789: train loss 1.55010. lr 4.989865e-04:  54%|█████▍    | 8789/16329 [1:14:00<1:03:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8789: train loss 1.55010. lr 4.989865e-04:  54%|█████▍    | 8790/16329 [1:14:00<1:04:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8790: train loss 1.53685. lr 4.989649e-04:  54%|█████▍    | 8790/16329 [1:14:01<1:04:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8790: train loss 1.53685. lr 4.989649e-04:  54%|█████▍    | 8791/16329 [1:14:01<1:05:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8791: train loss 1.47746. lr 4.989433e-04:  54%|█████▍    | 8791/16329 [1:14:01<1:05:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8791: train loss 1.47746. lr 4.989433e-04:  54%|█████▍    | 8792/16329 [1:14:01<1:05:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8792: train loss 1.53540. lr 4.989217e-04:  54%|█████▍    | 8792/16329 [1:14:02<1:05:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8792: train loss 1.53540. lr 4.989217e-04:  54%|█████▍    | 8793/16329 [1:14:02<1:04:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8793: train loss 1.48162. lr 4.989001e-04:  54%|█████▍    | 8793/16329 [1:14:02<1:04:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8793: train loss 1.48162. lr 4.989001e-04:  54%|█████▍    | 8794/16329 [1:14:02<1:04:30,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8794: train loss 1.48775. lr 4.988785e-04:  54%|█████▍    | 8794/16329 [1:14:03<1:04:30,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8794: train loss 1.48775. lr 4.988785e-04:  54%|█████▍    | 8795/16329 [1:14:03<1:03:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8795: train loss 1.49365. lr 4.988569e-04:  54%|█████▍    | 8795/16329 [1:14:03<1:03:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8795: train loss 1.49365. lr 4.988569e-04:  54%|█████▍    | 8796/16329 [1:14:03<1:03:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8796: train loss 1.49165. lr 4.988353e-04:  54%|█████▍    | 8796/16329 [1:14:04<1:03:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8796: train loss 1.49165. lr 4.988353e-04:  54%|█████▍    | 8797/16329 [1:14:04<1:02:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8797: train loss 1.48593. lr 4.988137e-04:  54%|█████▍    | 8797/16329 [1:14:05<1:02:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8797: train loss 1.48593. lr 4.988137e-04:  54%|█████▍    | 8798/16329 [1:14:05<1:11:47,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 8798: train loss 1.52073. lr 4.987921e-04:  54%|█████▍    | 8798/16329 [1:14:05<1:11:47,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 8798: train loss 1.52073. lr 4.987921e-04:  54%|█████▍    | 8799/16329 [1:14:05<1:08:55,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8799: train loss 1.51838. lr 4.987704e-04:  54%|█████▍    | 8799/16329 [1:14:06<1:08:55,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8799: train loss 1.51838. lr 4.987704e-04:  54%|█████▍    | 8800/16329 [1:14:06<1:06:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8800: train loss 1.50614. lr 4.987488e-04:  54%|█████▍    | 8800/16329 [1:14:06<1:06:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8800: train loss 1.50614. lr 4.987488e-04:  54%|█████▍    | 8801/16329 [1:14:06<1:05:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8801: train loss 1.52248. lr 4.987272e-04:  54%|█████▍    | 8801/16329 [1:14:07<1:05:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8801: train loss 1.52248. lr 4.987272e-04:  54%|█████▍    | 8802/16329 [1:14:07<1:04:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8802: train loss 1.53294. lr 4.987056e-04:  54%|█████▍    | 8802/16329 [1:14:07<1:04:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8802: train loss 1.53294. lr 4.987056e-04:  54%|█████▍    | 8803/16329 [1:14:07<1:03:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8803: train loss 1.50076. lr 4.986840e-04:  54%|█████▍    | 8803/16329 [1:14:08<1:03:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8803: train loss 1.50076. lr 4.986840e-04:  54%|█████▍    | 8804/16329 [1:14:08<1:03:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8804: train loss 1.50155. lr 4.986623e-04:  54%|█████▍    | 8804/16329 [1:14:08<1:03:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8804: train loss 1.50155. lr 4.986623e-04:  54%|█████▍    | 8805/16329 [1:14:08<1:02:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8805: train loss 1.50012. lr 4.986407e-04:  54%|█████▍    | 8805/16329 [1:14:09<1:02:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8805: train loss 1.50012. lr 4.986407e-04:  54%|█████▍    | 8806/16329 [1:14:09<1:02:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8806: train loss 1.52921. lr 4.986191e-04:  54%|█████▍    | 8806/16329 [1:14:09<1:02:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8806: train loss 1.52921. lr 4.986191e-04:  54%|█████▍    | 8807/16329 [1:14:09<1:02:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8807: train loss 1.53599. lr 4.985974e-04:  54%|█████▍    | 8807/16329 [1:14:10<1:02:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8807: train loss 1.53599. lr 4.985974e-04:  54%|█████▍    | 8808/16329 [1:14:10<1:02:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8808: train loss 1.51282. lr 4.985758e-04:  54%|█████▍    | 8808/16329 [1:14:10<1:02:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8808: train loss 1.51282. lr 4.985758e-04:  54%|█████▍    | 8809/16329 [1:14:10<1:02:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8809: train loss 1.51301. lr 4.985542e-04:  54%|█████▍    | 8809/16329 [1:14:11<1:02:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8809: train loss 1.51301. lr 4.985542e-04:  54%|█████▍    | 8810/16329 [1:14:11<1:02:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8810: train loss 1.53524. lr 4.985325e-04:  54%|█████▍    | 8810/16329 [1:14:11<1:02:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8810: train loss 1.53524. lr 4.985325e-04:  54%|█████▍    | 8811/16329 [1:14:11<1:02:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8811: train loss 1.46464. lr 4.985109e-04:  54%|█████▍    | 8811/16329 [1:14:12<1:02:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8811: train loss 1.46464. lr 4.985109e-04:  54%|█████▍    | 8812/16329 [1:14:12<1:02:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8812: train loss 1.53570. lr 4.984893e-04:  54%|█████▍    | 8812/16329 [1:14:12<1:02:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8812: train loss 1.53570. lr 4.984893e-04:  54%|█████▍    | 8813/16329 [1:14:12<1:02:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8813: train loss 1.44316. lr 4.984676e-04:  54%|█████▍    | 8813/16329 [1:14:13<1:02:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8813: train loss 1.44316. lr 4.984676e-04:  54%|█████▍    | 8814/16329 [1:14:13<1:02:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8814: train loss 1.52786. lr 4.984460e-04:  54%|█████▍    | 8814/16329 [1:14:13<1:02:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8814: train loss 1.52786. lr 4.984460e-04:  54%|█████▍    | 8815/16329 [1:14:13<1:02:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8815: train loss 1.47736. lr 4.984243e-04:  54%|█████▍    | 8815/16329 [1:14:14<1:02:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8815: train loss 1.47736. lr 4.984243e-04:  54%|█████▍    | 8816/16329 [1:14:14<1:02:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8816: train loss 1.51390. lr 4.984027e-04:  54%|█████▍    | 8816/16329 [1:14:14<1:02:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8816: train loss 1.51390. lr 4.984027e-04:  54%|█████▍    | 8817/16329 [1:14:14<1:03:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8817: train loss 1.50425. lr 4.983810e-04:  54%|█████▍    | 8817/16329 [1:14:15<1:03:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8817: train loss 1.50425. lr 4.983810e-04:  54%|█████▍    | 8818/16329 [1:14:15<1:02:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8818: train loss 1.53900. lr 4.983594e-04:  54%|█████▍    | 8818/16329 [1:14:15<1:02:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8818: train loss 1.53900. lr 4.983594e-04:  54%|█████▍    | 8819/16329 [1:14:15<1:02:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8819: train loss 1.52389. lr 4.983377e-04:  54%|█████▍    | 8819/16329 [1:14:16<1:02:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8819: train loss 1.52389. lr 4.983377e-04:  54%|█████▍    | 8820/16329 [1:14:16<1:02:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8820: train loss 1.49903. lr 4.983161e-04:  54%|█████▍    | 8820/16329 [1:14:16<1:02:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8820: train loss 1.49903. lr 4.983161e-04:  54%|█████▍    | 8821/16329 [1:14:16<1:02:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8821: train loss 1.49966. lr 4.982944e-04:  54%|█████▍    | 8821/16329 [1:14:17<1:02:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8821: train loss 1.49966. lr 4.982944e-04:  54%|█████▍    | 8822/16329 [1:14:17<1:03:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8822: train loss 1.51716. lr 4.982728e-04:  54%|█████▍    | 8822/16329 [1:14:17<1:03:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8822: train loss 1.51716. lr 4.982728e-04:  54%|█████▍    | 8823/16329 [1:14:17<1:03:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8823: train loss 1.49668. lr 4.982511e-04:  54%|█████▍    | 8823/16329 [1:14:18<1:03:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8823: train loss 1.49668. lr 4.982511e-04:  54%|█████▍    | 8824/16329 [1:14:18<1:04:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8824: train loss 1.57563. lr 4.982295e-04:  54%|█████▍    | 8824/16329 [1:14:18<1:04:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8824: train loss 1.57563. lr 4.982295e-04:  54%|█████▍    | 8825/16329 [1:14:18<1:04:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8825: train loss 1.52051. lr 4.982078e-04:  54%|█████▍    | 8825/16329 [1:14:19<1:04:14,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8825: train loss 1.52051. lr 4.982078e-04:  54%|█████▍    | 8826/16329 [1:14:19<1:04:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8826: train loss 1.51001. lr 4.981861e-04:  54%|█████▍    | 8826/16329 [1:14:19<1:04:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8826: train loss 1.51001. lr 4.981861e-04:  54%|█████▍    | 8827/16329 [1:14:19<1:03:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8827: train loss 1.51216. lr 4.981645e-04:  54%|█████▍    | 8827/16329 [1:14:20<1:03:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8827: train loss 1.51216. lr 4.981645e-04:  54%|█████▍    | 8828/16329 [1:14:20<1:03:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8828: train loss 1.50137. lr 4.981428e-04:  54%|█████▍    | 8828/16329 [1:14:20<1:03:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8828: train loss 1.50137. lr 4.981428e-04:  54%|█████▍    | 8829/16329 [1:14:20<1:03:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8829: train loss 1.51595. lr 4.981211e-04:  54%|█████▍    | 8829/16329 [1:14:21<1:03:11,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8829: train loss 1.51595. lr 4.981211e-04:  54%|█████▍    | 8830/16329 [1:14:21<1:03:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8830: train loss 1.51258. lr 4.980994e-04:  54%|█████▍    | 8830/16329 [1:14:21<1:03:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8830: train loss 1.51258. lr 4.980994e-04:  54%|█████▍    | 8831/16329 [1:14:21<1:02:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8831: train loss 1.51121. lr 4.980778e-04:  54%|█████▍    | 8831/16329 [1:14:22<1:02:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8831: train loss 1.51121. lr 4.980778e-04:  54%|█████▍    | 8832/16329 [1:14:22<1:02:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8832: train loss 1.49072. lr 4.980561e-04:  54%|█████▍    | 8832/16329 [1:14:22<1:02:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8832: train loss 1.49072. lr 4.980561e-04:  54%|█████▍    | 8833/16329 [1:14:22<1:08:50,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 8833: train loss 1.55121. lr 4.980344e-04:  54%|█████▍    | 8833/16329 [1:14:23<1:08:50,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 8833: train loss 1.55121. lr 4.980344e-04:  54%|█████▍    | 8834/16329 [1:14:23<1:06:37,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8834: train loss 1.50045. lr 4.980127e-04:  54%|█████▍    | 8834/16329 [1:14:23<1:06:37,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8834: train loss 1.50045. lr 4.980127e-04:  54%|█████▍    | 8835/16329 [1:14:23<1:06:30,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8835: train loss 1.56255. lr 4.979911e-04:  54%|█████▍    | 8835/16329 [1:14:24<1:06:30,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8835: train loss 1.56255. lr 4.979911e-04:  54%|█████▍    | 8836/16329 [1:14:24<1:06:11,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8836: train loss 1.53346. lr 4.979694e-04:  54%|█████▍    | 8836/16329 [1:14:24<1:06:11,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8836: train loss 1.53346. lr 4.979694e-04:  54%|█████▍    | 8837/16329 [1:14:24<1:05:41,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8837: train loss 1.51207. lr 4.979477e-04:  54%|█████▍    | 8837/16329 [1:14:25<1:05:41,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 8837: train loss 1.51207. lr 4.979477e-04:  54%|█████▍    | 8838/16329 [1:14:25<1:05:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8838: train loss 1.46910. lr 4.979260e-04:  54%|█████▍    | 8838/16329 [1:14:25<1:05:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8838: train loss 1.46910. lr 4.979260e-04:  54%|█████▍    | 8839/16329 [1:14:25<1:04:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8839: train loss 1.48658. lr 4.979043e-04:  54%|█████▍    | 8839/16329 [1:14:26<1:04:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8839: train loss 1.48658. lr 4.979043e-04:  54%|█████▍    | 8840/16329 [1:14:26<1:03:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8840: train loss 1.51365. lr 4.978826e-04:  54%|█████▍    | 8840/16329 [1:14:26<1:03:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8840: train loss 1.51365. lr 4.978826e-04:  54%|█████▍    | 8841/16329 [1:14:26<1:03:34,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8841: train loss 1.47973. lr 4.978609e-04:  54%|█████▍    | 8841/16329 [1:14:27<1:03:34,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8841: train loss 1.47973. lr 4.978609e-04:  54%|█████▍    | 8842/16329 [1:14:27<1:03:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8842: train loss 1.51649. lr 4.978392e-04:  54%|█████▍    | 8842/16329 [1:14:27<1:03:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8842: train loss 1.51649. lr 4.978392e-04:  54%|█████▍    | 8843/16329 [1:14:27<1:02:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8843: train loss 1.48390. lr 4.978175e-04:  54%|█████▍    | 8843/16329 [1:14:28<1:02:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8843: train loss 1.48390. lr 4.978175e-04:  54%|█████▍    | 8844/16329 [1:14:28<1:02:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8844: train loss 1.51379. lr 4.977958e-04:  54%|█████▍    | 8844/16329 [1:14:28<1:02:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8844: train loss 1.51379. lr 4.977958e-04:  54%|█████▍    | 8845/16329 [1:14:28<1:02:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8845: train loss 1.55493. lr 4.977741e-04:  54%|█████▍    | 8845/16329 [1:14:29<1:02:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8845: train loss 1.55493. lr 4.977741e-04:  54%|█████▍    | 8846/16329 [1:14:29<1:02:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8846: train loss 1.44623. lr 4.977524e-04:  54%|█████▍    | 8846/16329 [1:14:29<1:02:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8846: train loss 1.44623. lr 4.977524e-04:  54%|█████▍    | 8847/16329 [1:14:29<1:01:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8847: train loss 1.51689. lr 4.977307e-04:  54%|█████▍    | 8847/16329 [1:14:30<1:01:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8847: train loss 1.51689. lr 4.977307e-04:  54%|█████▍    | 8848/16329 [1:14:30<1:01:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8848: train loss 1.49651. lr 4.977090e-04:  54%|█████▍    | 8848/16329 [1:14:30<1:01:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8848: train loss 1.49651. lr 4.977090e-04:  54%|█████▍    | 8849/16329 [1:14:30<1:01:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8849: train loss 1.50508. lr 4.976873e-04:  54%|█████▍    | 8849/16329 [1:14:31<1:01:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8849: train loss 1.50508. lr 4.976873e-04:  54%|█████▍    | 8850/16329 [1:14:31<1:02:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8850: train loss 1.51743. lr 4.976656e-04:  54%|█████▍    | 8850/16329 [1:14:31<1:02:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8850: train loss 1.51743. lr 4.976656e-04:  54%|█████▍    | 8851/16329 [1:14:31<1:02:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8851: train loss 1.52106. lr 4.976439e-04:  54%|█████▍    | 8851/16329 [1:14:32<1:02:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8851: train loss 1.52106. lr 4.976439e-04:  54%|█████▍    | 8852/16329 [1:14:32<1:03:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8852: train loss 1.50349. lr 4.976222e-04:  54%|█████▍    | 8852/16329 [1:14:32<1:03:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8852: train loss 1.50349. lr 4.976222e-04:  54%|█████▍    | 8853/16329 [1:14:32<1:03:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8853: train loss 1.52753. lr 4.976005e-04:  54%|█████▍    | 8853/16329 [1:14:33<1:03:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8853: train loss 1.52753. lr 4.976005e-04:  54%|█████▍    | 8854/16329 [1:14:33<1:03:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8854: train loss 1.50549. lr 4.975788e-04:  54%|█████▍    | 8854/16329 [1:14:33<1:03:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8854: train loss 1.50549. lr 4.975788e-04:  54%|█████▍    | 8855/16329 [1:14:33<1:03:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8855: train loss 1.55185. lr 4.975570e-04:  54%|█████▍    | 8855/16329 [1:14:34<1:03:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8855: train loss 1.55185. lr 4.975570e-04:  54%|█████▍    | 8856/16329 [1:14:34<1:03:01,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8856: train loss 1.49172. lr 4.975353e-04:  54%|█████▍    | 8856/16329 [1:14:34<1:03:01,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8856: train loss 1.49172. lr 4.975353e-04:  54%|█████▍    | 8857/16329 [1:14:34<1:02:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8857: train loss 1.54605. lr 4.975136e-04:  54%|█████▍    | 8857/16329 [1:14:35<1:02:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8857: train loss 1.54605. lr 4.975136e-04:  54%|█████▍    | 8858/16329 [1:14:35<1:08:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 8858: train loss 1.49700. lr 4.974919e-04:  54%|█████▍    | 8858/16329 [1:14:36<1:08:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 8858: train loss 1.49700. lr 4.974919e-04:  54%|█████▍    | 8859/16329 [1:14:36<1:07:00,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8859: train loss 1.49955. lr 4.974701e-04:  54%|█████▍    | 8859/16329 [1:14:36<1:07:00,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8859: train loss 1.49955. lr 4.974701e-04:  54%|█████▍    | 8860/16329 [1:14:36<1:05:07,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8860: train loss 1.49095. lr 4.974484e-04:  54%|█████▍    | 8860/16329 [1:14:37<1:05:07,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8860: train loss 1.49095. lr 4.974484e-04:  54%|█████▍    | 8861/16329 [1:14:37<1:04:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8861: train loss 1.51538. lr 4.974267e-04:  54%|█████▍    | 8861/16329 [1:14:37<1:04:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8861: train loss 1.51538. lr 4.974267e-04:  54%|█████▍    | 8862/16329 [1:14:37<1:03:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8862: train loss 1.48496. lr 4.974050e-04:  54%|█████▍    | 8862/16329 [1:14:38<1:03:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8862: train loss 1.48496. lr 4.974050e-04:  54%|█████▍    | 8863/16329 [1:14:38<1:02:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8863: train loss 1.51396. lr 4.973832e-04:  54%|█████▍    | 8863/16329 [1:14:38<1:02:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8863: train loss 1.51396. lr 4.973832e-04:  54%|█████▍    | 8864/16329 [1:14:38<1:02:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8864: train loss 1.48325. lr 4.973615e-04:  54%|█████▍    | 8864/16329 [1:14:39<1:02:21,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8864: train loss 1.48325. lr 4.973615e-04:  54%|█████▍    | 8865/16329 [1:14:39<1:01:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8865: train loss 1.51161. lr 4.973398e-04:  54%|█████▍    | 8865/16329 [1:14:39<1:01:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8865: train loss 1.51161. lr 4.973398e-04:  54%|█████▍    | 8866/16329 [1:14:39<1:01:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8866: train loss 1.49295. lr 4.973180e-04:  54%|█████▍    | 8866/16329 [1:14:40<1:01:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8866: train loss 1.49295. lr 4.973180e-04:  54%|█████▍    | 8867/16329 [1:14:40<1:01:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8867: train loss 1.52313. lr 4.972963e-04:  54%|█████▍    | 8867/16329 [1:14:40<1:01:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8867: train loss 1.52313. lr 4.972963e-04:  54%|█████▍    | 8868/16329 [1:14:40<1:01:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8868: train loss 1.49608. lr 4.972745e-04:  54%|█████▍    | 8868/16329 [1:14:41<1:01:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8868: train loss 1.49608. lr 4.972745e-04:  54%|█████▍    | 8869/16329 [1:14:41<1:01:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8869: train loss 1.50678. lr 4.972528e-04:  54%|█████▍    | 8869/16329 [1:14:41<1:01:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8869: train loss 1.50678. lr 4.972528e-04:  54%|█████▍    | 8870/16329 [1:14:41<1:01:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8870: train loss 1.49529. lr 4.972310e-04:  54%|█████▍    | 8870/16329 [1:14:42<1:01:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8870: train loss 1.49529. lr 4.972310e-04:  54%|█████▍    | 8871/16329 [1:14:42<1:03:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8871: train loss 1.51327. lr 4.972093e-04:  54%|█████▍    | 8871/16329 [1:14:42<1:03:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8871: train loss 1.51327. lr 4.972093e-04:  54%|█████▍    | 8872/16329 [1:14:42<1:04:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8872: train loss 1.46027. lr 4.971875e-04:  54%|█████▍    | 8872/16329 [1:14:43<1:04:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8872: train loss 1.46027. lr 4.971875e-04:  54%|█████▍    | 8873/16329 [1:14:43<1:04:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8873: train loss 1.44984. lr 4.971658e-04:  54%|█████▍    | 8873/16329 [1:14:43<1:04:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8873: train loss 1.44984. lr 4.971658e-04:  54%|█████▍    | 8874/16329 [1:14:43<1:04:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8874: train loss 1.50018. lr 4.971440e-04:  54%|█████▍    | 8874/16329 [1:14:44<1:04:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8874: train loss 1.50018. lr 4.971440e-04:  54%|█████▍    | 8875/16329 [1:14:44<1:04:24,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8875: train loss 1.48852. lr 4.971223e-04:  54%|█████▍    | 8875/16329 [1:14:44<1:04:24,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8875: train loss 1.48852. lr 4.971223e-04:  54%|█████▍    | 8876/16329 [1:14:44<1:04:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8876: train loss 1.49692. lr 4.971005e-04:  54%|█████▍    | 8876/16329 [1:14:45<1:04:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8876: train loss 1.49692. lr 4.971005e-04:  54%|█████▍    | 8877/16329 [1:14:45<1:03:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8877: train loss 1.45905. lr 4.970788e-04:  54%|█████▍    | 8877/16329 [1:14:45<1:03:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8877: train loss 1.45905. lr 4.970788e-04:  54%|█████▍    | 8878/16329 [1:14:45<1:03:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8878: train loss 1.48507. lr 4.970570e-04:  54%|█████▍    | 8878/16329 [1:14:46<1:03:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8878: train loss 1.48507. lr 4.970570e-04:  54%|█████▍    | 8879/16329 [1:14:46<1:02:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8879: train loss 1.46504. lr 4.970353e-04:  54%|█████▍    | 8879/16329 [1:14:46<1:02:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8879: train loss 1.46504. lr 4.970353e-04:  54%|█████▍    | 8880/16329 [1:14:46<1:02:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8880: train loss 1.52130. lr 4.970135e-04:  54%|█████▍    | 8880/16329 [1:14:47<1:02:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8880: train loss 1.52130. lr 4.970135e-04:  54%|█████▍    | 8881/16329 [1:14:47<1:01:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8881: train loss 1.50151. lr 4.969917e-04:  54%|█████▍    | 8881/16329 [1:14:47<1:01:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8881: train loss 1.50151. lr 4.969917e-04:  54%|█████▍    | 8882/16329 [1:14:47<1:01:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8882: train loss 1.51281. lr 4.969700e-04:  54%|█████▍    | 8882/16329 [1:14:48<1:01:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8882: train loss 1.51281. lr 4.969700e-04:  54%|█████▍    | 8883/16329 [1:14:48<1:01:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8883: train loss 1.47078. lr 4.969482e-04:  54%|█████▍    | 8883/16329 [1:14:48<1:01:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8883: train loss 1.47078. lr 4.969482e-04:  54%|█████▍    | 8884/16329 [1:14:48<1:01:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8884: train loss 1.48427. lr 4.969264e-04:  54%|█████▍    | 8884/16329 [1:14:49<1:01:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8884: train loss 1.48427. lr 4.969264e-04:  54%|█████▍    | 8885/16329 [1:14:49<1:07:50,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8885: train loss 1.52194. lr 4.969046e-04:  54%|█████▍    | 8885/16329 [1:14:49<1:07:50,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 8885: train loss 1.52194. lr 4.969046e-04:  54%|█████▍    | 8886/16329 [1:14:49<1:05:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8886: train loss 1.51789. lr 4.968829e-04:  54%|█████▍    | 8886/16329 [1:14:50<1:05:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 8886: train loss 1.51789. lr 4.968829e-04:  54%|█████▍    | 8887/16329 [1:14:50<1:04:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8887: train loss 1.47905. lr 4.968611e-04:  54%|█████▍    | 8887/16329 [1:14:50<1:04:35,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8887: train loss 1.47905. lr 4.968611e-04:  54%|█████▍    | 8888/16329 [1:14:50<1:03:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8888: train loss 1.49632. lr 4.968393e-04:  54%|█████▍    | 8888/16329 [1:14:51<1:03:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8888: train loss 1.49632. lr 4.968393e-04:  54%|█████▍    | 8889/16329 [1:14:51<1:02:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8889: train loss 1.48593. lr 4.968175e-04:  54%|█████▍    | 8889/16329 [1:14:51<1:02:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8889: train loss 1.48593. lr 4.968175e-04:  54%|█████▍    | 8890/16329 [1:14:51<1:02:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8890: train loss 1.48989. lr 4.967957e-04:  54%|█████▍    | 8890/16329 [1:14:52<1:02:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8890: train loss 1.48989. lr 4.967957e-04:  54%|█████▍    | 8891/16329 [1:14:52<1:02:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8891: train loss 1.50188. lr 4.967740e-04:  54%|█████▍    | 8891/16329 [1:14:52<1:02:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8891: train loss 1.50188. lr 4.967740e-04:  54%|█████▍    | 8892/16329 [1:14:52<1:01:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8892: train loss 1.53547. lr 4.967522e-04:  54%|█████▍    | 8892/16329 [1:14:53<1:01:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8892: train loss 1.53547. lr 4.967522e-04:  54%|█████▍    | 8893/16329 [1:14:53<1:01:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8893: train loss 1.47736. lr 4.967304e-04:  54%|█████▍    | 8893/16329 [1:14:53<1:01:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8893: train loss 1.47736. lr 4.967304e-04:  54%|█████▍    | 8894/16329 [1:14:53<1:01:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8894: train loss 1.48428. lr 4.967086e-04:  54%|█████▍    | 8894/16329 [1:14:54<1:01:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8894: train loss 1.48428. lr 4.967086e-04:  54%|█████▍    | 8895/16329 [1:14:54<1:01:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8895: train loss 1.51573. lr 4.966868e-04:  54%|█████▍    | 8895/16329 [1:14:54<1:01:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8895: train loss 1.51573. lr 4.966868e-04:  54%|█████▍    | 8896/16329 [1:14:54<1:01:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8896: train loss 1.49241. lr 4.966650e-04:  54%|█████▍    | 8896/16329 [1:14:55<1:01:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8896: train loss 1.49241. lr 4.966650e-04:  54%|█████▍    | 8897/16329 [1:14:55<1:01:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8897: train loss 1.46739. lr 4.966432e-04:  54%|█████▍    | 8897/16329 [1:14:55<1:01:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8897: train loss 1.46739. lr 4.966432e-04:  54%|█████▍    | 8898/16329 [1:14:55<1:01:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8898: train loss 1.45151. lr 4.966214e-04:  54%|█████▍    | 8898/16329 [1:14:56<1:01:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8898: train loss 1.45151. lr 4.966214e-04:  54%|█████▍    | 8899/16329 [1:14:56<1:01:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8899: train loss 1.43728. lr 4.965996e-04:  54%|█████▍    | 8899/16329 [1:14:56<1:01:23,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8899: train loss 1.43728. lr 4.965996e-04:  55%|█████▍    | 8900/16329 [1:14:56<1:01:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8900: train loss 1.51569. lr 4.965778e-04:  55%|█████▍    | 8900/16329 [1:14:57<1:01:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8900: train loss 1.51569. lr 4.965778e-04:  55%|█████▍    | 8901/16329 [1:14:57<1:01:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8901: train loss 1.45017. lr 4.965560e-04:  55%|█████▍    | 8901/16329 [1:14:57<1:01:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8901: train loss 1.45017. lr 4.965560e-04:  55%|█████▍    | 8902/16329 [1:14:57<1:01:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8902: train loss 1.50329. lr 4.965342e-04:  55%|█████▍    | 8902/16329 [1:14:58<1:01:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8902: train loss 1.50329. lr 4.965342e-04:  55%|█████▍    | 8903/16329 [1:14:58<1:01:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8903: train loss 1.51445. lr 4.965124e-04:  55%|█████▍    | 8903/16329 [1:14:58<1:01:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8903: train loss 1.51445. lr 4.965124e-04:  55%|█████▍    | 8904/16329 [1:14:58<1:01:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8904: train loss 1.48367. lr 4.964906e-04:  55%|█████▍    | 8904/16329 [1:14:59<1:01:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8904: train loss 1.48367. lr 4.964906e-04:  55%|█████▍    | 8905/16329 [1:14:59<1:03:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8905: train loss 1.48135. lr 4.964688e-04:  55%|█████▍    | 8905/16329 [1:14:59<1:03:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8905: train loss 1.48135. lr 4.964688e-04:  55%|█████▍    | 8906/16329 [1:14:59<1:04:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8906: train loss 1.45459. lr 4.964470e-04:  55%|█████▍    | 8906/16329 [1:15:00<1:04:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8906: train loss 1.45459. lr 4.964470e-04:  55%|█████▍    | 8907/16329 [1:15:00<1:04:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8907: train loss 1.48387. lr 4.964252e-04:  55%|█████▍    | 8907/16329 [1:15:00<1:04:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8907: train loss 1.48387. lr 4.964252e-04:  55%|█████▍    | 8908/16329 [1:15:00<1:04:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8908: train loss 1.48969. lr 4.964034e-04:  55%|█████▍    | 8908/16329 [1:15:01<1:04:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8908: train loss 1.48969. lr 4.964034e-04:  55%|█████▍    | 8909/16329 [1:15:01<1:03:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8909: train loss 1.48436. lr 4.963815e-04:  55%|█████▍    | 8909/16329 [1:15:01<1:03:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8909: train loss 1.48436. lr 4.963815e-04:  55%|█████▍    | 8910/16329 [1:15:01<1:03:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8910: train loss 1.45696. lr 4.963597e-04:  55%|█████▍    | 8910/16329 [1:15:02<1:03:21,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8910: train loss 1.45696. lr 4.963597e-04:  55%|█████▍    | 8911/16329 [1:15:02<1:02:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8911: train loss 1.51150. lr 4.963379e-04:  55%|█████▍    | 8911/16329 [1:15:02<1:02:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8911: train loss 1.51150. lr 4.963379e-04:  55%|█████▍    | 8912/16329 [1:15:02<1:02:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8912: train loss 1.50437. lr 4.963161e-04:  55%|█████▍    | 8912/16329 [1:15:03<1:02:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8912: train loss 1.50437. lr 4.963161e-04:  55%|█████▍    | 8913/16329 [1:15:03<1:01:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8913: train loss 1.47020. lr 4.962943e-04:  55%|█████▍    | 8913/16329 [1:15:03<1:01:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8913: train loss 1.47020. lr 4.962943e-04:  55%|█████▍    | 8914/16329 [1:15:03<1:01:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8914: train loss 1.51521. lr 4.962724e-04:  55%|█████▍    | 8914/16329 [1:15:04<1:01:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8914: train loss 1.51521. lr 4.962724e-04:  55%|█████▍    | 8915/16329 [1:15:04<1:01:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8915: train loss 1.55691. lr 4.962506e-04:  55%|█████▍    | 8915/16329 [1:15:04<1:01:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8915: train loss 1.55691. lr 4.962506e-04:  55%|█████▍    | 8916/16329 [1:15:04<1:01:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8916: train loss 1.49962. lr 4.962288e-04:  55%|█████▍    | 8916/16329 [1:15:05<1:01:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8916: train loss 1.49962. lr 4.962288e-04:  55%|█████▍    | 8917/16329 [1:15:05<1:01:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8917: train loss 1.50368. lr 4.962069e-04:  55%|█████▍    | 8917/16329 [1:15:05<1:01:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8917: train loss 1.50368. lr 4.962069e-04:  55%|█████▍    | 8918/16329 [1:15:05<1:01:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8918: train loss 1.50879. lr 4.961851e-04:  55%|█████▍    | 8918/16329 [1:15:06<1:01:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8918: train loss 1.50879. lr 4.961851e-04:  55%|█████▍    | 8919/16329 [1:15:06<1:01:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8919: train loss 1.57246. lr 4.961633e-04:  55%|█████▍    | 8919/16329 [1:15:06<1:01:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8919: train loss 1.57246. lr 4.961633e-04:  55%|█████▍    | 8920/16329 [1:15:06<1:01:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8920: train loss 1.48826. lr 4.961414e-04:  55%|█████▍    | 8920/16329 [1:15:07<1:01:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8920: train loss 1.48826. lr 4.961414e-04:  55%|█████▍    | 8921/16329 [1:15:07<1:01:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8921: train loss 1.49624. lr 4.961196e-04:  55%|█████▍    | 8921/16329 [1:15:07<1:01:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8921: train loss 1.49624. lr 4.961196e-04:  55%|█████▍    | 8922/16329 [1:15:07<1:01:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8922: train loss 1.50309. lr 4.960978e-04:  55%|█████▍    | 8922/16329 [1:15:08<1:01:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8922: train loss 1.50309. lr 4.960978e-04:  55%|█████▍    | 8923/16329 [1:15:08<1:01:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8923: train loss 1.51505. lr 4.960759e-04:  55%|█████▍    | 8923/16329 [1:15:08<1:01:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8923: train loss 1.51505. lr 4.960759e-04:  55%|█████▍    | 8924/16329 [1:15:08<1:01:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8924: train loss 1.50731. lr 4.960541e-04:  55%|█████▍    | 8924/16329 [1:15:09<1:01:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8924: train loss 1.50731. lr 4.960541e-04:  55%|█████▍    | 8925/16329 [1:15:09<1:07:43,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8925: train loss 1.45961. lr 4.960322e-04:  55%|█████▍    | 8925/16329 [1:15:10<1:07:43,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8925: train loss 1.45961. lr 4.960322e-04:  55%|█████▍    | 8926/16329 [1:15:10<1:05:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8926: train loss 1.50204. lr 4.960104e-04:  55%|█████▍    | 8926/16329 [1:15:10<1:05:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 8926: train loss 1.50204. lr 4.960104e-04:  55%|█████▍    | 8927/16329 [1:15:10<1:04:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8927: train loss 1.52858. lr 4.959885e-04:  55%|█████▍    | 8927/16329 [1:15:10<1:04:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8927: train loss 1.52858. lr 4.959885e-04:  55%|█████▍    | 8928/16329 [1:15:11<1:03:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8928: train loss 1.47768. lr 4.959667e-04:  55%|█████▍    | 8928/16329 [1:15:11<1:03:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8928: train loss 1.47768. lr 4.959667e-04:  55%|█████▍    | 8929/16329 [1:15:11<1:02:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8929: train loss 1.49792. lr 4.959448e-04:  55%|█████▍    | 8929/16329 [1:15:11<1:02:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8929: train loss 1.49792. lr 4.959448e-04:  55%|█████▍    | 8930/16329 [1:15:11<1:02:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8930: train loss 1.51628. lr 4.959230e-04:  55%|█████▍    | 8930/16329 [1:15:12<1:02:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8930: train loss 1.51628. lr 4.959230e-04:  55%|█████▍    | 8931/16329 [1:15:12<1:01:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8931: train loss 1.54175. lr 4.959011e-04:  55%|█████▍    | 8931/16329 [1:15:12<1:01:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8931: train loss 1.54175. lr 4.959011e-04:  55%|█████▍    | 8932/16329 [1:15:12<1:01:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8932: train loss 1.49379. lr 4.958793e-04:  55%|█████▍    | 8932/16329 [1:15:13<1:01:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8932: train loss 1.49379. lr 4.958793e-04:  55%|█████▍    | 8933/16329 [1:15:13<1:01:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8933: train loss 1.50805. lr 4.958574e-04:  55%|█████▍    | 8933/16329 [1:15:13<1:01:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8933: train loss 1.50805. lr 4.958574e-04:  55%|█████▍    | 8934/16329 [1:15:13<1:01:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8934: train loss 1.46513. lr 4.958355e-04:  55%|█████▍    | 8934/16329 [1:15:14<1:01:28,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8934: train loss 1.46513. lr 4.958355e-04:  55%|█████▍    | 8935/16329 [1:15:14<1:01:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8935: train loss 1.45466. lr 4.958137e-04:  55%|█████▍    | 8935/16329 [1:15:14<1:01:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8935: train loss 1.45466. lr 4.958137e-04:  55%|█████▍    | 8936/16329 [1:15:14<1:01:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8936: train loss 1.45272. lr 4.957918e-04:  55%|█████▍    | 8936/16329 [1:15:15<1:01:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8936: train loss 1.45272. lr 4.957918e-04:  55%|█████▍    | 8937/16329 [1:15:15<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8937: train loss 1.46094. lr 4.957699e-04:  55%|█████▍    | 8937/16329 [1:15:15<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8937: train loss 1.46094. lr 4.957699e-04:  55%|█████▍    | 8938/16329 [1:15:15<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8938: train loss 1.46976. lr 4.957481e-04:  55%|█████▍    | 8938/16329 [1:15:16<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8938: train loss 1.46976. lr 4.957481e-04:  55%|█████▍    | 8939/16329 [1:15:16<1:01:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8939: train loss 1.50735. lr 4.957262e-04:  55%|█████▍    | 8939/16329 [1:15:16<1:01:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8939: train loss 1.50735. lr 4.957262e-04:  55%|█████▍    | 8940/16329 [1:15:16<1:01:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8940: train loss 1.47767. lr 4.957043e-04:  55%|█████▍    | 8940/16329 [1:15:17<1:01:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8940: train loss 1.47767. lr 4.957043e-04:  55%|█████▍    | 8941/16329 [1:15:17<1:01:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8941: train loss 1.47230. lr 4.956825e-04:  55%|█████▍    | 8941/16329 [1:15:17<1:01:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8941: train loss 1.47230. lr 4.956825e-04:  55%|█████▍    | 8942/16329 [1:15:17<1:01:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8942: train loss 1.47497. lr 4.956606e-04:  55%|█████▍    | 8942/16329 [1:15:18<1:01:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8942: train loss 1.47497. lr 4.956606e-04:  55%|█████▍    | 8943/16329 [1:15:18<1:01:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8943: train loss 1.52092. lr 4.956387e-04:  55%|█████▍    | 8943/16329 [1:15:18<1:01:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8943: train loss 1.52092. lr 4.956387e-04:  55%|█████▍    | 8944/16329 [1:15:18<1:01:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8944: train loss 1.47020. lr 4.956168e-04:  55%|█████▍    | 8944/16329 [1:15:19<1:01:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8944: train loss 1.47020. lr 4.956168e-04:  55%|█████▍    | 8945/16329 [1:15:19<1:02:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8945: train loss 1.50728. lr 4.955949e-04:  55%|█████▍    | 8945/16329 [1:15:20<1:02:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8945: train loss 1.50728. lr 4.955949e-04:  55%|█████▍    | 8946/16329 [1:15:20<1:03:25,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8946: train loss 1.47126. lr 4.955731e-04:  55%|█████▍    | 8946/16329 [1:15:20<1:03:25,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8946: train loss 1.47126. lr 4.955731e-04:  55%|█████▍    | 8947/16329 [1:15:20<1:03:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8947: train loss 1.53489. lr 4.955512e-04:  55%|█████▍    | 8947/16329 [1:15:21<1:03:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 8947: train loss 1.53489. lr 4.955512e-04:  55%|█████▍    | 8948/16329 [1:15:21<1:03:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8948: train loss 1.49482. lr 4.955293e-04:  55%|█████▍    | 8948/16329 [1:15:21<1:03:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8948: train loss 1.49482. lr 4.955293e-04:  55%|█████▍    | 8949/16329 [1:15:21<1:02:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8949: train loss 1.57398. lr 4.955074e-04:  55%|█████▍    | 8949/16329 [1:15:22<1:02:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 8949: train loss 1.57398. lr 4.955074e-04:  55%|█████▍    | 8950/16329 [1:15:22<1:02:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8950: train loss 1.49338. lr 4.954855e-04:  55%|█████▍    | 8950/16329 [1:15:22<1:02:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8950: train loss 1.49338. lr 4.954855e-04:  55%|█████▍    | 8951/16329 [1:15:22<1:02:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8951: train loss 1.49917. lr 4.954636e-04:  55%|█████▍    | 8951/16329 [1:15:23<1:02:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8951: train loss 1.49917. lr 4.954636e-04:  55%|█████▍    | 8952/16329 [1:15:23<1:02:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8952: train loss 1.50965. lr 4.954417e-04:  55%|█████▍    | 8952/16329 [1:15:23<1:02:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8952: train loss 1.50965. lr 4.954417e-04:  55%|█████▍    | 8953/16329 [1:15:23<1:01:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8953: train loss 1.49408. lr 4.954198e-04:  55%|█████▍    | 8953/16329 [1:15:24<1:01:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8953: train loss 1.49408. lr 4.954198e-04:  55%|█████▍    | 8954/16329 [1:15:24<1:01:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8954: train loss 1.51871. lr 4.953979e-04:  55%|█████▍    | 8954/16329 [1:15:24<1:01:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8954: train loss 1.51871. lr 4.953979e-04:  55%|█████▍    | 8955/16329 [1:15:24<1:01:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8955: train loss 1.48449. lr 4.953760e-04:  55%|█████▍    | 8955/16329 [1:15:25<1:01:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8955: train loss 1.48449. lr 4.953760e-04:  55%|█████▍    | 8956/16329 [1:15:25<1:01:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8956: train loss 1.45640. lr 4.953541e-04:  55%|█████▍    | 8956/16329 [1:15:25<1:01:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8956: train loss 1.45640. lr 4.953541e-04:  55%|█████▍    | 8957/16329 [1:15:25<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8957: train loss 1.49462. lr 4.953322e-04:  55%|█████▍    | 8957/16329 [1:15:26<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8957: train loss 1.49462. lr 4.953322e-04:  55%|█████▍    | 8958/16329 [1:15:26<1:01:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8958: train loss 1.49091. lr 4.953103e-04:  55%|█████▍    | 8958/16329 [1:15:26<1:01:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8958: train loss 1.49091. lr 4.953103e-04:  55%|█████▍    | 8959/16329 [1:15:26<1:01:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8959: train loss 1.49260. lr 4.952884e-04:  55%|█████▍    | 8959/16329 [1:15:27<1:01:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8959: train loss 1.49260. lr 4.952884e-04:  55%|█████▍    | 8960/16329 [1:15:27<1:07:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8960: train loss 1.45928. lr 4.952665e-04:  55%|█████▍    | 8960/16329 [1:15:27<1:07:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 8960: train loss 1.45928. lr 4.952665e-04:  55%|█████▍    | 8961/16329 [1:15:27<1:05:30,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8961: train loss 1.50117. lr 4.952446e-04:  55%|█████▍    | 8961/16329 [1:15:28<1:05:30,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 8961: train loss 1.50117. lr 4.952446e-04:  55%|█████▍    | 8962/16329 [1:15:28<1:04:03,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8962: train loss 1.48823. lr 4.952227e-04:  55%|█████▍    | 8962/16329 [1:15:28<1:04:03,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 8962: train loss 1.48823. lr 4.952227e-04:  55%|█████▍    | 8963/16329 [1:15:28<1:02:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8963: train loss 1.48066. lr 4.952008e-04:  55%|█████▍    | 8963/16329 [1:15:29<1:02:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8963: train loss 1.48066. lr 4.952008e-04:  55%|█████▍    | 8964/16329 [1:15:29<1:02:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8964: train loss 1.46482. lr 4.951788e-04:  55%|█████▍    | 8964/16329 [1:15:29<1:02:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8964: train loss 1.46482. lr 4.951788e-04:  55%|█████▍    | 8965/16329 [1:15:29<1:01:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8965: train loss 1.50931. lr 4.951569e-04:  55%|█████▍    | 8965/16329 [1:15:30<1:01:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8965: train loss 1.50931. lr 4.951569e-04:  55%|█████▍    | 8966/16329 [1:15:30<1:01:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8966: train loss 1.46261. lr 4.951350e-04:  55%|█████▍    | 8966/16329 [1:15:30<1:01:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8966: train loss 1.46261. lr 4.951350e-04:  55%|█████▍    | 8967/16329 [1:15:30<1:01:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8967: train loss 1.49673. lr 4.951131e-04:  55%|█████▍    | 8967/16329 [1:15:31<1:01:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8967: train loss 1.49673. lr 4.951131e-04:  55%|█████▍    | 8968/16329 [1:15:31<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8968: train loss 1.48287. lr 4.950912e-04:  55%|█████▍    | 8968/16329 [1:15:31<1:01:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8968: train loss 1.48287. lr 4.950912e-04:  55%|█████▍    | 8969/16329 [1:15:31<1:01:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8969: train loss 1.48697. lr 4.950692e-04:  55%|█████▍    | 8969/16329 [1:15:32<1:01:07,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 8969: train loss 1.48697. lr 4.950692e-04:  55%|█████▍    | 8970/16329 [1:15:32<1:00:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8970: train loss 1.47189. lr 4.950473e-04:  55%|█████▍    | 8970/16329 [1:15:32<1:00:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8970: train loss 1.47189. lr 4.950473e-04:  55%|█████▍    | 8971/16329 [1:15:32<1:01:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8971: train loss 1.48880. lr 4.950254e-04:  55%|█████▍    | 8971/16329 [1:15:33<1:01:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8971: train loss 1.48880. lr 4.950254e-04:  55%|█████▍    | 8972/16329 [1:15:33<1:00:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8972: train loss 1.48384. lr 4.950034e-04:  55%|█████▍    | 8972/16329 [1:15:33<1:00:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8972: train loss 1.48384. lr 4.950034e-04:  55%|█████▍    | 8973/16329 [1:15:33<1:01:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8973: train loss 1.50786. lr 4.949815e-04:  55%|█████▍    | 8973/16329 [1:15:34<1:01:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8973: train loss 1.50786. lr 4.949815e-04:  55%|█████▍    | 8974/16329 [1:15:34<1:00:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8974: train loss 1.49669. lr 4.949596e-04:  55%|█████▍    | 8974/16329 [1:15:34<1:00:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8974: train loss 1.49669. lr 4.949596e-04:  55%|█████▍    | 8975/16329 [1:15:34<1:00:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8975: train loss 1.49966. lr 4.949376e-04:  55%|█████▍    | 8975/16329 [1:15:35<1:00:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8975: train loss 1.49966. lr 4.949376e-04:  55%|█████▍    | 8976/16329 [1:15:35<1:01:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8976: train loss 1.49039. lr 4.949157e-04:  55%|█████▍    | 8976/16329 [1:15:35<1:01:55,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8976: train loss 1.49039. lr 4.949157e-04:  55%|█████▍    | 8977/16329 [1:15:35<1:02:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8977: train loss 1.48674. lr 4.948938e-04:  55%|█████▍    | 8977/16329 [1:15:36<1:02:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8977: train loss 1.48674. lr 4.948938e-04:  55%|█████▍    | 8978/16329 [1:15:36<1:03:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8978: train loss 1.49860. lr 4.948718e-04:  55%|█████▍    | 8978/16329 [1:15:36<1:03:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8978: train loss 1.49860. lr 4.948718e-04:  55%|█████▍    | 8979/16329 [1:15:36<1:03:03,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8979: train loss 1.52379. lr 4.948499e-04:  55%|█████▍    | 8979/16329 [1:15:37<1:03:03,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 8979: train loss 1.52379. lr 4.948499e-04:  55%|█████▍    | 8980/16329 [1:15:37<1:02:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8980: train loss 1.46899. lr 4.948279e-04:  55%|█████▍    | 8980/16329 [1:15:37<1:02:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8980: train loss 1.46899. lr 4.948279e-04:  55%|█████▌    | 8981/16329 [1:15:37<1:02:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8981: train loss 1.48314. lr 4.948060e-04:  55%|█████▌    | 8981/16329 [1:15:38<1:02:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8981: train loss 1.48314. lr 4.948060e-04:  55%|█████▌    | 8982/16329 [1:15:38<1:01:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8982: train loss 1.51100. lr 4.947840e-04:  55%|█████▌    | 8982/16329 [1:15:38<1:01:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8982: train loss 1.51100. lr 4.947840e-04:  55%|█████▌    | 8983/16329 [1:15:38<1:01:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8983: train loss 1.49985. lr 4.947621e-04:  55%|█████▌    | 8983/16329 [1:15:39<1:01:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8983: train loss 1.49985. lr 4.947621e-04:  55%|█████▌    | 8984/16329 [1:15:39<1:01:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8984: train loss 1.49806. lr 4.947401e-04:  55%|█████▌    | 8984/16329 [1:15:39<1:01:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8984: train loss 1.49806. lr 4.947401e-04:  55%|█████▌    | 8985/16329 [1:15:39<1:08:13,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 8985: train loss 1.47612. lr 4.947182e-04:  55%|█████▌    | 8985/16329 [1:15:40<1:08:13,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 8985: train loss 1.47612. lr 4.947182e-04:  55%|█████▌    | 8986/16329 [1:15:40<1:05:49,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8986: train loss 1.50121. lr 4.946962e-04:  55%|█████▌    | 8986/16329 [1:15:40<1:05:49,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 8986: train loss 1.50121. lr 4.946962e-04:  55%|█████▌    | 8987/16329 [1:15:40<1:04:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8987: train loss 1.46110. lr 4.946743e-04:  55%|█████▌    | 8987/16329 [1:15:41<1:04:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 8987: train loss 1.46110. lr 4.946743e-04:  55%|█████▌    | 8988/16329 [1:15:41<1:02:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8988: train loss 1.48925. lr 4.946523e-04:  55%|█████▌    | 8988/16329 [1:15:41<1:02:52,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 8988: train loss 1.48925. lr 4.946523e-04:  55%|█████▌    | 8989/16329 [1:15:41<1:02:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8989: train loss 1.47475. lr 4.946303e-04:  55%|█████▌    | 8989/16329 [1:15:42<1:02:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 8989: train loss 1.47475. lr 4.946303e-04:  55%|█████▌    | 8990/16329 [1:15:42<1:01:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8990: train loss 1.47630. lr 4.946084e-04:  55%|█████▌    | 8990/16329 [1:15:42<1:01:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 8990: train loss 1.47630. lr 4.946084e-04:  55%|█████▌    | 8991/16329 [1:15:42<1:01:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8991: train loss 1.50355. lr 4.945864e-04:  55%|█████▌    | 8991/16329 [1:15:43<1:01:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8991: train loss 1.50355. lr 4.945864e-04:  55%|█████▌    | 8992/16329 [1:15:43<1:01:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8992: train loss 1.52487. lr 4.945644e-04:  55%|█████▌    | 8992/16329 [1:15:43<1:01:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8992: train loss 1.52487. lr 4.945644e-04:  55%|█████▌    | 8993/16329 [1:15:43<1:00:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8993: train loss 1.49325. lr 4.945425e-04:  55%|█████▌    | 8993/16329 [1:15:44<1:00:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8993: train loss 1.49325. lr 4.945425e-04:  55%|█████▌    | 8994/16329 [1:15:44<1:00:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8994: train loss 1.47007. lr 4.945205e-04:  55%|█████▌    | 8994/16329 [1:15:44<1:00:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8994: train loss 1.47007. lr 4.945205e-04:  55%|█████▌    | 8995/16329 [1:15:44<1:00:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8995: train loss 1.49486. lr 4.944985e-04:  55%|█████▌    | 8995/16329 [1:15:45<1:00:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 8995: train loss 1.49486. lr 4.944985e-04:  55%|█████▌    | 8996/16329 [1:15:45<1:00:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8996: train loss 1.49052. lr 4.944766e-04:  55%|█████▌    | 8996/16329 [1:15:45<1:00:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 8996: train loss 1.49052. lr 4.944766e-04:  55%|█████▌    | 8997/16329 [1:15:45<1:01:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8997: train loss 1.50320. lr 4.944546e-04:  55%|█████▌    | 8997/16329 [1:15:46<1:01:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8997: train loss 1.50320. lr 4.944546e-04:  55%|█████▌    | 8998/16329 [1:15:46<1:01:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8998: train loss 1.49454. lr 4.944326e-04:  55%|█████▌    | 8998/16329 [1:15:46<1:01:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 8998: train loss 1.49454. lr 4.944326e-04:  55%|█████▌    | 8999/16329 [1:15:46<1:01:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8999: train loss 1.47618. lr 4.944106e-04:  55%|█████▌    | 8999/16329 [1:15:47<1:01:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 8999: train loss 1.47618. lr 4.944106e-04:  55%|█████▌    | 9000/16329 [1:15:47<1:01:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 9000: train loss 1.49916. lr 4.943886e-04:  55%|█████▌    | 9000/16329 [1:15:47<1:01:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 9000: train loss 1.49916. lr 4.943886e-04:  55%|█████▌    | 9001/16329 [1:15:47<1:00:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9001: train loss 1.50378. lr 4.943667e-04:  55%|█████▌    | 9001/16329 [1:15:48<1:00:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9001: train loss 1.50378. lr 4.943667e-04:  55%|█████▌    | 9002/16329 [1:15:48<1:00:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9002: train loss 1.47560. lr 4.943447e-04:  55%|█████▌    | 9002/16329 [1:15:48<1:00:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9002: train loss 1.47560. lr 4.943447e-04:  55%|█████▌    | 9003/16329 [1:15:48<1:02:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9003: train loss 1.47885. lr 4.943227e-04:  55%|█████▌    | 9003/16329 [1:15:49<1:02:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9003: train loss 1.47885. lr 4.943227e-04:  55%|█████▌    | 9004/16329 [1:15:49<1:04:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 9004: train loss 1.47646. lr 4.943007e-04:  55%|█████▌    | 9004/16329 [1:15:49<1:04:03,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 9004: train loss 1.47646. lr 4.943007e-04:  55%|█████▌    | 9005/16329 [1:15:49<1:04:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 9005: train loss 1.49861. lr 4.942787e-04:  55%|█████▌    | 9005/16329 [1:15:50<1:04:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 9005: train loss 1.49861. lr 4.942787e-04:  55%|█████▌    | 9006/16329 [1:15:50<1:04:11,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 9006: train loss 1.47433. lr 4.942567e-04:  55%|█████▌    | 9006/16329 [1:15:51<1:04:11,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 9006: train loss 1.47433. lr 4.942567e-04:  55%|█████▌    | 9007/16329 [1:15:51<1:03:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 9007: train loss 1.46248. lr 4.942347e-04:  55%|█████▌    | 9007/16329 [1:15:51<1:03:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 9007: train loss 1.46248. lr 4.942347e-04:  55%|█████▌    | 9008/16329 [1:15:51<1:03:19,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 9008: train loss 1.51831. lr 4.942127e-04:  55%|█████▌    | 9008/16329 [1:15:52<1:03:19,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 9008: train loss 1.51831. lr 4.942127e-04:  55%|█████▌    | 9009/16329 [1:15:52<1:02:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9009: train loss 1.50771. lr 4.941907e-04:  55%|█████▌    | 9009/16329 [1:15:52<1:02:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9009: train loss 1.50771. lr 4.941907e-04:  55%|█████▌    | 9010/16329 [1:15:52<1:02:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9010: train loss 1.48185. lr 4.941687e-04:  55%|█████▌    | 9010/16329 [1:15:53<1:02:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9010: train loss 1.48185. lr 4.941687e-04:  55%|█████▌    | 9011/16329 [1:15:53<1:01:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9011: train loss 1.48695. lr 4.941467e-04:  55%|█████▌    | 9011/16329 [1:15:53<1:01:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9011: train loss 1.48695. lr 4.941467e-04:  55%|█████▌    | 9012/16329 [1:15:53<1:09:28,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 9012: train loss 1.49230. lr 4.941247e-04:  55%|█████▌    | 9012/16329 [1:15:54<1:09:28,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 9012: train loss 1.49230. lr 4.941247e-04:  55%|█████▌    | 9013/16329 [1:15:54<1:06:43,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 9013: train loss 1.50092. lr 4.941027e-04:  55%|█████▌    | 9013/16329 [1:15:54<1:06:43,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 9013: train loss 1.50092. lr 4.941027e-04:  55%|█████▌    | 9014/16329 [1:15:54<1:04:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 9014: train loss 1.45969. lr 4.940807e-04:  55%|█████▌    | 9014/16329 [1:15:55<1:04:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 9014: train loss 1.45969. lr 4.940807e-04:  55%|█████▌    | 9015/16329 [1:15:55<1:03:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 9015: train loss 1.45203. lr 4.940587e-04:  55%|█████▌    | 9015/16329 [1:15:55<1:03:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 9015: train loss 1.45203. lr 4.940587e-04:  55%|█████▌    | 9016/16329 [1:15:55<1:02:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 9016: train loss 1.47546. lr 4.940367e-04:  55%|█████▌    | 9016/16329 [1:15:56<1:02:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 9016: train loss 1.47546. lr 4.940367e-04:  55%|█████▌    | 9017/16329 [1:15:56<1:01:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9017: train loss 1.44316. lr 4.940147e-04:  55%|█████▌    | 9017/16329 [1:15:56<1:01:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9017: train loss 1.44316. lr 4.940147e-04:  55%|█████▌    | 9018/16329 [1:15:56<1:01:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9018: train loss 1.47022. lr 4.939927e-04:  55%|█████▌    | 9018/16329 [1:15:57<1:01:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9018: train loss 1.47022. lr 4.939927e-04:  55%|█████▌    | 9019/16329 [1:15:57<1:01:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 9019: train loss 1.44638. lr 4.939707e-04:  55%|█████▌    | 9019/16329 [1:15:57<1:01:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 9019: train loss 1.44638. lr 4.939707e-04:  55%|█████▌    | 9020/16329 [1:15:57<1:00:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9020: train loss 1.48887. lr 4.939486e-04:  55%|█████▌    | 9020/16329 [1:15:58<1:00:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9020: train loss 1.48887. lr 4.939486e-04:  55%|█████▌    | 9021/16329 [1:15:58<1:00:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9021: train loss 1.47892. lr 4.939266e-04:  55%|█████▌    | 9021/16329 [1:15:58<1:00:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9021: train loss 1.47892. lr 4.939266e-04:  55%|█████▌    | 9022/16329 [1:15:58<1:00:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9022: train loss 1.48908. lr 4.939046e-04:  55%|█████▌    | 9022/16329 [1:15:59<1:00:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9022: train loss 1.48908. lr 4.939046e-04:  55%|█████▌    | 9023/16329 [1:15:59<1:00:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9023: train loss 1.44924. lr 4.938826e-04:  55%|█████▌    | 9023/16329 [1:15:59<1:00:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9023: train loss 1.44924. lr 4.938826e-04:  55%|█████▌    | 9024/16329 [1:15:59<1:00:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9024: train loss 1.47544. lr 4.938606e-04:  55%|█████▌    | 9024/16329 [1:16:00<1:00:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9024: train loss 1.47544. lr 4.938606e-04:  55%|█████▌    | 9025/16329 [1:16:00<1:01:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9025: train loss 1.46736. lr 4.938385e-04:  55%|█████▌    | 9025/16329 [1:16:00<1:01:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9025: train loss 1.46736. lr 4.938385e-04:  55%|█████▌    | 9026/16329 [1:16:00<1:01:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 9026: train loss 1.47709. lr 4.938165e-04:  55%|█████▌    | 9026/16329 [1:16:01<1:01:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 9026: train loss 1.47709. lr 4.938165e-04:  55%|█████▌    | 9027/16329 [1:16:01<1:02:35,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 9027: train loss 1.51521. lr 4.937945e-04:  55%|█████▌    | 9027/16329 [1:16:01<1:02:35,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 9027: train loss 1.51521. lr 4.937945e-04:  55%|█████▌    | 9028/16329 [1:16:01<1:02:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 9028: train loss 1.46690. lr 4.937724e-04:  55%|█████▌    | 9028/16329 [1:16:02<1:02:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 9028: train loss 1.46690. lr 4.937724e-04:  55%|█████▌    | 9029/16329 [1:16:02<1:02:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 9029: train loss 1.46654. lr 4.937504e-04:  55%|█████▌    | 9029/16329 [1:16:02<1:02:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 9029: train loss 1.46654. lr 4.937504e-04:  55%|█████▌    | 9030/16329 [1:16:02<1:02:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9030: train loss 1.46570. lr 4.937284e-04:  55%|█████▌    | 9030/16329 [1:16:03<1:02:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9030: train loss 1.46570. lr 4.937284e-04:  55%|█████▌    | 9031/16329 [1:16:03<1:02:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 9031: train loss 1.48691. lr 4.937063e-04:  55%|█████▌    | 9031/16329 [1:16:03<1:02:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 9031: train loss 1.48691. lr 4.937063e-04:  55%|█████▌    | 9032/16329 [1:16:03<1:01:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9032: train loss 1.52321. lr 4.936843e-04:  55%|█████▌    | 9032/16329 [1:16:04<1:01:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9032: train loss 1.52321. lr 4.936843e-04:  55%|█████▌    | 9033/16329 [1:16:04<1:01:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9033: train loss 1.48530. lr 4.936623e-04:  55%|█████▌    | 9033/16329 [1:16:04<1:01:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9033: train loss 1.48530. lr 4.936623e-04:  55%|█████▌    | 9034/16329 [1:16:04<1:00:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9034: train loss 1.47345. lr 4.936402e-04:  55%|█████▌    | 9034/16329 [1:16:05<1:00:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9034: train loss 1.47345. lr 4.936402e-04:  55%|█████▌    | 9035/16329 [1:16:05<1:00:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 9035: train loss 1.41412. lr 4.936182e-04:  55%|█████▌    | 9035/16329 [1:16:05<1:00:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 9035: train loss 1.41412. lr 4.936182e-04:  55%|█████▌    | 9036/16329 [1:16:05<1:00:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9036: train loss 1.46319. lr 4.935961e-04:  55%|█████▌    | 9036/16329 [1:16:06<1:00:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9036: train loss 1.46319. lr 4.935961e-04:  55%|█████▌    | 9037/16329 [1:16:06<1:00:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9037: train loss 1.49989. lr 4.935741e-04:  55%|█████▌    | 9037/16329 [1:16:06<1:00:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9037: train loss 1.49989. lr 4.935741e-04:  55%|█████▌    | 9038/16329 [1:16:06<1:00:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9038: train loss 1.49535. lr 4.935520e-04:  55%|█████▌    | 9038/16329 [1:16:07<1:00:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9038: train loss 1.49535. lr 4.935520e-04:  55%|█████▌    | 9039/16329 [1:16:07<1:00:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 9039: train loss 1.51372. lr 4.935300e-04:  55%|█████▌    | 9039/16329 [1:16:07<1:00:20,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 9039: train loss 1.51372. lr 4.935300e-04:  55%|█████▌    | 9040/16329 [1:16:07<1:00:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9040: train loss 1.46359. lr 4.935079e-04:  55%|█████▌    | 9040/16329 [1:16:08<1:00:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9040: train loss 1.46359. lr 4.935079e-04:  55%|█████▌    | 9041/16329 [1:16:08<1:00:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9041: train loss 1.49031. lr 4.934859e-04:  55%|█████▌    | 9041/16329 [1:16:08<1:00:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9041: train loss 1.49031. lr 4.934859e-04:  55%|█████▌    | 9042/16329 [1:16:08<1:00:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9042: train loss 1.46779. lr 4.934638e-04:  55%|█████▌    | 9042/16329 [1:16:09<1:00:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9042: train loss 1.46779. lr 4.934638e-04:  55%|█████▌    | 9043/16329 [1:16:09<59:57,  2.03it/s]  \u001b[A\n",
      "epoch 1 iter 9043: train loss 1.50015. lr 4.934418e-04:  55%|█████▌    | 9043/16329 [1:16:09<59:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 9043: train loss 1.50015. lr 4.934418e-04:  55%|█████▌    | 9044/16329 [1:16:09<1:00:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9044: train loss 1.47148. lr 4.934197e-04:  55%|█████▌    | 9044/16329 [1:16:10<1:00:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9044: train loss 1.47148. lr 4.934197e-04:  55%|█████▌    | 9045/16329 [1:16:10<59:58,  2.02it/s]  \u001b[A\n",
      "epoch 1 iter 9045: train loss 1.44356. lr 4.933976e-04:  55%|█████▌    | 9045/16329 [1:16:10<59:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9045: train loss 1.44356. lr 4.933976e-04:  55%|█████▌    | 9046/16329 [1:16:10<1:00:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9046: train loss 1.45957. lr 4.933756e-04:  55%|█████▌    | 9046/16329 [1:16:11<1:00:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9046: train loss 1.45957. lr 4.933756e-04:  55%|█████▌    | 9047/16329 [1:16:11<1:00:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9047: train loss 1.47268. lr 4.933535e-04:  55%|█████▌    | 9047/16329 [1:16:11<1:00:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9047: train loss 1.47268. lr 4.933535e-04:  55%|█████▌    | 9048/16329 [1:16:11<1:00:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9048: train loss 1.46862. lr 4.933314e-04:  55%|█████▌    | 9048/16329 [1:16:12<1:00:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9048: train loss 1.46862. lr 4.933314e-04:  55%|█████▌    | 9049/16329 [1:16:12<1:00:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9049: train loss 1.49726. lr 4.933094e-04:  55%|█████▌    | 9049/16329 [1:16:12<1:00:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9049: train loss 1.49726. lr 4.933094e-04:  55%|█████▌    | 9050/16329 [1:16:12<59:54,  2.02it/s]  \u001b[A\n",
      "epoch 1 iter 9050: train loss 1.53741. lr 4.932873e-04:  55%|█████▌    | 9050/16329 [1:16:13<59:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9050: train loss 1.53741. lr 4.932873e-04:  55%|█████▌    | 9051/16329 [1:16:13<1:00:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9051: train loss 1.51919. lr 4.932652e-04:  55%|█████▌    | 9051/16329 [1:16:13<1:00:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 9051: train loss 1.51919. lr 4.932652e-04:  55%|█████▌    | 9052/16329 [1:16:13<1:06:22,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 9052: train loss 1.47472. lr 4.932432e-04:  55%|█████▌    | 9052/16329 [1:16:14<1:06:22,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 9052: train loss 1.47472. lr 4.932432e-04:  55%|█████▌    | 9053/16329 [1:16:14<1:04:20,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 9053: train loss 1.49152. lr 4.932211e-04:  55%|█████▌    | 9053/16329 [1:16:14<1:04:20,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 9053: train loss 1.49152. lr 4.932211e-04:  55%|█████▌    | 9054/16329 [1:16:14<1:03:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 9054: train loss 1.50675. lr 4.931990e-04:  55%|█████▌    | 9054/16329 [1:16:15<1:03:13,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 9054: train loss 1.50675. lr 4.931990e-04:  55%|█████▌    | 9055/16329 [1:16:15<1:02:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9055: train loss 1.49726. lr 4.931769e-04:  55%|█████▌    | 9055/16329 [1:16:15<1:02:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 9055: train loss 1.49726. lr 4.931769e-04:  55%|█████▌    | 9056/16329 [1:16:15<1:01:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9056: train loss 1.46260. lr 4.931548e-04:  55%|█████▌    | 9056/16329 [1:16:16<1:01:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 9056: train loss 1.46260. lr 4.931548e-04:  55%|█████▌    | 9057/16329 [1:16:16<1:00:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9057: train loss 1.47089. lr 4.931328e-04:  55%|█████▌    | 9057/16329 [1:16:16<1:00:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 9057: train loss 1.47089. lr 4.931328e-04:  55%|█████▌    | 9058/16329 [1:16:16<1:00:48,  1.99it/s]\u001b[AIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "epoch 1 iter 10513: train loss 1.34400. lr 4.591916e-04:  64%|██████▍   | 10513/16329 [1:28:32<49:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10513: train loss 1.34400. lr 4.591916e-04:  64%|██████▍   | 10514/16329 [1:28:32<48:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10514: train loss 1.37618. lr 4.591671e-04:  64%|██████▍   | 10514/16329 [1:28:32<48:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10514: train loss 1.37618. lr 4.591671e-04:  64%|██████▍   | 10515/16329 [1:28:32<48:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10515: train loss 1.38746. lr 4.591426e-04:  64%|██████▍   | 10515/16329 [1:28:33<48:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10515: train loss 1.38746. lr 4.591426e-04:  64%|██████▍   | 10516/16329 [1:28:33<48:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10516: train loss 1.38672. lr 4.591182e-04:  64%|██████▍   | 10516/16329 [1:28:33<48:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10516: train loss 1.38672. lr 4.591182e-04:  64%|██████▍   | 10517/16329 [1:28:33<48:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10517: train loss 1.37521. lr 4.590937e-04:  64%|██████▍   | 10517/16329 [1:28:34<48:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10517: train loss 1.37521. lr 4.590937e-04:  64%|██████▍   | 10518/16329 [1:28:34<48:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10518: train loss 1.33806. lr 4.590692e-04:  64%|██████▍   | 10518/16329 [1:28:34<48:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10518: train loss 1.33806. lr 4.590692e-04:  64%|██████▍   | 10519/16329 [1:28:34<48:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10519: train loss 1.35804. lr 4.590448e-04:  64%|██████▍   | 10519/16329 [1:28:35<48:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10519: train loss 1.35804. lr 4.590448e-04:  64%|██████▍   | 10520/16329 [1:28:35<48:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10520: train loss 1.39142. lr 4.590203e-04:  64%|██████▍   | 10520/16329 [1:28:35<48:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10520: train loss 1.39142. lr 4.590203e-04:  64%|██████▍   | 10521/16329 [1:28:35<48:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10521: train loss 1.36895. lr 4.589958e-04:  64%|██████▍   | 10521/16329 [1:28:36<48:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10521: train loss 1.36895. lr 4.589958e-04:  64%|██████▍   | 10522/16329 [1:28:36<47:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10522: train loss 1.38320. lr 4.589713e-04:  64%|██████▍   | 10522/16329 [1:28:36<47:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10522: train loss 1.38320. lr 4.589713e-04:  64%|██████▍   | 10523/16329 [1:28:36<48:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10523: train loss 1.39944. lr 4.589469e-04:  64%|██████▍   | 10523/16329 [1:28:37<48:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10523: train loss 1.39944. lr 4.589469e-04:  64%|██████▍   | 10524/16329 [1:28:37<47:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10524: train loss 1.38451. lr 4.589224e-04:  64%|██████▍   | 10524/16329 [1:28:37<47:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10524: train loss 1.38451. lr 4.589224e-04:  64%|██████▍   | 10525/16329 [1:28:37<48:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10525: train loss 1.38319. lr 4.588979e-04:  64%|██████▍   | 10525/16329 [1:28:38<48:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10525: train loss 1.38319. lr 4.588979e-04:  64%|██████▍   | 10526/16329 [1:28:38<47:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10526: train loss 1.33977. lr 4.588734e-04:  64%|██████▍   | 10526/16329 [1:28:38<47:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10526: train loss 1.33977. lr 4.588734e-04:  64%|██████▍   | 10527/16329 [1:28:38<47:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10527: train loss 1.36744. lr 4.588490e-04:  64%|██████▍   | 10527/16329 [1:28:39<47:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10527: train loss 1.36744. lr 4.588490e-04:  64%|██████▍   | 10528/16329 [1:28:39<49:59,  1.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10528: train loss 1.34496. lr 4.588245e-04:  64%|██████▍   | 10528/16329 [1:28:39<49:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10528: train loss 1.34496. lr 4.588245e-04:  64%|██████▍   | 10529/16329 [1:28:39<51:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 10529: train loss 1.33383. lr 4.588000e-04:  64%|██████▍   | 10529/16329 [1:28:40<51:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 10529: train loss 1.33383. lr 4.588000e-04:  64%|██████▍   | 10530/16329 [1:28:40<51:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10530: train loss 1.32989. lr 4.587755e-04:  64%|██████▍   | 10530/16329 [1:28:41<51:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10530: train loss 1.32989. lr 4.587755e-04:  64%|██████▍   | 10531/16329 [1:28:41<51:37,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10531: train loss 1.33089. lr 4.587510e-04:  64%|██████▍   | 10531/16329 [1:28:41<51:37,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10531: train loss 1.33089. lr 4.587510e-04:  64%|██████▍   | 10532/16329 [1:28:41<51:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 10532: train loss 1.36000. lr 4.587265e-04:  64%|██████▍   | 10532/16329 [1:28:42<51:14,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 10532: train loss 1.36000. lr 4.587265e-04:  65%|██████▍   | 10533/16329 [1:28:42<50:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10533: train loss 1.37546. lr 4.587020e-04:  65%|██████▍   | 10533/16329 [1:28:42<50:50,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10533: train loss 1.37546. lr 4.587020e-04:  65%|██████▍   | 10534/16329 [1:28:42<50:30,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10534: train loss 1.37553. lr 4.586775e-04:  65%|██████▍   | 10534/16329 [1:28:43<50:30,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10534: train loss 1.37553. lr 4.586775e-04:  65%|██████▍   | 10535/16329 [1:28:43<50:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10535: train loss 1.34971. lr 4.586530e-04:  65%|██████▍   | 10535/16329 [1:28:43<50:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10535: train loss 1.34971. lr 4.586530e-04:  65%|██████▍   | 10536/16329 [1:28:43<54:48,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 10536: train loss 1.35286. lr 4.586285e-04:  65%|██████▍   | 10536/16329 [1:28:44<54:48,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 10536: train loss 1.35286. lr 4.586285e-04:  65%|██████▍   | 10537/16329 [1:28:44<52:57,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10537: train loss 1.38553. lr 4.586041e-04:  65%|██████▍   | 10537/16329 [1:28:44<52:57,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10537: train loss 1.38553. lr 4.586041e-04:  65%|██████▍   | 10538/16329 [1:28:44<51:36,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10538: train loss 1.33419. lr 4.585796e-04:  65%|██████▍   | 10538/16329 [1:28:45<51:36,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10538: train loss 1.33419. lr 4.585796e-04:  65%|██████▍   | 10539/16329 [1:28:45<50:38,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10539: train loss 1.35562. lr 4.585551e-04:  65%|██████▍   | 10539/16329 [1:28:45<50:38,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10539: train loss 1.35562. lr 4.585551e-04:  65%|██████▍   | 10540/16329 [1:28:45<49:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10540: train loss 1.37041. lr 4.585306e-04:  65%|██████▍   | 10540/16329 [1:28:46<49:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10540: train loss 1.37041. lr 4.585306e-04:  65%|██████▍   | 10541/16329 [1:28:46<49:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10541: train loss 1.36285. lr 4.585061e-04:  65%|██████▍   | 10541/16329 [1:28:46<49:10,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10541: train loss 1.36285. lr 4.585061e-04:  65%|██████▍   | 10542/16329 [1:28:46<48:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10542: train loss 1.33307. lr 4.584815e-04:  65%|██████▍   | 10542/16329 [1:28:47<48:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10542: train loss 1.33307. lr 4.584815e-04:  65%|██████▍   | 10543/16329 [1:28:47<48:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10543: train loss 1.36561. lr 4.584570e-04:  65%|██████▍   | 10543/16329 [1:28:47<48:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10543: train loss 1.36561. lr 4.584570e-04:  65%|██████▍   | 10544/16329 [1:28:47<48:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10544: train loss 1.34445. lr 4.584325e-04:  65%|██████▍   | 10544/16329 [1:28:48<48:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10544: train loss 1.34445. lr 4.584325e-04:  65%|██████▍   | 10545/16329 [1:28:48<47:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10545: train loss 1.34024. lr 4.584080e-04:  65%|██████▍   | 10545/16329 [1:28:48<47:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10545: train loss 1.34024. lr 4.584080e-04:  65%|██████▍   | 10546/16329 [1:28:48<47:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10546: train loss 1.30155. lr 4.583835e-04:  65%|██████▍   | 10546/16329 [1:28:49<47:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10546: train loss 1.30155. lr 4.583835e-04:  65%|██████▍   | 10547/16329 [1:28:49<47:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10547: train loss 1.35815. lr 4.583590e-04:  65%|██████▍   | 10547/16329 [1:28:49<47:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10547: train loss 1.35815. lr 4.583590e-04:  65%|██████▍   | 10548/16329 [1:28:49<47:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10548: train loss 1.33964. lr 4.583345e-04:  65%|██████▍   | 10548/16329 [1:28:50<47:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10548: train loss 1.33964. lr 4.583345e-04:  65%|██████▍   | 10549/16329 [1:28:50<47:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10549: train loss 1.34791. lr 4.583100e-04:  65%|██████▍   | 10549/16329 [1:28:50<47:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10549: train loss 1.34791. lr 4.583100e-04:  65%|██████▍   | 10550/16329 [1:28:50<47:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10550: train loss 1.36747. lr 4.582855e-04:  65%|██████▍   | 10550/16329 [1:28:51<47:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10550: train loss 1.36747. lr 4.582855e-04:  65%|██████▍   | 10551/16329 [1:28:51<47:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10551: train loss 1.35986. lr 4.582609e-04:  65%|██████▍   | 10551/16329 [1:28:51<47:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10551: train loss 1.35986. lr 4.582609e-04:  65%|██████▍   | 10552/16329 [1:28:51<47:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10552: train loss 1.36231. lr 4.582364e-04:  65%|██████▍   | 10552/16329 [1:28:52<47:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10552: train loss 1.36231. lr 4.582364e-04:  65%|██████▍   | 10553/16329 [1:28:52<47:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10553: train loss 1.40919. lr 4.582119e-04:  65%|██████▍   | 10553/16329 [1:28:52<47:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10553: train loss 1.40919. lr 4.582119e-04:  65%|██████▍   | 10554/16329 [1:28:52<47:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10554: train loss 1.36501. lr 4.581874e-04:  65%|██████▍   | 10554/16329 [1:28:53<47:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10554: train loss 1.36501. lr 4.581874e-04:  65%|██████▍   | 10555/16329 [1:28:53<47:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10555: train loss 1.33856. lr 4.581629e-04:  65%|██████▍   | 10555/16329 [1:28:53<47:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10555: train loss 1.33856. lr 4.581629e-04:  65%|██████▍   | 10556/16329 [1:28:53<47:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10556: train loss 1.34647. lr 4.581383e-04:  65%|██████▍   | 10556/16329 [1:28:54<47:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10556: train loss 1.34647. lr 4.581383e-04:  65%|██████▍   | 10557/16329 [1:28:54<47:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10557: train loss 1.41088. lr 4.581138e-04:  65%|██████▍   | 10557/16329 [1:28:54<47:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10557: train loss 1.41088. lr 4.581138e-04:  65%|██████▍   | 10558/16329 [1:28:54<47:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10558: train loss 1.36956. lr 4.580893e-04:  65%|██████▍   | 10558/16329 [1:28:55<47:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10558: train loss 1.36956. lr 4.580893e-04:  65%|██████▍   | 10559/16329 [1:28:55<47:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10559: train loss 1.34990. lr 4.580648e-04:  65%|██████▍   | 10559/16329 [1:28:55<47:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10559: train loss 1.34990. lr 4.580648e-04:  65%|██████▍   | 10560/16329 [1:28:55<47:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10560: train loss 1.38511. lr 4.580402e-04:  65%|██████▍   | 10560/16329 [1:28:56<47:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10560: train loss 1.38511. lr 4.580402e-04:  65%|██████▍   | 10561/16329 [1:28:56<47:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10561: train loss 1.35290. lr 4.580157e-04:  65%|██████▍   | 10561/16329 [1:28:56<47:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10561: train loss 1.35290. lr 4.580157e-04:  65%|██████▍   | 10562/16329 [1:28:56<47:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10562: train loss 1.35137. lr 4.579912e-04:  65%|██████▍   | 10562/16329 [1:28:57<47:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10562: train loss 1.35137. lr 4.579912e-04:  65%|██████▍   | 10563/16329 [1:28:57<47:34,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10563: train loss 1.35857. lr 4.579666e-04:  65%|██████▍   | 10563/16329 [1:28:57<47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10563: train loss 1.35857. lr 4.579666e-04:  65%|██████▍   | 10564/16329 [1:28:57<47:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10564: train loss 1.38539. lr 4.579421e-04:  65%|██████▍   | 10564/16329 [1:28:58<47:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10564: train loss 1.38539. lr 4.579421e-04:  65%|██████▍   | 10565/16329 [1:28:58<47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10565: train loss 1.36180. lr 4.579176e-04:  65%|██████▍   | 10565/16329 [1:28:58<47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10565: train loss 1.36180. lr 4.579176e-04:  65%|██████▍   | 10566/16329 [1:28:58<47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10566: train loss 1.36164. lr 4.578930e-04:  65%|██████▍   | 10566/16329 [1:28:59<47:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10566: train loss 1.36164. lr 4.578930e-04:  65%|██████▍   | 10567/16329 [1:28:59<47:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10567: train loss 1.34994. lr 4.578685e-04:  65%|██████▍   | 10567/16329 [1:28:59<47:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10567: train loss 1.34994. lr 4.578685e-04:  65%|██████▍   | 10568/16329 [1:28:59<47:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10568: train loss 1.35589. lr 4.578439e-04:  65%|██████▍   | 10568/16329 [1:29:00<47:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10568: train loss 1.35589. lr 4.578439e-04:  65%|██████▍   | 10569/16329 [1:29:00<47:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10569: train loss 1.37294. lr 4.578194e-04:  65%|██████▍   | 10569/16329 [1:29:00<47:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10569: train loss 1.37294. lr 4.578194e-04:  65%|██████▍   | 10570/16329 [1:29:00<47:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10570: train loss 1.33853. lr 4.577948e-04:  65%|██████▍   | 10570/16329 [1:29:01<47:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10570: train loss 1.33853. lr 4.577948e-04:  65%|██████▍   | 10571/16329 [1:29:01<47:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10571: train loss 1.34461. lr 4.577703e-04:  65%|██████▍   | 10571/16329 [1:29:01<47:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10571: train loss 1.34461. lr 4.577703e-04:  65%|██████▍   | 10572/16329 [1:29:01<47:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10572: train loss 1.36304. lr 4.577458e-04:  65%|██████▍   | 10572/16329 [1:29:02<47:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10572: train loss 1.36304. lr 4.577458e-04:  65%|██████▍   | 10573/16329 [1:29:02<47:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10573: train loss 1.35108. lr 4.577212e-04:  65%|██████▍   | 10573/16329 [1:29:02<47:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10573: train loss 1.35108. lr 4.577212e-04:  65%|██████▍   | 10574/16329 [1:29:02<47:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10574: train loss 1.32993. lr 4.576967e-04:  65%|██████▍   | 10574/16329 [1:29:03<47:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10574: train loss 1.32993. lr 4.576967e-04:  65%|██████▍   | 10575/16329 [1:29:03<47:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10575: train loss 1.31952. lr 4.576721e-04:  65%|██████▍   | 10575/16329 [1:29:03<47:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10575: train loss 1.31952. lr 4.576721e-04:  65%|██████▍   | 10576/16329 [1:29:03<52:26,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 10576: train loss 1.36174. lr 4.576475e-04:  65%|██████▍   | 10576/16329 [1:29:04<52:26,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 10576: train loss 1.36174. lr 4.576475e-04:  65%|██████▍   | 10577/16329 [1:29:04<50:59,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10577: train loss 1.35919. lr 4.576230e-04:  65%|██████▍   | 10577/16329 [1:29:04<50:59,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10577: train loss 1.35919. lr 4.576230e-04:  65%|██████▍   | 10578/16329 [1:29:04<49:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10578: train loss 1.36580. lr 4.575984e-04:  65%|██████▍   | 10578/16329 [1:29:05<49:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10578: train loss 1.36580. lr 4.575984e-04:  65%|██████▍   | 10579/16329 [1:29:05<49:19,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10579: train loss 1.37145. lr 4.575739e-04:  65%|██████▍   | 10579/16329 [1:29:05<49:19,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10579: train loss 1.37145. lr 4.575739e-04:  65%|██████▍   | 10580/16329 [1:29:05<48:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10580: train loss 1.38552. lr 4.575493e-04:  65%|██████▍   | 10580/16329 [1:29:06<48:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10580: train loss 1.38552. lr 4.575493e-04:  65%|██████▍   | 10581/16329 [1:29:06<48:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10581: train loss 1.35527. lr 4.575248e-04:  65%|██████▍   | 10581/16329 [1:29:06<48:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10581: train loss 1.35527. lr 4.575248e-04:  65%|██████▍   | 10582/16329 [1:29:06<48:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10582: train loss 1.32418. lr 4.575002e-04:  65%|██████▍   | 10582/16329 [1:29:07<48:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10582: train loss 1.32418. lr 4.575002e-04:  65%|██████▍   | 10583/16329 [1:29:07<47:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10583: train loss 1.37219. lr 4.574756e-04:  65%|██████▍   | 10583/16329 [1:29:07<47:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10583: train loss 1.37219. lr 4.574756e-04:  65%|██████▍   | 10584/16329 [1:29:07<47:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10584: train loss 1.37413. lr 4.574511e-04:  65%|██████▍   | 10584/16329 [1:29:08<47:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10584: train loss 1.37413. lr 4.574511e-04:  65%|██████▍   | 10585/16329 [1:29:08<47:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10585: train loss 1.38518. lr 4.574265e-04:  65%|██████▍   | 10585/16329 [1:29:08<47:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10585: train loss 1.38518. lr 4.574265e-04:  65%|██████▍   | 10586/16329 [1:29:08<47:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10586: train loss 1.36774. lr 4.574019e-04:  65%|██████▍   | 10586/16329 [1:29:09<47:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10586: train loss 1.36774. lr 4.574019e-04:  65%|██████▍   | 10587/16329 [1:29:09<47:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10587: train loss 1.35885. lr 4.573774e-04:  65%|██████▍   | 10587/16329 [1:29:09<47:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10587: train loss 1.35885. lr 4.573774e-04:  65%|██████▍   | 10588/16329 [1:29:09<47:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10588: train loss 1.37209. lr 4.573528e-04:  65%|██████▍   | 10588/16329 [1:29:10<47:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10588: train loss 1.37209. lr 4.573528e-04:  65%|██████▍   | 10589/16329 [1:29:10<47:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10589: train loss 1.33438. lr 4.573282e-04:  65%|██████▍   | 10589/16329 [1:29:10<47:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10589: train loss 1.33438. lr 4.573282e-04:  65%|██████▍   | 10590/16329 [1:29:10<47:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10590: train loss 1.39829. lr 4.573036e-04:  65%|██████▍   | 10590/16329 [1:29:11<47:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10590: train loss 1.39829. lr 4.573036e-04:  65%|██████▍   | 10591/16329 [1:29:11<47:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10591: train loss 1.33865. lr 4.572791e-04:  65%|██████▍   | 10591/16329 [1:29:11<47:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10591: train loss 1.33865. lr 4.572791e-04:  65%|██████▍   | 10592/16329 [1:29:11<47:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10592: train loss 1.38177. lr 4.572545e-04:  65%|██████▍   | 10592/16329 [1:29:12<47:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10592: train loss 1.38177. lr 4.572545e-04:  65%|██████▍   | 10593/16329 [1:29:12<47:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10593: train loss 1.36350. lr 4.572299e-04:  65%|██████▍   | 10593/16329 [1:29:12<47:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10593: train loss 1.36350. lr 4.572299e-04:  65%|██████▍   | 10594/16329 [1:29:12<47:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10594: train loss 1.35309. lr 4.572053e-04:  65%|██████▍   | 10594/16329 [1:29:13<47:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10594: train loss 1.35309. lr 4.572053e-04:  65%|██████▍   | 10595/16329 [1:29:13<47:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10595: train loss 1.31988. lr 4.571808e-04:  65%|██████▍   | 10595/16329 [1:29:13<47:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10595: train loss 1.31988. lr 4.571808e-04:  65%|██████▍   | 10596/16329 [1:29:13<47:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10596: train loss 1.32930. lr 4.571562e-04:  65%|██████▍   | 10596/16329 [1:29:14<47:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10596: train loss 1.32930. lr 4.571562e-04:  65%|██████▍   | 10597/16329 [1:29:14<47:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10597: train loss 1.35385. lr 4.571316e-04:  65%|██████▍   | 10597/16329 [1:29:14<47:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10597: train loss 1.35385. lr 4.571316e-04:  65%|██████▍   | 10598/16329 [1:29:14<47:17,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10598: train loss 1.39626. lr 4.571070e-04:  65%|██████▍   | 10598/16329 [1:29:15<47:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10598: train loss 1.39626. lr 4.571070e-04:  65%|██████▍   | 10599/16329 [1:29:15<47:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10599: train loss 1.38377. lr 4.570824e-04:  65%|██████▍   | 10599/16329 [1:29:15<47:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10599: train loss 1.38377. lr 4.570824e-04:  65%|██████▍   | 10600/16329 [1:29:15<47:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10600: train loss 1.35215. lr 4.570578e-04:  65%|██████▍   | 10600/16329 [1:29:16<47:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10600: train loss 1.35215. lr 4.570578e-04:  65%|██████▍   | 10601/16329 [1:29:16<47:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10601: train loss 1.33823. lr 4.570332e-04:  65%|██████▍   | 10601/16329 [1:29:16<47:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10601: train loss 1.33823. lr 4.570332e-04:  65%|██████▍   | 10602/16329 [1:29:16<47:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10602: train loss 1.37373. lr 4.570086e-04:  65%|██████▍   | 10602/16329 [1:29:17<47:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10602: train loss 1.37373. lr 4.570086e-04:  65%|██████▍   | 10603/16329 [1:29:17<47:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10603: train loss 1.34105. lr 4.569840e-04:  65%|██████▍   | 10603/16329 [1:29:17<47:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10603: train loss 1.34105. lr 4.569840e-04:  65%|██████▍   | 10604/16329 [1:29:17<47:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10604: train loss 1.35846. lr 4.569595e-04:  65%|██████▍   | 10604/16329 [1:29:18<47:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10604: train loss 1.35846. lr 4.569595e-04:  65%|██████▍   | 10605/16329 [1:29:18<47:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10605: train loss 1.38008. lr 4.569349e-04:  65%|██████▍   | 10605/16329 [1:29:18<47:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10605: train loss 1.38008. lr 4.569349e-04:  65%|██████▍   | 10606/16329 [1:29:18<47:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10606: train loss 1.35770. lr 4.569103e-04:  65%|██████▍   | 10606/16329 [1:29:19<47:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10606: train loss 1.35770. lr 4.569103e-04:  65%|██████▍   | 10607/16329 [1:29:19<47:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10607: train loss 1.33988. lr 4.568857e-04:  65%|██████▍   | 10607/16329 [1:29:19<47:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10607: train loss 1.33988. lr 4.568857e-04:  65%|██████▍   | 10608/16329 [1:29:19<47:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10608: train loss 1.33239. lr 4.568611e-04:  65%|██████▍   | 10608/16329 [1:29:20<47:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10608: train loss 1.33239. lr 4.568611e-04:  65%|██████▍   | 10609/16329 [1:29:20<47:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10609: train loss 1.38912. lr 4.568365e-04:  65%|██████▍   | 10609/16329 [1:29:20<47:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10609: train loss 1.38912. lr 4.568365e-04:  65%|██████▍   | 10610/16329 [1:29:20<47:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10610: train loss 1.30759. lr 4.568119e-04:  65%|██████▍   | 10610/16329 [1:29:21<47:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10610: train loss 1.30759. lr 4.568119e-04:  65%|██████▍   | 10611/16329 [1:29:21<52:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10611: train loss 1.34004. lr 4.567873e-04:  65%|██████▍   | 10611/16329 [1:29:21<52:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10611: train loss 1.34004. lr 4.567873e-04:  65%|██████▍   | 10612/16329 [1:29:21<50:42,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10612: train loss 1.31877. lr 4.567626e-04:  65%|██████▍   | 10612/16329 [1:29:22<50:42,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10612: train loss 1.31877. lr 4.567626e-04:  65%|██████▍   | 10613/16329 [1:29:22<49:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10613: train loss 1.35647. lr 4.567380e-04:  65%|██████▍   | 10613/16329 [1:29:22<49:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10613: train loss 1.35647. lr 4.567380e-04:  65%|██████▌   | 10614/16329 [1:29:22<48:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10614: train loss 1.36999. lr 4.567134e-04:  65%|██████▌   | 10614/16329 [1:29:23<48:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10614: train loss 1.36999. lr 4.567134e-04:  65%|██████▌   | 10615/16329 [1:29:23<48:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10615: train loss 1.38524. lr 4.566888e-04:  65%|██████▌   | 10615/16329 [1:29:23<48:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10615: train loss 1.38524. lr 4.566888e-04:  65%|██████▌   | 10616/16329 [1:29:23<47:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10616: train loss 1.32774. lr 4.566642e-04:  65%|██████▌   | 10616/16329 [1:29:24<47:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10616: train loss 1.32774. lr 4.566642e-04:  65%|██████▌   | 10617/16329 [1:29:24<47:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10617: train loss 1.34378. lr 4.566396e-04:  65%|██████▌   | 10617/16329 [1:29:24<47:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10617: train loss 1.34378. lr 4.566396e-04:  65%|██████▌   | 10618/16329 [1:29:24<47:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10618: train loss 1.36681. lr 4.566150e-04:  65%|██████▌   | 10618/16329 [1:29:25<47:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10618: train loss 1.36681. lr 4.566150e-04:  65%|██████▌   | 10619/16329 [1:29:25<47:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10619: train loss 1.34733. lr 4.565904e-04:  65%|██████▌   | 10619/16329 [1:29:25<47:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10619: train loss 1.34733. lr 4.565904e-04:  65%|██████▌   | 10620/16329 [1:29:25<47:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10620: train loss 1.37857. lr 4.565657e-04:  65%|██████▌   | 10620/16329 [1:29:26<47:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10620: train loss 1.37857. lr 4.565657e-04:  65%|██████▌   | 10621/16329 [1:29:26<47:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10621: train loss 1.34632. lr 4.565411e-04:  65%|██████▌   | 10621/16329 [1:29:26<47:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10621: train loss 1.34632. lr 4.565411e-04:  65%|██████▌   | 10622/16329 [1:29:26<47:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10622: train loss 1.33098. lr 4.565165e-04:  65%|██████▌   | 10622/16329 [1:29:27<47:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10622: train loss 1.33098. lr 4.565165e-04:  65%|██████▌   | 10623/16329 [1:29:27<47:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10623: train loss 1.35694. lr 4.564919e-04:  65%|██████▌   | 10623/16329 [1:29:27<47:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10623: train loss 1.35694. lr 4.564919e-04:  65%|██████▌   | 10624/16329 [1:29:27<47:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10624: train loss 1.38596. lr 4.564673e-04:  65%|██████▌   | 10624/16329 [1:29:28<47:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10624: train loss 1.38596. lr 4.564673e-04:  65%|██████▌   | 10625/16329 [1:29:28<47:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10625: train loss 1.36364. lr 4.564426e-04:  65%|██████▌   | 10625/16329 [1:29:28<47:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10625: train loss 1.36364. lr 4.564426e-04:  65%|██████▌   | 10626/16329 [1:29:28<47:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10626: train loss 1.33231. lr 4.564180e-04:  65%|██████▌   | 10626/16329 [1:29:29<47:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10626: train loss 1.33231. lr 4.564180e-04:  65%|██████▌   | 10627/16329 [1:29:29<47:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10627: train loss 1.35532. lr 4.563934e-04:  65%|██████▌   | 10627/16329 [1:29:29<47:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10627: train loss 1.35532. lr 4.563934e-04:  65%|██████▌   | 10628/16329 [1:29:29<47:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10628: train loss 1.34742. lr 4.563688e-04:  65%|██████▌   | 10628/16329 [1:29:30<47:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10628: train loss 1.34742. lr 4.563688e-04:  65%|██████▌   | 10629/16329 [1:29:30<47:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10629: train loss 1.36795. lr 4.563441e-04:  65%|██████▌   | 10629/16329 [1:29:30<47:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10629: train loss 1.36795. lr 4.563441e-04:  65%|██████▌   | 10630/16329 [1:29:30<48:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10630: train loss 1.35817. lr 4.563195e-04:  65%|██████▌   | 10630/16329 [1:29:31<48:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10630: train loss 1.35817. lr 4.563195e-04:  65%|██████▌   | 10631/16329 [1:29:31<48:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10631: train loss 1.33190. lr 4.562949e-04:  65%|██████▌   | 10631/16329 [1:29:31<48:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10631: train loss 1.33190. lr 4.562949e-04:  65%|██████▌   | 10632/16329 [1:29:31<49:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10632: train loss 1.36102. lr 4.562702e-04:  65%|██████▌   | 10632/16329 [1:29:32<49:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10632: train loss 1.36102. lr 4.562702e-04:  65%|██████▌   | 10633/16329 [1:29:32<48:59,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10633: train loss 1.32715. lr 4.562456e-04:  65%|██████▌   | 10633/16329 [1:29:32<48:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10633: train loss 1.32715. lr 4.562456e-04:  65%|██████▌   | 10634/16329 [1:29:32<48:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10634: train loss 1.36048. lr 4.562209e-04:  65%|██████▌   | 10634/16329 [1:29:33<48:52,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10634: train loss 1.36048. lr 4.562209e-04:  65%|██████▌   | 10635/16329 [1:29:33<48:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10635: train loss 1.38198. lr 4.561963e-04:  65%|██████▌   | 10635/16329 [1:29:33<48:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10635: train loss 1.38198. lr 4.561963e-04:  65%|██████▌   | 10636/16329 [1:29:33<53:22,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 10636: train loss 1.33111. lr 4.561717e-04:  65%|██████▌   | 10636/16329 [1:29:34<53:22,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 10636: train loss 1.33111. lr 4.561717e-04:  65%|██████▌   | 10637/16329 [1:29:34<51:26,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 10637: train loss 1.30661. lr 4.561470e-04:  65%|██████▌   | 10637/16329 [1:29:34<51:26,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 10637: train loss 1.30661. lr 4.561470e-04:  65%|██████▌   | 10638/16329 [1:29:34<50:11,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 10638: train loss 1.36374. lr 4.561224e-04:  65%|██████▌   | 10638/16329 [1:29:35<50:11,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 10638: train loss 1.36374. lr 4.561224e-04:  65%|██████▌   | 10639/16329 [1:29:35<49:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10639: train loss 1.35682. lr 4.560977e-04:  65%|██████▌   | 10639/16329 [1:29:35<49:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10639: train loss 1.35682. lr 4.560977e-04:  65%|██████▌   | 10640/16329 [1:29:35<48:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10640: train loss 1.36750. lr 4.560731e-04:  65%|██████▌   | 10640/16329 [1:29:36<48:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10640: train loss 1.36750. lr 4.560731e-04:  65%|██████▌   | 10641/16329 [1:29:36<48:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10641: train loss 1.37422. lr 4.560484e-04:  65%|██████▌   | 10641/16329 [1:29:36<48:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10641: train loss 1.37422. lr 4.560484e-04:  65%|██████▌   | 10642/16329 [1:29:36<47:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10642: train loss 1.35031. lr 4.560238e-04:  65%|██████▌   | 10642/16329 [1:29:37<47:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10642: train loss 1.35031. lr 4.560238e-04:  65%|██████▌   | 10643/16329 [1:29:37<47:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10643: train loss 1.34993. lr 4.559991e-04:  65%|██████▌   | 10643/16329 [1:29:37<47:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10643: train loss 1.34993. lr 4.559991e-04:  65%|██████▌   | 10644/16329 [1:29:37<47:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10644: train loss 1.32890. lr 4.559745e-04:  65%|██████▌   | 10644/16329 [1:29:38<47:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10644: train loss 1.32890. lr 4.559745e-04:  65%|██████▌   | 10645/16329 [1:29:38<47:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10645: train loss 1.31316. lr 4.559498e-04:  65%|██████▌   | 10645/16329 [1:29:38<47:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10645: train loss 1.31316. lr 4.559498e-04:  65%|██████▌   | 10646/16329 [1:29:38<47:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10646: train loss 1.35878. lr 4.559252e-04:  65%|██████▌   | 10646/16329 [1:29:39<47:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10646: train loss 1.35878. lr 4.559252e-04:  65%|██████▌   | 10647/16329 [1:29:39<46:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10647: train loss 1.35037. lr 4.559005e-04:  65%|██████▌   | 10647/16329 [1:29:39<46:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10647: train loss 1.35037. lr 4.559005e-04:  65%|██████▌   | 10648/16329 [1:29:39<47:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10648: train loss 1.35140. lr 4.558759e-04:  65%|██████▌   | 10648/16329 [1:29:40<47:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10648: train loss 1.35140. lr 4.558759e-04:  65%|██████▌   | 10649/16329 [1:29:40<46:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10649: train loss 1.34147. lr 4.558512e-04:  65%|██████▌   | 10649/16329 [1:29:40<46:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10649: train loss 1.34147. lr 4.558512e-04:  65%|██████▌   | 10650/16329 [1:29:40<46:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10650: train loss 1.35570. lr 4.558265e-04:  65%|██████▌   | 10650/16329 [1:29:41<46:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10650: train loss 1.35570. lr 4.558265e-04:  65%|██████▌   | 10651/16329 [1:29:41<46:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10651: train loss 1.35661. lr 4.558019e-04:  65%|██████▌   | 10651/16329 [1:29:41<46:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10651: train loss 1.35661. lr 4.558019e-04:  65%|██████▌   | 10652/16329 [1:29:41<46:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10652: train loss 1.34948. lr 4.557772e-04:  65%|██████▌   | 10652/16329 [1:29:42<46:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10652: train loss 1.34948. lr 4.557772e-04:  65%|██████▌   | 10653/16329 [1:29:42<46:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10653: train loss 1.37248. lr 4.557526e-04:  65%|██████▌   | 10653/16329 [1:29:42<46:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10653: train loss 1.37248. lr 4.557526e-04:  65%|██████▌   | 10654/16329 [1:29:42<46:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10654: train loss 1.33561. lr 4.557279e-04:  65%|██████▌   | 10654/16329 [1:29:43<46:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10654: train loss 1.33561. lr 4.557279e-04:  65%|██████▌   | 10655/16329 [1:29:43<46:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10655: train loss 1.36890. lr 4.557032e-04:  65%|██████▌   | 10655/16329 [1:29:43<46:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10655: train loss 1.36890. lr 4.557032e-04:  65%|██████▌   | 10656/16329 [1:29:43<46:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10656: train loss 1.37811. lr 4.556786e-04:  65%|██████▌   | 10656/16329 [1:29:44<46:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10656: train loss 1.37811. lr 4.556786e-04:  65%|██████▌   | 10657/16329 [1:29:44<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10657: train loss 1.35144. lr 4.556539e-04:  65%|██████▌   | 10657/16329 [1:29:44<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10657: train loss 1.35144. lr 4.556539e-04:  65%|██████▌   | 10658/16329 [1:29:44<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10658: train loss 1.40283. lr 4.556292e-04:  65%|██████▌   | 10658/16329 [1:29:45<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10658: train loss 1.40283. lr 4.556292e-04:  65%|██████▌   | 10659/16329 [1:29:45<46:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10659: train loss 1.33234. lr 4.556045e-04:  65%|██████▌   | 10659/16329 [1:29:45<46:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10659: train loss 1.33234. lr 4.556045e-04:  65%|██████▌   | 10660/16329 [1:29:45<46:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10660: train loss 1.33234. lr 4.555799e-04:  65%|██████▌   | 10660/16329 [1:29:46<46:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10660: train loss 1.33234. lr 4.555799e-04:  65%|██████▌   | 10661/16329 [1:29:46<46:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10661: train loss 1.38727. lr 4.555552e-04:  65%|██████▌   | 10661/16329 [1:29:46<46:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10661: train loss 1.38727. lr 4.555552e-04:  65%|██████▌   | 10662/16329 [1:29:46<48:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10662: train loss 1.33266. lr 4.555305e-04:  65%|██████▌   | 10662/16329 [1:29:47<48:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10662: train loss 1.33266. lr 4.555305e-04:  65%|██████▌   | 10663/16329 [1:29:47<53:19,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 10663: train loss 1.32366. lr 4.555058e-04:  65%|██████▌   | 10663/16329 [1:29:48<53:19,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 10663: train loss 1.32366. lr 4.555058e-04:  65%|██████▌   | 10664/16329 [1:29:48<51:54,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10664: train loss 1.30105. lr 4.554811e-04:  65%|██████▌   | 10664/16329 [1:29:48<51:54,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10664: train loss 1.30105. lr 4.554811e-04:  65%|██████▌   | 10665/16329 [1:29:48<50:45,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 10665: train loss 1.36960. lr 4.554565e-04:  65%|██████▌   | 10665/16329 [1:29:49<50:45,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 10665: train loss 1.36960. lr 4.554565e-04:  65%|██████▌   | 10666/16329 [1:29:49<49:37,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10666: train loss 1.34872. lr 4.554318e-04:  65%|██████▌   | 10666/16329 [1:29:49<49:37,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10666: train loss 1.34872. lr 4.554318e-04:  65%|██████▌   | 10667/16329 [1:29:49<48:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10667: train loss 1.35467. lr 4.554071e-04:  65%|██████▌   | 10667/16329 [1:29:50<48:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10667: train loss 1.35467. lr 4.554071e-04:  65%|██████▌   | 10668/16329 [1:29:50<48:05,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10668: train loss 1.31434. lr 4.553824e-04:  65%|██████▌   | 10668/16329 [1:29:50<48:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10668: train loss 1.31434. lr 4.553824e-04:  65%|██████▌   | 10669/16329 [1:29:50<47:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10669: train loss 1.36509. lr 4.553577e-04:  65%|██████▌   | 10669/16329 [1:29:51<47:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10669: train loss 1.36509. lr 4.553577e-04:  65%|██████▌   | 10670/16329 [1:29:51<47:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10670: train loss 1.33433. lr 4.553330e-04:  65%|██████▌   | 10670/16329 [1:29:51<47:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10670: train loss 1.33433. lr 4.553330e-04:  65%|██████▌   | 10671/16329 [1:29:51<47:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10671: train loss 1.33626. lr 4.553083e-04:  65%|██████▌   | 10671/16329 [1:29:52<47:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10671: train loss 1.33626. lr 4.553083e-04:  65%|██████▌   | 10672/16329 [1:29:52<47:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10672: train loss 1.37192. lr 4.552836e-04:  65%|██████▌   | 10672/16329 [1:29:52<47:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10672: train loss 1.37192. lr 4.552836e-04:  65%|██████▌   | 10673/16329 [1:29:52<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10673: train loss 1.36964. lr 4.552589e-04:  65%|██████▌   | 10673/16329 [1:29:53<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10673: train loss 1.36964. lr 4.552589e-04:  65%|██████▌   | 10674/16329 [1:29:53<46:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10674: train loss 1.35953. lr 4.552343e-04:  65%|██████▌   | 10674/16329 [1:29:53<46:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10674: train loss 1.35953. lr 4.552343e-04:  65%|██████▌   | 10675/16329 [1:29:53<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10675: train loss 1.32025. lr 4.552096e-04:  65%|██████▌   | 10675/16329 [1:29:54<46:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10675: train loss 1.32025. lr 4.552096e-04:  65%|██████▌   | 10676/16329 [1:29:54<46:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10676: train loss 1.34873. lr 4.551849e-04:  65%|██████▌   | 10676/16329 [1:29:54<46:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10676: train loss 1.34873. lr 4.551849e-04:  65%|██████▌   | 10677/16329 [1:29:54<46:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10677: train loss 1.37077. lr 4.551602e-04:  65%|██████▌   | 10677/16329 [1:29:55<46:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10677: train loss 1.37077. lr 4.551602e-04:  65%|██████▌   | 10678/16329 [1:29:55<46:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10678: train loss 1.36512. lr 4.551355e-04:  65%|██████▌   | 10678/16329 [1:29:55<46:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10678: train loss 1.36512. lr 4.551355e-04:  65%|██████▌   | 10679/16329 [1:29:55<46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10679: train loss 1.30653. lr 4.551108e-04:  65%|██████▌   | 10679/16329 [1:29:56<46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10679: train loss 1.30653. lr 4.551108e-04:  65%|██████▌   | 10680/16329 [1:29:56<46:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10680: train loss 1.38505. lr 4.550860e-04:  65%|██████▌   | 10680/16329 [1:29:56<46:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10680: train loss 1.38505. lr 4.550860e-04:  65%|██████▌   | 10681/16329 [1:29:56<46:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10681: train loss 1.36360. lr 4.550613e-04:  65%|██████▌   | 10681/16329 [1:29:57<46:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10681: train loss 1.36360. lr 4.550613e-04:  65%|██████▌   | 10682/16329 [1:29:57<46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10682: train loss 1.36568. lr 4.550366e-04:  65%|██████▌   | 10682/16329 [1:29:57<46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10682: train loss 1.36568. lr 4.550366e-04:  65%|██████▌   | 10683/16329 [1:29:57<46:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10683: train loss 1.35195. lr 4.550119e-04:  65%|██████▌   | 10683/16329 [1:29:58<46:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10683: train loss 1.35195. lr 4.550119e-04:  65%|██████▌   | 10684/16329 [1:29:58<46:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10684: train loss 1.35950. lr 4.549872e-04:  65%|██████▌   | 10684/16329 [1:29:58<46:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10684: train loss 1.35950. lr 4.549872e-04:  65%|██████▌   | 10685/16329 [1:29:58<46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10685: train loss 1.33774. lr 4.549625e-04:  65%|██████▌   | 10685/16329 [1:29:59<46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10685: train loss 1.33774. lr 4.549625e-04:  65%|██████▌   | 10686/16329 [1:29:59<46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10686: train loss 1.37961. lr 4.549378e-04:  65%|██████▌   | 10686/16329 [1:29:59<46:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10686: train loss 1.37961. lr 4.549378e-04:  65%|██████▌   | 10687/16329 [1:29:59<46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10687: train loss 1.35861. lr 4.549131e-04:  65%|██████▌   | 10687/16329 [1:30:00<46:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10687: train loss 1.35861. lr 4.549131e-04:  65%|██████▌   | 10688/16329 [1:30:00<46:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10688: train loss 1.35703. lr 4.548884e-04:  65%|██████▌   | 10688/16329 [1:30:00<46:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10688: train loss 1.35703. lr 4.548884e-04:  65%|██████▌   | 10689/16329 [1:30:00<46:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10689: train loss 1.36498. lr 4.548636e-04:  65%|██████▌   | 10689/16329 [1:30:01<46:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10689: train loss 1.36498. lr 4.548636e-04:  65%|██████▌   | 10690/16329 [1:30:01<46:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10690: train loss 1.38959. lr 4.548389e-04:  65%|██████▌   | 10690/16329 [1:30:01<46:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10690: train loss 1.38959. lr 4.548389e-04:  65%|██████▌   | 10691/16329 [1:30:01<46:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10691: train loss 1.35480. lr 4.548142e-04:  65%|██████▌   | 10691/16329 [1:30:02<46:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10691: train loss 1.35480. lr 4.548142e-04:  65%|██████▌   | 10692/16329 [1:30:02<46:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10692: train loss 1.37071. lr 4.547895e-04:  65%|██████▌   | 10692/16329 [1:30:02<46:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10692: train loss 1.37071. lr 4.547895e-04:  65%|██████▌   | 10693/16329 [1:30:02<46:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10693: train loss 1.33636. lr 4.547648e-04:  65%|██████▌   | 10693/16329 [1:30:03<46:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10693: train loss 1.33636. lr 4.547648e-04:  65%|██████▌   | 10694/16329 [1:30:03<46:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10694: train loss 1.33590. lr 4.547400e-04:  65%|██████▌   | 10694/16329 [1:30:03<46:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10694: train loss 1.33590. lr 4.547400e-04:  65%|██████▌   | 10695/16329 [1:30:03<46:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10695: train loss 1.36031. lr 4.547153e-04:  65%|██████▌   | 10695/16329 [1:30:04<46:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10695: train loss 1.36031. lr 4.547153e-04:  66%|██████▌   | 10696/16329 [1:30:04<46:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10696: train loss 1.37493. lr 4.546906e-04:  66%|██████▌   | 10696/16329 [1:30:04<46:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10696: train loss 1.37493. lr 4.546906e-04:  66%|██████▌   | 10697/16329 [1:30:04<46:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10697: train loss 1.34522. lr 4.546659e-04:  66%|██████▌   | 10697/16329 [1:30:05<46:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10697: train loss 1.34522. lr 4.546659e-04:  66%|██████▌   | 10698/16329 [1:30:05<46:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10698: train loss 1.33270. lr 4.546411e-04:  66%|██████▌   | 10698/16329 [1:30:05<46:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10698: train loss 1.33270. lr 4.546411e-04:  66%|██████▌   | 10699/16329 [1:30:05<47:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10699: train loss 1.30592. lr 4.546164e-04:  66%|██████▌   | 10699/16329 [1:30:06<47:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10699: train loss 1.30592. lr 4.546164e-04:  66%|██████▌   | 10700/16329 [1:30:06<47:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10700: train loss 1.31860. lr 4.545917e-04:  66%|██████▌   | 10700/16329 [1:30:06<47:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10700: train loss 1.31860. lr 4.545917e-04:  66%|██████▌   | 10701/16329 [1:30:06<48:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10701: train loss 1.35320. lr 4.545669e-04:  66%|██████▌   | 10701/16329 [1:30:07<48:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10701: train loss 1.35320. lr 4.545669e-04:  66%|██████▌   | 10702/16329 [1:30:07<48:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10702: train loss 1.31725. lr 4.545422e-04:  66%|██████▌   | 10702/16329 [1:30:07<48:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10702: train loss 1.31725. lr 4.545422e-04:  66%|██████▌   | 10703/16329 [1:30:07<54:02,  1.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10703: train loss 1.38178. lr 4.545175e-04:  66%|██████▌   | 10703/16329 [1:30:08<54:02,  1.73it/s]\u001b[A\n",
      "epoch 1 iter 10703: train loss 1.38178. lr 4.545175e-04:  66%|██████▌   | 10704/16329 [1:30:08<52:00,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 10704: train loss 1.35977. lr 4.544927e-04:  66%|██████▌   | 10704/16329 [1:30:08<52:00,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 10704: train loss 1.35977. lr 4.544927e-04:  66%|██████▌   | 10705/16329 [1:30:08<50:29,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 10705: train loss 1.33478. lr 4.544680e-04:  66%|██████▌   | 10705/16329 [1:30:09<50:29,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 10705: train loss 1.33478. lr 4.544680e-04:  66%|██████▌   | 10706/16329 [1:30:09<49:18,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10706: train loss 1.33860. lr 4.544432e-04:  66%|██████▌   | 10706/16329 [1:30:09<49:18,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10706: train loss 1.33860. lr 4.544432e-04:  66%|██████▌   | 10707/16329 [1:30:09<48:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10707: train loss 1.33270. lr 4.544185e-04:  66%|██████▌   | 10707/16329 [1:30:10<48:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10707: train loss 1.33270. lr 4.544185e-04:  66%|██████▌   | 10708/16329 [1:30:10<47:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10708: train loss 1.40404. lr 4.543938e-04:  66%|██████▌   | 10708/16329 [1:30:10<47:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10708: train loss 1.40404. lr 4.543938e-04:  66%|██████▌   | 10709/16329 [1:30:10<47:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10709: train loss 1.29481. lr 4.543690e-04:  66%|██████▌   | 10709/16329 [1:30:11<47:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10709: train loss 1.29481. lr 4.543690e-04:  66%|██████▌   | 10710/16329 [1:30:11<47:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10710: train loss 1.36167. lr 4.543443e-04:  66%|██████▌   | 10710/16329 [1:30:11<47:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10710: train loss 1.36167. lr 4.543443e-04:  66%|██████▌   | 10711/16329 [1:30:11<46:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10711: train loss 1.31124. lr 4.543195e-04:  66%|██████▌   | 10711/16329 [1:30:12<46:56,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10711: train loss 1.31124. lr 4.543195e-04:  66%|██████▌   | 10712/16329 [1:30:12<46:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10712: train loss 1.32030. lr 4.542948e-04:  66%|██████▌   | 10712/16329 [1:30:12<46:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10712: train loss 1.32030. lr 4.542948e-04:  66%|██████▌   | 10713/16329 [1:30:12<46:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10713: train loss 1.34951. lr 4.542700e-04:  66%|██████▌   | 10713/16329 [1:30:13<46:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10713: train loss 1.34951. lr 4.542700e-04:  66%|██████▌   | 10714/16329 [1:30:13<46:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10714: train loss 1.37443. lr 4.542453e-04:  66%|██████▌   | 10714/16329 [1:30:13<46:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10714: train loss 1.37443. lr 4.542453e-04:  66%|██████▌   | 10715/16329 [1:30:13<46:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10715: train loss 1.37410. lr 4.542205e-04:  66%|██████▌   | 10715/16329 [1:30:14<46:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10715: train loss 1.37410. lr 4.542205e-04:  66%|██████▌   | 10716/16329 [1:30:14<46:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10716: train loss 1.28288. lr 4.541957e-04:  66%|██████▌   | 10716/16329 [1:30:14<46:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10716: train loss 1.28288. lr 4.541957e-04:  66%|██████▌   | 10717/16329 [1:30:14<46:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10717: train loss 1.32822. lr 4.541710e-04:  66%|██████▌   | 10717/16329 [1:30:15<46:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10717: train loss 1.32822. lr 4.541710e-04:  66%|██████▌   | 10718/16329 [1:30:15<46:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10718: train loss 1.37431. lr 4.541462e-04:  66%|██████▌   | 10718/16329 [1:30:15<46:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10718: train loss 1.37431. lr 4.541462e-04:  66%|██████▌   | 10719/16329 [1:30:15<46:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10719: train loss 1.36016. lr 4.541215e-04:  66%|██████▌   | 10719/16329 [1:30:16<46:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10719: train loss 1.36016. lr 4.541215e-04:  66%|██████▌   | 10720/16329 [1:30:16<46:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10720: train loss 1.33496. lr 4.540967e-04:  66%|██████▌   | 10720/16329 [1:30:16<46:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10720: train loss 1.33496. lr 4.540967e-04:  66%|██████▌   | 10721/16329 [1:30:16<46:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10721: train loss 1.28767. lr 4.540719e-04:  66%|██████▌   | 10721/16329 [1:30:17<46:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10721: train loss 1.28767. lr 4.540719e-04:  66%|██████▌   | 10722/16329 [1:30:17<46:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10722: train loss 1.34393. lr 4.540472e-04:  66%|██████▌   | 10722/16329 [1:30:17<46:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10722: train loss 1.34393. lr 4.540472e-04:  66%|██████▌   | 10723/16329 [1:30:17<46:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10723: train loss 1.35981. lr 4.540224e-04:  66%|██████▌   | 10723/16329 [1:30:18<46:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10723: train loss 1.35981. lr 4.540224e-04:  66%|██████▌   | 10724/16329 [1:30:18<46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10724: train loss 1.33865. lr 4.539977e-04:  66%|██████▌   | 10724/16329 [1:30:18<46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10724: train loss 1.33865. lr 4.539977e-04:  66%|██████▌   | 10725/16329 [1:30:18<46:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10725: train loss 1.36157. lr 4.539729e-04:  66%|██████▌   | 10725/16329 [1:30:19<46:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10725: train loss 1.36157. lr 4.539729e-04:  66%|██████▌   | 10726/16329 [1:30:19<46:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10726: train loss 1.35754. lr 4.539481e-04:  66%|██████▌   | 10726/16329 [1:30:19<46:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10726: train loss 1.35754. lr 4.539481e-04:  66%|██████▌   | 10727/16329 [1:30:19<46:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10727: train loss 1.37808. lr 4.539233e-04:  66%|██████▌   | 10727/16329 [1:30:20<46:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10727: train loss 1.37808. lr 4.539233e-04:  66%|██████▌   | 10728/16329 [1:30:20<46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10728: train loss 1.38500. lr 4.538986e-04:  66%|██████▌   | 10728/16329 [1:30:20<46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10728: train loss 1.38500. lr 4.538986e-04:  66%|██████▌   | 10729/16329 [1:30:20<46:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10729: train loss 1.30032. lr 4.538738e-04:  66%|██████▌   | 10729/16329 [1:30:21<46:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10729: train loss 1.30032. lr 4.538738e-04:  66%|██████▌   | 10730/16329 [1:30:21<46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10730: train loss 1.32520. lr 4.538490e-04:  66%|██████▌   | 10730/16329 [1:30:21<46:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10730: train loss 1.32520. lr 4.538490e-04:  66%|██████▌   | 10731/16329 [1:30:21<46:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10731: train loss 1.31967. lr 4.538242e-04:  66%|██████▌   | 10731/16329 [1:30:22<46:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10731: train loss 1.31967. lr 4.538242e-04:  66%|██████▌   | 10732/16329 [1:30:22<46:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10732: train loss 1.33482. lr 4.537995e-04:  66%|██████▌   | 10732/16329 [1:30:22<46:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10732: train loss 1.33482. lr 4.537995e-04:  66%|██████▌   | 10733/16329 [1:30:22<46:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10733: train loss 1.37106. lr 4.537747e-04:  66%|██████▌   | 10733/16329 [1:30:23<46:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10733: train loss 1.37106. lr 4.537747e-04:  66%|██████▌   | 10734/16329 [1:30:23<46:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10734: train loss 1.32437. lr 4.537499e-04:  66%|██████▌   | 10734/16329 [1:30:23<46:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10734: train loss 1.32437. lr 4.537499e-04:  66%|██████▌   | 10735/16329 [1:30:23<46:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10735: train loss 1.34015. lr 4.537251e-04:  66%|██████▌   | 10735/16329 [1:30:24<46:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10735: train loss 1.34015. lr 4.537251e-04:  66%|██████▌   | 10736/16329 [1:30:24<46:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10736: train loss 1.34277. lr 4.537003e-04:  66%|██████▌   | 10736/16329 [1:30:24<46:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10736: train loss 1.34277. lr 4.537003e-04:  66%|██████▌   | 10737/16329 [1:30:24<46:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10737: train loss 1.31282. lr 4.536756e-04:  66%|██████▌   | 10737/16329 [1:30:25<46:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10737: train loss 1.31282. lr 4.536756e-04:  66%|██████▌   | 10738/16329 [1:30:25<51:37,  1.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10738: train loss 1.34811. lr 4.536508e-04:  66%|██████▌   | 10738/16329 [1:30:25<51:37,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 10738: train loss 1.34811. lr 4.536508e-04:  66%|██████▌   | 10739/16329 [1:30:25<49:48,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10739: train loss 1.37406. lr 4.536260e-04:  66%|██████▌   | 10739/16329 [1:30:26<49:48,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10739: train loss 1.37406. lr 4.536260e-04:  66%|██████▌   | 10740/16329 [1:30:26<48:52,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10740: train loss 1.37459. lr 4.536012e-04:  66%|██████▌   | 10740/16329 [1:30:26<48:52,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10740: train loss 1.37459. lr 4.536012e-04:  66%|██████▌   | 10741/16329 [1:30:26<48:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10741: train loss 1.35764. lr 4.535764e-04:  66%|██████▌   | 10741/16329 [1:30:27<48:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10741: train loss 1.35764. lr 4.535764e-04:  66%|██████▌   | 10742/16329 [1:30:27<47:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10742: train loss 1.35062. lr 4.535516e-04:  66%|██████▌   | 10742/16329 [1:30:27<47:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10742: train loss 1.35062. lr 4.535516e-04:  66%|██████▌   | 10743/16329 [1:30:27<47:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10743: train loss 1.33573. lr 4.535268e-04:  66%|██████▌   | 10743/16329 [1:30:28<47:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10743: train loss 1.33573. lr 4.535268e-04:  66%|██████▌   | 10744/16329 [1:30:28<46:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10744: train loss 1.32217. lr 4.535020e-04:  66%|██████▌   | 10744/16329 [1:30:28<46:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10744: train loss 1.32217. lr 4.535020e-04:  66%|██████▌   | 10745/16329 [1:30:28<47:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10745: train loss 1.33426. lr 4.534772e-04:  66%|██████▌   | 10745/16329 [1:30:29<47:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10745: train loss 1.33426. lr 4.534772e-04:  66%|██████▌   | 10746/16329 [1:30:29<48:25,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10746: train loss 1.29851. lr 4.534524e-04:  66%|██████▌   | 10746/16329 [1:30:29<48:25,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10746: train loss 1.29851. lr 4.534524e-04:  66%|██████▌   | 10747/16329 [1:30:29<48:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10747: train loss 1.33121. lr 4.534276e-04:  66%|██████▌   | 10747/16329 [1:30:30<48:37,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10747: train loss 1.33121. lr 4.534276e-04:  66%|██████▌   | 10748/16329 [1:30:30<48:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10748: train loss 1.36510. lr 4.534028e-04:  66%|██████▌   | 10748/16329 [1:30:31<48:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10748: train loss 1.36510. lr 4.534028e-04:  66%|██████▌   | 10749/16329 [1:30:31<48:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10749: train loss 1.38523. lr 4.533780e-04:  66%|██████▌   | 10749/16329 [1:30:31<48:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10749: train loss 1.38523. lr 4.533780e-04:  66%|██████▌   | 10750/16329 [1:30:31<48:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10750: train loss 1.36118. lr 4.533532e-04:  66%|██████▌   | 10750/16329 [1:30:32<48:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10750: train loss 1.36118. lr 4.533532e-04:  66%|██████▌   | 10751/16329 [1:30:32<47:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10751: train loss 1.37197. lr 4.533284e-04:  66%|██████▌   | 10751/16329 [1:30:32<47:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10751: train loss 1.37197. lr 4.533284e-04:  66%|██████▌   | 10752/16329 [1:30:32<47:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10752: train loss 1.33917. lr 4.533036e-04:  66%|██████▌   | 10752/16329 [1:30:33<47:40,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10752: train loss 1.33917. lr 4.533036e-04:  66%|██████▌   | 10753/16329 [1:30:33<47:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10753: train loss 1.35931. lr 4.532788e-04:  66%|██████▌   | 10753/16329 [1:30:33<47:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10753: train loss 1.35931. lr 4.532788e-04:  66%|██████▌   | 10754/16329 [1:30:33<47:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10754: train loss 1.33647. lr 4.532540e-04:  66%|██████▌   | 10754/16329 [1:30:34<47:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10754: train loss 1.33647. lr 4.532540e-04:  66%|██████▌   | 10755/16329 [1:30:34<46:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10755: train loss 1.34624. lr 4.532292e-04:  66%|██████▌   | 10755/16329 [1:30:34<46:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10755: train loss 1.34624. lr 4.532292e-04:  66%|██████▌   | 10756/16329 [1:30:34<46:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10756: train loss 1.33890. lr 4.532044e-04:  66%|██████▌   | 10756/16329 [1:30:35<46:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10756: train loss 1.33890. lr 4.532044e-04:  66%|██████▌   | 10757/16329 [1:30:35<46:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10757: train loss 1.34261. lr 4.531795e-04:  66%|██████▌   | 10757/16329 [1:30:35<46:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10757: train loss 1.34261. lr 4.531795e-04:  66%|██████▌   | 10758/16329 [1:30:35<46:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10758: train loss 1.33075. lr 4.531547e-04:  66%|██████▌   | 10758/16329 [1:30:36<46:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10758: train loss 1.33075. lr 4.531547e-04:  66%|██████▌   | 10759/16329 [1:30:36<46:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10759: train loss 1.30557. lr 4.531299e-04:  66%|██████▌   | 10759/16329 [1:30:36<46:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10759: train loss 1.30557. lr 4.531299e-04:  66%|██████▌   | 10760/16329 [1:30:36<47:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10760: train loss 1.34720. lr 4.531051e-04:  66%|██████▌   | 10760/16329 [1:30:37<47:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10760: train loss 1.34720. lr 4.531051e-04:  66%|██████▌   | 10761/16329 [1:30:37<47:50,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10761: train loss 1.34718. lr 4.530803e-04:  66%|██████▌   | 10761/16329 [1:30:37<47:50,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10761: train loss 1.34718. lr 4.530803e-04:  66%|██████▌   | 10762/16329 [1:30:37<47:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10762: train loss 1.34432. lr 4.530555e-04:  66%|██████▌   | 10762/16329 [1:30:38<47:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10762: train loss 1.34432. lr 4.530555e-04:  66%|██████▌   | 10763/16329 [1:30:38<52:54,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 10763: train loss 1.35729. lr 4.530306e-04:  66%|██████▌   | 10763/16329 [1:30:38<52:54,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 10763: train loss 1.35729. lr 4.530306e-04:  66%|██████▌   | 10764/16329 [1:30:38<50:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10764: train loss 1.36261. lr 4.530058e-04:  66%|██████▌   | 10764/16329 [1:30:39<50:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10764: train loss 1.36261. lr 4.530058e-04:  66%|██████▌   | 10765/16329 [1:30:39<49:33,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10765: train loss 1.35050. lr 4.529810e-04:  66%|██████▌   | 10765/16329 [1:30:39<49:33,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10765: train loss 1.35050. lr 4.529810e-04:  66%|██████▌   | 10766/16329 [1:30:39<48:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10766: train loss 1.30711. lr 4.529562e-04:  66%|██████▌   | 10766/16329 [1:30:40<48:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10766: train loss 1.30711. lr 4.529562e-04:  66%|██████▌   | 10767/16329 [1:30:40<47:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10767: train loss 1.35478. lr 4.529313e-04:  66%|██████▌   | 10767/16329 [1:30:40<47:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10767: train loss 1.35478. lr 4.529313e-04:  66%|██████▌   | 10768/16329 [1:30:40<47:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10768: train loss 1.38061. lr 4.529065e-04:  66%|██████▌   | 10768/16329 [1:30:41<47:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10768: train loss 1.38061. lr 4.529065e-04:  66%|██████▌   | 10769/16329 [1:30:41<46:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10769: train loss 1.34626. lr 4.528817e-04:  66%|██████▌   | 10769/16329 [1:30:41<46:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10769: train loss 1.34626. lr 4.528817e-04:  66%|██████▌   | 10770/16329 [1:30:41<46:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10770: train loss 1.33345. lr 4.528568e-04:  66%|██████▌   | 10770/16329 [1:30:42<46:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10770: train loss 1.33345. lr 4.528568e-04:  66%|██████▌   | 10771/16329 [1:30:42<46:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10771: train loss 1.35103. lr 4.528320e-04:  66%|██████▌   | 10771/16329 [1:30:42<46:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10771: train loss 1.35103. lr 4.528320e-04:  66%|██████▌   | 10772/16329 [1:30:42<46:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10772: train loss 1.36886. lr 4.528072e-04:  66%|██████▌   | 10772/16329 [1:30:43<46:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10772: train loss 1.36886. lr 4.528072e-04:  66%|██████▌   | 10773/16329 [1:30:43<46:00,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10773: train loss 1.35911. lr 4.527823e-04:  66%|██████▌   | 10773/16329 [1:30:43<46:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10773: train loss 1.35911. lr 4.527823e-04:  66%|██████▌   | 10774/16329 [1:30:43<45:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10774: train loss 1.32303. lr 4.527575e-04:  66%|██████▌   | 10774/16329 [1:30:44<45:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10774: train loss 1.32303. lr 4.527575e-04:  66%|██████▌   | 10775/16329 [1:30:44<45:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10775: train loss 1.35416. lr 4.527326e-04:  66%|██████▌   | 10775/16329 [1:30:44<45:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10775: train loss 1.35416. lr 4.527326e-04:  66%|██████▌   | 10776/16329 [1:30:44<45:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10776: train loss 1.34916. lr 4.527078e-04:  66%|██████▌   | 10776/16329 [1:30:45<45:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10776: train loss 1.34916. lr 4.527078e-04:  66%|██████▌   | 10777/16329 [1:30:45<45:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10777: train loss 1.37738. lr 4.526830e-04:  66%|██████▌   | 10777/16329 [1:30:45<45:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10777: train loss 1.37738. lr 4.526830e-04:  66%|██████▌   | 10778/16329 [1:30:45<46:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10778: train loss 1.35516. lr 4.526581e-04:  66%|██████▌   | 10778/16329 [1:30:46<46:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10778: train loss 1.35516. lr 4.526581e-04:  66%|██████▌   | 10779/16329 [1:30:46<46:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10779: train loss 1.34560. lr 4.526333e-04:  66%|██████▌   | 10779/16329 [1:30:46<46:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10779: train loss 1.34560. lr 4.526333e-04:  66%|██████▌   | 10780/16329 [1:30:46<45:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10780: train loss 1.36540. lr 4.526084e-04:  66%|██████▌   | 10780/16329 [1:30:47<45:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10780: train loss 1.36540. lr 4.526084e-04:  66%|██████▌   | 10781/16329 [1:30:47<45:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10781: train loss 1.40060. lr 4.525836e-04:  66%|██████▌   | 10781/16329 [1:30:47<45:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10781: train loss 1.40060. lr 4.525836e-04:  66%|██████▌   | 10782/16329 [1:30:47<45:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10782: train loss 1.35653. lr 4.525587e-04:  66%|██████▌   | 10782/16329 [1:30:48<45:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10782: train loss 1.35653. lr 4.525587e-04:  66%|██████▌   | 10783/16329 [1:30:48<45:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10783: train loss 1.35599. lr 4.525339e-04:  66%|██████▌   | 10783/16329 [1:30:48<45:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10783: train loss 1.35599. lr 4.525339e-04:  66%|██████▌   | 10784/16329 [1:30:48<45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10784: train loss 1.33659. lr 4.525090e-04:  66%|██████▌   | 10784/16329 [1:30:49<45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10784: train loss 1.33659. lr 4.525090e-04:  66%|██████▌   | 10785/16329 [1:30:49<45:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10785: train loss 1.34536. lr 4.524842e-04:  66%|██████▌   | 10785/16329 [1:30:49<45:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10785: train loss 1.34536. lr 4.524842e-04:  66%|██████▌   | 10786/16329 [1:30:49<45:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10786: train loss 1.35375. lr 4.524593e-04:  66%|██████▌   | 10786/16329 [1:30:50<45:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10786: train loss 1.35375. lr 4.524593e-04:  66%|██████▌   | 10787/16329 [1:30:50<45:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10787: train loss 1.33349. lr 4.524345e-04:  66%|██████▌   | 10787/16329 [1:30:50<45:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10787: train loss 1.33349. lr 4.524345e-04:  66%|██████▌   | 10788/16329 [1:30:50<45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10788: train loss 1.35847. lr 4.524096e-04:  66%|██████▌   | 10788/16329 [1:30:51<45:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10788: train loss 1.35847. lr 4.524096e-04:  66%|██████▌   | 10789/16329 [1:30:51<45:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10789: train loss 1.31553. lr 4.523847e-04:  66%|██████▌   | 10789/16329 [1:30:51<45:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10789: train loss 1.31553. lr 4.523847e-04:  66%|██████▌   | 10790/16329 [1:30:51<50:49,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10790: train loss 1.35438. lr 4.523599e-04:  66%|██████▌   | 10790/16329 [1:30:52<50:49,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10790: train loss 1.35438. lr 4.523599e-04:  66%|██████▌   | 10791/16329 [1:30:52<49:21,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10791: train loss 1.33677. lr 4.523350e-04:  66%|██████▌   | 10791/16329 [1:30:52<49:21,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10791: train loss 1.33677. lr 4.523350e-04:  66%|██████▌   | 10792/16329 [1:30:52<48:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10792: train loss 1.32434. lr 4.523102e-04:  66%|██████▌   | 10792/16329 [1:30:53<48:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10792: train loss 1.32434. lr 4.523102e-04:  66%|██████▌   | 10793/16329 [1:30:53<47:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10793: train loss 1.36455. lr 4.522853e-04:  66%|██████▌   | 10793/16329 [1:30:53<47:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10793: train loss 1.36455. lr 4.522853e-04:  66%|██████▌   | 10794/16329 [1:30:53<46:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10794: train loss 1.33415. lr 4.522604e-04:  66%|██████▌   | 10794/16329 [1:30:54<46:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10794: train loss 1.33415. lr 4.522604e-04:  66%|██████▌   | 10795/16329 [1:30:54<46:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10795: train loss 1.31930. lr 4.522356e-04:  66%|██████▌   | 10795/16329 [1:30:54<46:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10795: train loss 1.31930. lr 4.522356e-04:  66%|██████▌   | 10796/16329 [1:30:54<46:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10796: train loss 1.41874. lr 4.522107e-04:  66%|██████▌   | 10796/16329 [1:30:55<46:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10796: train loss 1.41874. lr 4.522107e-04:  66%|██████▌   | 10797/16329 [1:30:55<46:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10797: train loss 1.36610. lr 4.521858e-04:  66%|██████▌   | 10797/16329 [1:30:55<46:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10797: train loss 1.36610. lr 4.521858e-04:  66%|██████▌   | 10798/16329 [1:30:55<45:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10798: train loss 1.31611. lr 4.521610e-04:  66%|██████▌   | 10798/16329 [1:30:56<45:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10798: train loss 1.31611. lr 4.521610e-04:  66%|██████▌   | 10799/16329 [1:30:56<45:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10799: train loss 1.35232. lr 4.521361e-04:  66%|██████▌   | 10799/16329 [1:30:56<45:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10799: train loss 1.35232. lr 4.521361e-04:  66%|██████▌   | 10800/16329 [1:30:56<45:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10800: train loss 1.34763. lr 4.521112e-04:  66%|██████▌   | 10800/16329 [1:30:57<45:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10800: train loss 1.34763. lr 4.521112e-04:  66%|██████▌   | 10801/16329 [1:30:57<45:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10801: train loss 1.32969. lr 4.520863e-04:  66%|██████▌   | 10801/16329 [1:30:57<45:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10801: train loss 1.32969. lr 4.520863e-04:  66%|██████▌   | 10802/16329 [1:30:57<45:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10802: train loss 1.34703. lr 4.520615e-04:  66%|██████▌   | 10802/16329 [1:30:58<45:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10802: train loss 1.34703. lr 4.520615e-04:  66%|██████▌   | 10803/16329 [1:30:58<45:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10803: train loss 1.36265. lr 4.520366e-04:  66%|██████▌   | 10803/16329 [1:30:58<45:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10803: train loss 1.36265. lr 4.520366e-04:  66%|██████▌   | 10804/16329 [1:30:58<45:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10804: train loss 1.35813. lr 4.520117e-04:  66%|██████▌   | 10804/16329 [1:30:59<45:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10804: train loss 1.35813. lr 4.520117e-04:  66%|██████▌   | 10805/16329 [1:30:59<45:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10805: train loss 1.32003. lr 4.519868e-04:  66%|██████▌   | 10805/16329 [1:30:59<45:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10805: train loss 1.32003. lr 4.519868e-04:  66%|██████▌   | 10806/16329 [1:30:59<47:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10806: train loss 1.33729. lr 4.519619e-04:  66%|██████▌   | 10806/16329 [1:31:00<47:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10806: train loss 1.33729. lr 4.519619e-04:  66%|██████▌   | 10807/16329 [1:31:00<47:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10807: train loss 1.30949. lr 4.519370e-04:  66%|██████▌   | 10807/16329 [1:31:00<47:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10807: train loss 1.30949. lr 4.519370e-04:  66%|██████▌   | 10808/16329 [1:31:00<47:38,  1.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10808: train loss 1.37666. lr 4.519122e-04:  66%|██████▌   | 10808/16329 [1:31:01<47:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10808: train loss 1.37666. lr 4.519122e-04:  66%|██████▌   | 10809/16329 [1:31:01<47:37,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10809: train loss 1.30956. lr 4.518873e-04:  66%|██████▌   | 10809/16329 [1:31:01<47:37,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10809: train loss 1.30956. lr 4.518873e-04:  66%|██████▌   | 10810/16329 [1:31:01<47:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10810: train loss 1.32163. lr 4.518624e-04:  66%|██████▌   | 10810/16329 [1:31:02<47:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10810: train loss 1.32163. lr 4.518624e-04:  66%|██████▌   | 10811/16329 [1:31:02<47:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10811: train loss 1.33886. lr 4.518375e-04:  66%|██████▌   | 10811/16329 [1:31:02<47:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10811: train loss 1.33886. lr 4.518375e-04:  66%|██████▌   | 10812/16329 [1:31:02<46:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10812: train loss 1.30643. lr 4.518126e-04:  66%|██████▌   | 10812/16329 [1:31:03<46:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10812: train loss 1.30643. lr 4.518126e-04:  66%|██████▌   | 10813/16329 [1:31:03<46:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10813: train loss 1.33652. lr 4.517877e-04:  66%|██████▌   | 10813/16329 [1:31:03<46:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10813: train loss 1.33652. lr 4.517877e-04:  66%|██████▌   | 10814/16329 [1:31:03<46:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10814: train loss 1.32505. lr 4.517628e-04:  66%|██████▌   | 10814/16329 [1:31:04<46:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10814: train loss 1.32505. lr 4.517628e-04:  66%|██████▌   | 10815/16329 [1:31:04<46:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10815: train loss 1.33977. lr 4.517379e-04:  66%|██████▌   | 10815/16329 [1:31:04<46:13,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10815: train loss 1.33977. lr 4.517379e-04:  66%|██████▌   | 10816/16329 [1:31:04<46:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10816: train loss 1.39028. lr 4.517130e-04:  66%|██████▌   | 10816/16329 [1:31:05<46:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10816: train loss 1.39028. lr 4.517130e-04:  66%|██████▌   | 10817/16329 [1:31:05<45:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10817: train loss 1.37147. lr 4.516881e-04:  66%|██████▌   | 10817/16329 [1:31:05<45:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10817: train loss 1.37147. lr 4.516881e-04:  66%|██████▋   | 10818/16329 [1:31:05<45:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10818: train loss 1.35752. lr 4.516632e-04:  66%|██████▋   | 10818/16329 [1:31:06<45:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10818: train loss 1.35752. lr 4.516632e-04:  66%|██████▋   | 10819/16329 [1:31:06<45:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10819: train loss 1.36947. lr 4.516383e-04:  66%|██████▋   | 10819/16329 [1:31:06<45:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10819: train loss 1.36947. lr 4.516383e-04:  66%|██████▋   | 10820/16329 [1:31:06<45:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10820: train loss 1.30855. lr 4.516134e-04:  66%|██████▋   | 10820/16329 [1:31:07<45:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10820: train loss 1.30855. lr 4.516134e-04:  66%|██████▋   | 10821/16329 [1:31:07<45:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10821: train loss 1.37015. lr 4.515885e-04:  66%|██████▋   | 10821/16329 [1:31:07<45:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10821: train loss 1.37015. lr 4.515885e-04:  66%|██████▋   | 10822/16329 [1:31:07<45:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10822: train loss 1.35619. lr 4.515636e-04:  66%|██████▋   | 10822/16329 [1:31:08<45:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10822: train loss 1.35619. lr 4.515636e-04:  66%|██████▋   | 10823/16329 [1:31:08<45:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10823: train loss 1.36091. lr 4.515387e-04:  66%|██████▋   | 10823/16329 [1:31:08<45:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10823: train loss 1.36091. lr 4.515387e-04:  66%|██████▋   | 10824/16329 [1:31:08<45:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10824: train loss 1.30459. lr 4.515138e-04:  66%|██████▋   | 10824/16329 [1:31:09<45:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10824: train loss 1.30459. lr 4.515138e-04:  66%|██████▋   | 10825/16329 [1:31:09<45:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10825: train loss 1.34861. lr 4.514889e-04:  66%|██████▋   | 10825/16329 [1:31:09<45:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10825: train loss 1.34861. lr 4.514889e-04:  66%|██████▋   | 10826/16329 [1:31:09<45:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10826: train loss 1.33723. lr 4.514640e-04:  66%|██████▋   | 10826/16329 [1:31:10<45:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10826: train loss 1.33723. lr 4.514640e-04:  66%|██████▋   | 10827/16329 [1:31:10<45:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10827: train loss 1.36281. lr 4.514391e-04:  66%|██████▋   | 10827/16329 [1:31:10<45:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10827: train loss 1.36281. lr 4.514391e-04:  66%|██████▋   | 10828/16329 [1:31:10<45:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10828: train loss 1.33157. lr 4.514141e-04:  66%|██████▋   | 10828/16329 [1:31:11<45:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10828: train loss 1.33157. lr 4.514141e-04:  66%|██████▋   | 10829/16329 [1:31:11<45:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10829: train loss 1.33680. lr 4.513892e-04:  66%|██████▋   | 10829/16329 [1:31:12<45:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10829: train loss 1.33680. lr 4.513892e-04:  66%|██████▋   | 10830/16329 [1:31:12<50:09,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 10830: train loss 1.30630. lr 4.513643e-04:  66%|██████▋   | 10830/16329 [1:31:12<50:09,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 10830: train loss 1.30630. lr 4.513643e-04:  66%|██████▋   | 10831/16329 [1:31:12<48:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10831: train loss 1.33478. lr 4.513394e-04:  66%|██████▋   | 10831/16329 [1:31:13<48:41,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10831: train loss 1.33478. lr 4.513394e-04:  66%|██████▋   | 10832/16329 [1:31:13<47:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10832: train loss 1.34460. lr 4.513145e-04:  66%|██████▋   | 10832/16329 [1:31:13<47:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10832: train loss 1.34460. lr 4.513145e-04:  66%|██████▋   | 10833/16329 [1:31:13<46:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10833: train loss 1.33505. lr 4.512896e-04:  66%|██████▋   | 10833/16329 [1:31:14<46:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10833: train loss 1.33505. lr 4.512896e-04:  66%|██████▋   | 10834/16329 [1:31:14<46:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10834: train loss 1.32075. lr 4.512646e-04:  66%|██████▋   | 10834/16329 [1:31:14<46:19,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10834: train loss 1.32075. lr 4.512646e-04:  66%|██████▋   | 10835/16329 [1:31:14<46:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10835: train loss 1.35448. lr 4.512397e-04:  66%|██████▋   | 10835/16329 [1:31:15<46:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10835: train loss 1.35448. lr 4.512397e-04:  66%|██████▋   | 10836/16329 [1:31:15<45:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10836: train loss 1.34436. lr 4.512148e-04:  66%|██████▋   | 10836/16329 [1:31:15<45:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10836: train loss 1.34436. lr 4.512148e-04:  66%|██████▋   | 10837/16329 [1:31:15<45:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10837: train loss 1.33242. lr 4.511899e-04:  66%|██████▋   | 10837/16329 [1:31:15<45:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10837: train loss 1.33242. lr 4.511899e-04:  66%|██████▋   | 10838/16329 [1:31:15<45:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10838: train loss 1.32717. lr 4.511649e-04:  66%|██████▋   | 10838/16329 [1:31:16<45:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10838: train loss 1.32717. lr 4.511649e-04:  66%|██████▋   | 10839/16329 [1:31:16<45:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10839: train loss 1.29590. lr 4.511400e-04:  66%|██████▋   | 10839/16329 [1:31:16<45:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10839: train loss 1.29590. lr 4.511400e-04:  66%|██████▋   | 10840/16329 [1:31:16<45:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10840: train loss 1.32266. lr 4.511151e-04:  66%|██████▋   | 10840/16329 [1:31:17<45:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10840: train loss 1.32266. lr 4.511151e-04:  66%|██████▋   | 10841/16329 [1:31:17<45:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10841: train loss 1.35352. lr 4.510901e-04:  66%|██████▋   | 10841/16329 [1:31:17<45:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10841: train loss 1.35352. lr 4.510901e-04:  66%|██████▋   | 10842/16329 [1:31:17<45:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10842: train loss 1.35161. lr 4.510652e-04:  66%|██████▋   | 10842/16329 [1:31:18<45:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10842: train loss 1.35161. lr 4.510652e-04:  66%|██████▋   | 10843/16329 [1:31:18<45:16,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10843: train loss 1.31889. lr 4.510403e-04:  66%|██████▋   | 10843/16329 [1:31:18<45:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10843: train loss 1.31889. lr 4.510403e-04:  66%|██████▋   | 10844/16329 [1:31:18<45:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10844: train loss 1.33020. lr 4.510153e-04:  66%|██████▋   | 10844/16329 [1:31:19<45:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10844: train loss 1.33020. lr 4.510153e-04:  66%|██████▋   | 10845/16329 [1:31:19<45:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10845: train loss 1.31181. lr 4.509904e-04:  66%|██████▋   | 10845/16329 [1:31:19<45:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10845: train loss 1.31181. lr 4.509904e-04:  66%|██████▋   | 10846/16329 [1:31:19<45:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10846: train loss 1.32344. lr 4.509655e-04:  66%|██████▋   | 10846/16329 [1:31:20<45:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10846: train loss 1.32344. lr 4.509655e-04:  66%|██████▋   | 10847/16329 [1:31:20<45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10847: train loss 1.33812. lr 4.509405e-04:  66%|██████▋   | 10847/16329 [1:31:20<45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10847: train loss 1.33812. lr 4.509405e-04:  66%|██████▋   | 10848/16329 [1:31:20<45:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10848: train loss 1.38416. lr 4.509156e-04:  66%|██████▋   | 10848/16329 [1:31:21<45:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10848: train loss 1.38416. lr 4.509156e-04:  66%|██████▋   | 10849/16329 [1:31:21<45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10849: train loss 1.36198. lr 4.508906e-04:  66%|██████▋   | 10849/16329 [1:31:21<45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10849: train loss 1.36198. lr 4.508906e-04:  66%|██████▋   | 10850/16329 [1:31:21<45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10850: train loss 1.38201. lr 4.508657e-04:  66%|██████▋   | 10850/16329 [1:31:22<45:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10850: train loss 1.38201. lr 4.508657e-04:  66%|██████▋   | 10851/16329 [1:31:22<45:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10851: train loss 1.37412. lr 4.508407e-04:  66%|██████▋   | 10851/16329 [1:31:22<45:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10851: train loss 1.37412. lr 4.508407e-04:  66%|██████▋   | 10852/16329 [1:31:22<45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10852: train loss 1.33835. lr 4.508158e-04:  66%|██████▋   | 10852/16329 [1:31:23<45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10852: train loss 1.33835. lr 4.508158e-04:  66%|██████▋   | 10853/16329 [1:31:23<45:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10853: train loss 1.30285. lr 4.507908e-04:  66%|██████▋   | 10853/16329 [1:31:23<45:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10853: train loss 1.30285. lr 4.507908e-04:  66%|██████▋   | 10854/16329 [1:31:23<45:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10854: train loss 1.35937. lr 4.507659e-04:  66%|██████▋   | 10854/16329 [1:31:24<45:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10854: train loss 1.35937. lr 4.507659e-04:  66%|██████▋   | 10855/16329 [1:31:24<45:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10855: train loss 1.36267. lr 4.507409e-04:  66%|██████▋   | 10855/16329 [1:31:24<45:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10855: train loss 1.36267. lr 4.507409e-04:  66%|██████▋   | 10856/16329 [1:31:24<45:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10856: train loss 1.34913. lr 4.507160e-04:  66%|██████▋   | 10856/16329 [1:31:25<45:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10856: train loss 1.34913. lr 4.507160e-04:  66%|██████▋   | 10857/16329 [1:31:25<45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10857: train loss 1.38058. lr 4.506910e-04:  66%|██████▋   | 10857/16329 [1:31:25<45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10857: train loss 1.38058. lr 4.506910e-04:  66%|██████▋   | 10858/16329 [1:31:25<45:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10858: train loss 1.35437. lr 4.506661e-04:  66%|██████▋   | 10858/16329 [1:31:26<45:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10858: train loss 1.35437. lr 4.506661e-04:  67%|██████▋   | 10859/16329 [1:31:26<45:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10859: train loss 1.38165. lr 4.506411e-04:  67%|██████▋   | 10859/16329 [1:31:26<45:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10859: train loss 1.38165. lr 4.506411e-04:  67%|██████▋   | 10860/16329 [1:31:26<45:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10860: train loss 1.33016. lr 4.506162e-04:  67%|██████▋   | 10860/16329 [1:31:27<45:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10860: train loss 1.33016. lr 4.506162e-04:  67%|██████▋   | 10861/16329 [1:31:27<45:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10861: train loss 1.31927. lr 4.505912e-04:  67%|██████▋   | 10861/16329 [1:31:27<45:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10861: train loss 1.31927. lr 4.505912e-04:  67%|██████▋   | 10862/16329 [1:31:27<45:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10862: train loss 1.34773. lr 4.505662e-04:  67%|██████▋   | 10862/16329 [1:31:28<45:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10862: train loss 1.34773. lr 4.505662e-04:  67%|██████▋   | 10863/16329 [1:31:28<45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10863: train loss 1.30417. lr 4.505413e-04:  67%|██████▋   | 10863/16329 [1:31:28<45:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10863: train loss 1.30417. lr 4.505413e-04:  67%|██████▋   | 10864/16329 [1:31:28<45:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10864: train loss 1.34614. lr 4.505163e-04:  67%|██████▋   | 10864/16329 [1:31:29<45:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10864: train loss 1.34614. lr 4.505163e-04:  67%|██████▋   | 10865/16329 [1:31:29<50:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10865: train loss 1.35122. lr 4.504913e-04:  67%|██████▋   | 10865/16329 [1:31:30<50:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10865: train loss 1.35122. lr 4.504913e-04:  67%|██████▋   | 10866/16329 [1:31:30<48:44,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10866: train loss 1.34066. lr 4.504664e-04:  67%|██████▋   | 10866/16329 [1:31:30<48:44,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10866: train loss 1.34066. lr 4.504664e-04:  67%|██████▋   | 10867/16329 [1:31:30<47:40,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10867: train loss 1.35022. lr 4.504414e-04:  67%|██████▋   | 10867/16329 [1:31:31<47:40,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10867: train loss 1.35022. lr 4.504414e-04:  67%|██████▋   | 10868/16329 [1:31:31<46:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10868: train loss 1.34616. lr 4.504164e-04:  67%|██████▋   | 10868/16329 [1:31:31<46:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10868: train loss 1.34616. lr 4.504164e-04:  67%|██████▋   | 10869/16329 [1:31:31<46:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10869: train loss 1.34944. lr 4.503915e-04:  67%|██████▋   | 10869/16329 [1:31:32<46:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10869: train loss 1.34944. lr 4.503915e-04:  67%|██████▋   | 10870/16329 [1:31:32<46:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10870: train loss 1.36804. lr 4.503665e-04:  67%|██████▋   | 10870/16329 [1:31:32<46:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10870: train loss 1.36804. lr 4.503665e-04:  67%|██████▋   | 10871/16329 [1:31:32<45:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10871: train loss 1.32821. lr 4.503415e-04:  67%|██████▋   | 10871/16329 [1:31:33<45:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10871: train loss 1.32821. lr 4.503415e-04:  67%|██████▋   | 10872/16329 [1:31:33<45:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10872: train loss 1.35245. lr 4.503165e-04:  67%|██████▋   | 10872/16329 [1:31:33<45:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10872: train loss 1.35245. lr 4.503165e-04:  67%|██████▋   | 10873/16329 [1:31:33<45:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10873: train loss 1.37027. lr 4.502916e-04:  67%|██████▋   | 10873/16329 [1:31:34<45:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10873: train loss 1.37027. lr 4.502916e-04:  67%|██████▋   | 10874/16329 [1:31:34<45:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10874: train loss 1.31257. lr 4.502666e-04:  67%|██████▋   | 10874/16329 [1:31:34<45:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10874: train loss 1.31257. lr 4.502666e-04:  67%|██████▋   | 10875/16329 [1:31:34<45:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10875: train loss 1.37397. lr 4.502416e-04:  67%|██████▋   | 10875/16329 [1:31:35<45:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10875: train loss 1.37397. lr 4.502416e-04:  67%|██████▋   | 10876/16329 [1:31:35<45:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10876: train loss 1.34545. lr 4.502166e-04:  67%|██████▋   | 10876/16329 [1:31:35<45:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10876: train loss 1.34545. lr 4.502166e-04:  67%|██████▋   | 10877/16329 [1:31:35<45:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10877: train loss 1.33538. lr 4.501916e-04:  67%|██████▋   | 10877/16329 [1:31:36<45:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10877: train loss 1.33538. lr 4.501916e-04:  67%|██████▋   | 10878/16329 [1:31:36<45:06,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10878: train loss 1.33060. lr 4.501667e-04:  67%|██████▋   | 10878/16329 [1:31:36<45:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10878: train loss 1.33060. lr 4.501667e-04:  67%|██████▋   | 10879/16329 [1:31:36<45:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10879: train loss 1.31984. lr 4.501417e-04:  67%|██████▋   | 10879/16329 [1:31:37<45:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10879: train loss 1.31984. lr 4.501417e-04:  67%|██████▋   | 10880/16329 [1:31:37<45:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10880: train loss 1.34706. lr 4.501167e-04:  67%|██████▋   | 10880/16329 [1:31:37<45:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10880: train loss 1.34706. lr 4.501167e-04:  67%|██████▋   | 10881/16329 [1:31:37<45:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10881: train loss 1.33200. lr 4.500917e-04:  67%|██████▋   | 10881/16329 [1:31:38<45:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10881: train loss 1.33200. lr 4.500917e-04:  67%|██████▋   | 10882/16329 [1:31:38<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10882: train loss 1.31574. lr 4.500667e-04:  67%|██████▋   | 10882/16329 [1:31:38<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10882: train loss 1.31574. lr 4.500667e-04:  67%|██████▋   | 10883/16329 [1:31:38<45:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10883: train loss 1.33139. lr 4.500417e-04:  67%|██████▋   | 10883/16329 [1:31:38<45:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10883: train loss 1.33139. lr 4.500417e-04:  67%|██████▋   | 10884/16329 [1:31:39<45:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10884: train loss 1.34755. lr 4.500167e-04:  67%|██████▋   | 10884/16329 [1:31:39<45:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10884: train loss 1.34755. lr 4.500167e-04:  67%|██████▋   | 10885/16329 [1:31:39<45:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10885: train loss 1.37444. lr 4.499917e-04:  67%|██████▋   | 10885/16329 [1:31:39<45:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10885: train loss 1.37444. lr 4.499917e-04:  67%|██████▋   | 10886/16329 [1:31:39<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10886: train loss 1.31002. lr 4.499667e-04:  67%|██████▋   | 10886/16329 [1:31:40<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10886: train loss 1.31002. lr 4.499667e-04:  67%|██████▋   | 10887/16329 [1:31:40<45:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10887: train loss 1.33590. lr 4.499417e-04:  67%|██████▋   | 10887/16329 [1:31:40<45:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10887: train loss 1.33590. lr 4.499417e-04:  67%|██████▋   | 10888/16329 [1:31:40<45:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10888: train loss 1.33057. lr 4.499167e-04:  67%|██████▋   | 10888/16329 [1:31:41<45:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10888: train loss 1.33057. lr 4.499167e-04:  67%|██████▋   | 10889/16329 [1:31:41<45:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10889: train loss 1.31453. lr 4.498917e-04:  67%|██████▋   | 10889/16329 [1:31:42<45:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10889: train loss 1.31453. lr 4.498917e-04:  67%|██████▋   | 10890/16329 [1:31:42<49:47,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10890: train loss 1.30144. lr 4.498667e-04:  67%|██████▋   | 10890/16329 [1:31:42<49:47,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10890: train loss 1.30144. lr 4.498667e-04:  67%|██████▋   | 10891/16329 [1:31:42<48:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10891: train loss 1.35482. lr 4.498417e-04:  67%|██████▋   | 10891/16329 [1:31:43<48:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10891: train loss 1.35482. lr 4.498417e-04:  67%|██████▋   | 10892/16329 [1:31:43<47:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10892: train loss 1.34704. lr 4.498167e-04:  67%|██████▋   | 10892/16329 [1:31:43<47:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 10892: train loss 1.34704. lr 4.498167e-04:  67%|██████▋   | 10893/16329 [1:31:43<46:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10893: train loss 1.36079. lr 4.497917e-04:  67%|██████▋   | 10893/16329 [1:31:44<46:39,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10893: train loss 1.36079. lr 4.497917e-04:  67%|██████▋   | 10894/16329 [1:31:44<46:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10894: train loss 1.35120. lr 4.497667e-04:  67%|██████▋   | 10894/16329 [1:31:44<46:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10894: train loss 1.35120. lr 4.497667e-04:  67%|██████▋   | 10895/16329 [1:31:44<45:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10895: train loss 1.36292. lr 4.497417e-04:  67%|██████▋   | 10895/16329 [1:31:45<45:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10895: train loss 1.36292. lr 4.497417e-04:  67%|██████▋   | 10896/16329 [1:31:45<45:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10896: train loss 1.36145. lr 4.497167e-04:  67%|██████▋   | 10896/16329 [1:31:45<45:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10896: train loss 1.36145. lr 4.497167e-04:  67%|██████▋   | 10897/16329 [1:31:45<45:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10897: train loss 1.37517. lr 4.496917e-04:  67%|██████▋   | 10897/16329 [1:31:46<45:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10897: train loss 1.37517. lr 4.496917e-04:  67%|██████▋   | 10898/16329 [1:31:46<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10898: train loss 1.34364. lr 4.496667e-04:  67%|██████▋   | 10898/16329 [1:31:46<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10898: train loss 1.34364. lr 4.496667e-04:  67%|██████▋   | 10899/16329 [1:31:46<45:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10899: train loss 1.34445. lr 4.496417e-04:  67%|██████▋   | 10899/16329 [1:31:47<45:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10899: train loss 1.34445. lr 4.496417e-04:  67%|██████▋   | 10900/16329 [1:31:47<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10900: train loss 1.29149. lr 4.496167e-04:  67%|██████▋   | 10900/16329 [1:31:47<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10900: train loss 1.29149. lr 4.496167e-04:  67%|██████▋   | 10901/16329 [1:31:47<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10901: train loss 1.31239. lr 4.495916e-04:  67%|██████▋   | 10901/16329 [1:31:48<45:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10901: train loss 1.31239. lr 4.495916e-04:  67%|██████▋   | 10902/16329 [1:31:48<45:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10902: train loss 1.33523. lr 4.495666e-04:  67%|██████▋   | 10902/16329 [1:31:48<45:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10902: train loss 1.33523. lr 4.495666e-04:  67%|██████▋   | 10903/16329 [1:31:48<44:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10903: train loss 1.34473. lr 4.495416e-04:  67%|██████▋   | 10903/16329 [1:31:49<44:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10903: train loss 1.34473. lr 4.495416e-04:  67%|██████▋   | 10904/16329 [1:31:49<45:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10904: train loss 1.30932. lr 4.495166e-04:  67%|██████▋   | 10904/16329 [1:31:49<45:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10904: train loss 1.30932. lr 4.495166e-04:  67%|██████▋   | 10905/16329 [1:31:49<44:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10905: train loss 1.34185. lr 4.494916e-04:  67%|██████▋   | 10905/16329 [1:31:50<44:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10905: train loss 1.34185. lr 4.494916e-04:  67%|██████▋   | 10906/16329 [1:31:50<44:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10906: train loss 1.34623. lr 4.494665e-04:  67%|██████▋   | 10906/16329 [1:31:50<44:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10906: train loss 1.34623. lr 4.494665e-04:  67%|██████▋   | 10907/16329 [1:31:50<44:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10907: train loss 1.35249. lr 4.494415e-04:  67%|██████▋   | 10907/16329 [1:31:51<44:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10907: train loss 1.35249. lr 4.494415e-04:  67%|██████▋   | 10908/16329 [1:31:51<44:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10908: train loss 1.30609. lr 4.494165e-04:  67%|██████▋   | 10908/16329 [1:31:51<44:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10908: train loss 1.30609. lr 4.494165e-04:  67%|██████▋   | 10909/16329 [1:31:51<45:53,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10909: train loss 1.31629. lr 4.493915e-04:  67%|██████▋   | 10909/16329 [1:31:52<45:53,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10909: train loss 1.31629. lr 4.493915e-04:  67%|██████▋   | 10910/16329 [1:31:52<46:47,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10910: train loss 1.32286. lr 4.493664e-04:  67%|██████▋   | 10910/16329 [1:31:52<46:47,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10910: train loss 1.32286. lr 4.493664e-04:  67%|██████▋   | 10911/16329 [1:31:52<47:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10911: train loss 1.34532. lr 4.493414e-04:  67%|██████▋   | 10911/16329 [1:31:53<47:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10911: train loss 1.34532. lr 4.493414e-04:  67%|██████▋   | 10912/16329 [1:31:53<47:00,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10912: train loss 1.33284. lr 4.493164e-04:  67%|██████▋   | 10912/16329 [1:31:53<47:00,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10912: train loss 1.33284. lr 4.493164e-04:  67%|██████▋   | 10913/16329 [1:31:53<46:52,  1.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10913: train loss 1.32256. lr 4.492914e-04:  67%|██████▋   | 10913/16329 [1:31:54<46:52,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10913: train loss 1.32256. lr 4.492914e-04:  67%|██████▋   | 10914/16329 [1:31:54<46:42,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10914: train loss 1.32822. lr 4.492663e-04:  67%|██████▋   | 10914/16329 [1:31:54<46:42,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10914: train loss 1.32822. lr 4.492663e-04:  67%|██████▋   | 10915/16329 [1:31:54<46:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10915: train loss 1.30623. lr 4.492413e-04:  67%|██████▋   | 10915/16329 [1:31:55<46:26,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10915: train loss 1.30623. lr 4.492413e-04:  67%|██████▋   | 10916/16329 [1:31:55<46:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10916: train loss 1.29473. lr 4.492162e-04:  67%|██████▋   | 10916/16329 [1:31:55<46:12,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10916: train loss 1.29473. lr 4.492162e-04:  67%|██████▋   | 10917/16329 [1:31:55<50:46,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 10917: train loss 1.31160. lr 4.491912e-04:  67%|██████▋   | 10917/16329 [1:31:56<50:46,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 10917: train loss 1.31160. lr 4.491912e-04:  67%|██████▋   | 10918/16329 [1:31:56<49:04,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 10918: train loss 1.34525. lr 4.491662e-04:  67%|██████▋   | 10918/16329 [1:31:56<49:04,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 10918: train loss 1.34525. lr 4.491662e-04:  67%|██████▋   | 10919/16329 [1:31:56<47:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10919: train loss 1.29715. lr 4.491411e-04:  67%|██████▋   | 10919/16329 [1:31:57<47:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 10919: train loss 1.29715. lr 4.491411e-04:  67%|██████▋   | 10920/16329 [1:31:57<46:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10920: train loss 1.36848. lr 4.491161e-04:  67%|██████▋   | 10920/16329 [1:31:57<46:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10920: train loss 1.36848. lr 4.491161e-04:  67%|██████▋   | 10921/16329 [1:31:57<46:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10921: train loss 1.31896. lr 4.490910e-04:  67%|██████▋   | 10921/16329 [1:31:58<46:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10921: train loss 1.31896. lr 4.490910e-04:  67%|██████▋   | 10922/16329 [1:31:58<46:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10922: train loss 1.31297. lr 4.490660e-04:  67%|██████▋   | 10922/16329 [1:31:58<46:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10922: train loss 1.31297. lr 4.490660e-04:  67%|██████▋   | 10923/16329 [1:31:58<46:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10923: train loss 1.36251. lr 4.490410e-04:  67%|██████▋   | 10923/16329 [1:31:59<46:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10923: train loss 1.36251. lr 4.490410e-04:  67%|██████▋   | 10924/16329 [1:31:59<45:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10924: train loss 1.32628. lr 4.490159e-04:  67%|██████▋   | 10924/16329 [1:31:59<45:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10924: train loss 1.32628. lr 4.490159e-04:  67%|██████▋   | 10925/16329 [1:31:59<45:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10925: train loss 1.31774. lr 4.489909e-04:  67%|██████▋   | 10925/16329 [1:32:00<45:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10925: train loss 1.31774. lr 4.489909e-04:  67%|██████▋   | 10926/16329 [1:32:00<45:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10926: train loss 1.35145. lr 4.489658e-04:  67%|██████▋   | 10926/16329 [1:32:00<45:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10926: train loss 1.35145. lr 4.489658e-04:  67%|██████▋   | 10927/16329 [1:32:00<45:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10927: train loss 1.32315. lr 4.489408e-04:  67%|██████▋   | 10927/16329 [1:32:01<45:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10927: train loss 1.32315. lr 4.489408e-04:  67%|██████▋   | 10928/16329 [1:32:01<45:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10928: train loss 1.30638. lr 4.489157e-04:  67%|██████▋   | 10928/16329 [1:32:01<45:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10928: train loss 1.30638. lr 4.489157e-04:  67%|██████▋   | 10929/16329 [1:32:01<44:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10929: train loss 1.31325. lr 4.488906e-04:  67%|██████▋   | 10929/16329 [1:32:02<44:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10929: train loss 1.31325. lr 4.488906e-04:  67%|██████▋   | 10930/16329 [1:32:02<44:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10930: train loss 1.32846. lr 4.488656e-04:  67%|██████▋   | 10930/16329 [1:32:02<44:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10930: train loss 1.32846. lr 4.488656e-04:  67%|██████▋   | 10931/16329 [1:32:02<44:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10931: train loss 1.30044. lr 4.488405e-04:  67%|██████▋   | 10931/16329 [1:32:03<44:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10931: train loss 1.30044. lr 4.488405e-04:  67%|██████▋   | 10932/16329 [1:32:03<44:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10932: train loss 1.31352. lr 4.488155e-04:  67%|██████▋   | 10932/16329 [1:32:03<44:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10932: train loss 1.31352. lr 4.488155e-04:  67%|██████▋   | 10933/16329 [1:32:03<44:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10933: train loss 1.29968. lr 4.487904e-04:  67%|██████▋   | 10933/16329 [1:32:04<44:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10933: train loss 1.29968. lr 4.487904e-04:  67%|██████▋   | 10934/16329 [1:32:04<44:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10934: train loss 1.33854. lr 4.487654e-04:  67%|██████▋   | 10934/16329 [1:32:04<44:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10934: train loss 1.33854. lr 4.487654e-04:  67%|██████▋   | 10935/16329 [1:32:04<44:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10935: train loss 1.32516. lr 4.487403e-04:  67%|██████▋   | 10935/16329 [1:32:05<44:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10935: train loss 1.32516. lr 4.487403e-04:  67%|██████▋   | 10936/16329 [1:32:05<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10936: train loss 1.30767. lr 4.487152e-04:  67%|██████▋   | 10936/16329 [1:32:05<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10936: train loss 1.30767. lr 4.487152e-04:  67%|██████▋   | 10937/16329 [1:32:05<44:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10937: train loss 1.37287. lr 4.486902e-04:  67%|██████▋   | 10937/16329 [1:32:06<44:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10937: train loss 1.37287. lr 4.486902e-04:  67%|██████▋   | 10938/16329 [1:32:06<44:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10938: train loss 1.32215. lr 4.486651e-04:  67%|██████▋   | 10938/16329 [1:32:06<44:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10938: train loss 1.32215. lr 4.486651e-04:  67%|██████▋   | 10939/16329 [1:32:06<44:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10939: train loss 1.29618. lr 4.486400e-04:  67%|██████▋   | 10939/16329 [1:32:07<44:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10939: train loss 1.29618. lr 4.486400e-04:  67%|██████▋   | 10940/16329 [1:32:07<44:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10940: train loss 1.34113. lr 4.486150e-04:  67%|██████▋   | 10940/16329 [1:32:07<44:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10940: train loss 1.34113. lr 4.486150e-04:  67%|██████▋   | 10941/16329 [1:32:07<44:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10941: train loss 1.30713. lr 4.485899e-04:  67%|██████▋   | 10941/16329 [1:32:08<44:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10941: train loss 1.30713. lr 4.485899e-04:  67%|██████▋   | 10942/16329 [1:32:08<44:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10942: train loss 1.32925. lr 4.485648e-04:  67%|██████▋   | 10942/16329 [1:32:08<44:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10942: train loss 1.32925. lr 4.485648e-04:  67%|██████▋   | 10943/16329 [1:32:08<44:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10943: train loss 1.35746. lr 4.485397e-04:  67%|██████▋   | 10943/16329 [1:32:09<44:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10943: train loss 1.35746. lr 4.485397e-04:  67%|██████▋   | 10944/16329 [1:32:09<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10944: train loss 1.36423. lr 4.485147e-04:  67%|██████▋   | 10944/16329 [1:32:09<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10944: train loss 1.36423. lr 4.485147e-04:  67%|██████▋   | 10945/16329 [1:32:09<44:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10945: train loss 1.34209. lr 4.484896e-04:  67%|██████▋   | 10945/16329 [1:32:10<44:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10945: train loss 1.34209. lr 4.484896e-04:  67%|██████▋   | 10946/16329 [1:32:10<44:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10946: train loss 1.33469. lr 4.484645e-04:  67%|██████▋   | 10946/16329 [1:32:10<44:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10946: train loss 1.33469. lr 4.484645e-04:  67%|██████▋   | 10947/16329 [1:32:10<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10947: train loss 1.32385. lr 4.484394e-04:  67%|██████▋   | 10947/16329 [1:32:11<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10947: train loss 1.32385. lr 4.484394e-04:  67%|██████▋   | 10948/16329 [1:32:11<44:30,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10948: train loss 1.31536. lr 4.484144e-04:  67%|██████▋   | 10948/16329 [1:32:11<44:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10948: train loss 1.31536. lr 4.484144e-04:  67%|██████▋   | 10949/16329 [1:32:11<44:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10949: train loss 1.32938. lr 4.483893e-04:  67%|██████▋   | 10949/16329 [1:32:12<44:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10949: train loss 1.32938. lr 4.483893e-04:  67%|██████▋   | 10950/16329 [1:32:12<44:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10950: train loss 1.32029. lr 4.483642e-04:  67%|██████▋   | 10950/16329 [1:32:12<44:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10950: train loss 1.32029. lr 4.483642e-04:  67%|██████▋   | 10951/16329 [1:32:12<44:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10951: train loss 1.32221. lr 4.483391e-04:  67%|██████▋   | 10951/16329 [1:32:13<44:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10951: train loss 1.32221. lr 4.483391e-04:  67%|██████▋   | 10952/16329 [1:32:13<44:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10952: train loss 1.32350. lr 4.483140e-04:  67%|██████▋   | 10952/16329 [1:32:13<44:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10952: train loss 1.32350. lr 4.483140e-04:  67%|██████▋   | 10953/16329 [1:32:13<44:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10953: train loss 1.32188. lr 4.482889e-04:  67%|██████▋   | 10953/16329 [1:32:14<44:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10953: train loss 1.32188. lr 4.482889e-04:  67%|██████▋   | 10954/16329 [1:32:14<44:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10954: train loss 1.34357. lr 4.482638e-04:  67%|██████▋   | 10954/16329 [1:32:14<44:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10954: train loss 1.34357. lr 4.482638e-04:  67%|██████▋   | 10955/16329 [1:32:14<44:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10955: train loss 1.32236. lr 4.482388e-04:  67%|██████▋   | 10955/16329 [1:32:15<44:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10955: train loss 1.32236. lr 4.482388e-04:  67%|██████▋   | 10956/16329 [1:32:15<46:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10956: train loss 1.31421. lr 4.482137e-04:  67%|██████▋   | 10956/16329 [1:32:16<46:30,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 10956: train loss 1.31421. lr 4.482137e-04:  67%|██████▋   | 10957/16329 [1:32:16<52:13,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 10957: train loss 1.34480. lr 4.481886e-04:  67%|██████▋   | 10957/16329 [1:32:16<52:13,  1.71it/s]\u001b[A\n",
      "epoch 1 iter 10957: train loss 1.34480. lr 4.481886e-04:  67%|██████▋   | 10958/16329 [1:32:16<51:02,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 10958: train loss 1.31326. lr 4.481635e-04:  67%|██████▋   | 10958/16329 [1:32:17<51:02,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 10958: train loss 1.31326. lr 4.481635e-04:  67%|██████▋   | 10959/16329 [1:32:17<49:54,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 10959: train loss 1.35301. lr 4.481384e-04:  67%|██████▋   | 10959/16329 [1:32:17<49:54,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 10959: train loss 1.35301. lr 4.481384e-04:  67%|██████▋   | 10960/16329 [1:32:17<48:47,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 10960: train loss 1.32132. lr 4.481133e-04:  67%|██████▋   | 10960/16329 [1:32:18<48:47,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 10960: train loss 1.32132. lr 4.481133e-04:  67%|██████▋   | 10961/16329 [1:32:18<47:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10961: train loss 1.35519. lr 4.480882e-04:  67%|██████▋   | 10961/16329 [1:32:18<47:54,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10961: train loss 1.35519. lr 4.480882e-04:  67%|██████▋   | 10962/16329 [1:32:18<47:07,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10962: train loss 1.34789. lr 4.480631e-04:  67%|██████▋   | 10962/16329 [1:32:19<47:07,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 10962: train loss 1.34789. lr 4.480631e-04:  67%|██████▋   | 10963/16329 [1:32:19<46:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10963: train loss 1.34286. lr 4.480380e-04:  67%|██████▋   | 10963/16329 [1:32:19<46:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10963: train loss 1.34286. lr 4.480380e-04:  67%|██████▋   | 10964/16329 [1:32:19<45:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10964: train loss 1.30862. lr 4.480129e-04:  67%|██████▋   | 10964/16329 [1:32:20<45:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 10964: train loss 1.30862. lr 4.480129e-04:  67%|██████▋   | 10965/16329 [1:32:20<45:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10965: train loss 1.32993. lr 4.479878e-04:  67%|██████▋   | 10965/16329 [1:32:20<45:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10965: train loss 1.32993. lr 4.479878e-04:  67%|██████▋   | 10966/16329 [1:32:20<45:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10966: train loss 1.31655. lr 4.479627e-04:  67%|██████▋   | 10966/16329 [1:32:21<45:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10966: train loss 1.31655. lr 4.479627e-04:  67%|██████▋   | 10967/16329 [1:32:21<44:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10967: train loss 1.33973. lr 4.479376e-04:  67%|██████▋   | 10967/16329 [1:32:21<44:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10967: train loss 1.33973. lr 4.479376e-04:  67%|██████▋   | 10968/16329 [1:32:21<44:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10968: train loss 1.34766. lr 4.479125e-04:  67%|██████▋   | 10968/16329 [1:32:22<44:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10968: train loss 1.34766. lr 4.479125e-04:  67%|██████▋   | 10969/16329 [1:32:22<44:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10969: train loss 1.32120. lr 4.478873e-04:  67%|██████▋   | 10969/16329 [1:32:22<44:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10969: train loss 1.32120. lr 4.478873e-04:  67%|██████▋   | 10970/16329 [1:32:22<44:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10970: train loss 1.36271. lr 4.478622e-04:  67%|██████▋   | 10970/16329 [1:32:23<44:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10970: train loss 1.36271. lr 4.478622e-04:  67%|██████▋   | 10971/16329 [1:32:23<44:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10971: train loss 1.32165. lr 4.478371e-04:  67%|██████▋   | 10971/16329 [1:32:23<44:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10971: train loss 1.32165. lr 4.478371e-04:  67%|██████▋   | 10972/16329 [1:32:23<44:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10972: train loss 1.36765. lr 4.478120e-04:  67%|██████▋   | 10972/16329 [1:32:24<44:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 10972: train loss 1.36765. lr 4.478120e-04:  67%|██████▋   | 10973/16329 [1:32:24<44:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10973: train loss 1.32703. lr 4.477869e-04:  67%|██████▋   | 10973/16329 [1:32:24<44:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10973: train loss 1.32703. lr 4.477869e-04:  67%|██████▋   | 10974/16329 [1:32:24<44:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10974: train loss 1.30763. lr 4.477618e-04:  67%|██████▋   | 10974/16329 [1:32:25<44:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10974: train loss 1.30763. lr 4.477618e-04:  67%|██████▋   | 10975/16329 [1:32:25<44:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10975: train loss 1.37452. lr 4.477367e-04:  67%|██████▋   | 10975/16329 [1:32:25<44:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10975: train loss 1.37452. lr 4.477367e-04:  67%|██████▋   | 10976/16329 [1:32:25<43:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10976: train loss 1.31035. lr 4.477115e-04:  67%|██████▋   | 10976/16329 [1:32:26<43:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 10976: train loss 1.31035. lr 4.477115e-04:  67%|██████▋   | 10977/16329 [1:32:26<44:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10977: train loss 1.31678. lr 4.476864e-04:  67%|██████▋   | 10977/16329 [1:32:26<44:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10977: train loss 1.31678. lr 4.476864e-04:  67%|██████▋   | 10978/16329 [1:32:26<44:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10978: train loss 1.32512. lr 4.476613e-04:  67%|██████▋   | 10978/16329 [1:32:27<44:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10978: train loss 1.32512. lr 4.476613e-04:  67%|██████▋   | 10979/16329 [1:32:27<44:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10979: train loss 1.32840. lr 4.476362e-04:  67%|██████▋   | 10979/16329 [1:32:27<44:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10979: train loss 1.32840. lr 4.476362e-04:  67%|██████▋   | 10980/16329 [1:32:27<44:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10980: train loss 1.29153. lr 4.476111e-04:  67%|██████▋   | 10980/16329 [1:32:28<44:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10980: train loss 1.29153. lr 4.476111e-04:  67%|██████▋   | 10981/16329 [1:32:28<44:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10981: train loss 1.37146. lr 4.475859e-04:  67%|██████▋   | 10981/16329 [1:32:28<44:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 10981: train loss 1.37146. lr 4.475859e-04:  67%|██████▋   | 10982/16329 [1:32:28<45:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10982: train loss 1.32643. lr 4.475608e-04:  67%|██████▋   | 10982/16329 [1:32:29<45:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10982: train loss 1.32643. lr 4.475608e-04:  67%|██████▋   | 10983/16329 [1:32:29<45:29,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 10983: train loss 1.36662. lr 4.475357e-04:  67%|██████▋   | 10983/16329 [1:32:29<45:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10983: train loss 1.36662. lr 4.475357e-04:  67%|██████▋   | 10984/16329 [1:32:29<45:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10984: train loss 1.32683. lr 4.475105e-04:  67%|██████▋   | 10984/16329 [1:32:30<45:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10984: train loss 1.32683. lr 4.475105e-04:  67%|██████▋   | 10985/16329 [1:32:30<45:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10985: train loss 1.34501. lr 4.474854e-04:  67%|██████▋   | 10985/16329 [1:32:30<45:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 10985: train loss 1.34501. lr 4.474854e-04:  67%|██████▋   | 10986/16329 [1:32:30<45:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10986: train loss 1.32526. lr 4.474603e-04:  67%|██████▋   | 10986/16329 [1:32:31<45:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10986: train loss 1.32526. lr 4.474603e-04:  67%|██████▋   | 10987/16329 [1:32:31<45:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10987: train loss 1.33811. lr 4.474351e-04:  67%|██████▋   | 10987/16329 [1:32:31<45:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10987: train loss 1.33811. lr 4.474351e-04:  67%|██████▋   | 10988/16329 [1:32:31<44:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10988: train loss 1.28750. lr 4.474100e-04:  67%|██████▋   | 10988/16329 [1:32:32<44:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10988: train loss 1.28750. lr 4.474100e-04:  67%|██████▋   | 10989/16329 [1:32:32<44:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10989: train loss 1.35125. lr 4.473849e-04:  67%|██████▋   | 10989/16329 [1:32:32<44:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10989: train loss 1.35125. lr 4.473849e-04:  67%|██████▋   | 10990/16329 [1:32:32<44:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10990: train loss 1.34264. lr 4.473597e-04:  67%|██████▋   | 10990/16329 [1:32:33<44:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10990: train loss 1.34264. lr 4.473597e-04:  67%|██████▋   | 10991/16329 [1:32:33<44:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10991: train loss 1.32113. lr 4.473346e-04:  67%|██████▋   | 10991/16329 [1:32:33<44:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10991: train loss 1.32113. lr 4.473346e-04:  67%|██████▋   | 10992/16329 [1:32:33<49:00,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10992: train loss 1.30800. lr 4.473095e-04:  67%|██████▋   | 10992/16329 [1:32:34<49:00,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 10992: train loss 1.30800. lr 4.473095e-04:  67%|██████▋   | 10993/16329 [1:32:34<47:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10993: train loss 1.32036. lr 4.472843e-04:  67%|██████▋   | 10993/16329 [1:32:34<47:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 10993: train loss 1.32036. lr 4.472843e-04:  67%|██████▋   | 10994/16329 [1:32:34<46:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10994: train loss 1.31422. lr 4.472592e-04:  67%|██████▋   | 10994/16329 [1:32:35<46:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 10994: train loss 1.31422. lr 4.472592e-04:  67%|██████▋   | 10995/16329 [1:32:35<45:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10995: train loss 1.28656. lr 4.472340e-04:  67%|██████▋   | 10995/16329 [1:32:35<45:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 10995: train loss 1.28656. lr 4.472340e-04:  67%|██████▋   | 10996/16329 [1:32:35<45:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10996: train loss 1.35606. lr 4.472089e-04:  67%|██████▋   | 10996/16329 [1:32:36<45:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 10996: train loss 1.35606. lr 4.472089e-04:  67%|██████▋   | 10997/16329 [1:32:36<44:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10997: train loss 1.33731. lr 4.471837e-04:  67%|██████▋   | 10997/16329 [1:32:36<44:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 10997: train loss 1.33731. lr 4.471837e-04:  67%|██████▋   | 10998/16329 [1:32:36<44:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10998: train loss 1.30182. lr 4.471586e-04:  67%|██████▋   | 10998/16329 [1:32:37<44:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 10998: train loss 1.30182. lr 4.471586e-04:  67%|██████▋   | 10999/16329 [1:32:37<44:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10999: train loss 1.33831. lr 4.471334e-04:  67%|██████▋   | 10999/16329 [1:32:37<44:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 10999: train loss 1.33831. lr 4.471334e-04:  67%|██████▋   | 11000/16329 [1:32:37<46:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11000: train loss 1.33448. lr 4.471083e-04:  67%|██████▋   | 11000/16329 [1:32:38<46:08,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11000: train loss 1.33448. lr 4.471083e-04:  67%|██████▋   | 11001/16329 [1:32:38<47:20,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11001: train loss 1.30232. lr 4.470831e-04:  67%|██████▋   | 11001/16329 [1:32:39<47:20,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11001: train loss 1.30232. lr 4.470831e-04:  67%|██████▋   | 11002/16329 [1:32:39<47:45,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11002: train loss 1.34507. lr 4.470580e-04:  67%|██████▋   | 11002/16329 [1:32:39<47:45,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11002: train loss 1.34507. lr 4.470580e-04:  67%|██████▋   | 11003/16329 [1:32:39<47:38,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11003: train loss 1.32234. lr 4.470328e-04:  67%|██████▋   | 11003/16329 [1:32:40<47:38,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11003: train loss 1.32234. lr 4.470328e-04:  67%|██████▋   | 11004/16329 [1:32:40<47:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11004: train loss 1.32197. lr 4.470077e-04:  67%|██████▋   | 11004/16329 [1:32:40<47:18,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11004: train loss 1.32197. lr 4.470077e-04:  67%|██████▋   | 11005/16329 [1:32:40<46:50,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11005: train loss 1.31669. lr 4.469825e-04:  67%|██████▋   | 11005/16329 [1:32:41<46:50,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11005: train loss 1.31669. lr 4.469825e-04:  67%|██████▋   | 11006/16329 [1:32:41<46:18,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11006: train loss 1.33798. lr 4.469573e-04:  67%|██████▋   | 11006/16329 [1:32:41<46:18,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11006: train loss 1.33798. lr 4.469573e-04:  67%|██████▋   | 11007/16329 [1:32:41<45:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11007: train loss 1.34906. lr 4.469322e-04:  67%|██████▋   | 11007/16329 [1:32:42<45:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11007: train loss 1.34906. lr 4.469322e-04:  67%|██████▋   | 11008/16329 [1:32:42<45:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11008: train loss 1.35785. lr 4.469070e-04:  67%|██████▋   | 11008/16329 [1:32:42<45:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11008: train loss 1.35785. lr 4.469070e-04:  67%|██████▋   | 11009/16329 [1:32:42<44:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11009: train loss 1.29984. lr 4.468819e-04:  67%|██████▋   | 11009/16329 [1:32:43<44:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11009: train loss 1.29984. lr 4.468819e-04:  67%|██████▋   | 11010/16329 [1:32:43<44:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11010: train loss 1.29830. lr 4.468567e-04:  67%|██████▋   | 11010/16329 [1:32:43<44:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11010: train loss 1.29830. lr 4.468567e-04:  67%|██████▋   | 11011/16329 [1:32:43<44:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11011: train loss 1.33688. lr 4.468315e-04:  67%|██████▋   | 11011/16329 [1:32:44<44:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11011: train loss 1.33688. lr 4.468315e-04:  67%|██████▋   | 11012/16329 [1:32:44<44:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11012: train loss 1.33233. lr 4.468064e-04:  67%|██████▋   | 11012/16329 [1:32:44<44:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11012: train loss 1.33233. lr 4.468064e-04:  67%|██████▋   | 11013/16329 [1:32:44<44:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11013: train loss 1.29700. lr 4.467812e-04:  67%|██████▋   | 11013/16329 [1:32:45<44:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11013: train loss 1.29700. lr 4.467812e-04:  67%|██████▋   | 11014/16329 [1:32:45<44:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11014: train loss 1.33859. lr 4.467560e-04:  67%|██████▋   | 11014/16329 [1:32:45<44:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11014: train loss 1.33859. lr 4.467560e-04:  67%|██████▋   | 11015/16329 [1:32:45<44:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11015: train loss 1.32523. lr 4.467308e-04:  67%|██████▋   | 11015/16329 [1:32:46<44:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11015: train loss 1.32523. lr 4.467308e-04:  67%|██████▋   | 11016/16329 [1:32:46<43:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11016: train loss 1.35222. lr 4.467057e-04:  67%|██████▋   | 11016/16329 [1:32:46<43:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11016: train loss 1.35222. lr 4.467057e-04:  67%|██████▋   | 11017/16329 [1:32:46<48:38,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11017: train loss 1.32199. lr 4.466805e-04:  67%|██████▋   | 11017/16329 [1:32:47<48:38,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11017: train loss 1.32199. lr 4.466805e-04:  67%|██████▋   | 11018/16329 [1:32:47<47:10,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11018: train loss 1.31541. lr 4.466553e-04:  67%|██████▋   | 11018/16329 [1:32:47<47:10,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11018: train loss 1.31541. lr 4.466553e-04:  67%|██████▋   | 11019/16329 [1:32:47<46:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11019: train loss 1.33697. lr 4.466301e-04:  67%|██████▋   | 11019/16329 [1:32:48<46:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11019: train loss 1.33697. lr 4.466301e-04:  67%|██████▋   | 11020/16329 [1:32:48<45:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11020: train loss 1.38006. lr 4.466050e-04:  67%|██████▋   | 11020/16329 [1:32:48<45:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11020: train loss 1.38006. lr 4.466050e-04:  67%|██████▋   | 11021/16329 [1:32:48<44:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11021: train loss 1.33705. lr 4.465798e-04:  67%|██████▋   | 11021/16329 [1:32:49<44:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11021: train loss 1.33705. lr 4.465798e-04:  67%|██████▋   | 11022/16329 [1:32:49<44:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11022: train loss 1.32598. lr 4.465546e-04:  67%|██████▋   | 11022/16329 [1:32:49<44:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11022: train loss 1.32598. lr 4.465546e-04:  68%|██████▊   | 11023/16329 [1:32:49<44:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11023: train loss 1.32859. lr 4.465294e-04:  68%|██████▊   | 11023/16329 [1:32:50<44:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11023: train loss 1.32859. lr 4.465294e-04:  68%|██████▊   | 11024/16329 [1:32:50<44:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11024: train loss 1.30989. lr 4.465042e-04:  68%|██████▊   | 11024/16329 [1:32:50<44:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11024: train loss 1.30989. lr 4.465042e-04:  68%|██████▊   | 11025/16329 [1:32:50<44:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11025: train loss 1.31654. lr 4.464790e-04:  68%|██████▊   | 11025/16329 [1:32:51<44:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11025: train loss 1.31654. lr 4.464790e-04:  68%|██████▊   | 11026/16329 [1:32:51<43:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11026: train loss 1.33371. lr 4.464539e-04:  68%|██████▊   | 11026/16329 [1:32:51<43:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11026: train loss 1.33371. lr 4.464539e-04:  68%|██████▊   | 11027/16329 [1:32:51<43:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11027: train loss 1.31009. lr 4.464287e-04:  68%|██████▊   | 11027/16329 [1:32:52<43:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11027: train loss 1.31009. lr 4.464287e-04:  68%|██████▊   | 11028/16329 [1:32:52<43:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11028: train loss 1.31024. lr 4.464035e-04:  68%|██████▊   | 11028/16329 [1:32:52<43:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11028: train loss 1.31024. lr 4.464035e-04:  68%|██████▊   | 11029/16329 [1:32:52<43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11029: train loss 1.35113. lr 4.463783e-04:  68%|██████▊   | 11029/16329 [1:32:53<43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11029: train loss 1.35113. lr 4.463783e-04:  68%|██████▊   | 11030/16329 [1:32:53<43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11030: train loss 1.32374. lr 4.463531e-04:  68%|██████▊   | 11030/16329 [1:32:53<43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11030: train loss 1.32374. lr 4.463531e-04:  68%|██████▊   | 11031/16329 [1:32:53<43:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11031: train loss 1.32852. lr 4.463279e-04:  68%|██████▊   | 11031/16329 [1:32:54<43:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11031: train loss 1.32852. lr 4.463279e-04:  68%|██████▊   | 11032/16329 [1:32:54<43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11032: train loss 1.35842. lr 4.463027e-04:  68%|██████▊   | 11032/16329 [1:32:54<43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11032: train loss 1.35842. lr 4.463027e-04:  68%|██████▊   | 11033/16329 [1:32:54<43:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11033: train loss 1.34541. lr 4.462775e-04:  68%|██████▊   | 11033/16329 [1:32:55<43:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11033: train loss 1.34541. lr 4.462775e-04:  68%|██████▊   | 11034/16329 [1:32:55<43:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11034: train loss 1.33655. lr 4.462523e-04:  68%|██████▊   | 11034/16329 [1:32:55<43:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11034: train loss 1.33655. lr 4.462523e-04:  68%|██████▊   | 11035/16329 [1:32:55<43:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11035: train loss 1.28808. lr 4.462271e-04:  68%|██████▊   | 11035/16329 [1:32:56<43:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11035: train loss 1.28808. lr 4.462271e-04:  68%|██████▊   | 11036/16329 [1:32:56<43:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11036: train loss 1.34293. lr 4.462019e-04:  68%|██████▊   | 11036/16329 [1:32:56<43:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11036: train loss 1.34293. lr 4.462019e-04:  68%|██████▊   | 11037/16329 [1:32:56<43:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11037: train loss 1.33937. lr 4.461767e-04:  68%|██████▊   | 11037/16329 [1:32:57<43:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11037: train loss 1.33937. lr 4.461767e-04:  68%|██████▊   | 11038/16329 [1:32:57<43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11038: train loss 1.32668. lr 4.461515e-04:  68%|██████▊   | 11038/16329 [1:32:57<43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11038: train loss 1.32668. lr 4.461515e-04:  68%|██████▊   | 11039/16329 [1:32:57<43:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11039: train loss 1.33962. lr 4.461263e-04:  68%|██████▊   | 11039/16329 [1:32:58<43:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11039: train loss 1.33962. lr 4.461263e-04:  68%|██████▊   | 11040/16329 [1:32:58<43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11040: train loss 1.34169. lr 4.461011e-04:  68%|██████▊   | 11040/16329 [1:32:58<43:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11040: train loss 1.34169. lr 4.461011e-04:  68%|██████▊   | 11041/16329 [1:32:58<43:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11041: train loss 1.35580. lr 4.460759e-04:  68%|██████▊   | 11041/16329 [1:32:59<43:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11041: train loss 1.35580. lr 4.460759e-04:  68%|██████▊   | 11042/16329 [1:32:59<43:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11042: train loss 1.33060. lr 4.460507e-04:  68%|██████▊   | 11042/16329 [1:32:59<43:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11042: train loss 1.33060. lr 4.460507e-04:  68%|██████▊   | 11043/16329 [1:32:59<43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11043: train loss 1.32470. lr 4.460255e-04:  68%|██████▊   | 11043/16329 [1:33:00<43:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11043: train loss 1.32470. lr 4.460255e-04:  68%|██████▊   | 11044/16329 [1:33:00<49:02,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 11044: train loss 1.31615. lr 4.460003e-04:  68%|██████▊   | 11044/16329 [1:33:00<49:02,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 11044: train loss 1.31615. lr 4.460003e-04:  68%|██████▊   | 11045/16329 [1:33:00<47:19,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11045: train loss 1.27708. lr 4.459750e-04:  68%|██████▊   | 11045/16329 [1:33:01<47:19,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11045: train loss 1.27708. lr 4.459750e-04:  68%|██████▊   | 11046/16329 [1:33:01<46:05,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11046: train loss 1.32482. lr 4.459498e-04:  68%|██████▊   | 11046/16329 [1:33:01<46:05,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11046: train loss 1.32482. lr 4.459498e-04:  68%|██████▊   | 11047/16329 [1:33:01<45:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11047: train loss 1.32983. lr 4.459246e-04:  68%|██████▊   | 11047/16329 [1:33:02<45:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11047: train loss 1.32983. lr 4.459246e-04:  68%|██████▊   | 11048/16329 [1:33:02<44:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11048: train loss 1.35768. lr 4.458994e-04:  68%|██████▊   | 11048/16329 [1:33:02<44:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11048: train loss 1.35768. lr 4.458994e-04:  68%|██████▊   | 11049/16329 [1:33:02<44:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11049: train loss 1.32173. lr 4.458742e-04:  68%|██████▊   | 11049/16329 [1:33:03<44:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11049: train loss 1.32173. lr 4.458742e-04:  68%|██████▊   | 11050/16329 [1:33:03<43:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11050: train loss 1.35248. lr 4.458490e-04:  68%|██████▊   | 11050/16329 [1:33:03<43:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11050: train loss 1.35248. lr 4.458490e-04:  68%|██████▊   | 11051/16329 [1:33:03<43:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11051: train loss 1.33834. lr 4.458237e-04:  68%|██████▊   | 11051/16329 [1:33:04<43:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11051: train loss 1.33834. lr 4.458237e-04:  68%|██████▊   | 11052/16329 [1:33:04<43:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11052: train loss 1.33722. lr 4.457985e-04:  68%|██████▊   | 11052/16329 [1:33:04<43:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11052: train loss 1.33722. lr 4.457985e-04:  68%|██████▊   | 11053/16329 [1:33:04<43:31,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11053: train loss 1.29391. lr 4.457733e-04:  68%|██████▊   | 11053/16329 [1:33:05<43:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11053: train loss 1.29391. lr 4.457733e-04:  68%|██████▊   | 11054/16329 [1:33:05<43:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11054: train loss 1.30710. lr 4.457481e-04:  68%|██████▊   | 11054/16329 [1:33:05<43:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11054: train loss 1.30710. lr 4.457481e-04:  68%|██████▊   | 11055/16329 [1:33:05<43:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11055: train loss 1.30059. lr 4.457228e-04:  68%|██████▊   | 11055/16329 [1:33:06<43:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11055: train loss 1.30059. lr 4.457228e-04:  68%|██████▊   | 11056/16329 [1:33:06<43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11056: train loss 1.32898. lr 4.456976e-04:  68%|██████▊   | 11056/16329 [1:33:06<43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11056: train loss 1.32898. lr 4.456976e-04:  68%|██████▊   | 11057/16329 [1:33:06<43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11057: train loss 1.30734. lr 4.456724e-04:  68%|██████▊   | 11057/16329 [1:33:07<43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11057: train loss 1.30734. lr 4.456724e-04:  68%|██████▊   | 11058/16329 [1:33:07<43:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11058: train loss 1.28885. lr 4.456472e-04:  68%|██████▊   | 11058/16329 [1:33:07<43:18,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11058: train loss 1.28885. lr 4.456472e-04:  68%|██████▊   | 11059/16329 [1:33:07<43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11059: train loss 1.31254. lr 4.456219e-04:  68%|██████▊   | 11059/16329 [1:33:08<43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11059: train loss 1.31254. lr 4.456219e-04:  68%|██████▊   | 11060/16329 [1:33:08<43:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11060: train loss 1.34297. lr 4.455967e-04:  68%|██████▊   | 11060/16329 [1:33:08<43:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11060: train loss 1.34297. lr 4.455967e-04:  68%|██████▊   | 11061/16329 [1:33:08<43:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11061: train loss 1.31030. lr 4.455715e-04:  68%|██████▊   | 11061/16329 [1:33:09<43:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11061: train loss 1.31030. lr 4.455715e-04:  68%|██████▊   | 11062/16329 [1:33:09<43:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11062: train loss 1.33548. lr 4.455462e-04:  68%|██████▊   | 11062/16329 [1:33:09<43:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11062: train loss 1.33548. lr 4.455462e-04:  68%|██████▊   | 11063/16329 [1:33:09<43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11063: train loss 1.33514. lr 4.455210e-04:  68%|██████▊   | 11063/16329 [1:33:10<43:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11063: train loss 1.33514. lr 4.455210e-04:  68%|██████▊   | 11064/16329 [1:33:10<43:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11064: train loss 1.32713. lr 4.454958e-04:  68%|██████▊   | 11064/16329 [1:33:10<43:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11064: train loss 1.32713. lr 4.454958e-04:  68%|██████▊   | 11065/16329 [1:33:10<43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11065: train loss 1.33675. lr 4.454705e-04:  68%|██████▊   | 11065/16329 [1:33:11<43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11065: train loss 1.33675. lr 4.454705e-04:  68%|██████▊   | 11066/16329 [1:33:11<43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11066: train loss 1.33250. lr 4.454453e-04:  68%|██████▊   | 11066/16329 [1:33:11<43:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11066: train loss 1.33250. lr 4.454453e-04:  68%|██████▊   | 11067/16329 [1:33:11<43:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11067: train loss 1.29928. lr 4.454200e-04:  68%|██████▊   | 11067/16329 [1:33:12<43:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11067: train loss 1.29928. lr 4.454200e-04:  68%|██████▊   | 11068/16329 [1:33:12<43:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11068: train loss 1.33663. lr 4.453948e-04:  68%|██████▊   | 11068/16329 [1:33:12<43:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11068: train loss 1.33663. lr 4.453948e-04:  68%|██████▊   | 11069/16329 [1:33:12<43:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11069: train loss 1.30364. lr 4.453695e-04:  68%|██████▊   | 11069/16329 [1:33:13<43:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11069: train loss 1.30364. lr 4.453695e-04:  68%|██████▊   | 11070/16329 [1:33:13<43:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11070: train loss 1.30682. lr 4.453443e-04:  68%|██████▊   | 11070/16329 [1:33:13<43:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11070: train loss 1.30682. lr 4.453443e-04:  68%|██████▊   | 11071/16329 [1:33:13<43:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11071: train loss 1.34044. lr 4.453190e-04:  68%|██████▊   | 11071/16329 [1:33:14<43:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11071: train loss 1.34044. lr 4.453190e-04:  68%|██████▊   | 11072/16329 [1:33:14<43:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11072: train loss 1.33088. lr 4.452938e-04:  68%|██████▊   | 11072/16329 [1:33:14<43:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11072: train loss 1.33088. lr 4.452938e-04:  68%|██████▊   | 11073/16329 [1:33:14<43:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11073: train loss 1.29712. lr 4.452685e-04:  68%|██████▊   | 11073/16329 [1:33:15<43:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11073: train loss 1.29712. lr 4.452685e-04:  68%|██████▊   | 11074/16329 [1:33:15<44:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11074: train loss 1.35846. lr 4.452433e-04:  68%|██████▊   | 11074/16329 [1:33:15<44:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11074: train loss 1.35846. lr 4.452433e-04:  68%|██████▊   | 11075/16329 [1:33:15<44:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11075: train loss 1.34233. lr 4.452180e-04:  68%|██████▊   | 11075/16329 [1:33:16<44:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11075: train loss 1.34233. lr 4.452180e-04:  68%|██████▊   | 11076/16329 [1:33:16<44:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11076: train loss 1.33400. lr 4.451928e-04:  68%|██████▊   | 11076/16329 [1:33:16<44:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11076: train loss 1.33400. lr 4.451928e-04:  68%|██████▊   | 11077/16329 [1:33:16<44:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11077: train loss 1.32301. lr 4.451675e-04:  68%|██████▊   | 11077/16329 [1:33:17<44:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11077: train loss 1.32301. lr 4.451675e-04:  68%|██████▊   | 11078/16329 [1:33:17<44:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11078: train loss 1.30789. lr 4.451423e-04:  68%|██████▊   | 11078/16329 [1:33:17<44:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11078: train loss 1.30789. lr 4.451423e-04:  68%|██████▊   | 11079/16329 [1:33:17<44:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11079: train loss 1.34159. lr 4.451170e-04:  68%|██████▊   | 11079/16329 [1:33:18<44:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11079: train loss 1.34159. lr 4.451170e-04:  68%|██████▊   | 11080/16329 [1:33:18<44:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11080: train loss 1.31842. lr 4.450918e-04:  68%|██████▊   | 11080/16329 [1:33:18<44:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11080: train loss 1.31842. lr 4.450918e-04:  68%|██████▊   | 11081/16329 [1:33:18<43:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11081: train loss 1.34143. lr 4.450665e-04:  68%|██████▊   | 11081/16329 [1:33:19<43:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11081: train loss 1.34143. lr 4.450665e-04:  68%|██████▊   | 11082/16329 [1:33:19<43:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11082: train loss 1.34259. lr 4.450412e-04:  68%|██████▊   | 11082/16329 [1:33:19<43:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11082: train loss 1.34259. lr 4.450412e-04:  68%|██████▊   | 11083/16329 [1:33:19<43:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11083: train loss 1.28905. lr 4.450160e-04:  68%|██████▊   | 11083/16329 [1:33:20<43:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11083: train loss 1.28905. lr 4.450160e-04:  68%|██████▊   | 11084/16329 [1:33:20<48:32,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 11084: train loss 1.31907. lr 4.449907e-04:  68%|██████▊   | 11084/16329 [1:33:20<48:32,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 11084: train loss 1.31907. lr 4.449907e-04:  68%|██████▊   | 11085/16329 [1:33:20<46:57,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11085: train loss 1.36322. lr 4.449654e-04:  68%|██████▊   | 11085/16329 [1:33:21<46:57,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11085: train loss 1.36322. lr 4.449654e-04:  68%|██████▊   | 11086/16329 [1:33:21<45:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11086: train loss 1.29663. lr 4.449402e-04:  68%|██████▊   | 11086/16329 [1:33:21<45:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11086: train loss 1.29663. lr 4.449402e-04:  68%|██████▊   | 11087/16329 [1:33:21<45:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11087: train loss 1.31951. lr 4.449149e-04:  68%|██████▊   | 11087/16329 [1:33:22<45:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11087: train loss 1.31951. lr 4.449149e-04:  68%|██████▊   | 11088/16329 [1:33:22<44:31,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11088: train loss 1.31611. lr 4.448896e-04:  68%|██████▊   | 11088/16329 [1:33:22<44:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11088: train loss 1.31611. lr 4.448896e-04:  68%|██████▊   | 11089/16329 [1:33:22<44:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11089: train loss 1.30944. lr 4.448644e-04:  68%|██████▊   | 11089/16329 [1:33:23<44:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11089: train loss 1.30944. lr 4.448644e-04:  68%|██████▊   | 11090/16329 [1:33:23<43:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11090: train loss 1.30666. lr 4.448391e-04:  68%|██████▊   | 11090/16329 [1:33:23<43:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11090: train loss 1.30666. lr 4.448391e-04:  68%|██████▊   | 11091/16329 [1:33:23<43:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11091: train loss 1.31804. lr 4.448138e-04:  68%|██████▊   | 11091/16329 [1:33:24<43:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11091: train loss 1.31804. lr 4.448138e-04:  68%|██████▊   | 11092/16329 [1:33:24<43:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11092: train loss 1.29498. lr 4.447885e-04:  68%|██████▊   | 11092/16329 [1:33:24<43:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11092: train loss 1.29498. lr 4.447885e-04:  68%|██████▊   | 11093/16329 [1:33:24<43:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11093: train loss 1.35035. lr 4.447633e-04:  68%|██████▊   | 11093/16329 [1:33:25<43:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11093: train loss 1.35035. lr 4.447633e-04:  68%|██████▊   | 11094/16329 [1:33:25<43:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11094: train loss 1.32232. lr 4.447380e-04:  68%|██████▊   | 11094/16329 [1:33:25<43:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11094: train loss 1.32232. lr 4.447380e-04:  68%|██████▊   | 11095/16329 [1:33:25<43:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11095: train loss 1.34141. lr 4.447127e-04:  68%|██████▊   | 11095/16329 [1:33:26<43:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11095: train loss 1.34141. lr 4.447127e-04:  68%|██████▊   | 11096/16329 [1:33:26<43:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11096: train loss 1.32616. lr 4.446874e-04:  68%|██████▊   | 11096/16329 [1:33:26<43:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11096: train loss 1.32616. lr 4.446874e-04:  68%|██████▊   | 11097/16329 [1:33:26<43:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11097: train loss 1.34733. lr 4.446621e-04:  68%|██████▊   | 11097/16329 [1:33:27<43:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11097: train loss 1.34733. lr 4.446621e-04:  68%|██████▊   | 11098/16329 [1:33:27<43:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11098: train loss 1.34335. lr 4.446368e-04:  68%|██████▊   | 11098/16329 [1:33:27<43:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11098: train loss 1.34335. lr 4.446368e-04:  68%|██████▊   | 11099/16329 [1:33:27<43:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11099: train loss 1.34267. lr 4.446116e-04:  68%|██████▊   | 11099/16329 [1:33:28<43:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11099: train loss 1.34267. lr 4.446116e-04:  68%|██████▊   | 11100/16329 [1:33:28<43:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11100: train loss 1.30476. lr 4.445863e-04:  68%|██████▊   | 11100/16329 [1:33:28<43:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11100: train loss 1.30476. lr 4.445863e-04:  68%|██████▊   | 11101/16329 [1:33:28<43:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11101: train loss 1.33669. lr 4.445610e-04:  68%|██████▊   | 11101/16329 [1:33:29<43:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11101: train loss 1.33669. lr 4.445610e-04:  68%|██████▊   | 11102/16329 [1:33:29<43:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11102: train loss 1.36354. lr 4.445357e-04:  68%|██████▊   | 11102/16329 [1:33:29<43:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11102: train loss 1.36354. lr 4.445357e-04:  68%|██████▊   | 11103/16329 [1:33:29<43:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11103: train loss 1.32036. lr 4.445104e-04:  68%|██████▊   | 11103/16329 [1:33:30<43:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11103: train loss 1.32036. lr 4.445104e-04:  68%|██████▊   | 11104/16329 [1:33:30<43:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11104: train loss 1.33417. lr 4.444851e-04:  68%|██████▊   | 11104/16329 [1:33:30<43:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11104: train loss 1.33417. lr 4.444851e-04:  68%|██████▊   | 11105/16329 [1:33:30<43:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11105: train loss 1.31051. lr 4.444598e-04:  68%|██████▊   | 11105/16329 [1:33:31<43:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11105: train loss 1.31051. lr 4.444598e-04:  68%|██████▊   | 11106/16329 [1:33:31<44:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11106: train loss 1.32783. lr 4.444345e-04:  68%|██████▊   | 11106/16329 [1:33:31<44:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11106: train loss 1.32783. lr 4.444345e-04:  68%|██████▊   | 11107/16329 [1:33:31<44:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11107: train loss 1.30946. lr 4.444092e-04:  68%|██████▊   | 11107/16329 [1:33:32<44:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11107: train loss 1.30946. lr 4.444092e-04:  68%|██████▊   | 11108/16329 [1:33:32<44:53,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11108: train loss 1.30513. lr 4.443839e-04:  68%|██████▊   | 11108/16329 [1:33:32<44:53,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11108: train loss 1.30513. lr 4.443839e-04:  68%|██████▊   | 11109/16329 [1:33:32<44:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11109: train loss 1.33678. lr 4.443586e-04:  68%|██████▊   | 11109/16329 [1:33:33<44:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11109: train loss 1.33678. lr 4.443586e-04:  68%|██████▊   | 11110/16329 [1:33:33<44:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11110: train loss 1.33088. lr 4.443333e-04:  68%|██████▊   | 11110/16329 [1:33:33<44:38,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11110: train loss 1.33088. lr 4.443333e-04:  68%|██████▊   | 11111/16329 [1:33:33<44:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11111: train loss 1.29637. lr 4.443080e-04:  68%|██████▊   | 11111/16329 [1:33:34<44:26,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11111: train loss 1.29637. lr 4.443080e-04:  68%|██████▊   | 11112/16329 [1:33:34<44:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11112: train loss 1.28820. lr 4.442827e-04:  68%|██████▊   | 11112/16329 [1:33:34<44:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11112: train loss 1.28820. lr 4.442827e-04:  68%|██████▊   | 11113/16329 [1:33:34<44:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11113: train loss 1.27582. lr 4.442574e-04:  68%|██████▊   | 11113/16329 [1:33:35<44:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11113: train loss 1.27582. lr 4.442574e-04:  68%|██████▊   | 11114/16329 [1:33:35<43:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11114: train loss 1.31917. lr 4.442321e-04:  68%|██████▊   | 11114/16329 [1:33:35<43:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11114: train loss 1.31917. lr 4.442321e-04:  68%|██████▊   | 11115/16329 [1:33:35<43:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11115: train loss 1.31912. lr 4.442068e-04:  68%|██████▊   | 11115/16329 [1:33:36<43:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11115: train loss 1.31912. lr 4.442068e-04:  68%|██████▊   | 11116/16329 [1:33:36<43:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11116: train loss 1.32542. lr 4.441815e-04:  68%|██████▊   | 11116/16329 [1:33:36<43:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11116: train loss 1.32542. lr 4.441815e-04:  68%|██████▊   | 11117/16329 [1:33:36<43:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11117: train loss 1.36719. lr 4.441562e-04:  68%|██████▊   | 11117/16329 [1:33:37<43:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11117: train loss 1.36719. lr 4.441562e-04:  68%|██████▊   | 11118/16329 [1:33:37<43:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11118: train loss 1.28628. lr 4.441309e-04:  68%|██████▊   | 11118/16329 [1:33:38<43:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11118: train loss 1.28628. lr 4.441309e-04:  68%|██████▊   | 11119/16329 [1:33:38<48:02,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11119: train loss 1.32458. lr 4.441056e-04:  68%|██████▊   | 11119/16329 [1:33:38<48:02,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11119: train loss 1.32458. lr 4.441056e-04:  68%|██████▊   | 11120/16329 [1:33:38<46:18,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11120: train loss 1.31502. lr 4.440803e-04:  68%|██████▊   | 11120/16329 [1:33:39<46:18,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11120: train loss 1.31502. lr 4.440803e-04:  68%|██████▊   | 11121/16329 [1:33:39<45:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11121: train loss 1.30181. lr 4.440549e-04:  68%|██████▊   | 11121/16329 [1:33:39<45:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11121: train loss 1.30181. lr 4.440549e-04:  68%|██████▊   | 11122/16329 [1:33:39<44:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11122: train loss 1.29066. lr 4.440296e-04:  68%|██████▊   | 11122/16329 [1:33:40<44:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11122: train loss 1.29066. lr 4.440296e-04:  68%|██████▊   | 11123/16329 [1:33:40<44:08,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11123: train loss 1.32516. lr 4.440043e-04:  68%|██████▊   | 11123/16329 [1:33:40<44:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11123: train loss 1.32516. lr 4.440043e-04:  68%|██████▊   | 11124/16329 [1:33:40<43:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11124: train loss 1.31255. lr 4.439790e-04:  68%|██████▊   | 11124/16329 [1:33:41<43:44,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11124: train loss 1.31255. lr 4.439790e-04:  68%|██████▊   | 11125/16329 [1:33:41<43:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11125: train loss 1.34573. lr 4.439537e-04:  68%|██████▊   | 11125/16329 [1:33:41<43:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11125: train loss 1.34573. lr 4.439537e-04:  68%|██████▊   | 11126/16329 [1:33:41<43:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11126: train loss 1.29459. lr 4.439284e-04:  68%|██████▊   | 11126/16329 [1:33:42<43:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11126: train loss 1.29459. lr 4.439284e-04:  68%|██████▊   | 11127/16329 [1:33:42<43:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11127: train loss 1.34939. lr 4.439030e-04:  68%|██████▊   | 11127/16329 [1:33:42<43:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11127: train loss 1.34939. lr 4.439030e-04:  68%|██████▊   | 11128/16329 [1:33:42<43:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11128: train loss 1.29149. lr 4.438777e-04:  68%|██████▊   | 11128/16329 [1:33:43<43:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11128: train loss 1.29149. lr 4.438777e-04:  68%|██████▊   | 11129/16329 [1:33:43<42:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11129: train loss 1.28982. lr 4.438524e-04:  68%|██████▊   | 11129/16329 [1:33:43<42:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11129: train loss 1.28982. lr 4.438524e-04:  68%|██████▊   | 11130/16329 [1:33:43<42:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11130: train loss 1.32175. lr 4.438271e-04:  68%|██████▊   | 11130/16329 [1:33:44<42:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11130: train loss 1.32175. lr 4.438271e-04:  68%|██████▊   | 11131/16329 [1:33:44<42:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11131: train loss 1.30839. lr 4.438017e-04:  68%|██████▊   | 11131/16329 [1:33:44<42:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11131: train loss 1.30839. lr 4.438017e-04:  68%|██████▊   | 11132/16329 [1:33:44<42:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11132: train loss 1.28575. lr 4.437764e-04:  68%|██████▊   | 11132/16329 [1:33:45<42:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11132: train loss 1.28575. lr 4.437764e-04:  68%|██████▊   | 11133/16329 [1:33:45<42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11133: train loss 1.31173. lr 4.437511e-04:  68%|██████▊   | 11133/16329 [1:33:45<42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11133: train loss 1.31173. lr 4.437511e-04:  68%|██████▊   | 11134/16329 [1:33:45<42:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11134: train loss 1.30562. lr 4.437257e-04:  68%|██████▊   | 11134/16329 [1:33:46<42:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11134: train loss 1.30562. lr 4.437257e-04:  68%|██████▊   | 11135/16329 [1:33:46<43:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11135: train loss 1.29417. lr 4.437004e-04:  68%|██████▊   | 11135/16329 [1:33:46<43:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11135: train loss 1.29417. lr 4.437004e-04:  68%|██████▊   | 11136/16329 [1:33:46<42:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11136: train loss 1.31130. lr 4.436751e-04:  68%|██████▊   | 11136/16329 [1:33:47<42:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11136: train loss 1.31130. lr 4.436751e-04:  68%|██████▊   | 11137/16329 [1:33:47<42:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11137: train loss 1.33518. lr 4.436497e-04:  68%|██████▊   | 11137/16329 [1:33:47<42:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11137: train loss 1.33518. lr 4.436497e-04:  68%|██████▊   | 11138/16329 [1:33:47<42:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11138: train loss 1.34804. lr 4.436244e-04:  68%|██████▊   | 11138/16329 [1:33:48<42:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11138: train loss 1.34804. lr 4.436244e-04:  68%|██████▊   | 11139/16329 [1:33:48<42:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11139: train loss 1.31694. lr 4.435991e-04:  68%|██████▊   | 11139/16329 [1:33:48<42:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11139: train loss 1.31694. lr 4.435991e-04:  68%|██████▊   | 11140/16329 [1:33:48<42:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11140: train loss 1.31786. lr 4.435737e-04:  68%|██████▊   | 11140/16329 [1:33:49<42:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11140: train loss 1.31786. lr 4.435737e-04:  68%|██████▊   | 11141/16329 [1:33:49<42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11141: train loss 1.28500. lr 4.435484e-04:  68%|██████▊   | 11141/16329 [1:33:49<42:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11141: train loss 1.28500. lr 4.435484e-04:  68%|██████▊   | 11142/16329 [1:33:49<42:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11142: train loss 1.32993. lr 4.435230e-04:  68%|██████▊   | 11142/16329 [1:33:49<42:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11142: train loss 1.32993. lr 4.435230e-04:  68%|██████▊   | 11143/16329 [1:33:49<42:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11143: train loss 1.36076. lr 4.434977e-04:  68%|██████▊   | 11143/16329 [1:33:50<42:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11143: train loss 1.36076. lr 4.434977e-04:  68%|██████▊   | 11144/16329 [1:33:50<47:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11144: train loss 1.35351. lr 4.434723e-04:  68%|██████▊   | 11144/16329 [1:33:51<47:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11144: train loss 1.35351. lr 4.434723e-04:  68%|██████▊   | 11145/16329 [1:33:51<45:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11145: train loss 1.32893. lr 4.434470e-04:  68%|██████▊   | 11145/16329 [1:33:51<45:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11145: train loss 1.32893. lr 4.434470e-04:  68%|██████▊   | 11146/16329 [1:33:51<44:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11146: train loss 1.29414. lr 4.434217e-04:  68%|██████▊   | 11146/16329 [1:33:52<44:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11146: train loss 1.29414. lr 4.434217e-04:  68%|██████▊   | 11147/16329 [1:33:52<44:08,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11147: train loss 1.31532. lr 4.433963e-04:  68%|██████▊   | 11147/16329 [1:33:52<44:08,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11147: train loss 1.31532. lr 4.433963e-04:  68%|██████▊   | 11148/16329 [1:33:52<43:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11148: train loss 1.31029. lr 4.433710e-04:  68%|██████▊   | 11148/16329 [1:33:53<43:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11148: train loss 1.31029. lr 4.433710e-04:  68%|██████▊   | 11149/16329 [1:33:53<43:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11149: train loss 1.30745. lr 4.433456e-04:  68%|██████▊   | 11149/16329 [1:33:53<43:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11149: train loss 1.30745. lr 4.433456e-04:  68%|██████▊   | 11150/16329 [1:33:53<43:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11150: train loss 1.28902. lr 4.433202e-04:  68%|██████▊   | 11150/16329 [1:33:54<43:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11150: train loss 1.28902. lr 4.433202e-04:  68%|██████▊   | 11151/16329 [1:33:54<43:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11151: train loss 1.31956. lr 4.432949e-04:  68%|██████▊   | 11151/16329 [1:33:54<43:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11151: train loss 1.31956. lr 4.432949e-04:  68%|██████▊   | 11152/16329 [1:33:54<42:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11152: train loss 1.29950. lr 4.432695e-04:  68%|██████▊   | 11152/16329 [1:33:55<42:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11152: train loss 1.29950. lr 4.432695e-04:  68%|██████▊   | 11153/16329 [1:33:55<42:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11153: train loss 1.30037. lr 4.432442e-04:  68%|██████▊   | 11153/16329 [1:33:55<42:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11153: train loss 1.30037. lr 4.432442e-04:  68%|██████▊   | 11154/16329 [1:33:55<42:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11154: train loss 1.32270. lr 4.432188e-04:  68%|██████▊   | 11154/16329 [1:33:56<42:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11154: train loss 1.32270. lr 4.432188e-04:  68%|██████▊   | 11155/16329 [1:33:56<42:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11155: train loss 1.33144. lr 4.431935e-04:  68%|██████▊   | 11155/16329 [1:33:56<42:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11155: train loss 1.33144. lr 4.431935e-04:  68%|██████▊   | 11156/16329 [1:33:56<43:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11156: train loss 1.32037. lr 4.431681e-04:  68%|██████▊   | 11156/16329 [1:33:57<43:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11156: train loss 1.32037. lr 4.431681e-04:  68%|██████▊   | 11157/16329 [1:33:57<44:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11157: train loss 1.27474. lr 4.431427e-04:  68%|██████▊   | 11157/16329 [1:33:57<44:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11157: train loss 1.27474. lr 4.431427e-04:  68%|██████▊   | 11158/16329 [1:33:57<44:02,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11158: train loss 1.31066. lr 4.431174e-04:  68%|██████▊   | 11158/16329 [1:33:58<44:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11158: train loss 1.31066. lr 4.431174e-04:  68%|██████▊   | 11159/16329 [1:33:58<44:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11159: train loss 1.32179. lr 4.430920e-04:  68%|██████▊   | 11159/16329 [1:33:58<44:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11159: train loss 1.32179. lr 4.430920e-04:  68%|██████▊   | 11160/16329 [1:33:58<43:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11160: train loss 1.31850. lr 4.430666e-04:  68%|██████▊   | 11160/16329 [1:33:59<43:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11160: train loss 1.31850. lr 4.430666e-04:  68%|██████▊   | 11161/16329 [1:33:59<43:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11161: train loss 1.31731. lr 4.430413e-04:  68%|██████▊   | 11161/16329 [1:33:59<43:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11161: train loss 1.31731. lr 4.430413e-04:  68%|██████▊   | 11162/16329 [1:33:59<43:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11162: train loss 1.33045. lr 4.430159e-04:  68%|██████▊   | 11162/16329 [1:34:00<43:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11162: train loss 1.33045. lr 4.430159e-04:  68%|██████▊   | 11163/16329 [1:34:00<43:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11163: train loss 1.32445. lr 4.429905e-04:  68%|██████▊   | 11163/16329 [1:34:00<43:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11163: train loss 1.32445. lr 4.429905e-04:  68%|██████▊   | 11164/16329 [1:34:00<42:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11164: train loss 1.28280. lr 4.429652e-04:  68%|██████▊   | 11164/16329 [1:34:01<42:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11164: train loss 1.28280. lr 4.429652e-04:  68%|██████▊   | 11165/16329 [1:34:01<42:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11165: train loss 1.26642. lr 4.429398e-04:  68%|██████▊   | 11165/16329 [1:34:01<42:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11165: train loss 1.26642. lr 4.429398e-04:  68%|██████▊   | 11166/16329 [1:34:01<44:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11166: train loss 1.30640. lr 4.429144e-04:  68%|██████▊   | 11166/16329 [1:34:02<44:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11166: train loss 1.30640. lr 4.429144e-04:  68%|██████▊   | 11167/16329 [1:34:02<44:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11167: train loss 1.30991. lr 4.428890e-04:  68%|██████▊   | 11167/16329 [1:34:02<44:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11167: train loss 1.30991. lr 4.428890e-04:  68%|██████▊   | 11168/16329 [1:34:02<44:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11168: train loss 1.31301. lr 4.428637e-04:  68%|██████▊   | 11168/16329 [1:34:03<44:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11168: train loss 1.31301. lr 4.428637e-04:  68%|██████▊   | 11169/16329 [1:34:03<44:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11169: train loss 1.37836. lr 4.428383e-04:  68%|██████▊   | 11169/16329 [1:34:03<44:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11169: train loss 1.37836. lr 4.428383e-04:  68%|██████▊   | 11170/16329 [1:34:03<43:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11170: train loss 1.33785. lr 4.428129e-04:  68%|██████▊   | 11170/16329 [1:34:04<43:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11170: train loss 1.33785. lr 4.428129e-04:  68%|██████▊   | 11171/16329 [1:34:04<47:53,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 11171: train loss 1.33350. lr 4.427875e-04:  68%|██████▊   | 11171/16329 [1:34:04<47:53,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 11171: train loss 1.33350. lr 4.427875e-04:  68%|██████▊   | 11172/16329 [1:34:04<46:18,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11172: train loss 1.30297. lr 4.427621e-04:  68%|██████▊   | 11172/16329 [1:34:05<46:18,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11172: train loss 1.30297. lr 4.427621e-04:  68%|██████▊   | 11173/16329 [1:34:05<45:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11173: train loss 1.29304. lr 4.427368e-04:  68%|██████▊   | 11173/16329 [1:34:05<45:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11173: train loss 1.29304. lr 4.427368e-04:  68%|██████▊   | 11174/16329 [1:34:05<44:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11174: train loss 1.29691. lr 4.427114e-04:  68%|██████▊   | 11174/16329 [1:34:06<44:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11174: train loss 1.29691. lr 4.427114e-04:  68%|██████▊   | 11175/16329 [1:34:06<43:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11175: train loss 1.29536. lr 4.426860e-04:  68%|██████▊   | 11175/16329 [1:34:06<43:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11175: train loss 1.29536. lr 4.426860e-04:  68%|██████▊   | 11176/16329 [1:34:06<43:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11176: train loss 1.31246. lr 4.426606e-04:  68%|██████▊   | 11176/16329 [1:34:07<43:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11176: train loss 1.31246. lr 4.426606e-04:  68%|██████▊   | 11177/16329 [1:34:07<43:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11177: train loss 1.28226. lr 4.426352e-04:  68%|██████▊   | 11177/16329 [1:34:07<43:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11177: train loss 1.28226. lr 4.426352e-04:  68%|██████▊   | 11178/16329 [1:34:07<42:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11178: train loss 1.32194. lr 4.426098e-04:  68%|██████▊   | 11178/16329 [1:34:08<42:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11178: train loss 1.32194. lr 4.426098e-04:  68%|██████▊   | 11179/16329 [1:34:08<42:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11179: train loss 1.31105. lr 4.425844e-04:  68%|██████▊   | 11179/16329 [1:34:08<42:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11179: train loss 1.31105. lr 4.425844e-04:  68%|██████▊   | 11180/16329 [1:34:08<42:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11180: train loss 1.30707. lr 4.425590e-04:  68%|██████▊   | 11180/16329 [1:34:09<42:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11180: train loss 1.30707. lr 4.425590e-04:  68%|██████▊   | 11181/16329 [1:34:09<42:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11181: train loss 1.32568. lr 4.425336e-04:  68%|██████▊   | 11181/16329 [1:34:09<42:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11181: train loss 1.32568. lr 4.425336e-04:  68%|██████▊   | 11182/16329 [1:34:09<42:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11182: train loss 1.32783. lr 4.425082e-04:  68%|██████▊   | 11182/16329 [1:34:10<42:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11182: train loss 1.32783. lr 4.425082e-04:  68%|██████▊   | 11183/16329 [1:34:10<42:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11183: train loss 1.31271. lr 4.424828e-04:  68%|██████▊   | 11183/16329 [1:34:10<42:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11183: train loss 1.31271. lr 4.424828e-04:  68%|██████▊   | 11184/16329 [1:34:10<42:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11184: train loss 1.30004. lr 4.424574e-04:  68%|██████▊   | 11184/16329 [1:34:11<42:19,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11184: train loss 1.30004. lr 4.424574e-04:  68%|██████▊   | 11185/16329 [1:34:11<42:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11185: train loss 1.28068. lr 4.424320e-04:  68%|██████▊   | 11185/16329 [1:34:11<42:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11185: train loss 1.28068. lr 4.424320e-04:  69%|██████▊   | 11186/16329 [1:34:11<42:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11186: train loss 1.30504. lr 4.424066e-04:  69%|██████▊   | 11186/16329 [1:34:12<42:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11186: train loss 1.30504. lr 4.424066e-04:  69%|██████▊   | 11187/16329 [1:34:12<42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11187: train loss 1.31153. lr 4.423812e-04:  69%|██████▊   | 11187/16329 [1:34:12<42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11187: train loss 1.31153. lr 4.423812e-04:  69%|██████▊   | 11188/16329 [1:34:12<42:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11188: train loss 1.30273. lr 4.423558e-04:  69%|██████▊   | 11188/16329 [1:34:13<42:14,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11188: train loss 1.30273. lr 4.423558e-04:  69%|██████▊   | 11189/16329 [1:34:13<42:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11189: train loss 1.32061. lr 4.423304e-04:  69%|██████▊   | 11189/16329 [1:34:13<42:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11189: train loss 1.32061. lr 4.423304e-04:  69%|██████▊   | 11190/16329 [1:34:13<42:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11190: train loss 1.30987. lr 4.423050e-04:  69%|██████▊   | 11190/16329 [1:34:14<42:13,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11190: train loss 1.30987. lr 4.423050e-04:  69%|██████▊   | 11191/16329 [1:34:14<42:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11191: train loss 1.31967. lr 4.422796e-04:  69%|██████▊   | 11191/16329 [1:34:14<42:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11191: train loss 1.31967. lr 4.422796e-04:  69%|██████▊   | 11192/16329 [1:34:14<42:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11192: train loss 1.34076. lr 4.422542e-04:  69%|██████▊   | 11192/16329 [1:34:15<42:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11192: train loss 1.34076. lr 4.422542e-04:  69%|██████▊   | 11193/16329 [1:34:15<42:19,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11193: train loss 1.29773. lr 4.422288e-04:  69%|██████▊   | 11193/16329 [1:34:15<42:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11193: train loss 1.29773. lr 4.422288e-04:  69%|██████▊   | 11194/16329 [1:34:15<42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11194: train loss 1.31773. lr 4.422034e-04:  69%|██████▊   | 11194/16329 [1:34:16<42:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11194: train loss 1.31773. lr 4.422034e-04:  69%|██████▊   | 11195/16329 [1:34:16<42:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11195: train loss 1.31324. lr 4.421780e-04:  69%|██████▊   | 11195/16329 [1:34:16<42:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11195: train loss 1.31324. lr 4.421780e-04:  69%|██████▊   | 11196/16329 [1:34:16<42:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11196: train loss 1.36002. lr 4.421526e-04:  69%|██████▊   | 11196/16329 [1:34:17<42:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11196: train loss 1.36002. lr 4.421526e-04:  69%|██████▊   | 11197/16329 [1:34:17<44:32,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11197: train loss 1.29831. lr 4.421272e-04:  69%|██████▊   | 11197/16329 [1:34:17<44:32,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11197: train loss 1.29831. lr 4.421272e-04:  69%|██████▊   | 11198/16329 [1:34:17<45:10,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11198: train loss 1.28221. lr 4.421017e-04:  69%|██████▊   | 11198/16329 [1:34:18<45:10,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11198: train loss 1.28221. lr 4.421017e-04:  69%|██████▊   | 11199/16329 [1:34:18<45:15,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11199: train loss 1.30667. lr 4.420763e-04:  69%|██████▊   | 11199/16329 [1:34:18<45:15,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11199: train loss 1.30667. lr 4.420763e-04:  69%|██████▊   | 11200/16329 [1:34:18<45:05,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11200: train loss 1.28617. lr 4.420509e-04:  69%|██████▊   | 11200/16329 [1:34:19<45:05,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11200: train loss 1.28617. lr 4.420509e-04:  69%|██████▊   | 11201/16329 [1:34:19<44:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11201: train loss 1.29910. lr 4.420255e-04:  69%|██████▊   | 11201/16329 [1:34:19<44:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11201: train loss 1.29910. lr 4.420255e-04:  69%|██████▊   | 11202/16329 [1:34:19<44:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11202: train loss 1.28414. lr 4.420001e-04:  69%|██████▊   | 11202/16329 [1:34:20<44:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11202: train loss 1.28414. lr 4.420001e-04:  69%|██████▊   | 11203/16329 [1:34:20<43:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11203: train loss 1.31305. lr 4.419746e-04:  69%|██████▊   | 11203/16329 [1:34:20<43:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11203: train loss 1.31305. lr 4.419746e-04:  69%|██████▊   | 11204/16329 [1:34:20<43:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11204: train loss 1.29235. lr 4.419492e-04:  69%|██████▊   | 11204/16329 [1:34:21<43:30,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11204: train loss 1.29235. lr 4.419492e-04:  69%|██████▊   | 11205/16329 [1:34:21<43:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11205: train loss 1.30544. lr 4.419238e-04:  69%|██████▊   | 11205/16329 [1:34:21<43:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11205: train loss 1.30544. lr 4.419238e-04:  69%|██████▊   | 11206/16329 [1:34:21<42:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11206: train loss 1.30257. lr 4.418984e-04:  69%|██████▊   | 11206/16329 [1:34:22<42:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11206: train loss 1.30257. lr 4.418984e-04:  69%|██████▊   | 11207/16329 [1:34:22<42:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11207: train loss 1.34157. lr 4.418729e-04:  69%|██████▊   | 11207/16329 [1:34:22<42:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11207: train loss 1.34157. lr 4.418729e-04:  69%|██████▊   | 11208/16329 [1:34:22<42:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11208: train loss 1.31828. lr 4.418475e-04:  69%|██████▊   | 11208/16329 [1:34:23<42:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11208: train loss 1.31828. lr 4.418475e-04:  69%|██████▊   | 11209/16329 [1:34:23<42:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11209: train loss 1.29427. lr 4.418221e-04:  69%|██████▊   | 11209/16329 [1:34:23<42:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11209: train loss 1.29427. lr 4.418221e-04:  69%|██████▊   | 11210/16329 [1:34:23<42:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11210: train loss 1.33768. lr 4.417966e-04:  69%|██████▊   | 11210/16329 [1:34:24<42:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11210: train loss 1.33768. lr 4.417966e-04:  69%|██████▊   | 11211/16329 [1:34:24<46:49,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11211: train loss 1.30432. lr 4.417712e-04:  69%|██████▊   | 11211/16329 [1:34:25<46:49,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11211: train loss 1.30432. lr 4.417712e-04:  69%|██████▊   | 11212/16329 [1:34:25<45:20,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11212: train loss 1.32770. lr 4.417458e-04:  69%|██████▊   | 11212/16329 [1:34:25<45:20,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11212: train loss 1.32770. lr 4.417458e-04:  69%|██████▊   | 11213/16329 [1:34:25<44:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11213: train loss 1.36406. lr 4.417203e-04:  69%|██████▊   | 11213/16329 [1:34:26<44:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11213: train loss 1.36406. lr 4.417203e-04:  69%|██████▊   | 11214/16329 [1:34:26<43:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11214: train loss 1.35294. lr 4.416949e-04:  69%|██████▊   | 11214/16329 [1:34:26<43:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11214: train loss 1.35294. lr 4.416949e-04:  69%|██████▊   | 11215/16329 [1:34:26<43:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11215: train loss 1.30590. lr 4.416694e-04:  69%|██████▊   | 11215/16329 [1:34:27<43:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11215: train loss 1.30590. lr 4.416694e-04:  69%|██████▊   | 11216/16329 [1:34:27<42:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11216: train loss 1.30434. lr 4.416440e-04:  69%|██████▊   | 11216/16329 [1:34:27<42:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11216: train loss 1.30434. lr 4.416440e-04:  69%|██████▊   | 11217/16329 [1:34:27<42:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11217: train loss 1.33314. lr 4.416186e-04:  69%|██████▊   | 11217/16329 [1:34:28<42:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11217: train loss 1.33314. lr 4.416186e-04:  69%|██████▊   | 11218/16329 [1:34:28<42:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11218: train loss 1.32081. lr 4.415931e-04:  69%|██████▊   | 11218/16329 [1:34:28<42:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11218: train loss 1.32081. lr 4.415931e-04:  69%|██████▊   | 11219/16329 [1:34:28<42:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11219: train loss 1.29804. lr 4.415677e-04:  69%|██████▊   | 11219/16329 [1:34:29<42:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11219: train loss 1.29804. lr 4.415677e-04:  69%|██████▊   | 11220/16329 [1:34:29<42:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11220: train loss 1.33347. lr 4.415422e-04:  69%|██████▊   | 11220/16329 [1:34:29<42:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11220: train loss 1.33347. lr 4.415422e-04:  69%|██████▊   | 11221/16329 [1:34:29<42:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11221: train loss 1.30393. lr 4.415168e-04:  69%|██████▊   | 11221/16329 [1:34:30<42:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11221: train loss 1.30393. lr 4.415168e-04:  69%|██████▊   | 11222/16329 [1:34:30<42:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11222: train loss 1.30515. lr 4.414913e-04:  69%|██████▊   | 11222/16329 [1:34:30<42:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11222: train loss 1.30515. lr 4.414913e-04:  69%|██████▊   | 11223/16329 [1:34:30<42:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11223: train loss 1.29004. lr 4.414659e-04:  69%|██████▊   | 11223/16329 [1:34:31<42:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11223: train loss 1.29004. lr 4.414659e-04:  69%|██████▊   | 11224/16329 [1:34:31<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11224: train loss 1.35276. lr 4.414404e-04:  69%|██████▊   | 11224/16329 [1:34:31<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11224: train loss 1.35276. lr 4.414404e-04:  69%|██████▊   | 11225/16329 [1:34:31<42:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11225: train loss 1.29175. lr 4.414150e-04:  69%|██████▊   | 11225/16329 [1:34:32<42:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11225: train loss 1.29175. lr 4.414150e-04:  69%|██████▊   | 11226/16329 [1:34:32<42:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11226: train loss 1.33858. lr 4.413895e-04:  69%|██████▊   | 11226/16329 [1:34:32<42:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11226: train loss 1.33858. lr 4.413895e-04:  69%|██████▉   | 11227/16329 [1:34:32<42:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11227: train loss 1.31089. lr 4.413641e-04:  69%|██████▉   | 11227/16329 [1:34:33<42:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11227: train loss 1.31089. lr 4.413641e-04:  69%|██████▉   | 11228/16329 [1:34:33<42:02,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11228: train loss 1.30848. lr 4.413386e-04:  69%|██████▉   | 11228/16329 [1:34:33<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11228: train loss 1.30848. lr 4.413386e-04:  69%|██████▉   | 11229/16329 [1:34:33<41:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11229: train loss 1.29742. lr 4.413132e-04:  69%|██████▉   | 11229/16329 [1:34:34<41:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11229: train loss 1.29742. lr 4.413132e-04:  69%|██████▉   | 11230/16329 [1:34:34<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11230: train loss 1.29558. lr 4.412877e-04:  69%|██████▉   | 11230/16329 [1:34:34<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11230: train loss 1.29558. lr 4.412877e-04:  69%|██████▉   | 11231/16329 [1:34:34<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11231: train loss 1.30011. lr 4.412622e-04:  69%|██████▉   | 11231/16329 [1:34:34<42:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11231: train loss 1.30011. lr 4.412622e-04:  69%|██████▉   | 11232/16329 [1:34:35<42:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11232: train loss 1.28928. lr 4.412368e-04:  69%|██████▉   | 11232/16329 [1:34:35<42:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11232: train loss 1.28928. lr 4.412368e-04:  69%|██████▉   | 11233/16329 [1:34:35<41:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11233: train loss 1.31603. lr 4.412113e-04:  69%|██████▉   | 11233/16329 [1:34:35<41:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11233: train loss 1.31603. lr 4.412113e-04:  69%|██████▉   | 11234/16329 [1:34:35<42:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11234: train loss 1.30462. lr 4.411859e-04:  69%|██████▉   | 11234/16329 [1:34:36<42:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11234: train loss 1.30462. lr 4.411859e-04:  69%|██████▉   | 11235/16329 [1:34:36<42:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11235: train loss 1.28688. lr 4.411604e-04:  69%|██████▉   | 11235/16329 [1:34:36<42:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11235: train loss 1.28688. lr 4.411604e-04:  69%|██████▉   | 11236/16329 [1:34:36<41:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11236: train loss 1.28251. lr 4.411349e-04:  69%|██████▉   | 11236/16329 [1:34:37<41:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11236: train loss 1.28251. lr 4.411349e-04:  69%|██████▉   | 11237/16329 [1:34:37<41:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11237: train loss 1.30453. lr 4.411095e-04:  69%|██████▉   | 11237/16329 [1:34:37<41:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11237: train loss 1.30453. lr 4.411095e-04:  69%|██████▉   | 11238/16329 [1:34:37<41:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11238: train loss 1.33877. lr 4.410840e-04:  69%|██████▉   | 11238/16329 [1:34:38<41:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11238: train loss 1.33877. lr 4.410840e-04:  69%|██████▉   | 11239/16329 [1:34:38<41:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11239: train loss 1.29781. lr 4.410585e-04:  69%|██████▉   | 11239/16329 [1:34:38<41:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11239: train loss 1.29781. lr 4.410585e-04:  69%|██████▉   | 11240/16329 [1:34:38<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11240: train loss 1.31605. lr 4.410331e-04:  69%|██████▉   | 11240/16329 [1:34:39<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11240: train loss 1.31605. lr 4.410331e-04:  69%|██████▉   | 11241/16329 [1:34:39<41:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11241: train loss 1.32651. lr 4.410076e-04:  69%|██████▉   | 11241/16329 [1:34:39<41:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11241: train loss 1.32651. lr 4.410076e-04:  69%|██████▉   | 11242/16329 [1:34:39<41:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11242: train loss 1.33712. lr 4.409821e-04:  69%|██████▉   | 11242/16329 [1:34:40<41:51,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11242: train loss 1.33712. lr 4.409821e-04:  69%|██████▉   | 11243/16329 [1:34:40<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11243: train loss 1.35258. lr 4.409566e-04:  69%|██████▉   | 11243/16329 [1:34:40<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11243: train loss 1.35258. lr 4.409566e-04:  69%|██████▉   | 11244/16329 [1:34:40<41:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11244: train loss 1.28612. lr 4.409312e-04:  69%|██████▉   | 11244/16329 [1:34:41<41:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11244: train loss 1.28612. lr 4.409312e-04:  69%|██████▉   | 11245/16329 [1:34:41<41:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11245: train loss 1.29425. lr 4.409057e-04:  69%|██████▉   | 11245/16329 [1:34:42<41:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11245: train loss 1.29425. lr 4.409057e-04:  69%|██████▉   | 11246/16329 [1:34:42<46:03,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11246: train loss 1.30302. lr 4.408802e-04:  69%|██████▉   | 11246/16329 [1:34:42<46:03,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11246: train loss 1.30302. lr 4.408802e-04:  69%|██████▉   | 11247/16329 [1:34:42<44:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11247: train loss 1.32181. lr 4.408547e-04:  69%|██████▉   | 11247/16329 [1:34:43<44:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11247: train loss 1.32181. lr 4.408547e-04:  69%|██████▉   | 11248/16329 [1:34:43<43:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11248: train loss 1.28972. lr 4.408292e-04:  69%|██████▉   | 11248/16329 [1:34:43<43:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11248: train loss 1.28972. lr 4.408292e-04:  69%|██████▉   | 11249/16329 [1:34:43<43:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11249: train loss 1.30458. lr 4.408037e-04:  69%|██████▉   | 11249/16329 [1:34:44<43:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11249: train loss 1.30458. lr 4.408037e-04:  69%|██████▉   | 11250/16329 [1:34:44<42:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11250: train loss 1.27672. lr 4.407783e-04:  69%|██████▉   | 11250/16329 [1:34:44<42:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11250: train loss 1.27672. lr 4.407783e-04:  69%|██████▉   | 11251/16329 [1:34:44<42:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11251: train loss 1.30468. lr 4.407528e-04:  69%|██████▉   | 11251/16329 [1:34:45<42:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11251: train loss 1.30468. lr 4.407528e-04:  69%|██████▉   | 11252/16329 [1:34:45<42:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11252: train loss 1.29496. lr 4.407273e-04:  69%|██████▉   | 11252/16329 [1:34:45<42:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11252: train loss 1.29496. lr 4.407273e-04:  69%|██████▉   | 11253/16329 [1:34:45<42:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11253: train loss 1.31668. lr 4.407018e-04:  69%|██████▉   | 11253/16329 [1:34:46<42:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11253: train loss 1.31668. lr 4.407018e-04:  69%|██████▉   | 11254/16329 [1:34:46<42:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11254: train loss 1.32098. lr 4.406763e-04:  69%|██████▉   | 11254/16329 [1:34:46<42:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11254: train loss 1.32098. lr 4.406763e-04:  69%|██████▉   | 11255/16329 [1:34:46<42:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11255: train loss 1.30592. lr 4.406508e-04:  69%|██████▉   | 11255/16329 [1:34:47<42:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11255: train loss 1.30592. lr 4.406508e-04:  69%|██████▉   | 11256/16329 [1:34:47<41:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11256: train loss 1.28099. lr 4.406253e-04:  69%|██████▉   | 11256/16329 [1:34:47<41:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11256: train loss 1.28099. lr 4.406253e-04:  69%|██████▉   | 11257/16329 [1:34:47<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11257: train loss 1.30931. lr 4.405998e-04:  69%|██████▉   | 11257/16329 [1:34:48<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11257: train loss 1.30931. lr 4.405998e-04:  69%|██████▉   | 11258/16329 [1:34:48<41:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11258: train loss 1.32779. lr 4.405743e-04:  69%|██████▉   | 11258/16329 [1:34:48<41:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11258: train loss 1.32779. lr 4.405743e-04:  69%|██████▉   | 11259/16329 [1:34:48<41:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11259: train loss 1.32627. lr 4.405488e-04:  69%|██████▉   | 11259/16329 [1:34:49<41:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11259: train loss 1.32627. lr 4.405488e-04:  69%|██████▉   | 11260/16329 [1:34:49<41:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11260: train loss 1.31069. lr 4.405233e-04:  69%|██████▉   | 11260/16329 [1:34:49<41:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11260: train loss 1.31069. lr 4.405233e-04:  69%|██████▉   | 11261/16329 [1:34:49<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11261: train loss 1.33228. lr 4.404978e-04:  69%|██████▉   | 11261/16329 [1:34:50<41:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11261: train loss 1.33228. lr 4.404978e-04:  69%|██████▉   | 11262/16329 [1:34:50<41:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11262: train loss 1.32940. lr 4.404723e-04:  69%|██████▉   | 11262/16329 [1:34:50<41:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11262: train loss 1.32940. lr 4.404723e-04:  69%|██████▉   | 11263/16329 [1:34:50<42:01,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11263: train loss 1.33091. lr 4.404468e-04:  69%|██████▉   | 11263/16329 [1:34:51<42:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11263: train loss 1.33091. lr 4.404468e-04:  69%|██████▉   | 11264/16329 [1:34:51<44:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11264: train loss 1.31894. lr 4.404213e-04:  69%|██████▉   | 11264/16329 [1:34:51<44:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11264: train loss 1.31894. lr 4.404213e-04:  69%|██████▉   | 11265/16329 [1:34:51<45:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11265: train loss 1.28559. lr 4.403958e-04:  69%|██████▉   | 11265/16329 [1:34:52<45:10,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11265: train loss 1.28559. lr 4.403958e-04:  69%|██████▉   | 11266/16329 [1:34:52<45:21,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11266: train loss 1.31076. lr 4.403703e-04:  69%|██████▉   | 11266/16329 [1:34:52<45:21,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11266: train loss 1.31076. lr 4.403703e-04:  69%|██████▉   | 11267/16329 [1:34:52<45:13,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11267: train loss 1.30372. lr 4.403448e-04:  69%|██████▉   | 11267/16329 [1:34:53<45:13,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11267: train loss 1.30372. lr 4.403448e-04:  69%|██████▉   | 11268/16329 [1:34:53<44:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11268: train loss 1.30536. lr 4.403193e-04:  69%|██████▉   | 11268/16329 [1:34:53<44:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11268: train loss 1.30536. lr 4.403193e-04:  69%|██████▉   | 11269/16329 [1:34:53<44:17,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11269: train loss 1.32076. lr 4.402938e-04:  69%|██████▉   | 11269/16329 [1:34:54<44:17,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11269: train loss 1.32076. lr 4.402938e-04:  69%|██████▉   | 11270/16329 [1:34:54<43:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11270: train loss 1.32963. lr 4.402683e-04:  69%|██████▉   | 11270/16329 [1:34:54<43:48,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11270: train loss 1.32963. lr 4.402683e-04:  69%|██████▉   | 11271/16329 [1:34:54<47:48,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 11271: train loss 1.32491. lr 4.402428e-04:  69%|██████▉   | 11271/16329 [1:34:55<47:48,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 11271: train loss 1.32491. lr 4.402428e-04:  69%|██████▉   | 11272/16329 [1:34:55<46:06,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11272: train loss 1.30655. lr 4.402173e-04:  69%|██████▉   | 11272/16329 [1:34:55<46:06,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11272: train loss 1.30655. lr 4.402173e-04:  69%|██████▉   | 11273/16329 [1:34:55<44:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11273: train loss 1.34329. lr 4.401918e-04:  69%|██████▉   | 11273/16329 [1:34:56<44:54,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11273: train loss 1.34329. lr 4.401918e-04:  69%|██████▉   | 11274/16329 [1:34:56<43:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11274: train loss 1.31305. lr 4.401662e-04:  69%|██████▉   | 11274/16329 [1:34:56<43:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11274: train loss 1.31305. lr 4.401662e-04:  69%|██████▉   | 11275/16329 [1:34:56<43:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11275: train loss 1.31056. lr 4.401407e-04:  69%|██████▉   | 11275/16329 [1:34:57<43:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11275: train loss 1.31056. lr 4.401407e-04:  69%|██████▉   | 11276/16329 [1:34:57<42:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11276: train loss 1.32503. lr 4.401152e-04:  69%|██████▉   | 11276/16329 [1:34:57<42:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11276: train loss 1.32503. lr 4.401152e-04:  69%|██████▉   | 11277/16329 [1:34:57<42:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11277: train loss 1.31218. lr 4.400897e-04:  69%|██████▉   | 11277/16329 [1:34:58<42:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11277: train loss 1.31218. lr 4.400897e-04:  69%|██████▉   | 11278/16329 [1:34:58<42:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11278: train loss 1.28814. lr 4.400642e-04:  69%|██████▉   | 11278/16329 [1:34:58<42:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11278: train loss 1.28814. lr 4.400642e-04:  69%|██████▉   | 11279/16329 [1:34:58<41:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11279: train loss 1.30970. lr 4.400386e-04:  69%|██████▉   | 11279/16329 [1:34:59<41:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11279: train loss 1.30970. lr 4.400386e-04:  69%|██████▉   | 11280/16329 [1:34:59<41:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11280: train loss 1.35614. lr 4.400131e-04:  69%|██████▉   | 11280/16329 [1:34:59<41:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11280: train loss 1.35614. lr 4.400131e-04:  69%|██████▉   | 11281/16329 [1:34:59<41:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11281: train loss 1.31655. lr 4.399876e-04:  69%|██████▉   | 11281/16329 [1:35:00<41:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11281: train loss 1.31655. lr 4.399876e-04:  69%|██████▉   | 11282/16329 [1:35:00<41:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11282: train loss 1.29134. lr 4.399621e-04:  69%|██████▉   | 11282/16329 [1:35:00<41:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11282: train loss 1.29134. lr 4.399621e-04:  69%|██████▉   | 11283/16329 [1:35:00<41:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11283: train loss 1.34094. lr 4.399365e-04:  69%|██████▉   | 11283/16329 [1:35:01<41:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11283: train loss 1.34094. lr 4.399365e-04:  69%|██████▉   | 11284/16329 [1:35:01<41:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11284: train loss 1.33015. lr 4.399110e-04:  69%|██████▉   | 11284/16329 [1:35:01<41:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11284: train loss 1.33015. lr 4.399110e-04:  69%|██████▉   | 11285/16329 [1:35:01<41:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11285: train loss 1.33141. lr 4.398855e-04:  69%|██████▉   | 11285/16329 [1:35:02<41:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11285: train loss 1.33141. lr 4.398855e-04:  69%|██████▉   | 11286/16329 [1:35:02<41:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11286: train loss 1.31029. lr 4.398599e-04:  69%|██████▉   | 11286/16329 [1:35:02<41:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11286: train loss 1.31029. lr 4.398599e-04:  69%|██████▉   | 11287/16329 [1:35:02<41:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11287: train loss 1.29900. lr 4.398344e-04:  69%|██████▉   | 11287/16329 [1:35:03<41:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11287: train loss 1.29900. lr 4.398344e-04:  69%|██████▉   | 11288/16329 [1:35:03<41:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11288: train loss 1.31656. lr 4.398089e-04:  69%|██████▉   | 11288/16329 [1:35:03<41:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11288: train loss 1.31656. lr 4.398089e-04:  69%|██████▉   | 11289/16329 [1:35:03<41:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11289: train loss 1.31633. lr 4.397833e-04:  69%|██████▉   | 11289/16329 [1:35:04<41:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11289: train loss 1.31633. lr 4.397833e-04:  69%|██████▉   | 11290/16329 [1:35:04<41:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11290: train loss 1.28983. lr 4.397578e-04:  69%|██████▉   | 11290/16329 [1:35:04<41:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11290: train loss 1.28983. lr 4.397578e-04:  69%|██████▉   | 11291/16329 [1:35:04<41:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11291: train loss 1.32385. lr 4.397323e-04:  69%|██████▉   | 11291/16329 [1:35:05<41:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11291: train loss 1.32385. lr 4.397323e-04:  69%|██████▉   | 11292/16329 [1:35:05<41:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11292: train loss 1.31812. lr 4.397067e-04:  69%|██████▉   | 11292/16329 [1:35:05<41:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11292: train loss 1.31812. lr 4.397067e-04:  69%|██████▉   | 11293/16329 [1:35:05<41:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11293: train loss 1.31106. lr 4.396812e-04:  69%|██████▉   | 11293/16329 [1:35:06<41:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11293: train loss 1.31106. lr 4.396812e-04:  69%|██████▉   | 11294/16329 [1:35:06<41:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11294: train loss 1.29063. lr 4.396556e-04:  69%|██████▉   | 11294/16329 [1:35:06<41:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11294: train loss 1.29063. lr 4.396556e-04:  69%|██████▉   | 11295/16329 [1:35:06<41:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11295: train loss 1.30125. lr 4.396301e-04:  69%|██████▉   | 11295/16329 [1:35:07<41:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11295: train loss 1.30125. lr 4.396301e-04:  69%|██████▉   | 11296/16329 [1:35:07<41:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11296: train loss 1.27362. lr 4.396046e-04:  69%|██████▉   | 11296/16329 [1:35:07<41:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11296: train loss 1.27362. lr 4.396046e-04:  69%|██████▉   | 11297/16329 [1:35:07<41:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11297: train loss 1.29760. lr 4.395790e-04:  69%|██████▉   | 11297/16329 [1:35:08<41:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11297: train loss 1.29760. lr 4.395790e-04:  69%|██████▉   | 11298/16329 [1:35:08<45:48,  1.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11298: train loss 1.28284. lr 4.395535e-04:  69%|██████▉   | 11298/16329 [1:35:08<45:48,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11298: train loss 1.28284. lr 4.395535e-04:  69%|██████▉   | 11299/16329 [1:35:08<44:24,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11299: train loss 1.33264. lr 4.395279e-04:  69%|██████▉   | 11299/16329 [1:35:09<44:24,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11299: train loss 1.33264. lr 4.395279e-04:  69%|██████▉   | 11300/16329 [1:35:09<43:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11300: train loss 1.34406. lr 4.395024e-04:  69%|██████▉   | 11300/16329 [1:35:09<43:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11300: train loss 1.34406. lr 4.395024e-04:  69%|██████▉   | 11301/16329 [1:35:09<42:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11301: train loss 1.35103. lr 4.394768e-04:  69%|██████▉   | 11301/16329 [1:35:10<42:45,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11301: train loss 1.35103. lr 4.394768e-04:  69%|██████▉   | 11302/16329 [1:35:10<42:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11302: train loss 1.31145. lr 4.394513e-04:  69%|██████▉   | 11302/16329 [1:35:10<42:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11302: train loss 1.31145. lr 4.394513e-04:  69%|██████▉   | 11303/16329 [1:35:10<42:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11303: train loss 1.29878. lr 4.394257e-04:  69%|██████▉   | 11303/16329 [1:35:11<42:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11303: train loss 1.29878. lr 4.394257e-04:  69%|██████▉   | 11304/16329 [1:35:11<41:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11304: train loss 1.31614. lr 4.394002e-04:  69%|██████▉   | 11304/16329 [1:35:11<41:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11304: train loss 1.31614. lr 4.394002e-04:  69%|██████▉   | 11305/16329 [1:35:11<41:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11305: train loss 1.29065. lr 4.393746e-04:  69%|██████▉   | 11305/16329 [1:35:12<41:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11305: train loss 1.29065. lr 4.393746e-04:  69%|██████▉   | 11306/16329 [1:35:12<41:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11306: train loss 1.32714. lr 4.393490e-04:  69%|██████▉   | 11306/16329 [1:35:12<41:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11306: train loss 1.32714. lr 4.393490e-04:  69%|██████▉   | 11307/16329 [1:35:12<41:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11307: train loss 1.32545. lr 4.393235e-04:  69%|██████▉   | 11307/16329 [1:35:13<41:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11307: train loss 1.32545. lr 4.393235e-04:  69%|██████▉   | 11308/16329 [1:35:13<42:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11308: train loss 1.31343. lr 4.392979e-04:  69%|██████▉   | 11308/16329 [1:35:13<42:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11308: train loss 1.31343. lr 4.392979e-04:  69%|██████▉   | 11309/16329 [1:35:13<42:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11309: train loss 1.30399. lr 4.392724e-04:  69%|██████▉   | 11309/16329 [1:35:14<42:14,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11309: train loss 1.30399. lr 4.392724e-04:  69%|██████▉   | 11310/16329 [1:35:14<42:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11310: train loss 1.29680. lr 4.392468e-04:  69%|██████▉   | 11310/16329 [1:35:14<42:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11310: train loss 1.29680. lr 4.392468e-04:  69%|██████▉   | 11311/16329 [1:35:14<42:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11311: train loss 1.26715. lr 4.392212e-04:  69%|██████▉   | 11311/16329 [1:35:15<42:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11311: train loss 1.26715. lr 4.392212e-04:  69%|██████▉   | 11312/16329 [1:35:15<41:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11312: train loss 1.28807. lr 4.391957e-04:  69%|██████▉   | 11312/16329 [1:35:15<41:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11312: train loss 1.28807. lr 4.391957e-04:  69%|██████▉   | 11313/16329 [1:35:15<41:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11313: train loss 1.33307. lr 4.391701e-04:  69%|██████▉   | 11313/16329 [1:35:16<41:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11313: train loss 1.33307. lr 4.391701e-04:  69%|██████▉   | 11314/16329 [1:35:16<41:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11314: train loss 1.27996. lr 4.391445e-04:  69%|██████▉   | 11314/16329 [1:35:16<41:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11314: train loss 1.27996. lr 4.391445e-04:  69%|██████▉   | 11315/16329 [1:35:16<41:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11315: train loss 1.30745. lr 4.391190e-04:  69%|██████▉   | 11315/16329 [1:35:17<41:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11315: train loss 1.30745. lr 4.391190e-04:  69%|██████▉   | 11316/16329 [1:35:17<41:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11316: train loss 1.32628. lr 4.390934e-04:  69%|██████▉   | 11316/16329 [1:35:17<41:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11316: train loss 1.32628. lr 4.390934e-04:  69%|██████▉   | 11317/16329 [1:35:17<41:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11317: train loss 1.34848. lr 4.390678e-04:  69%|██████▉   | 11317/16329 [1:35:18<41:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11317: train loss 1.34848. lr 4.390678e-04:  69%|██████▉   | 11318/16329 [1:35:18<41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11318: train loss 1.31065. lr 4.390423e-04:  69%|██████▉   | 11318/16329 [1:35:18<41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11318: train loss 1.31065. lr 4.390423e-04:  69%|██████▉   | 11319/16329 [1:35:18<41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11319: train loss 1.26989. lr 4.390167e-04:  69%|██████▉   | 11319/16329 [1:35:19<41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11319: train loss 1.26989. lr 4.390167e-04:  69%|██████▉   | 11320/16329 [1:35:19<41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11320: train loss 1.28037. lr 4.389911e-04:  69%|██████▉   | 11320/16329 [1:35:19<41:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11320: train loss 1.28037. lr 4.389911e-04:  69%|██████▉   | 11321/16329 [1:35:19<41:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11321: train loss 1.31244. lr 4.389655e-04:  69%|██████▉   | 11321/16329 [1:35:20<41:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11321: train loss 1.31244. lr 4.389655e-04:  69%|██████▉   | 11322/16329 [1:35:20<41:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11322: train loss 1.28654. lr 4.389400e-04:  69%|██████▉   | 11322/16329 [1:35:20<41:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11322: train loss 1.28654. lr 4.389400e-04:  69%|██████▉   | 11323/16329 [1:35:20<41:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11323: train loss 1.27781. lr 4.389144e-04:  69%|██████▉   | 11323/16329 [1:35:21<41:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11323: train loss 1.27781. lr 4.389144e-04:  69%|██████▉   | 11324/16329 [1:35:21<41:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11324: train loss 1.32248. lr 4.388888e-04:  69%|██████▉   | 11324/16329 [1:35:21<41:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11324: train loss 1.32248. lr 4.388888e-04:  69%|██████▉   | 11325/16329 [1:35:21<41:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11325: train loss 1.29678. lr 4.388632e-04:  69%|██████▉   | 11325/16329 [1:35:22<41:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11325: train loss 1.29678. lr 4.388632e-04:  69%|██████▉   | 11326/16329 [1:35:22<41:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11326: train loss 1.32881. lr 4.388376e-04:  69%|██████▉   | 11326/16329 [1:35:22<41:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11326: train loss 1.32881. lr 4.388376e-04:  69%|██████▉   | 11327/16329 [1:35:22<41:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11327: train loss 1.28850. lr 4.388120e-04:  69%|██████▉   | 11327/16329 [1:35:23<41:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11327: train loss 1.28850. lr 4.388120e-04:  69%|██████▉   | 11328/16329 [1:35:23<41:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11328: train loss 1.32482. lr 4.387865e-04:  69%|██████▉   | 11328/16329 [1:35:23<41:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11328: train loss 1.32482. lr 4.387865e-04:  69%|██████▉   | 11329/16329 [1:35:23<41:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11329: train loss 1.35854. lr 4.387609e-04:  69%|██████▉   | 11329/16329 [1:35:24<41:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11329: train loss 1.35854. lr 4.387609e-04:  69%|██████▉   | 11330/16329 [1:35:24<41:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11330: train loss 1.27227. lr 4.387353e-04:  69%|██████▉   | 11330/16329 [1:35:24<41:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11330: train loss 1.27227. lr 4.387353e-04:  69%|██████▉   | 11331/16329 [1:35:24<41:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11331: train loss 1.31878. lr 4.387097e-04:  69%|██████▉   | 11331/16329 [1:35:25<41:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11331: train loss 1.31878. lr 4.387097e-04:  69%|██████▉   | 11332/16329 [1:35:25<41:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11332: train loss 1.27882. lr 4.386841e-04:  69%|██████▉   | 11332/16329 [1:35:25<41:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11332: train loss 1.27882. lr 4.386841e-04:  69%|██████▉   | 11333/16329 [1:35:25<41:06,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11333: train loss 1.28248. lr 4.386585e-04:  69%|██████▉   | 11333/16329 [1:35:26<41:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11333: train loss 1.28248. lr 4.386585e-04:  69%|██████▉   | 11334/16329 [1:35:26<41:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11334: train loss 1.32128. lr 4.386329e-04:  69%|██████▉   | 11334/16329 [1:35:26<41:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11334: train loss 1.32128. lr 4.386329e-04:  69%|██████▉   | 11335/16329 [1:35:26<41:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11335: train loss 1.29350. lr 4.386073e-04:  69%|██████▉   | 11335/16329 [1:35:27<41:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11335: train loss 1.29350. lr 4.386073e-04:  69%|██████▉   | 11336/16329 [1:35:27<41:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11336: train loss 1.29846. lr 4.385817e-04:  69%|██████▉   | 11336/16329 [1:35:27<41:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11336: train loss 1.29846. lr 4.385817e-04:  69%|██████▉   | 11337/16329 [1:35:27<41:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11337: train loss 1.28088. lr 4.385561e-04:  69%|██████▉   | 11337/16329 [1:35:28<41:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11337: train loss 1.28088. lr 4.385561e-04:  69%|██████▉   | 11338/16329 [1:35:28<46:30,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11338: train loss 1.30817. lr 4.385305e-04:  69%|██████▉   | 11338/16329 [1:35:29<46:30,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11338: train loss 1.30817. lr 4.385305e-04:  69%|██████▉   | 11339/16329 [1:35:29<45:58,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11339: train loss 1.27771. lr 4.385049e-04:  69%|██████▉   | 11339/16329 [1:35:29<45:58,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11339: train loss 1.27771. lr 4.385049e-04:  69%|██████▉   | 11340/16329 [1:35:29<45:09,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11340: train loss 1.29327. lr 4.384793e-04:  69%|██████▉   | 11340/16329 [1:35:30<45:09,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11340: train loss 1.29327. lr 4.384793e-04:  69%|██████▉   | 11341/16329 [1:35:30<44:17,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11341: train loss 1.29424. lr 4.384537e-04:  69%|██████▉   | 11341/16329 [1:35:30<44:17,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11341: train loss 1.29424. lr 4.384537e-04:  69%|██████▉   | 11342/16329 [1:35:30<43:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11342: train loss 1.30711. lr 4.384281e-04:  69%|██████▉   | 11342/16329 [1:35:31<43:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11342: train loss 1.30711. lr 4.384281e-04:  69%|██████▉   | 11343/16329 [1:35:31<43:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11343: train loss 1.30936. lr 4.384025e-04:  69%|██████▉   | 11343/16329 [1:35:31<43:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11343: train loss 1.30936. lr 4.384025e-04:  69%|██████▉   | 11344/16329 [1:35:31<42:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11344: train loss 1.27921. lr 4.383769e-04:  69%|██████▉   | 11344/16329 [1:35:32<42:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11344: train loss 1.27921. lr 4.383769e-04:  69%|██████▉   | 11345/16329 [1:35:32<42:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11345: train loss 1.31196. lr 4.383513e-04:  69%|██████▉   | 11345/16329 [1:35:32<42:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11345: train loss 1.31196. lr 4.383513e-04:  69%|██████▉   | 11346/16329 [1:35:32<41:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11346: train loss 1.29175. lr 4.383257e-04:  69%|██████▉   | 11346/16329 [1:35:33<41:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11346: train loss 1.29175. lr 4.383257e-04:  69%|██████▉   | 11347/16329 [1:35:33<41:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11347: train loss 1.32959. lr 4.383001e-04:  69%|██████▉   | 11347/16329 [1:35:33<41:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11347: train loss 1.32959. lr 4.383001e-04:  69%|██████▉   | 11348/16329 [1:35:33<41:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11348: train loss 1.29673. lr 4.382745e-04:  69%|██████▉   | 11348/16329 [1:35:34<41:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11348: train loss 1.29673. lr 4.382745e-04:  70%|██████▉   | 11349/16329 [1:35:34<41:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11349: train loss 1.28711. lr 4.382489e-04:  70%|██████▉   | 11349/16329 [1:35:34<41:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11349: train loss 1.28711. lr 4.382489e-04:  70%|██████▉   | 11350/16329 [1:35:34<41:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11350: train loss 1.32993. lr 4.382232e-04:  70%|██████▉   | 11350/16329 [1:35:35<41:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11350: train loss 1.32993. lr 4.382232e-04:  70%|██████▉   | 11351/16329 [1:35:35<42:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11351: train loss 1.31071. lr 4.381976e-04:  70%|██████▉   | 11351/16329 [1:35:35<42:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11351: train loss 1.31071. lr 4.381976e-04:  70%|██████▉   | 11352/16329 [1:35:35<42:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11352: train loss 1.30405. lr 4.381720e-04:  70%|██████▉   | 11352/16329 [1:35:36<42:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11352: train loss 1.30405. lr 4.381720e-04:  70%|██████▉   | 11353/16329 [1:35:36<42:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11353: train loss 1.29255. lr 4.381464e-04:  70%|██████▉   | 11353/16329 [1:35:36<42:43,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11353: train loss 1.29255. lr 4.381464e-04:  70%|██████▉   | 11354/16329 [1:35:36<42:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11354: train loss 1.28798. lr 4.381208e-04:  70%|██████▉   | 11354/16329 [1:35:37<42:38,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11354: train loss 1.28798. lr 4.381208e-04:  70%|██████▉   | 11355/16329 [1:35:37<42:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11355: train loss 1.28458. lr 4.380952e-04:  70%|██████▉   | 11355/16329 [1:35:37<42:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11355: train loss 1.28458. lr 4.380952e-04:  70%|██████▉   | 11356/16329 [1:35:37<41:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11356: train loss 1.31152. lr 4.380695e-04:  70%|██████▉   | 11356/16329 [1:35:38<41:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11356: train loss 1.31152. lr 4.380695e-04:  70%|██████▉   | 11357/16329 [1:35:38<41:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11357: train loss 1.27681. lr 4.380439e-04:  70%|██████▉   | 11357/16329 [1:35:38<41:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11357: train loss 1.27681. lr 4.380439e-04:  70%|██████▉   | 11358/16329 [1:35:38<41:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11358: train loss 1.28570. lr 4.380183e-04:  70%|██████▉   | 11358/16329 [1:35:39<41:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11358: train loss 1.28570. lr 4.380183e-04:  70%|██████▉   | 11359/16329 [1:35:39<41:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11359: train loss 1.32673. lr 4.379927e-04:  70%|██████▉   | 11359/16329 [1:35:39<41:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11359: train loss 1.32673. lr 4.379927e-04:  70%|██████▉   | 11360/16329 [1:35:39<41:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11360: train loss 1.29749. lr 4.379670e-04:  70%|██████▉   | 11360/16329 [1:35:40<41:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11360: train loss 1.29749. lr 4.379670e-04:  70%|██████▉   | 11361/16329 [1:35:40<41:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11361: train loss 1.29341. lr 4.379414e-04:  70%|██████▉   | 11361/16329 [1:35:40<41:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11361: train loss 1.29341. lr 4.379414e-04:  70%|██████▉   | 11362/16329 [1:35:40<41:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11362: train loss 1.28571. lr 4.379158e-04:  70%|██████▉   | 11362/16329 [1:35:41<41:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11362: train loss 1.28571. lr 4.379158e-04:  70%|██████▉   | 11363/16329 [1:35:41<40:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11363: train loss 1.30739. lr 4.378902e-04:  70%|██████▉   | 11363/16329 [1:35:41<40:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11363: train loss 1.30739. lr 4.378902e-04:  70%|██████▉   | 11364/16329 [1:35:41<41:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11364: train loss 1.32034. lr 4.378645e-04:  70%|██████▉   | 11364/16329 [1:35:42<41:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11364: train loss 1.32034. lr 4.378645e-04:  70%|██████▉   | 11365/16329 [1:35:42<40:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11365: train loss 1.36084. lr 4.378389e-04:  70%|██████▉   | 11365/16329 [1:35:42<40:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11365: train loss 1.36084. lr 4.378389e-04:  70%|██████▉   | 11366/16329 [1:35:42<40:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11366: train loss 1.29908. lr 4.378133e-04:  70%|██████▉   | 11366/16329 [1:35:43<40:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11366: train loss 1.29908. lr 4.378133e-04:  70%|██████▉   | 11367/16329 [1:35:43<40:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11367: train loss 1.27913. lr 4.377876e-04:  70%|██████▉   | 11367/16329 [1:35:43<40:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11367: train loss 1.27913. lr 4.377876e-04:  70%|██████▉   | 11368/16329 [1:35:43<40:54,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11368: train loss 1.27686. lr 4.377620e-04:  70%|██████▉   | 11368/16329 [1:35:44<40:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11368: train loss 1.27686. lr 4.377620e-04:  70%|██████▉   | 11369/16329 [1:35:44<40:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11369: train loss 1.28729. lr 4.377363e-04:  70%|██████▉   | 11369/16329 [1:35:44<40:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11369: train loss 1.28729. lr 4.377363e-04:  70%|██████▉   | 11370/16329 [1:35:44<40:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11370: train loss 1.27167. lr 4.377107e-04:  70%|██████▉   | 11370/16329 [1:35:45<40:47,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11370: train loss 1.27167. lr 4.377107e-04:  70%|██████▉   | 11371/16329 [1:35:45<40:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11371: train loss 1.30355. lr 4.376851e-04:  70%|██████▉   | 11371/16329 [1:35:45<40:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11371: train loss 1.30355. lr 4.376851e-04:  70%|██████▉   | 11372/16329 [1:35:45<40:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11372: train loss 1.32420. lr 4.376594e-04:  70%|██████▉   | 11372/16329 [1:35:46<40:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11372: train loss 1.32420. lr 4.376594e-04:  70%|██████▉   | 11373/16329 [1:35:46<45:14,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11373: train loss 1.31199. lr 4.376338e-04:  70%|██████▉   | 11373/16329 [1:35:46<45:14,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11373: train loss 1.31199. lr 4.376338e-04:  70%|██████▉   | 11374/16329 [1:35:46<44:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11374: train loss 1.31352. lr 4.376081e-04:  70%|██████▉   | 11374/16329 [1:35:47<44:01,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11374: train loss 1.31352. lr 4.376081e-04:  70%|██████▉   | 11375/16329 [1:35:47<42:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11375: train loss 1.28557. lr 4.375825e-04:  70%|██████▉   | 11375/16329 [1:35:47<42:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11375: train loss 1.28557. lr 4.375825e-04:  70%|██████▉   | 11376/16329 [1:35:47<42:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11376: train loss 1.30783. lr 4.375568e-04:  70%|██████▉   | 11376/16329 [1:35:48<42:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11376: train loss 1.30783. lr 4.375568e-04:  70%|██████▉   | 11377/16329 [1:35:48<41:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11377: train loss 1.32125. lr 4.375312e-04:  70%|██████▉   | 11377/16329 [1:35:48<41:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11377: train loss 1.32125. lr 4.375312e-04:  70%|██████▉   | 11378/16329 [1:35:48<41:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11378: train loss 1.27934. lr 4.375055e-04:  70%|██████▉   | 11378/16329 [1:35:49<41:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11378: train loss 1.27934. lr 4.375055e-04:  70%|██████▉   | 11379/16329 [1:35:49<41:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11379: train loss 1.28920. lr 4.374799e-04:  70%|██████▉   | 11379/16329 [1:35:49<41:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11379: train loss 1.28920. lr 4.374799e-04:  70%|██████▉   | 11380/16329 [1:35:49<41:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11380: train loss 1.31969. lr 4.374542e-04:  70%|██████▉   | 11380/16329 [1:35:50<41:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11380: train loss 1.31969. lr 4.374542e-04:  70%|██████▉   | 11381/16329 [1:35:50<41:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11381: train loss 1.32367. lr 4.374286e-04:  70%|██████▉   | 11381/16329 [1:35:50<41:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11381: train loss 1.32367. lr 4.374286e-04:  70%|██████▉   | 11382/16329 [1:35:50<40:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11382: train loss 1.29754. lr 4.374029e-04:  70%|██████▉   | 11382/16329 [1:35:51<40:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11382: train loss 1.29754. lr 4.374029e-04:  70%|██████▉   | 11383/16329 [1:35:51<40:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11383: train loss 1.29794. lr 4.373773e-04:  70%|██████▉   | 11383/16329 [1:35:51<40:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11383: train loss 1.29794. lr 4.373773e-04:  70%|██████▉   | 11384/16329 [1:35:51<40:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11384: train loss 1.29136. lr 4.373516e-04:  70%|██████▉   | 11384/16329 [1:35:52<40:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11384: train loss 1.29136. lr 4.373516e-04:  70%|██████▉   | 11385/16329 [1:35:52<40:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11385: train loss 1.28066. lr 4.373260e-04:  70%|██████▉   | 11385/16329 [1:35:52<40:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11385: train loss 1.28066. lr 4.373260e-04:  70%|██████▉   | 11386/16329 [1:35:52<42:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11386: train loss 1.30110. lr 4.373003e-04:  70%|██████▉   | 11386/16329 [1:35:53<42:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11386: train loss 1.30110. lr 4.373003e-04:  70%|██████▉   | 11387/16329 [1:35:53<43:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11387: train loss 1.32241. lr 4.372746e-04:  70%|██████▉   | 11387/16329 [1:35:53<43:40,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11387: train loss 1.32241. lr 4.372746e-04:  70%|██████▉   | 11388/16329 [1:35:53<44:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11388: train loss 1.30244. lr 4.372490e-04:  70%|██████▉   | 11388/16329 [1:35:54<44:06,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11388: train loss 1.30244. lr 4.372490e-04:  70%|██████▉   | 11389/16329 [1:35:54<43:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11389: train loss 1.29684. lr 4.372233e-04:  70%|██████▉   | 11389/16329 [1:35:54<43:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11389: train loss 1.29684. lr 4.372233e-04:  70%|██████▉   | 11390/16329 [1:35:54<43:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11390: train loss 1.30565. lr 4.371976e-04:  70%|██████▉   | 11390/16329 [1:35:55<43:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 11390: train loss 1.30565. lr 4.371976e-04:  70%|██████▉   | 11391/16329 [1:35:55<42:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11391: train loss 1.29501. lr 4.371720e-04:  70%|██████▉   | 11391/16329 [1:35:55<42:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11391: train loss 1.29501. lr 4.371720e-04:  70%|██████▉   | 11392/16329 [1:35:55<42:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11392: train loss 1.30026. lr 4.371463e-04:  70%|██████▉   | 11392/16329 [1:35:56<42:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11392: train loss 1.30026. lr 4.371463e-04:  70%|██████▉   | 11393/16329 [1:35:56<42:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11393: train loss 1.26707. lr 4.371206e-04:  70%|██████▉   | 11393/16329 [1:35:56<42:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11393: train loss 1.26707. lr 4.371206e-04:  70%|██████▉   | 11394/16329 [1:35:56<41:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11394: train loss 1.32480. lr 4.370950e-04:  70%|██████▉   | 11394/16329 [1:35:57<41:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11394: train loss 1.32480. lr 4.370950e-04:  70%|██████▉   | 11395/16329 [1:35:57<41:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11395: train loss 1.32571. lr 4.370693e-04:  70%|██████▉   | 11395/16329 [1:35:57<41:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11395: train loss 1.32571. lr 4.370693e-04:  70%|██████▉   | 11396/16329 [1:35:57<41:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11396: train loss 1.28064. lr 4.370436e-04:  70%|██████▉   | 11396/16329 [1:35:58<41:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11396: train loss 1.28064. lr 4.370436e-04:  70%|██████▉   | 11397/16329 [1:35:58<41:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11397: train loss 1.31422. lr 4.370180e-04:  70%|██████▉   | 11397/16329 [1:35:59<41:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11397: train loss 1.31422. lr 4.370180e-04:  70%|██████▉   | 11398/16329 [1:35:59<45:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11398: train loss 1.32670. lr 4.369923e-04:  70%|██████▉   | 11398/16329 [1:35:59<45:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11398: train loss 1.32670. lr 4.369923e-04:  70%|██████▉   | 11399/16329 [1:35:59<43:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11399: train loss 1.29827. lr 4.369666e-04:  70%|██████▉   | 11399/16329 [1:36:00<43:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11399: train loss 1.29827. lr 4.369666e-04:  70%|██████▉   | 11400/16329 [1:36:00<42:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11400: train loss 1.34599. lr 4.369409e-04:  70%|██████▉   | 11400/16329 [1:36:00<42:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11400: train loss 1.34599. lr 4.369409e-04:  70%|██████▉   | 11401/16329 [1:36:00<42:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11401: train loss 1.29814. lr 4.369153e-04:  70%|██████▉   | 11401/16329 [1:36:01<42:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11401: train loss 1.29814. lr 4.369153e-04:  70%|██████▉   | 11402/16329 [1:36:01<41:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11402: train loss 1.32233. lr 4.368896e-04:  70%|██████▉   | 11402/16329 [1:36:01<41:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11402: train loss 1.32233. lr 4.368896e-04:  70%|██████▉   | 11403/16329 [1:36:01<41:19,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11403: train loss 1.32432. lr 4.368639e-04:  70%|██████▉   | 11403/16329 [1:36:01<41:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11403: train loss 1.32432. lr 4.368639e-04:  70%|██████▉   | 11404/16329 [1:36:01<41:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11404: train loss 1.27690. lr 4.368382e-04:  70%|██████▉   | 11404/16329 [1:36:02<41:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11404: train loss 1.27690. lr 4.368382e-04:  70%|██████▉   | 11405/16329 [1:36:02<40:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11405: train loss 1.31378. lr 4.368125e-04:  70%|██████▉   | 11405/16329 [1:36:02<40:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11405: train loss 1.31378. lr 4.368125e-04:  70%|██████▉   | 11406/16329 [1:36:02<40:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11406: train loss 1.30085. lr 4.367868e-04:  70%|██████▉   | 11406/16329 [1:36:03<40:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11406: train loss 1.30085. lr 4.367868e-04:  70%|██████▉   | 11407/16329 [1:36:03<40:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11407: train loss 1.29577. lr 4.367612e-04:  70%|██████▉   | 11407/16329 [1:36:03<40:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11407: train loss 1.29577. lr 4.367612e-04:  70%|██████▉   | 11408/16329 [1:36:03<40:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11408: train loss 1.29581. lr 4.367355e-04:  70%|██████▉   | 11408/16329 [1:36:04<40:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11408: train loss 1.29581. lr 4.367355e-04:  70%|██████▉   | 11409/16329 [1:36:04<40:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11409: train loss 1.31306. lr 4.367098e-04:  70%|██████▉   | 11409/16329 [1:36:04<40:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11409: train loss 1.31306. lr 4.367098e-04:  70%|██████▉   | 11410/16329 [1:36:04<40:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11410: train loss 1.32091. lr 4.366841e-04:  70%|██████▉   | 11410/16329 [1:36:05<40:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11410: train loss 1.32091. lr 4.366841e-04:  70%|██████▉   | 11411/16329 [1:36:05<40:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11411: train loss 1.28820. lr 4.366584e-04:  70%|██████▉   | 11411/16329 [1:36:05<40:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11411: train loss 1.28820. lr 4.366584e-04:  70%|██████▉   | 11412/16329 [1:36:05<40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11412: train loss 1.28306. lr 4.366327e-04:  70%|██████▉   | 11412/16329 [1:36:06<40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11412: train loss 1.28306. lr 4.366327e-04:  70%|██████▉   | 11413/16329 [1:36:06<40:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11413: train loss 1.26859. lr 4.366070e-04:  70%|██████▉   | 11413/16329 [1:36:06<40:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11413: train loss 1.26859. lr 4.366070e-04:  70%|██████▉   | 11414/16329 [1:36:06<40:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11414: train loss 1.28081. lr 4.365813e-04:  70%|██████▉   | 11414/16329 [1:36:07<40:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11414: train loss 1.28081. lr 4.365813e-04:  70%|██████▉   | 11415/16329 [1:36:07<40:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11415: train loss 1.28214. lr 4.365556e-04:  70%|██████▉   | 11415/16329 [1:36:07<40:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11415: train loss 1.28214. lr 4.365556e-04:  70%|██████▉   | 11416/16329 [1:36:07<40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11416: train loss 1.27646. lr 4.365299e-04:  70%|██████▉   | 11416/16329 [1:36:08<40:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11416: train loss 1.27646. lr 4.365299e-04:  70%|██████▉   | 11417/16329 [1:36:08<40:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11417: train loss 1.29494. lr 4.365042e-04:  70%|██████▉   | 11417/16329 [1:36:08<40:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11417: train loss 1.29494. lr 4.365042e-04:  70%|██████▉   | 11418/16329 [1:36:08<40:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11418: train loss 1.30554. lr 4.364785e-04:  70%|██████▉   | 11418/16329 [1:36:09<40:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11418: train loss 1.30554. lr 4.364785e-04:  70%|██████▉   | 11419/16329 [1:36:09<40:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11419: train loss 1.26785. lr 4.364528e-04:  70%|██████▉   | 11419/16329 [1:36:09<40:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11419: train loss 1.26785. lr 4.364528e-04:  70%|██████▉   | 11420/16329 [1:36:09<40:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11420: train loss 1.30791. lr 4.364271e-04:  70%|██████▉   | 11420/16329 [1:36:10<40:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11420: train loss 1.30791. lr 4.364271e-04:  70%|██████▉   | 11421/16329 [1:36:10<40:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11421: train loss 1.32356. lr 4.364014e-04:  70%|██████▉   | 11421/16329 [1:36:10<40:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11421: train loss 1.32356. lr 4.364014e-04:  70%|██████▉   | 11422/16329 [1:36:10<40:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11422: train loss 1.30091. lr 4.363757e-04:  70%|██████▉   | 11422/16329 [1:36:11<40:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11422: train loss 1.30091. lr 4.363757e-04:  70%|██████▉   | 11423/16329 [1:36:11<40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11423: train loss 1.30269. lr 4.363500e-04:  70%|██████▉   | 11423/16329 [1:36:11<40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11423: train loss 1.30269. lr 4.363500e-04:  70%|██████▉   | 11424/16329 [1:36:11<40:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11424: train loss 1.32952. lr 4.363243e-04:  70%|██████▉   | 11424/16329 [1:36:12<40:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11424: train loss 1.32952. lr 4.363243e-04:  70%|██████▉   | 11425/16329 [1:36:12<44:51,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11425: train loss 1.27592. lr 4.362986e-04:  70%|██████▉   | 11425/16329 [1:36:13<44:51,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11425: train loss 1.27592. lr 4.362986e-04:  70%|██████▉   | 11426/16329 [1:36:13<43:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11426: train loss 1.27864. lr 4.362729e-04:  70%|██████▉   | 11426/16329 [1:36:13<43:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11426: train loss 1.27864. lr 4.362729e-04:  70%|██████▉   | 11427/16329 [1:36:13<42:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11427: train loss 1.29419. lr 4.362472e-04:  70%|██████▉   | 11427/16329 [1:36:14<42:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11427: train loss 1.29419. lr 4.362472e-04:  70%|██████▉   | 11428/16329 [1:36:14<41:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11428: train loss 1.31972. lr 4.362214e-04:  70%|██████▉   | 11428/16329 [1:36:14<41:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11428: train loss 1.31972. lr 4.362214e-04:  70%|██████▉   | 11429/16329 [1:36:14<41:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11429: train loss 1.30409. lr 4.361957e-04:  70%|██████▉   | 11429/16329 [1:36:15<41:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11429: train loss 1.30409. lr 4.361957e-04:  70%|██████▉   | 11430/16329 [1:36:15<41:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11430: train loss 1.29885. lr 4.361700e-04:  70%|██████▉   | 11430/16329 [1:36:15<41:09,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11430: train loss 1.29885. lr 4.361700e-04:  70%|███████   | 11431/16329 [1:36:15<40:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11431: train loss 1.28016. lr 4.361443e-04:  70%|███████   | 11431/16329 [1:36:16<40:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11431: train loss 1.28016. lr 4.361443e-04:  70%|███████   | 11432/16329 [1:36:16<40:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11432: train loss 1.30609. lr 4.361186e-04:  70%|███████   | 11432/16329 [1:36:16<40:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11432: train loss 1.30609. lr 4.361186e-04:  70%|███████   | 11433/16329 [1:36:16<40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11433: train loss 1.35027. lr 4.360929e-04:  70%|███████   | 11433/16329 [1:36:17<40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11433: train loss 1.35027. lr 4.360929e-04:  70%|███████   | 11434/16329 [1:36:17<40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11434: train loss 1.32778. lr 4.360671e-04:  70%|███████   | 11434/16329 [1:36:17<40:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11434: train loss 1.32778. lr 4.360671e-04:  70%|███████   | 11435/16329 [1:36:17<40:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11435: train loss 1.24516. lr 4.360414e-04:  70%|███████   | 11435/16329 [1:36:18<40:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11435: train loss 1.24516. lr 4.360414e-04:  70%|███████   | 11436/16329 [1:36:18<40:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11436: train loss 1.30610. lr 4.360157e-04:  70%|███████   | 11436/16329 [1:36:18<40:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11436: train loss 1.30610. lr 4.360157e-04:  70%|███████   | 11437/16329 [1:36:18<40:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11437: train loss 1.30418. lr 4.359900e-04:  70%|███████   | 11437/16329 [1:36:18<40:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11437: train loss 1.30418. lr 4.359900e-04:  70%|███████   | 11438/16329 [1:36:18<40:18,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11438: train loss 1.26814. lr 4.359642e-04:  70%|███████   | 11438/16329 [1:36:19<40:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11438: train loss 1.26814. lr 4.359642e-04:  70%|███████   | 11439/16329 [1:36:19<41:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11439: train loss 1.28268. lr 4.359385e-04:  70%|███████   | 11439/16329 [1:36:20<41:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11439: train loss 1.28268. lr 4.359385e-04:  70%|███████   | 11440/16329 [1:36:20<41:49,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11440: train loss 1.30432. lr 4.359128e-04:  70%|███████   | 11440/16329 [1:36:20<41:49,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11440: train loss 1.30432. lr 4.359128e-04:  70%|███████   | 11441/16329 [1:36:20<41:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11441: train loss 1.26232. lr 4.358871e-04:  70%|███████   | 11441/16329 [1:36:21<41:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11441: train loss 1.26232. lr 4.358871e-04:  70%|███████   | 11442/16329 [1:36:21<41:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11442: train loss 1.29177. lr 4.358613e-04:  70%|███████   | 11442/16329 [1:36:21<41:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11442: train loss 1.29177. lr 4.358613e-04:  70%|███████   | 11443/16329 [1:36:21<41:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11443: train loss 1.28540. lr 4.358356e-04:  70%|███████   | 11443/16329 [1:36:22<41:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11443: train loss 1.28540. lr 4.358356e-04:  70%|███████   | 11444/16329 [1:36:22<41:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11444: train loss 1.31740. lr 4.358099e-04:  70%|███████   | 11444/16329 [1:36:22<41:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11444: train loss 1.31740. lr 4.358099e-04:  70%|███████   | 11445/16329 [1:36:22<41:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11445: train loss 1.29962. lr 4.357841e-04:  70%|███████   | 11445/16329 [1:36:23<41:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11445: train loss 1.29962. lr 4.357841e-04:  70%|███████   | 11446/16329 [1:36:23<40:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11446: train loss 1.30509. lr 4.357584e-04:  70%|███████   | 11446/16329 [1:36:23<40:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11446: train loss 1.30509. lr 4.357584e-04:  70%|███████   | 11447/16329 [1:36:23<40:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11447: train loss 1.25643. lr 4.357327e-04:  70%|███████   | 11447/16329 [1:36:24<40:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11447: train loss 1.25643. lr 4.357327e-04:  70%|███████   | 11448/16329 [1:36:24<40:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11448: train loss 1.26997. lr 4.357069e-04:  70%|███████   | 11448/16329 [1:36:24<40:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11448: train loss 1.26997. lr 4.357069e-04:  70%|███████   | 11449/16329 [1:36:24<40:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11449: train loss 1.28555. lr 4.356812e-04:  70%|███████   | 11449/16329 [1:36:25<40:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11449: train loss 1.28555. lr 4.356812e-04:  70%|███████   | 11450/16329 [1:36:25<40:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11450: train loss 1.28419. lr 4.356554e-04:  70%|███████   | 11450/16329 [1:36:25<40:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11450: train loss 1.28419. lr 4.356554e-04:  70%|███████   | 11451/16329 [1:36:25<40:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11451: train loss 1.27261. lr 4.356297e-04:  70%|███████   | 11451/16329 [1:36:26<40:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11451: train loss 1.27261. lr 4.356297e-04:  70%|███████   | 11452/16329 [1:36:26<40:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11452: train loss 1.28937. lr 4.356040e-04:  70%|███████   | 11452/16329 [1:36:26<40:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11452: train loss 1.28937. lr 4.356040e-04:  70%|███████   | 11453/16329 [1:36:26<40:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11453: train loss 1.26653. lr 4.355782e-04:  70%|███████   | 11453/16329 [1:36:27<40:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11453: train loss 1.26653. lr 4.355782e-04:  70%|███████   | 11454/16329 [1:36:27<40:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11454: train loss 1.27665. lr 4.355525e-04:  70%|███████   | 11454/16329 [1:36:27<40:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11454: train loss 1.27665. lr 4.355525e-04:  70%|███████   | 11455/16329 [1:36:27<40:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11455: train loss 1.26921. lr 4.355267e-04:  70%|███████   | 11455/16329 [1:36:28<40:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11455: train loss 1.26921. lr 4.355267e-04:  70%|███████   | 11456/16329 [1:36:28<40:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11456: train loss 1.32808. lr 4.355010e-04:  70%|███████   | 11456/16329 [1:36:28<40:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11456: train loss 1.32808. lr 4.355010e-04:  70%|███████   | 11457/16329 [1:36:28<40:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11457: train loss 1.24805. lr 4.354752e-04:  70%|███████   | 11457/16329 [1:36:29<40:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11457: train loss 1.24805. lr 4.354752e-04:  70%|███████   | 11458/16329 [1:36:29<40:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11458: train loss 1.28911. lr 4.354495e-04:  70%|███████   | 11458/16329 [1:36:29<40:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11458: train loss 1.28911. lr 4.354495e-04:  70%|███████   | 11459/16329 [1:36:29<41:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11459: train loss 1.29969. lr 4.354237e-04:  70%|███████   | 11459/16329 [1:36:30<41:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11459: train loss 1.29969. lr 4.354237e-04:  70%|███████   | 11460/16329 [1:36:30<41:50,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11460: train loss 1.26608. lr 4.353980e-04:  70%|███████   | 11460/16329 [1:36:30<41:50,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11460: train loss 1.26608. lr 4.353980e-04:  70%|███████   | 11461/16329 [1:36:30<42:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11461: train loss 1.33168. lr 4.353722e-04:  70%|███████   | 11461/16329 [1:36:31<42:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11461: train loss 1.33168. lr 4.353722e-04:  70%|███████   | 11462/16329 [1:36:31<41:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11462: train loss 1.30766. lr 4.353465e-04:  70%|███████   | 11462/16329 [1:36:31<41:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11462: train loss 1.30766. lr 4.353465e-04:  70%|███████   | 11463/16329 [1:36:31<41:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11463: train loss 1.27145. lr 4.353207e-04:  70%|███████   | 11463/16329 [1:36:32<41:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11463: train loss 1.27145. lr 4.353207e-04:  70%|███████   | 11464/16329 [1:36:32<41:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11464: train loss 1.30233. lr 4.352949e-04:  70%|███████   | 11464/16329 [1:36:32<41:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11464: train loss 1.30233. lr 4.352949e-04:  70%|███████   | 11465/16329 [1:36:32<45:41,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 11465: train loss 1.28712. lr 4.352692e-04:  70%|███████   | 11465/16329 [1:36:33<45:41,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 11465: train loss 1.28712. lr 4.352692e-04:  70%|███████   | 11466/16329 [1:36:33<44:02,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11466: train loss 1.31005. lr 4.352434e-04:  70%|███████   | 11466/16329 [1:36:33<44:02,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11466: train loss 1.31005. lr 4.352434e-04:  70%|███████   | 11467/16329 [1:36:33<42:58,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11467: train loss 1.30941. lr 4.352177e-04:  70%|███████   | 11467/16329 [1:36:34<42:58,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11467: train loss 1.30941. lr 4.352177e-04:  70%|███████   | 11468/16329 [1:36:34<42:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11468: train loss 1.29879. lr 4.351919e-04:  70%|███████   | 11468/16329 [1:36:34<42:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11468: train loss 1.29879. lr 4.351919e-04:  70%|███████   | 11469/16329 [1:36:34<41:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11469: train loss 1.29382. lr 4.351661e-04:  70%|███████   | 11469/16329 [1:36:35<41:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11469: train loss 1.29382. lr 4.351661e-04:  70%|███████   | 11470/16329 [1:36:35<41:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11470: train loss 1.27722. lr 4.351404e-04:  70%|███████   | 11470/16329 [1:36:35<41:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11470: train loss 1.27722. lr 4.351404e-04:  70%|███████   | 11471/16329 [1:36:35<40:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11471: train loss 1.30159. lr 4.351146e-04:  70%|███████   | 11471/16329 [1:36:36<40:39,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11471: train loss 1.30159. lr 4.351146e-04:  70%|███████   | 11472/16329 [1:36:36<40:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11472: train loss 1.28789. lr 4.350888e-04:  70%|███████   | 11472/16329 [1:36:36<40:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11472: train loss 1.28789. lr 4.350888e-04:  70%|███████   | 11473/16329 [1:36:36<40:15,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11473: train loss 1.30410. lr 4.350631e-04:  70%|███████   | 11473/16329 [1:36:37<40:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11473: train loss 1.30410. lr 4.350631e-04:  70%|███████   | 11474/16329 [1:36:37<40:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11474: train loss 1.30987. lr 4.350373e-04:  70%|███████   | 11474/16329 [1:36:37<40:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11474: train loss 1.30987. lr 4.350373e-04:  70%|███████   | 11475/16329 [1:36:37<40:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11475: train loss 1.30252. lr 4.350115e-04:  70%|███████   | 11475/16329 [1:36:38<40:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11475: train loss 1.30252. lr 4.350115e-04:  70%|███████   | 11476/16329 [1:36:38<40:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11476: train loss 1.32620. lr 4.349858e-04:  70%|███████   | 11476/16329 [1:36:38<40:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11476: train loss 1.32620. lr 4.349858e-04:  70%|███████   | 11477/16329 [1:36:38<40:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11477: train loss 1.29241. lr 4.349600e-04:  70%|███████   | 11477/16329 [1:36:39<40:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11477: train loss 1.29241. lr 4.349600e-04:  70%|███████   | 11478/16329 [1:36:39<39:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11478: train loss 1.30667. lr 4.349342e-04:  70%|███████   | 11478/16329 [1:36:39<39:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11478: train loss 1.30667. lr 4.349342e-04:  70%|███████   | 11479/16329 [1:36:39<40:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11479: train loss 1.30678. lr 4.349084e-04:  70%|███████   | 11479/16329 [1:36:40<40:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11479: train loss 1.30678. lr 4.349084e-04:  70%|███████   | 11480/16329 [1:36:40<40:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11480: train loss 1.27591. lr 4.348826e-04:  70%|███████   | 11480/16329 [1:36:40<40:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11480: train loss 1.27591. lr 4.348826e-04:  70%|███████   | 11481/16329 [1:36:40<40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11481: train loss 1.27644. lr 4.348569e-04:  70%|███████   | 11481/16329 [1:36:41<40:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11481: train loss 1.27644. lr 4.348569e-04:  70%|███████   | 11482/16329 [1:36:41<40:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11482: train loss 1.29799. lr 4.348311e-04:  70%|███████   | 11482/16329 [1:36:41<40:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11482: train loss 1.29799. lr 4.348311e-04:  70%|███████   | 11483/16329 [1:36:41<40:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11483: train loss 1.28492. lr 4.348053e-04:  70%|███████   | 11483/16329 [1:36:42<40:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11483: train loss 1.28492. lr 4.348053e-04:  70%|███████   | 11484/16329 [1:36:42<40:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11484: train loss 1.30769. lr 4.347795e-04:  70%|███████   | 11484/16329 [1:36:42<40:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11484: train loss 1.30769. lr 4.347795e-04:  70%|███████   | 11485/16329 [1:36:42<40:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11485: train loss 1.30196. lr 4.347537e-04:  70%|███████   | 11485/16329 [1:36:43<40:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11485: train loss 1.30196. lr 4.347537e-04:  70%|███████   | 11486/16329 [1:36:43<40:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11486: train loss 1.28713. lr 4.347280e-04:  70%|███████   | 11486/16329 [1:36:43<40:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11486: train loss 1.28713. lr 4.347280e-04:  70%|███████   | 11487/16329 [1:36:43<40:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11487: train loss 1.28049. lr 4.347022e-04:  70%|███████   | 11487/16329 [1:36:44<40:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11487: train loss 1.28049. lr 4.347022e-04:  70%|███████   | 11488/16329 [1:36:44<40:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11488: train loss 1.31559. lr 4.346764e-04:  70%|███████   | 11488/16329 [1:36:44<40:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11488: train loss 1.31559. lr 4.346764e-04:  70%|███████   | 11489/16329 [1:36:44<40:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11489: train loss 1.28117. lr 4.346506e-04:  70%|███████   | 11489/16329 [1:36:45<40:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11489: train loss 1.28117. lr 4.346506e-04:  70%|███████   | 11490/16329 [1:36:45<40:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11490: train loss 1.25870. lr 4.346248e-04:  70%|███████   | 11490/16329 [1:36:45<40:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11490: train loss 1.25870. lr 4.346248e-04:  70%|███████   | 11491/16329 [1:36:45<40:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11491: train loss 1.30357. lr 4.345990e-04:  70%|███████   | 11491/16329 [1:36:46<40:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11491: train loss 1.30357. lr 4.345990e-04:  70%|███████   | 11492/16329 [1:36:46<39:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11492: train loss 1.29754. lr 4.345732e-04:  70%|███████   | 11492/16329 [1:36:46<39:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11492: train loss 1.29754. lr 4.345732e-04:  70%|███████   | 11493/16329 [1:36:46<40:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11493: train loss 1.31565. lr 4.345474e-04:  70%|███████   | 11493/16329 [1:36:47<40:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11493: train loss 1.31565. lr 4.345474e-04:  70%|███████   | 11494/16329 [1:36:47<40:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11494: train loss 1.31419. lr 4.345216e-04:  70%|███████   | 11494/16329 [1:36:47<40:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11494: train loss 1.31419. lr 4.345216e-04:  70%|███████   | 11495/16329 [1:36:47<40:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11495: train loss 1.26725. lr 4.344958e-04:  70%|███████   | 11495/16329 [1:36:48<40:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11495: train loss 1.26725. lr 4.344958e-04:  70%|███████   | 11496/16329 [1:36:48<39:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11496: train loss 1.30159. lr 4.344700e-04:  70%|███████   | 11496/16329 [1:36:48<39:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11496: train loss 1.30159. lr 4.344700e-04:  70%|███████   | 11497/16329 [1:36:48<39:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11497: train loss 1.28191. lr 4.344442e-04:  70%|███████   | 11497/16329 [1:36:49<39:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11497: train loss 1.28191. lr 4.344442e-04:  70%|███████   | 11498/16329 [1:36:49<40:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11498: train loss 1.32310. lr 4.344184e-04:  70%|███████   | 11498/16329 [1:36:49<40:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11498: train loss 1.32310. lr 4.344184e-04:  70%|███████   | 11499/16329 [1:36:49<39:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11499: train loss 1.25664. lr 4.343926e-04:  70%|███████   | 11499/16329 [1:36:50<39:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11499: train loss 1.25664. lr 4.343926e-04:  70%|███████   | 11500/16329 [1:36:50<44:32,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11500: train loss 1.30042. lr 4.343668e-04:  70%|███████   | 11500/16329 [1:36:50<44:32,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11500: train loss 1.30042. lr 4.343668e-04:  70%|███████   | 11501/16329 [1:36:50<43:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11501: train loss 1.24854. lr 4.343410e-04:  70%|███████   | 11501/16329 [1:36:51<43:05,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11501: train loss 1.24854. lr 4.343410e-04:  70%|███████   | 11502/16329 [1:36:51<42:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11502: train loss 1.27211. lr 4.343152e-04:  70%|███████   | 11502/16329 [1:36:51<42:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11502: train loss 1.27211. lr 4.343152e-04:  70%|███████   | 11503/16329 [1:36:51<41:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11503: train loss 1.27851. lr 4.342894e-04:  70%|███████   | 11503/16329 [1:36:52<41:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11503: train loss 1.27851. lr 4.342894e-04:  70%|███████   | 11504/16329 [1:36:52<40:53,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11504: train loss 1.28360. lr 4.342636e-04:  70%|███████   | 11504/16329 [1:36:52<40:53,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11504: train loss 1.28360. lr 4.342636e-04:  70%|███████   | 11505/16329 [1:36:52<40:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11505: train loss 1.27797. lr 4.342378e-04:  70%|███████   | 11505/16329 [1:36:53<40:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11505: train loss 1.27797. lr 4.342378e-04:  70%|███████   | 11506/16329 [1:36:53<40:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11506: train loss 1.32753. lr 4.342120e-04:  70%|███████   | 11506/16329 [1:36:53<40:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11506: train loss 1.32753. lr 4.342120e-04:  70%|███████   | 11507/16329 [1:36:53<40:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11507: train loss 1.28465. lr 4.341862e-04:  70%|███████   | 11507/16329 [1:36:54<40:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11507: train loss 1.28465. lr 4.341862e-04:  70%|███████   | 11508/16329 [1:36:54<40:03,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11508: train loss 1.29295. lr 4.341604e-04:  70%|███████   | 11508/16329 [1:36:54<40:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11508: train loss 1.29295. lr 4.341604e-04:  70%|███████   | 11509/16329 [1:36:54<39:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11509: train loss 1.26793. lr 4.341345e-04:  70%|███████   | 11509/16329 [1:36:55<39:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11509: train loss 1.26793. lr 4.341345e-04:  70%|███████   | 11510/16329 [1:36:55<39:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11510: train loss 1.27226. lr 4.341087e-04:  70%|███████   | 11510/16329 [1:36:55<39:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11510: train loss 1.27226. lr 4.341087e-04:  70%|███████   | 11511/16329 [1:36:55<39:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11511: train loss 1.27693. lr 4.340829e-04:  70%|███████   | 11511/16329 [1:36:56<39:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11511: train loss 1.27693. lr 4.340829e-04:  71%|███████   | 11512/16329 [1:36:56<39:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11512: train loss 1.34385. lr 4.340571e-04:  71%|███████   | 11512/16329 [1:36:56<39:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11512: train loss 1.34385. lr 4.340571e-04:  71%|███████   | 11513/16329 [1:36:56<39:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11513: train loss 1.30013. lr 4.340313e-04:  71%|███████   | 11513/16329 [1:36:57<39:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11513: train loss 1.30013. lr 4.340313e-04:  71%|███████   | 11514/16329 [1:36:57<39:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11514: train loss 1.26530. lr 4.340054e-04:  71%|███████   | 11514/16329 [1:36:57<39:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11514: train loss 1.26530. lr 4.340054e-04:  71%|███████   | 11515/16329 [1:36:57<39:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11515: train loss 1.27717. lr 4.339796e-04:  71%|███████   | 11515/16329 [1:36:58<39:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11515: train loss 1.27717. lr 4.339796e-04:  71%|███████   | 11516/16329 [1:36:58<39:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11516: train loss 1.25925. lr 4.339538e-04:  71%|███████   | 11516/16329 [1:36:58<39:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11516: train loss 1.25925. lr 4.339538e-04:  71%|███████   | 11517/16329 [1:36:58<39:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11517: train loss 1.28688. lr 4.339280e-04:  71%|███████   | 11517/16329 [1:36:59<39:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11517: train loss 1.28688. lr 4.339280e-04:  71%|███████   | 11518/16329 [1:36:59<39:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11518: train loss 1.31841. lr 4.339022e-04:  71%|███████   | 11518/16329 [1:36:59<39:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11518: train loss 1.31841. lr 4.339022e-04:  71%|███████   | 11519/16329 [1:36:59<39:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11519: train loss 1.28553. lr 4.338763e-04:  71%|███████   | 11519/16329 [1:37:00<39:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11519: train loss 1.28553. lr 4.338763e-04:  71%|███████   | 11520/16329 [1:37:00<39:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11520: train loss 1.26831. lr 4.338505e-04:  71%|███████   | 11520/16329 [1:37:00<39:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11520: train loss 1.26831. lr 4.338505e-04:  71%|███████   | 11521/16329 [1:37:00<39:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11521: train loss 1.30452. lr 4.338247e-04:  71%|███████   | 11521/16329 [1:37:01<39:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11521: train loss 1.30452. lr 4.338247e-04:  71%|███████   | 11522/16329 [1:37:01<39:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11522: train loss 1.33949. lr 4.337988e-04:  71%|███████   | 11522/16329 [1:37:01<39:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11522: train loss 1.33949. lr 4.337988e-04:  71%|███████   | 11523/16329 [1:37:01<39:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11523: train loss 1.27107. lr 4.337730e-04:  71%|███████   | 11523/16329 [1:37:02<39:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11523: train loss 1.27107. lr 4.337730e-04:  71%|███████   | 11524/16329 [1:37:02<39:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11524: train loss 1.25642. lr 4.337472e-04:  71%|███████   | 11524/16329 [1:37:02<39:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11524: train loss 1.25642. lr 4.337472e-04:  71%|███████   | 11525/16329 [1:37:02<43:57,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11525: train loss 1.27615. lr 4.337213e-04:  71%|███████   | 11525/16329 [1:37:03<43:57,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11525: train loss 1.27615. lr 4.337213e-04:  71%|███████   | 11526/16329 [1:37:03<42:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11526: train loss 1.27530. lr 4.336955e-04:  71%|███████   | 11526/16329 [1:37:03<42:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11526: train loss 1.27530. lr 4.336955e-04:  71%|███████   | 11527/16329 [1:37:03<41:43,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11527: train loss 1.30745. lr 4.336697e-04:  71%|███████   | 11527/16329 [1:37:04<41:43,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11527: train loss 1.30745. lr 4.336697e-04:  71%|███████   | 11528/16329 [1:37:04<40:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11528: train loss 1.28971. lr 4.336438e-04:  71%|███████   | 11528/16329 [1:37:04<40:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11528: train loss 1.28971. lr 4.336438e-04:  71%|███████   | 11529/16329 [1:37:04<40:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11529: train loss 1.28733. lr 4.336180e-04:  71%|███████   | 11529/16329 [1:37:05<40:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11529: train loss 1.28733. lr 4.336180e-04:  71%|███████   | 11530/16329 [1:37:05<40:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11530: train loss 1.26304. lr 4.335922e-04:  71%|███████   | 11530/16329 [1:37:05<40:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11530: train loss 1.26304. lr 4.335922e-04:  71%|███████   | 11531/16329 [1:37:05<40:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11531: train loss 1.29133. lr 4.335663e-04:  71%|███████   | 11531/16329 [1:37:06<40:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11531: train loss 1.29133. lr 4.335663e-04:  71%|███████   | 11532/16329 [1:37:06<39:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11532: train loss 1.28363. lr 4.335405e-04:  71%|███████   | 11532/16329 [1:37:06<39:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11532: train loss 1.28363. lr 4.335405e-04:  71%|███████   | 11533/16329 [1:37:06<39:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11533: train loss 1.27339. lr 4.335146e-04:  71%|███████   | 11533/16329 [1:37:07<39:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11533: train loss 1.27339. lr 4.335146e-04:  71%|███████   | 11534/16329 [1:37:07<39:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11534: train loss 1.28218. lr 4.334888e-04:  71%|███████   | 11534/16329 [1:37:07<39:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11534: train loss 1.28218. lr 4.334888e-04:  71%|███████   | 11535/16329 [1:37:07<39:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11535: train loss 1.30858. lr 4.334629e-04:  71%|███████   | 11535/16329 [1:37:08<39:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11535: train loss 1.30858. lr 4.334629e-04:  71%|███████   | 11536/16329 [1:37:08<39:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11536: train loss 1.29882. lr 4.334371e-04:  71%|███████   | 11536/16329 [1:37:08<39:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11536: train loss 1.29882. lr 4.334371e-04:  71%|███████   | 11537/16329 [1:37:08<39:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11537: train loss 1.29602. lr 4.334112e-04:  71%|███████   | 11537/16329 [1:37:09<39:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11537: train loss 1.29602. lr 4.334112e-04:  71%|███████   | 11538/16329 [1:37:09<39:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11538: train loss 1.28624. lr 4.333854e-04:  71%|███████   | 11538/16329 [1:37:09<39:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11538: train loss 1.28624. lr 4.333854e-04:  71%|███████   | 11539/16329 [1:37:09<39:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11539: train loss 1.27402. lr 4.333595e-04:  71%|███████   | 11539/16329 [1:37:10<39:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11539: train loss 1.27402. lr 4.333595e-04:  71%|███████   | 11540/16329 [1:37:10<39:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11540: train loss 1.29339. lr 4.333337e-04:  71%|███████   | 11540/16329 [1:37:10<39:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11540: train loss 1.29339. lr 4.333337e-04:  71%|███████   | 11541/16329 [1:37:10<39:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11541: train loss 1.27736. lr 4.333078e-04:  71%|███████   | 11541/16329 [1:37:11<39:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11541: train loss 1.27736. lr 4.333078e-04:  71%|███████   | 11542/16329 [1:37:11<39:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11542: train loss 1.30774. lr 4.332820e-04:  71%|███████   | 11542/16329 [1:37:11<39:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11542: train loss 1.30774. lr 4.332820e-04:  71%|███████   | 11543/16329 [1:37:11<39:44,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11543: train loss 1.27144. lr 4.332561e-04:  71%|███████   | 11543/16329 [1:37:12<39:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11543: train loss 1.27144. lr 4.332561e-04:  71%|███████   | 11544/16329 [1:37:12<39:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11544: train loss 1.31126. lr 4.332303e-04:  71%|███████   | 11544/16329 [1:37:12<39:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11544: train loss 1.31126. lr 4.332303e-04:  71%|███████   | 11545/16329 [1:37:12<39:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11545: train loss 1.30727. lr 4.332044e-04:  71%|███████   | 11545/16329 [1:37:13<39:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11545: train loss 1.30727. lr 4.332044e-04:  71%|███████   | 11546/16329 [1:37:13<39:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11546: train loss 1.28309. lr 4.331785e-04:  71%|███████   | 11546/16329 [1:37:13<39:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11546: train loss 1.28309. lr 4.331785e-04:  71%|███████   | 11547/16329 [1:37:13<39:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11547: train loss 1.27931. lr 4.331527e-04:  71%|███████   | 11547/16329 [1:37:14<39:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11547: train loss 1.27931. lr 4.331527e-04:  71%|███████   | 11548/16329 [1:37:14<39:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11548: train loss 1.26267. lr 4.331268e-04:  71%|███████   | 11548/16329 [1:37:14<39:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11548: train loss 1.26267. lr 4.331268e-04:  71%|███████   | 11549/16329 [1:37:14<39:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11549: train loss 1.29355. lr 4.331010e-04:  71%|███████   | 11549/16329 [1:37:15<39:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11549: train loss 1.29355. lr 4.331010e-04:  71%|███████   | 11550/16329 [1:37:15<39:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11550: train loss 1.32135. lr 4.330751e-04:  71%|███████   | 11550/16329 [1:37:15<39:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11550: train loss 1.32135. lr 4.330751e-04:  71%|███████   | 11551/16329 [1:37:15<39:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11551: train loss 1.29568. lr 4.330492e-04:  71%|███████   | 11551/16329 [1:37:16<39:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11551: train loss 1.29568. lr 4.330492e-04:  71%|███████   | 11552/16329 [1:37:16<43:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11552: train loss 1.30015. lr 4.330234e-04:  71%|███████   | 11552/16329 [1:37:17<43:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11552: train loss 1.30015. lr 4.330234e-04:  71%|███████   | 11553/16329 [1:37:17<42:41,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11553: train loss 1.29804. lr 4.329975e-04:  71%|███████   | 11553/16329 [1:37:17<42:41,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11553: train loss 1.29804. lr 4.329975e-04:  71%|███████   | 11554/16329 [1:37:17<41:42,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11554: train loss 1.26494. lr 4.329716e-04:  71%|███████   | 11554/16329 [1:37:18<41:42,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11554: train loss 1.26494. lr 4.329716e-04:  71%|███████   | 11555/16329 [1:37:18<41:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11555: train loss 1.24847. lr 4.329457e-04:  71%|███████   | 11555/16329 [1:37:18<41:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11555: train loss 1.24847. lr 4.329457e-04:  71%|███████   | 11556/16329 [1:37:18<40:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11556: train loss 1.28992. lr 4.329199e-04:  71%|███████   | 11556/16329 [1:37:18<40:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11556: train loss 1.28992. lr 4.329199e-04:  71%|███████   | 11557/16329 [1:37:18<40:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11557: train loss 1.29284. lr 4.328940e-04:  71%|███████   | 11557/16329 [1:37:19<40:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11557: train loss 1.29284. lr 4.328940e-04:  71%|███████   | 11558/16329 [1:37:19<40:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11558: train loss 1.31713. lr 4.328681e-04:  71%|███████   | 11558/16329 [1:37:19<40:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11558: train loss 1.31713. lr 4.328681e-04:  71%|███████   | 11559/16329 [1:37:19<39:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11559: train loss 1.28031. lr 4.328422e-04:  71%|███████   | 11559/16329 [1:37:20<39:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11559: train loss 1.28031. lr 4.328422e-04:  71%|███████   | 11560/16329 [1:37:20<39:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11560: train loss 1.28981. lr 4.328164e-04:  71%|███████   | 11560/16329 [1:37:20<39:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11560: train loss 1.28981. lr 4.328164e-04:  71%|███████   | 11561/16329 [1:37:20<39:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11561: train loss 1.27090. lr 4.327905e-04:  71%|███████   | 11561/16329 [1:37:21<39:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11561: train loss 1.27090. lr 4.327905e-04:  71%|███████   | 11562/16329 [1:37:21<39:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11562: train loss 1.28992. lr 4.327646e-04:  71%|███████   | 11562/16329 [1:37:21<39:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11562: train loss 1.28992. lr 4.327646e-04:  71%|███████   | 11563/16329 [1:37:21<39:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11563: train loss 1.25628. lr 4.327387e-04:  71%|███████   | 11563/16329 [1:37:22<39:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11563: train loss 1.25628. lr 4.327387e-04:  71%|███████   | 11564/16329 [1:37:22<39:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11564: train loss 1.28117. lr 4.327128e-04:  71%|███████   | 11564/16329 [1:37:22<39:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11564: train loss 1.28117. lr 4.327128e-04:  71%|███████   | 11565/16329 [1:37:22<39:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11565: train loss 1.29478. lr 4.326870e-04:  71%|███████   | 11565/16329 [1:37:23<39:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11565: train loss 1.29478. lr 4.326870e-04:  71%|███████   | 11566/16329 [1:37:23<39:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11566: train loss 1.25159. lr 4.326611e-04:  71%|███████   | 11566/16329 [1:37:23<39:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11566: train loss 1.25159. lr 4.326611e-04:  71%|███████   | 11567/16329 [1:37:23<39:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11567: train loss 1.27262. lr 4.326352e-04:  71%|███████   | 11567/16329 [1:37:24<39:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11567: train loss 1.27262. lr 4.326352e-04:  71%|███████   | 11568/16329 [1:37:24<39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11568: train loss 1.28448. lr 4.326093e-04:  71%|███████   | 11568/16329 [1:37:24<39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11568: train loss 1.28448. lr 4.326093e-04:  71%|███████   | 11569/16329 [1:37:24<39:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11569: train loss 1.28878. lr 4.325834e-04:  71%|███████   | 11569/16329 [1:37:25<39:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11569: train loss 1.28878. lr 4.325834e-04:  71%|███████   | 11570/16329 [1:37:25<39:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11570: train loss 1.24439. lr 4.325575e-04:  71%|███████   | 11570/16329 [1:37:25<39:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11570: train loss 1.24439. lr 4.325575e-04:  71%|███████   | 11571/16329 [1:37:25<39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11571: train loss 1.27884. lr 4.325316e-04:  71%|███████   | 11571/16329 [1:37:26<39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11571: train loss 1.27884. lr 4.325316e-04:  71%|███████   | 11572/16329 [1:37:26<39:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11572: train loss 1.27806. lr 4.325057e-04:  71%|███████   | 11572/16329 [1:37:26<39:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11572: train loss 1.27806. lr 4.325057e-04:  71%|███████   | 11573/16329 [1:37:26<39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11573: train loss 1.28267. lr 4.324799e-04:  71%|███████   | 11573/16329 [1:37:27<39:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11573: train loss 1.28267. lr 4.324799e-04:  71%|███████   | 11574/16329 [1:37:27<39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11574: train loss 1.26240. lr 4.324540e-04:  71%|███████   | 11574/16329 [1:37:27<39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11574: train loss 1.26240. lr 4.324540e-04:  71%|███████   | 11575/16329 [1:37:27<39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11575: train loss 1.29308. lr 4.324281e-04:  71%|███████   | 11575/16329 [1:37:28<39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11575: train loss 1.29308. lr 4.324281e-04:  71%|███████   | 11576/16329 [1:37:28<39:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11576: train loss 1.29367. lr 4.324022e-04:  71%|███████   | 11576/16329 [1:37:28<39:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11576: train loss 1.29367. lr 4.324022e-04:  71%|███████   | 11577/16329 [1:37:28<39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11577: train loss 1.25992. lr 4.323763e-04:  71%|███████   | 11577/16329 [1:37:29<39:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11577: train loss 1.25992. lr 4.323763e-04:  71%|███████   | 11578/16329 [1:37:29<39:13,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11578: train loss 1.26581. lr 4.323504e-04:  71%|███████   | 11578/16329 [1:37:29<39:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11578: train loss 1.26581. lr 4.323504e-04:  71%|███████   | 11579/16329 [1:37:29<39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11579: train loss 1.30653. lr 4.323245e-04:  71%|███████   | 11579/16329 [1:37:30<39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11579: train loss 1.30653. lr 4.323245e-04:  71%|███████   | 11580/16329 [1:37:30<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11580: train loss 1.27931. lr 4.322986e-04:  71%|███████   | 11580/16329 [1:37:30<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11580: train loss 1.27931. lr 4.322986e-04:  71%|███████   | 11581/16329 [1:37:30<39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11581: train loss 1.29083. lr 4.322727e-04:  71%|███████   | 11581/16329 [1:37:31<39:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11581: train loss 1.29083. lr 4.322727e-04:  71%|███████   | 11582/16329 [1:37:31<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11582: train loss 1.27546. lr 4.322468e-04:  71%|███████   | 11582/16329 [1:37:31<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11582: train loss 1.27546. lr 4.322468e-04:  71%|███████   | 11583/16329 [1:37:31<39:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11583: train loss 1.29246. lr 4.322209e-04:  71%|███████   | 11583/16329 [1:37:32<39:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11583: train loss 1.29246. lr 4.322209e-04:  71%|███████   | 11584/16329 [1:37:32<39:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11584: train loss 1.28005. lr 4.321949e-04:  71%|███████   | 11584/16329 [1:37:32<39:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11584: train loss 1.28005. lr 4.321949e-04:  71%|███████   | 11585/16329 [1:37:32<39:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11585: train loss 1.24061. lr 4.321690e-04:  71%|███████   | 11585/16329 [1:37:33<39:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11585: train loss 1.24061. lr 4.321690e-04:  71%|███████   | 11586/16329 [1:37:33<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11586: train loss 1.24906. lr 4.321431e-04:  71%|███████   | 11586/16329 [1:37:33<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11586: train loss 1.24906. lr 4.321431e-04:  71%|███████   | 11587/16329 [1:37:33<39:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11587: train loss 1.26009. lr 4.321172e-04:  71%|███████   | 11587/16329 [1:37:34<39:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11587: train loss 1.26009. lr 4.321172e-04:  71%|███████   | 11588/16329 [1:37:34<39:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11588: train loss 1.30141. lr 4.320913e-04:  71%|███████   | 11588/16329 [1:37:34<39:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11588: train loss 1.30141. lr 4.320913e-04:  71%|███████   | 11589/16329 [1:37:34<39:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11589: train loss 1.33836. lr 4.320654e-04:  71%|███████   | 11589/16329 [1:37:35<39:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11589: train loss 1.33836. lr 4.320654e-04:  71%|███████   | 11590/16329 [1:37:35<39:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11590: train loss 1.28068. lr 4.320395e-04:  71%|███████   | 11590/16329 [1:37:35<39:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11590: train loss 1.28068. lr 4.320395e-04:  71%|███████   | 11591/16329 [1:37:35<39:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11591: train loss 1.27218. lr 4.320136e-04:  71%|███████   | 11591/16329 [1:37:36<39:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11591: train loss 1.27218. lr 4.320136e-04:  71%|███████   | 11592/16329 [1:37:36<43:40,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11592: train loss 1.27072. lr 4.319877e-04:  71%|███████   | 11592/16329 [1:37:37<43:40,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11592: train loss 1.27072. lr 4.319877e-04:  71%|███████   | 11593/16329 [1:37:37<42:23,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11593: train loss 1.28207. lr 4.319617e-04:  71%|███████   | 11593/16329 [1:37:37<42:23,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11593: train loss 1.28207. lr 4.319617e-04:  71%|███████   | 11594/16329 [1:37:37<41:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11594: train loss 1.28251. lr 4.319358e-04:  71%|███████   | 11594/16329 [1:37:38<41:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11594: train loss 1.28251. lr 4.319358e-04:  71%|███████   | 11595/16329 [1:37:38<40:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11595: train loss 1.29056. lr 4.319099e-04:  71%|███████   | 11595/16329 [1:37:38<40:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11595: train loss 1.29056. lr 4.319099e-04:  71%|███████   | 11596/16329 [1:37:38<40:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11596: train loss 1.30457. lr 4.318840e-04:  71%|███████   | 11596/16329 [1:37:39<40:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11596: train loss 1.30457. lr 4.318840e-04:  71%|███████   | 11597/16329 [1:37:39<39:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11597: train loss 1.26403. lr 4.318580e-04:  71%|███████   | 11597/16329 [1:37:39<39:51,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11597: train loss 1.26403. lr 4.318580e-04:  71%|███████   | 11598/16329 [1:37:39<39:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11598: train loss 1.27543. lr 4.318321e-04:  71%|███████   | 11598/16329 [1:37:40<39:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11598: train loss 1.27543. lr 4.318321e-04:  71%|███████   | 11599/16329 [1:37:40<39:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11599: train loss 1.29509. lr 4.318062e-04:  71%|███████   | 11599/16329 [1:37:40<39:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11599: train loss 1.29509. lr 4.318062e-04:  71%|███████   | 11600/16329 [1:37:40<39:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11600: train loss 1.31052. lr 4.317803e-04:  71%|███████   | 11600/16329 [1:37:41<39:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11600: train loss 1.31052. lr 4.317803e-04:  71%|███████   | 11601/16329 [1:37:41<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11601: train loss 1.28582. lr 4.317543e-04:  71%|███████   | 11601/16329 [1:37:41<39:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11601: train loss 1.28582. lr 4.317543e-04:  71%|███████   | 11602/16329 [1:37:41<39:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11602: train loss 1.32493. lr 4.317284e-04:  71%|███████   | 11602/16329 [1:37:42<39:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11602: train loss 1.32493. lr 4.317284e-04:  71%|███████   | 11603/16329 [1:37:42<39:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11603: train loss 1.30636. lr 4.317025e-04:  71%|███████   | 11603/16329 [1:37:42<39:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11603: train loss 1.30636. lr 4.317025e-04:  71%|███████   | 11604/16329 [1:37:42<40:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11604: train loss 1.29193. lr 4.316766e-04:  71%|███████   | 11604/16329 [1:37:43<40:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11604: train loss 1.29193. lr 4.316766e-04:  71%|███████   | 11605/16329 [1:37:43<40:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11605: train loss 1.32459. lr 4.316506e-04:  71%|███████   | 11605/16329 [1:37:43<40:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11605: train loss 1.32459. lr 4.316506e-04:  71%|███████   | 11606/16329 [1:37:43<40:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11606: train loss 1.30684. lr 4.316247e-04:  71%|███████   | 11606/16329 [1:37:44<40:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11606: train loss 1.30684. lr 4.316247e-04:  71%|███████   | 11607/16329 [1:37:44<40:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11607: train loss 1.28734. lr 4.315988e-04:  71%|███████   | 11607/16329 [1:37:44<40:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11607: train loss 1.28734. lr 4.315988e-04:  71%|███████   | 11608/16329 [1:37:44<39:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11608: train loss 1.33355. lr 4.315728e-04:  71%|███████   | 11608/16329 [1:37:45<39:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11608: train loss 1.33355. lr 4.315728e-04:  71%|███████   | 11609/16329 [1:37:45<39:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11609: train loss 1.28270. lr 4.315469e-04:  71%|███████   | 11609/16329 [1:37:45<39:42,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11609: train loss 1.28270. lr 4.315469e-04:  71%|███████   | 11610/16329 [1:37:45<39:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11610: train loss 1.25938. lr 4.315209e-04:  71%|███████   | 11610/16329 [1:37:46<39:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11610: train loss 1.25938. lr 4.315209e-04:  71%|███████   | 11611/16329 [1:37:46<39:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11611: train loss 1.30317. lr 4.314950e-04:  71%|███████   | 11611/16329 [1:37:46<39:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11611: train loss 1.30317. lr 4.314950e-04:  71%|███████   | 11612/16329 [1:37:46<39:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11612: train loss 1.30831. lr 4.314691e-04:  71%|███████   | 11612/16329 [1:37:47<39:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11612: train loss 1.30831. lr 4.314691e-04:  71%|███████   | 11613/16329 [1:37:47<39:14,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11613: train loss 1.29060. lr 4.314431e-04:  71%|███████   | 11613/16329 [1:37:47<39:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11613: train loss 1.29060. lr 4.314431e-04:  71%|███████   | 11614/16329 [1:37:47<39:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11614: train loss 1.31262. lr 4.314172e-04:  71%|███████   | 11614/16329 [1:37:48<39:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11614: train loss 1.31262. lr 4.314172e-04:  71%|███████   | 11615/16329 [1:37:48<39:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11615: train loss 1.25360. lr 4.313912e-04:  71%|███████   | 11615/16329 [1:37:48<39:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11615: train loss 1.25360. lr 4.313912e-04:  71%|███████   | 11616/16329 [1:37:48<38:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11616: train loss 1.32056. lr 4.313653e-04:  71%|███████   | 11616/16329 [1:37:49<38:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11616: train loss 1.32056. lr 4.313653e-04:  71%|███████   | 11617/16329 [1:37:49<38:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11617: train loss 1.24631. lr 4.313393e-04:  71%|███████   | 11617/16329 [1:37:49<38:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11617: train loss 1.24631. lr 4.313393e-04:  71%|███████   | 11618/16329 [1:37:49<38:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11618: train loss 1.28472. lr 4.313134e-04:  71%|███████   | 11618/16329 [1:37:50<38:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11618: train loss 1.28472. lr 4.313134e-04:  71%|███████   | 11619/16329 [1:37:50<38:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11619: train loss 1.29569. lr 4.312874e-04:  71%|███████   | 11619/16329 [1:37:50<38:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11619: train loss 1.29569. lr 4.312874e-04:  71%|███████   | 11620/16329 [1:37:50<38:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11620: train loss 1.27876. lr 4.312615e-04:  71%|███████   | 11620/16329 [1:37:51<38:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11620: train loss 1.27876. lr 4.312615e-04:  71%|███████   | 11621/16329 [1:37:51<39:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11621: train loss 1.26875. lr 4.312355e-04:  71%|███████   | 11621/16329 [1:37:51<39:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11621: train loss 1.26875. lr 4.312355e-04:  71%|███████   | 11622/16329 [1:37:51<39:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11622: train loss 1.27203. lr 4.312096e-04:  71%|███████   | 11622/16329 [1:37:52<39:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11622: train loss 1.27203. lr 4.312096e-04:  71%|███████   | 11623/16329 [1:37:52<39:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11623: train loss 1.26577. lr 4.311836e-04:  71%|███████   | 11623/16329 [1:37:52<39:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11623: train loss 1.26577. lr 4.311836e-04:  71%|███████   | 11624/16329 [1:37:52<39:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11624: train loss 1.27357. lr 4.311577e-04:  71%|███████   | 11624/16329 [1:37:53<39:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11624: train loss 1.27357. lr 4.311577e-04:  71%|███████   | 11625/16329 [1:37:53<39:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11625: train loss 1.30280. lr 4.311317e-04:  71%|███████   | 11625/16329 [1:37:53<39:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11625: train loss 1.30280. lr 4.311317e-04:  71%|███████   | 11626/16329 [1:37:53<38:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11626: train loss 1.29530. lr 4.311058e-04:  71%|███████   | 11626/16329 [1:37:54<38:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11626: train loss 1.29530. lr 4.311058e-04:  71%|███████   | 11627/16329 [1:37:54<43:14,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11627: train loss 1.31804. lr 4.310798e-04:  71%|███████   | 11627/16329 [1:37:54<43:14,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11627: train loss 1.31804. lr 4.310798e-04:  71%|███████   | 11628/16329 [1:37:54<41:56,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11628: train loss 1.26209. lr 4.310538e-04:  71%|███████   | 11628/16329 [1:37:55<41:56,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11628: train loss 1.26209. lr 4.310538e-04:  71%|███████   | 11629/16329 [1:37:55<40:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11629: train loss 1.28614. lr 4.310279e-04:  71%|███████   | 11629/16329 [1:37:55<40:54,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11629: train loss 1.28614. lr 4.310279e-04:  71%|███████   | 11630/16329 [1:37:55<40:18,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11630: train loss 1.29659. lr 4.310019e-04:  71%|███████   | 11630/16329 [1:37:56<40:18,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11630: train loss 1.29659. lr 4.310019e-04:  71%|███████   | 11631/16329 [1:37:56<39:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11631: train loss 1.30757. lr 4.309760e-04:  71%|███████   | 11631/16329 [1:37:56<39:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11631: train loss 1.30757. lr 4.309760e-04:  71%|███████   | 11632/16329 [1:37:56<39:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11632: train loss 1.32924. lr 4.309500e-04:  71%|███████   | 11632/16329 [1:37:57<39:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11632: train loss 1.32924. lr 4.309500e-04:  71%|███████   | 11633/16329 [1:37:57<39:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11633: train loss 1.26186. lr 4.309240e-04:  71%|███████   | 11633/16329 [1:37:57<39:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11633: train loss 1.26186. lr 4.309240e-04:  71%|███████   | 11634/16329 [1:37:57<39:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11634: train loss 1.28902. lr 4.308981e-04:  71%|███████   | 11634/16329 [1:37:58<39:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11634: train loss 1.28902. lr 4.308981e-04:  71%|███████▏  | 11635/16329 [1:37:58<38:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11635: train loss 1.28243. lr 4.308721e-04:  71%|███████▏  | 11635/16329 [1:37:58<38:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11635: train loss 1.28243. lr 4.308721e-04:  71%|███████▏  | 11636/16329 [1:37:58<38:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11636: train loss 1.27360. lr 4.308461e-04:  71%|███████▏  | 11636/16329 [1:37:59<38:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11636: train loss 1.27360. lr 4.308461e-04:  71%|███████▏  | 11637/16329 [1:37:59<38:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11637: train loss 1.28298. lr 4.308201e-04:  71%|███████▏  | 11637/16329 [1:37:59<38:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11637: train loss 1.28298. lr 4.308201e-04:  71%|███████▏  | 11638/16329 [1:37:59<38:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11638: train loss 1.27916. lr 4.307942e-04:  71%|███████▏  | 11638/16329 [1:38:00<38:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11638: train loss 1.27916. lr 4.307942e-04:  71%|███████▏  | 11639/16329 [1:38:00<38:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11639: train loss 1.28670. lr 4.307682e-04:  71%|███████▏  | 11639/16329 [1:38:00<38:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11639: train loss 1.28670. lr 4.307682e-04:  71%|███████▏  | 11640/16329 [1:38:00<38:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11640: train loss 1.31639. lr 4.307422e-04:  71%|███████▏  | 11640/16329 [1:38:01<38:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11640: train loss 1.31639. lr 4.307422e-04:  71%|███████▏  | 11641/16329 [1:38:01<38:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11641: train loss 1.27914. lr 4.307163e-04:  71%|███████▏  | 11641/16329 [1:38:01<38:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11641: train loss 1.27914. lr 4.307163e-04:  71%|███████▏  | 11642/16329 [1:38:01<38:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11642: train loss 1.28729. lr 4.306903e-04:  71%|███████▏  | 11642/16329 [1:38:02<38:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11642: train loss 1.28729. lr 4.306903e-04:  71%|███████▏  | 11643/16329 [1:38:02<38:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11643: train loss 1.25229. lr 4.306643e-04:  71%|███████▏  | 11643/16329 [1:38:02<38:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11643: train loss 1.25229. lr 4.306643e-04:  71%|███████▏  | 11644/16329 [1:38:02<38:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11644: train loss 1.29756. lr 4.306383e-04:  71%|███████▏  | 11644/16329 [1:38:03<38:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11644: train loss 1.29756. lr 4.306383e-04:  71%|███████▏  | 11645/16329 [1:38:03<38:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11645: train loss 1.27973. lr 4.306123e-04:  71%|███████▏  | 11645/16329 [1:38:03<38:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11645: train loss 1.27973. lr 4.306123e-04:  71%|███████▏  | 11646/16329 [1:38:03<38:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11646: train loss 1.25988. lr 4.305864e-04:  71%|███████▏  | 11646/16329 [1:38:04<38:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11646: train loss 1.25988. lr 4.305864e-04:  71%|███████▏  | 11647/16329 [1:38:04<38:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11647: train loss 1.26151. lr 4.305604e-04:  71%|███████▏  | 11647/16329 [1:38:04<38:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11647: train loss 1.26151. lr 4.305604e-04:  71%|███████▏  | 11648/16329 [1:38:04<38:39,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11648: train loss 1.27463. lr 4.305344e-04:  71%|███████▏  | 11648/16329 [1:38:05<38:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11648: train loss 1.27463. lr 4.305344e-04:  71%|███████▏  | 11649/16329 [1:38:05<38:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11649: train loss 1.26184. lr 4.305084e-04:  71%|███████▏  | 11649/16329 [1:38:05<38:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11649: train loss 1.26184. lr 4.305084e-04:  71%|███████▏  | 11650/16329 [1:38:05<38:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11650: train loss 1.30403. lr 4.304824e-04:  71%|███████▏  | 11650/16329 [1:38:06<38:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11650: train loss 1.30403. lr 4.304824e-04:  71%|███████▏  | 11651/16329 [1:38:06<38:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11651: train loss 1.29517. lr 4.304564e-04:  71%|███████▏  | 11651/16329 [1:38:06<38:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11651: train loss 1.29517. lr 4.304564e-04:  71%|███████▏  | 11652/16329 [1:38:06<42:41,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11652: train loss 1.27799. lr 4.304304e-04:  71%|███████▏  | 11652/16329 [1:38:07<42:41,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11652: train loss 1.27799. lr 4.304304e-04:  71%|███████▏  | 11653/16329 [1:38:07<41:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11653: train loss 1.25219. lr 4.304044e-04:  71%|███████▏  | 11653/16329 [1:38:07<41:31,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11653: train loss 1.25219. lr 4.304044e-04:  71%|███████▏  | 11654/16329 [1:38:07<40:38,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11654: train loss 1.27495. lr 4.303785e-04:  71%|███████▏  | 11654/16329 [1:38:08<40:38,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11654: train loss 1.27495. lr 4.303785e-04:  71%|███████▏  | 11655/16329 [1:38:08<39:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11655: train loss 1.29879. lr 4.303525e-04:  71%|███████▏  | 11655/16329 [1:38:08<39:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11655: train loss 1.29879. lr 4.303525e-04:  71%|███████▏  | 11656/16329 [1:38:08<39:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11656: train loss 1.27071. lr 4.303265e-04:  71%|███████▏  | 11656/16329 [1:38:09<39:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11656: train loss 1.27071. lr 4.303265e-04:  71%|███████▏  | 11657/16329 [1:38:09<39:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11657: train loss 1.23875. lr 4.303005e-04:  71%|███████▏  | 11657/16329 [1:38:09<39:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11657: train loss 1.23875. lr 4.303005e-04:  71%|███████▏  | 11658/16329 [1:38:09<39:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11658: train loss 1.28471. lr 4.302745e-04:  71%|███████▏  | 11658/16329 [1:38:10<39:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11658: train loss 1.28471. lr 4.302745e-04:  71%|███████▏  | 11659/16329 [1:38:10<38:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11659: train loss 1.26540. lr 4.302485e-04:  71%|███████▏  | 11659/16329 [1:38:10<38:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11659: train loss 1.26540. lr 4.302485e-04:  71%|███████▏  | 11660/16329 [1:38:10<38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11660: train loss 1.28976. lr 4.302225e-04:  71%|███████▏  | 11660/16329 [1:38:11<38:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11660: train loss 1.28976. lr 4.302225e-04:  71%|███████▏  | 11661/16329 [1:38:11<38:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11661: train loss 1.26868. lr 4.301965e-04:  71%|███████▏  | 11661/16329 [1:38:11<38:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11661: train loss 1.26868. lr 4.301965e-04:  71%|███████▏  | 11662/16329 [1:38:11<38:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11662: train loss 1.28206. lr 4.301705e-04:  71%|███████▏  | 11662/16329 [1:38:12<38:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11662: train loss 1.28206. lr 4.301705e-04:  71%|███████▏  | 11663/16329 [1:38:12<38:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11663: train loss 1.29691. lr 4.301445e-04:  71%|███████▏  | 11663/16329 [1:38:12<38:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11663: train loss 1.29691. lr 4.301445e-04:  71%|███████▏  | 11664/16329 [1:38:12<38:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11664: train loss 1.27167. lr 4.301185e-04:  71%|███████▏  | 11664/16329 [1:38:13<38:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11664: train loss 1.27167. lr 4.301185e-04:  71%|███████▏  | 11665/16329 [1:38:13<38:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11665: train loss 1.25697. lr 4.300925e-04:  71%|███████▏  | 11665/16329 [1:38:13<38:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11665: train loss 1.25697. lr 4.300925e-04:  71%|███████▏  | 11666/16329 [1:38:13<38:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11666: train loss 1.31546. lr 4.300665e-04:  71%|███████▏  | 11666/16329 [1:38:14<38:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11666: train loss 1.31546. lr 4.300665e-04:  71%|███████▏  | 11667/16329 [1:38:14<38:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11667: train loss 1.31868. lr 4.300405e-04:  71%|███████▏  | 11667/16329 [1:38:14<38:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11667: train loss 1.31868. lr 4.300405e-04:  71%|███████▏  | 11668/16329 [1:38:14<38:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11668: train loss 1.26732. lr 4.300144e-04:  71%|███████▏  | 11668/16329 [1:38:15<38:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11668: train loss 1.26732. lr 4.300144e-04:  71%|███████▏  | 11669/16329 [1:38:15<38:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11669: train loss 1.28381. lr 4.299884e-04:  71%|███████▏  | 11669/16329 [1:38:15<38:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11669: train loss 1.28381. lr 4.299884e-04:  71%|███████▏  | 11670/16329 [1:38:15<38:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11670: train loss 1.27407. lr 4.299624e-04:  71%|███████▏  | 11670/16329 [1:38:16<38:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11670: train loss 1.27407. lr 4.299624e-04:  71%|███████▏  | 11671/16329 [1:38:16<40:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11671: train loss 1.27361. lr 4.299364e-04:  71%|███████▏  | 11671/16329 [1:38:16<40:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11671: train loss 1.27361. lr 4.299364e-04:  71%|███████▏  | 11672/16329 [1:38:16<40:35,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11672: train loss 1.24945. lr 4.299104e-04:  71%|███████▏  | 11672/16329 [1:38:17<40:35,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11672: train loss 1.24945. lr 4.299104e-04:  71%|███████▏  | 11673/16329 [1:38:17<40:40,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11673: train loss 1.28239. lr 4.298844e-04:  71%|███████▏  | 11673/16329 [1:38:17<40:40,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11673: train loss 1.28239. lr 4.298844e-04:  71%|███████▏  | 11674/16329 [1:38:17<42:01,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 11674: train loss 1.26889. lr 4.298584e-04:  71%|███████▏  | 11674/16329 [1:38:18<42:01,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 11674: train loss 1.26889. lr 4.298584e-04:  71%|███████▏  | 11675/16329 [1:38:18<42:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11675: train loss 1.26480. lr 4.298323e-04:  71%|███████▏  | 11675/16329 [1:38:19<42:34,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11675: train loss 1.26480. lr 4.298323e-04:  72%|███████▏  | 11676/16329 [1:38:19<42:33,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11676: train loss 1.24892. lr 4.298063e-04:  72%|███████▏  | 11676/16329 [1:38:19<42:33,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11676: train loss 1.24892. lr 4.298063e-04:  72%|███████▏  | 11677/16329 [1:38:19<42:07,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11677: train loss 1.24293. lr 4.297803e-04:  72%|███████▏  | 11677/16329 [1:38:20<42:07,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11677: train loss 1.24293. lr 4.297803e-04:  72%|███████▏  | 11678/16329 [1:38:20<41:34,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11678: train loss 1.29555. lr 4.297543e-04:  72%|███████▏  | 11678/16329 [1:38:20<41:34,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11678: train loss 1.29555. lr 4.297543e-04:  72%|███████▏  | 11679/16329 [1:38:20<45:07,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 11679: train loss 1.27679. lr 4.297283e-04:  72%|███████▏  | 11679/16329 [1:38:21<45:07,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 11679: train loss 1.27679. lr 4.297283e-04:  72%|███████▏  | 11680/16329 [1:38:21<43:20,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11680: train loss 1.27929. lr 4.297022e-04:  72%|███████▏  | 11680/16329 [1:38:21<43:20,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11680: train loss 1.27929. lr 4.297022e-04:  72%|███████▏  | 11681/16329 [1:38:21<41:43,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11681: train loss 1.24437. lr 4.296762e-04:  72%|███████▏  | 11681/16329 [1:38:22<41:43,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11681: train loss 1.24437. lr 4.296762e-04:  72%|███████▏  | 11682/16329 [1:38:22<40:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11682: train loss 1.28748. lr 4.296502e-04:  72%|███████▏  | 11682/16329 [1:38:22<40:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11682: train loss 1.28748. lr 4.296502e-04:  72%|███████▏  | 11683/16329 [1:38:22<39:59,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11683: train loss 1.26504. lr 4.296242e-04:  72%|███████▏  | 11683/16329 [1:38:23<39:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11683: train loss 1.26504. lr 4.296242e-04:  72%|███████▏  | 11684/16329 [1:38:23<39:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11684: train loss 1.28002. lr 4.295981e-04:  72%|███████▏  | 11684/16329 [1:38:23<39:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11684: train loss 1.28002. lr 4.295981e-04:  72%|███████▏  | 11685/16329 [1:38:23<39:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11685: train loss 1.25981. lr 4.295721e-04:  72%|███████▏  | 11685/16329 [1:38:24<39:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11685: train loss 1.25981. lr 4.295721e-04:  72%|███████▏  | 11686/16329 [1:38:24<38:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11686: train loss 1.28375. lr 4.295461e-04:  72%|███████▏  | 11686/16329 [1:38:24<38:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11686: train loss 1.28375. lr 4.295461e-04:  72%|███████▏  | 11687/16329 [1:38:24<38:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11687: train loss 1.27665. lr 4.295201e-04:  72%|███████▏  | 11687/16329 [1:38:25<38:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11687: train loss 1.27665. lr 4.295201e-04:  72%|███████▏  | 11688/16329 [1:38:25<38:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11688: train loss 1.24558. lr 4.294940e-04:  72%|███████▏  | 11688/16329 [1:38:25<38:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11688: train loss 1.24558. lr 4.294940e-04:  72%|███████▏  | 11689/16329 [1:38:25<38:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11689: train loss 1.31368. lr 4.294680e-04:  72%|███████▏  | 11689/16329 [1:38:26<38:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11689: train loss 1.31368. lr 4.294680e-04:  72%|███████▏  | 11690/16329 [1:38:26<38:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11690: train loss 1.30793. lr 4.294419e-04:  72%|███████▏  | 11690/16329 [1:38:26<38:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11690: train loss 1.30793. lr 4.294419e-04:  72%|███████▏  | 11691/16329 [1:38:26<38:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11691: train loss 1.24716. lr 4.294159e-04:  72%|███████▏  | 11691/16329 [1:38:27<38:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11691: train loss 1.24716. lr 4.294159e-04:  72%|███████▏  | 11692/16329 [1:38:27<38:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11692: train loss 1.21392. lr 4.293899e-04:  72%|███████▏  | 11692/16329 [1:38:27<38:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11692: train loss 1.21392. lr 4.293899e-04:  72%|███████▏  | 11693/16329 [1:38:27<38:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11693: train loss 1.25457. lr 4.293638e-04:  72%|███████▏  | 11693/16329 [1:38:28<38:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11693: train loss 1.25457. lr 4.293638e-04:  72%|███████▏  | 11694/16329 [1:38:28<38:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11694: train loss 1.25888. lr 4.293378e-04:  72%|███████▏  | 11694/16329 [1:38:28<38:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11694: train loss 1.25888. lr 4.293378e-04:  72%|███████▏  | 11695/16329 [1:38:28<38:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11695: train loss 1.27767. lr 4.293118e-04:  72%|███████▏  | 11695/16329 [1:38:29<38:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11695: train loss 1.27767. lr 4.293118e-04:  72%|███████▏  | 11696/16329 [1:38:29<38:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11696: train loss 1.26602. lr 4.292857e-04:  72%|███████▏  | 11696/16329 [1:38:29<38:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11696: train loss 1.26602. lr 4.292857e-04:  72%|███████▏  | 11697/16329 [1:38:29<38:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11697: train loss 1.31231. lr 4.292597e-04:  72%|███████▏  | 11697/16329 [1:38:30<38:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11697: train loss 1.31231. lr 4.292597e-04:  72%|███████▏  | 11698/16329 [1:38:30<38:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11698: train loss 1.29298. lr 4.292336e-04:  72%|███████▏  | 11698/16329 [1:38:30<38:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11698: train loss 1.29298. lr 4.292336e-04:  72%|███████▏  | 11699/16329 [1:38:30<38:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11699: train loss 1.24899. lr 4.292076e-04:  72%|███████▏  | 11699/16329 [1:38:31<38:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11699: train loss 1.24899. lr 4.292076e-04:  72%|███████▏  | 11700/16329 [1:38:31<38:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11700: train loss 1.33327. lr 4.291815e-04:  72%|███████▏  | 11700/16329 [1:38:31<38:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11700: train loss 1.33327. lr 4.291815e-04:  72%|███████▏  | 11701/16329 [1:38:31<38:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11701: train loss 1.22544. lr 4.291555e-04:  72%|███████▏  | 11701/16329 [1:38:32<38:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11701: train loss 1.22544. lr 4.291555e-04:  72%|███████▏  | 11702/16329 [1:38:32<38:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11702: train loss 1.27362. lr 4.291294e-04:  72%|███████▏  | 11702/16329 [1:38:32<38:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11702: train loss 1.27362. lr 4.291294e-04:  72%|███████▏  | 11703/16329 [1:38:32<38:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11703: train loss 1.25423. lr 4.291034e-04:  72%|███████▏  | 11703/16329 [1:38:33<38:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11703: train loss 1.25423. lr 4.291034e-04:  72%|███████▏  | 11704/16329 [1:38:33<38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11704: train loss 1.30803. lr 4.290773e-04:  72%|███████▏  | 11704/16329 [1:38:33<38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11704: train loss 1.30803. lr 4.290773e-04:  72%|███████▏  | 11705/16329 [1:38:33<38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11705: train loss 1.28491. lr 4.290513e-04:  72%|███████▏  | 11705/16329 [1:38:34<38:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11705: train loss 1.28491. lr 4.290513e-04:  72%|███████▏  | 11706/16329 [1:38:34<38:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11706: train loss 1.31716. lr 4.290252e-04:  72%|███████▏  | 11706/16329 [1:38:34<38:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11706: train loss 1.31716. lr 4.290252e-04:  72%|███████▏  | 11707/16329 [1:38:34<38:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11707: train loss 1.27693. lr 4.289992e-04:  72%|███████▏  | 11707/16329 [1:38:35<38:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11707: train loss 1.27693. lr 4.289992e-04:  72%|███████▏  | 11708/16329 [1:38:35<38:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11708: train loss 1.33167. lr 4.289731e-04:  72%|███████▏  | 11708/16329 [1:38:35<38:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11708: train loss 1.33167. lr 4.289731e-04:  72%|███████▏  | 11709/16329 [1:38:35<38:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11709: train loss 1.27357. lr 4.289471e-04:  72%|███████▏  | 11709/16329 [1:38:36<38:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11709: train loss 1.27357. lr 4.289471e-04:  72%|███████▏  | 11710/16329 [1:38:36<38:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11710: train loss 1.28902. lr 4.289210e-04:  72%|███████▏  | 11710/16329 [1:38:36<38:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11710: train loss 1.28902. lr 4.289210e-04:  72%|███████▏  | 11711/16329 [1:38:36<38:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11711: train loss 1.25891. lr 4.288949e-04:  72%|███████▏  | 11711/16329 [1:38:37<38:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11711: train loss 1.25891. lr 4.288949e-04:  72%|███████▏  | 11712/16329 [1:38:37<38:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11712: train loss 1.26339. lr 4.288689e-04:  72%|███████▏  | 11712/16329 [1:38:37<38:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11712: train loss 1.26339. lr 4.288689e-04:  72%|███████▏  | 11713/16329 [1:38:37<38:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11713: train loss 1.29708. lr 4.288428e-04:  72%|███████▏  | 11713/16329 [1:38:38<38:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11713: train loss 1.29708. lr 4.288428e-04:  72%|███████▏  | 11714/16329 [1:38:38<38:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11714: train loss 1.27005. lr 4.288167e-04:  72%|███████▏  | 11714/16329 [1:38:38<38:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11714: train loss 1.27005. lr 4.288167e-04:  72%|███████▏  | 11715/16329 [1:38:38<38:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11715: train loss 1.25141. lr 4.287907e-04:  72%|███████▏  | 11715/16329 [1:38:39<38:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11715: train loss 1.25141. lr 4.287907e-04:  72%|███████▏  | 11716/16329 [1:38:39<38:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11716: train loss 1.28419. lr 4.287646e-04:  72%|███████▏  | 11716/16329 [1:38:39<38:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11716: train loss 1.28419. lr 4.287646e-04:  72%|███████▏  | 11717/16329 [1:38:39<38:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11717: train loss 1.26853. lr 4.287386e-04:  72%|███████▏  | 11717/16329 [1:38:40<38:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11717: train loss 1.26853. lr 4.287386e-04:  72%|███████▏  | 11718/16329 [1:38:40<38:11,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11718: train loss 1.24582. lr 4.287125e-04:  72%|███████▏  | 11718/16329 [1:38:40<38:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11718: train loss 1.24582. lr 4.287125e-04:  72%|███████▏  | 11719/16329 [1:38:40<42:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11719: train loss 1.30848. lr 4.286864e-04:  72%|███████▏  | 11719/16329 [1:38:41<42:16,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11719: train loss 1.30848. lr 4.286864e-04:  72%|███████▏  | 11720/16329 [1:38:41<40:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11720: train loss 1.23818. lr 4.286603e-04:  72%|███████▏  | 11720/16329 [1:38:41<40:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11720: train loss 1.23818. lr 4.286603e-04:  72%|███████▏  | 11721/16329 [1:38:41<40:12,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11721: train loss 1.24742. lr 4.286343e-04:  72%|███████▏  | 11721/16329 [1:38:42<40:12,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11721: train loss 1.24742. lr 4.286343e-04:  72%|███████▏  | 11722/16329 [1:38:42<39:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11722: train loss 1.26655. lr 4.286082e-04:  72%|███████▏  | 11722/16329 [1:38:42<39:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11722: train loss 1.26655. lr 4.286082e-04:  72%|███████▏  | 11723/16329 [1:38:42<39:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11723: train loss 1.24664. lr 4.285821e-04:  72%|███████▏  | 11723/16329 [1:38:43<39:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11723: train loss 1.24664. lr 4.285821e-04:  72%|███████▏  | 11724/16329 [1:38:43<38:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11724: train loss 1.26640. lr 4.285560e-04:  72%|███████▏  | 11724/16329 [1:38:43<38:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11724: train loss 1.26640. lr 4.285560e-04:  72%|███████▏  | 11725/16329 [1:38:43<38:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11725: train loss 1.30266. lr 4.285300e-04:  72%|███████▏  | 11725/16329 [1:38:44<38:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11725: train loss 1.30266. lr 4.285300e-04:  72%|███████▏  | 11726/16329 [1:38:44<38:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11726: train loss 1.29695. lr 4.285039e-04:  72%|███████▏  | 11726/16329 [1:38:44<38:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11726: train loss 1.29695. lr 4.285039e-04:  72%|███████▏  | 11727/16329 [1:38:44<38:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11727: train loss 1.29182. lr 4.284778e-04:  72%|███████▏  | 11727/16329 [1:38:45<38:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11727: train loss 1.29182. lr 4.284778e-04:  72%|███████▏  | 11728/16329 [1:38:45<38:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11728: train loss 1.28678. lr 4.284517e-04:  72%|███████▏  | 11728/16329 [1:38:45<38:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11728: train loss 1.28678. lr 4.284517e-04:  72%|███████▏  | 11729/16329 [1:38:45<38:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11729: train loss 1.26221. lr 4.284257e-04:  72%|███████▏  | 11729/16329 [1:38:46<38:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11729: train loss 1.26221. lr 4.284257e-04:  72%|███████▏  | 11730/16329 [1:38:46<37:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11730: train loss 1.26287. lr 4.283996e-04:  72%|███████▏  | 11730/16329 [1:38:46<37:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11730: train loss 1.26287. lr 4.283996e-04:  72%|███████▏  | 11731/16329 [1:38:46<38:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11731: train loss 1.32512. lr 4.283735e-04:  72%|███████▏  | 11731/16329 [1:38:47<38:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11731: train loss 1.32512. lr 4.283735e-04:  72%|███████▏  | 11732/16329 [1:38:47<37:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11732: train loss 1.27639. lr 4.283474e-04:  72%|███████▏  | 11732/16329 [1:38:47<37:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11732: train loss 1.27639. lr 4.283474e-04:  72%|███████▏  | 11733/16329 [1:38:47<37:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11733: train loss 1.26153. lr 4.283213e-04:  72%|███████▏  | 11733/16329 [1:38:48<37:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11733: train loss 1.26153. lr 4.283213e-04:  72%|███████▏  | 11734/16329 [1:38:48<37:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11734: train loss 1.24760. lr 4.282952e-04:  72%|███████▏  | 11734/16329 [1:38:48<37:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11734: train loss 1.24760. lr 4.282952e-04:  72%|███████▏  | 11735/16329 [1:38:48<37:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11735: train loss 1.27583. lr 4.282691e-04:  72%|███████▏  | 11735/16329 [1:38:49<37:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11735: train loss 1.27583. lr 4.282691e-04:  72%|███████▏  | 11736/16329 [1:38:49<37:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11736: train loss 1.30130. lr 4.282430e-04:  72%|███████▏  | 11736/16329 [1:38:49<37:44,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11736: train loss 1.30130. lr 4.282430e-04:  72%|███████▏  | 11737/16329 [1:38:49<37:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11737: train loss 1.31739. lr 4.282170e-04:  72%|███████▏  | 11737/16329 [1:38:50<37:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11737: train loss 1.31739. lr 4.282170e-04:  72%|███████▏  | 11738/16329 [1:38:50<37:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11738: train loss 1.24809. lr 4.281909e-04:  72%|███████▏  | 11738/16329 [1:38:50<37:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11738: train loss 1.24809. lr 4.281909e-04:  72%|███████▏  | 11739/16329 [1:38:50<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11739: train loss 1.26524. lr 4.281648e-04:  72%|███████▏  | 11739/16329 [1:38:51<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11739: train loss 1.26524. lr 4.281648e-04:  72%|███████▏  | 11740/16329 [1:38:51<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11740: train loss 1.28002. lr 4.281387e-04:  72%|███████▏  | 11740/16329 [1:38:51<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11740: train loss 1.28002. lr 4.281387e-04:  72%|███████▏  | 11741/16329 [1:38:51<37:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11741: train loss 1.26069. lr 4.281126e-04:  72%|███████▏  | 11741/16329 [1:38:52<37:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11741: train loss 1.26069. lr 4.281126e-04:  72%|███████▏  | 11742/16329 [1:38:52<37:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11742: train loss 1.25910. lr 4.280865e-04:  72%|███████▏  | 11742/16329 [1:38:52<37:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11742: train loss 1.25910. lr 4.280865e-04:  72%|███████▏  | 11743/16329 [1:38:52<37:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11743: train loss 1.29914. lr 4.280604e-04:  72%|███████▏  | 11743/16329 [1:38:53<37:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11743: train loss 1.29914. lr 4.280604e-04:  72%|███████▏  | 11744/16329 [1:38:53<37:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11744: train loss 1.28832. lr 4.280343e-04:  72%|███████▏  | 11744/16329 [1:38:53<37:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11744: train loss 1.28832. lr 4.280343e-04:  72%|███████▏  | 11745/16329 [1:38:53<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11745: train loss 1.27153. lr 4.280082e-04:  72%|███████▏  | 11745/16329 [1:38:54<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11745: train loss 1.27153. lr 4.280082e-04:  72%|███████▏  | 11746/16329 [1:38:54<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11746: train loss 1.29400. lr 4.279821e-04:  72%|███████▏  | 11746/16329 [1:38:54<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11746: train loss 1.29400. lr 4.279821e-04:  72%|███████▏  | 11747/16329 [1:38:54<37:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11747: train loss 1.28099. lr 4.279560e-04:  72%|███████▏  | 11747/16329 [1:38:55<37:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11747: train loss 1.28099. lr 4.279560e-04:  72%|███████▏  | 11748/16329 [1:38:55<37:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11748: train loss 1.30517. lr 4.279299e-04:  72%|███████▏  | 11748/16329 [1:38:55<37:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11748: train loss 1.30517. lr 4.279299e-04:  72%|███████▏  | 11749/16329 [1:38:55<37:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11749: train loss 1.28376. lr 4.279038e-04:  72%|███████▏  | 11749/16329 [1:38:56<37:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11749: train loss 1.28376. lr 4.279038e-04:  72%|███████▏  | 11750/16329 [1:38:56<37:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11750: train loss 1.27674. lr 4.278777e-04:  72%|███████▏  | 11750/16329 [1:38:56<37:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11750: train loss 1.27674. lr 4.278777e-04:  72%|███████▏  | 11751/16329 [1:38:56<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11751: train loss 1.27651. lr 4.278516e-04:  72%|███████▏  | 11751/16329 [1:38:57<37:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11751: train loss 1.27651. lr 4.278516e-04:  72%|███████▏  | 11752/16329 [1:38:57<37:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11752: train loss 1.28161. lr 4.278254e-04:  72%|███████▏  | 11752/16329 [1:38:57<37:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11752: train loss 1.28161. lr 4.278254e-04:  72%|███████▏  | 11753/16329 [1:38:57<37:49,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11753: train loss 1.28509. lr 4.277993e-04:  72%|███████▏  | 11753/16329 [1:38:58<37:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11753: train loss 1.28509. lr 4.277993e-04:  72%|███████▏  | 11754/16329 [1:38:58<41:44,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11754: train loss 1.23732. lr 4.277732e-04:  72%|███████▏  | 11754/16329 [1:38:58<41:44,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11754: train loss 1.23732. lr 4.277732e-04:  72%|███████▏  | 11755/16329 [1:38:58<40:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11755: train loss 1.25338. lr 4.277471e-04:  72%|███████▏  | 11755/16329 [1:38:59<40:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11755: train loss 1.25338. lr 4.277471e-04:  72%|███████▏  | 11756/16329 [1:38:59<39:42,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11756: train loss 1.26820. lr 4.277210e-04:  72%|███████▏  | 11756/16329 [1:38:59<39:42,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11756: train loss 1.26820. lr 4.277210e-04:  72%|███████▏  | 11757/16329 [1:38:59<39:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11757: train loss 1.27104. lr 4.276949e-04:  72%|███████▏  | 11757/16329 [1:39:00<39:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11757: train loss 1.27104. lr 4.276949e-04:  72%|███████▏  | 11758/16329 [1:39:00<38:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11758: train loss 1.27802. lr 4.276688e-04:  72%|███████▏  | 11758/16329 [1:39:00<38:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11758: train loss 1.27802. lr 4.276688e-04:  72%|███████▏  | 11759/16329 [1:39:00<38:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11759: train loss 1.25826. lr 4.276427e-04:  72%|███████▏  | 11759/16329 [1:39:01<38:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11759: train loss 1.25826. lr 4.276427e-04:  72%|███████▏  | 11760/16329 [1:39:01<38:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11760: train loss 1.26569. lr 4.276165e-04:  72%|███████▏  | 11760/16329 [1:39:01<38:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11760: train loss 1.26569. lr 4.276165e-04:  72%|███████▏  | 11761/16329 [1:39:01<38:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11761: train loss 1.25407. lr 4.275904e-04:  72%|███████▏  | 11761/16329 [1:39:02<38:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11761: train loss 1.25407. lr 4.275904e-04:  72%|███████▏  | 11762/16329 [1:39:02<37:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11762: train loss 1.24615. lr 4.275643e-04:  72%|███████▏  | 11762/16329 [1:39:02<37:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11762: train loss 1.24615. lr 4.275643e-04:  72%|███████▏  | 11763/16329 [1:39:02<37:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11763: train loss 1.28914. lr 4.275382e-04:  72%|███████▏  | 11763/16329 [1:39:03<37:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11763: train loss 1.28914. lr 4.275382e-04:  72%|███████▏  | 11764/16329 [1:39:03<37:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11764: train loss 1.26088. lr 4.275120e-04:  72%|███████▏  | 11764/16329 [1:39:03<37:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11764: train loss 1.26088. lr 4.275120e-04:  72%|███████▏  | 11765/16329 [1:39:03<37:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11765: train loss 1.21843. lr 4.274859e-04:  72%|███████▏  | 11765/16329 [1:39:04<37:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11765: train loss 1.21843. lr 4.274859e-04:  72%|███████▏  | 11766/16329 [1:39:04<37:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11766: train loss 1.32337. lr 4.274598e-04:  72%|███████▏  | 11766/16329 [1:39:04<37:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11766: train loss 1.32337. lr 4.274598e-04:  72%|███████▏  | 11767/16329 [1:39:04<37:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11767: train loss 1.26203. lr 4.274337e-04:  72%|███████▏  | 11767/16329 [1:39:05<37:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11767: train loss 1.26203. lr 4.274337e-04:  72%|███████▏  | 11768/16329 [1:39:05<37:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11768: train loss 1.26144. lr 4.274075e-04:  72%|███████▏  | 11768/16329 [1:39:05<37:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11768: train loss 1.26144. lr 4.274075e-04:  72%|███████▏  | 11769/16329 [1:39:05<37:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11769: train loss 1.29934. lr 4.273814e-04:  72%|███████▏  | 11769/16329 [1:39:06<37:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11769: train loss 1.29934. lr 4.273814e-04:  72%|███████▏  | 11770/16329 [1:39:06<38:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11770: train loss 1.26526. lr 4.273553e-04:  72%|███████▏  | 11770/16329 [1:39:06<38:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11770: train loss 1.26526. lr 4.273553e-04:  72%|███████▏  | 11771/16329 [1:39:06<39:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11771: train loss 1.26736. lr 4.273292e-04:  72%|███████▏  | 11771/16329 [1:39:07<39:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11771: train loss 1.26736. lr 4.273292e-04:  72%|███████▏  | 11772/16329 [1:39:07<39:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11772: train loss 1.30651. lr 4.273030e-04:  72%|███████▏  | 11772/16329 [1:39:07<39:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11772: train loss 1.30651. lr 4.273030e-04:  72%|███████▏  | 11773/16329 [1:39:07<39:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11773: train loss 1.26562. lr 4.272769e-04:  72%|███████▏  | 11773/16329 [1:39:08<39:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11773: train loss 1.26562. lr 4.272769e-04:  72%|███████▏  | 11774/16329 [1:39:08<38:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11774: train loss 1.31199. lr 4.272508e-04:  72%|███████▏  | 11774/16329 [1:39:08<38:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11774: train loss 1.31199. lr 4.272508e-04:  72%|███████▏  | 11775/16329 [1:39:08<38:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11775: train loss 1.24691. lr 4.272246e-04:  72%|███████▏  | 11775/16329 [1:39:09<38:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11775: train loss 1.24691. lr 4.272246e-04:  72%|███████▏  | 11776/16329 [1:39:09<38:25,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11776: train loss 1.22400. lr 4.271985e-04:  72%|███████▏  | 11776/16329 [1:39:09<38:25,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11776: train loss 1.22400. lr 4.271985e-04:  72%|███████▏  | 11777/16329 [1:39:09<38:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11777: train loss 1.28623. lr 4.271723e-04:  72%|███████▏  | 11777/16329 [1:39:10<38:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11777: train loss 1.28623. lr 4.271723e-04:  72%|███████▏  | 11778/16329 [1:39:10<38:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11778: train loss 1.25438. lr 4.271462e-04:  72%|███████▏  | 11778/16329 [1:39:10<38:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11778: train loss 1.25438. lr 4.271462e-04:  72%|███████▏  | 11779/16329 [1:39:10<41:55,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11779: train loss 1.25818. lr 4.271201e-04:  72%|███████▏  | 11779/16329 [1:39:11<41:55,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11779: train loss 1.25818. lr 4.271201e-04:  72%|███████▏  | 11780/16329 [1:39:11<40:32,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11780: train loss 1.26492. lr 4.270939e-04:  72%|███████▏  | 11780/16329 [1:39:11<40:32,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11780: train loss 1.26492. lr 4.270939e-04:  72%|███████▏  | 11781/16329 [1:39:11<39:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11781: train loss 1.25682. lr 4.270678e-04:  72%|███████▏  | 11781/16329 [1:39:12<39:33,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11781: train loss 1.25682. lr 4.270678e-04:  72%|███████▏  | 11782/16329 [1:39:12<38:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11782: train loss 1.23689. lr 4.270416e-04:  72%|███████▏  | 11782/16329 [1:39:12<38:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11782: train loss 1.23689. lr 4.270416e-04:  72%|███████▏  | 11783/16329 [1:39:12<38:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11783: train loss 1.26920. lr 4.270155e-04:  72%|███████▏  | 11783/16329 [1:39:13<38:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11783: train loss 1.26920. lr 4.270155e-04:  72%|███████▏  | 11784/16329 [1:39:13<38:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11784: train loss 1.25834. lr 4.269893e-04:  72%|███████▏  | 11784/16329 [1:39:13<38:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11784: train loss 1.25834. lr 4.269893e-04:  72%|███████▏  | 11785/16329 [1:39:13<37:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11785: train loss 1.26709. lr 4.269632e-04:  72%|███████▏  | 11785/16329 [1:39:14<37:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11785: train loss 1.26709. lr 4.269632e-04:  72%|███████▏  | 11786/16329 [1:39:14<37:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11786: train loss 1.29333. lr 4.269370e-04:  72%|███████▏  | 11786/16329 [1:39:14<37:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11786: train loss 1.29333. lr 4.269370e-04:  72%|███████▏  | 11787/16329 [1:39:14<37:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11787: train loss 1.26645. lr 4.269109e-04:  72%|███████▏  | 11787/16329 [1:39:15<37:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11787: train loss 1.26645. lr 4.269109e-04:  72%|███████▏  | 11788/16329 [1:39:15<37:38,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11788: train loss 1.27679. lr 4.268847e-04:  72%|███████▏  | 11788/16329 [1:39:15<37:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11788: train loss 1.27679. lr 4.268847e-04:  72%|███████▏  | 11789/16329 [1:39:15<37:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11789: train loss 1.32104. lr 4.268586e-04:  72%|███████▏  | 11789/16329 [1:39:16<37:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11789: train loss 1.32104. lr 4.268586e-04:  72%|███████▏  | 11790/16329 [1:39:16<37:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11790: train loss 1.30185. lr 4.268324e-04:  72%|███████▏  | 11790/16329 [1:39:16<37:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11790: train loss 1.30185. lr 4.268324e-04:  72%|███████▏  | 11791/16329 [1:39:16<37:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11791: train loss 1.30406. lr 4.268063e-04:  72%|███████▏  | 11791/16329 [1:39:17<37:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11791: train loss 1.30406. lr 4.268063e-04:  72%|███████▏  | 11792/16329 [1:39:17<37:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11792: train loss 1.24384. lr 4.267801e-04:  72%|███████▏  | 11792/16329 [1:39:17<37:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11792: train loss 1.24384. lr 4.267801e-04:  72%|███████▏  | 11793/16329 [1:39:17<37:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11793: train loss 1.28034. lr 4.267540e-04:  72%|███████▏  | 11793/16329 [1:39:18<37:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11793: train loss 1.28034. lr 4.267540e-04:  72%|███████▏  | 11794/16329 [1:39:18<37:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11794: train loss 1.26573. lr 4.267278e-04:  72%|███████▏  | 11794/16329 [1:39:18<37:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11794: train loss 1.26573. lr 4.267278e-04:  72%|███████▏  | 11795/16329 [1:39:18<38:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11795: train loss 1.26132. lr 4.267017e-04:  72%|███████▏  | 11795/16329 [1:39:19<38:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11795: train loss 1.26132. lr 4.267017e-04:  72%|███████▏  | 11796/16329 [1:39:19<39:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11796: train loss 1.25808. lr 4.266755e-04:  72%|███████▏  | 11796/16329 [1:39:19<39:01,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11796: train loss 1.25808. lr 4.266755e-04:  72%|███████▏  | 11797/16329 [1:39:19<39:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11797: train loss 1.26259. lr 4.266493e-04:  72%|███████▏  | 11797/16329 [1:39:20<39:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11797: train loss 1.26259. lr 4.266493e-04:  72%|███████▏  | 11798/16329 [1:39:20<39:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11798: train loss 1.30034. lr 4.266232e-04:  72%|███████▏  | 11798/16329 [1:39:21<39:04,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11798: train loss 1.30034. lr 4.266232e-04:  72%|███████▏  | 11799/16329 [1:39:21<38:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11799: train loss 1.28939. lr 4.265970e-04:  72%|███████▏  | 11799/16329 [1:39:21<38:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11799: train loss 1.28939. lr 4.265970e-04:  72%|███████▏  | 11800/16329 [1:39:21<38:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11800: train loss 1.27293. lr 4.265708e-04:  72%|███████▏  | 11800/16329 [1:39:22<38:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11800: train loss 1.27293. lr 4.265708e-04:  72%|███████▏  | 11801/16329 [1:39:22<38:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11801: train loss 1.27840. lr 4.265447e-04:  72%|███████▏  | 11801/16329 [1:39:22<38:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11801: train loss 1.27840. lr 4.265447e-04:  72%|███████▏  | 11802/16329 [1:39:22<38:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11802: train loss 1.22430. lr 4.265185e-04:  72%|███████▏  | 11802/16329 [1:39:23<38:02,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11802: train loss 1.22430. lr 4.265185e-04:  72%|███████▏  | 11803/16329 [1:39:23<37:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11803: train loss 1.26737. lr 4.264923e-04:  72%|███████▏  | 11803/16329 [1:39:23<37:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11803: train loss 1.26737. lr 4.264923e-04:  72%|███████▏  | 11804/16329 [1:39:23<37:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11804: train loss 1.24907. lr 4.264662e-04:  72%|███████▏  | 11804/16329 [1:39:23<37:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11804: train loss 1.24907. lr 4.264662e-04:  72%|███████▏  | 11805/16329 [1:39:23<37:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11805: train loss 1.31558. lr 4.264400e-04:  72%|███████▏  | 11805/16329 [1:39:24<37:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11805: train loss 1.31558. lr 4.264400e-04:  72%|███████▏  | 11806/16329 [1:39:24<41:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11806: train loss 1.27602. lr 4.264138e-04:  72%|███████▏  | 11806/16329 [1:39:25<41:22,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11806: train loss 1.27602. lr 4.264138e-04:  72%|███████▏  | 11807/16329 [1:39:25<40:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11807: train loss 1.29206. lr 4.263876e-04:  72%|███████▏  | 11807/16329 [1:39:25<40:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11807: train loss 1.29206. lr 4.263876e-04:  72%|███████▏  | 11808/16329 [1:39:25<40:18,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11808: train loss 1.28442. lr 4.263615e-04:  72%|███████▏  | 11808/16329 [1:39:26<40:18,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11808: train loss 1.28442. lr 4.263615e-04:  72%|███████▏  | 11809/16329 [1:39:26<40:14,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11809: train loss 1.27964. lr 4.263353e-04:  72%|███████▏  | 11809/16329 [1:39:26<40:14,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11809: train loss 1.27964. lr 4.263353e-04:  72%|███████▏  | 11810/16329 [1:39:26<39:48,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11810: train loss 1.24412. lr 4.263091e-04:  72%|███████▏  | 11810/16329 [1:39:27<39:48,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 11810: train loss 1.24412. lr 4.263091e-04:  72%|███████▏  | 11811/16329 [1:39:27<39:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11811: train loss 1.27069. lr 4.262829e-04:  72%|███████▏  | 11811/16329 [1:39:27<39:29,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11811: train loss 1.27069. lr 4.262829e-04:  72%|███████▏  | 11812/16329 [1:39:27<39:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11812: train loss 1.32070. lr 4.262568e-04:  72%|███████▏  | 11812/16329 [1:39:28<39:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11812: train loss 1.32070. lr 4.262568e-04:  72%|███████▏  | 11813/16329 [1:39:28<38:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11813: train loss 1.29178. lr 4.262306e-04:  72%|███████▏  | 11813/16329 [1:39:28<38:39,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11813: train loss 1.29178. lr 4.262306e-04:  72%|███████▏  | 11814/16329 [1:39:28<38:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11814: train loss 1.26420. lr 4.262044e-04:  72%|███████▏  | 11814/16329 [1:39:29<38:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11814: train loss 1.26420. lr 4.262044e-04:  72%|███████▏  | 11815/16329 [1:39:29<38:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11815: train loss 1.28396. lr 4.261782e-04:  72%|███████▏  | 11815/16329 [1:39:29<38:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11815: train loss 1.28396. lr 4.261782e-04:  72%|███████▏  | 11816/16329 [1:39:29<37:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11816: train loss 1.29617. lr 4.261520e-04:  72%|███████▏  | 11816/16329 [1:39:30<37:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11816: train loss 1.29617. lr 4.261520e-04:  72%|███████▏  | 11817/16329 [1:39:30<37:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11817: train loss 1.24884. lr 4.261258e-04:  72%|███████▏  | 11817/16329 [1:39:30<37:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11817: train loss 1.24884. lr 4.261258e-04:  72%|███████▏  | 11818/16329 [1:39:30<37:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11818: train loss 1.25242. lr 4.260997e-04:  72%|███████▏  | 11818/16329 [1:39:31<37:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11818: train loss 1.25242. lr 4.260997e-04:  72%|███████▏  | 11819/16329 [1:39:31<37:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11819: train loss 1.26798. lr 4.260735e-04:  72%|███████▏  | 11819/16329 [1:39:31<37:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11819: train loss 1.26798. lr 4.260735e-04:  72%|███████▏  | 11820/16329 [1:39:31<37:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11820: train loss 1.27751. lr 4.260473e-04:  72%|███████▏  | 11820/16329 [1:39:32<37:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11820: train loss 1.27751. lr 4.260473e-04:  72%|███████▏  | 11821/16329 [1:39:32<37:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11821: train loss 1.28743. lr 4.260211e-04:  72%|███████▏  | 11821/16329 [1:39:32<37:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11821: train loss 1.28743. lr 4.260211e-04:  72%|███████▏  | 11822/16329 [1:39:32<37:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11822: train loss 1.24942. lr 4.259949e-04:  72%|███████▏  | 11822/16329 [1:39:33<37:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11822: train loss 1.24942. lr 4.259949e-04:  72%|███████▏  | 11823/16329 [1:39:33<37:09,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11823: train loss 1.26121. lr 4.259687e-04:  72%|███████▏  | 11823/16329 [1:39:33<37:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11823: train loss 1.26121. lr 4.259687e-04:  72%|███████▏  | 11824/16329 [1:39:33<37:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11824: train loss 1.26259. lr 4.259425e-04:  72%|███████▏  | 11824/16329 [1:39:34<37:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11824: train loss 1.26259. lr 4.259425e-04:  72%|███████▏  | 11825/16329 [1:39:34<37:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11825: train loss 1.28271. lr 4.259163e-04:  72%|███████▏  | 11825/16329 [1:39:34<37:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11825: train loss 1.28271. lr 4.259163e-04:  72%|███████▏  | 11826/16329 [1:39:34<37:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11826: train loss 1.27996. lr 4.258901e-04:  72%|███████▏  | 11826/16329 [1:39:35<37:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11826: train loss 1.27996. lr 4.258901e-04:  72%|███████▏  | 11827/16329 [1:39:35<36:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11827: train loss 1.27631. lr 4.258639e-04:  72%|███████▏  | 11827/16329 [1:39:35<36:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11827: train loss 1.27631. lr 4.258639e-04:  72%|███████▏  | 11828/16329 [1:39:35<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11828: train loss 1.30692. lr 4.258377e-04:  72%|███████▏  | 11828/16329 [1:39:36<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11828: train loss 1.30692. lr 4.258377e-04:  72%|███████▏  | 11829/16329 [1:39:36<37:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11829: train loss 1.25419. lr 4.258115e-04:  72%|███████▏  | 11829/16329 [1:39:36<37:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11829: train loss 1.25419. lr 4.258115e-04:  72%|███████▏  | 11830/16329 [1:39:36<37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11830: train loss 1.27073. lr 4.257853e-04:  72%|███████▏  | 11830/16329 [1:39:37<37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11830: train loss 1.27073. lr 4.257853e-04:  72%|███████▏  | 11831/16329 [1:39:37<36:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11831: train loss 1.27481. lr 4.257591e-04:  72%|███████▏  | 11831/16329 [1:39:37<36:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11831: train loss 1.27481. lr 4.257591e-04:  72%|███████▏  | 11832/16329 [1:39:37<37:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11832: train loss 1.28281. lr 4.257329e-04:  72%|███████▏  | 11832/16329 [1:39:38<37:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11832: train loss 1.28281. lr 4.257329e-04:  72%|███████▏  | 11833/16329 [1:39:38<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11833: train loss 1.30282. lr 4.257067e-04:  72%|███████▏  | 11833/16329 [1:39:38<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11833: train loss 1.30282. lr 4.257067e-04:  72%|███████▏  | 11834/16329 [1:39:38<36:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11834: train loss 1.29180. lr 4.256805e-04:  72%|███████▏  | 11834/16329 [1:39:39<36:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11834: train loss 1.29180. lr 4.256805e-04:  72%|███████▏  | 11835/16329 [1:39:39<37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11835: train loss 1.29712. lr 4.256543e-04:  72%|███████▏  | 11835/16329 [1:39:39<37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11835: train loss 1.29712. lr 4.256543e-04:  72%|███████▏  | 11836/16329 [1:39:39<37:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11836: train loss 1.25993. lr 4.256281e-04:  72%|███████▏  | 11836/16329 [1:39:40<37:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11836: train loss 1.25993. lr 4.256281e-04:  72%|███████▏  | 11837/16329 [1:39:40<37:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11837: train loss 1.28819. lr 4.256019e-04:  72%|███████▏  | 11837/16329 [1:39:40<37:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11837: train loss 1.28819. lr 4.256019e-04:  72%|███████▏  | 11838/16329 [1:39:40<37:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11838: train loss 1.26389. lr 4.255757e-04:  72%|███████▏  | 11838/16329 [1:39:41<37:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11838: train loss 1.26389. lr 4.255757e-04:  73%|███████▎  | 11839/16329 [1:39:41<37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11839: train loss 1.24191. lr 4.255495e-04:  73%|███████▎  | 11839/16329 [1:39:41<37:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11839: train loss 1.24191. lr 4.255495e-04:  73%|███████▎  | 11840/16329 [1:39:41<37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11840: train loss 1.26298. lr 4.255233e-04:  73%|███████▎  | 11840/16329 [1:39:42<37:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11840: train loss 1.26298. lr 4.255233e-04:  73%|███████▎  | 11841/16329 [1:39:42<37:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11841: train loss 1.28602. lr 4.254971e-04:  73%|███████▎  | 11841/16329 [1:39:42<37:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11841: train loss 1.28602. lr 4.254971e-04:  73%|███████▎  | 11842/16329 [1:39:42<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11842: train loss 1.24873. lr 4.254708e-04:  73%|███████▎  | 11842/16329 [1:39:43<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11842: train loss 1.24873. lr 4.254708e-04:  73%|███████▎  | 11843/16329 [1:39:43<37:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11843: train loss 1.29667. lr 4.254446e-04:  73%|███████▎  | 11843/16329 [1:39:43<37:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11843: train loss 1.29667. lr 4.254446e-04:  73%|███████▎  | 11844/16329 [1:39:43<37:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11844: train loss 1.30240. lr 4.254184e-04:  73%|███████▎  | 11844/16329 [1:39:44<37:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11844: train loss 1.30240. lr 4.254184e-04:  73%|███████▎  | 11845/16329 [1:39:44<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11845: train loss 1.28027. lr 4.253922e-04:  73%|███████▎  | 11845/16329 [1:39:44<37:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11845: train loss 1.28027. lr 4.253922e-04:  73%|███████▎  | 11846/16329 [1:39:44<40:46,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11846: train loss 1.26009. lr 4.253660e-04:  73%|███████▎  | 11846/16329 [1:39:45<40:46,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 11846: train loss 1.26009. lr 4.253660e-04:  73%|███████▎  | 11847/16329 [1:39:45<39:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11847: train loss 1.24673. lr 4.253397e-04:  73%|███████▎  | 11847/16329 [1:39:45<39:43,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11847: train loss 1.24673. lr 4.253397e-04:  73%|███████▎  | 11848/16329 [1:39:45<38:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11848: train loss 1.23436. lr 4.253135e-04:  73%|███████▎  | 11848/16329 [1:39:46<38:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11848: train loss 1.23436. lr 4.253135e-04:  73%|███████▎  | 11849/16329 [1:39:46<38:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11849: train loss 1.28823. lr 4.252873e-04:  73%|███████▎  | 11849/16329 [1:39:46<38:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11849: train loss 1.28823. lr 4.252873e-04:  73%|███████▎  | 11850/16329 [1:39:46<37:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11850: train loss 1.29283. lr 4.252611e-04:  73%|███████▎  | 11850/16329 [1:39:47<37:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11850: train loss 1.29283. lr 4.252611e-04:  73%|███████▎  | 11851/16329 [1:39:47<37:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11851: train loss 1.26588. lr 4.252349e-04:  73%|███████▎  | 11851/16329 [1:39:47<37:34,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11851: train loss 1.26588. lr 4.252349e-04:  73%|███████▎  | 11852/16329 [1:39:47<37:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11852: train loss 1.29978. lr 4.252086e-04:  73%|███████▎  | 11852/16329 [1:39:48<37:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11852: train loss 1.29978. lr 4.252086e-04:  73%|███████▎  | 11853/16329 [1:39:48<37:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11853: train loss 1.27375. lr 4.251824e-04:  73%|███████▎  | 11853/16329 [1:39:48<37:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11853: train loss 1.27375. lr 4.251824e-04:  73%|███████▎  | 11854/16329 [1:39:48<37:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11854: train loss 1.26815. lr 4.251562e-04:  73%|███████▎  | 11854/16329 [1:39:49<37:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11854: train loss 1.26815. lr 4.251562e-04:  73%|███████▎  | 11855/16329 [1:39:49<37:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11855: train loss 1.27526. lr 4.251299e-04:  73%|███████▎  | 11855/16329 [1:39:49<37:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11855: train loss 1.27526. lr 4.251299e-04:  73%|███████▎  | 11856/16329 [1:39:49<36:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11856: train loss 1.25583. lr 4.251037e-04:  73%|███████▎  | 11856/16329 [1:39:50<36:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11856: train loss 1.25583. lr 4.251037e-04:  73%|███████▎  | 11857/16329 [1:39:50<36:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11857: train loss 1.25328. lr 4.250775e-04:  73%|███████▎  | 11857/16329 [1:39:50<36:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11857: train loss 1.25328. lr 4.250775e-04:  73%|███████▎  | 11858/16329 [1:39:50<36:48,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11858: train loss 1.27956. lr 4.250512e-04:  73%|███████▎  | 11858/16329 [1:39:51<36:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11858: train loss 1.27956. lr 4.250512e-04:  73%|███████▎  | 11859/16329 [1:39:51<36:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11859: train loss 1.25480. lr 4.250250e-04:  73%|███████▎  | 11859/16329 [1:39:51<36:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11859: train loss 1.25480. lr 4.250250e-04:  73%|███████▎  | 11860/16329 [1:39:51<36:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11860: train loss 1.25490. lr 4.249988e-04:  73%|███████▎  | 11860/16329 [1:39:52<36:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11860: train loss 1.25490. lr 4.249988e-04:  73%|███████▎  | 11861/16329 [1:39:52<36:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11861: train loss 1.26851. lr 4.249725e-04:  73%|███████▎  | 11861/16329 [1:39:52<36:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11861: train loss 1.26851. lr 4.249725e-04:  73%|███████▎  | 11862/16329 [1:39:52<36:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11862: train loss 1.23453. lr 4.249463e-04:  73%|███████▎  | 11862/16329 [1:39:53<36:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11862: train loss 1.23453. lr 4.249463e-04:  73%|███████▎  | 11863/16329 [1:39:53<36:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11863: train loss 1.25349. lr 4.249201e-04:  73%|███████▎  | 11863/16329 [1:39:53<36:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11863: train loss 1.25349. lr 4.249201e-04:  73%|███████▎  | 11864/16329 [1:39:53<36:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11864: train loss 1.29602. lr 4.248938e-04:  73%|███████▎  | 11864/16329 [1:39:54<36:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11864: train loss 1.29602. lr 4.248938e-04:  73%|███████▎  | 11865/16329 [1:39:54<37:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11865: train loss 1.29571. lr 4.248676e-04:  73%|███████▎  | 11865/16329 [1:39:54<37:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11865: train loss 1.29571. lr 4.248676e-04:  73%|███████▎  | 11866/16329 [1:39:54<38:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11866: train loss 1.25513. lr 4.248413e-04:  73%|███████▎  | 11866/16329 [1:39:55<38:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11866: train loss 1.25513. lr 4.248413e-04:  73%|███████▎  | 11867/16329 [1:39:55<38:15,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11867: train loss 1.28129. lr 4.248151e-04:  73%|███████▎  | 11867/16329 [1:39:55<38:15,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11867: train loss 1.28129. lr 4.248151e-04:  73%|███████▎  | 11868/16329 [1:39:55<38:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11868: train loss 1.24903. lr 4.247889e-04:  73%|███████▎  | 11868/16329 [1:39:56<38:06,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11868: train loss 1.24903. lr 4.247889e-04:  73%|███████▎  | 11869/16329 [1:39:56<37:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11869: train loss 1.28457. lr 4.247626e-04:  73%|███████▎  | 11869/16329 [1:39:56<37:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11869: train loss 1.28457. lr 4.247626e-04:  73%|███████▎  | 11870/16329 [1:39:56<37:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11870: train loss 1.25993. lr 4.247364e-04:  73%|███████▎  | 11870/16329 [1:39:57<37:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11870: train loss 1.25993. lr 4.247364e-04:  73%|███████▎  | 11871/16329 [1:39:57<37:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11871: train loss 1.26173. lr 4.247101e-04:  73%|███████▎  | 11871/16329 [1:39:57<37:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11871: train loss 1.26173. lr 4.247101e-04:  73%|███████▎  | 11872/16329 [1:39:57<37:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11872: train loss 1.27395. lr 4.246839e-04:  73%|███████▎  | 11872/16329 [1:39:58<37:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11872: train loss 1.27395. lr 4.246839e-04:  73%|███████▎  | 11873/16329 [1:39:58<37:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11873: train loss 1.27950. lr 4.246576e-04:  73%|███████▎  | 11873/16329 [1:39:58<37:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11873: train loss 1.27950. lr 4.246576e-04:  73%|███████▎  | 11874/16329 [1:39:58<37:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11874: train loss 1.30130. lr 4.246314e-04:  73%|███████▎  | 11874/16329 [1:39:59<37:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11874: train loss 1.30130. lr 4.246314e-04:  73%|███████▎  | 11875/16329 [1:39:59<36:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11875: train loss 1.27102. lr 4.246051e-04:  73%|███████▎  | 11875/16329 [1:39:59<36:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11875: train loss 1.27102. lr 4.246051e-04:  73%|███████▎  | 11876/16329 [1:39:59<36:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11876: train loss 1.28019. lr 4.245789e-04:  73%|███████▎  | 11876/16329 [1:40:00<36:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11876: train loss 1.28019. lr 4.245789e-04:  73%|███████▎  | 11877/16329 [1:40:00<36:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11877: train loss 1.26776. lr 4.245526e-04:  73%|███████▎  | 11877/16329 [1:40:00<36:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11877: train loss 1.26776. lr 4.245526e-04:  73%|███████▎  | 11878/16329 [1:40:00<36:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11878: train loss 1.29402. lr 4.245263e-04:  73%|███████▎  | 11878/16329 [1:40:01<36:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11878: train loss 1.29402. lr 4.245263e-04:  73%|███████▎  | 11879/16329 [1:40:01<36:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11879: train loss 1.27342. lr 4.245001e-04:  73%|███████▎  | 11879/16329 [1:40:01<36:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11879: train loss 1.27342. lr 4.245001e-04:  73%|███████▎  | 11880/16329 [1:40:01<36:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11880: train loss 1.23967. lr 4.244738e-04:  73%|███████▎  | 11880/16329 [1:40:02<36:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11880: train loss 1.23967. lr 4.244738e-04:  73%|███████▎  | 11881/16329 [1:40:02<41:19,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11881: train loss 1.25722. lr 4.244476e-04:  73%|███████▎  | 11881/16329 [1:40:02<41:19,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11881: train loss 1.25722. lr 4.244476e-04:  73%|███████▎  | 11882/16329 [1:40:02<39:52,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11882: train loss 1.29264. lr 4.244213e-04:  73%|███████▎  | 11882/16329 [1:40:03<39:52,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 11882: train loss 1.29264. lr 4.244213e-04:  73%|███████▎  | 11883/16329 [1:40:03<38:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11883: train loss 1.30341. lr 4.243951e-04:  73%|███████▎  | 11883/16329 [1:40:03<38:45,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11883: train loss 1.30341. lr 4.243951e-04:  73%|███████▎  | 11884/16329 [1:40:03<38:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11884: train loss 1.29286. lr 4.243688e-04:  73%|███████▎  | 11884/16329 [1:40:04<38:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11884: train loss 1.29286. lr 4.243688e-04:  73%|███████▎  | 11885/16329 [1:40:04<37:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11885: train loss 1.26935. lr 4.243425e-04:  73%|███████▎  | 11885/16329 [1:40:04<37:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11885: train loss 1.26935. lr 4.243425e-04:  73%|███████▎  | 11886/16329 [1:40:04<37:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11886: train loss 1.29351. lr 4.243163e-04:  73%|███████▎  | 11886/16329 [1:40:05<37:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11886: train loss 1.29351. lr 4.243163e-04:  73%|███████▎  | 11887/16329 [1:40:05<37:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11887: train loss 1.24387. lr 4.242900e-04:  73%|███████▎  | 11887/16329 [1:40:05<37:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11887: train loss 1.24387. lr 4.242900e-04:  73%|███████▎  | 11888/16329 [1:40:05<36:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11888: train loss 1.27884. lr 4.242637e-04:  73%|███████▎  | 11888/16329 [1:40:06<36:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11888: train loss 1.27884. lr 4.242637e-04:  73%|███████▎  | 11889/16329 [1:40:06<36:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11889: train loss 1.22334. lr 4.242375e-04:  73%|███████▎  | 11889/16329 [1:40:06<36:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11889: train loss 1.22334. lr 4.242375e-04:  73%|███████▎  | 11890/16329 [1:40:06<36:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11890: train loss 1.30258. lr 4.242112e-04:  73%|███████▎  | 11890/16329 [1:40:07<36:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11890: train loss 1.30258. lr 4.242112e-04:  73%|███████▎  | 11891/16329 [1:40:07<36:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11891: train loss 1.26749. lr 4.241849e-04:  73%|███████▎  | 11891/16329 [1:40:07<36:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11891: train loss 1.26749. lr 4.241849e-04:  73%|███████▎  | 11892/16329 [1:40:07<36:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11892: train loss 1.23128. lr 4.241586e-04:  73%|███████▎  | 11892/16329 [1:40:08<36:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11892: train loss 1.23128. lr 4.241586e-04:  73%|███████▎  | 11893/16329 [1:40:08<36:33,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11893: train loss 1.28649. lr 4.241324e-04:  73%|███████▎  | 11893/16329 [1:40:08<36:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11893: train loss 1.28649. lr 4.241324e-04:  73%|███████▎  | 11894/16329 [1:40:08<36:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11894: train loss 1.27157. lr 4.241061e-04:  73%|███████▎  | 11894/16329 [1:40:09<36:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11894: train loss 1.27157. lr 4.241061e-04:  73%|███████▎  | 11895/16329 [1:40:09<36:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11895: train loss 1.27180. lr 4.240798e-04:  73%|███████▎  | 11895/16329 [1:40:09<36:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11895: train loss 1.27180. lr 4.240798e-04:  73%|███████▎  | 11896/16329 [1:40:09<36:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11896: train loss 1.25566. lr 4.240535e-04:  73%|███████▎  | 11896/16329 [1:40:10<36:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11896: train loss 1.25566. lr 4.240535e-04:  73%|███████▎  | 11897/16329 [1:40:10<36:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11897: train loss 1.29099. lr 4.240273e-04:  73%|███████▎  | 11897/16329 [1:40:10<36:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11897: train loss 1.29099. lr 4.240273e-04:  73%|███████▎  | 11898/16329 [1:40:10<36:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11898: train loss 1.28313. lr 4.240010e-04:  73%|███████▎  | 11898/16329 [1:40:11<36:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11898: train loss 1.28313. lr 4.240010e-04:  73%|███████▎  | 11899/16329 [1:40:11<36:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11899: train loss 1.23530. lr 4.239747e-04:  73%|███████▎  | 11899/16329 [1:40:11<36:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11899: train loss 1.23530. lr 4.239747e-04:  73%|███████▎  | 11900/16329 [1:40:11<36:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11900: train loss 1.27163. lr 4.239484e-04:  73%|███████▎  | 11900/16329 [1:40:12<36:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11900: train loss 1.27163. lr 4.239484e-04:  73%|███████▎  | 11901/16329 [1:40:12<36:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11901: train loss 1.25823. lr 4.239221e-04:  73%|███████▎  | 11901/16329 [1:40:12<36:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11901: train loss 1.25823. lr 4.239221e-04:  73%|███████▎  | 11902/16329 [1:40:12<36:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11902: train loss 1.28547. lr 4.238959e-04:  73%|███████▎  | 11902/16329 [1:40:13<36:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11902: train loss 1.28547. lr 4.238959e-04:  73%|███████▎  | 11903/16329 [1:40:13<36:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11903: train loss 1.27737. lr 4.238696e-04:  73%|███████▎  | 11903/16329 [1:40:13<36:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11903: train loss 1.27737. lr 4.238696e-04:  73%|███████▎  | 11904/16329 [1:40:13<36:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11904: train loss 1.27580. lr 4.238433e-04:  73%|███████▎  | 11904/16329 [1:40:14<36:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11904: train loss 1.27580. lr 4.238433e-04:  73%|███████▎  | 11905/16329 [1:40:14<36:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11905: train loss 1.31860. lr 4.238170e-04:  73%|███████▎  | 11905/16329 [1:40:14<36:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11905: train loss 1.31860. lr 4.238170e-04:  73%|███████▎  | 11906/16329 [1:40:14<40:48,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11906: train loss 1.27702. lr 4.237907e-04:  73%|███████▎  | 11906/16329 [1:40:15<40:48,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 11906: train loss 1.27702. lr 4.237907e-04:  73%|███████▎  | 11907/16329 [1:40:15<39:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11907: train loss 1.29974. lr 4.237644e-04:  73%|███████▎  | 11907/16329 [1:40:15<39:25,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11907: train loss 1.29974. lr 4.237644e-04:  73%|███████▎  | 11908/16329 [1:40:15<38:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11908: train loss 1.24825. lr 4.237381e-04:  73%|███████▎  | 11908/16329 [1:40:16<38:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11908: train loss 1.24825. lr 4.237381e-04:  73%|███████▎  | 11909/16329 [1:40:16<37:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11909: train loss 1.25295. lr 4.237118e-04:  73%|███████▎  | 11909/16329 [1:40:16<37:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11909: train loss 1.25295. lr 4.237118e-04:  73%|███████▎  | 11910/16329 [1:40:16<37:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11910: train loss 1.31673. lr 4.236855e-04:  73%|███████▎  | 11910/16329 [1:40:17<37:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11910: train loss 1.31673. lr 4.236855e-04:  73%|███████▎  | 11911/16329 [1:40:17<37:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11911: train loss 1.23849. lr 4.236593e-04:  73%|███████▎  | 11911/16329 [1:40:17<37:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11911: train loss 1.23849. lr 4.236593e-04:  73%|███████▎  | 11912/16329 [1:40:17<36:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11912: train loss 1.32097. lr 4.236330e-04:  73%|███████▎  | 11912/16329 [1:40:18<36:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11912: train loss 1.32097. lr 4.236330e-04:  73%|███████▎  | 11913/16329 [1:40:18<36:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11913: train loss 1.26871. lr 4.236067e-04:  73%|███████▎  | 11913/16329 [1:40:18<36:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11913: train loss 1.26871. lr 4.236067e-04:  73%|███████▎  | 11914/16329 [1:40:18<36:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11914: train loss 1.29240. lr 4.235804e-04:  73%|███████▎  | 11914/16329 [1:40:19<36:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11914: train loss 1.29240. lr 4.235804e-04:  73%|███████▎  | 11915/16329 [1:40:19<36:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11915: train loss 1.26182. lr 4.235541e-04:  73%|███████▎  | 11915/16329 [1:40:19<36:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11915: train loss 1.26182. lr 4.235541e-04:  73%|███████▎  | 11916/16329 [1:40:19<37:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11916: train loss 1.26454. lr 4.235278e-04:  73%|███████▎  | 11916/16329 [1:40:20<37:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11916: train loss 1.26454. lr 4.235278e-04:  73%|███████▎  | 11917/16329 [1:40:20<37:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11917: train loss 1.26325. lr 4.235015e-04:  73%|███████▎  | 11917/16329 [1:40:21<37:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11917: train loss 1.26325. lr 4.235015e-04:  73%|███████▎  | 11918/16329 [1:40:21<38:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11918: train loss 1.26806. lr 4.234752e-04:  73%|███████▎  | 11918/16329 [1:40:21<38:03,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11918: train loss 1.26806. lr 4.234752e-04:  73%|███████▎  | 11919/16329 [1:40:21<37:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11919: train loss 1.28309. lr 4.234489e-04:  73%|███████▎  | 11919/16329 [1:40:22<37:59,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11919: train loss 1.28309. lr 4.234489e-04:  73%|███████▎  | 11920/16329 [1:40:22<37:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11920: train loss 1.26868. lr 4.234226e-04:  73%|███████▎  | 11920/16329 [1:40:22<37:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11920: train loss 1.26868. lr 4.234226e-04:  73%|███████▎  | 11921/16329 [1:40:22<37:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11921: train loss 1.28326. lr 4.233963e-04:  73%|███████▎  | 11921/16329 [1:40:22<37:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11921: train loss 1.28326. lr 4.233963e-04:  73%|███████▎  | 11922/16329 [1:40:22<36:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11922: train loss 1.24616. lr 4.233699e-04:  73%|███████▎  | 11922/16329 [1:40:23<36:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11922: train loss 1.24616. lr 4.233699e-04:  73%|███████▎  | 11923/16329 [1:40:23<36:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11923: train loss 1.23805. lr 4.233436e-04:  73%|███████▎  | 11923/16329 [1:40:23<36:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11923: train loss 1.23805. lr 4.233436e-04:  73%|███████▎  | 11924/16329 [1:40:23<36:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11924: train loss 1.26755. lr 4.233173e-04:  73%|███████▎  | 11924/16329 [1:40:24<36:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11924: train loss 1.26755. lr 4.233173e-04:  73%|███████▎  | 11925/16329 [1:40:24<36:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11925: train loss 1.27301. lr 4.232910e-04:  73%|███████▎  | 11925/16329 [1:40:24<36:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11925: train loss 1.27301. lr 4.232910e-04:  73%|███████▎  | 11926/16329 [1:40:24<36:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11926: train loss 1.25478. lr 4.232647e-04:  73%|███████▎  | 11926/16329 [1:40:25<36:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11926: train loss 1.25478. lr 4.232647e-04:  73%|███████▎  | 11927/16329 [1:40:25<36:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11927: train loss 1.27144. lr 4.232384e-04:  73%|███████▎  | 11927/16329 [1:40:25<36:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11927: train loss 1.27144. lr 4.232384e-04:  73%|███████▎  | 11928/16329 [1:40:25<36:11,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11928: train loss 1.23268. lr 4.232121e-04:  73%|███████▎  | 11928/16329 [1:40:26<36:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11928: train loss 1.23268. lr 4.232121e-04:  73%|███████▎  | 11929/16329 [1:40:26<36:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11929: train loss 1.23631. lr 4.231858e-04:  73%|███████▎  | 11929/16329 [1:40:26<36:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11929: train loss 1.23631. lr 4.231858e-04:  73%|███████▎  | 11930/16329 [1:40:26<36:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11930: train loss 1.25955. lr 4.231595e-04:  73%|███████▎  | 11930/16329 [1:40:27<36:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11930: train loss 1.25955. lr 4.231595e-04:  73%|███████▎  | 11931/16329 [1:40:27<36:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11931: train loss 1.26414. lr 4.231331e-04:  73%|███████▎  | 11931/16329 [1:40:27<36:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11931: train loss 1.26414. lr 4.231331e-04:  73%|███████▎  | 11932/16329 [1:40:27<36:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11932: train loss 1.26106. lr 4.231068e-04:  73%|███████▎  | 11932/16329 [1:40:28<36:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11932: train loss 1.26106. lr 4.231068e-04:  73%|███████▎  | 11933/16329 [1:40:28<40:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11933: train loss 1.26426. lr 4.230805e-04:  73%|███████▎  | 11933/16329 [1:40:29<40:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 11933: train loss 1.26426. lr 4.230805e-04:  73%|███████▎  | 11934/16329 [1:40:29<39:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11934: train loss 1.27153. lr 4.230542e-04:  73%|███████▎  | 11934/16329 [1:40:29<39:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 11934: train loss 1.27153. lr 4.230542e-04:  73%|███████▎  | 11935/16329 [1:40:29<38:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11935: train loss 1.25037. lr 4.230279e-04:  73%|███████▎  | 11935/16329 [1:40:30<38:11,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 11935: train loss 1.25037. lr 4.230279e-04:  73%|███████▎  | 11936/16329 [1:40:30<37:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11936: train loss 1.25902. lr 4.230015e-04:  73%|███████▎  | 11936/16329 [1:40:30<37:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11936: train loss 1.25902. lr 4.230015e-04:  73%|███████▎  | 11937/16329 [1:40:30<37:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11937: train loss 1.23264. lr 4.229752e-04:  73%|███████▎  | 11937/16329 [1:40:31<37:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11937: train loss 1.23264. lr 4.229752e-04:  73%|███████▎  | 11938/16329 [1:40:31<36:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11938: train loss 1.29880. lr 4.229489e-04:  73%|███████▎  | 11938/16329 [1:40:31<36:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11938: train loss 1.29880. lr 4.229489e-04:  73%|███████▎  | 11939/16329 [1:40:31<36:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11939: train loss 1.28261. lr 4.229226e-04:  73%|███████▎  | 11939/16329 [1:40:32<36:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11939: train loss 1.28261. lr 4.229226e-04:  73%|███████▎  | 11940/16329 [1:40:32<36:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11940: train loss 1.26539. lr 4.228962e-04:  73%|███████▎  | 11940/16329 [1:40:32<36:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11940: train loss 1.26539. lr 4.228962e-04:  73%|███████▎  | 11941/16329 [1:40:32<36:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11941: train loss 1.27636. lr 4.228699e-04:  73%|███████▎  | 11941/16329 [1:40:33<36:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11941: train loss 1.27636. lr 4.228699e-04:  73%|███████▎  | 11942/16329 [1:40:33<36:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11942: train loss 1.28600. lr 4.228436e-04:  73%|███████▎  | 11942/16329 [1:40:33<36:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11942: train loss 1.28600. lr 4.228436e-04:  73%|███████▎  | 11943/16329 [1:40:33<36:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11943: train loss 1.24468. lr 4.228172e-04:  73%|███████▎  | 11943/16329 [1:40:34<36:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11943: train loss 1.24468. lr 4.228172e-04:  73%|███████▎  | 11944/16329 [1:40:34<36:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11944: train loss 1.27970. lr 4.227909e-04:  73%|███████▎  | 11944/16329 [1:40:34<36:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11944: train loss 1.27970. lr 4.227909e-04:  73%|███████▎  | 11945/16329 [1:40:34<36:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11945: train loss 1.27110. lr 4.227646e-04:  73%|███████▎  | 11945/16329 [1:40:35<36:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11945: train loss 1.27110. lr 4.227646e-04:  73%|███████▎  | 11946/16329 [1:40:35<36:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11946: train loss 1.22598. lr 4.227382e-04:  73%|███████▎  | 11946/16329 [1:40:35<36:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11946: train loss 1.22598. lr 4.227382e-04:  73%|███████▎  | 11947/16329 [1:40:35<36:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11947: train loss 1.25371. lr 4.227119e-04:  73%|███████▎  | 11947/16329 [1:40:36<36:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11947: train loss 1.25371. lr 4.227119e-04:  73%|███████▎  | 11948/16329 [1:40:36<36:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11948: train loss 1.26682. lr 4.226856e-04:  73%|███████▎  | 11948/16329 [1:40:36<36:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11948: train loss 1.26682. lr 4.226856e-04:  73%|███████▎  | 11949/16329 [1:40:36<36:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11949: train loss 1.26449. lr 4.226592e-04:  73%|███████▎  | 11949/16329 [1:40:37<36:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11949: train loss 1.26449. lr 4.226592e-04:  73%|███████▎  | 11950/16329 [1:40:37<35:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11950: train loss 1.27304. lr 4.226329e-04:  73%|███████▎  | 11950/16329 [1:40:37<35:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11950: train loss 1.27304. lr 4.226329e-04:  73%|███████▎  | 11951/16329 [1:40:37<36:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11951: train loss 1.23442. lr 4.226066e-04:  73%|███████▎  | 11951/16329 [1:40:38<36:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11951: train loss 1.23442. lr 4.226066e-04:  73%|███████▎  | 11952/16329 [1:40:38<36:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11952: train loss 1.29106. lr 4.225802e-04:  73%|███████▎  | 11952/16329 [1:40:38<36:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11952: train loss 1.29106. lr 4.225802e-04:  73%|███████▎  | 11953/16329 [1:40:38<36:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11953: train loss 1.24096. lr 4.225539e-04:  73%|███████▎  | 11953/16329 [1:40:38<36:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11953: train loss 1.24096. lr 4.225539e-04:  73%|███████▎  | 11954/16329 [1:40:38<36:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11954: train loss 1.25342. lr 4.225275e-04:  73%|███████▎  | 11954/16329 [1:40:39<36:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11954: train loss 1.25342. lr 4.225275e-04:  73%|███████▎  | 11955/16329 [1:40:39<35:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11955: train loss 1.27239. lr 4.225012e-04:  73%|███████▎  | 11955/16329 [1:40:40<35:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11955: train loss 1.27239. lr 4.225012e-04:  73%|███████▎  | 11956/16329 [1:40:40<37:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11956: train loss 1.26406. lr 4.224748e-04:  73%|███████▎  | 11956/16329 [1:40:40<37:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11956: train loss 1.26406. lr 4.224748e-04:  73%|███████▎  | 11957/16329 [1:40:40<37:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11957: train loss 1.24515. lr 4.224485e-04:  73%|███████▎  | 11957/16329 [1:40:41<37:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11957: train loss 1.24515. lr 4.224485e-04:  73%|███████▎  | 11958/16329 [1:40:41<37:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11958: train loss 1.27581. lr 4.224222e-04:  73%|███████▎  | 11958/16329 [1:40:41<37:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11958: train loss 1.27581. lr 4.224222e-04:  73%|███████▎  | 11959/16329 [1:40:41<37:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11959: train loss 1.26021. lr 4.223958e-04:  73%|███████▎  | 11959/16329 [1:40:42<37:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11959: train loss 1.26021. lr 4.223958e-04:  73%|███████▎  | 11960/16329 [1:40:42<37:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11960: train loss 1.24555. lr 4.223695e-04:  73%|███████▎  | 11960/16329 [1:40:42<37:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11960: train loss 1.24555. lr 4.223695e-04:  73%|███████▎  | 11961/16329 [1:40:42<36:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11961: train loss 1.28202. lr 4.223431e-04:  73%|███████▎  | 11961/16329 [1:40:43<36:54,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11961: train loss 1.28202. lr 4.223431e-04:  73%|███████▎  | 11962/16329 [1:40:43<36:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11962: train loss 1.27725. lr 4.223168e-04:  73%|███████▎  | 11962/16329 [1:40:43<36:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11962: train loss 1.27725. lr 4.223168e-04:  73%|███████▎  | 11963/16329 [1:40:43<36:27,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11963: train loss 1.22647. lr 4.222904e-04:  73%|███████▎  | 11963/16329 [1:40:44<36:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11963: train loss 1.22647. lr 4.222904e-04:  73%|███████▎  | 11964/16329 [1:40:44<36:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11964: train loss 1.26875. lr 4.222640e-04:  73%|███████▎  | 11964/16329 [1:40:44<36:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11964: train loss 1.26875. lr 4.222640e-04:  73%|███████▎  | 11965/16329 [1:40:44<37:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11965: train loss 1.26353. lr 4.222377e-04:  73%|███████▎  | 11965/16329 [1:40:45<37:22,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11965: train loss 1.26353. lr 4.222377e-04:  73%|███████▎  | 11966/16329 [1:40:45<37:31,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11966: train loss 1.28748. lr 4.222113e-04:  73%|███████▎  | 11966/16329 [1:40:45<37:31,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11966: train loss 1.28748. lr 4.222113e-04:  73%|███████▎  | 11967/16329 [1:40:45<37:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11967: train loss 1.26049. lr 4.221850e-04:  73%|███████▎  | 11967/16329 [1:40:46<37:28,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 11967: train loss 1.26049. lr 4.221850e-04:  73%|███████▎  | 11968/16329 [1:40:46<37:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11968: train loss 1.23112. lr 4.221586e-04:  73%|███████▎  | 11968/16329 [1:40:46<37:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11968: train loss 1.23112. lr 4.221586e-04:  73%|███████▎  | 11969/16329 [1:40:46<37:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11969: train loss 1.29055. lr 4.221323e-04:  73%|███████▎  | 11969/16329 [1:40:47<37:02,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11969: train loss 1.29055. lr 4.221323e-04:  73%|███████▎  | 11970/16329 [1:40:47<36:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11970: train loss 1.29241. lr 4.221059e-04:  73%|███████▎  | 11970/16329 [1:40:47<36:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11970: train loss 1.29241. lr 4.221059e-04:  73%|███████▎  | 11971/16329 [1:40:47<36:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11971: train loss 1.22566. lr 4.220795e-04:  73%|███████▎  | 11971/16329 [1:40:48<36:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11971: train loss 1.22566. lr 4.220795e-04:  73%|███████▎  | 11972/16329 [1:40:48<37:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11972: train loss 1.26210. lr 4.220532e-04:  73%|███████▎  | 11972/16329 [1:40:48<37:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 11972: train loss 1.26210. lr 4.220532e-04:  73%|███████▎  | 11973/16329 [1:40:48<41:37,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 11973: train loss 1.26228. lr 4.220268e-04:  73%|███████▎  | 11973/16329 [1:40:49<41:37,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 11973: train loss 1.26228. lr 4.220268e-04:  73%|███████▎  | 11974/16329 [1:40:49<40:32,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11974: train loss 1.22202. lr 4.220004e-04:  73%|███████▎  | 11974/16329 [1:40:49<40:32,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 11974: train loss 1.22202. lr 4.220004e-04:  73%|███████▎  | 11975/16329 [1:40:49<39:30,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11975: train loss 1.27221. lr 4.219741e-04:  73%|███████▎  | 11975/16329 [1:40:50<39:30,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 11975: train loss 1.27221. lr 4.219741e-04:  73%|███████▎  | 11976/16329 [1:40:50<38:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11976: train loss 1.24336. lr 4.219477e-04:  73%|███████▎  | 11976/16329 [1:40:50<38:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 11976: train loss 1.24336. lr 4.219477e-04:  73%|███████▎  | 11977/16329 [1:40:50<37:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11977: train loss 1.26232. lr 4.219213e-04:  73%|███████▎  | 11977/16329 [1:40:51<37:59,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 11977: train loss 1.26232. lr 4.219213e-04:  73%|███████▎  | 11978/16329 [1:40:51<37:28,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11978: train loss 1.21643. lr 4.218950e-04:  73%|███████▎  | 11978/16329 [1:40:51<37:28,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 11978: train loss 1.21643. lr 4.218950e-04:  73%|███████▎  | 11979/16329 [1:40:51<36:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11979: train loss 1.25588. lr 4.218686e-04:  73%|███████▎  | 11979/16329 [1:40:52<36:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11979: train loss 1.25588. lr 4.218686e-04:  73%|███████▎  | 11980/16329 [1:40:52<36:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11980: train loss 1.26875. lr 4.218422e-04:  73%|███████▎  | 11980/16329 [1:40:52<36:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 11980: train loss 1.26875. lr 4.218422e-04:  73%|███████▎  | 11981/16329 [1:40:52<36:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11981: train loss 1.24191. lr 4.218159e-04:  73%|███████▎  | 11981/16329 [1:40:53<36:19,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11981: train loss 1.24191. lr 4.218159e-04:  73%|███████▎  | 11982/16329 [1:40:53<36:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11982: train loss 1.25148. lr 4.217895e-04:  73%|███████▎  | 11982/16329 [1:40:53<36:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 11982: train loss 1.25148. lr 4.217895e-04:  73%|███████▎  | 11983/16329 [1:40:53<35:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11983: train loss 1.24033. lr 4.217631e-04:  73%|███████▎  | 11983/16329 [1:40:54<35:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 11983: train loss 1.24033. lr 4.217631e-04:  73%|███████▎  | 11984/16329 [1:40:54<35:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11984: train loss 1.26805. lr 4.217367e-04:  73%|███████▎  | 11984/16329 [1:40:54<35:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11984: train loss 1.26805. lr 4.217367e-04:  73%|███████▎  | 11985/16329 [1:40:54<35:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11985: train loss 1.26113. lr 4.217103e-04:  73%|███████▎  | 11985/16329 [1:40:55<35:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11985: train loss 1.26113. lr 4.217103e-04:  73%|███████▎  | 11986/16329 [1:40:55<35:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11986: train loss 1.27639. lr 4.216840e-04:  73%|███████▎  | 11986/16329 [1:40:55<35:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11986: train loss 1.27639. lr 4.216840e-04:  73%|███████▎  | 11987/16329 [1:40:55<35:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11987: train loss 1.25551. lr 4.216576e-04:  73%|███████▎  | 11987/16329 [1:40:56<35:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11987: train loss 1.25551. lr 4.216576e-04:  73%|███████▎  | 11988/16329 [1:40:56<35:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11988: train loss 1.26020. lr 4.216312e-04:  73%|███████▎  | 11988/16329 [1:40:56<35:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11988: train loss 1.26020. lr 4.216312e-04:  73%|███████▎  | 11989/16329 [1:40:56<35:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11989: train loss 1.25476. lr 4.216048e-04:  73%|███████▎  | 11989/16329 [1:40:57<35:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11989: train loss 1.25476. lr 4.216048e-04:  73%|███████▎  | 11990/16329 [1:40:57<35:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11990: train loss 1.24538. lr 4.215784e-04:  73%|███████▎  | 11990/16329 [1:40:57<35:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11990: train loss 1.24538. lr 4.215784e-04:  73%|███████▎  | 11991/16329 [1:40:57<35:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11991: train loss 1.27792. lr 4.215521e-04:  73%|███████▎  | 11991/16329 [1:40:58<35:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11991: train loss 1.27792. lr 4.215521e-04:  73%|███████▎  | 11992/16329 [1:40:58<35:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11992: train loss 1.23340. lr 4.215257e-04:  73%|███████▎  | 11992/16329 [1:40:58<35:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 11992: train loss 1.23340. lr 4.215257e-04:  73%|███████▎  | 11993/16329 [1:40:58<35:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11993: train loss 1.28116. lr 4.214993e-04:  73%|███████▎  | 11993/16329 [1:40:59<35:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11993: train loss 1.28116. lr 4.214993e-04:  73%|███████▎  | 11994/16329 [1:40:59<35:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11994: train loss 1.26063. lr 4.214729e-04:  73%|███████▎  | 11994/16329 [1:40:59<35:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 11994: train loss 1.26063. lr 4.214729e-04:  73%|███████▎  | 11995/16329 [1:40:59<36:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11995: train loss 1.24667. lr 4.214465e-04:  73%|███████▎  | 11995/16329 [1:41:00<36:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 11995: train loss 1.24667. lr 4.214465e-04:  73%|███████▎  | 11996/16329 [1:41:00<36:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11996: train loss 1.24388. lr 4.214201e-04:  73%|███████▎  | 11996/16329 [1:41:00<36:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11996: train loss 1.24388. lr 4.214201e-04:  73%|███████▎  | 11997/16329 [1:41:00<36:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11997: train loss 1.24438. lr 4.213937e-04:  73%|███████▎  | 11997/16329 [1:41:01<36:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 11997: train loss 1.24438. lr 4.213937e-04:  73%|███████▎  | 11998/16329 [1:41:01<36:43,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 11998: train loss 1.25365. lr 4.213673e-04:  73%|███████▎  | 11998/16329 [1:41:01<36:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11998: train loss 1.25365. lr 4.213673e-04:  73%|███████▎  | 11999/16329 [1:41:01<36:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11999: train loss 1.26039. lr 4.213409e-04:  73%|███████▎  | 11999/16329 [1:41:02<36:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 11999: train loss 1.26039. lr 4.213409e-04:  73%|███████▎  | 12000/16329 [1:41:02<36:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12000: train loss 1.26262. lr 4.213145e-04:  73%|███████▎  | 12000/16329 [1:41:02<36:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12000: train loss 1.26262. lr 4.213145e-04:  73%|███████▎  | 12001/16329 [1:41:02<36:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12001: train loss 1.26132. lr 4.212881e-04:  73%|███████▎  | 12001/16329 [1:41:03<36:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12001: train loss 1.26132. lr 4.212881e-04:  74%|███████▎  | 12002/16329 [1:41:03<35:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12002: train loss 1.24308. lr 4.212618e-04:  74%|███████▎  | 12002/16329 [1:41:03<35:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12002: train loss 1.24308. lr 4.212618e-04:  74%|███████▎  | 12003/16329 [1:41:03<35:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12003: train loss 1.25717. lr 4.212354e-04:  74%|███████▎  | 12003/16329 [1:41:04<35:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12003: train loss 1.25717. lr 4.212354e-04:  74%|███████▎  | 12004/16329 [1:41:04<35:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12004: train loss 1.24989. lr 4.212090e-04:  74%|███████▎  | 12004/16329 [1:41:04<35:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12004: train loss 1.24989. lr 4.212090e-04:  74%|███████▎  | 12005/16329 [1:41:04<35:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12005: train loss 1.25224. lr 4.211826e-04:  74%|███████▎  | 12005/16329 [1:41:05<35:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12005: train loss 1.25224. lr 4.211826e-04:  74%|███████▎  | 12006/16329 [1:41:05<35:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12006: train loss 1.27562. lr 4.211562e-04:  74%|███████▎  | 12006/16329 [1:41:05<35:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12006: train loss 1.27562. lr 4.211562e-04:  74%|███████▎  | 12007/16329 [1:41:05<35:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12007: train loss 1.24820. lr 4.211297e-04:  74%|███████▎  | 12007/16329 [1:41:06<35:28,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12007: train loss 1.24820. lr 4.211297e-04:  74%|███████▎  | 12008/16329 [1:41:06<39:16,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12008: train loss 1.30328. lr 4.211033e-04:  74%|███████▎  | 12008/16329 [1:41:07<39:16,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12008: train loss 1.30328. lr 4.211033e-04:  74%|███████▎  | 12009/16329 [1:41:07<38:07,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12009: train loss 1.24252. lr 4.210769e-04:  74%|███████▎  | 12009/16329 [1:41:07<38:07,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12009: train loss 1.24252. lr 4.210769e-04:  74%|███████▎  | 12010/16329 [1:41:07<37:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12010: train loss 1.26228. lr 4.210505e-04:  74%|███████▎  | 12010/16329 [1:41:08<37:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12010: train loss 1.26228. lr 4.210505e-04:  74%|███████▎  | 12011/16329 [1:41:08<36:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12011: train loss 1.25722. lr 4.210241e-04:  74%|███████▎  | 12011/16329 [1:41:08<36:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12011: train loss 1.25722. lr 4.210241e-04:  74%|███████▎  | 12012/16329 [1:41:08<36:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12012: train loss 1.26791. lr 4.209977e-04:  74%|███████▎  | 12012/16329 [1:41:09<36:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12012: train loss 1.26791. lr 4.209977e-04:  74%|███████▎  | 12013/16329 [1:41:09<36:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12013: train loss 1.26329. lr 4.209713e-04:  74%|███████▎  | 12013/16329 [1:41:09<36:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12013: train loss 1.26329. lr 4.209713e-04:  74%|███████▎  | 12014/16329 [1:41:09<35:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12014: train loss 1.25361. lr 4.209449e-04:  74%|███████▎  | 12014/16329 [1:41:09<35:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12014: train loss 1.25361. lr 4.209449e-04:  74%|███████▎  | 12015/16329 [1:41:10<35:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12015: train loss 1.21967. lr 4.209185e-04:  74%|███████▎  | 12015/16329 [1:41:10<35:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12015: train loss 1.21967. lr 4.209185e-04:  74%|███████▎  | 12016/16329 [1:41:10<35:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12016: train loss 1.25074. lr 4.208921e-04:  74%|███████▎  | 12016/16329 [1:41:10<35:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12016: train loss 1.25074. lr 4.208921e-04:  74%|███████▎  | 12017/16329 [1:41:10<35:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12017: train loss 1.27482. lr 4.208657e-04:  74%|███████▎  | 12017/16329 [1:41:11<35:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12017: train loss 1.27482. lr 4.208657e-04:  74%|███████▎  | 12018/16329 [1:41:11<35:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12018: train loss 1.19889. lr 4.208392e-04:  74%|███████▎  | 12018/16329 [1:41:11<35:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12018: train loss 1.19889. lr 4.208392e-04:  74%|███████▎  | 12019/16329 [1:41:11<35:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12019: train loss 1.26446. lr 4.208128e-04:  74%|███████▎  | 12019/16329 [1:41:12<35:26,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12019: train loss 1.26446. lr 4.208128e-04:  74%|███████▎  | 12020/16329 [1:41:12<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12020: train loss 1.26287. lr 4.207864e-04:  74%|███████▎  | 12020/16329 [1:41:12<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12020: train loss 1.26287. lr 4.207864e-04:  74%|███████▎  | 12021/16329 [1:41:12<35:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12021: train loss 1.28221. lr 4.207600e-04:  74%|███████▎  | 12021/16329 [1:41:13<35:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12021: train loss 1.28221. lr 4.207600e-04:  74%|███████▎  | 12022/16329 [1:41:13<35:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12022: train loss 1.22608. lr 4.207336e-04:  74%|███████▎  | 12022/16329 [1:41:13<35:17,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12022: train loss 1.22608. lr 4.207336e-04:  74%|███████▎  | 12023/16329 [1:41:13<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12023: train loss 1.24761. lr 4.207072e-04:  74%|███████▎  | 12023/16329 [1:41:14<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12023: train loss 1.24761. lr 4.207072e-04:  74%|███████▎  | 12024/16329 [1:41:14<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12024: train loss 1.30267. lr 4.206807e-04:  74%|███████▎  | 12024/16329 [1:41:14<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12024: train loss 1.30267. lr 4.206807e-04:  74%|███████▎  | 12025/16329 [1:41:14<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12025: train loss 1.26293. lr 4.206543e-04:  74%|███████▎  | 12025/16329 [1:41:15<35:23,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12025: train loss 1.26293. lr 4.206543e-04:  74%|███████▎  | 12026/16329 [1:41:15<35:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12026: train loss 1.24640. lr 4.206279e-04:  74%|███████▎  | 12026/16329 [1:41:15<35:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12026: train loss 1.24640. lr 4.206279e-04:  74%|███████▎  | 12027/16329 [1:41:15<35:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12027: train loss 1.24415. lr 4.206015e-04:  74%|███████▎  | 12027/16329 [1:41:16<35:20,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12027: train loss 1.24415. lr 4.206015e-04:  74%|███████▎  | 12028/16329 [1:41:16<35:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12028: train loss 1.29807. lr 4.205750e-04:  74%|███████▎  | 12028/16329 [1:41:16<35:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12028: train loss 1.29807. lr 4.205750e-04:  74%|███████▎  | 12029/16329 [1:41:16<35:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12029: train loss 1.28060. lr 4.205486e-04:  74%|███████▎  | 12029/16329 [1:41:17<35:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12029: train loss 1.28060. lr 4.205486e-04:  74%|███████▎  | 12030/16329 [1:41:17<35:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12030: train loss 1.25492. lr 4.205222e-04:  74%|███████▎  | 12030/16329 [1:41:17<35:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12030: train loss 1.25492. lr 4.205222e-04:  74%|███████▎  | 12031/16329 [1:41:17<35:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12031: train loss 1.25075. lr 4.204957e-04:  74%|███████▎  | 12031/16329 [1:41:18<35:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12031: train loss 1.25075. lr 4.204957e-04:  74%|███████▎  | 12032/16329 [1:41:18<35:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12032: train loss 1.22751. lr 4.204693e-04:  74%|███████▎  | 12032/16329 [1:41:19<35:21,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12032: train loss 1.22751. lr 4.204693e-04:  74%|███████▎  | 12033/16329 [1:41:19<39:09,  1.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12033: train loss 1.22340. lr 4.204429e-04:  74%|███████▎  | 12033/16329 [1:41:19<39:09,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12033: train loss 1.22340. lr 4.204429e-04:  74%|███████▎  | 12034/16329 [1:41:19<38:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12034: train loss 1.22596. lr 4.204165e-04:  74%|███████▎  | 12034/16329 [1:41:20<38:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12034: train loss 1.22596. lr 4.204165e-04:  74%|███████▎  | 12035/16329 [1:41:20<37:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12035: train loss 1.32703. lr 4.203900e-04:  74%|███████▎  | 12035/16329 [1:41:20<37:21,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12035: train loss 1.32703. lr 4.203900e-04:  74%|███████▎  | 12036/16329 [1:41:20<36:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12036: train loss 1.26892. lr 4.203636e-04:  74%|███████▎  | 12036/16329 [1:41:21<36:44,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12036: train loss 1.26892. lr 4.203636e-04:  74%|███████▎  | 12037/16329 [1:41:21<36:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12037: train loss 1.26197. lr 4.203371e-04:  74%|███████▎  | 12037/16329 [1:41:21<36:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12037: train loss 1.26197. lr 4.203371e-04:  74%|███████▎  | 12038/16329 [1:41:21<36:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12038: train loss 1.24530. lr 4.203107e-04:  74%|███████▎  | 12038/16329 [1:41:22<36:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12038: train loss 1.24530. lr 4.203107e-04:  74%|███████▎  | 12039/16329 [1:41:22<35:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12039: train loss 1.27470. lr 4.202843e-04:  74%|███████▎  | 12039/16329 [1:41:22<35:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12039: train loss 1.27470. lr 4.202843e-04:  74%|███████▎  | 12040/16329 [1:41:22<35:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12040: train loss 1.25188. lr 4.202578e-04:  74%|███████▎  | 12040/16329 [1:41:23<35:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12040: train loss 1.25188. lr 4.202578e-04:  74%|███████▎  | 12041/16329 [1:41:23<35:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12041: train loss 1.27005. lr 4.202314e-04:  74%|███████▎  | 12041/16329 [1:41:23<35:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12041: train loss 1.27005. lr 4.202314e-04:  74%|███████▎  | 12042/16329 [1:41:23<35:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12042: train loss 1.27998. lr 4.202050e-04:  74%|███████▎  | 12042/16329 [1:41:24<35:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12042: train loss 1.27998. lr 4.202050e-04:  74%|███████▍  | 12043/16329 [1:41:24<35:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12043: train loss 1.23586. lr 4.201785e-04:  74%|███████▍  | 12043/16329 [1:41:24<35:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12043: train loss 1.23586. lr 4.201785e-04:  74%|███████▍  | 12044/16329 [1:41:24<35:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12044: train loss 1.27314. lr 4.201521e-04:  74%|███████▍  | 12044/16329 [1:41:25<35:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12044: train loss 1.27314. lr 4.201521e-04:  74%|███████▍  | 12045/16329 [1:41:25<35:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12045: train loss 1.25757. lr 4.201256e-04:  74%|███████▍  | 12045/16329 [1:41:25<35:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12045: train loss 1.25757. lr 4.201256e-04:  74%|███████▍  | 12046/16329 [1:41:25<35:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12046: train loss 1.24115. lr 4.200992e-04:  74%|███████▍  | 12046/16329 [1:41:25<35:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12046: train loss 1.24115. lr 4.200992e-04:  74%|███████▍  | 12047/16329 [1:41:25<35:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12047: train loss 1.21423. lr 4.200727e-04:  74%|███████▍  | 12047/16329 [1:41:26<35:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12047: train loss 1.21423. lr 4.200727e-04:  74%|███████▍  | 12048/16329 [1:41:26<35:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12048: train loss 1.24316. lr 4.200463e-04:  74%|███████▍  | 12048/16329 [1:41:26<35:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12048: train loss 1.24316. lr 4.200463e-04:  74%|███████▍  | 12049/16329 [1:41:26<35:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12049: train loss 1.21588. lr 4.200198e-04:  74%|███████▍  | 12049/16329 [1:41:27<35:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12049: train loss 1.21588. lr 4.200198e-04:  74%|███████▍  | 12050/16329 [1:41:27<35:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12050: train loss 1.25917. lr 4.199934e-04:  74%|███████▍  | 12050/16329 [1:41:27<35:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12050: train loss 1.25917. lr 4.199934e-04:  74%|███████▍  | 12051/16329 [1:41:27<35:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12051: train loss 1.23548. lr 4.199669e-04:  74%|███████▍  | 12051/16329 [1:41:28<35:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12051: train loss 1.23548. lr 4.199669e-04:  74%|███████▍  | 12052/16329 [1:41:28<35:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12052: train loss 1.23928. lr 4.199405e-04:  74%|███████▍  | 12052/16329 [1:41:28<35:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12052: train loss 1.23928. lr 4.199405e-04:  74%|███████▍  | 12053/16329 [1:41:28<35:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12053: train loss 1.26347. lr 4.199140e-04:  74%|███████▍  | 12053/16329 [1:41:29<35:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12053: train loss 1.26347. lr 4.199140e-04:  74%|███████▍  | 12054/16329 [1:41:29<35:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12054: train loss 1.24698. lr 4.198876e-04:  74%|███████▍  | 12054/16329 [1:41:29<35:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12054: train loss 1.24698. lr 4.198876e-04:  74%|███████▍  | 12055/16329 [1:41:29<35:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12055: train loss 1.25689. lr 4.198611e-04:  74%|███████▍  | 12055/16329 [1:41:30<35:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12055: train loss 1.25689. lr 4.198611e-04:  74%|███████▍  | 12056/16329 [1:41:30<35:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12056: train loss 1.26770. lr 4.198347e-04:  74%|███████▍  | 12056/16329 [1:41:30<35:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12056: train loss 1.26770. lr 4.198347e-04:  74%|███████▍  | 12057/16329 [1:41:30<35:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12057: train loss 1.25272. lr 4.198082e-04:  74%|███████▍  | 12057/16329 [1:41:31<35:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12057: train loss 1.25272. lr 4.198082e-04:  74%|███████▍  | 12058/16329 [1:41:31<35:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12058: train loss 1.26723. lr 4.197817e-04:  74%|███████▍  | 12058/16329 [1:41:31<35:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12058: train loss 1.26723. lr 4.197817e-04:  74%|███████▍  | 12059/16329 [1:41:31<35:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12059: train loss 1.25845. lr 4.197553e-04:  74%|███████▍  | 12059/16329 [1:41:32<35:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12059: train loss 1.25845. lr 4.197553e-04:  74%|███████▍  | 12060/16329 [1:41:32<39:10,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12060: train loss 1.28464. lr 4.197288e-04:  74%|███████▍  | 12060/16329 [1:41:33<39:10,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12060: train loss 1.28464. lr 4.197288e-04:  74%|███████▍  | 12061/16329 [1:41:33<37:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12061: train loss 1.24744. lr 4.197023e-04:  74%|███████▍  | 12061/16329 [1:41:33<37:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12061: train loss 1.24744. lr 4.197023e-04:  74%|███████▍  | 12062/16329 [1:41:33<37:10,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12062: train loss 1.27106. lr 4.196759e-04:  74%|███████▍  | 12062/16329 [1:41:34<37:10,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12062: train loss 1.27106. lr 4.196759e-04:  74%|███████▍  | 12063/16329 [1:41:34<36:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12063: train loss 1.23828. lr 4.196494e-04:  74%|███████▍  | 12063/16329 [1:41:34<36:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12063: train loss 1.23828. lr 4.196494e-04:  74%|███████▍  | 12064/16329 [1:41:34<36:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12064: train loss 1.27380. lr 4.196230e-04:  74%|███████▍  | 12064/16329 [1:41:35<36:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12064: train loss 1.27380. lr 4.196230e-04:  74%|███████▍  | 12065/16329 [1:41:35<35:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12065: train loss 1.25384. lr 4.195965e-04:  74%|███████▍  | 12065/16329 [1:41:35<35:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12065: train loss 1.25384. lr 4.195965e-04:  74%|███████▍  | 12066/16329 [1:41:35<35:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12066: train loss 1.26300. lr 4.195700e-04:  74%|███████▍  | 12066/16329 [1:41:36<35:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12066: train loss 1.26300. lr 4.195700e-04:  74%|███████▍  | 12067/16329 [1:41:36<35:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12067: train loss 1.26263. lr 4.195435e-04:  74%|███████▍  | 12067/16329 [1:41:36<35:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12067: train loss 1.26263. lr 4.195435e-04:  74%|███████▍  | 12068/16329 [1:41:36<35:25,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12068: train loss 1.23326. lr 4.195171e-04:  74%|███████▍  | 12068/16329 [1:41:37<35:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12068: train loss 1.23326. lr 4.195171e-04:  74%|███████▍  | 12069/16329 [1:41:37<35:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12069: train loss 1.22894. lr 4.194906e-04:  74%|███████▍  | 12069/16329 [1:41:37<35:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12069: train loss 1.22894. lr 4.194906e-04:  74%|███████▍  | 12070/16329 [1:41:37<35:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12070: train loss 1.25242. lr 4.194641e-04:  74%|███████▍  | 12070/16329 [1:41:38<35:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12070: train loss 1.25242. lr 4.194641e-04:  74%|███████▍  | 12071/16329 [1:41:38<35:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12071: train loss 1.24550. lr 4.194377e-04:  74%|███████▍  | 12071/16329 [1:41:38<35:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12071: train loss 1.24550. lr 4.194377e-04:  74%|███████▍  | 12072/16329 [1:41:38<35:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12072: train loss 1.25846. lr 4.194112e-04:  74%|███████▍  | 12072/16329 [1:41:39<35:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12072: train loss 1.25846. lr 4.194112e-04:  74%|███████▍  | 12073/16329 [1:41:39<35:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12073: train loss 1.26589. lr 4.193847e-04:  74%|███████▍  | 12073/16329 [1:41:39<35:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12073: train loss 1.26589. lr 4.193847e-04:  74%|███████▍  | 12074/16329 [1:41:39<35:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12074: train loss 1.25559. lr 4.193582e-04:  74%|███████▍  | 12074/16329 [1:41:40<35:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12074: train loss 1.25559. lr 4.193582e-04:  74%|███████▍  | 12075/16329 [1:41:40<35:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12075: train loss 1.18843. lr 4.193318e-04:  74%|███████▍  | 12075/16329 [1:41:40<35:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12075: train loss 1.18843. lr 4.193318e-04:  74%|███████▍  | 12076/16329 [1:41:40<35:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12076: train loss 1.24419. lr 4.193053e-04:  74%|███████▍  | 12076/16329 [1:41:41<35:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12076: train loss 1.24419. lr 4.193053e-04:  74%|███████▍  | 12077/16329 [1:41:41<35:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12077: train loss 1.24668. lr 4.192788e-04:  74%|███████▍  | 12077/16329 [1:41:41<35:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12077: train loss 1.24668. lr 4.192788e-04:  74%|███████▍  | 12078/16329 [1:41:41<35:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12078: train loss 1.26127. lr 4.192523e-04:  74%|███████▍  | 12078/16329 [1:41:42<35:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12078: train loss 1.26127. lr 4.192523e-04:  74%|███████▍  | 12079/16329 [1:41:42<35:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12079: train loss 1.26274. lr 4.192258e-04:  74%|███████▍  | 12079/16329 [1:41:42<35:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12079: train loss 1.26274. lr 4.192258e-04:  74%|███████▍  | 12080/16329 [1:41:42<35:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12080: train loss 1.27919. lr 4.191993e-04:  74%|███████▍  | 12080/16329 [1:41:43<35:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12080: train loss 1.27919. lr 4.191993e-04:  74%|███████▍  | 12081/16329 [1:41:43<35:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12081: train loss 1.26585. lr 4.191729e-04:  74%|███████▍  | 12081/16329 [1:41:43<35:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12081: train loss 1.26585. lr 4.191729e-04:  74%|███████▍  | 12082/16329 [1:41:43<35:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12082: train loss 1.25548. lr 4.191464e-04:  74%|███████▍  | 12082/16329 [1:41:44<35:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12082: train loss 1.25548. lr 4.191464e-04:  74%|███████▍  | 12083/16329 [1:41:44<34:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12083: train loss 1.20518. lr 4.191199e-04:  74%|███████▍  | 12083/16329 [1:41:44<34:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12083: train loss 1.20518. lr 4.191199e-04:  74%|███████▍  | 12084/16329 [1:41:44<35:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12084: train loss 1.28385. lr 4.190934e-04:  74%|███████▍  | 12084/16329 [1:41:45<35:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12084: train loss 1.28385. lr 4.190934e-04:  74%|███████▍  | 12085/16329 [1:41:45<35:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12085: train loss 1.25217. lr 4.190669e-04:  74%|███████▍  | 12085/16329 [1:41:45<35:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12085: train loss 1.25217. lr 4.190669e-04:  74%|███████▍  | 12086/16329 [1:41:45<35:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12086: train loss 1.25636. lr 4.190404e-04:  74%|███████▍  | 12086/16329 [1:41:45<35:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12086: train loss 1.25636. lr 4.190404e-04:  74%|███████▍  | 12087/16329 [1:41:46<35:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12087: train loss 1.24225. lr 4.190139e-04:  74%|███████▍  | 12087/16329 [1:41:46<35:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12087: train loss 1.24225. lr 4.190139e-04:  74%|███████▍  | 12088/16329 [1:41:46<35:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12088: train loss 1.25667. lr 4.189874e-04:  74%|███████▍  | 12088/16329 [1:41:46<35:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12088: train loss 1.25667. lr 4.189874e-04:  74%|███████▍  | 12089/16329 [1:41:46<35:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12089: train loss 1.23499. lr 4.189609e-04:  74%|███████▍  | 12089/16329 [1:41:47<35:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12089: train loss 1.23499. lr 4.189609e-04:  74%|███████▍  | 12090/16329 [1:41:47<34:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12090: train loss 1.25121. lr 4.189344e-04:  74%|███████▍  | 12090/16329 [1:41:48<34:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12090: train loss 1.25121. lr 4.189344e-04:  74%|███████▍  | 12091/16329 [1:41:48<35:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12091: train loss 1.24322. lr 4.189079e-04:  74%|███████▍  | 12091/16329 [1:41:48<35:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12091: train loss 1.24322. lr 4.189079e-04:  74%|███████▍  | 12092/16329 [1:41:48<36:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12092: train loss 1.23879. lr 4.188815e-04:  74%|███████▍  | 12092/16329 [1:41:49<36:17,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12092: train loss 1.23879. lr 4.188815e-04:  74%|███████▍  | 12093/16329 [1:41:49<36:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12093: train loss 1.24495. lr 4.188550e-04:  74%|███████▍  | 12093/16329 [1:41:49<36:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12093: train loss 1.24495. lr 4.188550e-04:  74%|███████▍  | 12094/16329 [1:41:49<36:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12094: train loss 1.23718. lr 4.188285e-04:  74%|███████▍  | 12094/16329 [1:41:50<36:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12094: train loss 1.23718. lr 4.188285e-04:  74%|███████▍  | 12095/16329 [1:41:50<35:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12095: train loss 1.22740. lr 4.188020e-04:  74%|███████▍  | 12095/16329 [1:41:50<35:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12095: train loss 1.22740. lr 4.188020e-04:  74%|███████▍  | 12096/16329 [1:41:50<35:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12096: train loss 1.25513. lr 4.187755e-04:  74%|███████▍  | 12096/16329 [1:41:51<35:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12096: train loss 1.25513. lr 4.187755e-04:  74%|███████▍  | 12097/16329 [1:41:51<35:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12097: train loss 1.23669. lr 4.187489e-04:  74%|███████▍  | 12097/16329 [1:41:51<35:35,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12097: train loss 1.23669. lr 4.187489e-04:  74%|███████▍  | 12098/16329 [1:41:51<35:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12098: train loss 1.23009. lr 4.187224e-04:  74%|███████▍  | 12098/16329 [1:41:52<35:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12098: train loss 1.23009. lr 4.187224e-04:  74%|███████▍  | 12099/16329 [1:41:52<35:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12099: train loss 1.25461. lr 4.186959e-04:  74%|███████▍  | 12099/16329 [1:41:52<35:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12099: train loss 1.25461. lr 4.186959e-04:  74%|███████▍  | 12100/16329 [1:41:52<38:57,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 12100: train loss 1.25521. lr 4.186694e-04:  74%|███████▍  | 12100/16329 [1:41:53<38:57,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 12100: train loss 1.25521. lr 4.186694e-04:  74%|███████▍  | 12101/16329 [1:41:53<37:48,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12101: train loss 1.22706. lr 4.186429e-04:  74%|███████▍  | 12101/16329 [1:41:53<37:48,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12101: train loss 1.22706. lr 4.186429e-04:  74%|███████▍  | 12102/16329 [1:41:53<36:54,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12102: train loss 1.23767. lr 4.186164e-04:  74%|███████▍  | 12102/16329 [1:41:54<36:54,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12102: train loss 1.23767. lr 4.186164e-04:  74%|███████▍  | 12103/16329 [1:41:54<36:11,  1.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12103: train loss 1.26663. lr 4.185899e-04:  74%|███████▍  | 12103/16329 [1:41:54<36:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12103: train loss 1.26663. lr 4.185899e-04:  74%|███████▍  | 12104/16329 [1:41:54<35:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12104: train loss 1.24176. lr 4.185634e-04:  74%|███████▍  | 12104/16329 [1:41:55<35:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12104: train loss 1.24176. lr 4.185634e-04:  74%|███████▍  | 12105/16329 [1:41:55<35:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12105: train loss 1.24421. lr 4.185369e-04:  74%|███████▍  | 12105/16329 [1:41:55<35:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12105: train loss 1.24421. lr 4.185369e-04:  74%|███████▍  | 12106/16329 [1:41:55<35:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12106: train loss 1.28734. lr 4.185104e-04:  74%|███████▍  | 12106/16329 [1:41:56<35:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12106: train loss 1.28734. lr 4.185104e-04:  74%|███████▍  | 12107/16329 [1:41:56<35:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12107: train loss 1.28809. lr 4.184839e-04:  74%|███████▍  | 12107/16329 [1:41:56<35:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12107: train loss 1.28809. lr 4.184839e-04:  74%|███████▍  | 12108/16329 [1:41:56<35:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12108: train loss 1.26098. lr 4.184573e-04:  74%|███████▍  | 12108/16329 [1:41:57<35:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12108: train loss 1.26098. lr 4.184573e-04:  74%|███████▍  | 12109/16329 [1:41:57<35:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12109: train loss 1.23628. lr 4.184308e-04:  74%|███████▍  | 12109/16329 [1:41:57<35:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12109: train loss 1.23628. lr 4.184308e-04:  74%|███████▍  | 12110/16329 [1:41:57<34:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12110: train loss 1.27929. lr 4.184043e-04:  74%|███████▍  | 12110/16329 [1:41:58<34:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12110: train loss 1.27929. lr 4.184043e-04:  74%|███████▍  | 12111/16329 [1:41:58<34:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12111: train loss 1.24545. lr 4.183778e-04:  74%|███████▍  | 12111/16329 [1:41:58<34:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12111: train loss 1.24545. lr 4.183778e-04:  74%|███████▍  | 12112/16329 [1:41:58<34:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12112: train loss 1.24297. lr 4.183513e-04:  74%|███████▍  | 12112/16329 [1:41:59<34:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12112: train loss 1.24297. lr 4.183513e-04:  74%|███████▍  | 12113/16329 [1:41:59<34:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12113: train loss 1.24184. lr 4.183248e-04:  74%|███████▍  | 12113/16329 [1:41:59<34:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12113: train loss 1.24184. lr 4.183248e-04:  74%|███████▍  | 12114/16329 [1:41:59<34:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12114: train loss 1.26330. lr 4.182982e-04:  74%|███████▍  | 12114/16329 [1:42:00<34:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12114: train loss 1.26330. lr 4.182982e-04:  74%|███████▍  | 12115/16329 [1:42:00<34:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12115: train loss 1.27931. lr 4.182717e-04:  74%|███████▍  | 12115/16329 [1:42:00<34:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12115: train loss 1.27931. lr 4.182717e-04:  74%|███████▍  | 12116/16329 [1:42:00<34:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12116: train loss 1.28809. lr 4.182452e-04:  74%|███████▍  | 12116/16329 [1:42:01<34:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12116: train loss 1.28809. lr 4.182452e-04:  74%|███████▍  | 12117/16329 [1:42:01<34:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12117: train loss 1.21535. lr 4.182187e-04:  74%|███████▍  | 12117/16329 [1:42:01<34:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12117: train loss 1.21535. lr 4.182187e-04:  74%|███████▍  | 12118/16329 [1:42:01<34:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12118: train loss 1.26143. lr 4.181921e-04:  74%|███████▍  | 12118/16329 [1:42:02<34:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12118: train loss 1.26143. lr 4.181921e-04:  74%|███████▍  | 12119/16329 [1:42:02<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12119: train loss 1.26930. lr 4.181656e-04:  74%|███████▍  | 12119/16329 [1:42:02<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12119: train loss 1.26930. lr 4.181656e-04:  74%|███████▍  | 12120/16329 [1:42:02<34:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12120: train loss 1.24084. lr 4.181391e-04:  74%|███████▍  | 12120/16329 [1:42:03<34:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12120: train loss 1.24084. lr 4.181391e-04:  74%|███████▍  | 12121/16329 [1:42:03<34:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12121: train loss 1.23927. lr 4.181126e-04:  74%|███████▍  | 12121/16329 [1:42:03<34:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12121: train loss 1.23927. lr 4.181126e-04:  74%|███████▍  | 12122/16329 [1:42:03<34:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12122: train loss 1.20049. lr 4.180860e-04:  74%|███████▍  | 12122/16329 [1:42:04<34:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12122: train loss 1.20049. lr 4.180860e-04:  74%|███████▍  | 12123/16329 [1:42:04<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12123: train loss 1.24285. lr 4.180595e-04:  74%|███████▍  | 12123/16329 [1:42:04<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12123: train loss 1.24285. lr 4.180595e-04:  74%|███████▍  | 12124/16329 [1:42:04<34:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12124: train loss 1.24885. lr 4.180330e-04:  74%|███████▍  | 12124/16329 [1:42:05<34:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12124: train loss 1.24885. lr 4.180330e-04:  74%|███████▍  | 12125/16329 [1:42:05<34:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12125: train loss 1.27788. lr 4.180064e-04:  74%|███████▍  | 12125/16329 [1:42:05<34:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12125: train loss 1.27788. lr 4.180064e-04:  74%|███████▍  | 12126/16329 [1:42:05<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12126: train loss 1.25297. lr 4.179799e-04:  74%|███████▍  | 12126/16329 [1:42:06<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12126: train loss 1.25297. lr 4.179799e-04:  74%|███████▍  | 12127/16329 [1:42:06<34:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12127: train loss 1.22458. lr 4.179534e-04:  74%|███████▍  | 12127/16329 [1:42:06<34:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12127: train loss 1.22458. lr 4.179534e-04:  74%|███████▍  | 12128/16329 [1:42:06<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12128: train loss 1.22718. lr 4.179268e-04:  74%|███████▍  | 12128/16329 [1:42:07<34:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12128: train loss 1.22718. lr 4.179268e-04:  74%|███████▍  | 12129/16329 [1:42:07<34:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12129: train loss 1.25304. lr 4.179003e-04:  74%|███████▍  | 12129/16329 [1:42:07<34:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12129: train loss 1.25304. lr 4.179003e-04:  74%|███████▍  | 12130/16329 [1:42:07<34:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12130: train loss 1.26091. lr 4.178737e-04:  74%|███████▍  | 12130/16329 [1:42:08<34:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12130: train loss 1.26091. lr 4.178737e-04:  74%|███████▍  | 12131/16329 [1:42:08<34:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12131: train loss 1.23882. lr 4.178472e-04:  74%|███████▍  | 12131/16329 [1:42:08<34:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12131: train loss 1.23882. lr 4.178472e-04:  74%|███████▍  | 12132/16329 [1:42:08<34:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12132: train loss 1.20155. lr 4.178207e-04:  74%|███████▍  | 12132/16329 [1:42:09<34:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12132: train loss 1.20155. lr 4.178207e-04:  74%|███████▍  | 12133/16329 [1:42:09<34:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12133: train loss 1.24168. lr 4.177941e-04:  74%|███████▍  | 12133/16329 [1:42:09<34:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12133: train loss 1.24168. lr 4.177941e-04:  74%|███████▍  | 12134/16329 [1:42:09<34:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12134: train loss 1.25493. lr 4.177676e-04:  74%|███████▍  | 12134/16329 [1:42:10<34:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12134: train loss 1.25493. lr 4.177676e-04:  74%|███████▍  | 12135/16329 [1:42:10<38:29,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12135: train loss 1.25224. lr 4.177410e-04:  74%|███████▍  | 12135/16329 [1:42:10<38:29,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12135: train loss 1.25224. lr 4.177410e-04:  74%|███████▍  | 12136/16329 [1:42:10<37:38,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12136: train loss 1.24629. lr 4.177145e-04:  74%|███████▍  | 12136/16329 [1:42:11<37:38,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12136: train loss 1.24629. lr 4.177145e-04:  74%|███████▍  | 12137/16329 [1:42:11<37:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12137: train loss 1.24591. lr 4.176879e-04:  74%|███████▍  | 12137/16329 [1:42:11<37:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12137: train loss 1.24591. lr 4.176879e-04:  74%|███████▍  | 12138/16329 [1:42:11<36:14,  1.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12138: train loss 1.24178. lr 4.176614e-04:  74%|███████▍  | 12138/16329 [1:42:12<36:14,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12138: train loss 1.24178. lr 4.176614e-04:  74%|███████▍  | 12139/16329 [1:42:12<35:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12139: train loss 1.25246. lr 4.176349e-04:  74%|███████▍  | 12139/16329 [1:42:12<35:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12139: train loss 1.25246. lr 4.176349e-04:  74%|███████▍  | 12140/16329 [1:42:12<35:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12140: train loss 1.26570. lr 4.176083e-04:  74%|███████▍  | 12140/16329 [1:42:13<35:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12140: train loss 1.26570. lr 4.176083e-04:  74%|███████▍  | 12141/16329 [1:42:13<35:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12141: train loss 1.24222. lr 4.175818e-04:  74%|███████▍  | 12141/16329 [1:42:13<35:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12141: train loss 1.24222. lr 4.175818e-04:  74%|███████▍  | 12142/16329 [1:42:13<36:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12142: train loss 1.26258. lr 4.175552e-04:  74%|███████▍  | 12142/16329 [1:42:14<36:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12142: train loss 1.26258. lr 4.175552e-04:  74%|███████▍  | 12143/16329 [1:42:14<36:52,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12143: train loss 1.27564. lr 4.175286e-04:  74%|███████▍  | 12143/16329 [1:42:14<36:52,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12143: train loss 1.27564. lr 4.175286e-04:  74%|███████▍  | 12144/16329 [1:42:14<37:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12144: train loss 1.28656. lr 4.175021e-04:  74%|███████▍  | 12144/16329 [1:42:15<37:04,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12144: train loss 1.28656. lr 4.175021e-04:  74%|███████▍  | 12145/16329 [1:42:15<36:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12145: train loss 1.23188. lr 4.174755e-04:  74%|███████▍  | 12145/16329 [1:42:15<36:53,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12145: train loss 1.23188. lr 4.174755e-04:  74%|███████▍  | 12146/16329 [1:42:15<36:32,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12146: train loss 1.24635. lr 4.174490e-04:  74%|███████▍  | 12146/16329 [1:42:16<36:32,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12146: train loss 1.24635. lr 4.174490e-04:  74%|███████▍  | 12147/16329 [1:42:16<36:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12147: train loss 1.27826. lr 4.174224e-04:  74%|███████▍  | 12147/16329 [1:42:16<36:17,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12147: train loss 1.27826. lr 4.174224e-04:  74%|███████▍  | 12148/16329 [1:42:16<35:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12148: train loss 1.25546. lr 4.173959e-04:  74%|███████▍  | 12148/16329 [1:42:17<35:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12148: train loss 1.25546. lr 4.173959e-04:  74%|███████▍  | 12149/16329 [1:42:17<35:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12149: train loss 1.26645. lr 4.173693e-04:  74%|███████▍  | 12149/16329 [1:42:17<35:43,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12149: train loss 1.26645. lr 4.173693e-04:  74%|███████▍  | 12150/16329 [1:42:17<35:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12150: train loss 1.22476. lr 4.173427e-04:  74%|███████▍  | 12150/16329 [1:42:18<35:24,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12150: train loss 1.22476. lr 4.173427e-04:  74%|███████▍  | 12151/16329 [1:42:18<35:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12151: train loss 1.21479. lr 4.173162e-04:  74%|███████▍  | 12151/16329 [1:42:18<35:12,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12151: train loss 1.21479. lr 4.173162e-04:  74%|███████▍  | 12152/16329 [1:42:18<35:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12152: train loss 1.27290. lr 4.172896e-04:  74%|███████▍  | 12152/16329 [1:42:19<35:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12152: train loss 1.27290. lr 4.172896e-04:  74%|███████▍  | 12153/16329 [1:42:19<34:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12153: train loss 1.23951. lr 4.172631e-04:  74%|███████▍  | 12153/16329 [1:42:19<34:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12153: train loss 1.23951. lr 4.172631e-04:  74%|███████▍  | 12154/16329 [1:42:19<34:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12154: train loss 1.23055. lr 4.172365e-04:  74%|███████▍  | 12154/16329 [1:42:20<34:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12154: train loss 1.23055. lr 4.172365e-04:  74%|███████▍  | 12155/16329 [1:42:20<34:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12155: train loss 1.28905. lr 4.172099e-04:  74%|███████▍  | 12155/16329 [1:42:20<34:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12155: train loss 1.28905. lr 4.172099e-04:  74%|███████▍  | 12156/16329 [1:42:20<34:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12156: train loss 1.23584. lr 4.171834e-04:  74%|███████▍  | 12156/16329 [1:42:21<34:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12156: train loss 1.23584. lr 4.171834e-04:  74%|███████▍  | 12157/16329 [1:42:21<34:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12157: train loss 1.26055. lr 4.171568e-04:  74%|███████▍  | 12157/16329 [1:42:21<34:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12157: train loss 1.26055. lr 4.171568e-04:  74%|███████▍  | 12158/16329 [1:42:21<34:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12158: train loss 1.22560. lr 4.171302e-04:  74%|███████▍  | 12158/16329 [1:42:22<34:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12158: train loss 1.22560. lr 4.171302e-04:  74%|███████▍  | 12159/16329 [1:42:22<34:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12159: train loss 1.23845. lr 4.171037e-04:  74%|███████▍  | 12159/16329 [1:42:23<34:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12159: train loss 1.23845. lr 4.171037e-04:  74%|███████▍  | 12160/16329 [1:42:23<38:34,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12160: train loss 1.20848. lr 4.170771e-04:  74%|███████▍  | 12160/16329 [1:42:23<38:34,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12160: train loss 1.20848. lr 4.170771e-04:  74%|███████▍  | 12161/16329 [1:42:23<37:19,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12161: train loss 1.24053. lr 4.170505e-04:  74%|███████▍  | 12161/16329 [1:42:24<37:19,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12161: train loss 1.24053. lr 4.170505e-04:  74%|███████▍  | 12162/16329 [1:42:24<36:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12162: train loss 1.23095. lr 4.170239e-04:  74%|███████▍  | 12162/16329 [1:42:24<36:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12162: train loss 1.23095. lr 4.170239e-04:  74%|███████▍  | 12163/16329 [1:42:24<35:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12163: train loss 1.23274. lr 4.169974e-04:  74%|███████▍  | 12163/16329 [1:42:25<35:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12163: train loss 1.23274. lr 4.169974e-04:  74%|███████▍  | 12164/16329 [1:42:25<35:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12164: train loss 1.25665. lr 4.169708e-04:  74%|███████▍  | 12164/16329 [1:42:25<35:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12164: train loss 1.25665. lr 4.169708e-04:  74%|███████▍  | 12165/16329 [1:42:25<35:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12165: train loss 1.26103. lr 4.169442e-04:  74%|███████▍  | 12165/16329 [1:42:26<35:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12165: train loss 1.26103. lr 4.169442e-04:  75%|███████▍  | 12166/16329 [1:42:26<34:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12166: train loss 1.22888. lr 4.169176e-04:  75%|███████▍  | 12166/16329 [1:42:26<34:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12166: train loss 1.22888. lr 4.169176e-04:  75%|███████▍  | 12167/16329 [1:42:26<34:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12167: train loss 1.22679. lr 4.168911e-04:  75%|███████▍  | 12167/16329 [1:42:27<34:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12167: train loss 1.22679. lr 4.168911e-04:  75%|███████▍  | 12168/16329 [1:42:27<35:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12168: train loss 1.25388. lr 4.168645e-04:  75%|███████▍  | 12168/16329 [1:42:27<35:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12168: train loss 1.25388. lr 4.168645e-04:  75%|███████▍  | 12169/16329 [1:42:27<35:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12169: train loss 1.24149. lr 4.168379e-04:  75%|███████▍  | 12169/16329 [1:42:28<35:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12169: train loss 1.24149. lr 4.168379e-04:  75%|███████▍  | 12170/16329 [1:42:28<35:28,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12170: train loss 1.26046. lr 4.168113e-04:  75%|███████▍  | 12170/16329 [1:42:28<35:28,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12170: train loss 1.26046. lr 4.168113e-04:  75%|███████▍  | 12171/16329 [1:42:28<35:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12171: train loss 1.24311. lr 4.167847e-04:  75%|███████▍  | 12171/16329 [1:42:29<35:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12171: train loss 1.24311. lr 4.167847e-04:  75%|███████▍  | 12172/16329 [1:42:29<35:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12172: train loss 1.23355. lr 4.167581e-04:  75%|███████▍  | 12172/16329 [1:42:29<35:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12172: train loss 1.23355. lr 4.167581e-04:  75%|███████▍  | 12173/16329 [1:42:29<35:01,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12173: train loss 1.25215. lr 4.167316e-04:  75%|███████▍  | 12173/16329 [1:42:30<35:01,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12173: train loss 1.25215. lr 4.167316e-04:  75%|███████▍  | 12174/16329 [1:42:30<34:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12174: train loss 1.27434. lr 4.167050e-04:  75%|███████▍  | 12174/16329 [1:42:30<34:49,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12174: train loss 1.27434. lr 4.167050e-04:  75%|███████▍  | 12175/16329 [1:42:30<34:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12175: train loss 1.24487. lr 4.166784e-04:  75%|███████▍  | 12175/16329 [1:42:31<34:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12175: train loss 1.24487. lr 4.166784e-04:  75%|███████▍  | 12176/16329 [1:42:31<34:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12176: train loss 1.26099. lr 4.166518e-04:  75%|███████▍  | 12176/16329 [1:42:31<34:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12176: train loss 1.26099. lr 4.166518e-04:  75%|███████▍  | 12177/16329 [1:42:31<34:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12177: train loss 1.26334. lr 4.166252e-04:  75%|███████▍  | 12177/16329 [1:42:32<34:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12177: train loss 1.26334. lr 4.166252e-04:  75%|███████▍  | 12178/16329 [1:42:32<34:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12178: train loss 1.25848. lr 4.165986e-04:  75%|███████▍  | 12178/16329 [1:42:32<34:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12178: train loss 1.25848. lr 4.165986e-04:  75%|███████▍  | 12179/16329 [1:42:32<34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12179: train loss 1.25264. lr 4.165720e-04:  75%|███████▍  | 12179/16329 [1:42:33<34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12179: train loss 1.25264. lr 4.165720e-04:  75%|███████▍  | 12180/16329 [1:42:33<34:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12180: train loss 1.24203. lr 4.165454e-04:  75%|███████▍  | 12180/16329 [1:42:33<34:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12180: train loss 1.24203. lr 4.165454e-04:  75%|███████▍  | 12181/16329 [1:42:33<34:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12181: train loss 1.24877. lr 4.165188e-04:  75%|███████▍  | 12181/16329 [1:42:34<34:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12181: train loss 1.24877. lr 4.165188e-04:  75%|███████▍  | 12182/16329 [1:42:34<34:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12182: train loss 1.26450. lr 4.164922e-04:  75%|███████▍  | 12182/16329 [1:42:34<34:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12182: train loss 1.26450. lr 4.164922e-04:  75%|███████▍  | 12183/16329 [1:42:34<34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12183: train loss 1.26134. lr 4.164656e-04:  75%|███████▍  | 12183/16329 [1:42:35<34:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12183: train loss 1.26134. lr 4.164656e-04:  75%|███████▍  | 12184/16329 [1:42:35<34:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12184: train loss 1.26232. lr 4.164390e-04:  75%|███████▍  | 12184/16329 [1:42:35<34:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12184: train loss 1.26232. lr 4.164390e-04:  75%|███████▍  | 12185/16329 [1:42:35<34:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12185: train loss 1.24976. lr 4.164124e-04:  75%|███████▍  | 12185/16329 [1:42:36<34:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12185: train loss 1.24976. lr 4.164124e-04:  75%|███████▍  | 12186/16329 [1:42:36<34:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12186: train loss 1.24570. lr 4.163858e-04:  75%|███████▍  | 12186/16329 [1:42:36<34:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12186: train loss 1.24570. lr 4.163858e-04:  75%|███████▍  | 12187/16329 [1:42:36<38:39,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 12187: train loss 1.23915. lr 4.163592e-04:  75%|███████▍  | 12187/16329 [1:42:37<38:39,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 12187: train loss 1.23915. lr 4.163592e-04:  75%|███████▍  | 12188/16329 [1:42:37<37:19,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 12188: train loss 1.23519. lr 4.163326e-04:  75%|███████▍  | 12188/16329 [1:42:37<37:19,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 12188: train loss 1.23519. lr 4.163326e-04:  75%|███████▍  | 12189/16329 [1:42:37<36:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12189: train loss 1.24364. lr 4.163060e-04:  75%|███████▍  | 12189/16329 [1:42:38<36:20,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12189: train loss 1.24364. lr 4.163060e-04:  75%|███████▍  | 12190/16329 [1:42:38<35:45,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12190: train loss 1.24228. lr 4.162794e-04:  75%|███████▍  | 12190/16329 [1:42:38<35:45,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12190: train loss 1.24228. lr 4.162794e-04:  75%|███████▍  | 12191/16329 [1:42:38<35:13,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12191: train loss 1.24562. lr 4.162528e-04:  75%|███████▍  | 12191/16329 [1:42:39<35:13,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12191: train loss 1.24562. lr 4.162528e-04:  75%|███████▍  | 12192/16329 [1:42:39<34:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12192: train loss 1.26981. lr 4.162262e-04:  75%|███████▍  | 12192/16329 [1:42:39<34:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12192: train loss 1.26981. lr 4.162262e-04:  75%|███████▍  | 12193/16329 [1:42:39<34:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12193: train loss 1.27025. lr 4.161996e-04:  75%|███████▍  | 12193/16329 [1:42:40<34:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12193: train loss 1.27025. lr 4.161996e-04:  75%|███████▍  | 12194/16329 [1:42:40<34:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12194: train loss 1.22193. lr 4.161730e-04:  75%|███████▍  | 12194/16329 [1:42:40<34:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12194: train loss 1.22193. lr 4.161730e-04:  75%|███████▍  | 12195/16329 [1:42:40<34:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12195: train loss 1.22319. lr 4.161464e-04:  75%|███████▍  | 12195/16329 [1:42:41<34:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12195: train loss 1.22319. lr 4.161464e-04:  75%|███████▍  | 12196/16329 [1:42:41<34:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12196: train loss 1.22886. lr 4.161198e-04:  75%|███████▍  | 12196/16329 [1:42:41<34:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12196: train loss 1.22886. lr 4.161198e-04:  75%|███████▍  | 12197/16329 [1:42:41<34:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12197: train loss 1.25832. lr 4.160932e-04:  75%|███████▍  | 12197/16329 [1:42:42<34:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12197: train loss 1.25832. lr 4.160932e-04:  75%|███████▍  | 12198/16329 [1:42:42<34:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12198: train loss 1.26347. lr 4.160666e-04:  75%|███████▍  | 12198/16329 [1:42:42<34:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12198: train loss 1.26347. lr 4.160666e-04:  75%|███████▍  | 12199/16329 [1:42:42<34:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12199: train loss 1.23519. lr 4.160400e-04:  75%|███████▍  | 12199/16329 [1:42:43<34:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12199: train loss 1.23519. lr 4.160400e-04:  75%|███████▍  | 12200/16329 [1:42:43<34:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12200: train loss 1.22199. lr 4.160133e-04:  75%|███████▍  | 12200/16329 [1:42:43<34:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12200: train loss 1.22199. lr 4.160133e-04:  75%|███████▍  | 12201/16329 [1:42:43<34:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12201: train loss 1.25673. lr 4.159867e-04:  75%|███████▍  | 12201/16329 [1:42:44<34:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12201: train loss 1.25673. lr 4.159867e-04:  75%|███████▍  | 12202/16329 [1:42:44<34:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12202: train loss 1.25626. lr 4.159601e-04:  75%|███████▍  | 12202/16329 [1:42:44<34:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12202: train loss 1.25626. lr 4.159601e-04:  75%|███████▍  | 12203/16329 [1:42:44<34:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12203: train loss 1.26057. lr 4.159335e-04:  75%|███████▍  | 12203/16329 [1:42:45<34:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12203: train loss 1.26057. lr 4.159335e-04:  75%|███████▍  | 12204/16329 [1:42:45<34:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12204: train loss 1.25897. lr 4.159069e-04:  75%|███████▍  | 12204/16329 [1:42:45<34:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12204: train loss 1.25897. lr 4.159069e-04:  75%|███████▍  | 12205/16329 [1:42:45<34:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12205: train loss 1.22441. lr 4.158803e-04:  75%|███████▍  | 12205/16329 [1:42:46<34:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12205: train loss 1.22441. lr 4.158803e-04:  75%|███████▍  | 12206/16329 [1:42:46<34:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12206: train loss 1.25114. lr 4.158536e-04:  75%|███████▍  | 12206/16329 [1:42:46<34:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12206: train loss 1.25114. lr 4.158536e-04:  75%|███████▍  | 12207/16329 [1:42:46<34:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12207: train loss 1.22522. lr 4.158270e-04:  75%|███████▍  | 12207/16329 [1:42:47<34:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12207: train loss 1.22522. lr 4.158270e-04:  75%|███████▍  | 12208/16329 [1:42:47<33:59,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12208: train loss 1.24434. lr 4.158004e-04:  75%|███████▍  | 12208/16329 [1:42:47<33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12208: train loss 1.24434. lr 4.158004e-04:  75%|███████▍  | 12209/16329 [1:42:47<34:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12209: train loss 1.25890. lr 4.157738e-04:  75%|███████▍  | 12209/16329 [1:42:48<34:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12209: train loss 1.25890. lr 4.157738e-04:  75%|███████▍  | 12210/16329 [1:42:48<33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12210: train loss 1.23827. lr 4.157471e-04:  75%|███████▍  | 12210/16329 [1:42:48<33:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12210: train loss 1.23827. lr 4.157471e-04:  75%|███████▍  | 12211/16329 [1:42:48<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12211: train loss 1.26046. lr 4.157205e-04:  75%|███████▍  | 12211/16329 [1:42:49<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12211: train loss 1.26046. lr 4.157205e-04:  75%|███████▍  | 12212/16329 [1:42:49<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12212: train loss 1.21570. lr 4.156939e-04:  75%|███████▍  | 12212/16329 [1:42:49<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12212: train loss 1.21570. lr 4.156939e-04:  75%|███████▍  | 12213/16329 [1:42:49<33:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12213: train loss 1.23223. lr 4.156673e-04:  75%|███████▍  | 12213/16329 [1:42:50<33:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12213: train loss 1.23223. lr 4.156673e-04:  75%|███████▍  | 12214/16329 [1:42:50<34:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12214: train loss 1.20824. lr 4.156406e-04:  75%|███████▍  | 12214/16329 [1:42:50<34:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12214: train loss 1.20824. lr 4.156406e-04:  75%|███████▍  | 12215/16329 [1:42:50<33:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12215: train loss 1.24989. lr 4.156140e-04:  75%|███████▍  | 12215/16329 [1:42:51<33:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12215: train loss 1.24989. lr 4.156140e-04:  75%|███████▍  | 12216/16329 [1:42:51<34:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12216: train loss 1.26631. lr 4.155874e-04:  75%|███████▍  | 12216/16329 [1:42:51<34:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12216: train loss 1.26631. lr 4.155874e-04:  75%|███████▍  | 12217/16329 [1:42:51<34:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12217: train loss 1.26083. lr 4.155607e-04:  75%|███████▍  | 12217/16329 [1:42:52<34:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12217: train loss 1.26083. lr 4.155607e-04:  75%|███████▍  | 12218/16329 [1:42:52<34:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12218: train loss 1.25639. lr 4.155341e-04:  75%|███████▍  | 12218/16329 [1:42:52<34:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12218: train loss 1.25639. lr 4.155341e-04:  75%|███████▍  | 12219/16329 [1:42:52<34:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12219: train loss 1.27068. lr 4.155075e-04:  75%|███████▍  | 12219/16329 [1:42:53<34:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12219: train loss 1.27068. lr 4.155075e-04:  75%|███████▍  | 12220/16329 [1:42:53<33:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12220: train loss 1.26953. lr 4.154808e-04:  75%|███████▍  | 12220/16329 [1:42:53<33:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12220: train loss 1.26953. lr 4.154808e-04:  75%|███████▍  | 12221/16329 [1:42:53<33:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12221: train loss 1.25199. lr 4.154542e-04:  75%|███████▍  | 12221/16329 [1:42:54<33:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12221: train loss 1.25199. lr 4.154542e-04:  75%|███████▍  | 12222/16329 [1:42:54<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12222: train loss 1.20202. lr 4.154276e-04:  75%|███████▍  | 12222/16329 [1:42:54<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12222: train loss 1.20202. lr 4.154276e-04:  75%|███████▍  | 12223/16329 [1:42:54<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12223: train loss 1.28195. lr 4.154009e-04:  75%|███████▍  | 12223/16329 [1:42:55<33:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12223: train loss 1.28195. lr 4.154009e-04:  75%|███████▍  | 12224/16329 [1:42:55<33:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12224: train loss 1.25020. lr 4.153743e-04:  75%|███████▍  | 12224/16329 [1:42:55<33:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12224: train loss 1.25020. lr 4.153743e-04:  75%|███████▍  | 12225/16329 [1:42:55<33:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12225: train loss 1.25934. lr 4.153476e-04:  75%|███████▍  | 12225/16329 [1:42:56<33:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12225: train loss 1.25934. lr 4.153476e-04:  75%|███████▍  | 12226/16329 [1:42:56<33:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12226: train loss 1.24252. lr 4.153210e-04:  75%|███████▍  | 12226/16329 [1:42:56<33:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12226: train loss 1.24252. lr 4.153210e-04:  75%|███████▍  | 12227/16329 [1:42:56<37:32,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12227: train loss 1.23266. lr 4.152943e-04:  75%|███████▍  | 12227/16329 [1:42:57<37:32,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12227: train loss 1.23266. lr 4.152943e-04:  75%|███████▍  | 12228/16329 [1:42:57<36:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12228: train loss 1.25432. lr 4.152677e-04:  75%|███████▍  | 12228/16329 [1:42:57<36:26,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12228: train loss 1.25432. lr 4.152677e-04:  75%|███████▍  | 12229/16329 [1:42:57<35:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12229: train loss 1.23410. lr 4.152411e-04:  75%|███████▍  | 12229/16329 [1:42:58<35:43,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12229: train loss 1.23410. lr 4.152411e-04:  75%|███████▍  | 12230/16329 [1:42:58<35:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12230: train loss 1.25499. lr 4.152144e-04:  75%|███████▍  | 12230/16329 [1:42:58<35:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12230: train loss 1.25499. lr 4.152144e-04:  75%|███████▍  | 12231/16329 [1:42:58<35:57,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12240: train loss 1.24665. lr 4.149479e-04:  75%|███████▍  | 12240/16329 [1:43:04<34:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12240: train loss 1.24665. lr 4.149479e-04:  75%|███████▍  | 12241/16329 [1:43:04<34:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12241: train loss 1.23506. lr 4.149212e-04:  75%|███████▍  | 12241/16329 [1:43:04<34:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12241: train loss 1.23506. lr 4.149212e-04:  75%|███████▍  | 12242/16329 [1:43:04<34:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12242: train loss 1.20419. lr 4.148946e-04:  75%|███████▍  | 12242/16329 [1:43:05<34:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12242: train loss 1.20419. lr 4.148946e-04:  75%|███████▍  | 12243/16329 [1:43:05<33:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12243: train loss 1.26561. lr 4.148679e-04:  75%|███████▍  | 12243/16329 [1:43:05<33:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12243: train loss 1.26561. lr 4.148679e-04:  75%|███████▍  | 12244/16329 [1:43:05<33:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12244: train loss 1.26838. lr 4.148412e-04:  75%|███████▍  | 12244/16329 [1:43:06<33:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12244: train loss 1.26838. lr 4.148412e-04:  75%|███████▍  | 12245/16329 [1:43:06<34:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12245: train loss 1.22906. lr 4.148146e-04:  75%|███████▍  | 12245/16329 [1:43:06<34:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12245: train loss 1.22906. lr 4.148146e-04:  75%|███████▍  | 12246/16329 [1:43:06<35:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12246: train loss 1.22687. lr 4.147879e-04:  75%|███████▍  | 12246/16329 [1:43:07<35:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12246: train loss 1.22687. lr 4.147879e-04:  75%|███████▌  | 12247/16329 [1:43:07<35:38,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12247: train loss 1.24177. lr 4.147613e-04:  75%|███████▌  | 12247/16329 [1:43:07<35:38,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12247: train loss 1.24177. lr 4.147613e-04:  75%|███████▌  | 12248/16329 [1:43:07<35:29,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12248: train loss 1.24572. lr 4.147346e-04:  75%|███████▌  | 12248/16329 [1:43:08<35:29,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12248: train loss 1.24572. lr 4.147346e-04:  75%|███████▌  | 12249/16329 [1:43:08<35:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12249: train loss 1.22508. lr 4.147079e-04:  75%|███████▌  | 12249/16329 [1:43:08<35:18,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12249: train loss 1.22508. lr 4.147079e-04:  75%|███████▌  | 12250/16329 [1:43:08<35:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12250: train loss 1.21852. lr 4.146813e-04:  75%|███████▌  | 12250/16329 [1:43:09<35:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12250: train loss 1.21852. lr 4.146813e-04:  75%|███████▌  | 12251/16329 [1:43:09<34:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12251: train loss 1.25379. lr 4.146546e-04:  75%|███████▌  | 12251/16329 [1:43:09<34:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12251: train loss 1.25379. lr 4.146546e-04:  75%|███████▌  | 12252/16329 [1:43:09<34:29,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12252: train loss 1.24030. lr 4.146279e-04:  75%|███████▌  | 12252/16329 [1:43:10<34:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12252: train loss 1.24030. lr 4.146279e-04:  75%|███████▌  | 12253/16329 [1:43:10<34:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12253: train loss 1.21958. lr 4.146012e-04:  75%|███████▌  | 12253/16329 [1:43:10<34:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12253: train loss 1.21958. lr 4.146012e-04:  75%|███████▌  | 12254/16329 [1:43:10<33:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12254: train loss 1.23828. lr 4.145746e-04:  75%|███████▌  | 12254/16329 [1:43:11<33:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12254: train loss 1.23828. lr 4.145746e-04:  75%|███████▌  | 12255/16329 [1:43:11<33:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12255: train loss 1.21729. lr 4.145479e-04:  75%|███████▌  | 12255/16329 [1:43:11<33:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12255: train loss 1.21729. lr 4.145479e-04:  75%|███████▌  | 12256/16329 [1:43:11<33:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12256: train loss 1.23692. lr 4.145212e-04:  75%|███████▌  | 12256/16329 [1:43:12<33:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12256: train loss 1.23692. lr 4.145212e-04:  75%|███████▌  | 12257/16329 [1:43:12<33:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12257: train loss 1.23545. lr 4.144946e-04:  75%|███████▌  | 12257/16329 [1:43:12<33:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12257: train loss 1.23545. lr 4.144946e-04:  75%|███████▌  | 12258/16329 [1:43:12<33:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12258: train loss 1.26260. lr 4.144679e-04:  75%|███████▌  | 12258/16329 [1:43:13<33:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12258: train loss 1.26260. lr 4.144679e-04:  75%|███████▌  | 12259/16329 [1:43:13<33:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12259: train loss 1.20122. lr 4.144412e-04:  75%|███████▌  | 12259/16329 [1:43:13<33:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12259: train loss 1.20122. lr 4.144412e-04:  75%|███████▌  | 12260/16329 [1:43:13<33:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12260: train loss 1.25875. lr 4.144145e-04:  75%|███████▌  | 12260/16329 [1:43:14<33:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12260: train loss 1.25875. lr 4.144145e-04:  75%|███████▌  | 12261/16329 [1:43:14<33:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12261: train loss 1.24914. lr 4.143878e-04:  75%|███████▌  | 12261/16329 [1:43:14<33:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12261: train loss 1.24914. lr 4.143878e-04:  75%|███████▌  | 12262/16329 [1:43:14<37:13,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12262: train loss 1.24401. lr 4.143612e-04:  75%|███████▌  | 12262/16329 [1:43:15<37:13,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12262: train loss 1.24401. lr 4.143612e-04:  75%|███████▌  | 12263/16329 [1:43:15<36:02,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12263: train loss 1.22470. lr 4.143345e-04:  75%|███████▌  | 12263/16329 [1:43:15<36:02,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12263: train loss 1.22470. lr 4.143345e-04:  75%|███████▌  | 12264/16329 [1:43:15<35:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12264: train loss 1.26179. lr 4.143078e-04:  75%|███████▌  | 12264/16329 [1:43:16<35:15,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12264: train loss 1.26179. lr 4.143078e-04:  75%|███████▌  | 12265/16329 [1:43:16<34:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12265: train loss 1.22406. lr 4.142811e-04:  75%|███████▌  | 12265/16329 [1:43:16<34:46,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12265: train loss 1.22406. lr 4.142811e-04:  75%|███████▌  | 12266/16329 [1:43:16<34:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12266: train loss 1.27576. lr 4.142544e-04:  75%|███████▌  | 12266/16329 [1:43:17<34:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12266: train loss 1.27576. lr 4.142544e-04:  75%|███████▌  | 12267/16329 [1:43:17<34:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12267: train loss 1.22713. lr 4.142277e-04:  75%|███████▌  | 12267/16329 [1:43:17<34:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12267: train loss 1.22713. lr 4.142277e-04:  75%|███████▌  | 12268/16329 [1:43:17<33:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12268: train loss 1.23476. lr 4.142011e-04:  75%|███████▌  | 12268/16329 [1:43:18<33:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12268: train loss 1.23476. lr 4.142011e-04:  75%|███████▌  | 12269/16329 [1:43:18<33:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12269: train loss 1.25270. lr 4.141744e-04:  75%|███████▌  | 12269/16329 [1:43:18<33:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12269: train loss 1.25270. lr 4.141744e-04:  75%|███████▌  | 12270/16329 [1:43:18<33:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12270: train loss 1.26730. lr 4.141477e-04:  75%|███████▌  | 12270/16329 [1:43:19<33:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12270: train loss 1.26730. lr 4.141477e-04:  75%|███████▌  | 12271/16329 [1:43:19<33:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12271: train loss 1.24743. lr 4.141210e-04:  75%|███████▌  | 12271/16329 [1:43:19<33:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12271: train loss 1.24743. lr 4.141210e-04:  75%|███████▌  | 12272/16329 [1:43:19<33:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12272: train loss 1.24451. lr 4.140943e-04:  75%|███████▌  | 12272/16329 [1:43:20<33:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12272: train loss 1.24451. lr 4.140943e-04:  75%|███████▌  | 12273/16329 [1:43:20<33:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12273: train loss 1.26296. lr 4.140676e-04:  75%|███████▌  | 12273/16329 [1:43:20<33:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12273: train loss 1.26296. lr 4.140676e-04:  75%|███████▌  | 12274/16329 [1:43:20<33:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12274: train loss 1.24807. lr 4.140409e-04:  75%|███████▌  | 12274/16329 [1:43:21<33:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12274: train loss 1.24807. lr 4.140409e-04:  75%|███████▌  | 12275/16329 [1:43:21<33:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12275: train loss 1.25219. lr 4.140142e-04:  75%|███████▌  | 12275/16329 [1:43:21<33:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12275: train loss 1.25219. lr 4.140142e-04:  75%|███████▌  | 12276/16329 [1:43:21<33:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12276: train loss 1.25840. lr 4.139875e-04:  75%|███████▌  | 12276/16329 [1:43:22<33:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12276: train loss 1.25840. lr 4.139875e-04:  75%|███████▌  | 12277/16329 [1:43:22<33:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12277: train loss 1.23532. lr 4.139608e-04:  75%|███████▌  | 12277/16329 [1:43:22<33:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12277: train loss 1.23532. lr 4.139608e-04:  75%|███████▌  | 12278/16329 [1:43:22<33:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12278: train loss 1.24697. lr 4.139341e-04:  75%|███████▌  | 12278/16329 [1:43:23<33:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12278: train loss 1.24697. lr 4.139341e-04:  75%|███████▌  | 12279/16329 [1:43:23<33:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12279: train loss 1.22938. lr 4.139074e-04:  75%|███████▌  | 12279/16329 [1:43:23<33:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12279: train loss 1.22938. lr 4.139074e-04:  75%|███████▌  | 12280/16329 [1:43:23<33:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12280: train loss 1.24173. lr 4.138807e-04:  75%|███████▌  | 12280/16329 [1:43:24<33:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12280: train loss 1.24173. lr 4.138807e-04:  75%|███████▌  | 12281/16329 [1:43:24<33:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12281: train loss 1.24413. lr 4.138540e-04:  75%|███████▌  | 12281/16329 [1:43:24<33:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12281: train loss 1.24413. lr 4.138540e-04:  75%|███████▌  | 12282/16329 [1:43:24<33:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12282: train loss 1.23718. lr 4.138273e-04:  75%|███████▌  | 12282/16329 [1:43:25<33:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12282: train loss 1.23718. lr 4.138273e-04:  75%|███████▌  | 12283/16329 [1:43:25<33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12283: train loss 1.24063. lr 4.138006e-04:  75%|███████▌  | 12283/16329 [1:43:25<33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12283: train loss 1.24063. lr 4.138006e-04:  75%|███████▌  | 12284/16329 [1:43:25<33:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12284: train loss 1.22880. lr 4.137739e-04:  75%|███████▌  | 12284/16329 [1:43:26<33:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12284: train loss 1.22880. lr 4.137739e-04:  75%|███████▌  | 12285/16329 [1:43:26<33:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12285: train loss 1.23835. lr 4.137472e-04:  75%|███████▌  | 12285/16329 [1:43:26<33:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12285: train loss 1.23835. lr 4.137472e-04:  75%|███████▌  | 12286/16329 [1:43:26<33:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12286: train loss 1.22006. lr 4.137205e-04:  75%|███████▌  | 12286/16329 [1:43:27<33:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12286: train loss 1.22006. lr 4.137205e-04:  75%|███████▌  | 12287/16329 [1:43:27<36:46,  1.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12287: train loss 1.24091. lr 4.136938e-04:  75%|███████▌  | 12287/16329 [1:43:27<36:46,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12287: train loss 1.24091. lr 4.136938e-04:  75%|███████▌  | 12288/16329 [1:43:27<35:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12288: train loss 1.20729. lr 4.136671e-04:  75%|███████▌  | 12288/16329 [1:43:28<35:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12288: train loss 1.20729. lr 4.136671e-04:  75%|███████▌  | 12289/16329 [1:43:28<35:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12289: train loss 1.25248. lr 4.136404e-04:  75%|███████▌  | 12289/16329 [1:43:28<35:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12289: train loss 1.25248. lr 4.136404e-04:  75%|███████▌  | 12290/16329 [1:43:28<34:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12290: train loss 1.22448. lr 4.136137e-04:  75%|███████▌  | 12290/16329 [1:43:29<34:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12290: train loss 1.22448. lr 4.136137e-04:  75%|███████▌  | 12291/16329 [1:43:29<34:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12291: train loss 1.24837. lr 4.135870e-04:  75%|███████▌  | 12291/16329 [1:43:29<34:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12291: train loss 1.24837. lr 4.135870e-04:  75%|███████▌  | 12292/16329 [1:43:29<34:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12292: train loss 1.22909. lr 4.135603e-04:  75%|███████▌  | 12292/16329 [1:43:30<34:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12292: train loss 1.22909. lr 4.135603e-04:  75%|███████▌  | 12293/16329 [1:43:30<33:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12293: train loss 1.26313. lr 4.135335e-04:  75%|███████▌  | 12293/16329 [1:43:30<33:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12293: train loss 1.26313. lr 4.135335e-04:  75%|███████▌  | 12294/16329 [1:43:30<33:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12294: train loss 1.24264. lr 4.135068e-04:  75%|███████▌  | 12294/16329 [1:43:31<33:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12294: train loss 1.24264. lr 4.135068e-04:  75%|███████▌  | 12295/16329 [1:43:31<33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12295: train loss 1.25101. lr 4.134801e-04:  75%|███████▌  | 12295/16329 [1:43:31<33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12295: train loss 1.25101. lr 4.134801e-04:  75%|███████▌  | 12296/16329 [1:43:31<33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12296: train loss 1.20798. lr 4.134534e-04:  75%|███████▌  | 12296/16329 [1:43:32<33:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12296: train loss 1.20798. lr 4.134534e-04:  75%|███████▌  | 12297/16329 [1:43:32<33:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12297: train loss 1.25131. lr 4.134267e-04:  75%|███████▌  | 12297/16329 [1:43:32<33:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12297: train loss 1.25131. lr 4.134267e-04:  75%|███████▌  | 12298/16329 [1:43:32<33:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12298: train loss 1.22854. lr 4.134000e-04:  75%|███████▌  | 12298/16329 [1:43:33<33:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12298: train loss 1.22854. lr 4.134000e-04:  75%|███████▌  | 12299/16329 [1:43:33<33:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12299: train loss 1.24357. lr 4.133732e-04:  75%|███████▌  | 12299/16329 [1:43:33<33:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12299: train loss 1.24357. lr 4.133732e-04:  75%|███████▌  | 12300/16329 [1:43:33<33:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12300: train loss 1.26562. lr 4.133465e-04:  75%|███████▌  | 12300/16329 [1:43:34<33:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12300: train loss 1.26562. lr 4.133465e-04:  75%|███████▌  | 12301/16329 [1:43:34<33:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12301: train loss 1.24636. lr 4.133198e-04:  75%|███████▌  | 12301/16329 [1:43:34<33:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12301: train loss 1.24636. lr 4.133198e-04:  75%|███████▌  | 12302/16329 [1:43:34<33:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12302: train loss 1.26083. lr 4.132931e-04:  75%|███████▌  | 12302/16329 [1:43:35<33:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12302: train loss 1.26083. lr 4.132931e-04:  75%|███████▌  | 12303/16329 [1:43:35<33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12303: train loss 1.25685. lr 4.132663e-04:  75%|███████▌  | 12303/16329 [1:43:35<33:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12303: train loss 1.25685. lr 4.132663e-04:  75%|███████▌  | 12304/16329 [1:43:35<33:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12304: train loss 1.25834. lr 4.132396e-04:  75%|███████▌  | 12304/16329 [1:43:36<33:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12304: train loss 1.25834. lr 4.132396e-04:  75%|███████▌  | 12305/16329 [1:43:36<33:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12305: train loss 1.27471. lr 4.132129e-04:  75%|███████▌  | 12305/16329 [1:43:36<33:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12305: train loss 1.27471. lr 4.132129e-04:  75%|███████▌  | 12306/16329 [1:43:36<33:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12306: train loss 1.22217. lr 4.131862e-04:  75%|███████▌  | 12306/16329 [1:43:37<33:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12306: train loss 1.22217. lr 4.131862e-04:  75%|███████▌  | 12307/16329 [1:43:37<33:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12307: train loss 1.22488. lr 4.131594e-04:  75%|███████▌  | 12307/16329 [1:43:37<33:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12307: train loss 1.22488. lr 4.131594e-04:  75%|███████▌  | 12308/16329 [1:43:37<33:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12308: train loss 1.23558. lr 4.131327e-04:  75%|███████▌  | 12308/16329 [1:43:38<33:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12308: train loss 1.23558. lr 4.131327e-04:  75%|███████▌  | 12309/16329 [1:43:38<33:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12309: train loss 1.18904. lr 4.131060e-04:  75%|███████▌  | 12309/16329 [1:43:38<33:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12309: train loss 1.18904. lr 4.131060e-04:  75%|███████▌  | 12310/16329 [1:43:38<33:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12310: train loss 1.22148. lr 4.130793e-04:  75%|███████▌  | 12310/16329 [1:43:39<33:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12310: train loss 1.22148. lr 4.130793e-04:  75%|███████▌  | 12311/16329 [1:43:39<33:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12311: train loss 1.23922. lr 4.130525e-04:  75%|███████▌  | 12311/16329 [1:43:39<33:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12311: train loss 1.23922. lr 4.130525e-04:  75%|███████▌  | 12312/16329 [1:43:39<33:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12312: train loss 1.21892. lr 4.130258e-04:  75%|███████▌  | 12312/16329 [1:43:40<33:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12312: train loss 1.21892. lr 4.130258e-04:  75%|███████▌  | 12313/16329 [1:43:40<33:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12313: train loss 1.26151. lr 4.129991e-04:  75%|███████▌  | 12313/16329 [1:43:40<33:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12313: train loss 1.26151. lr 4.129991e-04:  75%|███████▌  | 12314/16329 [1:43:40<36:36,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12314: train loss 1.26546. lr 4.129723e-04:  75%|███████▌  | 12314/16329 [1:43:41<36:36,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12314: train loss 1.26546. lr 4.129723e-04:  75%|███████▌  | 12315/16329 [1:43:41<35:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12315: train loss 1.19819. lr 4.129456e-04:  75%|███████▌  | 12315/16329 [1:43:41<35:36,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12315: train loss 1.19819. lr 4.129456e-04:  75%|███████▌  | 12316/16329 [1:43:41<34:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12316: train loss 1.25269. lr 4.129188e-04:  75%|███████▌  | 12316/16329 [1:43:42<34:49,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12316: train loss 1.25269. lr 4.129188e-04:  75%|███████▌  | 12317/16329 [1:43:42<34:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12317: train loss 1.19289. lr 4.128921e-04:  75%|███████▌  | 12317/16329 [1:43:42<34:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12317: train loss 1.19289. lr 4.128921e-04:  75%|███████▌  | 12318/16329 [1:43:42<33:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12318: train loss 1.23489. lr 4.128654e-04:  75%|███████▌  | 12318/16329 [1:43:43<33:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12318: train loss 1.23489. lr 4.128654e-04:  75%|███████▌  | 12319/16329 [1:43:43<33:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12319: train loss 1.19300. lr 4.128386e-04:  75%|███████▌  | 12319/16329 [1:43:43<33:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12319: train loss 1.19300. lr 4.128386e-04:  75%|███████▌  | 12320/16329 [1:43:43<34:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12320: train loss 1.25165. lr 4.128119e-04:  75%|███████▌  | 12320/16329 [1:43:44<34:10,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12320: train loss 1.25165. lr 4.128119e-04:  75%|███████▌  | 12321/16329 [1:43:44<34:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12321: train loss 1.25925. lr 4.127851e-04:  75%|███████▌  | 12321/16329 [1:43:44<34:23,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12321: train loss 1.25925. lr 4.127851e-04:  75%|███████▌  | 12322/16329 [1:43:44<34:22,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12322: train loss 1.24491. lr 4.127584e-04:  75%|███████▌  | 12322/16329 [1:43:45<34:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12322: train loss 1.24491. lr 4.127584e-04:  75%|███████▌  | 12323/16329 [1:43:45<34:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12323: train loss 1.23865. lr 4.127317e-04:  75%|███████▌  | 12323/16329 [1:43:45<34:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12323: train loss 1.23865. lr 4.127317e-04:  75%|███████▌  | 12324/16329 [1:43:45<33:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12324: train loss 1.23598. lr 4.127049e-04:  75%|███████▌  | 12324/16329 [1:43:46<33:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12324: train loss 1.23598. lr 4.127049e-04:  75%|███████▌  | 12325/16329 [1:43:46<33:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12325: train loss 1.23093. lr 4.126782e-04:  75%|███████▌  | 12325/16329 [1:43:46<33:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12325: train loss 1.23093. lr 4.126782e-04:  75%|███████▌  | 12326/16329 [1:43:46<33:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12326: train loss 1.21251. lr 4.126514e-04:  75%|███████▌  | 12326/16329 [1:43:47<33:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12326: train loss 1.21251. lr 4.126514e-04:  75%|███████▌  | 12327/16329 [1:43:47<33:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12327: train loss 1.28520. lr 4.126247e-04:  75%|███████▌  | 12327/16329 [1:43:47<33:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12327: train loss 1.28520. lr 4.126247e-04:  75%|███████▌  | 12328/16329 [1:43:47<33:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12328: train loss 1.20802. lr 4.125979e-04:  75%|███████▌  | 12328/16329 [1:43:48<33:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12328: train loss 1.20802. lr 4.125979e-04:  76%|███████▌  | 12329/16329 [1:43:48<33:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12329: train loss 1.25060. lr 4.125712e-04:  76%|███████▌  | 12329/16329 [1:43:48<33:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12329: train loss 1.25060. lr 4.125712e-04:  76%|███████▌  | 12330/16329 [1:43:48<33:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12330: train loss 1.21471. lr 4.125444e-04:  76%|███████▌  | 12330/16329 [1:43:49<33:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12330: train loss 1.21471. lr 4.125444e-04:  76%|███████▌  | 12331/16329 [1:43:49<33:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12331: train loss 1.25337. lr 4.125177e-04:  76%|███████▌  | 12331/16329 [1:43:49<33:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12331: train loss 1.25337. lr 4.125177e-04:  76%|███████▌  | 12332/16329 [1:43:49<33:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12332: train loss 1.22705. lr 4.124909e-04:  76%|███████▌  | 12332/16329 [1:43:50<33:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12332: train loss 1.22705. lr 4.124909e-04:  76%|███████▌  | 12333/16329 [1:43:50<33:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12333: train loss 1.20620. lr 4.124641e-04:  76%|███████▌  | 12333/16329 [1:43:50<33:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12333: train loss 1.20620. lr 4.124641e-04:  76%|███████▌  | 12334/16329 [1:43:50<33:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12334: train loss 1.23144. lr 4.124374e-04:  76%|███████▌  | 12334/16329 [1:43:51<33:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12334: train loss 1.23144. lr 4.124374e-04:  76%|███████▌  | 12335/16329 [1:43:51<33:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12335: train loss 1.22626. lr 4.124106e-04:  76%|███████▌  | 12335/16329 [1:43:51<33:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12335: train loss 1.22626. lr 4.124106e-04:  76%|███████▌  | 12336/16329 [1:43:51<33:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12336: train loss 1.25373. lr 4.123839e-04:  76%|███████▌  | 12336/16329 [1:43:52<33:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12336: train loss 1.25373. lr 4.123839e-04:  76%|███████▌  | 12337/16329 [1:43:52<33:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12337: train loss 1.26045. lr 4.123571e-04:  76%|███████▌  | 12337/16329 [1:43:52<33:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12337: train loss 1.26045. lr 4.123571e-04:  76%|███████▌  | 12338/16329 [1:43:52<33:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12338: train loss 1.20635. lr 4.123304e-04:  76%|███████▌  | 12338/16329 [1:43:53<33:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12338: train loss 1.20635. lr 4.123304e-04:  76%|███████▌  | 12339/16329 [1:43:53<33:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12339: train loss 1.25047. lr 4.123036e-04:  76%|███████▌  | 12339/16329 [1:43:53<33:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12339: train loss 1.25047. lr 4.123036e-04:  76%|███████▌  | 12340/16329 [1:43:53<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12340: train loss 1.24128. lr 4.122768e-04:  76%|███████▌  | 12340/16329 [1:43:54<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12340: train loss 1.24128. lr 4.122768e-04:  76%|███████▌  | 12341/16329 [1:43:54<32:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12341: train loss 1.24121. lr 4.122501e-04:  76%|███████▌  | 12341/16329 [1:43:54<32:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12341: train loss 1.24121. lr 4.122501e-04:  76%|███████▌  | 12342/16329 [1:43:54<32:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12342: train loss 1.26991. lr 4.122233e-04:  76%|███████▌  | 12342/16329 [1:43:55<32:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12342: train loss 1.26991. lr 4.122233e-04:  76%|███████▌  | 12343/16329 [1:43:55<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12343: train loss 1.27706. lr 4.121965e-04:  76%|███████▌  | 12343/16329 [1:43:55<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12343: train loss 1.27706. lr 4.121965e-04:  76%|███████▌  | 12344/16329 [1:43:55<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12344: train loss 1.23903. lr 4.121698e-04:  76%|███████▌  | 12344/16329 [1:43:56<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12344: train loss 1.23903. lr 4.121698e-04:  76%|███████▌  | 12345/16329 [1:43:56<32:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12345: train loss 1.19129. lr 4.121430e-04:  76%|███████▌  | 12345/16329 [1:43:56<32:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12345: train loss 1.19129. lr 4.121430e-04:  76%|███████▌  | 12346/16329 [1:43:56<33:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12346: train loss 1.21463. lr 4.121162e-04:  76%|███████▌  | 12346/16329 [1:43:57<33:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12346: train loss 1.21463. lr 4.121162e-04:  76%|███████▌  | 12347/16329 [1:43:57<33:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12347: train loss 1.25043. lr 4.120895e-04:  76%|███████▌  | 12347/16329 [1:43:57<33:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12347: train loss 1.25043. lr 4.120895e-04:  76%|███████▌  | 12348/16329 [1:43:57<33:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12348: train loss 1.22688. lr 4.120627e-04:  76%|███████▌  | 12348/16329 [1:43:58<33:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12348: train loss 1.22688. lr 4.120627e-04:  76%|███████▌  | 12349/16329 [1:43:58<33:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12349: train loss 1.24122. lr 4.120359e-04:  76%|███████▌  | 12349/16329 [1:43:58<33:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12349: train loss 1.24122. lr 4.120359e-04:  76%|███████▌  | 12350/16329 [1:43:58<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12350: train loss 1.24837. lr 4.120092e-04:  76%|███████▌  | 12350/16329 [1:43:59<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12350: train loss 1.24837. lr 4.120092e-04:  76%|███████▌  | 12351/16329 [1:43:59<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12351: train loss 1.23122. lr 4.119824e-04:  76%|███████▌  | 12351/16329 [1:43:59<33:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12351: train loss 1.23122. lr 4.119824e-04:  76%|███████▌  | 12352/16329 [1:43:59<32:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12352: train loss 1.26426. lr 4.119556e-04:  76%|███████▌  | 12352/16329 [1:44:00<32:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12352: train loss 1.26426. lr 4.119556e-04:  76%|███████▌  | 12353/16329 [1:44:00<33:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12353: train loss 1.24447. lr 4.119288e-04:  76%|███████▌  | 12353/16329 [1:44:01<33:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12353: train loss 1.24447. lr 4.119288e-04:  76%|███████▌  | 12354/16329 [1:44:01<37:08,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 12354: train loss 1.27531. lr 4.119021e-04:  76%|███████▌  | 12354/16329 [1:44:01<37:08,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 12354: train loss 1.27531. lr 4.119021e-04:  76%|███████▌  | 12355/16329 [1:44:01<36:19,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12355: train loss 1.18914. lr 4.118753e-04:  76%|███████▌  | 12355/16329 [1:44:02<36:19,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12355: train loss 1.18914. lr 4.118753e-04:  76%|███████▌  | 12356/16329 [1:44:02<35:31,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12356: train loss 1.24404. lr 4.118485e-04:  76%|███████▌  | 12356/16329 [1:44:02<35:31,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12356: train loss 1.24404. lr 4.118485e-04:  76%|███████▌  | 12357/16329 [1:44:02<34:59,  1.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12357: train loss 1.24563. lr 4.118217e-04:  76%|███████▌  | 12357/16329 [1:44:03<34:59,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12357: train loss 1.24563. lr 4.118217e-04:  76%|███████▌  | 12358/16329 [1:44:03<34:29,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12358: train loss 1.22802. lr 4.117949e-04:  76%|███████▌  | 12358/16329 [1:44:03<34:29,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12358: train loss 1.22802. lr 4.117949e-04:  76%|███████▌  | 12359/16329 [1:44:03<34:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12359: train loss 1.21498. lr 4.117682e-04:  76%|███████▌  | 12359/16329 [1:44:04<34:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12359: train loss 1.21498. lr 4.117682e-04:  76%|███████▌  | 12360/16329 [1:44:04<33:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12360: train loss 1.22288. lr 4.117414e-04:  76%|███████▌  | 12360/16329 [1:44:04<33:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12360: train loss 1.22288. lr 4.117414e-04:  76%|███████▌  | 12361/16329 [1:44:04<33:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12361: train loss 1.24226. lr 4.117146e-04:  76%|███████▌  | 12361/16329 [1:44:05<33:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12361: train loss 1.24226. lr 4.117146e-04:  76%|███████▌  | 12362/16329 [1:44:05<33:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12362: train loss 1.25173. lr 4.116878e-04:  76%|███████▌  | 12362/16329 [1:44:05<33:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12362: train loss 1.25173. lr 4.116878e-04:  76%|███████▌  | 12363/16329 [1:44:05<33:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12363: train loss 1.22605. lr 4.116610e-04:  76%|███████▌  | 12363/16329 [1:44:06<33:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12363: train loss 1.22605. lr 4.116610e-04:  76%|███████▌  | 12364/16329 [1:44:06<33:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12364: train loss 1.24253. lr 4.116342e-04:  76%|███████▌  | 12364/16329 [1:44:06<33:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12364: train loss 1.24253. lr 4.116342e-04:  76%|███████▌  | 12365/16329 [1:44:06<32:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12365: train loss 1.23980. lr 4.116074e-04:  76%|███████▌  | 12365/16329 [1:44:07<32:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12365: train loss 1.23980. lr 4.116074e-04:  76%|███████▌  | 12366/16329 [1:44:07<32:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12366: train loss 1.20429. lr 4.115806e-04:  76%|███████▌  | 12366/16329 [1:44:07<32:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12366: train loss 1.20429. lr 4.115806e-04:  76%|███████▌  | 12367/16329 [1:44:07<33:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12367: train loss 1.24648. lr 4.115539e-04:  76%|███████▌  | 12367/16329 [1:44:08<33:29,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12367: train loss 1.24648. lr 4.115539e-04:  76%|███████▌  | 12368/16329 [1:44:08<34:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12368: train loss 1.22888. lr 4.115271e-04:  76%|███████▌  | 12368/16329 [1:44:08<34:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12368: train loss 1.22888. lr 4.115271e-04:  76%|███████▌  | 12369/16329 [1:44:08<34:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12369: train loss 1.22661. lr 4.115003e-04:  76%|███████▌  | 12369/16329 [1:44:09<34:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12369: train loss 1.22661. lr 4.115003e-04:  76%|███████▌  | 12370/16329 [1:44:09<34:13,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12370: train loss 1.23008. lr 4.114735e-04:  76%|███████▌  | 12370/16329 [1:44:09<34:13,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12370: train loss 1.23008. lr 4.114735e-04:  76%|███████▌  | 12371/16329 [1:44:09<34:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12371: train loss 1.21116. lr 4.114467e-04:  76%|███████▌  | 12371/16329 [1:44:10<34:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12371: train loss 1.21116. lr 4.114467e-04:  76%|███████▌  | 12372/16329 [1:44:10<33:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12372: train loss 1.19763. lr 4.114199e-04:  76%|███████▌  | 12372/16329 [1:44:10<33:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12372: train loss 1.19763. lr 4.114199e-04:  76%|███████▌  | 12373/16329 [1:44:10<33:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12373: train loss 1.20038. lr 4.113931e-04:  76%|███████▌  | 12373/16329 [1:44:11<33:30,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12373: train loss 1.20038. lr 4.113931e-04:  76%|███████▌  | 12374/16329 [1:44:11<33:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12374: train loss 1.24954. lr 4.113663e-04:  76%|███████▌  | 12374/16329 [1:44:11<33:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12374: train loss 1.24954. lr 4.113663e-04:  76%|███████▌  | 12375/16329 [1:44:11<33:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12375: train loss 1.22062. lr 4.113395e-04:  76%|███████▌  | 12375/16329 [1:44:12<33:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12375: train loss 1.22062. lr 4.113395e-04:  76%|███████▌  | 12376/16329 [1:44:12<32:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12376: train loss 1.23313. lr 4.113127e-04:  76%|███████▌  | 12376/16329 [1:44:12<32:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12376: train loss 1.23313. lr 4.113127e-04:  76%|███████▌  | 12377/16329 [1:44:12<32:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12377: train loss 1.26864. lr 4.112859e-04:  76%|███████▌  | 12377/16329 [1:44:13<32:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12377: train loss 1.26864. lr 4.112859e-04:  76%|███████▌  | 12378/16329 [1:44:13<32:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12378: train loss 1.24243. lr 4.112591e-04:  76%|███████▌  | 12378/16329 [1:44:13<32:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12378: train loss 1.24243. lr 4.112591e-04:  76%|███████▌  | 12379/16329 [1:44:13<32:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12379: train loss 1.24108. lr 4.112323e-04:  76%|███████▌  | 12379/16329 [1:44:14<32:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12379: train loss 1.24108. lr 4.112323e-04:  76%|███████▌  | 12380/16329 [1:44:14<32:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12380: train loss 1.19354. lr 4.112055e-04:  76%|███████▌  | 12380/16329 [1:44:14<32:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12380: train loss 1.19354. lr 4.112055e-04:  76%|███████▌  | 12381/16329 [1:44:14<32:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12381: train loss 1.24118. lr 4.111787e-04:  76%|███████▌  | 12381/16329 [1:44:15<32:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12381: train loss 1.24118. lr 4.111787e-04:  76%|███████▌  | 12382/16329 [1:44:15<32:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12382: train loss 1.21256. lr 4.111519e-04:  76%|███████▌  | 12382/16329 [1:44:15<32:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12382: train loss 1.21256. lr 4.111519e-04:  76%|███████▌  | 12383/16329 [1:44:15<32:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12383: train loss 1.22733. lr 4.111251e-04:  76%|███████▌  | 12383/16329 [1:44:16<32:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12383: train loss 1.22733. lr 4.111251e-04:  76%|███████▌  | 12384/16329 [1:44:16<32:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12384: train loss 1.21800. lr 4.110983e-04:  76%|███████▌  | 12384/16329 [1:44:16<32:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12384: train loss 1.21800. lr 4.110983e-04:  76%|███████▌  | 12385/16329 [1:44:16<32:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12385: train loss 1.24611. lr 4.110715e-04:  76%|███████▌  | 12385/16329 [1:44:17<32:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12385: train loss 1.24611. lr 4.110715e-04:  76%|███████▌  | 12386/16329 [1:44:17<32:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12386: train loss 1.21430. lr 4.110446e-04:  76%|███████▌  | 12386/16329 [1:44:17<32:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12386: train loss 1.21430. lr 4.110446e-04:  76%|███████▌  | 12387/16329 [1:44:17<32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12387: train loss 1.25939. lr 4.110178e-04:  76%|███████▌  | 12387/16329 [1:44:18<32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12387: train loss 1.25939. lr 4.110178e-04:  76%|███████▌  | 12388/16329 [1:44:18<32:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12388: train loss 1.20496. lr 4.109910e-04:  76%|███████▌  | 12388/16329 [1:44:18<32:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12388: train loss 1.20496. lr 4.109910e-04:  76%|███████▌  | 12389/16329 [1:44:18<35:57,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12389: train loss 1.25238. lr 4.109642e-04:  76%|███████▌  | 12389/16329 [1:44:19<35:57,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12389: train loss 1.25238. lr 4.109642e-04:  76%|███████▌  | 12390/16329 [1:44:19<34:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12390: train loss 1.21858. lr 4.109374e-04:  76%|███████▌  | 12390/16329 [1:44:19<34:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12390: train loss 1.21858. lr 4.109374e-04:  76%|███████▌  | 12391/16329 [1:44:19<34:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12391: train loss 1.26812. lr 4.109106e-04:  76%|███████▌  | 12391/16329 [1:44:20<34:12,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12391: train loss 1.26812. lr 4.109106e-04:  76%|███████▌  | 12392/16329 [1:44:20<33:46,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12392: train loss 1.25523. lr 4.108838e-04:  76%|███████▌  | 12392/16329 [1:44:20<33:46,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12392: train loss 1.25523. lr 4.108838e-04:  76%|███████▌  | 12393/16329 [1:44:20<33:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12393: train loss 1.25298. lr 4.108569e-04:  76%|███████▌  | 12393/16329 [1:44:21<33:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12393: train loss 1.25298. lr 4.108569e-04:  76%|███████▌  | 12394/16329 [1:44:21<33:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12394: train loss 1.23417. lr 4.108301e-04:  76%|███████▌  | 12394/16329 [1:44:21<33:08,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12394: train loss 1.23417. lr 4.108301e-04:  76%|███████▌  | 12395/16329 [1:44:21<33:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12395: train loss 1.24300. lr 4.108033e-04:  76%|███████▌  | 12395/16329 [1:44:22<33:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12395: train loss 1.24300. lr 4.108033e-04:  76%|███████▌  | 12396/16329 [1:44:22<32:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12396: train loss 1.22054. lr 4.107765e-04:  76%|███████▌  | 12396/16329 [1:44:22<32:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12396: train loss 1.22054. lr 4.107765e-04:  76%|███████▌  | 12397/16329 [1:44:22<32:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12397: train loss 1.26896. lr 4.107497e-04:  76%|███████▌  | 12397/16329 [1:44:23<32:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12397: train loss 1.26896. lr 4.107497e-04:  76%|███████▌  | 12398/16329 [1:44:23<32:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12398: train loss 1.21333. lr 4.107228e-04:  76%|███████▌  | 12398/16329 [1:44:23<32:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12398: train loss 1.21333. lr 4.107228e-04:  76%|███████▌  | 12399/16329 [1:44:23<33:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12399: train loss 1.23802. lr 4.106960e-04:  76%|███████▌  | 12399/16329 [1:44:24<33:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12399: train loss 1.23802. lr 4.106960e-04:  76%|███████▌  | 12400/16329 [1:44:24<33:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12400: train loss 1.23279. lr 4.106692e-04:  76%|███████▌  | 12400/16329 [1:44:24<33:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12400: train loss 1.23279. lr 4.106692e-04:  76%|███████▌  | 12401/16329 [1:44:24<33:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12401: train loss 1.19531. lr 4.106424e-04:  76%|███████▌  | 12401/16329 [1:44:25<33:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12401: train loss 1.19531. lr 4.106424e-04:  76%|███████▌  | 12402/16329 [1:44:25<33:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12402: train loss 1.22539. lr 4.106155e-04:  76%|███████▌  | 12402/16329 [1:44:25<33:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12402: train loss 1.22539. lr 4.106155e-04:  76%|███████▌  | 12403/16329 [1:44:25<33:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12403: train loss 1.24881. lr 4.105887e-04:  76%|███████▌  | 12403/16329 [1:44:26<33:07,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12403: train loss 1.24881. lr 4.105887e-04:  76%|███████▌  | 12404/16329 [1:44:26<32:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12404: train loss 1.24387. lr 4.105619e-04:  76%|███████▌  | 12404/16329 [1:44:26<32:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12404: train loss 1.24387. lr 4.105619e-04:  76%|███████▌  | 12405/16329 [1:44:26<32:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12405: train loss 1.22845. lr 4.105351e-04:  76%|███████▌  | 12405/16329 [1:44:27<32:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12405: train loss 1.22845. lr 4.105351e-04:  76%|███████▌  | 12406/16329 [1:44:27<32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12406: train loss 1.22589. lr 4.105082e-04:  76%|███████▌  | 12406/16329 [1:44:27<32:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12406: train loss 1.22589. lr 4.105082e-04:  76%|███████▌  | 12407/16329 [1:44:27<32:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12407: train loss 1.25904. lr 4.104814e-04:  76%|███████▌  | 12407/16329 [1:44:28<32:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12407: train loss 1.25904. lr 4.104814e-04:  76%|███████▌  | 12408/16329 [1:44:28<32:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12408: train loss 1.22801. lr 4.104546e-04:  76%|███████▌  | 12408/16329 [1:44:28<32:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12408: train loss 1.22801. lr 4.104546e-04:  76%|███████▌  | 12409/16329 [1:44:28<32:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12409: train loss 1.23489. lr 4.104277e-04:  76%|███████▌  | 12409/16329 [1:44:29<32:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12409: train loss 1.23489. lr 4.104277e-04:  76%|███████▌  | 12410/16329 [1:44:29<32:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12410: train loss 1.25413. lr 4.104009e-04:  76%|███████▌  | 12410/16329 [1:44:29<32:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12410: train loss 1.25413. lr 4.104009e-04:  76%|███████▌  | 12411/16329 [1:44:29<32:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12411: train loss 1.23165. lr 4.103741e-04:  76%|███████▌  | 12411/16329 [1:44:30<32:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12411: train loss 1.23165. lr 4.103741e-04:  76%|███████▌  | 12412/16329 [1:44:30<32:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12412: train loss 1.24674. lr 4.103472e-04:  76%|███████▌  | 12412/16329 [1:44:30<32:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12412: train loss 1.24674. lr 4.103472e-04:  76%|███████▌  | 12413/16329 [1:44:30<32:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12413: train loss 1.22446. lr 4.103204e-04:  76%|███████▌  | 12413/16329 [1:44:31<32:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12413: train loss 1.22446. lr 4.103204e-04:  76%|███████▌  | 12414/16329 [1:44:31<35:38,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12414: train loss 1.23788. lr 4.102936e-04:  76%|███████▌  | 12414/16329 [1:44:32<35:38,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12414: train loss 1.23788. lr 4.102936e-04:  76%|███████▌  | 12415/16329 [1:44:32<34:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12415: train loss 1.25643. lr 4.102667e-04:  76%|███████▌  | 12415/16329 [1:44:32<34:38,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12415: train loss 1.25643. lr 4.102667e-04:  76%|███████▌  | 12416/16329 [1:44:32<33:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12416: train loss 1.23028. lr 4.102399e-04:  76%|███████▌  | 12416/16329 [1:44:32<33:51,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12416: train loss 1.23028. lr 4.102399e-04:  76%|███████▌  | 12417/16329 [1:44:32<33:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12417: train loss 1.22667. lr 4.102130e-04:  76%|███████▌  | 12417/16329 [1:44:33<33:23,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12417: train loss 1.22667. lr 4.102130e-04:  76%|███████▌  | 12418/16329 [1:44:33<33:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12418: train loss 1.24415. lr 4.101862e-04:  76%|███████▌  | 12418/16329 [1:44:33<33:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12418: train loss 1.24415. lr 4.101862e-04:  76%|███████▌  | 12419/16329 [1:44:33<32:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12419: train loss 1.21009. lr 4.101593e-04:  76%|███████▌  | 12419/16329 [1:44:34<32:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12419: train loss 1.21009. lr 4.101593e-04:  76%|███████▌  | 12420/16329 [1:44:34<32:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12420: train loss 1.20743. lr 4.101325e-04:  76%|███████▌  | 12420/16329 [1:44:34<32:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12420: train loss 1.20743. lr 4.101325e-04:  76%|███████▌  | 12421/16329 [1:44:34<32:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12421: train loss 1.24608. lr 4.101057e-04:  76%|███████▌  | 12421/16329 [1:44:35<32:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12421: train loss 1.24608. lr 4.101057e-04:  76%|███████▌  | 12422/16329 [1:44:35<32:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12422: train loss 1.24178. lr 4.100788e-04:  76%|███████▌  | 12422/16329 [1:44:35<32:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12422: train loss 1.24178. lr 4.100788e-04:  76%|███████▌  | 12423/16329 [1:44:35<32:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12423: train loss 1.22357. lr 4.100520e-04:  76%|███████▌  | 12423/16329 [1:44:36<32:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12423: train loss 1.22357. lr 4.100520e-04:  76%|███████▌  | 12424/16329 [1:44:36<32:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12424: train loss 1.21081. lr 4.100251e-04:  76%|███████▌  | 12424/16329 [1:44:36<32:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12424: train loss 1.21081. lr 4.100251e-04:  76%|███████▌  | 12425/16329 [1:44:36<32:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12425: train loss 1.23600. lr 4.099983e-04:  76%|███████▌  | 12425/16329 [1:44:37<32:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12425: train loss 1.23600. lr 4.099983e-04:  76%|███████▌  | 12426/16329 [1:44:37<32:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12426: train loss 1.23428. lr 4.099714e-04:  76%|███████▌  | 12426/16329 [1:44:37<32:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12426: train loss 1.23428. lr 4.099714e-04:  76%|███████▌  | 12427/16329 [1:44:37<32:07,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12427: train loss 1.24120. lr 4.099446e-04:  76%|███████▌  | 12427/16329 [1:44:38<32:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12427: train loss 1.24120. lr 4.099446e-04:  76%|███████▌  | 12428/16329 [1:44:38<32:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12428: train loss 1.23207. lr 4.099177e-04:  76%|███████▌  | 12428/16329 [1:44:38<32:02,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12428: train loss 1.23207. lr 4.099177e-04:  76%|███████▌  | 12429/16329 [1:44:38<32:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12429: train loss 1.25938. lr 4.098909e-04:  76%|███████▌  | 12429/16329 [1:44:39<32:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12429: train loss 1.25938. lr 4.098909e-04:  76%|███████▌  | 12430/16329 [1:44:39<32:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12430: train loss 1.23526. lr 4.098640e-04:  76%|███████▌  | 12430/16329 [1:44:39<32:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12430: train loss 1.23526. lr 4.098640e-04:  76%|███████▌  | 12431/16329 [1:44:39<31:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12431: train loss 1.24207. lr 4.098371e-04:  76%|███████▌  | 12431/16329 [1:44:40<31:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12431: train loss 1.24207. lr 4.098371e-04:  76%|███████▌  | 12432/16329 [1:44:40<32:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12432: train loss 1.23828. lr 4.098103e-04:  76%|███████▌  | 12432/16329 [1:44:40<32:03,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12432: train loss 1.23828. lr 4.098103e-04:  76%|███████▌  | 12433/16329 [1:44:40<31:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12433: train loss 1.21740. lr 4.097834e-04:  76%|███████▌  | 12433/16329 [1:44:41<31:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12433: train loss 1.21740. lr 4.097834e-04:  76%|███████▌  | 12434/16329 [1:44:41<32:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12434: train loss 1.23811. lr 4.097566e-04:  76%|███████▌  | 12434/16329 [1:44:41<32:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12434: train loss 1.23811. lr 4.097566e-04:  76%|███████▌  | 12435/16329 [1:44:41<32:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12435: train loss 1.24191. lr 4.097297e-04:  76%|███████▌  | 12435/16329 [1:44:42<32:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12435: train loss 1.24191. lr 4.097297e-04:  76%|███████▌  | 12436/16329 [1:44:42<32:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12436: train loss 1.20178. lr 4.097028e-04:  76%|███████▌  | 12436/16329 [1:44:42<32:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12436: train loss 1.20178. lr 4.097028e-04:  76%|███████▌  | 12437/16329 [1:44:42<31:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12437: train loss 1.23112. lr 4.096760e-04:  76%|███████▌  | 12437/16329 [1:44:43<31:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12437: train loss 1.23112. lr 4.096760e-04:  76%|███████▌  | 12438/16329 [1:44:43<31:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12438: train loss 1.19772. lr 4.096491e-04:  76%|███████▌  | 12438/16329 [1:44:43<31:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12438: train loss 1.19772. lr 4.096491e-04:  76%|███████▌  | 12439/16329 [1:44:43<32:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12439: train loss 1.25021. lr 4.096223e-04:  76%|███████▌  | 12439/16329 [1:44:44<32:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12439: train loss 1.25021. lr 4.096223e-04:  76%|███████▌  | 12440/16329 [1:44:44<31:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12440: train loss 1.20331. lr 4.095954e-04:  76%|███████▌  | 12440/16329 [1:44:45<31:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12440: train loss 1.20331. lr 4.095954e-04:  76%|███████▌  | 12441/16329 [1:44:45<35:15,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 12441: train loss 1.19642. lr 4.095685e-04:  76%|███████▌  | 12441/16329 [1:44:45<35:15,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 12441: train loss 1.19642. lr 4.095685e-04:  76%|███████▌  | 12442/16329 [1:44:45<34:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12442: train loss 1.21617. lr 4.095417e-04:  76%|███████▌  | 12442/16329 [1:44:45<34:23,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12442: train loss 1.21617. lr 4.095417e-04:  76%|███████▌  | 12443/16329 [1:44:45<33:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12443: train loss 1.24771. lr 4.095148e-04:  76%|███████▌  | 12443/16329 [1:44:46<33:38,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12443: train loss 1.24771. lr 4.095148e-04:  76%|███████▌  | 12444/16329 [1:44:46<33:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12444: train loss 1.21232. lr 4.094879e-04:  76%|███████▌  | 12444/16329 [1:44:46<33:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12444: train loss 1.21232. lr 4.094879e-04:  76%|███████▌  | 12445/16329 [1:44:46<32:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12445: train loss 1.22614. lr 4.094611e-04:  76%|███████▌  | 12445/16329 [1:44:47<32:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12445: train loss 1.22614. lr 4.094611e-04:  76%|███████▌  | 12446/16329 [1:44:47<32:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12446: train loss 1.28425. lr 4.094342e-04:  76%|███████▌  | 12446/16329 [1:44:47<32:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12446: train loss 1.28425. lr 4.094342e-04:  76%|███████▌  | 12447/16329 [1:44:47<32:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12447: train loss 1.25060. lr 4.094073e-04:  76%|███████▌  | 12447/16329 [1:44:48<32:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12447: train loss 1.25060. lr 4.094073e-04:  76%|███████▌  | 12448/16329 [1:44:48<32:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12448: train loss 1.23775. lr 4.093804e-04:  76%|███████▌  | 12448/16329 [1:44:48<32:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12448: train loss 1.23775. lr 4.093804e-04:  76%|███████▌  | 12449/16329 [1:44:48<32:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12449: train loss 1.22097. lr 4.093536e-04:  76%|███████▌  | 12449/16329 [1:44:49<32:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12449: train loss 1.22097. lr 4.093536e-04:  76%|███████▌  | 12450/16329 [1:44:49<32:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12450: train loss 1.25342. lr 4.093267e-04:  76%|███████▌  | 12450/16329 [1:44:49<32:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12450: train loss 1.25342. lr 4.093267e-04:  76%|███████▋  | 12451/16329 [1:44:49<31:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12451: train loss 1.22197. lr 4.092998e-04:  76%|███████▋  | 12451/16329 [1:44:50<31:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12451: train loss 1.22197. lr 4.092998e-04:  76%|███████▋  | 12452/16329 [1:44:50<31:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12452: train loss 1.18505. lr 4.092729e-04:  76%|███████▋  | 12452/16329 [1:44:50<31:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12452: train loss 1.18505. lr 4.092729e-04:  76%|███████▋  | 12453/16329 [1:44:50<31:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12453: train loss 1.21808. lr 4.092461e-04:  76%|███████▋  | 12453/16329 [1:44:51<31:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12453: train loss 1.21808. lr 4.092461e-04:  76%|███████▋  | 12454/16329 [1:44:51<31:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12454: train loss 1.22126. lr 4.092192e-04:  76%|███████▋  | 12454/16329 [1:44:51<31:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12454: train loss 1.22126. lr 4.092192e-04:  76%|███████▋  | 12455/16329 [1:44:51<31:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12455: train loss 1.23363. lr 4.091923e-04:  76%|███████▋  | 12455/16329 [1:44:52<31:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12455: train loss 1.23363. lr 4.091923e-04:  76%|███████▋  | 12456/16329 [1:44:52<31:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12456: train loss 1.20451. lr 4.091654e-04:  76%|███████▋  | 12456/16329 [1:44:52<31:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12456: train loss 1.20451. lr 4.091654e-04:  76%|███████▋  | 12457/16329 [1:44:52<32:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12457: train loss 1.24219. lr 4.091385e-04:  76%|███████▋  | 12457/16329 [1:44:53<32:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12457: train loss 1.24219. lr 4.091385e-04:  76%|███████▋  | 12458/16329 [1:44:53<33:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12458: train loss 1.24348. lr 4.091116e-04:  76%|███████▋  | 12458/16329 [1:44:54<33:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12458: train loss 1.24348. lr 4.091116e-04:  76%|███████▋  | 12459/16329 [1:44:54<33:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12459: train loss 1.23325. lr 4.090848e-04:  76%|███████▋  | 12459/16329 [1:44:54<33:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12459: train loss 1.23325. lr 4.090848e-04:  76%|███████▋  | 12460/16329 [1:44:54<33:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12460: train loss 1.24762. lr 4.090579e-04:  76%|███████▋  | 12460/16329 [1:44:55<33:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12460: train loss 1.24762. lr 4.090579e-04:  76%|███████▋  | 12461/16329 [1:44:55<33:32,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12461: train loss 1.20471. lr 4.090310e-04:  76%|███████▋  | 12461/16329 [1:44:55<33:32,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12461: train loss 1.20471. lr 4.090310e-04:  76%|███████▋  | 12462/16329 [1:44:55<33:15,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12462: train loss 1.22705. lr 4.090041e-04:  76%|███████▋  | 12462/16329 [1:44:56<33:15,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12462: train loss 1.22705. lr 4.090041e-04:  76%|███████▋  | 12463/16329 [1:44:56<33:00,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12463: train loss 1.24874. lr 4.089772e-04:  76%|███████▋  | 12463/16329 [1:44:56<33:00,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12463: train loss 1.24874. lr 4.089772e-04:  76%|███████▋  | 12464/16329 [1:44:56<32:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12464: train loss 1.25322. lr 4.089503e-04:  76%|███████▋  | 12464/16329 [1:44:57<32:46,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12464: train loss 1.25322. lr 4.089503e-04:  76%|███████▋  | 12465/16329 [1:44:57<32:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12465: train loss 1.21236. lr 4.089234e-04:  76%|███████▋  | 12465/16329 [1:44:57<32:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12465: train loss 1.21236. lr 4.089234e-04:  76%|███████▋  | 12466/16329 [1:44:57<32:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12466: train loss 1.21965. lr 4.088965e-04:  76%|███████▋  | 12466/16329 [1:44:58<32:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12466: train loss 1.21965. lr 4.088965e-04:  76%|███████▋  | 12467/16329 [1:44:58<32:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12467: train loss 1.23536. lr 4.088697e-04:  76%|███████▋  | 12467/16329 [1:44:58<32:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12467: train loss 1.23536. lr 4.088697e-04:  76%|███████▋  | 12468/16329 [1:44:58<31:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12468: train loss 1.21365. lr 4.088428e-04:  76%|███████▋  | 12468/16329 [1:44:59<31:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12468: train loss 1.21365. lr 4.088428e-04:  76%|███████▋  | 12469/16329 [1:44:59<31:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12469: train loss 1.23929. lr 4.088159e-04:  76%|███████▋  | 12469/16329 [1:44:59<31:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12469: train loss 1.23929. lr 4.088159e-04:  76%|███████▋  | 12470/16329 [1:44:59<31:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12470: train loss 1.21416. lr 4.087890e-04:  76%|███████▋  | 12470/16329 [1:45:00<31:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12470: train loss 1.21416. lr 4.087890e-04:  76%|███████▋  | 12471/16329 [1:45:00<31:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12471: train loss 1.22698. lr 4.087621e-04:  76%|███████▋  | 12471/16329 [1:45:00<31:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12471: train loss 1.22698. lr 4.087621e-04:  76%|███████▋  | 12472/16329 [1:45:00<31:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12472: train loss 1.22813. lr 4.087352e-04:  76%|███████▋  | 12472/16329 [1:45:00<31:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12472: train loss 1.22813. lr 4.087352e-04:  76%|███████▋  | 12473/16329 [1:45:00<31:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12473: train loss 1.23488. lr 4.087083e-04:  76%|███████▋  | 12473/16329 [1:45:01<31:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12473: train loss 1.23488. lr 4.087083e-04:  76%|███████▋  | 12474/16329 [1:45:01<31:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12474: train loss 1.22332. lr 4.086814e-04:  76%|███████▋  | 12474/16329 [1:45:01<31:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12474: train loss 1.22332. lr 4.086814e-04:  76%|███████▋  | 12475/16329 [1:45:01<31:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12475: train loss 1.21814. lr 4.086545e-04:  76%|███████▋  | 12475/16329 [1:45:02<31:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12475: train loss 1.21814. lr 4.086545e-04:  76%|███████▋  | 12476/16329 [1:45:02<31:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12476: train loss 1.22542. lr 4.086276e-04:  76%|███████▋  | 12476/16329 [1:45:02<31:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12476: train loss 1.22542. lr 4.086276e-04:  76%|███████▋  | 12477/16329 [1:45:02<31:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12477: train loss 1.21044. lr 4.086007e-04:  76%|███████▋  | 12477/16329 [1:45:03<31:39,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12477: train loss 1.21044. lr 4.086007e-04:  76%|███████▋  | 12478/16329 [1:45:03<31:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12478: train loss 1.25892. lr 4.085738e-04:  76%|███████▋  | 12478/16329 [1:45:03<31:32,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12478: train loss 1.25892. lr 4.085738e-04:  76%|███████▋  | 12479/16329 [1:45:03<31:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12479: train loss 1.22106. lr 4.085469e-04:  76%|███████▋  | 12479/16329 [1:45:04<31:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12479: train loss 1.22106. lr 4.085469e-04:  76%|███████▋  | 12480/16329 [1:45:04<31:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12480: train loss 1.22878. lr 4.085200e-04:  76%|███████▋  | 12480/16329 [1:45:05<31:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12480: train loss 1.22878. lr 4.085200e-04:  76%|███████▋  | 12481/16329 [1:45:05<35:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12481: train loss 1.25933. lr 4.084931e-04:  76%|███████▋  | 12481/16329 [1:45:05<35:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12481: train loss 1.25933. lr 4.084931e-04:  76%|███████▋  | 12482/16329 [1:45:05<34:09,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12482: train loss 1.22943. lr 4.084661e-04:  76%|███████▋  | 12482/16329 [1:45:06<34:09,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12482: train loss 1.22943. lr 4.084661e-04:  76%|███████▋  | 12483/16329 [1:45:06<33:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12483: train loss 1.22666. lr 4.084392e-04:  76%|███████▋  | 12483/16329 [1:45:06<33:22,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12483: train loss 1.22666. lr 4.084392e-04:  76%|███████▋  | 12484/16329 [1:45:06<32:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12484: train loss 1.19743. lr 4.084123e-04:  76%|███████▋  | 12484/16329 [1:45:07<32:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12484: train loss 1.19743. lr 4.084123e-04:  76%|███████▋  | 12485/16329 [1:45:07<32:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12485: train loss 1.22412. lr 4.083854e-04:  76%|███████▋  | 12485/16329 [1:45:07<32:27,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12485: train loss 1.22412. lr 4.083854e-04:  76%|███████▋  | 12486/16329 [1:45:07<32:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12486: train loss 1.21848. lr 4.083585e-04:  76%|███████▋  | 12486/16329 [1:45:08<32:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12486: train loss 1.21848. lr 4.083585e-04:  76%|███████▋  | 12487/16329 [1:45:08<32:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12487: train loss 1.22760. lr 4.083316e-04:  76%|███████▋  | 12487/16329 [1:45:08<32:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12487: train loss 1.22760. lr 4.083316e-04:  76%|███████▋  | 12488/16329 [1:45:08<31:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12488: train loss 1.25129. lr 4.083047e-04:  76%|███████▋  | 12488/16329 [1:45:09<31:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12488: train loss 1.25129. lr 4.083047e-04:  76%|███████▋  | 12489/16329 [1:45:09<31:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12489: train loss 1.22457. lr 4.082778e-04:  76%|███████▋  | 12489/16329 [1:45:09<31:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12489: train loss 1.22457. lr 4.082778e-04:  76%|███████▋  | 12490/16329 [1:45:09<31:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12490: train loss 1.22613. lr 4.082509e-04:  76%|███████▋  | 12490/16329 [1:45:10<31:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12490: train loss 1.22613. lr 4.082509e-04:  76%|███████▋  | 12491/16329 [1:45:10<31:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12491: train loss 1.24749. lr 4.082239e-04:  76%|███████▋  | 12491/16329 [1:45:10<31:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12491: train loss 1.24749. lr 4.082239e-04:  77%|███████▋  | 12492/16329 [1:45:10<31:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12492: train loss 1.18953. lr 4.081970e-04:  77%|███████▋  | 12492/16329 [1:45:11<31:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12492: train loss 1.18953. lr 4.081970e-04:  77%|███████▋  | 12493/16329 [1:45:11<31:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12493: train loss 1.24588. lr 4.081701e-04:  77%|███████▋  | 12493/16329 [1:45:11<31:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12493: train loss 1.24588. lr 4.081701e-04:  77%|███████▋  | 12494/16329 [1:45:11<31:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12494: train loss 1.24967. lr 4.081432e-04:  77%|███████▋  | 12494/16329 [1:45:12<31:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12494: train loss 1.24967. lr 4.081432e-04:  77%|███████▋  | 12495/16329 [1:45:12<31:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12495: train loss 1.22270. lr 4.081163e-04:  77%|███████▋  | 12495/16329 [1:45:12<31:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12495: train loss 1.22270. lr 4.081163e-04:  77%|███████▋  | 12496/16329 [1:45:12<31:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12496: train loss 1.21456. lr 4.080893e-04:  77%|███████▋  | 12496/16329 [1:45:13<31:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12496: train loss 1.21456. lr 4.080893e-04:  77%|███████▋  | 12497/16329 [1:45:13<31:29,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12497: train loss 1.22893. lr 4.080624e-04:  77%|███████▋  | 12497/16329 [1:45:13<31:29,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12497: train loss 1.22893. lr 4.080624e-04:  77%|███████▋  | 12498/16329 [1:45:13<31:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12498: train loss 1.20783. lr 4.080355e-04:  77%|███████▋  | 12498/16329 [1:45:14<31:30,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12498: train loss 1.20783. lr 4.080355e-04:  77%|███████▋  | 12499/16329 [1:45:14<32:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12499: train loss 1.15370. lr 4.080086e-04:  77%|███████▋  | 12499/16329 [1:45:14<32:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12499: train loss 1.15370. lr 4.080086e-04:  77%|███████▋  | 12500/16329 [1:45:14<32:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12500: train loss 1.21164. lr 4.079816e-04:  77%|███████▋  | 12500/16329 [1:45:15<32:23,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12500: train loss 1.21164. lr 4.079816e-04:  77%|███████▋  | 12501/16329 [1:45:15<32:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12501: train loss 1.21162. lr 4.079547e-04:  77%|███████▋  | 12501/16329 [1:45:15<32:20,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12501: train loss 1.21162. lr 4.079547e-04:  77%|███████▋  | 12502/16329 [1:45:15<32:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12502: train loss 1.23297. lr 4.079278e-04:  77%|███████▋  | 12502/16329 [1:45:16<32:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12502: train loss 1.23297. lr 4.079278e-04:  77%|███████▋  | 12503/16329 [1:45:16<32:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12503: train loss 1.21976. lr 4.079009e-04:  77%|███████▋  | 12503/16329 [1:45:16<32:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12503: train loss 1.21976. lr 4.079009e-04:  77%|███████▋  | 12504/16329 [1:45:16<32:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12504: train loss 1.25450. lr 4.078739e-04:  77%|███████▋  | 12504/16329 [1:45:17<32:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12504: train loss 1.25450. lr 4.078739e-04:  77%|███████▋  | 12505/16329 [1:45:17<31:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12505: train loss 1.24675. lr 4.078470e-04:  77%|███████▋  | 12505/16329 [1:45:17<31:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12505: train loss 1.24675. lr 4.078470e-04:  77%|███████▋  | 12506/16329 [1:45:17<31:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12506: train loss 1.22184. lr 4.078201e-04:  77%|███████▋  | 12506/16329 [1:45:18<31:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12506: train loss 1.22184. lr 4.078201e-04:  77%|███████▋  | 12507/16329 [1:45:18<31:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12507: train loss 1.20086. lr 4.077931e-04:  77%|███████▋  | 12507/16329 [1:45:18<31:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12507: train loss 1.20086. lr 4.077931e-04:  77%|███████▋  | 12508/16329 [1:45:18<31:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12508: train loss 1.24181. lr 4.077662e-04:  77%|███████▋  | 12508/16329 [1:45:19<31:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12508: train loss 1.24181. lr 4.077662e-04:  77%|███████▋  | 12509/16329 [1:45:19<31:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12509: train loss 1.20745. lr 4.077393e-04:  77%|███████▋  | 12509/16329 [1:45:19<31:25,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12509: train loss 1.20745. lr 4.077393e-04:  77%|███████▋  | 12510/16329 [1:45:19<32:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12510: train loss 1.25376. lr 4.077123e-04:  77%|███████▋  | 12510/16329 [1:45:20<32:16,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12510: train loss 1.25376. lr 4.077123e-04:  77%|███████▋  | 12511/16329 [1:45:20<32:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12511: train loss 1.22845. lr 4.076854e-04:  77%|███████▋  | 12511/16329 [1:45:20<32:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12511: train loss 1.22845. lr 4.076854e-04:  77%|███████▋  | 12512/16329 [1:45:20<33:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12512: train loss 1.22864. lr 4.076585e-04:  77%|███████▋  | 12512/16329 [1:45:21<33:04,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12512: train loss 1.22864. lr 4.076585e-04:  77%|███████▋  | 12513/16329 [1:45:21<33:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12513: train loss 1.24034. lr 4.076315e-04:  77%|███████▋  | 12513/16329 [1:45:21<33:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12513: train loss 1.24034. lr 4.076315e-04:  77%|███████▋  | 12514/16329 [1:45:21<32:55,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12514: train loss 1.19458. lr 4.076046e-04:  77%|███████▋  | 12514/16329 [1:45:22<32:55,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12514: train loss 1.19458. lr 4.076046e-04:  77%|███████▋  | 12515/16329 [1:45:22<32:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12515: train loss 1.20103. lr 4.075776e-04:  77%|███████▋  | 12515/16329 [1:45:22<32:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12515: train loss 1.20103. lr 4.075776e-04:  77%|███████▋  | 12516/16329 [1:45:22<35:50,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 12516: train loss 1.23163. lr 4.075507e-04:  77%|███████▋  | 12516/16329 [1:45:23<35:50,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 12516: train loss 1.23163. lr 4.075507e-04:  77%|███████▋  | 12517/16329 [1:45:23<34:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12517: train loss 1.19443. lr 4.075238e-04:  77%|███████▋  | 12517/16329 [1:45:23<34:37,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 12517: train loss 1.19443. lr 4.075238e-04:  77%|███████▋  | 12518/16329 [1:45:23<33:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12518: train loss 1.22571. lr 4.074968e-04:  77%|███████▋  | 12518/16329 [1:45:24<33:44,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12518: train loss 1.22571. lr 4.074968e-04:  77%|███████▋  | 12519/16329 [1:45:24<32:58,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12519: train loss 1.23509. lr 4.074699e-04:  77%|███████▋  | 12519/16329 [1:45:24<32:58,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12519: train loss 1.23509. lr 4.074699e-04:  77%|███████▋  | 12520/16329 [1:45:24<32:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12520: train loss 1.24239. lr 4.074429e-04:  77%|███████▋  | 12520/16329 [1:45:25<32:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12520: train loss 1.24239. lr 4.074429e-04:  77%|███████▋  | 12521/16329 [1:45:25<32:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12521: train loss 1.20480. lr 4.074160e-04:  77%|███████▋  | 12521/16329 [1:45:25<32:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12521: train loss 1.20480. lr 4.074160e-04:  77%|███████▋  | 12522/16329 [1:45:25<31:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12522: train loss 1.21595. lr 4.073890e-04:  77%|███████▋  | 12522/16329 [1:45:26<31:54,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12522: train loss 1.21595. lr 4.073890e-04:  77%|███████▋  | 12523/16329 [1:45:26<31:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12523: train loss 1.21604. lr 4.073621e-04:  77%|███████▋  | 12523/16329 [1:45:26<31:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12523: train loss 1.21604. lr 4.073621e-04:  77%|███████▋  | 12524/16329 [1:45:26<31:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12524: train loss 1.23839. lr 4.073351e-04:  77%|███████▋  | 12524/16329 [1:45:27<31:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12524: train loss 1.23839. lr 4.073351e-04:  77%|███████▋  | 12525/16329 [1:45:27<31:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12525: train loss 1.26436. lr 4.073082e-04:  77%|███████▋  | 12525/16329 [1:45:27<31:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12525: train loss 1.26436. lr 4.073082e-04:  77%|███████▋  | 12526/16329 [1:45:27<31:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12526: train loss 1.21131. lr 4.072812e-04:  77%|███████▋  | 12526/16329 [1:45:28<31:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12526: train loss 1.21131. lr 4.072812e-04:  77%|███████▋  | 12527/16329 [1:45:28<31:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12527: train loss 1.21242. lr 4.072543e-04:  77%|███████▋  | 12527/16329 [1:45:28<31:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12527: train loss 1.21242. lr 4.072543e-04:  77%|███████▋  | 12528/16329 [1:45:28<31:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12528: train loss 1.20087. lr 4.072273e-04:  77%|███████▋  | 12528/16329 [1:45:29<31:16,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12528: train loss 1.20087. lr 4.072273e-04:  77%|███████▋  | 12529/16329 [1:45:29<31:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12529: train loss 1.21435. lr 4.072004e-04:  77%|███████▋  | 12529/16329 [1:45:29<31:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12529: train loss 1.21435. lr 4.072004e-04:  77%|███████▋  | 12530/16329 [1:45:29<31:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12530: train loss 1.23986. lr 4.071734e-04:  77%|███████▋  | 12530/16329 [1:45:30<31:15,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12530: train loss 1.23986. lr 4.071734e-04:  77%|███████▋  | 12531/16329 [1:45:30<31:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12531: train loss 1.20511. lr 4.071465e-04:  77%|███████▋  | 12531/16329 [1:45:30<31:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12531: train loss 1.20511. lr 4.071465e-04:  77%|███████▋  | 12532/16329 [1:45:30<31:12,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12532: train loss 1.22819. lr 4.071195e-04:  77%|███████▋  | 12532/16329 [1:45:31<31:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12532: train loss 1.22819. lr 4.071195e-04:  77%|███████▋  | 12533/16329 [1:45:31<31:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12533: train loss 1.23870. lr 4.070925e-04:  77%|███████▋  | 12533/16329 [1:45:31<31:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12533: train loss 1.23870. lr 4.070925e-04:  77%|███████▋  | 12534/16329 [1:45:31<31:04,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 12534: train loss 1.18656. lr 4.070656e-04:  77%|███████▋  | 12534/16329 [1:45:32<31:04,  2.04it/s]\u001b[A\n",
      "epoch 1 iter 12534: train loss 1.18656. lr 4.070656e-04:  77%|███████▋  | 12535/16329 [1:45:32<31:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12535: train loss 1.21715. lr 4.070386e-04:  77%|███████▋  | 12535/16329 [1:45:32<31:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12535: train loss 1.21715. lr 4.070386e-04:  77%|███████▋  | 12536/16329 [1:45:32<31:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12536: train loss 1.18099. lr 4.070117e-04:  77%|███████▋  | 12536/16329 [1:45:33<31:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12536: train loss 1.18099. lr 4.070117e-04:  77%|███████▋  | 12537/16329 [1:45:33<31:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12537: train loss 1.21238. lr 4.069847e-04:  77%|███████▋  | 12537/16329 [1:45:33<31:11,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12537: train loss 1.21238. lr 4.069847e-04:  77%|███████▋  | 12538/16329 [1:45:33<31:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12538: train loss 1.23090. lr 4.069577e-04:  77%|███████▋  | 12538/16329 [1:45:34<31:08,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12538: train loss 1.23090. lr 4.069577e-04:  77%|███████▋  | 12539/16329 [1:45:34<31:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12539: train loss 1.21945. lr 4.069308e-04:  77%|███████▋  | 12539/16329 [1:45:34<31:04,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12539: train loss 1.21945. lr 4.069308e-04:  77%|███████▋  | 12540/16329 [1:45:34<31:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12540: train loss 1.21329. lr 4.069038e-04:  77%|███████▋  | 12540/16329 [1:45:35<31:06,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12540: train loss 1.21329. lr 4.069038e-04:  77%|███████▋  | 12541/16329 [1:45:35<34:56,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 12541: train loss 1.22866. lr 4.068768e-04:  77%|███████▋  | 12541/16329 [1:45:35<34:56,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 12541: train loss 1.22866. lr 4.068768e-04:  77%|███████▋  | 12542/16329 [1:45:35<33:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12542: train loss 1.23697. lr 4.068499e-04:  77%|███████▋  | 12542/16329 [1:45:36<33:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12542: train loss 1.23697. lr 4.068499e-04:  77%|███████▋  | 12543/16329 [1:45:36<32:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12543: train loss 1.23231. lr 4.068229e-04:  77%|███████▋  | 12543/16329 [1:45:36<32:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12543: train loss 1.23231. lr 4.068229e-04:  77%|███████▋  | 12544/16329 [1:45:36<32:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12544: train loss 1.26747. lr 4.067959e-04:  77%|███████▋  | 12544/16329 [1:45:37<32:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12544: train loss 1.26747. lr 4.067959e-04:  77%|███████▋  | 12545/16329 [1:45:37<31:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12545: train loss 1.20904. lr 4.067690e-04:  77%|███████▋  | 12545/16329 [1:45:37<31:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12545: train loss 1.20904. lr 4.067690e-04:  77%|███████▋  | 12546/16329 [1:45:37<31:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12546: train loss 1.21232. lr 4.067420e-04:  77%|███████▋  | 12546/16329 [1:45:38<31:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12546: train loss 1.21232. lr 4.067420e-04:  77%|███████▋  | 12547/16329 [1:45:38<31:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12547: train loss 1.24526. lr 4.067150e-04:  77%|███████▋  | 12547/16329 [1:45:38<31:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12547: train loss 1.24526. lr 4.067150e-04:  77%|███████▋  | 12548/16329 [1:45:38<31:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12548: train loss 1.21519. lr 4.066880e-04:  77%|███████▋  | 12548/16329 [1:45:39<31:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12548: train loss 1.21519. lr 4.066880e-04:  77%|███████▋  | 12549/16329 [1:45:39<31:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12549: train loss 1.19273. lr 4.066611e-04:  77%|███████▋  | 12549/16329 [1:45:39<31:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12549: train loss 1.19273. lr 4.066611e-04:  77%|███████▋  | 12550/16329 [1:45:39<31:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12550: train loss 1.25812. lr 4.066341e-04:  77%|███████▋  | 12550/16329 [1:45:40<31:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12550: train loss 1.25812. lr 4.066341e-04:  77%|███████▋  | 12551/16329 [1:45:40<31:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12551: train loss 1.23931. lr 4.066071e-04:  77%|███████▋  | 12551/16329 [1:45:40<31:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12551: train loss 1.23931. lr 4.066071e-04:  77%|███████▋  | 12552/16329 [1:45:40<31:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12552: train loss 1.23971. lr 4.065801e-04:  77%|███████▋  | 12552/16329 [1:45:41<31:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12552: train loss 1.23971. lr 4.065801e-04:  77%|███████▋  | 12553/16329 [1:45:41<31:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12553: train loss 1.21989. lr 4.065532e-04:  77%|███████▋  | 12553/16329 [1:45:41<31:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12553: train loss 1.21989. lr 4.065532e-04:  77%|███████▋  | 12554/16329 [1:45:41<31:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12554: train loss 1.23836. lr 4.065262e-04:  77%|███████▋  | 12554/16329 [1:45:42<31:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12554: train loss 1.23836. lr 4.065262e-04:  77%|███████▋  | 12555/16329 [1:45:42<31:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12555: train loss 1.21160. lr 4.064992e-04:  77%|███████▋  | 12555/16329 [1:45:42<31:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12555: train loss 1.21160. lr 4.064992e-04:  77%|███████▋  | 12556/16329 [1:45:42<31:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12556: train loss 1.21534. lr 4.064722e-04:  77%|███████▋  | 12556/16329 [1:45:43<31:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12556: train loss 1.21534. lr 4.064722e-04:  77%|███████▋  | 12557/16329 [1:45:43<31:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12557: train loss 1.20286. lr 4.064452e-04:  77%|███████▋  | 12557/16329 [1:45:43<31:01,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12557: train loss 1.20286. lr 4.064452e-04:  77%|███████▋  | 12558/16329 [1:45:43<31:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12558: train loss 1.23914. lr 4.064183e-04:  77%|███████▋  | 12558/16329 [1:45:44<31:00,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12558: train loss 1.23914. lr 4.064183e-04:  77%|███████▋  | 12559/16329 [1:45:44<31:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12559: train loss 1.20246. lr 4.063913e-04:  77%|███████▋  | 12559/16329 [1:45:44<31:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12559: train loss 1.20246. lr 4.063913e-04:  77%|███████▋  | 12560/16329 [1:45:44<30:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12560: train loss 1.22756. lr 4.063643e-04:  77%|███████▋  | 12560/16329 [1:45:45<30:58,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12560: train loss 1.22756. lr 4.063643e-04:  77%|███████▋  | 12561/16329 [1:45:45<30:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12561: train loss 1.22745. lr 4.063373e-04:  77%|███████▋  | 12561/16329 [1:45:45<30:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12561: train loss 1.22745. lr 4.063373e-04:  77%|███████▋  | 12562/16329 [1:45:45<30:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12562: train loss 1.26367. lr 4.063103e-04:  77%|███████▋  | 12562/16329 [1:45:46<30:56,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12562: train loss 1.26367. lr 4.063103e-04:  77%|███████▋  | 12563/16329 [1:45:46<30:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12563: train loss 1.23215. lr 4.062833e-04:  77%|███████▋  | 12563/16329 [1:45:46<30:57,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12563: train loss 1.23215. lr 4.062833e-04:  77%|███████▋  | 12564/16329 [1:45:46<30:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12564: train loss 1.24813. lr 4.062563e-04:  77%|███████▋  | 12564/16329 [1:45:47<30:59,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12564: train loss 1.24813. lr 4.062563e-04:  77%|███████▋  | 12565/16329 [1:45:47<30:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12565: train loss 1.25098. lr 4.062294e-04:  77%|███████▋  | 12565/16329 [1:45:47<30:55,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12565: train loss 1.25098. lr 4.062294e-04:  77%|███████▋  | 12566/16329 [1:45:47<30:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12566: train loss 1.23794. lr 4.062024e-04:  77%|███████▋  | 12566/16329 [1:45:48<30:52,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12566: train loss 1.23794. lr 4.062024e-04:  77%|███████▋  | 12567/16329 [1:45:48<30:54,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12567: train loss 1.18553. lr 4.061754e-04:  77%|███████▋  | 12567/16329 [1:45:48<30:54,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12567: train loss 1.18553. lr 4.061754e-04:  77%|███████▋  | 12568/16329 [1:45:48<34:33,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 12568: train loss 1.16719. lr 4.061484e-04:  77%|███████▋  | 12568/16329 [1:45:49<34:33,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 12568: train loss 1.16719. lr 4.061484e-04:  77%|███████▋  | 12569/16329 [1:45:49<33:33,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12569: train loss 1.27188. lr 4.061214e-04:  77%|███████▋  | 12569/16329 [1:45:49<33:33,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12569: train loss 1.27188. lr 4.061214e-04:  77%|███████▋  | 12570/16329 [1:45:49<32:42,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12570: train loss 1.24205. lr 4.060944e-04:  77%|███████▋  | 12570/16329 [1:45:50<32:42,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12570: train loss 1.24205. lr 4.060944e-04:  77%|███████▋  | 12571/16329 [1:45:50<32:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12571: train loss 1.20311. lr 4.060674e-04:  77%|███████▋  | 12571/16329 [1:45:50<32:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12571: train loss 1.20311. lr 4.060674e-04:  77%|███████▋  | 12572/16329 [1:45:50<31:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12572: train loss 1.24973. lr 4.060404e-04:  77%|███████▋  | 12572/16329 [1:45:51<31:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12572: train loss 1.24973. lr 4.060404e-04:  77%|███████▋  | 12573/16329 [1:45:51<31:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12573: train loss 1.23555. lr 4.060134e-04:  77%|███████▋  | 12573/16329 [1:45:51<31:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12573: train loss 1.23555. lr 4.060134e-04:  77%|███████▋  | 12574/16329 [1:45:51<31:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12574: train loss 1.21125. lr 4.059864e-04:  77%|███████▋  | 12574/16329 [1:45:52<31:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12574: train loss 1.21125. lr 4.059864e-04:  77%|███████▋  | 12575/16329 [1:45:52<31:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12575: train loss 1.18542. lr 4.059594e-04:  77%|███████▋  | 12575/16329 [1:45:52<31:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12575: train loss 1.18542. lr 4.059594e-04:  77%|███████▋  | 12576/16329 [1:45:52<30:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12576: train loss 1.20973. lr 4.059324e-04:  77%|███████▋  | 12576/16329 [1:45:53<30:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12576: train loss 1.20973. lr 4.059324e-04:  77%|███████▋  | 12577/16329 [1:45:53<30:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12577: train loss 1.24692. lr 4.059054e-04:  77%|███████▋  | 12577/16329 [1:45:53<30:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12577: train loss 1.24692. lr 4.059054e-04:  77%|███████▋  | 12578/16329 [1:45:53<30:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12578: train loss 1.20756. lr 4.058784e-04:  77%|███████▋  | 12578/16329 [1:45:54<30:49,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12578: train loss 1.20756. lr 4.058784e-04:  77%|███████▋  | 12579/16329 [1:45:54<30:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12579: train loss 1.21743. lr 4.058514e-04:  77%|███████▋  | 12579/16329 [1:45:54<30:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12579: train loss 1.21743. lr 4.058514e-04:  77%|███████▋  | 12580/16329 [1:45:54<30:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12580: train loss 1.21581. lr 4.058244e-04:  77%|███████▋  | 12580/16329 [1:45:55<30:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12580: train loss 1.21581. lr 4.058244e-04:  77%|███████▋  | 12581/16329 [1:45:55<30:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12581: train loss 1.23915. lr 4.057974e-04:  77%|███████▋  | 12581/16329 [1:45:55<30:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12581: train loss 1.23915. lr 4.057974e-04:  77%|███████▋  | 12582/16329 [1:45:55<30:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12582: train loss 1.22838. lr 4.057704e-04:  77%|███████▋  | 12582/16329 [1:45:56<30:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12582: train loss 1.22838. lr 4.057704e-04:  77%|███████▋  | 12583/16329 [1:45:56<30:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12583: train loss 1.21140. lr 4.057434e-04:  77%|███████▋  | 12583/16329 [1:45:56<30:45,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12583: train loss 1.21140. lr 4.057434e-04:  77%|███████▋  | 12584/16329 [1:45:56<30:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12584: train loss 1.20686. lr 4.057164e-04:  77%|███████▋  | 12584/16329 [1:45:57<30:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12584: train loss 1.20686. lr 4.057164e-04:  77%|███████▋  | 12585/16329 [1:45:57<31:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12585: train loss 1.22854. lr 4.056893e-04:  77%|███████▋  | 12585/16329 [1:45:57<31:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12585: train loss 1.22854. lr 4.056893e-04:  77%|███████▋  | 12586/16329 [1:45:57<31:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12586: train loss 1.21826. lr 4.056623e-04:  77%|███████▋  | 12586/16329 [1:45:58<31:30,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12586: train loss 1.21826. lr 4.056623e-04:  77%|███████▋  | 12587/16329 [1:45:58<31:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12587: train loss 1.22519. lr 4.056353e-04:  77%|███████▋  | 12587/16329 [1:45:58<31:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12587: train loss 1.22519. lr 4.056353e-04:  77%|███████▋  | 12588/16329 [1:45:58<31:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12588: train loss 1.19178. lr 4.056083e-04:  77%|███████▋  | 12588/16329 [1:45:59<31:33,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12588: train loss 1.19178. lr 4.056083e-04:  77%|███████▋  | 12589/16329 [1:45:59<31:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12589: train loss 1.23209. lr 4.055813e-04:  77%|███████▋  | 12589/16329 [1:45:59<31:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12589: train loss 1.23209. lr 4.055813e-04:  77%|███████▋  | 12590/16329 [1:45:59<31:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12590: train loss 1.24022. lr 4.055543e-04:  77%|███████▋  | 12590/16329 [1:46:00<31:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12590: train loss 1.24022. lr 4.055543e-04:  77%|███████▋  | 12591/16329 [1:46:00<30:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12591: train loss 1.22183. lr 4.055273e-04:  77%|███████▋  | 12591/16329 [1:46:00<30:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12591: train loss 1.22183. lr 4.055273e-04:  77%|███████▋  | 12592/16329 [1:46:00<30:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12592: train loss 1.22914. lr 4.055003e-04:  77%|███████▋  | 12592/16329 [1:46:01<30:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12592: train loss 1.22914. lr 4.055003e-04:  77%|███████▋  | 12593/16329 [1:46:01<30:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12593: train loss 1.24074. lr 4.054732e-04:  77%|███████▋  | 12593/16329 [1:46:01<30:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12593: train loss 1.24074. lr 4.054732e-04:  77%|███████▋  | 12594/16329 [1:46:01<30:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12594: train loss 1.23920. lr 4.054462e-04:  77%|███████▋  | 12594/16329 [1:46:02<30:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12594: train loss 1.23920. lr 4.054462e-04:  77%|███████▋  | 12595/16329 [1:46:02<30:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12595: train loss 1.20922. lr 4.054192e-04:  77%|███████▋  | 12595/16329 [1:46:02<30:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12595: train loss 1.20922. lr 4.054192e-04:  77%|███████▋  | 12596/16329 [1:46:02<30:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12596: train loss 1.20311. lr 4.053922e-04:  77%|███████▋  | 12596/16329 [1:46:03<30:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12596: train loss 1.20311. lr 4.053922e-04:  77%|███████▋  | 12597/16329 [1:46:03<30:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12597: train loss 1.25480. lr 4.053652e-04:  77%|███████▋  | 12597/16329 [1:46:03<30:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12597: train loss 1.25480. lr 4.053652e-04:  77%|███████▋  | 12598/16329 [1:46:03<30:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12598: train loss 1.22686. lr 4.053381e-04:  77%|███████▋  | 12598/16329 [1:46:04<30:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12598: train loss 1.22686. lr 4.053381e-04:  77%|███████▋  | 12599/16329 [1:46:04<30:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12599: train loss 1.22826. lr 4.053111e-04:  77%|███████▋  | 12599/16329 [1:46:04<30:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12599: train loss 1.22826. lr 4.053111e-04:  77%|███████▋  | 12600/16329 [1:46:04<30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12600: train loss 1.23578. lr 4.052841e-04:  77%|███████▋  | 12600/16329 [1:46:05<30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12600: train loss 1.23578. lr 4.052841e-04:  77%|███████▋  | 12601/16329 [1:46:05<30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12601: train loss 1.23141. lr 4.052571e-04:  77%|███████▋  | 12601/16329 [1:46:05<30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12601: train loss 1.23141. lr 4.052571e-04:  77%|███████▋  | 12602/16329 [1:46:05<30:37,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12602: train loss 1.18472. lr 4.052300e-04:  77%|███████▋  | 12602/16329 [1:46:06<30:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12602: train loss 1.18472. lr 4.052300e-04:  77%|███████▋  | 12603/16329 [1:46:06<30:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12603: train loss 1.20029. lr 4.052030e-04:  77%|███████▋  | 12603/16329 [1:46:06<30:37,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12603: train loss 1.20029. lr 4.052030e-04:  77%|███████▋  | 12604/16329 [1:46:06<30:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12604: train loss 1.25070. lr 4.051760e-04:  77%|███████▋  | 12604/16329 [1:46:07<30:35,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12604: train loss 1.25070. lr 4.051760e-04:  77%|███████▋  | 12605/16329 [1:46:07<30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12605: train loss 1.26639. lr 4.051490e-04:  77%|███████▋  | 12605/16329 [1:46:07<30:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12605: train loss 1.26639. lr 4.051490e-04:  77%|███████▋  | 12606/16329 [1:46:07<30:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12606: train loss 1.22619. lr 4.051219e-04:  77%|███████▋  | 12606/16329 [1:46:08<30:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12606: train loss 1.22619. lr 4.051219e-04:  77%|███████▋  | 12607/16329 [1:46:08<30:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12607: train loss 1.21632. lr 4.050949e-04:  77%|███████▋  | 12607/16329 [1:46:08<30:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12607: train loss 1.21632. lr 4.050949e-04:  77%|███████▋  | 12608/16329 [1:46:08<34:02,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12608: train loss 1.25903. lr 4.050679e-04:  77%|███████▋  | 12608/16329 [1:46:09<34:02,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12608: train loss 1.25903. lr 4.050679e-04:  77%|███████▋  | 12609/16329 [1:46:09<32:57,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12609: train loss 1.24083. lr 4.050408e-04:  77%|███████▋  | 12609/16329 [1:46:09<32:57,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12609: train loss 1.24083. lr 4.050408e-04:  77%|███████▋  | 12610/16329 [1:46:09<32:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12610: train loss 1.23599. lr 4.050138e-04:  77%|███████▋  | 12610/16329 [1:46:10<32:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12610: train loss 1.23599. lr 4.050138e-04:  77%|███████▋  | 12611/16329 [1:46:10<31:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12611: train loss 1.21365. lr 4.049868e-04:  77%|███████▋  | 12611/16329 [1:46:10<31:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12611: train loss 1.21365. lr 4.049868e-04:  77%|███████▋  | 12612/16329 [1:46:10<31:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12612: train loss 1.19699. lr 4.049597e-04:  77%|███████▋  | 12612/16329 [1:46:11<31:21,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12612: train loss 1.19699. lr 4.049597e-04:  77%|███████▋  | 12613/16329 [1:46:11<31:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12613: train loss 1.22792. lr 4.049327e-04:  77%|███████▋  | 12613/16329 [1:46:11<31:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12613: train loss 1.22792. lr 4.049327e-04:  77%|███████▋  | 12614/16329 [1:46:11<30:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12614: train loss 1.24764. lr 4.049056e-04:  77%|███████▋  | 12614/16329 [1:46:12<30:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12614: train loss 1.24764. lr 4.049056e-04:  77%|███████▋  | 12615/16329 [1:46:12<30:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12615: train loss 1.21349. lr 4.048786e-04:  77%|███████▋  | 12615/16329 [1:46:12<30:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12615: train loss 1.21349. lr 4.048786e-04:  77%|███████▋  | 12616/16329 [1:46:12<30:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12616: train loss 1.26129. lr 4.048516e-04:  77%|███████▋  | 12616/16329 [1:46:13<30:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12616: train loss 1.26129. lr 4.048516e-04:  77%|███████▋  | 12617/16329 [1:46:13<30:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12617: train loss 1.25847. lr 4.048245e-04:  77%|███████▋  | 12617/16329 [1:46:13<30:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12617: train loss 1.25847. lr 4.048245e-04:  77%|███████▋  | 12618/16329 [1:46:13<30:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12618: train loss 1.20111. lr 4.047975e-04:  77%|███████▋  | 12618/16329 [1:46:14<30:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12618: train loss 1.20111. lr 4.047975e-04:  77%|███████▋  | 12619/16329 [1:46:14<30:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12619: train loss 1.25630. lr 4.047704e-04:  77%|███████▋  | 12619/16329 [1:46:14<30:31,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12619: train loss 1.25630. lr 4.047704e-04:  77%|███████▋  | 12620/16329 [1:46:14<30:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12620: train loss 1.18837. lr 4.047434e-04:  77%|███████▋  | 12620/16329 [1:46:15<30:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12620: train loss 1.18837. lr 4.047434e-04:  77%|███████▋  | 12621/16329 [1:46:15<30:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12621: train loss 1.21648. lr 4.047164e-04:  77%|███████▋  | 12621/16329 [1:46:15<30:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12621: train loss 1.21648. lr 4.047164e-04:  77%|███████▋  | 12622/16329 [1:46:15<30:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12622: train loss 1.22752. lr 4.046893e-04:  77%|███████▋  | 12622/16329 [1:46:16<30:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12622: train loss 1.22752. lr 4.046893e-04:  77%|███████▋  | 12623/16329 [1:46:16<30:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12623: train loss 1.21657. lr 4.046623e-04:  77%|███████▋  | 12623/16329 [1:46:16<30:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12623: train loss 1.21657. lr 4.046623e-04:  77%|███████▋  | 12624/16329 [1:46:16<30:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12624: train loss 1.22940. lr 4.046352e-04:  77%|███████▋  | 12624/16329 [1:46:17<30:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12624: train loss 1.22940. lr 4.046352e-04:  77%|███████▋  | 12625/16329 [1:46:17<30:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12625: train loss 1.20275. lr 4.046082e-04:  77%|███████▋  | 12625/16329 [1:46:17<30:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12625: train loss 1.20275. lr 4.046082e-04:  77%|███████▋  | 12626/16329 [1:46:17<30:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12626: train loss 1.20736. lr 4.045811e-04:  77%|███████▋  | 12626/16329 [1:46:18<30:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12626: train loss 1.20736. lr 4.045811e-04:  77%|███████▋  | 12627/16329 [1:46:18<30:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12627: train loss 1.23635. lr 4.045541e-04:  77%|███████▋  | 12627/16329 [1:46:18<30:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12627: train loss 1.23635. lr 4.045541e-04:  77%|███████▋  | 12628/16329 [1:46:18<30:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12628: train loss 1.22572. lr 4.045270e-04:  77%|███████▋  | 12628/16329 [1:46:19<30:27,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12628: train loss 1.22572. lr 4.045270e-04:  77%|███████▋  | 12629/16329 [1:46:19<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12629: train loss 1.20959. lr 4.045000e-04:  77%|███████▋  | 12629/16329 [1:46:19<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12629: train loss 1.20959. lr 4.045000e-04:  77%|███████▋  | 12630/16329 [1:46:19<30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12630: train loss 1.23288. lr 4.044729e-04:  77%|███████▋  | 12630/16329 [1:46:20<30:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12630: train loss 1.23288. lr 4.044729e-04:  77%|███████▋  | 12631/16329 [1:46:20<30:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12631: train loss 1.22879. lr 4.044459e-04:  77%|███████▋  | 12631/16329 [1:46:20<30:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12631: train loss 1.22879. lr 4.044459e-04:  77%|███████▋  | 12632/16329 [1:46:20<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12632: train loss 1.21400. lr 4.044188e-04:  77%|███████▋  | 12632/16329 [1:46:21<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12632: train loss 1.21400. lr 4.044188e-04:  77%|███████▋  | 12633/16329 [1:46:21<30:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12633: train loss 1.20175. lr 4.043917e-04:  77%|███████▋  | 12633/16329 [1:46:21<30:24,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12633: train loss 1.20175. lr 4.043917e-04:  77%|███████▋  | 12634/16329 [1:46:21<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12634: train loss 1.22942. lr 4.043647e-04:  77%|███████▋  | 12634/16329 [1:46:22<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12634: train loss 1.22942. lr 4.043647e-04:  77%|███████▋  | 12635/16329 [1:46:22<30:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12635: train loss 1.24358. lr 4.043376e-04:  77%|███████▋  | 12635/16329 [1:46:22<30:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12635: train loss 1.24358. lr 4.043376e-04:  77%|███████▋  | 12636/16329 [1:46:22<30:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12636: train loss 1.19403. lr 4.043106e-04:  77%|███████▋  | 12636/16329 [1:46:23<30:22,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 12636: train loss 1.19403. lr 4.043106e-04:  77%|███████▋  | 12637/16329 [1:46:23<30:28,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12637: train loss 1.17261. lr 4.042835e-04:  77%|███████▋  | 12637/16329 [1:46:23<30:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12637: train loss 1.17261. lr 4.042835e-04:  77%|███████▋  | 12638/16329 [1:46:23<31:01,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12638: train loss 1.24474. lr 4.042564e-04:  77%|███████▋  | 12638/16329 [1:46:24<31:01,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12638: train loss 1.24474. lr 4.042564e-04:  77%|███████▋  | 12639/16329 [1:46:24<31:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12639: train loss 1.22483. lr 4.042294e-04:  77%|███████▋  | 12639/16329 [1:46:24<31:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12639: train loss 1.22483. lr 4.042294e-04:  77%|███████▋  | 12640/16329 [1:46:24<31:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12640: train loss 1.22922. lr 4.042023e-04:  77%|███████▋  | 12640/16329 [1:46:25<31:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12640: train loss 1.22922. lr 4.042023e-04:  77%|███████▋  | 12641/16329 [1:46:25<31:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12641: train loss 1.20117. lr 4.041753e-04:  77%|███████▋  | 12641/16329 [1:46:25<31:44,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12641: train loss 1.20117. lr 4.041753e-04:  77%|███████▋  | 12642/16329 [1:46:25<32:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12642: train loss 1.24484. lr 4.041482e-04:  77%|███████▋  | 12642/16329 [1:46:26<32:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12642: train loss 1.24484. lr 4.041482e-04:  77%|███████▋  | 12643/16329 [1:46:26<35:21,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 12643: train loss 1.21528. lr 4.041211e-04:  77%|███████▋  | 12643/16329 [1:46:27<35:21,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 12643: train loss 1.21528. lr 4.041211e-04:  77%|███████▋  | 12644/16329 [1:46:27<34:12,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12644: train loss 1.21226. lr 4.040941e-04:  77%|███████▋  | 12644/16329 [1:46:27<34:12,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12644: train loss 1.21226. lr 4.040941e-04:  77%|███████▋  | 12645/16329 [1:46:27<33:17,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 12645: train loss 1.20298. lr 4.040670e-04:  77%|███████▋  | 12645/16329 [1:46:28<33:17,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 12645: train loss 1.20298. lr 4.040670e-04:  77%|███████▋  | 12646/16329 [1:46:28<32:31,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12646: train loss 1.21641. lr 4.040399e-04:  77%|███████▋  | 12646/16329 [1:46:28<32:31,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 12646: train loss 1.21641. lr 4.040399e-04:  77%|███████▋  | 12647/16329 [1:46:28<32:00,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12647: train loss 1.21057. lr 4.040129e-04:  77%|███████▋  | 12647/16329 [1:46:29<32:00,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12647: train loss 1.21057. lr 4.040129e-04:  77%|███████▋  | 12648/16329 [1:46:29<31:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12648: train loss 1.21380. lr 4.039858e-04:  77%|███████▋  | 12648/16329 [1:46:29<31:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12648: train loss 1.21380. lr 4.039858e-04:  77%|███████▋  | 12649/16329 [1:46:29<31:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12649: train loss 1.21048. lr 4.039587e-04:  77%|███████▋  | 12649/16329 [1:46:30<31:16,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12649: train loss 1.21048. lr 4.039587e-04:  77%|███████▋  | 12650/16329 [1:46:30<31:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12650: train loss 1.23304. lr 4.039316e-04:  77%|███████▋  | 12650/16329 [1:46:30<31:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12650: train loss 1.23304. lr 4.039316e-04:  77%|███████▋  | 12651/16329 [1:46:30<30:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12651: train loss 1.21718. lr 4.039046e-04:  77%|███████▋  | 12651/16329 [1:46:31<30:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12651: train loss 1.21718. lr 4.039046e-04:  77%|███████▋  | 12652/16329 [1:46:31<30:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12652: train loss 1.21570. lr 4.038775e-04:  77%|███████▋  | 12652/16329 [1:46:31<30:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12652: train loss 1.21570. lr 4.038775e-04:  77%|███████▋  | 12653/16329 [1:46:31<30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12653: train loss 1.24740. lr 4.038504e-04:  77%|███████▋  | 12653/16329 [1:46:32<30:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12653: train loss 1.24740. lr 4.038504e-04:  77%|███████▋  | 12654/16329 [1:46:32<31:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12654: train loss 1.20702. lr 4.038233e-04:  77%|███████▋  | 12654/16329 [1:46:32<31:46,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12654: train loss 1.20702. lr 4.038233e-04:  78%|███████▊  | 12655/16329 [1:46:32<32:09,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12655: train loss 1.21540. lr 4.037963e-04:  78%|███████▊  | 12655/16329 [1:46:33<32:09,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12655: train loss 1.21540. lr 4.037963e-04:  78%|███████▊  | 12656/16329 [1:46:33<32:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12656: train loss 1.20795. lr 4.037692e-04:  78%|███████▊  | 12656/16329 [1:46:33<32:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12656: train loss 1.20795. lr 4.037692e-04:  78%|███████▊  | 12657/16329 [1:46:33<32:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12657: train loss 1.22233. lr 4.037421e-04:  78%|███████▊  | 12657/16329 [1:46:34<32:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12657: train loss 1.22233. lr 4.037421e-04:  78%|███████▊  | 12658/16329 [1:46:34<31:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12658: train loss 1.20768. lr 4.037150e-04:  78%|███████▊  | 12658/16329 [1:46:34<31:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12658: train loss 1.20768. lr 4.037150e-04:  78%|███████▊  | 12659/16329 [1:46:34<31:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12659: train loss 1.22046. lr 4.036879e-04:  78%|███████▊  | 12659/16329 [1:46:35<31:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12659: train loss 1.22046. lr 4.036879e-04:  78%|███████▊  | 12660/16329 [1:46:35<31:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12660: train loss 1.20908. lr 4.036609e-04:  78%|███████▊  | 12660/16329 [1:46:35<31:20,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12660: train loss 1.20908. lr 4.036609e-04:  78%|███████▊  | 12661/16329 [1:46:35<31:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12661: train loss 1.21210. lr 4.036338e-04:  78%|███████▊  | 12661/16329 [1:46:36<31:04,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12661: train loss 1.21210. lr 4.036338e-04:  78%|███████▊  | 12662/16329 [1:46:36<30:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12662: train loss 1.20880. lr 4.036067e-04:  78%|███████▊  | 12662/16329 [1:46:36<30:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12662: train loss 1.20880. lr 4.036067e-04:  78%|███████▊  | 12663/16329 [1:46:36<30:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12663: train loss 1.23573. lr 4.035796e-04:  78%|███████▊  | 12663/16329 [1:46:37<30:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12663: train loss 1.23573. lr 4.035796e-04:  78%|███████▊  | 12664/16329 [1:46:37<30:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12664: train loss 1.23192. lr 4.035525e-04:  78%|███████▊  | 12664/16329 [1:46:37<30:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12664: train loss 1.23192. lr 4.035525e-04:  78%|███████▊  | 12665/16329 [1:46:37<30:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12665: train loss 1.21531. lr 4.035254e-04:  78%|███████▊  | 12665/16329 [1:46:38<30:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12665: train loss 1.21531. lr 4.035254e-04:  78%|███████▊  | 12666/16329 [1:46:38<30:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12666: train loss 1.22413. lr 4.034984e-04:  78%|███████▊  | 12666/16329 [1:46:38<30:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12666: train loss 1.22413. lr 4.034984e-04:  78%|███████▊  | 12667/16329 [1:46:38<30:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12667: train loss 1.21500. lr 4.034713e-04:  78%|███████▊  | 12667/16329 [1:46:39<30:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12667: train loss 1.21500. lr 4.034713e-04:  78%|███████▊  | 12668/16329 [1:46:39<33:32,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12668: train loss 1.24013. lr 4.034442e-04:  78%|███████▊  | 12668/16329 [1:46:39<33:32,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12668: train loss 1.24013. lr 4.034442e-04:  78%|███████▊  | 12669/16329 [1:46:39<32:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12669: train loss 1.18009. lr 4.034171e-04:  78%|███████▊  | 12669/16329 [1:46:40<32:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12669: train loss 1.18009. lr 4.034171e-04:  78%|███████▊  | 12670/16329 [1:46:40<31:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12670: train loss 1.20049. lr 4.033900e-04:  78%|███████▊  | 12670/16329 [1:46:40<31:53,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12670: train loss 1.20049. lr 4.033900e-04:  78%|███████▊  | 12671/16329 [1:46:40<31:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12671: train loss 1.23417. lr 4.033629e-04:  78%|███████▊  | 12671/16329 [1:46:41<31:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12671: train loss 1.23417. lr 4.033629e-04:  78%|███████▊  | 12672/16329 [1:46:41<30:56,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12672: train loss 1.24258. lr 4.033358e-04:  78%|███████▊  | 12672/16329 [1:46:41<30:56,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12672: train loss 1.24258. lr 4.033358e-04:  78%|███████▊  | 12673/16329 [1:46:41<30:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12673: train loss 1.26989. lr 4.033087e-04:  78%|███████▊  | 12673/16329 [1:46:42<30:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12673: train loss 1.26989. lr 4.033087e-04:  78%|███████▊  | 12674/16329 [1:46:42<30:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12674: train loss 1.23778. lr 4.032816e-04:  78%|███████▊  | 12674/16329 [1:46:42<30:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12674: train loss 1.23778. lr 4.032816e-04:  78%|███████▊  | 12675/16329 [1:46:42<30:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12675: train loss 1.21840. lr 4.032545e-04:  78%|███████▊  | 12675/16329 [1:46:43<30:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12675: train loss 1.21840. lr 4.032545e-04:  78%|███████▊  | 12676/16329 [1:46:43<30:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12676: train loss 1.21177. lr 4.032274e-04:  78%|███████▊  | 12676/16329 [1:46:43<30:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12676: train loss 1.21177. lr 4.032274e-04:  78%|███████▊  | 12677/16329 [1:46:43<30:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12677: train loss 1.23456. lr 4.032003e-04:  78%|███████▊  | 12677/16329 [1:46:44<30:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12677: train loss 1.23456. lr 4.032003e-04:  78%|███████▊  | 12678/16329 [1:46:44<30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12678: train loss 1.17182. lr 4.031732e-04:  78%|███████▊  | 12678/16329 [1:46:44<30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12678: train loss 1.17182. lr 4.031732e-04:  78%|███████▊  | 12679/16329 [1:46:44<30:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12679: train loss 1.24092. lr 4.031461e-04:  78%|███████▊  | 12679/16329 [1:46:45<30:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12679: train loss 1.24092. lr 4.031461e-04:  78%|███████▊  | 12680/16329 [1:46:45<30:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12680: train loss 1.21227. lr 4.031190e-04:  78%|███████▊  | 12680/16329 [1:46:45<30:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12680: train loss 1.21227. lr 4.031190e-04:  78%|███████▊  | 12681/16329 [1:46:45<30:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12681: train loss 1.18944. lr 4.030919e-04:  78%|███████▊  | 12681/16329 [1:46:46<30:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12681: train loss 1.18944. lr 4.030919e-04:  78%|███████▊  | 12682/16329 [1:46:46<30:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12682: train loss 1.22229. lr 4.030648e-04:  78%|███████▊  | 12682/16329 [1:46:46<30:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12682: train loss 1.22229. lr 4.030648e-04:  78%|███████▊  | 12683/16329 [1:46:46<30:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12683: train loss 1.21365. lr 4.030377e-04:  78%|███████▊  | 12683/16329 [1:46:47<30:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12683: train loss 1.21365. lr 4.030377e-04:  78%|███████▊  | 12684/16329 [1:46:47<30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12684: train loss 1.19516. lr 4.030106e-04:  78%|███████▊  | 12684/16329 [1:46:47<30:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12684: train loss 1.19516. lr 4.030106e-04:  78%|███████▊  | 12685/16329 [1:46:47<30:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12685: train loss 1.18437. lr 4.029835e-04:  78%|███████▊  | 12685/16329 [1:46:48<30:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12685: train loss 1.18437. lr 4.029835e-04:  78%|███████▊  | 12686/16329 [1:46:48<30:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12686: train loss 1.21370. lr 4.029564e-04:  78%|███████▊  | 12686/16329 [1:46:48<30:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12686: train loss 1.21370. lr 4.029564e-04:  78%|███████▊  | 12687/16329 [1:46:48<30:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12687: train loss 1.20369. lr 4.029293e-04:  78%|███████▊  | 12687/16329 [1:46:49<30:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12687: train loss 1.20369. lr 4.029293e-04:  78%|███████▊  | 12688/16329 [1:46:49<30:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12688: train loss 1.21880. lr 4.029022e-04:  78%|███████▊  | 12688/16329 [1:46:49<30:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12688: train loss 1.21880. lr 4.029022e-04:  78%|███████▊  | 12689/16329 [1:46:49<30:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12689: train loss 1.21553. lr 4.028751e-04:  78%|███████▊  | 12689/16329 [1:46:50<30:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12689: train loss 1.21553. lr 4.028751e-04:  78%|███████▊  | 12690/16329 [1:46:50<30:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12690: train loss 1.23086. lr 4.028480e-04:  78%|███████▊  | 12690/16329 [1:46:50<30:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12690: train loss 1.23086. lr 4.028480e-04:  78%|███████▊  | 12691/16329 [1:46:50<30:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12691: train loss 1.22117. lr 4.028208e-04:  78%|███████▊  | 12691/16329 [1:46:51<30:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12691: train loss 1.22117. lr 4.028208e-04:  78%|███████▊  | 12692/16329 [1:46:51<30:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12692: train loss 1.21402. lr 4.027937e-04:  78%|███████▊  | 12692/16329 [1:46:51<30:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12692: train loss 1.21402. lr 4.027937e-04:  78%|███████▊  | 12693/16329 [1:46:51<30:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12693: train loss 1.22580. lr 4.027666e-04:  78%|███████▊  | 12693/16329 [1:46:52<30:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12693: train loss 1.22580. lr 4.027666e-04:  78%|███████▊  | 12694/16329 [1:46:52<30:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12694: train loss 1.18855. lr 4.027395e-04:  78%|███████▊  | 12694/16329 [1:46:52<30:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12694: train loss 1.18855. lr 4.027395e-04:  78%|███████▊  | 12695/16329 [1:46:52<33:15,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12695: train loss 1.19902. lr 4.027124e-04:  78%|███████▊  | 12695/16329 [1:46:53<33:15,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12695: train loss 1.19902. lr 4.027124e-04:  78%|███████▊  | 12696/16329 [1:46:53<32:20,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12696: train loss 1.17721. lr 4.026853e-04:  78%|███████▊  | 12696/16329 [1:46:53<32:20,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12696: train loss 1.17721. lr 4.026853e-04:  78%|███████▊  | 12697/16329 [1:46:53<31:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12697: train loss 1.18898. lr 4.026582e-04:  78%|███████▊  | 12697/16329 [1:46:54<31:36,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12697: train loss 1.18898. lr 4.026582e-04:  78%|███████▊  | 12698/16329 [1:46:54<31:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12698: train loss 1.20921. lr 4.026310e-04:  78%|███████▊  | 12698/16329 [1:46:54<31:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12698: train loss 1.20921. lr 4.026310e-04:  78%|███████▊  | 12699/16329 [1:46:54<30:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12699: train loss 1.22119. lr 4.026039e-04:  78%|███████▊  | 12699/16329 [1:46:55<30:44,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12699: train loss 1.22119. lr 4.026039e-04:  78%|███████▊  | 12700/16329 [1:46:55<30:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12700: train loss 1.23385. lr 4.025768e-04:  78%|███████▊  | 12700/16329 [1:46:55<30:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12700: train loss 1.23385. lr 4.025768e-04:  78%|███████▊  | 12701/16329 [1:46:55<30:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12701: train loss 1.22447. lr 4.025497e-04:  78%|███████▊  | 12701/16329 [1:46:56<30:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12701: train loss 1.22447. lr 4.025497e-04:  78%|███████▊  | 12702/16329 [1:46:56<30:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12702: train loss 1.21046. lr 4.025225e-04:  78%|███████▊  | 12702/16329 [1:46:57<30:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12702: train loss 1.21046. lr 4.025225e-04:  78%|███████▊  | 12703/16329 [1:46:57<30:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12703: train loss 1.18802. lr 4.024954e-04:  78%|███████▊  | 12703/16329 [1:46:57<30:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12703: train loss 1.18802. lr 4.024954e-04:  78%|███████▊  | 12704/16329 [1:46:57<30:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12704: train loss 1.21352. lr 4.024683e-04:  78%|███████▊  | 12704/16329 [1:46:58<30:56,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12704: train loss 1.21352. lr 4.024683e-04:  78%|███████▊  | 12705/16329 [1:46:58<30:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12705: train loss 1.18281. lr 4.024412e-04:  78%|███████▊  | 12705/16329 [1:46:58<30:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12705: train loss 1.18281. lr 4.024412e-04:  78%|███████▊  | 12706/16329 [1:46:58<30:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12706: train loss 1.20030. lr 4.024140e-04:  78%|███████▊  | 12706/16329 [1:46:59<30:43,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12706: train loss 1.20030. lr 4.024140e-04:  78%|███████▊  | 12707/16329 [1:46:59<30:34,  1.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12707: train loss 1.17766. lr 4.023869e-04:  78%|███████▊  | 12707/16329 [1:46:59<30:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12707: train loss 1.17766. lr 4.023869e-04:  78%|███████▊  | 12708/16329 [1:46:59<30:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12708: train loss 1.19864. lr 4.023598e-04:  78%|███████▊  | 12708/16329 [1:47:00<30:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12708: train loss 1.19864. lr 4.023598e-04:  78%|███████▊  | 12709/16329 [1:47:00<30:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12709: train loss 1.20812. lr 4.023327e-04:  78%|███████▊  | 12709/16329 [1:47:00<30:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12709: train loss 1.20812. lr 4.023327e-04:  78%|███████▊  | 12710/16329 [1:47:00<30:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12710: train loss 1.23918. lr 4.023055e-04:  78%|███████▊  | 12710/16329 [1:47:01<30:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12710: train loss 1.23918. lr 4.023055e-04:  78%|███████▊  | 12711/16329 [1:47:01<30:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12711: train loss 1.23215. lr 4.022784e-04:  78%|███████▊  | 12711/16329 [1:47:01<30:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12711: train loss 1.23215. lr 4.022784e-04:  78%|███████▊  | 12712/16329 [1:47:01<30:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12712: train loss 1.22973. lr 4.022513e-04:  78%|███████▊  | 12712/16329 [1:47:02<30:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12712: train loss 1.22973. lr 4.022513e-04:  78%|███████▊  | 12713/16329 [1:47:02<29:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12713: train loss 1.24981. lr 4.022241e-04:  78%|███████▊  | 12713/16329 [1:47:02<29:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12713: train loss 1.24981. lr 4.022241e-04:  78%|███████▊  | 12714/16329 [1:47:02<29:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12714: train loss 1.21585. lr 4.021970e-04:  78%|███████▊  | 12714/16329 [1:47:03<29:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12714: train loss 1.21585. lr 4.021970e-04:  78%|███████▊  | 12715/16329 [1:47:03<29:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12715: train loss 1.25436. lr 4.021699e-04:  78%|███████▊  | 12715/16329 [1:47:03<29:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12715: train loss 1.25436. lr 4.021699e-04:  78%|███████▊  | 12716/16329 [1:47:03<29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12716: train loss 1.22516. lr 4.021427e-04:  78%|███████▊  | 12716/16329 [1:47:04<29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12716: train loss 1.22516. lr 4.021427e-04:  78%|███████▊  | 12717/16329 [1:47:04<29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12717: train loss 1.19888. lr 4.021156e-04:  78%|███████▊  | 12717/16329 [1:47:04<29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12717: train loss 1.19888. lr 4.021156e-04:  78%|███████▊  | 12718/16329 [1:47:04<29:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12718: train loss 1.22138. lr 4.020885e-04:  78%|███████▊  | 12718/16329 [1:47:04<29:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12718: train loss 1.22138. lr 4.020885e-04:  78%|███████▊  | 12719/16329 [1:47:04<29:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12719: train loss 1.20132. lr 4.020613e-04:  78%|███████▊  | 12719/16329 [1:47:05<29:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12719: train loss 1.20132. lr 4.020613e-04:  78%|███████▊  | 12720/16329 [1:47:05<29:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12720: train loss 1.22177. lr 4.020342e-04:  78%|███████▊  | 12720/16329 [1:47:05<29:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12720: train loss 1.22177. lr 4.020342e-04:  78%|███████▊  | 12721/16329 [1:47:05<29:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12721: train loss 1.21517. lr 4.020070e-04:  78%|███████▊  | 12721/16329 [1:47:06<29:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12721: train loss 1.21517. lr 4.020070e-04:  78%|███████▊  | 12722/16329 [1:47:06<29:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12722: train loss 1.20788. lr 4.019799e-04:  78%|███████▊  | 12722/16329 [1:47:06<29:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12722: train loss 1.20788. lr 4.019799e-04:  78%|███████▊  | 12723/16329 [1:47:06<29:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12723: train loss 1.16942. lr 4.019528e-04:  78%|███████▊  | 12723/16329 [1:47:07<29:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12723: train loss 1.16942. lr 4.019528e-04:  78%|███████▊  | 12724/16329 [1:47:07<29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12724: train loss 1.24136. lr 4.019256e-04:  78%|███████▊  | 12724/16329 [1:47:07<29:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12724: train loss 1.24136. lr 4.019256e-04:  78%|███████▊  | 12725/16329 [1:47:07<29:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12725: train loss 1.24312. lr 4.018985e-04:  78%|███████▊  | 12725/16329 [1:47:08<29:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12725: train loss 1.24312. lr 4.018985e-04:  78%|███████▊  | 12726/16329 [1:47:08<29:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12726: train loss 1.18607. lr 4.018713e-04:  78%|███████▊  | 12726/16329 [1:47:08<29:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12726: train loss 1.18607. lr 4.018713e-04:  78%|███████▊  | 12727/16329 [1:47:08<30:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12727: train loss 1.22987. lr 4.018442e-04:  78%|███████▊  | 12727/16329 [1:47:09<30:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12727: train loss 1.22987. lr 4.018442e-04:  78%|███████▊  | 12728/16329 [1:47:09<30:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12728: train loss 1.22364. lr 4.018170e-04:  78%|███████▊  | 12728/16329 [1:47:09<30:12,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12728: train loss 1.22364. lr 4.018170e-04:  78%|███████▊  | 12729/16329 [1:47:09<30:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12729: train loss 1.19656. lr 4.017899e-04:  78%|███████▊  | 12729/16329 [1:47:10<30:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12729: train loss 1.19656. lr 4.017899e-04:  78%|███████▊  | 12730/16329 [1:47:10<30:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12730: train loss 1.22487. lr 4.017627e-04:  78%|███████▊  | 12730/16329 [1:47:10<30:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12730: train loss 1.22487. lr 4.017627e-04:  78%|███████▊  | 12731/16329 [1:47:10<29:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12731: train loss 1.21961. lr 4.017356e-04:  78%|███████▊  | 12731/16329 [1:47:11<29:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12731: train loss 1.21961. lr 4.017356e-04:  78%|███████▊  | 12732/16329 [1:47:11<29:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12732: train loss 1.24272. lr 4.017084e-04:  78%|███████▊  | 12732/16329 [1:47:11<29:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12732: train loss 1.24272. lr 4.017084e-04:  78%|███████▊  | 12733/16329 [1:47:11<29:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12733: train loss 1.20261. lr 4.016813e-04:  78%|███████▊  | 12733/16329 [1:47:12<29:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12733: train loss 1.20261. lr 4.016813e-04:  78%|███████▊  | 12734/16329 [1:47:12<29:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12734: train loss 1.22869. lr 4.016541e-04:  78%|███████▊  | 12734/16329 [1:47:13<29:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12734: train loss 1.22869. lr 4.016541e-04:  78%|███████▊  | 12735/16329 [1:47:13<32:52,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12735: train loss 1.21462. lr 4.016270e-04:  78%|███████▊  | 12735/16329 [1:47:13<32:52,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12735: train loss 1.21462. lr 4.016270e-04:  78%|███████▊  | 12736/16329 [1:47:13<31:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12736: train loss 1.15751. lr 4.015998e-04:  78%|███████▊  | 12736/16329 [1:47:14<31:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12736: train loss 1.15751. lr 4.015998e-04:  78%|███████▊  | 12737/16329 [1:47:14<31:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12737: train loss 1.25957. lr 4.015727e-04:  78%|███████▊  | 12737/16329 [1:47:14<31:22,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12737: train loss 1.25957. lr 4.015727e-04:  78%|███████▊  | 12738/16329 [1:47:14<30:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12738: train loss 1.20875. lr 4.015455e-04:  78%|███████▊  | 12738/16329 [1:47:15<30:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12738: train loss 1.20875. lr 4.015455e-04:  78%|███████▊  | 12739/16329 [1:47:15<30:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12739: train loss 1.25196. lr 4.015184e-04:  78%|███████▊  | 12739/16329 [1:47:15<30:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12739: train loss 1.25196. lr 4.015184e-04:  78%|███████▊  | 12740/16329 [1:47:15<30:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12740: train loss 1.18121. lr 4.014912e-04:  78%|███████▊  | 12740/16329 [1:47:16<30:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12740: train loss 1.18121. lr 4.014912e-04:  78%|███████▊  | 12741/16329 [1:47:16<30:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12741: train loss 1.20028. lr 4.014640e-04:  78%|███████▊  | 12741/16329 [1:47:16<30:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12741: train loss 1.20028. lr 4.014640e-04:  78%|███████▊  | 12742/16329 [1:47:16<30:02,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12742: train loss 1.16913. lr 4.014369e-04:  78%|███████▊  | 12742/16329 [1:47:17<30:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12742: train loss 1.16913. lr 4.014369e-04:  78%|███████▊  | 12743/16329 [1:47:17<29:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12743: train loss 1.22502. lr 4.014097e-04:  78%|███████▊  | 12743/16329 [1:47:17<29:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12743: train loss 1.22502. lr 4.014097e-04:  78%|███████▊  | 12744/16329 [1:47:17<29:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12744: train loss 1.18975. lr 4.013826e-04:  78%|███████▊  | 12744/16329 [1:47:18<29:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12744: train loss 1.18975. lr 4.013826e-04:  78%|███████▊  | 12745/16329 [1:47:18<29:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12745: train loss 1.18094. lr 4.013554e-04:  78%|███████▊  | 12745/16329 [1:47:18<29:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12745: train loss 1.18094. lr 4.013554e-04:  78%|███████▊  | 12746/16329 [1:47:18<29:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12746: train loss 1.23825. lr 4.013282e-04:  78%|███████▊  | 12746/16329 [1:47:19<29:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12746: train loss 1.23825. lr 4.013282e-04:  78%|███████▊  | 12747/16329 [1:47:19<29:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12747: train loss 1.22130. lr 4.013011e-04:  78%|███████▊  | 12747/16329 [1:47:19<29:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12747: train loss 1.22130. lr 4.013011e-04:  78%|███████▊  | 12748/16329 [1:47:19<29:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12748: train loss 1.22361. lr 4.012739e-04:  78%|███████▊  | 12748/16329 [1:47:20<29:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12748: train loss 1.22361. lr 4.012739e-04:  78%|███████▊  | 12749/16329 [1:47:20<29:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12749: train loss 1.21784. lr 4.012467e-04:  78%|███████▊  | 12749/16329 [1:47:20<29:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12749: train loss 1.21784. lr 4.012467e-04:  78%|███████▊  | 12750/16329 [1:47:20<29:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12750: train loss 1.25043. lr 4.012196e-04:  78%|███████▊  | 12750/16329 [1:47:21<29:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12750: train loss 1.25043. lr 4.012196e-04:  78%|███████▊  | 12751/16329 [1:47:21<29:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12751: train loss 1.20000. lr 4.011924e-04:  78%|███████▊  | 12751/16329 [1:47:21<29:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12751: train loss 1.20000. lr 4.011924e-04:  78%|███████▊  | 12752/16329 [1:47:21<29:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12752: train loss 1.20503. lr 4.011652e-04:  78%|███████▊  | 12752/16329 [1:47:22<29:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12752: train loss 1.20503. lr 4.011652e-04:  78%|███████▊  | 12753/16329 [1:47:22<29:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12753: train loss 1.21032. lr 4.011381e-04:  78%|███████▊  | 12753/16329 [1:47:22<29:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12753: train loss 1.21032. lr 4.011381e-04:  78%|███████▊  | 12754/16329 [1:47:22<29:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12754: train loss 1.23492. lr 4.011109e-04:  78%|███████▊  | 12754/16329 [1:47:23<29:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12754: train loss 1.23492. lr 4.011109e-04:  78%|███████▊  | 12755/16329 [1:47:23<29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12755: train loss 1.21059. lr 4.010837e-04:  78%|███████▊  | 12755/16329 [1:47:23<29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12755: train loss 1.21059. lr 4.010837e-04:  78%|███████▊  | 12756/16329 [1:47:23<29:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12756: train loss 1.22252. lr 4.010565e-04:  78%|███████▊  | 12756/16329 [1:47:24<29:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12756: train loss 1.22252. lr 4.010565e-04:  78%|███████▊  | 12757/16329 [1:47:24<29:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12757: train loss 1.22894. lr 4.010294e-04:  78%|███████▊  | 12757/16329 [1:47:24<29:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12757: train loss 1.22894. lr 4.010294e-04:  78%|███████▊  | 12758/16329 [1:47:24<29:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12758: train loss 1.21440. lr 4.010022e-04:  78%|███████▊  | 12758/16329 [1:47:25<29:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12758: train loss 1.21440. lr 4.010022e-04:  78%|███████▊  | 12759/16329 [1:47:25<29:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12759: train loss 1.19634. lr 4.009750e-04:  78%|███████▊  | 12759/16329 [1:47:25<29:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12759: train loss 1.19634. lr 4.009750e-04:  78%|███████▊  | 12760/16329 [1:47:25<29:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12760: train loss 1.17712. lr 4.009478e-04:  78%|███████▊  | 12760/16329 [1:47:26<29:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12760: train loss 1.17712. lr 4.009478e-04:  78%|███████▊  | 12761/16329 [1:47:26<29:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12761: train loss 1.22871. lr 4.009207e-04:  78%|███████▊  | 12761/16329 [1:47:26<29:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12761: train loss 1.22871. lr 4.009207e-04:  78%|███████▊  | 12762/16329 [1:47:26<29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12762: train loss 1.22592. lr 4.008935e-04:  78%|███████▊  | 12762/16329 [1:47:27<29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12762: train loss 1.22592. lr 4.008935e-04:  78%|███████▊  | 12763/16329 [1:47:27<29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12763: train loss 1.22426. lr 4.008663e-04:  78%|███████▊  | 12763/16329 [1:47:27<29:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12763: train loss 1.22426. lr 4.008663e-04:  78%|███████▊  | 12764/16329 [1:47:27<29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12764: train loss 1.20240. lr 4.008391e-04:  78%|███████▊  | 12764/16329 [1:47:28<29:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12764: train loss 1.20240. lr 4.008391e-04:  78%|███████▊  | 12765/16329 [1:47:28<29:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12765: train loss 1.22941. lr 4.008119e-04:  78%|███████▊  | 12765/16329 [1:47:28<29:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12765: train loss 1.22941. lr 4.008119e-04:  78%|███████▊  | 12766/16329 [1:47:28<30:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12766: train loss 1.21547. lr 4.007848e-04:  78%|███████▊  | 12766/16329 [1:47:29<30:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12766: train loss 1.21547. lr 4.007848e-04:  78%|███████▊  | 12767/16329 [1:47:29<30:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12767: train loss 1.19445. lr 4.007576e-04:  78%|███████▊  | 12767/16329 [1:47:29<30:34,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12767: train loss 1.19445. lr 4.007576e-04:  78%|███████▊  | 12768/16329 [1:47:29<30:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12768: train loss 1.19207. lr 4.007304e-04:  78%|███████▊  | 12768/16329 [1:47:30<30:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12768: train loss 1.19207. lr 4.007304e-04:  78%|███████▊  | 12769/16329 [1:47:30<30:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12769: train loss 1.18307. lr 4.007032e-04:  78%|███████▊  | 12769/16329 [1:47:30<30:43,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12769: train loss 1.18307. lr 4.007032e-04:  78%|███████▊  | 12770/16329 [1:47:30<33:44,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 12770: train loss 1.22366. lr 4.006760e-04:  78%|███████▊  | 12770/16329 [1:47:31<33:44,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 12770: train loss 1.22366. lr 4.006760e-04:  78%|███████▊  | 12771/16329 [1:47:31<32:36,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12771: train loss 1.21102. lr 4.006488e-04:  78%|███████▊  | 12771/16329 [1:47:31<32:36,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12771: train loss 1.21102. lr 4.006488e-04:  78%|███████▊  | 12772/16329 [1:47:31<31:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12772: train loss 1.23141. lr 4.006216e-04:  78%|███████▊  | 12772/16329 [1:47:32<31:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12772: train loss 1.23141. lr 4.006216e-04:  78%|███████▊  | 12773/16329 [1:47:32<31:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12773: train loss 1.21950. lr 4.005945e-04:  78%|███████▊  | 12773/16329 [1:47:32<31:06,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12773: train loss 1.21950. lr 4.005945e-04:  78%|███████▊  | 12774/16329 [1:47:32<30:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12774: train loss 1.20121. lr 4.005673e-04:  78%|███████▊  | 12774/16329 [1:47:33<30:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12774: train loss 1.20121. lr 4.005673e-04:  78%|███████▊  | 12775/16329 [1:47:33<30:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12775: train loss 1.19879. lr 4.005401e-04:  78%|███████▊  | 12775/16329 [1:47:33<30:18,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12775: train loss 1.19879. lr 4.005401e-04:  78%|███████▊  | 12776/16329 [1:47:33<30:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12776: train loss 1.20943. lr 4.005129e-04:  78%|███████▊  | 12776/16329 [1:47:34<30:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12776: train loss 1.20943. lr 4.005129e-04:  78%|███████▊  | 12777/16329 [1:47:34<29:47,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12777: train loss 1.21311. lr 4.004857e-04:  78%|███████▊  | 12777/16329 [1:47:34<29:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12777: train loss 1.21311. lr 4.004857e-04:  78%|███████▊  | 12778/16329 [1:47:34<29:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12778: train loss 1.20774. lr 4.004585e-04:  78%|███████▊  | 12778/16329 [1:47:35<29:41,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12778: train loss 1.20774. lr 4.004585e-04:  78%|███████▊  | 12779/16329 [1:47:35<29:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12779: train loss 1.18998. lr 4.004313e-04:  78%|███████▊  | 12779/16329 [1:47:35<29:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12779: train loss 1.18998. lr 4.004313e-04:  78%|███████▊  | 12780/16329 [1:47:35<29:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12780: train loss 1.16212. lr 4.004041e-04:  78%|███████▊  | 12780/16329 [1:47:36<29:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12780: train loss 1.16212. lr 4.004041e-04:  78%|███████▊  | 12781/16329 [1:47:36<29:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12781: train loss 1.18922. lr 4.003769e-04:  78%|███████▊  | 12781/16329 [1:47:36<29:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12781: train loss 1.18922. lr 4.003769e-04:  78%|███████▊  | 12782/16329 [1:47:36<29:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12782: train loss 1.16782. lr 4.003497e-04:  78%|███████▊  | 12782/16329 [1:47:37<29:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12782: train loss 1.16782. lr 4.003497e-04:  78%|███████▊  | 12783/16329 [1:47:37<29:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12783: train loss 1.19399. lr 4.003225e-04:  78%|███████▊  | 12783/16329 [1:47:37<29:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12783: train loss 1.19399. lr 4.003225e-04:  78%|███████▊  | 12784/16329 [1:47:37<29:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12784: train loss 1.19602. lr 4.002953e-04:  78%|███████▊  | 12784/16329 [1:47:38<29:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12784: train loss 1.19602. lr 4.002953e-04:  78%|███████▊  | 12785/16329 [1:47:38<29:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12785: train loss 1.20956. lr 4.002681e-04:  78%|███████▊  | 12785/16329 [1:47:38<29:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12785: train loss 1.20956. lr 4.002681e-04:  78%|███████▊  | 12786/16329 [1:47:38<29:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12786: train loss 1.24081. lr 4.002409e-04:  78%|███████▊  | 12786/16329 [1:47:39<29:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12786: train loss 1.24081. lr 4.002409e-04:  78%|███████▊  | 12787/16329 [1:47:39<29:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12787: train loss 1.19470. lr 4.002137e-04:  78%|███████▊  | 12787/16329 [1:47:39<29:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12787: train loss 1.19470. lr 4.002137e-04:  78%|███████▊  | 12788/16329 [1:47:39<29:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12788: train loss 1.21144. lr 4.001865e-04:  78%|███████▊  | 12788/16329 [1:47:40<29:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12788: train loss 1.21144. lr 4.001865e-04:  78%|███████▊  | 12789/16329 [1:47:40<29:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12789: train loss 1.19644. lr 4.001593e-04:  78%|███████▊  | 12789/16329 [1:47:40<29:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12789: train loss 1.19644. lr 4.001593e-04:  78%|███████▊  | 12790/16329 [1:47:40<29:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12790: train loss 1.22405. lr 4.001321e-04:  78%|███████▊  | 12790/16329 [1:47:41<29:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12790: train loss 1.22405. lr 4.001321e-04:  78%|███████▊  | 12791/16329 [1:47:41<29:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12791: train loss 1.20909. lr 4.001049e-04:  78%|███████▊  | 12791/16329 [1:47:41<29:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12791: train loss 1.20909. lr 4.001049e-04:  78%|███████▊  | 12792/16329 [1:47:41<29:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12792: train loss 1.22844. lr 4.000777e-04:  78%|███████▊  | 12792/16329 [1:47:42<29:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12792: train loss 1.22844. lr 4.000777e-04:  78%|███████▊  | 12793/16329 [1:47:42<29:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12793: train loss 1.21867. lr 4.000505e-04:  78%|███████▊  | 12793/16329 [1:47:42<29:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12793: train loss 1.21867. lr 4.000505e-04:  78%|███████▊  | 12794/16329 [1:47:42<29:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12794: train loss 1.19025. lr 4.000233e-04:  78%|███████▊  | 12794/16329 [1:47:43<29:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12794: train loss 1.19025. lr 4.000233e-04:  78%|███████▊  | 12795/16329 [1:47:43<32:45,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12795: train loss 1.19518. lr 3.999961e-04:  78%|███████▊  | 12795/16329 [1:47:43<32:45,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12795: train loss 1.19518. lr 3.999961e-04:  78%|███████▊  | 12796/16329 [1:47:43<31:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12796: train loss 1.23452. lr 3.999689e-04:  78%|███████▊  | 12796/16329 [1:47:44<31:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12796: train loss 1.23452. lr 3.999689e-04:  78%|███████▊  | 12797/16329 [1:47:44<30:56,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12797: train loss 1.17748. lr 3.999416e-04:  78%|███████▊  | 12797/16329 [1:47:44<30:56,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12797: train loss 1.17748. lr 3.999416e-04:  78%|███████▊  | 12798/16329 [1:47:44<30:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12798: train loss 1.19683. lr 3.999144e-04:  78%|███████▊  | 12798/16329 [1:47:45<30:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12798: train loss 1.19683. lr 3.999144e-04:  78%|███████▊  | 12799/16329 [1:47:45<29:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12799: train loss 1.20681. lr 3.998872e-04:  78%|███████▊  | 12799/16329 [1:47:45<29:57,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12799: train loss 1.20681. lr 3.998872e-04:  78%|███████▊  | 12800/16329 [1:47:45<29:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12800: train loss 1.21841. lr 3.998600e-04:  78%|███████▊  | 12800/16329 [1:47:46<29:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12800: train loss 1.21841. lr 3.998600e-04:  78%|███████▊  | 12801/16329 [1:47:46<29:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12801: train loss 1.23655. lr 3.998328e-04:  78%|███████▊  | 12801/16329 [1:47:46<29:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12801: train loss 1.23655. lr 3.998328e-04:  78%|███████▊  | 12802/16329 [1:47:46<29:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12802: train loss 1.21148. lr 3.998056e-04:  78%|███████▊  | 12802/16329 [1:47:47<29:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12802: train loss 1.21148. lr 3.998056e-04:  78%|███████▊  | 12803/16329 [1:47:47<29:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12803: train loss 1.22326. lr 3.997784e-04:  78%|███████▊  | 12803/16329 [1:47:47<29:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12803: train loss 1.22326. lr 3.997784e-04:  78%|███████▊  | 12804/16329 [1:47:47<29:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12804: train loss 1.20521. lr 3.997511e-04:  78%|███████▊  | 12804/16329 [1:47:48<29:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12804: train loss 1.20521. lr 3.997511e-04:  78%|███████▊  | 12805/16329 [1:47:48<29:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12805: train loss 1.18356. lr 3.997239e-04:  78%|███████▊  | 12805/16329 [1:47:48<29:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12805: train loss 1.18356. lr 3.997239e-04:  78%|███████▊  | 12806/16329 [1:47:48<29:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12806: train loss 1.19489. lr 3.996967e-04:  78%|███████▊  | 12806/16329 [1:47:49<29:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12806: train loss 1.19489. lr 3.996967e-04:  78%|███████▊  | 12807/16329 [1:47:49<29:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12807: train loss 1.22694. lr 3.996695e-04:  78%|███████▊  | 12807/16329 [1:47:49<29:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12807: train loss 1.22694. lr 3.996695e-04:  78%|███████▊  | 12808/16329 [1:47:49<29:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12808: train loss 1.21188. lr 3.996423e-04:  78%|███████▊  | 12808/16329 [1:47:50<29:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12808: train loss 1.21188. lr 3.996423e-04:  78%|███████▊  | 12809/16329 [1:47:50<29:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12809: train loss 1.21074. lr 3.996150e-04:  78%|███████▊  | 12809/16329 [1:47:50<29:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12809: train loss 1.21074. lr 3.996150e-04:  78%|███████▊  | 12810/16329 [1:47:50<29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12810: train loss 1.20304. lr 3.995878e-04:  78%|███████▊  | 12810/16329 [1:47:51<29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12810: train loss 1.20304. lr 3.995878e-04:  78%|███████▊  | 12811/16329 [1:47:51<29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12811: train loss 1.20409. lr 3.995606e-04:  78%|███████▊  | 12811/16329 [1:47:51<29:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12811: train loss 1.20409. lr 3.995606e-04:  78%|███████▊  | 12812/16329 [1:47:51<29:02,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12812: train loss 1.23008. lr 3.995334e-04:  78%|███████▊  | 12812/16329 [1:47:52<29:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12812: train loss 1.23008. lr 3.995334e-04:  78%|███████▊  | 12813/16329 [1:47:52<28:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12813: train loss 1.23200. lr 3.995061e-04:  78%|███████▊  | 12813/16329 [1:47:52<28:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12813: train loss 1.23200. lr 3.995061e-04:  78%|███████▊  | 12814/16329 [1:47:52<29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12814: train loss 1.22738. lr 3.994789e-04:  78%|███████▊  | 12814/16329 [1:47:53<29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12814: train loss 1.22738. lr 3.994789e-04:  78%|███████▊  | 12815/16329 [1:47:53<29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12815: train loss 1.21599. lr 3.994517e-04:  78%|███████▊  | 12815/16329 [1:47:53<29:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12815: train loss 1.21599. lr 3.994517e-04:  78%|███████▊  | 12816/16329 [1:47:53<29:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12816: train loss 1.20678. lr 3.994245e-04:  78%|███████▊  | 12816/16329 [1:47:54<29:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12816: train loss 1.20678. lr 3.994245e-04:  78%|███████▊  | 12817/16329 [1:47:54<29:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12817: train loss 1.19415. lr 3.993972e-04:  78%|███████▊  | 12817/16329 [1:47:54<29:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12817: train loss 1.19415. lr 3.993972e-04:  78%|███████▊  | 12818/16329 [1:47:54<28:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12818: train loss 1.21157. lr 3.993700e-04:  78%|███████▊  | 12818/16329 [1:47:55<28:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12818: train loss 1.21157. lr 3.993700e-04:  79%|███████▊  | 12819/16329 [1:47:55<28:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12819: train loss 1.17799. lr 3.993428e-04:  79%|███████▊  | 12819/16329 [1:47:55<28:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12819: train loss 1.17799. lr 3.993428e-04:  79%|███████▊  | 12820/16329 [1:47:55<28:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12820: train loss 1.23222. lr 3.993155e-04:  79%|███████▊  | 12820/16329 [1:47:56<28:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12820: train loss 1.23222. lr 3.993155e-04:  79%|███████▊  | 12821/16329 [1:47:56<29:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12821: train loss 1.19006. lr 3.992883e-04:  79%|███████▊  | 12821/16329 [1:47:57<29:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12821: train loss 1.19006. lr 3.992883e-04:  79%|███████▊  | 12822/16329 [1:47:57<32:30,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12822: train loss 1.24509. lr 3.992611e-04:  79%|███████▊  | 12822/16329 [1:47:57<32:30,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12822: train loss 1.24509. lr 3.992611e-04:  79%|███████▊  | 12823/16329 [1:47:57<31:29,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12823: train loss 1.20238. lr 3.992338e-04:  79%|███████▊  | 12823/16329 [1:47:58<31:29,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 12823: train loss 1.20238. lr 3.992338e-04:  79%|███████▊  | 12824/16329 [1:47:58<30:45,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12824: train loss 1.22545. lr 3.992066e-04:  79%|███████▊  | 12824/16329 [1:47:58<30:45,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12824: train loss 1.22545. lr 3.992066e-04:  79%|███████▊  | 12825/16329 [1:47:58<30:11,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12825: train loss 1.19463. lr 3.991794e-04:  79%|███████▊  | 12825/16329 [1:47:59<30:11,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12825: train loss 1.19463. lr 3.991794e-04:  79%|███████▊  | 12826/16329 [1:47:59<29:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12826: train loss 1.22479. lr 3.991521e-04:  79%|███████▊  | 12826/16329 [1:47:59<29:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12826: train loss 1.22479. lr 3.991521e-04:  79%|███████▊  | 12827/16329 [1:47:59<29:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12827: train loss 1.20000. lr 3.991249e-04:  79%|███████▊  | 12827/16329 [1:48:00<29:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12827: train loss 1.20000. lr 3.991249e-04:  79%|███████▊  | 12828/16329 [1:48:00<29:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12828: train loss 1.19025. lr 3.990976e-04:  79%|███████▊  | 12828/16329 [1:48:00<29:24,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12828: train loss 1.19025. lr 3.990976e-04:  79%|███████▊  | 12829/16329 [1:48:00<29:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12829: train loss 1.22636. lr 3.990704e-04:  79%|███████▊  | 12829/16329 [1:48:01<29:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12829: train loss 1.22636. lr 3.990704e-04:  79%|███████▊  | 12830/16329 [1:48:01<29:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12830: train loss 1.16540. lr 3.990432e-04:  79%|███████▊  | 12830/16329 [1:48:01<29:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12830: train loss 1.16540. lr 3.990432e-04:  79%|███████▊  | 12831/16329 [1:48:01<29:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12831: train loss 1.23888. lr 3.990159e-04:  79%|███████▊  | 12831/16329 [1:48:02<29:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12831: train loss 1.23888. lr 3.990159e-04:  79%|███████▊  | 12832/16329 [1:48:02<29:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12832: train loss 1.20590. lr 3.989887e-04:  79%|███████▊  | 12832/16329 [1:48:02<29:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12832: train loss 1.20590. lr 3.989887e-04:  79%|███████▊  | 12833/16329 [1:48:02<29:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12833: train loss 1.19664. lr 3.989614e-04:  79%|███████▊  | 12833/16329 [1:48:03<29:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12833: train loss 1.19664. lr 3.989614e-04:  79%|███████▊  | 12834/16329 [1:48:03<28:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12834: train loss 1.21643. lr 3.989342e-04:  79%|███████▊  | 12834/16329 [1:48:03<28:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12834: train loss 1.21643. lr 3.989342e-04:  79%|███████▊  | 12835/16329 [1:48:03<28:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12835: train loss 1.18737. lr 3.989069e-04:  79%|███████▊  | 12835/16329 [1:48:04<28:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12835: train loss 1.18737. lr 3.989069e-04:  79%|███████▊  | 12836/16329 [1:48:04<29:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12836: train loss 1.20580. lr 3.988797e-04:  79%|███████▊  | 12836/16329 [1:48:04<29:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12836: train loss 1.20580. lr 3.988797e-04:  79%|███████▊  | 12837/16329 [1:48:04<29:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12837: train loss 1.21457. lr 3.988524e-04:  79%|███████▊  | 12837/16329 [1:48:05<29:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12837: train loss 1.21457. lr 3.988524e-04:  79%|███████▊  | 12838/16329 [1:48:05<28:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12838: train loss 1.20269. lr 3.988252e-04:  79%|███████▊  | 12838/16329 [1:48:05<28:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12838: train loss 1.20269. lr 3.988252e-04:  79%|███████▊  | 12839/16329 [1:48:05<28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12839: train loss 1.19705. lr 3.987979e-04:  79%|███████▊  | 12839/16329 [1:48:06<28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12839: train loss 1.19705. lr 3.987979e-04:  79%|███████▊  | 12840/16329 [1:48:06<28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12840: train loss 1.20968. lr 3.987707e-04:  79%|███████▊  | 12840/16329 [1:48:06<28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12840: train loss 1.20968. lr 3.987707e-04:  79%|███████▊  | 12841/16329 [1:48:06<28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12841: train loss 1.19499. lr 3.987434e-04:  79%|███████▊  | 12841/16329 [1:48:07<28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12841: train loss 1.19499. lr 3.987434e-04:  79%|███████▊  | 12842/16329 [1:48:07<28:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12842: train loss 1.21176. lr 3.987162e-04:  79%|███████▊  | 12842/16329 [1:48:07<28:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12842: train loss 1.21176. lr 3.987162e-04:  79%|███████▊  | 12843/16329 [1:48:07<28:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12843: train loss 1.21500. lr 3.986889e-04:  79%|███████▊  | 12843/16329 [1:48:08<28:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12843: train loss 1.21500. lr 3.986889e-04:  79%|███████▊  | 12844/16329 [1:48:08<28:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12844: train loss 1.21340. lr 3.986617e-04:  79%|███████▊  | 12844/16329 [1:48:08<28:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12844: train loss 1.21340. lr 3.986617e-04:  79%|███████▊  | 12845/16329 [1:48:08<28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12845: train loss 1.18395. lr 3.986344e-04:  79%|███████▊  | 12845/16329 [1:48:09<28:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12845: train loss 1.18395. lr 3.986344e-04:  79%|███████▊  | 12846/16329 [1:48:09<28:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12846: train loss 1.20449. lr 3.986072e-04:  79%|███████▊  | 12846/16329 [1:48:09<28:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12846: train loss 1.20449. lr 3.986072e-04:  79%|███████▊  | 12847/16329 [1:48:09<28:46,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12847: train loss 1.19176. lr 3.985799e-04:  79%|███████▊  | 12847/16329 [1:48:10<28:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12847: train loss 1.19176. lr 3.985799e-04:  79%|███████▊  | 12848/16329 [1:48:10<28:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12848: train loss 1.19899. lr 3.985526e-04:  79%|███████▊  | 12848/16329 [1:48:10<28:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12848: train loss 1.19899. lr 3.985526e-04:  79%|███████▊  | 12849/16329 [1:48:10<28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12849: train loss 1.20407. lr 3.985254e-04:  79%|███████▊  | 12849/16329 [1:48:10<28:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12849: train loss 1.20407. lr 3.985254e-04:  79%|███████▊  | 12850/16329 [1:48:11<28:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12850: train loss 1.18473. lr 3.984981e-04:  79%|███████▊  | 12850/16329 [1:48:11<28:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12850: train loss 1.18473. lr 3.984981e-04:  79%|███████▊  | 12851/16329 [1:48:11<28:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12851: train loss 1.20012. lr 3.984709e-04:  79%|███████▊  | 12851/16329 [1:48:11<28:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12851: train loss 1.20012. lr 3.984709e-04:  79%|███████▊  | 12852/16329 [1:48:12<28:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12852: train loss 1.18917. lr 3.984436e-04:  79%|███████▊  | 12852/16329 [1:48:12<28:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12852: train loss 1.18917. lr 3.984436e-04:  79%|███████▊  | 12853/16329 [1:48:12<28:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12853: train loss 1.19738. lr 3.984163e-04:  79%|███████▊  | 12853/16329 [1:48:12<28:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12853: train loss 1.19738. lr 3.984163e-04:  79%|███████▊  | 12854/16329 [1:48:12<28:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12854: train loss 1.18855. lr 3.983891e-04:  79%|███████▊  | 12854/16329 [1:48:13<28:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12854: train loss 1.18855. lr 3.983891e-04:  79%|███████▊  | 12855/16329 [1:48:13<29:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12855: train loss 1.24218. lr 3.983618e-04:  79%|███████▊  | 12855/16329 [1:48:14<29:09,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12855: train loss 1.24218. lr 3.983618e-04:  79%|███████▊  | 12856/16329 [1:48:14<29:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12856: train loss 1.20462. lr 3.983345e-04:  79%|███████▊  | 12856/16329 [1:48:14<29:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12856: train loss 1.20462. lr 3.983345e-04:  79%|███████▊  | 12857/16329 [1:48:14<29:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12857: train loss 1.20347. lr 3.983073e-04:  79%|███████▊  | 12857/16329 [1:48:15<29:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12857: train loss 1.20347. lr 3.983073e-04:  79%|███████▊  | 12858/16329 [1:48:15<29:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12858: train loss 1.19812. lr 3.982800e-04:  79%|███████▊  | 12858/16329 [1:48:15<29:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12858: train loss 1.19812. lr 3.982800e-04:  79%|███████▊  | 12859/16329 [1:48:15<29:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12859: train loss 1.24686. lr 3.982527e-04:  79%|███████▊  | 12859/16329 [1:48:16<29:16,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12859: train loss 1.24686. lr 3.982527e-04:  79%|███████▉  | 12860/16329 [1:48:16<29:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12860: train loss 1.25379. lr 3.982255e-04:  79%|███████▉  | 12860/16329 [1:48:16<29:13,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12860: train loss 1.25379. lr 3.982255e-04:  79%|███████▉  | 12861/16329 [1:48:16<29:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12861: train loss 1.21534. lr 3.981982e-04:  79%|███████▉  | 12861/16329 [1:48:17<29:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12861: train loss 1.21534. lr 3.981982e-04:  79%|███████▉  | 12862/16329 [1:48:17<33:03,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 12862: train loss 1.18193. lr 3.981709e-04:  79%|███████▉  | 12862/16329 [1:48:17<33:03,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 12862: train loss 1.18193. lr 3.981709e-04:  79%|███████▉  | 12863/16329 [1:48:17<32:00,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12863: train loss 1.23433. lr 3.981437e-04:  79%|███████▉  | 12863/16329 [1:48:18<32:00,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12863: train loss 1.23433. lr 3.981437e-04:  79%|███████▉  | 12864/16329 [1:48:18<31:14,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 12864: train loss 1.20659. lr 3.981164e-04:  79%|███████▉  | 12864/16329 [1:48:18<31:14,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 12864: train loss 1.20659. lr 3.981164e-04:  79%|███████▉  | 12865/16329 [1:48:18<30:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12865: train loss 1.22154. lr 3.980891e-04:  79%|███████▉  | 12865/16329 [1:48:19<30:39,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 12865: train loss 1.22154. lr 3.980891e-04:  79%|███████▉  | 12866/16329 [1:48:19<30:10,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12866: train loss 1.17576. lr 3.980618e-04:  79%|███████▉  | 12866/16329 [1:48:19<30:10,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12866: train loss 1.17576. lr 3.980618e-04:  79%|███████▉  | 12867/16329 [1:48:19<29:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12867: train loss 1.20623. lr 3.980346e-04:  79%|███████▉  | 12867/16329 [1:48:20<29:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12867: train loss 1.20623. lr 3.980346e-04:  79%|███████▉  | 12868/16329 [1:48:20<29:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12868: train loss 1.20667. lr 3.980073e-04:  79%|███████▉  | 12868/16329 [1:48:20<29:35,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12868: train loss 1.20667. lr 3.980073e-04:  79%|███████▉  | 12869/16329 [1:48:20<29:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12869: train loss 1.21337. lr 3.979800e-04:  79%|███████▉  | 12869/16329 [1:48:21<29:15,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12869: train loss 1.21337. lr 3.979800e-04:  79%|███████▉  | 12870/16329 [1:48:21<29:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12870: train loss 1.21179. lr 3.979527e-04:  79%|███████▉  | 12870/16329 [1:48:21<29:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12870: train loss 1.21179. lr 3.979527e-04:  79%|███████▉  | 12871/16329 [1:48:21<28:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12871: train loss 1.19579. lr 3.979255e-04:  79%|███████▉  | 12871/16329 [1:48:22<28:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12871: train loss 1.19579. lr 3.979255e-04:  79%|███████▉  | 12872/16329 [1:48:22<28:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12872: train loss 1.22162. lr 3.978982e-04:  79%|███████▉  | 12872/16329 [1:48:22<28:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12872: train loss 1.22162. lr 3.978982e-04:  79%|███████▉  | 12873/16329 [1:48:22<28:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12873: train loss 1.19768. lr 3.978709e-04:  79%|███████▉  | 12873/16329 [1:48:23<28:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12873: train loss 1.19768. lr 3.978709e-04:  79%|███████▉  | 12874/16329 [1:48:23<28:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12874: train loss 1.21386. lr 3.978436e-04:  79%|███████▉  | 12874/16329 [1:48:23<28:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12874: train loss 1.21386. lr 3.978436e-04:  79%|███████▉  | 12875/16329 [1:48:23<28:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12875: train loss 1.23824. lr 3.978163e-04:  79%|███████▉  | 12875/16329 [1:48:24<28:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12875: train loss 1.23824. lr 3.978163e-04:  79%|███████▉  | 12876/16329 [1:48:24<28:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12876: train loss 1.20500. lr 3.977890e-04:  79%|███████▉  | 12876/16329 [1:48:24<28:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12876: train loss 1.20500. lr 3.977890e-04:  79%|███████▉  | 12877/16329 [1:48:24<28:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12877: train loss 1.21464. lr 3.977618e-04:  79%|███████▉  | 12877/16329 [1:48:25<28:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12877: train loss 1.21464. lr 3.977618e-04:  79%|███████▉  | 12878/16329 [1:48:25<28:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12878: train loss 1.20588. lr 3.977345e-04:  79%|███████▉  | 12878/16329 [1:48:25<28:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12878: train loss 1.20588. lr 3.977345e-04:  79%|███████▉  | 12879/16329 [1:48:25<28:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12879: train loss 1.21642. lr 3.977072e-04:  79%|███████▉  | 12879/16329 [1:48:26<28:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12879: train loss 1.21642. lr 3.977072e-04:  79%|███████▉  | 12880/16329 [1:48:26<28:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12880: train loss 1.21188. lr 3.976799e-04:  79%|███████▉  | 12880/16329 [1:48:26<28:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12880: train loss 1.21188. lr 3.976799e-04:  79%|███████▉  | 12881/16329 [1:48:26<28:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12881: train loss 1.19973. lr 3.976526e-04:  79%|███████▉  | 12881/16329 [1:48:27<28:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12881: train loss 1.19973. lr 3.976526e-04:  79%|███████▉  | 12882/16329 [1:48:27<28:34,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12882: train loss 1.14912. lr 3.976253e-04:  79%|███████▉  | 12882/16329 [1:48:27<28:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12882: train loss 1.14912. lr 3.976253e-04:  79%|███████▉  | 12883/16329 [1:48:27<28:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12883: train loss 1.23167. lr 3.975980e-04:  79%|███████▉  | 12883/16329 [1:48:28<28:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12883: train loss 1.23167. lr 3.975980e-04:  79%|███████▉  | 12884/16329 [1:48:28<28:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12884: train loss 1.21867. lr 3.975707e-04:  79%|███████▉  | 12884/16329 [1:48:28<28:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12884: train loss 1.21867. lr 3.975707e-04:  79%|███████▉  | 12885/16329 [1:48:28<28:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12885: train loss 1.22774. lr 3.975435e-04:  79%|███████▉  | 12885/16329 [1:48:29<28:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12885: train loss 1.22774. lr 3.975435e-04:  79%|███████▉  | 12886/16329 [1:48:29<28:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12886: train loss 1.20271. lr 3.975162e-04:  79%|███████▉  | 12886/16329 [1:48:29<28:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12886: train loss 1.20271. lr 3.975162e-04:  79%|███████▉  | 12887/16329 [1:48:29<28:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12887: train loss 1.20891. lr 3.974889e-04:  79%|███████▉  | 12887/16329 [1:48:30<28:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12887: train loss 1.20891. lr 3.974889e-04:  79%|███████▉  | 12888/16329 [1:48:30<28:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12888: train loss 1.19386. lr 3.974616e-04:  79%|███████▉  | 12888/16329 [1:48:30<28:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12888: train loss 1.19386. lr 3.974616e-04:  79%|███████▉  | 12889/16329 [1:48:30<28:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12889: train loss 1.22777. lr 3.974343e-04:  79%|███████▉  | 12889/16329 [1:48:31<28:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12889: train loss 1.22777. lr 3.974343e-04:  79%|███████▉  | 12890/16329 [1:48:31<28:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12890: train loss 1.21346. lr 3.974070e-04:  79%|███████▉  | 12890/16329 [1:48:31<28:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12890: train loss 1.21346. lr 3.974070e-04:  79%|███████▉  | 12891/16329 [1:48:31<28:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12891: train loss 1.19017. lr 3.973797e-04:  79%|███████▉  | 12891/16329 [1:48:32<28:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12891: train loss 1.19017. lr 3.973797e-04:  79%|███████▉  | 12892/16329 [1:48:32<28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12892: train loss 1.20125. lr 3.973524e-04:  79%|███████▉  | 12892/16329 [1:48:32<28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12892: train loss 1.20125. lr 3.973524e-04:  79%|███████▉  | 12893/16329 [1:48:32<28:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12893: train loss 1.17710. lr 3.973251e-04:  79%|███████▉  | 12893/16329 [1:48:33<28:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12893: train loss 1.17710. lr 3.973251e-04:  79%|███████▉  | 12894/16329 [1:48:33<28:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12894: train loss 1.19536. lr 3.972978e-04:  79%|███████▉  | 12894/16329 [1:48:33<28:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12894: train loss 1.19536. lr 3.972978e-04:  79%|███████▉  | 12895/16329 [1:48:33<28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12895: train loss 1.23203. lr 3.972705e-04:  79%|███████▉  | 12895/16329 [1:48:34<28:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12895: train loss 1.23203. lr 3.972705e-04:  79%|███████▉  | 12896/16329 [1:48:34<28:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12896: train loss 1.23223. lr 3.972432e-04:  79%|███████▉  | 12896/16329 [1:48:34<28:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12896: train loss 1.23223. lr 3.972432e-04:  79%|███████▉  | 12897/16329 [1:48:34<31:44,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12897: train loss 1.21223. lr 3.972159e-04:  79%|███████▉  | 12897/16329 [1:48:35<31:44,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 12897: train loss 1.21223. lr 3.972159e-04:  79%|███████▉  | 12898/16329 [1:48:35<30:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12898: train loss 1.20994. lr 3.971886e-04:  79%|███████▉  | 12898/16329 [1:48:35<30:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12898: train loss 1.20994. lr 3.971886e-04:  79%|███████▉  | 12899/16329 [1:48:35<30:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12899: train loss 1.20466. lr 3.971613e-04:  79%|███████▉  | 12899/16329 [1:48:36<30:02,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 12899: train loss 1.20466. lr 3.971613e-04:  79%|███████▉  | 12900/16329 [1:48:36<29:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12900: train loss 1.19664. lr 3.971340e-04:  79%|███████▉  | 12900/16329 [1:48:36<29:36,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 12900: train loss 1.19664. lr 3.971340e-04:  79%|███████▉  | 12901/16329 [1:48:36<29:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12901: train loss 1.18157. lr 3.971067e-04:  79%|███████▉  | 12901/16329 [1:48:37<29:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 12901: train loss 1.18157. lr 3.971067e-04:  79%|███████▉  | 12902/16329 [1:48:37<29:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12902: train loss 1.21863. lr 3.970794e-04:  79%|███████▉  | 12902/16329 [1:48:37<29:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12902: train loss 1.21863. lr 3.970794e-04:  79%|███████▉  | 12903/16329 [1:48:37<28:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12903: train loss 1.15876. lr 3.970521e-04:  79%|███████▉  | 12903/16329 [1:48:38<28:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12903: train loss 1.15876. lr 3.970521e-04:  79%|███████▉  | 12904/16329 [1:48:38<28:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12904: train loss 1.18971. lr 3.970247e-04:  79%|███████▉  | 12904/16329 [1:48:38<28:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12904: train loss 1.18971. lr 3.970247e-04:  79%|███████▉  | 12905/16329 [1:48:38<28:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12905: train loss 1.19386. lr 3.969974e-04:  79%|███████▉  | 12905/16329 [1:48:39<28:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12905: train loss 1.19386. lr 3.969974e-04:  79%|███████▉  | 12906/16329 [1:48:39<28:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12906: train loss 1.20290. lr 3.969701e-04:  79%|███████▉  | 12906/16329 [1:48:39<28:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12906: train loss 1.20290. lr 3.969701e-04:  79%|███████▉  | 12907/16329 [1:48:39<28:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12907: train loss 1.22852. lr 3.969428e-04:  79%|███████▉  | 12907/16329 [1:48:40<28:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12907: train loss 1.22852. lr 3.969428e-04:  79%|███████▉  | 12908/16329 [1:48:40<28:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12908: train loss 1.18743. lr 3.969155e-04:  79%|███████▉  | 12908/16329 [1:48:40<28:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12908: train loss 1.18743. lr 3.969155e-04:  79%|███████▉  | 12909/16329 [1:48:40<28:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12909: train loss 1.21634. lr 3.968882e-04:  79%|███████▉  | 12909/16329 [1:48:41<28:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12909: train loss 1.21634. lr 3.968882e-04:  79%|███████▉  | 12910/16329 [1:48:41<28:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12910: train loss 1.20371. lr 3.968609e-04:  79%|███████▉  | 12910/16329 [1:48:41<28:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12910: train loss 1.20371. lr 3.968609e-04:  79%|███████▉  | 12911/16329 [1:48:41<28:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12911: train loss 1.20237. lr 3.968336e-04:  79%|███████▉  | 12911/16329 [1:48:42<28:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12911: train loss 1.20237. lr 3.968336e-04:  79%|███████▉  | 12912/16329 [1:48:42<28:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12912: train loss 1.19447. lr 3.968062e-04:  79%|███████▉  | 12912/16329 [1:48:42<28:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 12912: train loss 1.19447. lr 3.968062e-04:  79%|███████▉  | 12913/16329 [1:48:42<28:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12913: train loss 1.20103. lr 3.967789e-04:  79%|███████▉  | 12913/16329 [1:48:43<28:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12913: train loss 1.20103. lr 3.967789e-04:  79%|███████▉  | 12914/16329 [1:48:43<28:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12914: train loss 1.19791. lr 3.967516e-04:  79%|███████▉  | 12914/16329 [1:48:43<28:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12914: train loss 1.19791. lr 3.967516e-04:  79%|███████▉  | 12915/16329 [1:48:43<28:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12915: train loss 1.19747. lr 3.967243e-04:  79%|███████▉  | 12915/16329 [1:48:44<28:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12915: train loss 1.19747. lr 3.967243e-04:  79%|███████▉  | 12916/16329 [1:48:44<28:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12916: train loss 1.19319. lr 3.966970e-04:  79%|███████▉  | 12916/16329 [1:48:44<28:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12916: train loss 1.19319. lr 3.966970e-04:  79%|███████▉  | 12917/16329 [1:48:44<28:15,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12917: train loss 1.21494. lr 3.966696e-04:  79%|███████▉  | 12917/16329 [1:48:45<28:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12917: train loss 1.21494. lr 3.966696e-04:  79%|███████▉  | 12918/16329 [1:48:45<28:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12918: train loss 1.18122. lr 3.966423e-04:  79%|███████▉  | 12918/16329 [1:48:45<28:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12918: train loss 1.18122. lr 3.966423e-04:  79%|███████▉  | 12919/16329 [1:48:45<28:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12919: train loss 1.22877. lr 3.966150e-04:  79%|███████▉  | 12919/16329 [1:48:46<28:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12919: train loss 1.22877. lr 3.966150e-04:  79%|███████▉  | 12920/16329 [1:48:46<28:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12920: train loss 1.17855. lr 3.965877e-04:  79%|███████▉  | 12920/16329 [1:48:46<28:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12920: train loss 1.17855. lr 3.965877e-04:  79%|███████▉  | 12921/16329 [1:48:46<28:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12921: train loss 1.17747. lr 3.965604e-04:  79%|███████▉  | 12921/16329 [1:48:47<28:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12921: train loss 1.17747. lr 3.965604e-04:  79%|███████▉  | 12922/16329 [1:48:47<31:13,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12922: train loss 1.18841. lr 3.965330e-04:  79%|███████▉  | 12922/16329 [1:48:48<31:13,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12922: train loss 1.18841. lr 3.965330e-04:  79%|███████▉  | 12923/16329 [1:48:48<30:23,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12923: train loss 1.16864. lr 3.965057e-04:  79%|███████▉  | 12923/16329 [1:48:48<30:23,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12923: train loss 1.16864. lr 3.965057e-04:  79%|███████▉  | 12924/16329 [1:48:48<29:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12924: train loss 1.19567. lr 3.964784e-04:  79%|███████▉  | 12924/16329 [1:48:49<29:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 12924: train loss 1.19567. lr 3.964784e-04:  79%|███████▉  | 12925/16329 [1:48:49<29:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12925: train loss 1.20342. lr 3.964511e-04:  79%|███████▉  | 12925/16329 [1:48:49<29:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12925: train loss 1.20342. lr 3.964511e-04:  79%|███████▉  | 12926/16329 [1:48:49<28:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12926: train loss 1.18999. lr 3.964237e-04:  79%|███████▉  | 12926/16329 [1:48:50<28:49,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12926: train loss 1.18999. lr 3.964237e-04:  79%|███████▉  | 12927/16329 [1:48:50<28:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12927: train loss 1.21638. lr 3.963964e-04:  79%|███████▉  | 12927/16329 [1:48:50<28:39,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12927: train loss 1.21638. lr 3.963964e-04:  79%|███████▉  | 12928/16329 [1:48:50<28:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12928: train loss 1.17523. lr 3.963691e-04:  79%|███████▉  | 12928/16329 [1:48:51<28:28,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12928: train loss 1.17523. lr 3.963691e-04:  79%|███████▉  | 12929/16329 [1:48:51<28:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12929: train loss 1.19582. lr 3.963417e-04:  79%|███████▉  | 12929/16329 [1:48:51<28:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12929: train loss 1.19582. lr 3.963417e-04:  79%|███████▉  | 12930/16329 [1:48:51<28:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12930: train loss 1.20209. lr 3.963144e-04:  79%|███████▉  | 12930/16329 [1:48:51<28:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12930: train loss 1.20209. lr 3.963144e-04:  79%|███████▉  | 12931/16329 [1:48:51<28:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12931: train loss 1.18464. lr 3.962871e-04:  79%|███████▉  | 12931/16329 [1:48:52<28:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12931: train loss 1.18464. lr 3.962871e-04:  79%|███████▉  | 12932/16329 [1:48:52<28:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12932: train loss 1.21287. lr 3.962597e-04:  79%|███████▉  | 12932/16329 [1:48:53<28:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12932: train loss 1.21287. lr 3.962597e-04:  79%|███████▉  | 12933/16329 [1:48:53<28:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12933: train loss 1.18646. lr 3.962324e-04:  79%|███████▉  | 12933/16329 [1:48:53<28:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12933: train loss 1.18646. lr 3.962324e-04:  79%|███████▉  | 12934/16329 [1:48:53<28:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12934: train loss 1.20288. lr 3.962051e-04:  79%|███████▉  | 12934/16329 [1:48:54<28:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12934: train loss 1.20288. lr 3.962051e-04:  79%|███████▉  | 12935/16329 [1:48:54<28:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12935: train loss 1.19839. lr 3.961777e-04:  79%|███████▉  | 12935/16329 [1:48:54<28:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12935: train loss 1.19839. lr 3.961777e-04:  79%|███████▉  | 12936/16329 [1:48:54<28:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12936: train loss 1.16441. lr 3.961504e-04:  79%|███████▉  | 12936/16329 [1:48:55<28:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12936: train loss 1.16441. lr 3.961504e-04:  79%|███████▉  | 12937/16329 [1:48:55<28:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12937: train loss 1.23050. lr 3.961230e-04:  79%|███████▉  | 12937/16329 [1:48:55<28:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 12937: train loss 1.23050. lr 3.961230e-04:  79%|███████▉  | 12938/16329 [1:48:55<28:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12938: train loss 1.15156. lr 3.960957e-04:  79%|███████▉  | 12938/16329 [1:48:56<28:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12938: train loss 1.15156. lr 3.960957e-04:  79%|███████▉  | 12939/16329 [1:48:56<28:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12939: train loss 1.26846. lr 3.960684e-04:  79%|███████▉  | 12939/16329 [1:48:56<28:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12939: train loss 1.26846. lr 3.960684e-04:  79%|███████▉  | 12940/16329 [1:48:56<28:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12940: train loss 1.20185. lr 3.960410e-04:  79%|███████▉  | 12940/16329 [1:48:57<28:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12940: train loss 1.20185. lr 3.960410e-04:  79%|███████▉  | 12941/16329 [1:48:57<28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12941: train loss 1.21983. lr 3.960137e-04:  79%|███████▉  | 12941/16329 [1:48:57<28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12941: train loss 1.21983. lr 3.960137e-04:  79%|███████▉  | 12942/16329 [1:48:57<28:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12942: train loss 1.20300. lr 3.959863e-04:  79%|███████▉  | 12942/16329 [1:48:58<28:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12942: train loss 1.20300. lr 3.959863e-04:  79%|███████▉  | 12943/16329 [1:48:58<28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12943: train loss 1.18692. lr 3.959590e-04:  79%|███████▉  | 12943/16329 [1:48:58<28:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12943: train loss 1.18692. lr 3.959590e-04:  79%|███████▉  | 12944/16329 [1:48:58<28:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12944: train loss 1.22254. lr 3.959317e-04:  79%|███████▉  | 12944/16329 [1:48:59<28:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12944: train loss 1.22254. lr 3.959317e-04:  79%|███████▉  | 12945/16329 [1:48:59<28:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12945: train loss 1.22076. lr 3.959043e-04:  79%|███████▉  | 12945/16329 [1:48:59<28:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12945: train loss 1.22076. lr 3.959043e-04:  79%|███████▉  | 12946/16329 [1:48:59<28:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12946: train loss 1.18419. lr 3.958770e-04:  79%|███████▉  | 12946/16329 [1:49:00<28:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12946: train loss 1.18419. lr 3.958770e-04:  79%|███████▉  | 12947/16329 [1:49:00<28:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12947: train loss 1.18823. lr 3.958496e-04:  79%|███████▉  | 12947/16329 [1:49:00<28:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12947: train loss 1.18823. lr 3.958496e-04:  79%|███████▉  | 12948/16329 [1:49:00<28:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12948: train loss 1.21971. lr 3.958223e-04:  79%|███████▉  | 12948/16329 [1:49:01<28:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12948: train loss 1.21971. lr 3.958223e-04:  79%|███████▉  | 12949/16329 [1:49:01<30:58,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12949: train loss 1.19308. lr 3.957949e-04:  79%|███████▉  | 12949/16329 [1:49:01<30:58,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12949: train loss 1.19308. lr 3.957949e-04:  79%|███████▉  | 12950/16329 [1:49:01<30:07,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12950: train loss 1.20423. lr 3.957676e-04:  79%|███████▉  | 12950/16329 [1:49:02<30:07,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12950: train loss 1.20423. lr 3.957676e-04:  79%|███████▉  | 12951/16329 [1:49:02<29:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12951: train loss 1.19060. lr 3.957402e-04:  79%|███████▉  | 12951/16329 [1:49:02<29:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12951: train loss 1.19060. lr 3.957402e-04:  79%|███████▉  | 12952/16329 [1:49:02<28:59,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12952: train loss 1.23326. lr 3.957129e-04:  79%|███████▉  | 12952/16329 [1:49:03<28:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12952: train loss 1.23326. lr 3.957129e-04:  79%|███████▉  | 12953/16329 [1:49:03<28:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12953: train loss 1.22105. lr 3.956855e-04:  79%|███████▉  | 12953/16329 [1:49:03<28:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12953: train loss 1.22105. lr 3.956855e-04:  79%|███████▉  | 12954/16329 [1:49:03<28:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12954: train loss 1.19393. lr 3.956582e-04:  79%|███████▉  | 12954/16329 [1:49:04<28:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12954: train loss 1.19393. lr 3.956582e-04:  79%|███████▉  | 12955/16329 [1:49:04<28:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12955: train loss 1.20479. lr 3.956308e-04:  79%|███████▉  | 12955/16329 [1:49:04<28:15,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12955: train loss 1.20479. lr 3.956308e-04:  79%|███████▉  | 12956/16329 [1:49:04<28:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12956: train loss 1.17292. lr 3.956035e-04:  79%|███████▉  | 12956/16329 [1:49:05<28:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12956: train loss 1.17292. lr 3.956035e-04:  79%|███████▉  | 12957/16329 [1:49:05<28:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12957: train loss 1.18261. lr 3.955761e-04:  79%|███████▉  | 12957/16329 [1:49:05<28:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12957: train loss 1.18261. lr 3.955761e-04:  79%|███████▉  | 12958/16329 [1:49:05<27:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12958: train loss 1.22093. lr 3.955487e-04:  79%|███████▉  | 12958/16329 [1:49:06<27:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12958: train loss 1.22093. lr 3.955487e-04:  79%|███████▉  | 12959/16329 [1:49:06<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12959: train loss 1.19033. lr 3.955214e-04:  79%|███████▉  | 12959/16329 [1:49:06<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12959: train loss 1.19033. lr 3.955214e-04:  79%|███████▉  | 12960/16329 [1:49:06<27:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12960: train loss 1.24046. lr 3.954940e-04:  79%|███████▉  | 12960/16329 [1:49:07<27:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12960: train loss 1.24046. lr 3.954940e-04:  79%|███████▉  | 12961/16329 [1:49:07<27:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12961: train loss 1.18696. lr 3.954667e-04:  79%|███████▉  | 12961/16329 [1:49:07<27:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12961: train loss 1.18696. lr 3.954667e-04:  79%|███████▉  | 12962/16329 [1:49:07<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12962: train loss 1.19195. lr 3.954393e-04:  79%|███████▉  | 12962/16329 [1:49:08<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12962: train loss 1.19195. lr 3.954393e-04:  79%|███████▉  | 12963/16329 [1:49:08<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12963: train loss 1.18487. lr 3.954119e-04:  79%|███████▉  | 12963/16329 [1:49:08<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12963: train loss 1.18487. lr 3.954119e-04:  79%|███████▉  | 12964/16329 [1:49:08<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12964: train loss 1.17879. lr 3.953846e-04:  79%|███████▉  | 12964/16329 [1:49:09<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12964: train loss 1.17879. lr 3.953846e-04:  79%|███████▉  | 12965/16329 [1:49:09<27:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12965: train loss 1.18424. lr 3.953572e-04:  79%|███████▉  | 12965/16329 [1:49:09<27:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12965: train loss 1.18424. lr 3.953572e-04:  79%|███████▉  | 12966/16329 [1:49:09<27:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12966: train loss 1.20466. lr 3.953299e-04:  79%|███████▉  | 12966/16329 [1:49:10<27:59,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12966: train loss 1.20466. lr 3.953299e-04:  79%|███████▉  | 12967/16329 [1:49:10<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12967: train loss 1.19364. lr 3.953025e-04:  79%|███████▉  | 12967/16329 [1:49:10<27:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12967: train loss 1.19364. lr 3.953025e-04:  79%|███████▉  | 12968/16329 [1:49:10<27:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12968: train loss 1.13888. lr 3.952751e-04:  79%|███████▉  | 12968/16329 [1:49:11<27:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12968: train loss 1.13888. lr 3.952751e-04:  79%|███████▉  | 12969/16329 [1:49:11<27:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12969: train loss 1.20402. lr 3.952478e-04:  79%|███████▉  | 12969/16329 [1:49:11<27:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12969: train loss 1.20402. lr 3.952478e-04:  79%|███████▉  | 12970/16329 [1:49:11<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12970: train loss 1.23447. lr 3.952204e-04:  79%|███████▉  | 12970/16329 [1:49:12<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12970: train loss 1.23447. lr 3.952204e-04:  79%|███████▉  | 12971/16329 [1:49:12<27:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12971: train loss 1.20061. lr 3.951930e-04:  79%|███████▉  | 12971/16329 [1:49:12<27:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12971: train loss 1.20061. lr 3.951930e-04:  79%|███████▉  | 12972/16329 [1:49:12<27:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12972: train loss 1.18473. lr 3.951656e-04:  79%|███████▉  | 12972/16329 [1:49:13<27:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12972: train loss 1.18473. lr 3.951656e-04:  79%|███████▉  | 12973/16329 [1:49:13<27:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12973: train loss 1.20950. lr 3.951383e-04:  79%|███████▉  | 12973/16329 [1:49:13<27:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12973: train loss 1.20950. lr 3.951383e-04:  79%|███████▉  | 12974/16329 [1:49:13<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12974: train loss 1.23065. lr 3.951109e-04:  79%|███████▉  | 12974/16329 [1:49:14<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12974: train loss 1.23065. lr 3.951109e-04:  79%|███████▉  | 12975/16329 [1:49:14<27:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12975: train loss 1.17145. lr 3.950835e-04:  79%|███████▉  | 12975/16329 [1:49:14<27:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12975: train loss 1.17145. lr 3.950835e-04:  79%|███████▉  | 12976/16329 [1:49:14<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12976: train loss 1.19905. lr 3.950562e-04:  79%|███████▉  | 12976/16329 [1:49:15<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12976: train loss 1.19905. lr 3.950562e-04:  79%|███████▉  | 12977/16329 [1:49:15<27:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12977: train loss 1.19985. lr 3.950288e-04:  79%|███████▉  | 12977/16329 [1:49:15<27:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12977: train loss 1.19985. lr 3.950288e-04:  79%|███████▉  | 12978/16329 [1:49:15<27:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12978: train loss 1.16299. lr 3.950014e-04:  79%|███████▉  | 12978/16329 [1:49:16<27:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12978: train loss 1.16299. lr 3.950014e-04:  79%|███████▉  | 12979/16329 [1:49:16<27:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12979: train loss 1.18376. lr 3.949740e-04:  79%|███████▉  | 12979/16329 [1:49:16<27:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12979: train loss 1.18376. lr 3.949740e-04:  79%|███████▉  | 12980/16329 [1:49:16<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12980: train loss 1.21391. lr 3.949467e-04:  79%|███████▉  | 12980/16329 [1:49:17<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12980: train loss 1.21391. lr 3.949467e-04:  79%|███████▉  | 12981/16329 [1:49:17<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12981: train loss 1.18099. lr 3.949193e-04:  79%|███████▉  | 12981/16329 [1:49:17<27:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12981: train loss 1.18099. lr 3.949193e-04:  80%|███████▉  | 12982/16329 [1:49:17<27:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12982: train loss 1.21187. lr 3.948919e-04:  80%|███████▉  | 12982/16329 [1:49:18<27:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12982: train loss 1.21187. lr 3.948919e-04:  80%|███████▉  | 12983/16329 [1:49:18<27:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12983: train loss 1.19713. lr 3.948645e-04:  80%|███████▉  | 12983/16329 [1:49:18<27:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12983: train loss 1.19713. lr 3.948645e-04:  80%|███████▉  | 12984/16329 [1:49:18<27:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12984: train loss 1.19941. lr 3.948371e-04:  80%|███████▉  | 12984/16329 [1:49:19<27:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12984: train loss 1.19941. lr 3.948371e-04:  80%|███████▉  | 12985/16329 [1:49:19<27:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12985: train loss 1.21982. lr 3.948098e-04:  80%|███████▉  | 12985/16329 [1:49:19<27:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12985: train loss 1.21982. lr 3.948098e-04:  80%|███████▉  | 12986/16329 [1:49:19<27:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12986: train loss 1.18704. lr 3.947824e-04:  80%|███████▉  | 12986/16329 [1:49:20<27:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12986: train loss 1.18704. lr 3.947824e-04:  80%|███████▉  | 12987/16329 [1:49:20<27:44,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 12987: train loss 1.16755. lr 3.947550e-04:  80%|███████▉  | 12987/16329 [1:49:20<27:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12987: train loss 1.16755. lr 3.947550e-04:  80%|███████▉  | 12988/16329 [1:49:20<27:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12988: train loss 1.19961. lr 3.947276e-04:  80%|███████▉  | 12988/16329 [1:49:21<27:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 12988: train loss 1.19961. lr 3.947276e-04:  80%|███████▉  | 12989/16329 [1:49:21<30:36,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12989: train loss 1.16659. lr 3.947002e-04:  80%|███████▉  | 12989/16329 [1:49:21<30:36,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 12989: train loss 1.16659. lr 3.947002e-04:  80%|███████▉  | 12990/16329 [1:49:21<29:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12990: train loss 1.20269. lr 3.946729e-04:  80%|███████▉  | 12990/16329 [1:49:22<29:46,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 12990: train loss 1.20269. lr 3.946729e-04:  80%|███████▉  | 12991/16329 [1:49:22<29:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12991: train loss 1.18408. lr 3.946455e-04:  80%|███████▉  | 12991/16329 [1:49:22<29:04,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 12991: train loss 1.18408. lr 3.946455e-04:  80%|███████▉  | 12992/16329 [1:49:22<28:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12992: train loss 1.19364. lr 3.946181e-04:  80%|███████▉  | 12992/16329 [1:49:23<28:36,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 12992: train loss 1.19364. lr 3.946181e-04:  80%|███████▉  | 12993/16329 [1:49:23<28:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12993: train loss 1.20880. lr 3.945907e-04:  80%|███████▉  | 12993/16329 [1:49:23<28:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 12993: train loss 1.20880. lr 3.945907e-04:  80%|███████▉  | 12994/16329 [1:49:23<28:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12994: train loss 1.20372. lr 3.945633e-04:  80%|███████▉  | 12994/16329 [1:49:24<28:03,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 12994: train loss 1.20372. lr 3.945633e-04:  80%|███████▉  | 12995/16329 [1:49:24<27:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12995: train loss 1.21358. lr 3.945359e-04:  80%|███████▉  | 12995/16329 [1:49:24<27:57,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12995: train loss 1.21358. lr 3.945359e-04:  80%|███████▉  | 12996/16329 [1:49:24<27:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12996: train loss 1.17667. lr 3.945085e-04:  80%|███████▉  | 12996/16329 [1:49:25<27:51,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12996: train loss 1.17667. lr 3.945085e-04:  80%|███████▉  | 12997/16329 [1:49:25<27:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12997: train loss 1.20921. lr 3.944811e-04:  80%|███████▉  | 12997/16329 [1:49:25<27:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 12997: train loss 1.20921. lr 3.944811e-04:  80%|███████▉  | 12998/16329 [1:49:25<27:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12998: train loss 1.24449. lr 3.944537e-04:  80%|███████▉  | 12998/16329 [1:49:26<27:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12998: train loss 1.24449. lr 3.944537e-04:  80%|███████▉  | 12999/16329 [1:49:26<27:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12999: train loss 1.18803. lr 3.944263e-04:  80%|███████▉  | 12999/16329 [1:49:26<27:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 12999: train loss 1.18803. lr 3.944263e-04:  80%|███████▉  | 13000/16329 [1:49:26<27:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13000: train loss 1.21138. lr 3.943990e-04:  80%|███████▉  | 13000/16329 [1:49:27<27:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13000: train loss 1.21138. lr 3.943990e-04:  80%|███████▉  | 13001/16329 [1:49:27<27:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13001: train loss 1.21533. lr 3.943716e-04:  80%|███████▉  | 13001/16329 [1:49:27<27:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13001: train loss 1.21533. lr 3.943716e-04:  80%|███████▉  | 13002/16329 [1:49:27<27:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13002: train loss 1.24106. lr 3.943442e-04:  80%|███████▉  | 13002/16329 [1:49:28<27:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13002: train loss 1.24106. lr 3.943442e-04:  80%|███████▉  | 13003/16329 [1:49:28<27:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13003: train loss 1.20735. lr 3.943168e-04:  80%|███████▉  | 13003/16329 [1:49:28<27:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13003: train loss 1.20735. lr 3.943168e-04:  80%|███████▉  | 13004/16329 [1:49:28<27:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13004: train loss 1.20566. lr 3.942894e-04:  80%|███████▉  | 13004/16329 [1:49:29<27:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13004: train loss 1.20566. lr 3.942894e-04:  80%|███████▉  | 13005/16329 [1:49:29<27:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13005: train loss 1.19402. lr 3.942620e-04:  80%|███████▉  | 13005/16329 [1:49:29<27:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13005: train loss 1.19402. lr 3.942620e-04:  80%|███████▉  | 13006/16329 [1:49:29<27:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13006: train loss 1.20158. lr 3.942346e-04:  80%|███████▉  | 13006/16329 [1:49:30<27:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13006: train loss 1.20158. lr 3.942346e-04:  80%|███████▉  | 13007/16329 [1:49:30<27:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13007: train loss 1.18327. lr 3.942072e-04:  80%|███████▉  | 13007/16329 [1:49:30<27:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13007: train loss 1.18327. lr 3.942072e-04:  80%|███████▉  | 13008/16329 [1:49:30<27:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13008: train loss 1.15317. lr 3.941798e-04:  80%|███████▉  | 13008/16329 [1:49:31<27:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13008: train loss 1.15317. lr 3.941798e-04:  80%|███████▉  | 13009/16329 [1:49:31<27:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13009: train loss 1.21704. lr 3.941524e-04:  80%|███████▉  | 13009/16329 [1:49:31<27:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13009: train loss 1.21704. lr 3.941524e-04:  80%|███████▉  | 13010/16329 [1:49:31<27:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13010: train loss 1.19493. lr 3.941250e-04:  80%|███████▉  | 13010/16329 [1:49:32<27:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13010: train loss 1.19493. lr 3.941250e-04:  80%|███████▉  | 13011/16329 [1:49:32<27:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13011: train loss 1.17315. lr 3.940976e-04:  80%|███████▉  | 13011/16329 [1:49:32<27:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13011: train loss 1.17315. lr 3.940976e-04:  80%|███████▉  | 13012/16329 [1:49:32<27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13012: train loss 1.20787. lr 3.940702e-04:  80%|███████▉  | 13012/16329 [1:49:33<27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13012: train loss 1.20787. lr 3.940702e-04:  80%|███████▉  | 13013/16329 [1:49:33<27:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13013: train loss 1.17503. lr 3.940428e-04:  80%|███████▉  | 13013/16329 [1:49:33<27:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13013: train loss 1.17503. lr 3.940428e-04:  80%|███████▉  | 13014/16329 [1:49:33<27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13014: train loss 1.24160. lr 3.940153e-04:  80%|███████▉  | 13014/16329 [1:49:34<27:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13014: train loss 1.24160. lr 3.940153e-04:  80%|███████▉  | 13015/16329 [1:49:34<27:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13015: train loss 1.19988. lr 3.939879e-04:  80%|███████▉  | 13015/16329 [1:49:34<27:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13015: train loss 1.19988. lr 3.939879e-04:  80%|███████▉  | 13016/16329 [1:49:34<27:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13016: train loss 1.20556. lr 3.939605e-04:  80%|███████▉  | 13016/16329 [1:49:35<27:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13016: train loss 1.20556. lr 3.939605e-04:  80%|███████▉  | 13017/16329 [1:49:35<27:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13017: train loss 1.21964. lr 3.939331e-04:  80%|███████▉  | 13017/16329 [1:49:35<27:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13017: train loss 1.21964. lr 3.939331e-04:  80%|███████▉  | 13018/16329 [1:49:35<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13018: train loss 1.18201. lr 3.939057e-04:  80%|███████▉  | 13018/16329 [1:49:36<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13018: train loss 1.18201. lr 3.939057e-04:  80%|███████▉  | 13019/16329 [1:49:36<27:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13019: train loss 1.24220. lr 3.938783e-04:  80%|███████▉  | 13019/16329 [1:49:36<27:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13019: train loss 1.24220. lr 3.938783e-04:  80%|███████▉  | 13020/16329 [1:49:36<27:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13020: train loss 1.14927. lr 3.938509e-04:  80%|███████▉  | 13020/16329 [1:49:37<27:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13020: train loss 1.14927. lr 3.938509e-04:  80%|███████▉  | 13021/16329 [1:49:37<27:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13021: train loss 1.18977. lr 3.938235e-04:  80%|███████▉  | 13021/16329 [1:49:37<27:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13021: train loss 1.18977. lr 3.938235e-04:  80%|███████▉  | 13022/16329 [1:49:37<27:20,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13022: train loss 1.16827. lr 3.937961e-04:  80%|███████▉  | 13022/16329 [1:49:38<27:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13022: train loss 1.16827. lr 3.937961e-04:  80%|███████▉  | 13023/16329 [1:49:38<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13023: train loss 1.22341. lr 3.937687e-04:  80%|███████▉  | 13023/16329 [1:49:38<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13023: train loss 1.22341. lr 3.937687e-04:  80%|███████▉  | 13024/16329 [1:49:38<30:21,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13024: train loss 1.24182. lr 3.937412e-04:  80%|███████▉  | 13024/16329 [1:49:39<30:21,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13024: train loss 1.24182. lr 3.937412e-04:  80%|███████▉  | 13025/16329 [1:49:39<29:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13025: train loss 1.19716. lr 3.937138e-04:  80%|███████▉  | 13025/16329 [1:49:39<29:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13025: train loss 1.19716. lr 3.937138e-04:  80%|███████▉  | 13026/16329 [1:49:39<28:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13026: train loss 1.19189. lr 3.936864e-04:  80%|███████▉  | 13026/16329 [1:49:40<28:46,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13026: train loss 1.19189. lr 3.936864e-04:  80%|███████▉  | 13027/16329 [1:49:40<28:18,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13027: train loss 1.19842. lr 3.936590e-04:  80%|███████▉  | 13027/16329 [1:49:40<28:18,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13027: train loss 1.19842. lr 3.936590e-04:  80%|███████▉  | 13028/16329 [1:49:40<27:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13028: train loss 1.18780. lr 3.936316e-04:  80%|███████▉  | 13028/16329 [1:49:41<27:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13028: train loss 1.18780. lr 3.936316e-04:  80%|███████▉  | 13029/16329 [1:49:41<27:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13029: train loss 1.20468. lr 3.936042e-04:  80%|███████▉  | 13029/16329 [1:49:41<27:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13029: train loss 1.20468. lr 3.936042e-04:  80%|███████▉  | 13030/16329 [1:49:41<27:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13030: train loss 1.17695. lr 3.935767e-04:  80%|███████▉  | 13030/16329 [1:49:42<27:36,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13030: train loss 1.17695. lr 3.935767e-04:  80%|███████▉  | 13031/16329 [1:49:42<27:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13031: train loss 1.20601. lr 3.935493e-04:  80%|███████▉  | 13031/16329 [1:49:42<27:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13031: train loss 1.20601. lr 3.935493e-04:  80%|███████▉  | 13032/16329 [1:49:42<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13032: train loss 1.16001. lr 3.935219e-04:  80%|███████▉  | 13032/16329 [1:49:43<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13032: train loss 1.16001. lr 3.935219e-04:  80%|███████▉  | 13033/16329 [1:49:43<27:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13033: train loss 1.19134. lr 3.934945e-04:  80%|███████▉  | 13033/16329 [1:49:43<27:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13033: train loss 1.19134. lr 3.934945e-04:  80%|███████▉  | 13034/16329 [1:49:43<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13034: train loss 1.17846. lr 3.934670e-04:  80%|███████▉  | 13034/16329 [1:49:44<27:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13034: train loss 1.17846. lr 3.934670e-04:  80%|███████▉  | 13035/16329 [1:49:44<27:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13035: train loss 1.18517. lr 3.934396e-04:  80%|███████▉  | 13035/16329 [1:49:44<27:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13035: train loss 1.18517. lr 3.934396e-04:  80%|███████▉  | 13036/16329 [1:49:44<27:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13036: train loss 1.24970. lr 3.934122e-04:  80%|███████▉  | 13036/16329 [1:49:45<27:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13036: train loss 1.24970. lr 3.934122e-04:  80%|███████▉  | 13037/16329 [1:49:45<27:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13037: train loss 1.18487. lr 3.933848e-04:  80%|███████▉  | 13037/16329 [1:49:45<27:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13037: train loss 1.18487. lr 3.933848e-04:  80%|███████▉  | 13038/16329 [1:49:45<27:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13038: train loss 1.21199. lr 3.933573e-04:  80%|███████▉  | 13038/16329 [1:49:46<27:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13038: train loss 1.21199. lr 3.933573e-04:  80%|███████▉  | 13039/16329 [1:49:46<27:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13039: train loss 1.18459. lr 3.933299e-04:  80%|███████▉  | 13039/16329 [1:49:46<27:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13039: train loss 1.18459. lr 3.933299e-04:  80%|███████▉  | 13040/16329 [1:49:46<27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13040: train loss 1.21024. lr 3.933025e-04:  80%|███████▉  | 13040/16329 [1:49:47<27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13040: train loss 1.21024. lr 3.933025e-04:  80%|███████▉  | 13041/16329 [1:49:47<27:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13041: train loss 1.18359. lr 3.932751e-04:  80%|███████▉  | 13041/16329 [1:49:47<27:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13041: train loss 1.18359. lr 3.932751e-04:  80%|███████▉  | 13042/16329 [1:49:47<27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13042: train loss 1.18855. lr 3.932476e-04:  80%|███████▉  | 13042/16329 [1:49:48<27:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13042: train loss 1.18855. lr 3.932476e-04:  80%|███████▉  | 13043/16329 [1:49:48<27:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13043: train loss 1.22690. lr 3.932202e-04:  80%|███████▉  | 13043/16329 [1:49:48<27:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13043: train loss 1.22690. lr 3.932202e-04:  80%|███████▉  | 13044/16329 [1:49:48<27:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13044: train loss 1.19148. lr 3.931928e-04:  80%|███████▉  | 13044/16329 [1:49:49<27:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13044: train loss 1.19148. lr 3.931928e-04:  80%|███████▉  | 13045/16329 [1:49:49<27:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13045: train loss 1.20566. lr 3.931653e-04:  80%|███████▉  | 13045/16329 [1:49:49<27:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13045: train loss 1.20566. lr 3.931653e-04:  80%|███████▉  | 13046/16329 [1:49:49<27:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13046: train loss 1.20363. lr 3.931379e-04:  80%|███████▉  | 13046/16329 [1:49:50<27:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13046: train loss 1.20363. lr 3.931379e-04:  80%|███████▉  | 13047/16329 [1:49:50<27:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13047: train loss 1.20578. lr 3.931105e-04:  80%|███████▉  | 13047/16329 [1:49:50<27:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13047: train loss 1.20578. lr 3.931105e-04:  80%|███████▉  | 13048/16329 [1:49:50<27:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13048: train loss 1.19204. lr 3.930830e-04:  80%|███████▉  | 13048/16329 [1:49:51<27:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13048: train loss 1.19204. lr 3.930830e-04:  80%|███████▉  | 13049/16329 [1:49:51<29:57,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13049: train loss 1.21126. lr 3.930556e-04:  80%|███████▉  | 13049/16329 [1:49:51<29:57,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13049: train loss 1.21126. lr 3.930556e-04:  80%|███████▉  | 13050/16329 [1:49:51<29:11,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13050: train loss 1.18378. lr 3.930282e-04:  80%|███████▉  | 13050/16329 [1:49:52<29:11,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13050: train loss 1.18378. lr 3.930282e-04:  80%|███████▉  | 13051/16329 [1:49:52<28:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13051: train loss 1.19834. lr 3.930007e-04:  80%|███████▉  | 13051/16329 [1:49:52<28:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13051: train loss 1.19834. lr 3.930007e-04:  80%|███████▉  | 13052/16329 [1:49:52<28:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13052: train loss 1.16234. lr 3.929733e-04:  80%|███████▉  | 13052/16329 [1:49:53<28:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13052: train loss 1.16234. lr 3.929733e-04:  80%|███████▉  | 13053/16329 [1:49:53<27:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13053: train loss 1.20167. lr 3.929458e-04:  80%|███████▉  | 13053/16329 [1:49:53<27:51,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13053: train loss 1.20167. lr 3.929458e-04:  80%|███████▉  | 13054/16329 [1:49:53<27:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13054: train loss 1.19495. lr 3.929184e-04:  80%|███████▉  | 13054/16329 [1:49:54<27:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13054: train loss 1.19495. lr 3.929184e-04:  80%|███████▉  | 13055/16329 [1:49:54<27:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13055: train loss 1.18772. lr 3.928910e-04:  80%|███████▉  | 13055/16329 [1:49:54<27:31,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13055: train loss 1.18772. lr 3.928910e-04:  80%|███████▉  | 13056/16329 [1:49:54<27:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13056: train loss 1.22000. lr 3.928635e-04:  80%|███████▉  | 13056/16329 [1:49:55<27:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13056: train loss 1.22000. lr 3.928635e-04:  80%|███████▉  | 13057/16329 [1:49:55<27:22,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13057: train loss 1.19951. lr 3.928361e-04:  80%|███████▉  | 13057/16329 [1:49:55<27:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13057: train loss 1.19951. lr 3.928361e-04:  80%|███████▉  | 13058/16329 [1:49:55<27:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13058: train loss 1.19043. lr 3.928086e-04:  80%|███████▉  | 13058/16329 [1:49:56<27:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13058: train loss 1.19043. lr 3.928086e-04:  80%|███████▉  | 13059/16329 [1:49:56<27:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13059: train loss 1.20169. lr 3.927812e-04:  80%|███████▉  | 13059/16329 [1:49:56<27:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13059: train loss 1.20169. lr 3.927812e-04:  80%|███████▉  | 13060/16329 [1:49:56<27:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13060: train loss 1.19036. lr 3.927537e-04:  80%|███████▉  | 13060/16329 [1:49:57<27:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13060: train loss 1.19036. lr 3.927537e-04:  80%|███████▉  | 13061/16329 [1:49:57<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13061: train loss 1.19180. lr 3.927263e-04:  80%|███████▉  | 13061/16329 [1:49:57<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13061: train loss 1.19180. lr 3.927263e-04:  80%|███████▉  | 13062/16329 [1:49:57<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13062: train loss 1.21027. lr 3.926988e-04:  80%|███████▉  | 13062/16329 [1:49:58<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13062: train loss 1.21027. lr 3.926988e-04:  80%|███████▉  | 13063/16329 [1:49:58<27:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13063: train loss 1.17166. lr 3.926714e-04:  80%|███████▉  | 13063/16329 [1:49:58<27:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13063: train loss 1.17166. lr 3.926714e-04:  80%|████████  | 13064/16329 [1:49:58<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13064: train loss 1.17184. lr 3.926439e-04:  80%|████████  | 13064/16329 [1:49:59<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13064: train loss 1.17184. lr 3.926439e-04:  80%|████████  | 13065/16329 [1:49:59<27:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13065: train loss 1.18367. lr 3.926165e-04:  80%|████████  | 13065/16329 [1:49:59<27:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13065: train loss 1.18367. lr 3.926165e-04:  80%|████████  | 13066/16329 [1:49:59<27:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13066: train loss 1.17154. lr 3.925890e-04:  80%|████████  | 13066/16329 [1:50:00<27:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13066: train loss 1.17154. lr 3.925890e-04:  80%|████████  | 13067/16329 [1:50:00<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13067: train loss 1.23077. lr 3.925616e-04:  80%|████████  | 13067/16329 [1:50:00<27:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13067: train loss 1.23077. lr 3.925616e-04:  80%|████████  | 13068/16329 [1:50:00<27:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13068: train loss 1.18062. lr 3.925341e-04:  80%|████████  | 13068/16329 [1:50:01<27:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13068: train loss 1.18062. lr 3.925341e-04:  80%|████████  | 13069/16329 [1:50:01<26:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13069: train loss 1.17271. lr 3.925067e-04:  80%|████████  | 13069/16329 [1:50:01<26:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13069: train loss 1.17271. lr 3.925067e-04:  80%|████████  | 13070/16329 [1:50:01<26:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13070: train loss 1.14637. lr 3.924792e-04:  80%|████████  | 13070/16329 [1:50:02<26:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13070: train loss 1.14637. lr 3.924792e-04:  80%|████████  | 13071/16329 [1:50:02<27:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13071: train loss 1.18886. lr 3.924518e-04:  80%|████████  | 13071/16329 [1:50:02<27:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13071: train loss 1.18886. lr 3.924518e-04:  80%|████████  | 13072/16329 [1:50:02<27:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13072: train loss 1.19675. lr 3.924243e-04:  80%|████████  | 13072/16329 [1:50:03<27:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13072: train loss 1.19675. lr 3.924243e-04:  80%|████████  | 13073/16329 [1:50:03<28:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13073: train loss 1.19601. lr 3.923969e-04:  80%|████████  | 13073/16329 [1:50:03<28:07,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13073: train loss 1.19601. lr 3.923969e-04:  80%|████████  | 13074/16329 [1:50:03<28:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13074: train loss 1.19751. lr 3.923694e-04:  80%|████████  | 13074/16329 [1:50:04<28:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13074: train loss 1.19751. lr 3.923694e-04:  80%|████████  | 13075/16329 [1:50:04<27:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13075: train loss 1.20789. lr 3.923419e-04:  80%|████████  | 13075/16329 [1:50:05<27:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13075: train loss 1.20789. lr 3.923419e-04:  80%|████████  | 13076/16329 [1:50:05<30:10,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13076: train loss 1.14986. lr 3.923145e-04:  80%|████████  | 13076/16329 [1:50:05<30:10,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13076: train loss 1.14986. lr 3.923145e-04:  80%|████████  | 13077/16329 [1:50:05<29:12,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13077: train loss 1.18735. lr 3.922870e-04:  80%|████████  | 13077/16329 [1:50:06<29:12,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13077: train loss 1.18735. lr 3.922870e-04:  80%|████████  | 13078/16329 [1:50:06<28:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13078: train loss 1.19076. lr 3.922596e-04:  80%|████████  | 13078/16329 [1:50:06<28:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13078: train loss 1.19076. lr 3.922596e-04:  80%|████████  | 13079/16329 [1:50:06<28:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13079: train loss 1.20468. lr 3.922321e-04:  80%|████████  | 13079/16329 [1:50:07<28:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13079: train loss 1.20468. lr 3.922321e-04:  80%|████████  | 13080/16329 [1:50:07<27:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13080: train loss 1.17996. lr 3.922046e-04:  80%|████████  | 13080/16329 [1:50:07<27:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13080: train loss 1.17996. lr 3.922046e-04:  80%|████████  | 13081/16329 [1:50:07<27:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13081: train loss 1.19007. lr 3.921772e-04:  80%|████████  | 13081/16329 [1:50:08<27:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13081: train loss 1.19007. lr 3.921772e-04:  80%|████████  | 13082/16329 [1:50:08<27:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13082: train loss 1.17809. lr 3.921497e-04:  80%|████████  | 13082/16329 [1:50:08<27:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13082: train loss 1.17809. lr 3.921497e-04:  80%|████████  | 13083/16329 [1:50:08<27:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13083: train loss 1.18970. lr 3.921222e-04:  80%|████████  | 13083/16329 [1:50:09<27:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13083: train loss 1.18970. lr 3.921222e-04:  80%|████████  | 13084/16329 [1:50:09<27:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13084: train loss 1.18889. lr 3.920948e-04:  80%|████████  | 13084/16329 [1:50:09<27:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13084: train loss 1.18889. lr 3.920948e-04:  80%|████████  | 13085/16329 [1:50:09<26:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13085: train loss 1.16032. lr 3.920673e-04:  80%|████████  | 13085/16329 [1:50:10<26:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13085: train loss 1.16032. lr 3.920673e-04:  80%|████████  | 13086/16329 [1:50:10<26:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13086: train loss 1.17196. lr 3.920398e-04:  80%|████████  | 13086/16329 [1:50:10<26:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13086: train loss 1.17196. lr 3.920398e-04:  80%|████████  | 13087/16329 [1:50:10<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13087: train loss 1.17033. lr 3.920124e-04:  80%|████████  | 13087/16329 [1:50:11<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13087: train loss 1.17033. lr 3.920124e-04:  80%|████████  | 13088/16329 [1:50:11<26:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13088: train loss 1.21279. lr 3.919849e-04:  80%|████████  | 13088/16329 [1:50:11<26:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13088: train loss 1.21279. lr 3.919849e-04:  80%|████████  | 13089/16329 [1:50:11<26:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13089: train loss 1.19772. lr 3.919574e-04:  80%|████████  | 13089/16329 [1:50:12<26:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13089: train loss 1.19772. lr 3.919574e-04:  80%|████████  | 13090/16329 [1:50:12<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13090: train loss 1.19659. lr 3.919300e-04:  80%|████████  | 13090/16329 [1:50:12<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13090: train loss 1.19659. lr 3.919300e-04:  80%|████████  | 13091/16329 [1:50:12<26:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13091: train loss 1.23269. lr 3.919025e-04:  80%|████████  | 13091/16329 [1:50:13<26:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13091: train loss 1.23269. lr 3.919025e-04:  80%|████████  | 13092/16329 [1:50:13<26:52,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13092: train loss 1.18914. lr 3.918750e-04:  80%|████████  | 13092/16329 [1:50:13<26:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13092: train loss 1.18914. lr 3.918750e-04:  80%|████████  | 13093/16329 [1:50:13<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13093: train loss 1.17917. lr 3.918475e-04:  80%|████████  | 13093/16329 [1:50:14<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13093: train loss 1.17917. lr 3.918475e-04:  80%|████████  | 13094/16329 [1:50:14<26:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13094: train loss 1.23278. lr 3.918201e-04:  80%|████████  | 13094/16329 [1:50:14<26:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13094: train loss 1.23278. lr 3.918201e-04:  80%|████████  | 13095/16329 [1:50:14<26:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13095: train loss 1.20925. lr 3.917926e-04:  80%|████████  | 13095/16329 [1:50:15<26:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13095: train loss 1.20925. lr 3.917926e-04:  80%|████████  | 13096/16329 [1:50:15<26:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13096: train loss 1.20848. lr 3.917651e-04:  80%|████████  | 13096/16329 [1:50:15<26:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13096: train loss 1.20848. lr 3.917651e-04:  80%|████████  | 13097/16329 [1:50:15<26:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13097: train loss 1.17027. lr 3.917376e-04:  80%|████████  | 13097/16329 [1:50:16<26:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13097: train loss 1.17027. lr 3.917376e-04:  80%|████████  | 13098/16329 [1:50:16<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13098: train loss 1.21929. lr 3.917102e-04:  80%|████████  | 13098/16329 [1:50:16<26:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13098: train loss 1.21929. lr 3.917102e-04:  80%|████████  | 13099/16329 [1:50:16<26:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13099: train loss 1.18144. lr 3.916827e-04:  80%|████████  | 13099/16329 [1:50:17<26:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13099: train loss 1.18144. lr 3.916827e-04:  80%|████████  | 13100/16329 [1:50:17<26:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13100: train loss 1.23421. lr 3.916552e-04:  80%|████████  | 13100/16329 [1:50:17<26:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13100: train loss 1.23421. lr 3.916552e-04:  80%|████████  | 13101/16329 [1:50:17<26:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13101: train loss 1.17917. lr 3.916277e-04:  80%|████████  | 13101/16329 [1:50:18<26:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13101: train loss 1.17917. lr 3.916277e-04:  80%|████████  | 13102/16329 [1:50:18<26:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13102: train loss 1.19895. lr 3.916002e-04:  80%|████████  | 13102/16329 [1:50:18<26:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13102: train loss 1.19895. lr 3.916002e-04:  80%|████████  | 13103/16329 [1:50:18<26:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13103: train loss 1.19340. lr 3.915728e-04:  80%|████████  | 13103/16329 [1:50:19<26:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13103: train loss 1.19340. lr 3.915728e-04:  80%|████████  | 13104/16329 [1:50:19<26:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13104: train loss 1.23834. lr 3.915453e-04:  80%|████████  | 13104/16329 [1:50:19<26:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13104: train loss 1.23834. lr 3.915453e-04:  80%|████████  | 13105/16329 [1:50:19<26:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13105: train loss 1.20836. lr 3.915178e-04:  80%|████████  | 13105/16329 [1:50:20<26:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13105: train loss 1.20836. lr 3.915178e-04:  80%|████████  | 13106/16329 [1:50:20<26:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13106: train loss 1.16633. lr 3.914903e-04:  80%|████████  | 13106/16329 [1:50:20<26:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13106: train loss 1.16633. lr 3.914903e-04:  80%|████████  | 13107/16329 [1:50:20<26:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13107: train loss 1.17256. lr 3.914628e-04:  80%|████████  | 13107/16329 [1:50:21<26:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13107: train loss 1.17256. lr 3.914628e-04:  80%|████████  | 13108/16329 [1:50:21<26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13108: train loss 1.18461. lr 3.914353e-04:  80%|████████  | 13108/16329 [1:50:21<26:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13108: train loss 1.18461. lr 3.914353e-04:  80%|████████  | 13109/16329 [1:50:21<26:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13109: train loss 1.18184. lr 3.914078e-04:  80%|████████  | 13109/16329 [1:50:21<26:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13109: train loss 1.18184. lr 3.914078e-04:  80%|████████  | 13110/16329 [1:50:21<26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13110: train loss 1.20416. lr 3.913804e-04:  80%|████████  | 13110/16329 [1:50:22<26:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13110: train loss 1.20416. lr 3.913804e-04:  80%|████████  | 13111/16329 [1:50:22<27:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13111: train loss 1.19084. lr 3.913529e-04:  80%|████████  | 13111/16329 [1:50:23<27:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13111: train loss 1.19084. lr 3.913529e-04:  80%|████████  | 13112/16329 [1:50:23<27:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13112: train loss 1.17834. lr 3.913254e-04:  80%|████████  | 13112/16329 [1:50:23<27:23,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13112: train loss 1.17834. lr 3.913254e-04:  80%|████████  | 13113/16329 [1:50:23<27:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13113: train loss 1.18186. lr 3.912979e-04:  80%|████████  | 13113/16329 [1:50:24<27:25,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13113: train loss 1.18186. lr 3.912979e-04:  80%|████████  | 13114/16329 [1:50:24<27:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13114: train loss 1.19284. lr 3.912704e-04:  80%|████████  | 13114/16329 [1:50:24<27:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13114: train loss 1.19284. lr 3.912704e-04:  80%|████████  | 13115/16329 [1:50:24<27:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13115: train loss 1.21386. lr 3.912429e-04:  80%|████████  | 13115/16329 [1:50:25<27:19,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13115: train loss 1.21386. lr 3.912429e-04:  80%|████████  | 13116/16329 [1:50:25<29:58,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13116: train loss 1.19087. lr 3.912154e-04:  80%|████████  | 13116/16329 [1:50:25<29:58,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13116: train loss 1.19087. lr 3.912154e-04:  80%|████████  | 13117/16329 [1:50:25<28:55,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13117: train loss 1.21178. lr 3.911879e-04:  80%|████████  | 13117/16329 [1:50:26<28:55,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13117: train loss 1.21178. lr 3.911879e-04:  80%|████████  | 13118/16329 [1:50:26<28:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13118: train loss 1.17278. lr 3.911604e-04:  80%|████████  | 13118/16329 [1:50:26<28:12,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13118: train loss 1.17278. lr 3.911604e-04:  80%|████████  | 13119/16329 [1:50:26<27:45,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13119: train loss 1.18813. lr 3.911329e-04:  80%|████████  | 13119/16329 [1:50:27<27:45,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13119: train loss 1.18813. lr 3.911329e-04:  80%|████████  | 13120/16329 [1:50:27<27:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13120: train loss 1.17932. lr 3.911054e-04:  80%|████████  | 13120/16329 [1:50:27<27:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13120: train loss 1.17932. lr 3.911054e-04:  80%|████████  | 13121/16329 [1:50:27<27:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13121: train loss 1.18937. lr 3.910779e-04:  80%|████████  | 13121/16329 [1:50:28<27:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13121: train loss 1.18937. lr 3.910779e-04:  80%|████████  | 13122/16329 [1:50:28<28:08,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13122: train loss 1.18507. lr 3.910504e-04:  80%|████████  | 13122/16329 [1:50:28<28:08,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13122: train loss 1.18507. lr 3.910504e-04:  80%|████████  | 13123/16329 [1:50:28<28:10,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13123: train loss 1.19646. lr 3.910229e-04:  80%|████████  | 13123/16329 [1:50:29<28:10,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13123: train loss 1.19646. lr 3.910229e-04:  80%|████████  | 13124/16329 [1:50:29<28:03,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13124: train loss 1.13729. lr 3.909954e-04:  80%|████████  | 13124/16329 [1:50:29<28:03,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13124: train loss 1.13729. lr 3.909954e-04:  80%|████████  | 13125/16329 [1:50:29<27:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13125: train loss 1.18274. lr 3.909679e-04:  80%|████████  | 13125/16329 [1:50:30<27:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13125: train loss 1.18274. lr 3.909679e-04:  80%|████████  | 13126/16329 [1:50:30<27:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13126: train loss 1.21095. lr 3.909404e-04:  80%|████████  | 13126/16329 [1:50:30<27:40,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13126: train loss 1.21095. lr 3.909404e-04:  80%|████████  | 13127/16329 [1:50:30<27:27,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13127: train loss 1.20263. lr 3.909129e-04:  80%|████████  | 13127/16329 [1:50:31<27:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13127: train loss 1.20263. lr 3.909129e-04:  80%|████████  | 13128/16329 [1:50:31<27:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13128: train loss 1.19036. lr 3.908854e-04:  80%|████████  | 13128/16329 [1:50:31<27:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13128: train loss 1.19036. lr 3.908854e-04:  80%|████████  | 13129/16329 [1:50:31<26:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13129: train loss 1.16981. lr 3.908579e-04:  80%|████████  | 13129/16329 [1:50:32<26:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13129: train loss 1.16981. lr 3.908579e-04:  80%|████████  | 13130/16329 [1:50:32<26:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13130: train loss 1.13805. lr 3.908304e-04:  80%|████████  | 13130/16329 [1:50:32<26:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13130: train loss 1.13805. lr 3.908304e-04:  80%|████████  | 13131/16329 [1:50:32<26:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13131: train loss 1.20000. lr 3.908029e-04:  80%|████████  | 13131/16329 [1:50:33<26:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13131: train loss 1.20000. lr 3.908029e-04:  80%|████████  | 13132/16329 [1:50:33<26:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13132: train loss 1.16289. lr 3.907754e-04:  80%|████████  | 13132/16329 [1:50:33<26:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13132: train loss 1.16289. lr 3.907754e-04:  80%|████████  | 13133/16329 [1:50:33<26:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13133: train loss 1.16983. lr 3.907479e-04:  80%|████████  | 13133/16329 [1:50:34<26:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13133: train loss 1.16983. lr 3.907479e-04:  80%|████████  | 13134/16329 [1:50:34<26:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13134: train loss 1.19081. lr 3.907204e-04:  80%|████████  | 13134/16329 [1:50:34<26:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13134: train loss 1.19081. lr 3.907204e-04:  80%|████████  | 13135/16329 [1:50:34<26:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13135: train loss 1.18499. lr 3.906929e-04:  80%|████████  | 13135/16329 [1:50:35<26:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13135: train loss 1.18499. lr 3.906929e-04:  80%|████████  | 13136/16329 [1:50:35<26:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13136: train loss 1.16537. lr 3.906654e-04:  80%|████████  | 13136/16329 [1:50:35<26:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13136: train loss 1.16537. lr 3.906654e-04:  80%|████████  | 13137/16329 [1:50:35<26:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13137: train loss 1.21189. lr 3.906378e-04:  80%|████████  | 13137/16329 [1:50:36<26:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13137: train loss 1.21189. lr 3.906378e-04:  80%|████████  | 13138/16329 [1:50:36<26:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13138: train loss 1.18743. lr 3.906103e-04:  80%|████████  | 13138/16329 [1:50:36<26:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13138: train loss 1.18743. lr 3.906103e-04:  80%|████████  | 13139/16329 [1:50:36<26:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13139: train loss 1.19796. lr 3.905828e-04:  80%|████████  | 13139/16329 [1:50:37<26:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13139: train loss 1.19796. lr 3.905828e-04:  80%|████████  | 13140/16329 [1:50:37<26:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13140: train loss 1.18021. lr 3.905553e-04:  80%|████████  | 13140/16329 [1:50:37<26:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13140: train loss 1.18021. lr 3.905553e-04:  80%|████████  | 13141/16329 [1:50:37<26:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13141: train loss 1.18613. lr 3.905278e-04:  80%|████████  | 13141/16329 [1:50:38<26:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13141: train loss 1.18613. lr 3.905278e-04:  80%|████████  | 13142/16329 [1:50:38<26:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13142: train loss 1.21886. lr 3.905003e-04:  80%|████████  | 13142/16329 [1:50:38<26:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13142: train loss 1.21886. lr 3.905003e-04:  80%|████████  | 13143/16329 [1:50:38<26:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13143: train loss 1.14413. lr 3.904728e-04:  80%|████████  | 13143/16329 [1:50:39<26:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13143: train loss 1.14413. lr 3.904728e-04:  80%|████████  | 13144/16329 [1:50:39<26:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13144: train loss 1.18390. lr 3.904452e-04:  80%|████████  | 13144/16329 [1:50:39<26:12,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13144: train loss 1.18390. lr 3.904452e-04:  81%|████████  | 13145/16329 [1:50:39<26:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13145: train loss 1.19667. lr 3.904177e-04:  81%|████████  | 13145/16329 [1:50:40<26:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13145: train loss 1.19667. lr 3.904177e-04:  81%|████████  | 13146/16329 [1:50:40<26:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13146: train loss 1.19709. lr 3.903902e-04:  81%|████████  | 13146/16329 [1:50:40<26:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13146: train loss 1.19709. lr 3.903902e-04:  81%|████████  | 13147/16329 [1:50:40<26:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13147: train loss 1.22404. lr 3.903627e-04:  81%|████████  | 13147/16329 [1:50:41<26:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13147: train loss 1.22404. lr 3.903627e-04:  81%|████████  | 13148/16329 [1:50:41<26:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13148: train loss 1.16572. lr 3.903352e-04:  81%|████████  | 13148/16329 [1:50:41<26:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13148: train loss 1.16572. lr 3.903352e-04:  81%|████████  | 13149/16329 [1:50:41<26:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13149: train loss 1.17836. lr 3.903076e-04:  81%|████████  | 13149/16329 [1:50:42<26:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13149: train loss 1.17836. lr 3.903076e-04:  81%|████████  | 13150/16329 [1:50:42<26:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13150: train loss 1.19966. lr 3.902801e-04:  81%|████████  | 13150/16329 [1:50:43<26:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13150: train loss 1.19966. lr 3.902801e-04:  81%|████████  | 13151/16329 [1:50:43<30:01,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 13151: train loss 1.18613. lr 3.902526e-04:  81%|████████  | 13151/16329 [1:50:43<30:01,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 13151: train loss 1.18613. lr 3.902526e-04:  81%|████████  | 13152/16329 [1:50:43<29:08,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13152: train loss 1.19589. lr 3.902251e-04:  81%|████████  | 13152/16329 [1:50:44<29:08,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13152: train loss 1.19589. lr 3.902251e-04:  81%|████████  | 13153/16329 [1:50:44<28:29,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13153: train loss 1.23636. lr 3.901976e-04:  81%|████████  | 13153/16329 [1:50:44<28:29,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13153: train loss 1.23636. lr 3.901976e-04:  81%|████████  | 13154/16329 [1:50:44<27:53,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13154: train loss 1.21123. lr 3.901700e-04:  81%|████████  | 13154/16329 [1:50:45<27:53,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13154: train loss 1.21123. lr 3.901700e-04:  81%|████████  | 13155/16329 [1:50:45<27:30,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13155: train loss 1.19763. lr 3.901425e-04:  81%|████████  | 13155/16329 [1:50:45<27:30,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13155: train loss 1.19763. lr 3.901425e-04:  81%|████████  | 13156/16329 [1:50:45<27:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13156: train loss 1.19887. lr 3.901150e-04:  81%|████████  | 13156/16329 [1:50:46<27:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13156: train loss 1.19887. lr 3.901150e-04:  81%|████████  | 13157/16329 [1:50:46<26:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13157: train loss 1.18927. lr 3.900874e-04:  81%|████████  | 13157/16329 [1:50:46<26:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13157: train loss 1.18927. lr 3.900874e-04:  81%|████████  | 13158/16329 [1:50:46<26:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13158: train loss 1.19995. lr 3.900599e-04:  81%|████████  | 13158/16329 [1:50:47<26:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13158: train loss 1.19995. lr 3.900599e-04:  81%|████████  | 13159/16329 [1:50:47<26:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13159: train loss 1.19425. lr 3.900324e-04:  81%|████████  | 13159/16329 [1:50:47<26:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13159: train loss 1.19425. lr 3.900324e-04:  81%|████████  | 13160/16329 [1:50:47<26:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13160: train loss 1.16152. lr 3.900049e-04:  81%|████████  | 13160/16329 [1:50:48<26:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13160: train loss 1.16152. lr 3.900049e-04:  81%|████████  | 13161/16329 [1:50:48<26:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13161: train loss 1.21462. lr 3.899773e-04:  81%|████████  | 13161/16329 [1:50:48<26:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13161: train loss 1.21462. lr 3.899773e-04:  81%|████████  | 13162/16329 [1:50:48<26:18,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13162: train loss 1.19267. lr 3.899498e-04:  81%|████████  | 13162/16329 [1:50:49<26:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13162: train loss 1.19267. lr 3.899498e-04:  81%|████████  | 13163/16329 [1:50:49<26:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13163: train loss 1.20583. lr 3.899223e-04:  81%|████████  | 13163/16329 [1:50:49<26:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13163: train loss 1.20583. lr 3.899223e-04:  81%|████████  | 13164/16329 [1:50:49<26:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13164: train loss 1.19983. lr 3.898947e-04:  81%|████████  | 13164/16329 [1:50:50<26:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13164: train loss 1.19983. lr 3.898947e-04:  81%|████████  | 13165/16329 [1:50:50<26:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13165: train loss 1.17684. lr 3.898672e-04:  81%|████████  | 13165/16329 [1:50:50<26:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13165: train loss 1.17684. lr 3.898672e-04:  81%|████████  | 13166/16329 [1:50:50<26:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13166: train loss 1.21880. lr 3.898397e-04:  81%|████████  | 13166/16329 [1:50:51<26:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13166: train loss 1.21880. lr 3.898397e-04:  81%|████████  | 13167/16329 [1:50:51<26:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13167: train loss 1.21597. lr 3.898121e-04:  81%|████████  | 13167/16329 [1:50:51<26:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13167: train loss 1.21597. lr 3.898121e-04:  81%|████████  | 13168/16329 [1:50:51<26:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13168: train loss 1.16698. lr 3.897846e-04:  81%|████████  | 13168/16329 [1:50:52<26:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13168: train loss 1.16698. lr 3.897846e-04:  81%|████████  | 13169/16329 [1:50:52<26:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13169: train loss 1.19543. lr 3.897570e-04:  81%|████████  | 13169/16329 [1:50:52<26:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13169: train loss 1.19543. lr 3.897570e-04:  81%|████████  | 13170/16329 [1:50:52<26:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13170: train loss 1.18930. lr 3.897295e-04:  81%|████████  | 13170/16329 [1:50:53<26:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13170: train loss 1.18930. lr 3.897295e-04:  81%|████████  | 13171/16329 [1:50:53<26:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13171: train loss 1.18945. lr 3.897020e-04:  81%|████████  | 13171/16329 [1:50:53<26:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13171: train loss 1.18945. lr 3.897020e-04:  81%|████████  | 13172/16329 [1:50:53<26:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13172: train loss 1.20873. lr 3.896744e-04:  81%|████████  | 13172/16329 [1:50:54<26:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13172: train loss 1.20873. lr 3.896744e-04:  81%|████████  | 13173/16329 [1:50:54<26:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13173: train loss 1.18562. lr 3.896469e-04:  81%|████████  | 13173/16329 [1:50:54<26:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13173: train loss 1.18562. lr 3.896469e-04:  81%|████████  | 13174/16329 [1:50:54<26:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13174: train loss 1.19621. lr 3.896193e-04:  81%|████████  | 13174/16329 [1:50:55<26:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13174: train loss 1.19621. lr 3.896193e-04:  81%|████████  | 13175/16329 [1:50:55<26:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13175: train loss 1.17087. lr 3.895918e-04:  81%|████████  | 13175/16329 [1:50:55<26:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13175: train loss 1.17087. lr 3.895918e-04:  81%|████████  | 13176/16329 [1:50:55<29:22,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13176: train loss 1.19351. lr 3.895643e-04:  81%|████████  | 13176/16329 [1:50:56<29:22,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13176: train loss 1.19351. lr 3.895643e-04:  81%|████████  | 13177/16329 [1:50:56<29:06,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13177: train loss 1.19965. lr 3.895367e-04:  81%|████████  | 13177/16329 [1:50:56<29:06,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13177: train loss 1.19965. lr 3.895367e-04:  81%|████████  | 13178/16329 [1:50:56<28:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13178: train loss 1.18248. lr 3.895092e-04:  81%|████████  | 13178/16329 [1:50:57<28:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13178: train loss 1.18248. lr 3.895092e-04:  81%|████████  | 13179/16329 [1:50:57<28:35,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 13179: train loss 1.16197. lr 3.894816e-04:  81%|████████  | 13179/16329 [1:50:57<28:35,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 13179: train loss 1.16197. lr 3.894816e-04:  81%|████████  | 13180/16329 [1:50:57<28:13,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13180: train loss 1.16987. lr 3.894541e-04:  81%|████████  | 13180/16329 [1:50:58<28:13,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13180: train loss 1.16987. lr 3.894541e-04:  81%|████████  | 13181/16329 [1:50:58<27:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13181: train loss 1.19175. lr 3.894265e-04:  81%|████████  | 13181/16329 [1:50:58<27:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13181: train loss 1.19175. lr 3.894265e-04:  81%|████████  | 13182/16329 [1:50:58<27:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13182: train loss 1.20848. lr 3.893990e-04:  81%|████████  | 13182/16329 [1:50:59<27:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13182: train loss 1.20848. lr 3.893990e-04:  81%|████████  | 13183/16329 [1:50:59<27:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13183: train loss 1.17797. lr 3.893714e-04:  81%|████████  | 13183/16329 [1:50:59<27:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13183: train loss 1.17797. lr 3.893714e-04:  81%|████████  | 13184/16329 [1:50:59<26:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13184: train loss 1.20011. lr 3.893439e-04:  81%|████████  | 13184/16329 [1:51:00<26:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13184: train loss 1.20011. lr 3.893439e-04:  81%|████████  | 13185/16329 [1:51:00<26:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13185: train loss 1.17190. lr 3.893163e-04:  81%|████████  | 13185/16329 [1:51:00<26:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13185: train loss 1.17190. lr 3.893163e-04:  81%|████████  | 13186/16329 [1:51:00<26:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13186: train loss 1.17302. lr 3.892888e-04:  81%|████████  | 13186/16329 [1:51:01<26:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13186: train loss 1.17302. lr 3.892888e-04:  81%|████████  | 13187/16329 [1:51:01<26:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13187: train loss 1.17281. lr 3.892612e-04:  81%|████████  | 13187/16329 [1:51:01<26:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13187: train loss 1.17281. lr 3.892612e-04:  81%|████████  | 13188/16329 [1:51:01<26:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13188: train loss 1.20759. lr 3.892337e-04:  81%|████████  | 13188/16329 [1:51:02<26:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13188: train loss 1.20759. lr 3.892337e-04:  81%|████████  | 13189/16329 [1:51:02<26:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13189: train loss 1.17575. lr 3.892061e-04:  81%|████████  | 13189/16329 [1:51:02<26:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13189: train loss 1.17575. lr 3.892061e-04:  81%|████████  | 13190/16329 [1:51:02<25:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13190: train loss 1.17143. lr 3.891786e-04:  81%|████████  | 13190/16329 [1:51:03<25:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13190: train loss 1.17143. lr 3.891786e-04:  81%|████████  | 13191/16329 [1:51:03<26:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13191: train loss 1.23583. lr 3.891510e-04:  81%|████████  | 13191/16329 [1:51:03<26:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13191: train loss 1.23583. lr 3.891510e-04:  81%|████████  | 13192/16329 [1:51:03<25:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13192: train loss 1.19386. lr 3.891234e-04:  81%|████████  | 13192/16329 [1:51:04<25:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13192: train loss 1.19386. lr 3.891234e-04:  81%|████████  | 13193/16329 [1:51:04<25:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13193: train loss 1.21011. lr 3.890959e-04:  81%|████████  | 13193/16329 [1:51:04<25:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13193: train loss 1.21011. lr 3.890959e-04:  81%|████████  | 13194/16329 [1:51:04<25:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13194: train loss 1.19117. lr 3.890683e-04:  81%|████████  | 13194/16329 [1:51:05<25:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13194: train loss 1.19117. lr 3.890683e-04:  81%|████████  | 13195/16329 [1:51:05<25:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13195: train loss 1.17554. lr 3.890408e-04:  81%|████████  | 13195/16329 [1:51:05<25:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13195: train loss 1.17554. lr 3.890408e-04:  81%|████████  | 13196/16329 [1:51:05<25:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13196: train loss 1.21479. lr 3.890132e-04:  81%|████████  | 13196/16329 [1:51:06<25:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13196: train loss 1.21479. lr 3.890132e-04:  81%|████████  | 13197/16329 [1:51:06<25:46,  2.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13197: train loss 1.18984. lr 3.889856e-04:  81%|████████  | 13197/16329 [1:51:06<25:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13197: train loss 1.18984. lr 3.889856e-04:  81%|████████  | 13198/16329 [1:51:06<25:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13198: train loss 1.18655. lr 3.889581e-04:  81%|████████  | 13198/16329 [1:51:07<25:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13198: train loss 1.18655. lr 3.889581e-04:  81%|████████  | 13199/16329 [1:51:07<25:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13199: train loss 1.20035. lr 3.889305e-04:  81%|████████  | 13199/16329 [1:51:07<25:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13199: train loss 1.20035. lr 3.889305e-04:  81%|████████  | 13200/16329 [1:51:07<25:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13200: train loss 1.18147. lr 3.889030e-04:  81%|████████  | 13200/16329 [1:51:08<25:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13200: train loss 1.18147. lr 3.889030e-04:  81%|████████  | 13201/16329 [1:51:08<25:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13201: train loss 1.13891. lr 3.888754e-04:  81%|████████  | 13201/16329 [1:51:08<25:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13201: train loss 1.13891. lr 3.888754e-04:  81%|████████  | 13202/16329 [1:51:08<25:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13202: train loss 1.18382. lr 3.888478e-04:  81%|████████  | 13202/16329 [1:51:09<25:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13202: train loss 1.18382. lr 3.888478e-04:  81%|████████  | 13203/16329 [1:51:09<28:30,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13203: train loss 1.16712. lr 3.888203e-04:  81%|████████  | 13203/16329 [1:51:09<28:30,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13203: train loss 1.16712. lr 3.888203e-04:  81%|████████  | 13204/16329 [1:51:09<27:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13204: train loss 1.21029. lr 3.887927e-04:  81%|████████  | 13204/16329 [1:51:10<27:45,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13204: train loss 1.21029. lr 3.887927e-04:  81%|████████  | 13205/16329 [1:51:10<27:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13205: train loss 1.16675. lr 3.887651e-04:  81%|████████  | 13205/16329 [1:51:10<27:07,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13205: train loss 1.16675. lr 3.887651e-04:  81%|████████  | 13206/16329 [1:51:10<26:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13206: train loss 1.16309. lr 3.887376e-04:  81%|████████  | 13206/16329 [1:51:11<26:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13206: train loss 1.16309. lr 3.887376e-04:  81%|████████  | 13207/16329 [1:51:11<26:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13207: train loss 1.18676. lr 3.887100e-04:  81%|████████  | 13207/16329 [1:51:11<26:29,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13207: train loss 1.18676. lr 3.887100e-04:  81%|████████  | 13208/16329 [1:51:11<26:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13208: train loss 1.16114. lr 3.886824e-04:  81%|████████  | 13208/16329 [1:51:12<26:17,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13208: train loss 1.16114. lr 3.886824e-04:  81%|████████  | 13209/16329 [1:51:12<26:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13209: train loss 1.16783. lr 3.886548e-04:  81%|████████  | 13209/16329 [1:51:12<26:08,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13209: train loss 1.16783. lr 3.886548e-04:  81%|████████  | 13210/16329 [1:51:12<26:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13210: train loss 1.20994. lr 3.886273e-04:  81%|████████  | 13210/16329 [1:51:13<26:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13210: train loss 1.20994. lr 3.886273e-04:  81%|████████  | 13211/16329 [1:51:13<25:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13211: train loss 1.17987. lr 3.885997e-04:  81%|████████  | 13211/16329 [1:51:13<25:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13211: train loss 1.17987. lr 3.885997e-04:  81%|████████  | 13212/16329 [1:51:13<25:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13212: train loss 1.22056. lr 3.885721e-04:  81%|████████  | 13212/16329 [1:51:14<25:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13212: train loss 1.22056. lr 3.885721e-04:  81%|████████  | 13213/16329 [1:51:14<25:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13213: train loss 1.19483. lr 3.885446e-04:  81%|████████  | 13213/16329 [1:51:14<25:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13213: train loss 1.19483. lr 3.885446e-04:  81%|████████  | 13214/16329 [1:51:14<25:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13214: train loss 1.20009. lr 3.885170e-04:  81%|████████  | 13214/16329 [1:51:15<25:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13214: train loss 1.20009. lr 3.885170e-04:  81%|████████  | 13215/16329 [1:51:15<25:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13215: train loss 1.20656. lr 3.884894e-04:  81%|████████  | 13215/16329 [1:51:15<25:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13215: train loss 1.20656. lr 3.884894e-04:  81%|████████  | 13216/16329 [1:51:15<25:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13216: train loss 1.20612. lr 3.884618e-04:  81%|████████  | 13216/16329 [1:51:16<25:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13216: train loss 1.20612. lr 3.884618e-04:  81%|████████  | 13217/16329 [1:51:16<25:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13217: train loss 1.19645. lr 3.884343e-04:  81%|████████  | 13217/16329 [1:51:16<25:36,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13217: train loss 1.19645. lr 3.884343e-04:  81%|████████  | 13218/16329 [1:51:16<25:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13218: train loss 1.17739. lr 3.884067e-04:  81%|████████  | 13218/16329 [1:51:17<25:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13218: train loss 1.17739. lr 3.884067e-04:  81%|████████  | 13219/16329 [1:51:17<25:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13219: train loss 1.18570. lr 3.883791e-04:  81%|████████  | 13219/16329 [1:51:17<25:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13219: train loss 1.18570. lr 3.883791e-04:  81%|████████  | 13220/16329 [1:51:17<25:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13220: train loss 1.17363. lr 3.883515e-04:  81%|████████  | 13220/16329 [1:51:18<25:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13220: train loss 1.17363. lr 3.883515e-04:  81%|████████  | 13221/16329 [1:51:18<25:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13221: train loss 1.17101. lr 3.883239e-04:  81%|████████  | 13221/16329 [1:51:18<25:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13221: train loss 1.17101. lr 3.883239e-04:  81%|████████  | 13222/16329 [1:51:18<25:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13222: train loss 1.18408. lr 3.882964e-04:  81%|████████  | 13222/16329 [1:51:19<25:33,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13222: train loss 1.18408. lr 3.882964e-04:  81%|████████  | 13223/16329 [1:51:19<26:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13223: train loss 1.17991. lr 3.882688e-04:  81%|████████  | 13223/16329 [1:51:19<26:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13223: train loss 1.17991. lr 3.882688e-04:  81%|████████  | 13224/16329 [1:51:19<26:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13224: train loss 1.20393. lr 3.882412e-04:  81%|████████  | 13224/16329 [1:51:20<26:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13224: train loss 1.20393. lr 3.882412e-04:  81%|████████  | 13225/16329 [1:51:20<26:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13225: train loss 1.21674. lr 3.882136e-04:  81%|████████  | 13225/16329 [1:51:20<26:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13225: train loss 1.21674. lr 3.882136e-04:  81%|████████  | 13226/16329 [1:51:20<26:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13226: train loss 1.20271. lr 3.881860e-04:  81%|████████  | 13226/16329 [1:51:21<26:31,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13226: train loss 1.20271. lr 3.881860e-04:  81%|████████  | 13227/16329 [1:51:21<26:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13227: train loss 1.14355. lr 3.881584e-04:  81%|████████  | 13227/16329 [1:51:21<26:25,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13227: train loss 1.14355. lr 3.881584e-04:  81%|████████  | 13228/16329 [1:51:21<26:18,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13228: train loss 1.20281. lr 3.881308e-04:  81%|████████  | 13228/16329 [1:51:22<26:18,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13228: train loss 1.20281. lr 3.881308e-04:  81%|████████  | 13229/16329 [1:51:22<26:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13229: train loss 1.17517. lr 3.881033e-04:  81%|████████  | 13229/16329 [1:51:22<26:10,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13229: train loss 1.17517. lr 3.881033e-04:  81%|████████  | 13230/16329 [1:51:22<26:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13230: train loss 1.16539. lr 3.880757e-04:  81%|████████  | 13230/16329 [1:51:23<26:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13230: train loss 1.16539. lr 3.880757e-04:  81%|████████  | 13231/16329 [1:51:23<26:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13231: train loss 1.21423. lr 3.880481e-04:  81%|████████  | 13231/16329 [1:51:24<26:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13231: train loss 1.21423. lr 3.880481e-04:  81%|████████  | 13232/16329 [1:51:24<27:05,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13232: train loss 1.19628. lr 3.880205e-04:  81%|████████  | 13232/16329 [1:51:24<27:05,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13232: train loss 1.19628. lr 3.880205e-04:  81%|████████  | 13233/16329 [1:51:24<27:10,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13233: train loss 1.21031. lr 3.879929e-04:  81%|████████  | 13233/16329 [1:51:25<27:10,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13233: train loss 1.21031. lr 3.879929e-04:  81%|████████  | 13234/16329 [1:51:25<27:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13234: train loss 1.17583. lr 3.879653e-04:  81%|████████  | 13234/16329 [1:51:25<27:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13234: train loss 1.17583. lr 3.879653e-04:  81%|████████  | 13235/16329 [1:51:25<26:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13235: train loss 1.16880. lr 3.879377e-04:  81%|████████  | 13235/16329 [1:51:26<26:50,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13235: train loss 1.16880. lr 3.879377e-04:  81%|████████  | 13236/16329 [1:51:26<26:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13236: train loss 1.19647. lr 3.879101e-04:  81%|████████  | 13236/16329 [1:51:26<26:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13236: train loss 1.19647. lr 3.879101e-04:  81%|████████  | 13237/16329 [1:51:26<26:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13237: train loss 1.16560. lr 3.878825e-04:  81%|████████  | 13237/16329 [1:51:27<26:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13237: train loss 1.16560. lr 3.878825e-04:  81%|████████  | 13238/16329 [1:51:27<26:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13238: train loss 1.15829. lr 3.878549e-04:  81%|████████  | 13238/16329 [1:51:27<26:05,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13238: train loss 1.15829. lr 3.878549e-04:  81%|████████  | 13239/16329 [1:51:27<25:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13239: train loss 1.17077. lr 3.878273e-04:  81%|████████  | 13239/16329 [1:51:28<25:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13239: train loss 1.17077. lr 3.878273e-04:  81%|████████  | 13240/16329 [1:51:28<25:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13240: train loss 1.14927. lr 3.877997e-04:  81%|████████  | 13240/16329 [1:51:28<25:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13240: train loss 1.14927. lr 3.877997e-04:  81%|████████  | 13241/16329 [1:51:28<25:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13241: train loss 1.18873. lr 3.877721e-04:  81%|████████  | 13241/16329 [1:51:29<25:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13241: train loss 1.18873. lr 3.877721e-04:  81%|████████  | 13242/16329 [1:51:29<25:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13242: train loss 1.21019. lr 3.877445e-04:  81%|████████  | 13242/16329 [1:51:29<25:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13242: train loss 1.21019. lr 3.877445e-04:  81%|████████  | 13243/16329 [1:51:29<28:40,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13243: train loss 1.14017. lr 3.877170e-04:  81%|████████  | 13243/16329 [1:51:30<28:40,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13243: train loss 1.14017. lr 3.877170e-04:  81%|████████  | 13244/16329 [1:51:30<27:40,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13244: train loss 1.17104. lr 3.876894e-04:  81%|████████  | 13244/16329 [1:51:30<27:40,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13244: train loss 1.17104. lr 3.876894e-04:  81%|████████  | 13245/16329 [1:51:30<26:59,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13245: train loss 1.19133. lr 3.876618e-04:  81%|████████  | 13245/16329 [1:51:31<26:59,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13245: train loss 1.19133. lr 3.876618e-04:  81%|████████  | 13246/16329 [1:51:31<26:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13246: train loss 1.17179. lr 3.876342e-04:  81%|████████  | 13246/16329 [1:51:31<26:35,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13246: train loss 1.17179. lr 3.876342e-04:  81%|████████  | 13247/16329 [1:51:31<26:13,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13247: train loss 1.15809. lr 3.876065e-04:  81%|████████  | 13247/16329 [1:51:32<26:13,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13247: train loss 1.15809. lr 3.876065e-04:  81%|████████  | 13248/16329 [1:51:32<26:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13248: train loss 1.17189. lr 3.875789e-04:  81%|████████  | 13248/16329 [1:51:32<26:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13248: train loss 1.17189. lr 3.875789e-04:  81%|████████  | 13249/16329 [1:51:32<25:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13249: train loss 1.17940. lr 3.875513e-04:  81%|████████  | 13249/16329 [1:51:33<25:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13249: train loss 1.17940. lr 3.875513e-04:  81%|████████  | 13250/16329 [1:51:33<25:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13250: train loss 1.18067. lr 3.875237e-04:  81%|████████  | 13250/16329 [1:51:33<25:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13250: train loss 1.18067. lr 3.875237e-04:  81%|████████  | 13251/16329 [1:51:33<25:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13251: train loss 1.20162. lr 3.874961e-04:  81%|████████  | 13251/16329 [1:51:34<25:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13251: train loss 1.20162. lr 3.874961e-04:  81%|████████  | 13252/16329 [1:51:34<25:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13252: train loss 1.16563. lr 3.874685e-04:  81%|████████  | 13252/16329 [1:51:34<25:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13252: train loss 1.16563. lr 3.874685e-04:  81%|████████  | 13253/16329 [1:51:34<25:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13253: train loss 1.19777. lr 3.874409e-04:  81%|████████  | 13253/16329 [1:51:35<25:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13253: train loss 1.19777. lr 3.874409e-04:  81%|████████  | 13254/16329 [1:51:35<25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13254: train loss 1.16243. lr 3.874133e-04:  81%|████████  | 13254/16329 [1:51:35<25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13254: train loss 1.16243. lr 3.874133e-04:  81%|████████  | 13255/16329 [1:51:35<25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13255: train loss 1.16137. lr 3.873857e-04:  81%|████████  | 13255/16329 [1:51:36<25:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13255: train loss 1.16137. lr 3.873857e-04:  81%|████████  | 13256/16329 [1:51:36<25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13256: train loss 1.17999. lr 3.873581e-04:  81%|████████  | 13256/16329 [1:51:36<25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13256: train loss 1.17999. lr 3.873581e-04:  81%|████████  | 13257/16329 [1:51:36<25:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13257: train loss 1.17567. lr 3.873305e-04:  81%|████████  | 13257/16329 [1:51:37<25:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13257: train loss 1.17567. lr 3.873305e-04:  81%|████████  | 13258/16329 [1:51:37<25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13258: train loss 1.16729. lr 3.873029e-04:  81%|████████  | 13258/16329 [1:51:37<25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13258: train loss 1.16729. lr 3.873029e-04:  81%|████████  | 13259/16329 [1:51:37<25:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13259: train loss 1.16863. lr 3.872753e-04:  81%|████████  | 13259/16329 [1:51:38<25:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13259: train loss 1.16863. lr 3.872753e-04:  81%|████████  | 13260/16329 [1:51:38<25:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13260: train loss 1.16979. lr 3.872476e-04:  81%|████████  | 13260/16329 [1:51:38<25:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13260: train loss 1.16979. lr 3.872476e-04:  81%|████████  | 13261/16329 [1:51:38<25:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13261: train loss 1.19929. lr 3.872200e-04:  81%|████████  | 13261/16329 [1:51:39<25:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13261: train loss 1.19929. lr 3.872200e-04:  81%|████████  | 13262/16329 [1:51:39<25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13262: train loss 1.18885. lr 3.871924e-04:  81%|████████  | 13262/16329 [1:51:39<25:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13262: train loss 1.18885. lr 3.871924e-04:  81%|████████  | 13263/16329 [1:51:39<25:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13263: train loss 1.17019. lr 3.871648e-04:  81%|████████  | 13263/16329 [1:51:40<25:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13263: train loss 1.17019. lr 3.871648e-04:  81%|████████  | 13264/16329 [1:51:40<25:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13264: train loss 1.18441. lr 3.871372e-04:  81%|████████  | 13264/16329 [1:51:40<25:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13264: train loss 1.18441. lr 3.871372e-04:  81%|████████  | 13265/16329 [1:51:40<25:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13265: train loss 1.17237. lr 3.871096e-04:  81%|████████  | 13265/16329 [1:51:41<25:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13265: train loss 1.17237. lr 3.871096e-04:  81%|████████  | 13266/16329 [1:51:41<25:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13266: train loss 1.19122. lr 3.870820e-04:  81%|████████  | 13266/16329 [1:51:41<25:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13266: train loss 1.19122. lr 3.870820e-04:  81%|████████  | 13267/16329 [1:51:41<25:19,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13267: train loss 1.16677. lr 3.870543e-04:  81%|████████  | 13267/16329 [1:51:42<25:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13267: train loss 1.16677. lr 3.870543e-04:  81%|████████▏ | 13268/16329 [1:51:42<25:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13268: train loss 1.18119. lr 3.870267e-04:  81%|████████▏ | 13268/16329 [1:51:42<25:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13268: train loss 1.18119. lr 3.870267e-04:  81%|████████▏ | 13269/16329 [1:51:42<25:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13269: train loss 1.19944. lr 3.869991e-04:  81%|████████▏ | 13269/16329 [1:51:43<25:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13269: train loss 1.19944. lr 3.869991e-04:  81%|████████▏ | 13270/16329 [1:51:43<25:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13270: train loss 1.17137. lr 3.869715e-04:  81%|████████▏ | 13270/16329 [1:51:43<25:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13270: train loss 1.17137. lr 3.869715e-04:  81%|████████▏ | 13271/16329 [1:51:43<25:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13271: train loss 1.18180. lr 3.869439e-04:  81%|████████▏ | 13271/16329 [1:51:44<25:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13271: train loss 1.18180. lr 3.869439e-04:  81%|████████▏ | 13272/16329 [1:51:44<25:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13272: train loss 1.19045. lr 3.869162e-04:  81%|████████▏ | 13272/16329 [1:51:44<25:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13272: train loss 1.19045. lr 3.869162e-04:  81%|████████▏ | 13273/16329 [1:51:44<25:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13273: train loss 1.16378. lr 3.868886e-04:  81%|████████▏ | 13273/16329 [1:51:45<25:09,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13273: train loss 1.16378. lr 3.868886e-04:  81%|████████▏ | 13274/16329 [1:51:45<25:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13274: train loss 1.17526. lr 3.868610e-04:  81%|████████▏ | 13274/16329 [1:51:45<25:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13274: train loss 1.17526. lr 3.868610e-04:  81%|████████▏ | 13275/16329 [1:51:45<25:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13275: train loss 1.18053. lr 3.868334e-04:  81%|████████▏ | 13275/16329 [1:51:46<25:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13275: train loss 1.18053. lr 3.868334e-04:  81%|████████▏ | 13276/16329 [1:51:46<25:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13276: train loss 1.19034. lr 3.868057e-04:  81%|████████▏ | 13276/16329 [1:51:46<25:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13276: train loss 1.19034. lr 3.868057e-04:  81%|████████▏ | 13277/16329 [1:51:46<25:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13277: train loss 1.15725. lr 3.867781e-04:  81%|████████▏ | 13277/16329 [1:51:47<25:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13277: train loss 1.15725. lr 3.867781e-04:  81%|████████▏ | 13278/16329 [1:51:47<27:49,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13278: train loss 1.16622. lr 3.867505e-04:  81%|████████▏ | 13278/16329 [1:51:47<27:49,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13278: train loss 1.16622. lr 3.867505e-04:  81%|████████▏ | 13279/16329 [1:51:47<27:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13279: train loss 1.18395. lr 3.867229e-04:  81%|████████▏ | 13279/16329 [1:51:48<27:03,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13279: train loss 1.18395. lr 3.867229e-04:  81%|████████▏ | 13280/16329 [1:51:48<26:28,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13280: train loss 1.17172. lr 3.866952e-04:  81%|████████▏ | 13280/16329 [1:51:48<26:28,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13280: train loss 1.17172. lr 3.866952e-04:  81%|████████▏ | 13281/16329 [1:51:48<26:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13281: train loss 1.15917. lr 3.866676e-04:  81%|████████▏ | 13281/16329 [1:51:49<26:05,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13281: train loss 1.15917. lr 3.866676e-04:  81%|████████▏ | 13282/16329 [1:51:49<25:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13282: train loss 1.20589. lr 3.866400e-04:  81%|████████▏ | 13282/16329 [1:51:49<25:50,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13282: train loss 1.20589. lr 3.866400e-04:  81%|████████▏ | 13283/16329 [1:51:49<25:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13283: train loss 1.17845. lr 3.866123e-04:  81%|████████▏ | 13283/16329 [1:51:50<25:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13283: train loss 1.17845. lr 3.866123e-04:  81%|████████▏ | 13284/16329 [1:51:50<25:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13284: train loss 1.20970. lr 3.865847e-04:  81%|████████▏ | 13284/16329 [1:51:50<25:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13284: train loss 1.20970. lr 3.865847e-04:  81%|████████▏ | 13285/16329 [1:51:50<25:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13285: train loss 1.21624. lr 3.865571e-04:  81%|████████▏ | 13285/16329 [1:51:51<25:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13285: train loss 1.21624. lr 3.865571e-04:  81%|████████▏ | 13286/16329 [1:51:51<25:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13286: train loss 1.17762. lr 3.865294e-04:  81%|████████▏ | 13286/16329 [1:51:51<25:20,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13286: train loss 1.17762. lr 3.865294e-04:  81%|████████▏ | 13287/16329 [1:51:51<25:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13287: train loss 1.18475. lr 3.865018e-04:  81%|████████▏ | 13287/16329 [1:51:52<25:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13287: train loss 1.18475. lr 3.865018e-04:  81%|████████▏ | 13288/16329 [1:51:52<25:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13288: train loss 1.17025. lr 3.864742e-04:  81%|████████▏ | 13288/16329 [1:51:52<25:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13288: train loss 1.17025. lr 3.864742e-04:  81%|████████▏ | 13289/16329 [1:51:52<25:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13289: train loss 1.19301. lr 3.864465e-04:  81%|████████▏ | 13289/16329 [1:51:53<25:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13289: train loss 1.19301. lr 3.864465e-04:  81%|████████▏ | 13290/16329 [1:51:53<25:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13290: train loss 1.18894. lr 3.864189e-04:  81%|████████▏ | 13290/16329 [1:51:53<25:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13290: train loss 1.18894. lr 3.864189e-04:  81%|████████▏ | 13291/16329 [1:51:53<25:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13291: train loss 1.19266. lr 3.863913e-04:  81%|████████▏ | 13291/16329 [1:51:54<25:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13291: train loss 1.19266. lr 3.863913e-04:  81%|████████▏ | 13292/16329 [1:51:54<25:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13292: train loss 1.17614. lr 3.863636e-04:  81%|████████▏ | 13292/16329 [1:51:54<25:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13292: train loss 1.17614. lr 3.863636e-04:  81%|████████▏ | 13293/16329 [1:51:54<25:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13293: train loss 1.17083. lr 3.863360e-04:  81%|████████▏ | 13293/16329 [1:51:55<25:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13293: train loss 1.17083. lr 3.863360e-04:  81%|████████▏ | 13294/16329 [1:51:55<25:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13294: train loss 1.19253. lr 3.863083e-04:  81%|████████▏ | 13294/16329 [1:51:55<25:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13294: train loss 1.19253. lr 3.863083e-04:  81%|████████▏ | 13295/16329 [1:51:55<25:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13295: train loss 1.18960. lr 3.862807e-04:  81%|████████▏ | 13295/16329 [1:51:56<25:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13295: train loss 1.18960. lr 3.862807e-04:  81%|████████▏ | 13296/16329 [1:51:56<25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13296: train loss 1.16113. lr 3.862531e-04:  81%|████████▏ | 13296/16329 [1:51:56<25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13296: train loss 1.16113. lr 3.862531e-04:  81%|████████▏ | 13297/16329 [1:51:56<25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13297: train loss 1.21073. lr 3.862254e-04:  81%|████████▏ | 13297/16329 [1:51:57<25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13297: train loss 1.21073. lr 3.862254e-04:  81%|████████▏ | 13298/16329 [1:51:57<25:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13298: train loss 1.18801. lr 3.861978e-04:  81%|████████▏ | 13298/16329 [1:51:57<25:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13298: train loss 1.18801. lr 3.861978e-04:  81%|████████▏ | 13299/16329 [1:51:57<25:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13299: train loss 1.17735. lr 3.861701e-04:  81%|████████▏ | 13299/16329 [1:51:58<25:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13299: train loss 1.17735. lr 3.861701e-04:  81%|████████▏ | 13300/16329 [1:51:58<25:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13300: train loss 1.18909. lr 3.861425e-04:  81%|████████▏ | 13300/16329 [1:51:58<25:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13300: train loss 1.18909. lr 3.861425e-04:  81%|████████▏ | 13301/16329 [1:51:58<25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13301: train loss 1.17669. lr 3.861148e-04:  81%|████████▏ | 13301/16329 [1:51:59<25:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13301: train loss 1.17669. lr 3.861148e-04:  81%|████████▏ | 13302/16329 [1:51:59<24:55,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13302: train loss 1.15850. lr 3.860872e-04:  81%|████████▏ | 13302/16329 [1:51:59<24:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13302: train loss 1.15850. lr 3.860872e-04:  81%|████████▏ | 13303/16329 [1:51:59<27:42,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13303: train loss 1.17134. lr 3.860596e-04:  81%|████████▏ | 13303/16329 [1:52:00<27:42,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13303: train loss 1.17134. lr 3.860596e-04:  81%|████████▏ | 13304/16329 [1:52:00<26:52,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13304: train loss 1.20112. lr 3.860319e-04:  81%|████████▏ | 13304/16329 [1:52:00<26:52,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13304: train loss 1.20112. lr 3.860319e-04:  81%|████████▏ | 13305/16329 [1:52:00<26:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13305: train loss 1.19862. lr 3.860043e-04:  81%|████████▏ | 13305/16329 [1:52:01<26:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13305: train loss 1.19862. lr 3.860043e-04:  81%|████████▏ | 13306/16329 [1:52:01<25:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13306: train loss 1.19144. lr 3.859766e-04:  81%|████████▏ | 13306/16329 [1:52:01<25:51,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13306: train loss 1.19144. lr 3.859766e-04:  81%|████████▏ | 13307/16329 [1:52:01<25:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13307: train loss 1.17489. lr 3.859490e-04:  81%|████████▏ | 13307/16329 [1:52:02<25:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13307: train loss 1.17489. lr 3.859490e-04:  81%|████████▏ | 13308/16329 [1:52:02<25:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13308: train loss 1.16062. lr 3.859213e-04:  81%|████████▏ | 13308/16329 [1:52:02<25:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13308: train loss 1.16062. lr 3.859213e-04:  82%|████████▏ | 13309/16329 [1:52:02<25:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13309: train loss 1.15625. lr 3.858937e-04:  82%|████████▏ | 13309/16329 [1:52:03<25:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13309: train loss 1.15625. lr 3.858937e-04:  82%|████████▏ | 13310/16329 [1:52:03<25:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13310: train loss 1.16943. lr 3.858660e-04:  82%|████████▏ | 13310/16329 [1:52:03<25:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13310: train loss 1.16943. lr 3.858660e-04:  82%|████████▏ | 13311/16329 [1:52:03<25:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13311: train loss 1.19410. lr 3.858383e-04:  82%|████████▏ | 13311/16329 [1:52:04<25:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13311: train loss 1.19410. lr 3.858383e-04:  82%|████████▏ | 13312/16329 [1:52:04<24:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13312: train loss 1.19646. lr 3.858107e-04:  82%|████████▏ | 13312/16329 [1:52:04<24:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13312: train loss 1.19646. lr 3.858107e-04:  82%|████████▏ | 13313/16329 [1:52:04<24:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13313: train loss 1.16298. lr 3.857830e-04:  82%|████████▏ | 13313/16329 [1:52:05<24:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13313: train loss 1.16298. lr 3.857830e-04:  82%|████████▏ | 13314/16329 [1:52:05<24:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13314: train loss 1.17772. lr 3.857554e-04:  82%|████████▏ | 13314/16329 [1:52:05<24:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13314: train loss 1.17772. lr 3.857554e-04:  82%|████████▏ | 13315/16329 [1:52:05<24:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13315: train loss 1.17270. lr 3.857277e-04:  82%|████████▏ | 13315/16329 [1:52:06<24:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13315: train loss 1.17270. lr 3.857277e-04:  82%|████████▏ | 13316/16329 [1:52:06<24:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13316: train loss 1.17917. lr 3.857001e-04:  82%|████████▏ | 13316/16329 [1:52:06<24:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13316: train loss 1.17917. lr 3.857001e-04:  82%|████████▏ | 13317/16329 [1:52:06<24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13317: train loss 1.20886. lr 3.856724e-04:  82%|████████▏ | 13317/16329 [1:52:07<24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13317: train loss 1.20886. lr 3.856724e-04:  82%|████████▏ | 13318/16329 [1:52:07<24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13318: train loss 1.19051. lr 3.856448e-04:  82%|████████▏ | 13318/16329 [1:52:07<24:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13318: train loss 1.19051. lr 3.856448e-04:  82%|████████▏ | 13319/16329 [1:52:07<24:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13319: train loss 1.21632. lr 3.856171e-04:  82%|████████▏ | 13319/16329 [1:52:08<24:46,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13319: train loss 1.21632. lr 3.856171e-04:  82%|████████▏ | 13320/16329 [1:52:08<24:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13320: train loss 1.17703. lr 3.855894e-04:  82%|████████▏ | 13320/16329 [1:52:08<24:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13320: train loss 1.17703. lr 3.855894e-04:  82%|████████▏ | 13321/16329 [1:52:08<24:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13321: train loss 1.18111. lr 3.855618e-04:  82%|████████▏ | 13321/16329 [1:52:09<24:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13321: train loss 1.18111. lr 3.855618e-04:  82%|████████▏ | 13322/16329 [1:52:09<24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13322: train loss 1.17720. lr 3.855341e-04:  82%|████████▏ | 13322/16329 [1:52:09<24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13322: train loss 1.17720. lr 3.855341e-04:  82%|████████▏ | 13323/16329 [1:52:09<24:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13323: train loss 1.18508. lr 3.855064e-04:  82%|████████▏ | 13323/16329 [1:52:10<24:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13323: train loss 1.18508. lr 3.855064e-04:  82%|████████▏ | 13324/16329 [1:52:10<24:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13324: train loss 1.16557. lr 3.854788e-04:  82%|████████▏ | 13324/16329 [1:52:10<24:43,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13324: train loss 1.16557. lr 3.854788e-04:  82%|████████▏ | 13325/16329 [1:52:10<24:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13325: train loss 1.19817. lr 3.854511e-04:  82%|████████▏ | 13325/16329 [1:52:11<24:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13325: train loss 1.19817. lr 3.854511e-04:  82%|████████▏ | 13326/16329 [1:52:11<24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13326: train loss 1.17515. lr 3.854235e-04:  82%|████████▏ | 13326/16329 [1:52:11<24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13326: train loss 1.17515. lr 3.854235e-04:  82%|████████▏ | 13327/16329 [1:52:11<24:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13327: train loss 1.21818. lr 3.853958e-04:  82%|████████▏ | 13327/16329 [1:52:12<24:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13327: train loss 1.21818. lr 3.853958e-04:  82%|████████▏ | 13328/16329 [1:52:12<24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13328: train loss 1.16249. lr 3.853681e-04:  82%|████████▏ | 13328/16329 [1:52:12<24:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13328: train loss 1.16249. lr 3.853681e-04:  82%|████████▏ | 13329/16329 [1:52:12<24:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13329: train loss 1.21499. lr 3.853405e-04:  82%|████████▏ | 13329/16329 [1:52:13<24:40,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 13329: train loss 1.21499. lr 3.853405e-04:  82%|████████▏ | 13330/16329 [1:52:13<27:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13330: train loss 1.17433. lr 3.853128e-04:  82%|████████▏ | 13330/16329 [1:52:13<27:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13330: train loss 1.17433. lr 3.853128e-04:  82%|████████▏ | 13331/16329 [1:52:13<26:44,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13331: train loss 1.15662. lr 3.852851e-04:  82%|████████▏ | 13331/16329 [1:52:14<26:44,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13331: train loss 1.15662. lr 3.852851e-04:  82%|████████▏ | 13332/16329 [1:52:14<26:14,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13332: train loss 1.20304. lr 3.852574e-04:  82%|████████▏ | 13332/16329 [1:52:14<26:14,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13332: train loss 1.20304. lr 3.852574e-04:  82%|████████▏ | 13333/16329 [1:52:14<25:48,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13333: train loss 1.17664. lr 3.852298e-04:  82%|████████▏ | 13333/16329 [1:52:15<25:48,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13333: train loss 1.17664. lr 3.852298e-04:  82%|████████▏ | 13334/16329 [1:52:15<25:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13334: train loss 1.17769. lr 3.852021e-04:  82%|████████▏ | 13334/16329 [1:52:15<25:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13334: train loss 1.17769. lr 3.852021e-04:  82%|████████▏ | 13335/16329 [1:52:15<25:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13335: train loss 1.16222. lr 3.851744e-04:  82%|████████▏ | 13335/16329 [1:52:16<25:18,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13335: train loss 1.16222. lr 3.851744e-04:  82%|████████▏ | 13336/16329 [1:52:16<25:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13336: train loss 1.18025. lr 3.851468e-04:  82%|████████▏ | 13336/16329 [1:52:16<25:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13336: train loss 1.18025. lr 3.851468e-04:  82%|████████▏ | 13337/16329 [1:52:16<25:02,  1.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13337: train loss 1.17830. lr 3.851191e-04:  82%|████████▏ | 13337/16329 [1:52:17<25:02,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13337: train loss 1.17830. lr 3.851191e-04:  82%|████████▏ | 13338/16329 [1:52:17<24:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13338: train loss 1.18165. lr 3.850914e-04:  82%|████████▏ | 13338/16329 [1:52:17<24:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13338: train loss 1.18165. lr 3.850914e-04:  82%|████████▏ | 13339/16329 [1:52:17<24:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13339: train loss 1.16873. lr 3.850637e-04:  82%|████████▏ | 13339/16329 [1:52:18<24:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13339: train loss 1.16873. lr 3.850637e-04:  82%|████████▏ | 13340/16329 [1:52:18<24:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13340: train loss 1.14483. lr 3.850361e-04:  82%|████████▏ | 13340/16329 [1:52:18<24:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13340: train loss 1.14483. lr 3.850361e-04:  82%|████████▏ | 13341/16329 [1:52:18<24:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13341: train loss 1.16532. lr 3.850084e-04:  82%|████████▏ | 13341/16329 [1:52:19<24:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13341: train loss 1.16532. lr 3.850084e-04:  82%|████████▏ | 13342/16329 [1:52:19<24:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13342: train loss 1.18383. lr 3.849807e-04:  82%|████████▏ | 13342/16329 [1:52:19<24:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13342: train loss 1.18383. lr 3.849807e-04:  82%|████████▏ | 13343/16329 [1:52:19<24:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13343: train loss 1.17110. lr 3.849530e-04:  82%|████████▏ | 13343/16329 [1:52:20<24:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13343: train loss 1.17110. lr 3.849530e-04:  82%|████████▏ | 13344/16329 [1:52:20<24:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13344: train loss 1.19039. lr 3.849253e-04:  82%|████████▏ | 13344/16329 [1:52:20<24:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13344: train loss 1.19039. lr 3.849253e-04:  82%|████████▏ | 13345/16329 [1:52:20<24:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13345: train loss 1.18132. lr 3.848977e-04:  82%|████████▏ | 13345/16329 [1:52:21<24:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13345: train loss 1.18132. lr 3.848977e-04:  82%|████████▏ | 13346/16329 [1:52:21<24:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13346: train loss 1.17371. lr 3.848700e-04:  82%|████████▏ | 13346/16329 [1:52:21<24:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13346: train loss 1.17371. lr 3.848700e-04:  82%|████████▏ | 13347/16329 [1:52:21<24:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13347: train loss 1.14364. lr 3.848423e-04:  82%|████████▏ | 13347/16329 [1:52:22<24:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13347: train loss 1.14364. lr 3.848423e-04:  82%|████████▏ | 13348/16329 [1:52:22<24:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13348: train loss 1.19247. lr 3.848146e-04:  82%|████████▏ | 13348/16329 [1:52:22<24:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13348: train loss 1.19247. lr 3.848146e-04:  82%|████████▏ | 13349/16329 [1:52:22<24:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13349: train loss 1.16612. lr 3.847869e-04:  82%|████████▏ | 13349/16329 [1:52:23<24:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13349: train loss 1.16612. lr 3.847869e-04:  82%|████████▏ | 13350/16329 [1:52:23<24:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13350: train loss 1.17942. lr 3.847593e-04:  82%|████████▏ | 13350/16329 [1:52:23<24:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13350: train loss 1.17942. lr 3.847593e-04:  82%|████████▏ | 13351/16329 [1:52:23<24:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13351: train loss 1.18290. lr 3.847316e-04:  82%|████████▏ | 13351/16329 [1:52:24<24:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13351: train loss 1.18290. lr 3.847316e-04:  82%|████████▏ | 13352/16329 [1:52:24<24:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13352: train loss 1.18643. lr 3.847039e-04:  82%|████████▏ | 13352/16329 [1:52:24<24:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13352: train loss 1.18643. lr 3.847039e-04:  82%|████████▏ | 13353/16329 [1:52:24<24:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13353: train loss 1.20635. lr 3.846762e-04:  82%|████████▏ | 13353/16329 [1:52:25<24:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13353: train loss 1.20635. lr 3.846762e-04:  82%|████████▏ | 13354/16329 [1:52:25<24:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13354: train loss 1.19181. lr 3.846485e-04:  82%|████████▏ | 13354/16329 [1:52:25<24:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13354: train loss 1.19181. lr 3.846485e-04:  82%|████████▏ | 13355/16329 [1:52:25<24:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13355: train loss 1.18160. lr 3.846208e-04:  82%|████████▏ | 13355/16329 [1:52:26<24:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13355: train loss 1.18160. lr 3.846208e-04:  82%|████████▏ | 13356/16329 [1:52:26<24:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13356: train loss 1.19665. lr 3.845931e-04:  82%|████████▏ | 13356/16329 [1:52:26<24:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13356: train loss 1.19665. lr 3.845931e-04:  82%|████████▏ | 13357/16329 [1:52:26<24:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13357: train loss 1.20230. lr 3.845654e-04:  82%|████████▏ | 13357/16329 [1:52:27<24:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13357: train loss 1.20230. lr 3.845654e-04:  82%|████████▏ | 13358/16329 [1:52:27<24:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13358: train loss 1.14594. lr 3.845378e-04:  82%|████████▏ | 13358/16329 [1:52:27<24:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13358: train loss 1.14594. lr 3.845378e-04:  82%|████████▏ | 13359/16329 [1:52:27<24:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13359: train loss 1.18059. lr 3.845101e-04:  82%|████████▏ | 13359/16329 [1:52:28<24:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13359: train loss 1.18059. lr 3.845101e-04:  82%|████████▏ | 13360/16329 [1:52:28<24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13360: train loss 1.20284. lr 3.844824e-04:  82%|████████▏ | 13360/16329 [1:52:28<24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13360: train loss 1.20284. lr 3.844824e-04:  82%|████████▏ | 13361/16329 [1:52:28<24:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13361: train loss 1.19065. lr 3.844547e-04:  82%|████████▏ | 13361/16329 [1:52:29<24:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13361: train loss 1.19065. lr 3.844547e-04:  82%|████████▏ | 13362/16329 [1:52:29<24:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13362: train loss 1.18477. lr 3.844270e-04:  82%|████████▏ | 13362/16329 [1:52:29<24:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13362: train loss 1.18477. lr 3.844270e-04:  82%|████████▏ | 13363/16329 [1:52:29<24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13363: train loss 1.18548. lr 3.843993e-04:  82%|████████▏ | 13363/16329 [1:52:30<24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13363: train loss 1.18548. lr 3.843993e-04:  82%|████████▏ | 13364/16329 [1:52:30<24:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13364: train loss 1.19002. lr 3.843716e-04:  82%|████████▏ | 13364/16329 [1:52:30<24:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13364: train loss 1.19002. lr 3.843716e-04:  82%|████████▏ | 13365/16329 [1:52:30<24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13365: train loss 1.18794. lr 3.843439e-04:  82%|████████▏ | 13365/16329 [1:52:31<24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13365: train loss 1.18794. lr 3.843439e-04:  82%|████████▏ | 13366/16329 [1:52:31<24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13366: train loss 1.21201. lr 3.843162e-04:  82%|████████▏ | 13366/16329 [1:52:31<24:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13366: train loss 1.21201. lr 3.843162e-04:  82%|████████▏ | 13367/16329 [1:52:31<24:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13367: train loss 1.16585. lr 3.842885e-04:  82%|████████▏ | 13367/16329 [1:52:32<24:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13367: train loss 1.16585. lr 3.842885e-04:  82%|████████▏ | 13368/16329 [1:52:32<24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13368: train loss 1.13806. lr 3.842608e-04:  82%|████████▏ | 13368/16329 [1:52:32<24:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13368: train loss 1.13806. lr 3.842608e-04:  82%|████████▏ | 13369/16329 [1:52:32<24:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13369: train loss 1.14398. lr 3.842331e-04:  82%|████████▏ | 13369/16329 [1:52:33<24:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13369: train loss 1.14398. lr 3.842331e-04:  82%|████████▏ | 13370/16329 [1:52:33<27:10,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13370: train loss 1.16656. lr 3.842054e-04:  82%|████████▏ | 13370/16329 [1:52:33<27:10,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13370: train loss 1.16656. lr 3.842054e-04:  82%|████████▏ | 13371/16329 [1:52:33<26:18,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13371: train loss 1.16290. lr 3.841777e-04:  82%|████████▏ | 13371/16329 [1:52:34<26:18,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13371: train loss 1.16290. lr 3.841777e-04:  82%|████████▏ | 13372/16329 [1:52:34<25:43,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13372: train loss 1.19846. lr 3.841500e-04:  82%|████████▏ | 13372/16329 [1:52:34<25:43,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13372: train loss 1.19846. lr 3.841500e-04:  82%|████████▏ | 13373/16329 [1:52:34<25:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13373: train loss 1.16808. lr 3.841223e-04:  82%|████████▏ | 13373/16329 [1:52:35<25:20,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13373: train loss 1.16808. lr 3.841223e-04:  82%|████████▏ | 13374/16329 [1:52:35<24:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13374: train loss 1.17626. lr 3.840946e-04:  82%|████████▏ | 13374/16329 [1:52:35<24:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13374: train loss 1.17626. lr 3.840946e-04:  82%|████████▏ | 13375/16329 [1:52:35<24:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13375: train loss 1.20932. lr 3.840669e-04:  82%|████████▏ | 13375/16329 [1:52:36<24:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13375: train loss 1.20932. lr 3.840669e-04:  82%|████████▏ | 13376/16329 [1:52:36<24:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13376: train loss 1.12821. lr 3.840392e-04:  82%|████████▏ | 13376/16329 [1:52:36<24:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13376: train loss 1.12821. lr 3.840392e-04:  82%|████████▏ | 13377/16329 [1:52:36<24:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13377: train loss 1.19150. lr 3.840115e-04:  82%|████████▏ | 13377/16329 [1:52:37<24:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13377: train loss 1.19150. lr 3.840115e-04:  82%|████████▏ | 13378/16329 [1:52:37<24:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13378: train loss 1.15478. lr 3.839838e-04:  82%|████████▏ | 13378/16329 [1:52:37<24:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13378: train loss 1.15478. lr 3.839838e-04:  82%|████████▏ | 13379/16329 [1:52:37<24:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13379: train loss 1.19171. lr 3.839561e-04:  82%|████████▏ | 13379/16329 [1:52:38<24:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13379: train loss 1.19171. lr 3.839561e-04:  82%|████████▏ | 13380/16329 [1:52:38<24:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13380: train loss 1.15823. lr 3.839284e-04:  82%|████████▏ | 13380/16329 [1:52:38<24:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13380: train loss 1.15823. lr 3.839284e-04:  82%|████████▏ | 13381/16329 [1:52:38<24:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13381: train loss 1.16136. lr 3.839007e-04:  82%|████████▏ | 13381/16329 [1:52:39<24:42,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13381: train loss 1.16136. lr 3.839007e-04:  82%|████████▏ | 13382/16329 [1:52:39<24:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13382: train loss 1.14945. lr 3.838729e-04:  82%|████████▏ | 13382/16329 [1:52:39<24:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13382: train loss 1.14945. lr 3.838729e-04:  82%|████████▏ | 13383/16329 [1:52:39<24:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13383: train loss 1.15871. lr 3.838452e-04:  82%|████████▏ | 13383/16329 [1:52:40<24:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13383: train loss 1.15871. lr 3.838452e-04:  82%|████████▏ | 13384/16329 [1:52:40<24:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13384: train loss 1.13180. lr 3.838175e-04:  82%|████████▏ | 13384/16329 [1:52:40<24:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13384: train loss 1.13180. lr 3.838175e-04:  82%|████████▏ | 13385/16329 [1:52:40<24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13385: train loss 1.16858. lr 3.837898e-04:  82%|████████▏ | 13385/16329 [1:52:41<24:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13385: train loss 1.16858. lr 3.837898e-04:  82%|████████▏ | 13386/16329 [1:52:41<24:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13386: train loss 1.17900. lr 3.837621e-04:  82%|████████▏ | 13386/16329 [1:52:41<24:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13386: train loss 1.17900. lr 3.837621e-04:  82%|████████▏ | 13387/16329 [1:52:41<24:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13387: train loss 1.18383. lr 3.837344e-04:  82%|████████▏ | 13387/16329 [1:52:42<24:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13387: train loss 1.18383. lr 3.837344e-04:  82%|████████▏ | 13388/16329 [1:52:42<24:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13388: train loss 1.15030. lr 3.837067e-04:  82%|████████▏ | 13388/16329 [1:52:42<24:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13388: train loss 1.15030. lr 3.837067e-04:  82%|████████▏ | 13389/16329 [1:52:42<24:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13389: train loss 1.16503. lr 3.836790e-04:  82%|████████▏ | 13389/16329 [1:52:43<24:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13389: train loss 1.16503. lr 3.836790e-04:  82%|████████▏ | 13390/16329 [1:52:43<24:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13390: train loss 1.18285. lr 3.836512e-04:  82%|████████▏ | 13390/16329 [1:52:43<24:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13390: train loss 1.18285. lr 3.836512e-04:  82%|████████▏ | 13391/16329 [1:52:43<24:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13391: train loss 1.18839. lr 3.836235e-04:  82%|████████▏ | 13391/16329 [1:52:44<24:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13391: train loss 1.18839. lr 3.836235e-04:  82%|████████▏ | 13392/16329 [1:52:44<24:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13392: train loss 1.18844. lr 3.835958e-04:  82%|████████▏ | 13392/16329 [1:52:44<24:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13392: train loss 1.18844. lr 3.835958e-04:  82%|████████▏ | 13393/16329 [1:52:44<24:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13393: train loss 1.20827. lr 3.835681e-04:  82%|████████▏ | 13393/16329 [1:52:45<24:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13393: train loss 1.20827. lr 3.835681e-04:  82%|████████▏ | 13394/16329 [1:52:45<25:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13394: train loss 1.14945. lr 3.835404e-04:  82%|████████▏ | 13394/16329 [1:52:46<25:21,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13394: train loss 1.14945. lr 3.835404e-04:  82%|████████▏ | 13395/16329 [1:52:46<25:39,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13395: train loss 1.17943. lr 3.835127e-04:  82%|████████▏ | 13395/16329 [1:52:46<25:39,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13395: train loss 1.17943. lr 3.835127e-04:  82%|████████▏ | 13396/16329 [1:52:46<25:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13396: train loss 1.15949. lr 3.834849e-04:  82%|████████▏ | 13396/16329 [1:52:47<25:44,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13396: train loss 1.15949. lr 3.834849e-04:  82%|████████▏ | 13397/16329 [1:52:47<25:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13397: train loss 1.16440. lr 3.834572e-04:  82%|████████▏ | 13397/16329 [1:52:47<25:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13397: train loss 1.16440. lr 3.834572e-04:  82%|████████▏ | 13398/16329 [1:52:47<25:24,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13398: train loss 1.20176. lr 3.834295e-04:  82%|████████▏ | 13398/16329 [1:52:48<25:24,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13398: train loss 1.20176. lr 3.834295e-04:  82%|████████▏ | 13399/16329 [1:52:48<25:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13399: train loss 1.17011. lr 3.834018e-04:  82%|████████▏ | 13399/16329 [1:52:48<25:12,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13399: train loss 1.17011. lr 3.834018e-04:  82%|████████▏ | 13400/16329 [1:52:48<25:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13400: train loss 1.17097. lr 3.833741e-04:  82%|████████▏ | 13400/16329 [1:52:49<25:01,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13400: train loss 1.17097. lr 3.833741e-04:  82%|████████▏ | 13401/16329 [1:52:49<24:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13401: train loss 1.18948. lr 3.833463e-04:  82%|████████▏ | 13401/16329 [1:52:49<24:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13401: train loss 1.18948. lr 3.833463e-04:  82%|████████▏ | 13402/16329 [1:52:49<24:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13402: train loss 1.14237. lr 3.833186e-04:  82%|████████▏ | 13402/16329 [1:52:50<24:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13402: train loss 1.14237. lr 3.833186e-04:  82%|████████▏ | 13403/16329 [1:52:50<24:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13403: train loss 1.14562. lr 3.832909e-04:  82%|████████▏ | 13403/16329 [1:52:50<24:30,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13403: train loss 1.14562. lr 3.832909e-04:  82%|████████▏ | 13404/16329 [1:52:50<24:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13404: train loss 1.14294. lr 3.832632e-04:  82%|████████▏ | 13404/16329 [1:52:51<24:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13404: train loss 1.14294. lr 3.832632e-04:  82%|████████▏ | 13405/16329 [1:52:51<26:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13405: train loss 1.16327. lr 3.832354e-04:  82%|████████▏ | 13405/16329 [1:52:51<26:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13405: train loss 1.16327. lr 3.832354e-04:  82%|████████▏ | 13406/16329 [1:52:51<26:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13406: train loss 1.18551. lr 3.832077e-04:  82%|████████▏ | 13406/16329 [1:52:52<26:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13406: train loss 1.18551. lr 3.832077e-04:  82%|████████▏ | 13407/16329 [1:52:52<25:25,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13407: train loss 1.17657. lr 3.831800e-04:  82%|████████▏ | 13407/16329 [1:52:52<25:25,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13407: train loss 1.17657. lr 3.831800e-04:  82%|████████▏ | 13408/16329 [1:52:52<25:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13408: train loss 1.18450. lr 3.831522e-04:  82%|████████▏ | 13408/16329 [1:52:53<25:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13408: train loss 1.18450. lr 3.831522e-04:  82%|████████▏ | 13409/16329 [1:52:53<24:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13409: train loss 1.18386. lr 3.831245e-04:  82%|████████▏ | 13409/16329 [1:52:53<24:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13409: train loss 1.18386. lr 3.831245e-04:  82%|████████▏ | 13410/16329 [1:52:53<24:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13410: train loss 1.15341. lr 3.830968e-04:  82%|████████▏ | 13410/16329 [1:52:54<24:38,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13410: train loss 1.15341. lr 3.830968e-04:  82%|████████▏ | 13411/16329 [1:52:54<24:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13411: train loss 1.20373. lr 3.830690e-04:  82%|████████▏ | 13411/16329 [1:52:54<24:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13411: train loss 1.20373. lr 3.830690e-04:  82%|████████▏ | 13412/16329 [1:52:54<24:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13412: train loss 1.19568. lr 3.830413e-04:  82%|████████▏ | 13412/16329 [1:52:55<24:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13412: train loss 1.19568. lr 3.830413e-04:  82%|████████▏ | 13413/16329 [1:52:55<24:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13413: train loss 1.17454. lr 3.830136e-04:  82%|████████▏ | 13413/16329 [1:52:55<24:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13413: train loss 1.17454. lr 3.830136e-04:  82%|████████▏ | 13414/16329 [1:52:55<24:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13414: train loss 1.16479. lr 3.829859e-04:  82%|████████▏ | 13414/16329 [1:52:56<24:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13414: train loss 1.16479. lr 3.829859e-04:  82%|████████▏ | 13415/16329 [1:52:56<24:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13415: train loss 1.16993. lr 3.829581e-04:  82%|████████▏ | 13415/16329 [1:52:56<24:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13415: train loss 1.16993. lr 3.829581e-04:  82%|████████▏ | 13416/16329 [1:52:56<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13416: train loss 1.18485. lr 3.829304e-04:  82%|████████▏ | 13416/16329 [1:52:57<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13416: train loss 1.18485. lr 3.829304e-04:  82%|████████▏ | 13417/16329 [1:52:57<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13417: train loss 1.16430. lr 3.829026e-04:  82%|████████▏ | 13417/16329 [1:52:57<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13417: train loss 1.16430. lr 3.829026e-04:  82%|████████▏ | 13418/16329 [1:52:57<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13418: train loss 1.15118. lr 3.828749e-04:  82%|████████▏ | 13418/16329 [1:52:58<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13418: train loss 1.15118. lr 3.828749e-04:  82%|████████▏ | 13419/16329 [1:52:58<24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13419: train loss 1.15226. lr 3.828472e-04:  82%|████████▏ | 13419/16329 [1:52:58<24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13419: train loss 1.15226. lr 3.828472e-04:  82%|████████▏ | 13420/16329 [1:52:58<24:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13420: train loss 1.17240. lr 3.828194e-04:  82%|████████▏ | 13420/16329 [1:52:59<24:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13420: train loss 1.17240. lr 3.828194e-04:  82%|████████▏ | 13421/16329 [1:52:59<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13421: train loss 1.16902. lr 3.827917e-04:  82%|████████▏ | 13421/16329 [1:52:59<24:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13421: train loss 1.16902. lr 3.827917e-04:  82%|████████▏ | 13422/16329 [1:52:59<24:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13422: train loss 1.17493. lr 3.827640e-04:  82%|████████▏ | 13422/16329 [1:53:00<24:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13422: train loss 1.17493. lr 3.827640e-04:  82%|████████▏ | 13423/16329 [1:53:00<24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13423: train loss 1.14428. lr 3.827362e-04:  82%|████████▏ | 13423/16329 [1:53:00<24:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13423: train loss 1.14428. lr 3.827362e-04:  82%|████████▏ | 13424/16329 [1:53:00<24:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13424: train loss 1.20068. lr 3.827085e-04:  82%|████████▏ | 13424/16329 [1:53:01<24:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13424: train loss 1.20068. lr 3.827085e-04:  82%|████████▏ | 13425/16329 [1:53:01<24:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13425: train loss 1.20326. lr 3.826807e-04:  82%|████████▏ | 13425/16329 [1:53:01<24:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13425: train loss 1.20326. lr 3.826807e-04:  82%|████████▏ | 13426/16329 [1:53:01<23:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13426: train loss 1.18730. lr 3.826530e-04:  82%|████████▏ | 13426/16329 [1:53:02<23:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13426: train loss 1.18730. lr 3.826530e-04:  82%|████████▏ | 13427/16329 [1:53:02<23:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13427: train loss 1.19689. lr 3.826252e-04:  82%|████████▏ | 13427/16329 [1:53:02<23:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13427: train loss 1.19689. lr 3.826252e-04:  82%|████████▏ | 13428/16329 [1:53:02<23:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13428: train loss 1.14170. lr 3.825975e-04:  82%|████████▏ | 13428/16329 [1:53:03<23:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13428: train loss 1.14170. lr 3.825975e-04:  82%|████████▏ | 13429/16329 [1:53:03<24:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13429: train loss 1.15884. lr 3.825698e-04:  82%|████████▏ | 13429/16329 [1:53:03<24:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13429: train loss 1.15884. lr 3.825698e-04:  82%|████████▏ | 13430/16329 [1:53:03<26:29,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13430: train loss 1.17753. lr 3.825420e-04:  82%|████████▏ | 13430/16329 [1:53:04<26:29,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13430: train loss 1.17753. lr 3.825420e-04:  82%|████████▏ | 13431/16329 [1:53:04<25:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13431: train loss 1.15286. lr 3.825143e-04:  82%|████████▏ | 13431/16329 [1:53:04<25:40,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13431: train loss 1.15286. lr 3.825143e-04:  82%|████████▏ | 13432/16329 [1:53:04<25:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13432: train loss 1.16408. lr 3.824865e-04:  82%|████████▏ | 13432/16329 [1:53:05<25:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13432: train loss 1.16408. lr 3.824865e-04:  82%|████████▏ | 13433/16329 [1:53:05<24:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13433: train loss 1.16860. lr 3.824588e-04:  82%|████████▏ | 13433/16329 [1:53:05<24:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13433: train loss 1.16860. lr 3.824588e-04:  82%|████████▏ | 13434/16329 [1:53:05<24:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13434: train loss 1.20235. lr 3.824310e-04:  82%|████████▏ | 13434/16329 [1:53:06<24:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13434: train loss 1.20235. lr 3.824310e-04:  82%|████████▏ | 13435/16329 [1:53:06<24:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13435: train loss 1.15335. lr 3.824033e-04:  82%|████████▏ | 13435/16329 [1:53:06<24:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13435: train loss 1.15335. lr 3.824033e-04:  82%|████████▏ | 13436/16329 [1:53:06<24:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13436: train loss 1.20722. lr 3.823755e-04:  82%|████████▏ | 13436/16329 [1:53:07<24:08,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13436: train loss 1.20722. lr 3.823755e-04:  82%|████████▏ | 13437/16329 [1:53:07<24:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13437: train loss 1.16644. lr 3.823478e-04:  82%|████████▏ | 13437/16329 [1:53:07<24:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13437: train loss 1.16644. lr 3.823478e-04:  82%|████████▏ | 13438/16329 [1:53:07<23:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13438: train loss 1.19448. lr 3.823200e-04:  82%|████████▏ | 13438/16329 [1:53:08<23:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13438: train loss 1.19448. lr 3.823200e-04:  82%|████████▏ | 13439/16329 [1:53:08<23:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13439: train loss 1.14185. lr 3.822923e-04:  82%|████████▏ | 13439/16329 [1:53:08<23:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13439: train loss 1.14185. lr 3.822923e-04:  82%|████████▏ | 13440/16329 [1:53:08<23:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13440: train loss 1.15693. lr 3.822645e-04:  82%|████████▏ | 13440/16329 [1:53:09<23:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13440: train loss 1.15693. lr 3.822645e-04:  82%|████████▏ | 13441/16329 [1:53:09<24:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13441: train loss 1.14909. lr 3.822367e-04:  82%|████████▏ | 13441/16329 [1:53:09<24:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13441: train loss 1.14909. lr 3.822367e-04:  82%|████████▏ | 13442/16329 [1:53:09<23:55,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13442: train loss 1.16270. lr 3.822090e-04:  82%|████████▏ | 13442/16329 [1:53:10<23:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13442: train loss 1.16270. lr 3.822090e-04:  82%|████████▏ | 13443/16329 [1:53:10<23:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13443: train loss 1.14925. lr 3.821812e-04:  82%|████████▏ | 13443/16329 [1:53:10<23:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13443: train loss 1.14925. lr 3.821812e-04:  82%|████████▏ | 13444/16329 [1:53:10<23:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13444: train loss 1.16130. lr 3.821535e-04:  82%|████████▏ | 13444/16329 [1:53:11<23:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13444: train loss 1.16130. lr 3.821535e-04:  82%|████████▏ | 13445/16329 [1:53:11<23:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13445: train loss 1.17996. lr 3.821257e-04:  82%|████████▏ | 13445/16329 [1:53:11<23:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13445: train loss 1.17996. lr 3.821257e-04:  82%|████████▏ | 13446/16329 [1:53:11<23:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13446: train loss 1.15788. lr 3.820980e-04:  82%|████████▏ | 13446/16329 [1:53:12<23:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13446: train loss 1.15788. lr 3.820980e-04:  82%|████████▏ | 13447/16329 [1:53:12<23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13447: train loss 1.18202. lr 3.820702e-04:  82%|████████▏ | 13447/16329 [1:53:12<23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13447: train loss 1.18202. lr 3.820702e-04:  82%|████████▏ | 13448/16329 [1:53:12<23:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13448: train loss 1.17026. lr 3.820424e-04:  82%|████████▏ | 13448/16329 [1:53:13<23:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13448: train loss 1.17026. lr 3.820424e-04:  82%|████████▏ | 13449/16329 [1:53:13<23:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13449: train loss 1.17376. lr 3.820147e-04:  82%|████████▏ | 13449/16329 [1:53:13<23:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13449: train loss 1.17376. lr 3.820147e-04:  82%|████████▏ | 13450/16329 [1:53:13<23:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13450: train loss 1.16261. lr 3.819869e-04:  82%|████████▏ | 13450/16329 [1:53:14<23:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13450: train loss 1.16261. lr 3.819869e-04:  82%|████████▏ | 13451/16329 [1:53:14<23:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13451: train loss 1.15632. lr 3.819592e-04:  82%|████████▏ | 13451/16329 [1:53:14<23:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13451: train loss 1.15632. lr 3.819592e-04:  82%|████████▏ | 13452/16329 [1:53:14<23:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13452: train loss 1.15775. lr 3.819314e-04:  82%|████████▏ | 13452/16329 [1:53:15<23:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13452: train loss 1.15775. lr 3.819314e-04:  82%|████████▏ | 13453/16329 [1:53:15<23:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13453: train loss 1.16997. lr 3.819036e-04:  82%|████████▏ | 13453/16329 [1:53:15<23:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13453: train loss 1.16997. lr 3.819036e-04:  82%|████████▏ | 13454/16329 [1:53:15<23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13454: train loss 1.14527. lr 3.818759e-04:  82%|████████▏ | 13454/16329 [1:53:16<23:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13454: train loss 1.14527. lr 3.818759e-04:  82%|████████▏ | 13455/16329 [1:53:16<23:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13455: train loss 1.15177. lr 3.818481e-04:  82%|████████▏ | 13455/16329 [1:53:16<23:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13455: train loss 1.15177. lr 3.818481e-04:  82%|████████▏ | 13456/16329 [1:53:16<23:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13456: train loss 1.15571. lr 3.818203e-04:  82%|████████▏ | 13456/16329 [1:53:17<23:53,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13456: train loss 1.15571. lr 3.818203e-04:  82%|████████▏ | 13457/16329 [1:53:17<26:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13457: train loss 1.17319. lr 3.817926e-04:  82%|████████▏ | 13457/16329 [1:53:17<26:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13457: train loss 1.17319. lr 3.817926e-04:  82%|████████▏ | 13458/16329 [1:53:17<25:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13458: train loss 1.15303. lr 3.817648e-04:  82%|████████▏ | 13458/16329 [1:53:18<25:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13458: train loss 1.15303. lr 3.817648e-04:  82%|████████▏ | 13459/16329 [1:53:18<25:01,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13459: train loss 1.18767. lr 3.817370e-04:  82%|████████▏ | 13459/16329 [1:53:18<25:01,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13459: train loss 1.18767. lr 3.817370e-04:  82%|████████▏ | 13460/16329 [1:53:18<24:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13460: train loss 1.14594. lr 3.817093e-04:  82%|████████▏ | 13460/16329 [1:53:19<24:37,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13460: train loss 1.14594. lr 3.817093e-04:  82%|████████▏ | 13461/16329 [1:53:19<24:21,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13461: train loss 1.14586. lr 3.816815e-04:  82%|████████▏ | 13461/16329 [1:53:19<24:21,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13461: train loss 1.14586. lr 3.816815e-04:  82%|████████▏ | 13462/16329 [1:53:19<24:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13462: train loss 1.19439. lr 3.816537e-04:  82%|████████▏ | 13462/16329 [1:53:20<24:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13462: train loss 1.19439. lr 3.816537e-04:  82%|████████▏ | 13463/16329 [1:53:20<23:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13463: train loss 1.13327. lr 3.816260e-04:  82%|████████▏ | 13463/16329 [1:53:20<23:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13463: train loss 1.13327. lr 3.816260e-04:  82%|████████▏ | 13464/16329 [1:53:20<23:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13464: train loss 1.15555. lr 3.815982e-04:  82%|████████▏ | 13464/16329 [1:53:21<23:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13464: train loss 1.15555. lr 3.815982e-04:  82%|████████▏ | 13465/16329 [1:53:21<23:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13465: train loss 1.20685. lr 3.815704e-04:  82%|████████▏ | 13465/16329 [1:53:21<23:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13465: train loss 1.20685. lr 3.815704e-04:  82%|████████▏ | 13466/16329 [1:53:21<23:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13466: train loss 1.19566. lr 3.815426e-04:  82%|████████▏ | 13466/16329 [1:53:22<23:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13466: train loss 1.19566. lr 3.815426e-04:  82%|████████▏ | 13467/16329 [1:53:22<23:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13467: train loss 1.17852. lr 3.815149e-04:  82%|████████▏ | 13467/16329 [1:53:22<23:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13467: train loss 1.17852. lr 3.815149e-04:  82%|████████▏ | 13468/16329 [1:53:22<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13468: train loss 1.19455. lr 3.814871e-04:  82%|████████▏ | 13468/16329 [1:53:23<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13468: train loss 1.19455. lr 3.814871e-04:  82%|████████▏ | 13469/16329 [1:53:23<23:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13469: train loss 1.17553. lr 3.814593e-04:  82%|████████▏ | 13469/16329 [1:53:23<23:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13469: train loss 1.17553. lr 3.814593e-04:  82%|████████▏ | 13470/16329 [1:53:23<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13470: train loss 1.14309. lr 3.814315e-04:  82%|████████▏ | 13470/16329 [1:53:24<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13470: train loss 1.14309. lr 3.814315e-04:  82%|████████▏ | 13471/16329 [1:53:24<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13471: train loss 1.19826. lr 3.814038e-04:  82%|████████▏ | 13471/16329 [1:53:24<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13471: train loss 1.19826. lr 3.814038e-04:  83%|████████▎ | 13472/16329 [1:53:24<23:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13472: train loss 1.16996. lr 3.813760e-04:  83%|████████▎ | 13472/16329 [1:53:25<23:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13472: train loss 1.16996. lr 3.813760e-04:  83%|████████▎ | 13473/16329 [1:53:25<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13473: train loss 1.17240. lr 3.813482e-04:  83%|████████▎ | 13473/16329 [1:53:25<23:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13473: train loss 1.17240. lr 3.813482e-04:  83%|████████▎ | 13474/16329 [1:53:25<23:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13474: train loss 1.16168. lr 3.813204e-04:  83%|████████▎ | 13474/16329 [1:53:26<23:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13474: train loss 1.16168. lr 3.813204e-04:  83%|████████▎ | 13475/16329 [1:53:26<23:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13475: train loss 1.17402. lr 3.812926e-04:  83%|████████▎ | 13475/16329 [1:53:26<23:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13475: train loss 1.17402. lr 3.812926e-04:  83%|████████▎ | 13476/16329 [1:53:26<23:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13476: train loss 1.18975. lr 3.812649e-04:  83%|████████▎ | 13476/16329 [1:53:27<23:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13476: train loss 1.18975. lr 3.812649e-04:  83%|████████▎ | 13477/16329 [1:53:27<23:35,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13477: train loss 1.18019. lr 3.812371e-04:  83%|████████▎ | 13477/16329 [1:53:27<23:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13477: train loss 1.18019. lr 3.812371e-04:  83%|████████▎ | 13478/16329 [1:53:27<23:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13478: train loss 1.15229. lr 3.812093e-04:  83%|████████▎ | 13478/16329 [1:53:28<23:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13478: train loss 1.15229. lr 3.812093e-04:  83%|████████▎ | 13479/16329 [1:53:28<23:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13479: train loss 1.17679. lr 3.811815e-04:  83%|████████▎ | 13479/16329 [1:53:28<23:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13479: train loss 1.17679. lr 3.811815e-04:  83%|████████▎ | 13480/16329 [1:53:28<23:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13480: train loss 1.17943. lr 3.811537e-04:  83%|████████▎ | 13480/16329 [1:53:29<23:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13480: train loss 1.17943. lr 3.811537e-04:  83%|████████▎ | 13481/16329 [1:53:29<23:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13481: train loss 1.17998. lr 3.811260e-04:  83%|████████▎ | 13481/16329 [1:53:29<23:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13481: train loss 1.17998. lr 3.811260e-04:  83%|████████▎ | 13482/16329 [1:53:29<23:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13482: train loss 1.16374. lr 3.810982e-04:  83%|████████▎ | 13482/16329 [1:53:30<23:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13482: train loss 1.16374. lr 3.810982e-04:  83%|████████▎ | 13483/16329 [1:53:30<23:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13483: train loss 1.16847. lr 3.810704e-04:  83%|████████▎ | 13483/16329 [1:53:30<23:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13483: train loss 1.16847. lr 3.810704e-04:  83%|████████▎ | 13484/16329 [1:53:30<23:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13484: train loss 1.16873. lr 3.810426e-04:  83%|████████▎ | 13484/16329 [1:53:31<23:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13484: train loss 1.16873. lr 3.810426e-04:  83%|████████▎ | 13485/16329 [1:53:31<23:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13485: train loss 1.16412. lr 3.810148e-04:  83%|████████▎ | 13485/16329 [1:53:31<23:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13485: train loss 1.16412. lr 3.810148e-04:  83%|████████▎ | 13486/16329 [1:53:31<23:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13486: train loss 1.19531. lr 3.809870e-04:  83%|████████▎ | 13486/16329 [1:53:32<23:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13486: train loss 1.19531. lr 3.809870e-04:  83%|████████▎ | 13487/16329 [1:53:32<23:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13487: train loss 1.11951. lr 3.809592e-04:  83%|████████▎ | 13487/16329 [1:53:32<23:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13487: train loss 1.11951. lr 3.809592e-04:  83%|████████▎ | 13488/16329 [1:53:32<23:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13488: train loss 1.16073. lr 3.809314e-04:  83%|████████▎ | 13488/16329 [1:53:33<23:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13488: train loss 1.16073. lr 3.809314e-04:  83%|████████▎ | 13489/16329 [1:53:33<23:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13489: train loss 1.17893. lr 3.809036e-04:  83%|████████▎ | 13489/16329 [1:53:33<23:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13489: train loss 1.17893. lr 3.809036e-04:  83%|████████▎ | 13490/16329 [1:53:33<23:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13490: train loss 1.17704. lr 3.808759e-04:  83%|████████▎ | 13490/16329 [1:53:34<23:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13490: train loss 1.17704. lr 3.808759e-04:  83%|████████▎ | 13491/16329 [1:53:34<23:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13491: train loss 1.19359. lr 3.808481e-04:  83%|████████▎ | 13491/16329 [1:53:34<23:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13491: train loss 1.19359. lr 3.808481e-04:  83%|████████▎ | 13492/16329 [1:53:34<23:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13492: train loss 1.16197. lr 3.808203e-04:  83%|████████▎ | 13492/16329 [1:53:35<23:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13492: train loss 1.16197. lr 3.808203e-04:  83%|████████▎ | 13493/16329 [1:53:35<23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13493: train loss 1.15510. lr 3.807925e-04:  83%|████████▎ | 13493/16329 [1:53:35<23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13493: train loss 1.15510. lr 3.807925e-04:  83%|████████▎ | 13494/16329 [1:53:35<23:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13494: train loss 1.16981. lr 3.807647e-04:  83%|████████▎ | 13494/16329 [1:53:36<23:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13494: train loss 1.16981. lr 3.807647e-04:  83%|████████▎ | 13495/16329 [1:53:36<23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13495: train loss 1.14965. lr 3.807369e-04:  83%|████████▎ | 13495/16329 [1:53:36<23:21,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13495: train loss 1.14965. lr 3.807369e-04:  83%|████████▎ | 13496/16329 [1:53:36<23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13496: train loss 1.19405. lr 3.807091e-04:  83%|████████▎ | 13496/16329 [1:53:37<23:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13496: train loss 1.19405. lr 3.807091e-04:  83%|████████▎ | 13497/16329 [1:53:37<25:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13497: train loss 1.18637. lr 3.806813e-04:  83%|████████▎ | 13497/16329 [1:53:37<25:53,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13497: train loss 1.18637. lr 3.806813e-04:  83%|████████▎ | 13498/16329 [1:53:37<25:05,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13498: train loss 1.18913. lr 3.806535e-04:  83%|████████▎ | 13498/16329 [1:53:38<25:05,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13498: train loss 1.18913. lr 3.806535e-04:  83%|████████▎ | 13499/16329 [1:53:38<24:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13499: train loss 1.14546. lr 3.806257e-04:  83%|████████▎ | 13499/16329 [1:53:38<24:36,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13499: train loss 1.14546. lr 3.806257e-04:  83%|████████▎ | 13500/16329 [1:53:38<24:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13500: train loss 1.13945. lr 3.805979e-04:  83%|████████▎ | 13500/16329 [1:53:39<24:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13500: train loss 1.13945. lr 3.805979e-04:  83%|████████▎ | 13501/16329 [1:53:39<24:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13501: train loss 1.12670. lr 3.805701e-04:  83%|████████▎ | 13501/16329 [1:53:39<24:00,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13501: train loss 1.12670. lr 3.805701e-04:  83%|████████▎ | 13502/16329 [1:53:39<23:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13502: train loss 1.16074. lr 3.805423e-04:  83%|████████▎ | 13502/16329 [1:53:40<23:48,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13502: train loss 1.16074. lr 3.805423e-04:  83%|████████▎ | 13503/16329 [1:53:40<23:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13503: train loss 1.13015. lr 3.805145e-04:  83%|████████▎ | 13503/16329 [1:53:40<23:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13503: train loss 1.13015. lr 3.805145e-04:  83%|████████▎ | 13504/16329 [1:53:40<23:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13504: train loss 1.17750. lr 3.804867e-04:  83%|████████▎ | 13504/16329 [1:53:41<23:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13504: train loss 1.17750. lr 3.804867e-04:  83%|████████▎ | 13505/16329 [1:53:41<23:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13505: train loss 1.19170. lr 3.804589e-04:  83%|████████▎ | 13505/16329 [1:53:41<23:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13505: train loss 1.19170. lr 3.804589e-04:  83%|████████▎ | 13506/16329 [1:53:41<23:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13506: train loss 1.16634. lr 3.804311e-04:  83%|████████▎ | 13506/16329 [1:53:42<23:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13506: train loss 1.16634. lr 3.804311e-04:  83%|████████▎ | 13507/16329 [1:53:42<23:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13507: train loss 1.18125. lr 3.804033e-04:  83%|████████▎ | 13507/16329 [1:53:42<23:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13507: train loss 1.18125. lr 3.804033e-04:  83%|████████▎ | 13508/16329 [1:53:42<23:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13508: train loss 1.17121. lr 3.803755e-04:  83%|████████▎ | 13508/16329 [1:53:43<23:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13508: train loss 1.17121. lr 3.803755e-04:  83%|████████▎ | 13509/16329 [1:53:43<23:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13509: train loss 1.15642. lr 3.803477e-04:  83%|████████▎ | 13509/16329 [1:53:43<23:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13509: train loss 1.15642. lr 3.803477e-04:  83%|████████▎ | 13510/16329 [1:53:43<23:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13510: train loss 1.19606. lr 3.803199e-04:  83%|████████▎ | 13510/16329 [1:53:44<23:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13510: train loss 1.19606. lr 3.803199e-04:  83%|████████▎ | 13511/16329 [1:53:44<23:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13511: train loss 1.17978. lr 3.802921e-04:  83%|████████▎ | 13511/16329 [1:53:44<23:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13511: train loss 1.17978. lr 3.802921e-04:  83%|████████▎ | 13512/16329 [1:53:44<23:15,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13512: train loss 1.18225. lr 3.802643e-04:  83%|████████▎ | 13512/16329 [1:53:45<23:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13512: train loss 1.18225. lr 3.802643e-04:  83%|████████▎ | 13513/16329 [1:53:45<23:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13513: train loss 1.19352. lr 3.802364e-04:  83%|████████▎ | 13513/16329 [1:53:45<23:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13513: train loss 1.19352. lr 3.802364e-04:  83%|████████▎ | 13514/16329 [1:53:45<23:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13514: train loss 1.16262. lr 3.802086e-04:  83%|████████▎ | 13514/16329 [1:53:46<23:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13514: train loss 1.16262. lr 3.802086e-04:  83%|████████▎ | 13515/16329 [1:53:46<23:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13515: train loss 1.12264. lr 3.801808e-04:  83%|████████▎ | 13515/16329 [1:53:46<23:35,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13515: train loss 1.12264. lr 3.801808e-04:  83%|████████▎ | 13516/16329 [1:53:46<23:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13516: train loss 1.19766. lr 3.801530e-04:  83%|████████▎ | 13516/16329 [1:53:47<23:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13516: train loss 1.19766. lr 3.801530e-04:  83%|████████▎ | 13517/16329 [1:53:47<23:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13517: train loss 1.16714. lr 3.801252e-04:  83%|████████▎ | 13517/16329 [1:53:47<23:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13517: train loss 1.16714. lr 3.801252e-04:  83%|████████▎ | 13518/16329 [1:53:47<23:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13518: train loss 1.18770. lr 3.800974e-04:  83%|████████▎ | 13518/16329 [1:53:48<23:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13518: train loss 1.18770. lr 3.800974e-04:  83%|████████▎ | 13519/16329 [1:53:48<23:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13519: train loss 1.16158. lr 3.800696e-04:  83%|████████▎ | 13519/16329 [1:53:48<23:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13519: train loss 1.16158. lr 3.800696e-04:  83%|████████▎ | 13520/16329 [1:53:48<23:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13520: train loss 1.17780. lr 3.800418e-04:  83%|████████▎ | 13520/16329 [1:53:49<23:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13520: train loss 1.17780. lr 3.800418e-04:  83%|████████▎ | 13521/16329 [1:53:49<23:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13521: train loss 1.16775. lr 3.800140e-04:  83%|████████▎ | 13521/16329 [1:53:49<23:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13521: train loss 1.16775. lr 3.800140e-04:  83%|████████▎ | 13522/16329 [1:53:49<23:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13522: train loss 1.14595. lr 3.799861e-04:  83%|████████▎ | 13522/16329 [1:53:50<23:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13522: train loss 1.14595. lr 3.799861e-04:  83%|████████▎ | 13523/16329 [1:53:50<23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13523: train loss 1.15200. lr 3.799583e-04:  83%|████████▎ | 13523/16329 [1:53:50<23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13523: train loss 1.15200. lr 3.799583e-04:  83%|████████▎ | 13524/16329 [1:53:50<23:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13524: train loss 1.21383. lr 3.799305e-04:  83%|████████▎ | 13524/16329 [1:53:51<23:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13524: train loss 1.21383. lr 3.799305e-04:  83%|████████▎ | 13525/16329 [1:53:51<23:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13525: train loss 1.14789. lr 3.799027e-04:  83%|████████▎ | 13525/16329 [1:53:51<23:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13525: train loss 1.14789. lr 3.799027e-04:  83%|████████▎ | 13526/16329 [1:53:51<23:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13526: train loss 1.15652. lr 3.798749e-04:  83%|████████▎ | 13526/16329 [1:53:52<23:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13526: train loss 1.15652. lr 3.798749e-04:  83%|████████▎ | 13527/16329 [1:53:52<23:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13527: train loss 1.19945. lr 3.798470e-04:  83%|████████▎ | 13527/16329 [1:53:52<23:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13527: train loss 1.19945. lr 3.798470e-04:  83%|████████▎ | 13528/16329 [1:53:52<23:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13528: train loss 1.17292. lr 3.798192e-04:  83%|████████▎ | 13528/16329 [1:53:53<23:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13528: train loss 1.17292. lr 3.798192e-04:  83%|████████▎ | 13529/16329 [1:53:53<23:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13529: train loss 1.17886. lr 3.797914e-04:  83%|████████▎ | 13529/16329 [1:53:53<23:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13529: train loss 1.17886. lr 3.797914e-04:  83%|████████▎ | 13530/16329 [1:53:53<23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13530: train loss 1.14802. lr 3.797636e-04:  83%|████████▎ | 13530/16329 [1:53:54<23:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13530: train loss 1.14802. lr 3.797636e-04:  83%|████████▎ | 13531/16329 [1:53:54<23:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13531: train loss 1.18150. lr 3.797358e-04:  83%|████████▎ | 13531/16329 [1:53:55<23:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13531: train loss 1.18150. lr 3.797358e-04:  83%|████████▎ | 13532/16329 [1:53:55<25:46,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13532: train loss 1.13775. lr 3.797079e-04:  83%|████████▎ | 13532/16329 [1:53:55<25:46,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13532: train loss 1.13775. lr 3.797079e-04:  83%|████████▎ | 13533/16329 [1:53:55<24:55,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13533: train loss 1.14841. lr 3.796801e-04:  83%|████████▎ | 13533/16329 [1:53:56<24:55,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13533: train loss 1.14841. lr 3.796801e-04:  83%|████████▎ | 13534/16329 [1:53:56<24:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13534: train loss 1.16717. lr 3.796523e-04:  83%|████████▎ | 13534/16329 [1:53:56<24:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13534: train loss 1.16717. lr 3.796523e-04:  83%|████████▎ | 13535/16329 [1:53:56<24:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13535: train loss 1.18870. lr 3.796245e-04:  83%|████████▎ | 13535/16329 [1:53:57<24:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13535: train loss 1.18870. lr 3.796245e-04:  83%|████████▎ | 13536/16329 [1:53:57<23:49,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13536: train loss 1.16125. lr 3.795966e-04:  83%|████████▎ | 13536/16329 [1:53:57<23:49,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13536: train loss 1.16125. lr 3.795966e-04:  83%|████████▎ | 13537/16329 [1:53:57<23:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13537: train loss 1.12996. lr 3.795688e-04:  83%|████████▎ | 13537/16329 [1:53:58<23:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13537: train loss 1.12996. lr 3.795688e-04:  83%|████████▎ | 13538/16329 [1:53:58<23:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13538: train loss 1.19094. lr 3.795410e-04:  83%|████████▎ | 13538/16329 [1:53:58<23:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13538: train loss 1.19094. lr 3.795410e-04:  83%|████████▎ | 13539/16329 [1:53:58<23:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13539: train loss 1.19532. lr 3.795132e-04:  83%|████████▎ | 13539/16329 [1:53:59<23:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13539: train loss 1.19532. lr 3.795132e-04:  83%|████████▎ | 13540/16329 [1:53:59<23:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13540: train loss 1.18356. lr 3.794853e-04:  83%|████████▎ | 13540/16329 [1:53:59<23:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13540: train loss 1.18356. lr 3.794853e-04:  83%|████████▎ | 13541/16329 [1:53:59<23:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13541: train loss 1.15077. lr 3.794575e-04:  83%|████████▎ | 13541/16329 [1:53:59<23:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13541: train loss 1.15077. lr 3.794575e-04:  83%|████████▎ | 13542/16329 [1:53:59<23:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13542: train loss 1.15691. lr 3.794297e-04:  83%|████████▎ | 13542/16329 [1:54:00<23:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13542: train loss 1.15691. lr 3.794297e-04:  83%|████████▎ | 13543/16329 [1:54:00<23:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13543: train loss 1.14801. lr 3.794018e-04:  83%|████████▎ | 13543/16329 [1:54:00<23:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13543: train loss 1.14801. lr 3.794018e-04:  83%|████████▎ | 13544/16329 [1:54:00<23:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13544: train loss 1.14195. lr 3.793740e-04:  83%|████████▎ | 13544/16329 [1:54:01<23:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13544: train loss 1.14195. lr 3.793740e-04:  83%|████████▎ | 13545/16329 [1:54:01<23:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13545: train loss 1.15064. lr 3.793462e-04:  83%|████████▎ | 13545/16329 [1:54:01<23:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13545: train loss 1.15064. lr 3.793462e-04:  83%|████████▎ | 13546/16329 [1:54:01<23:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13546: train loss 1.20558. lr 3.793183e-04:  83%|████████▎ | 13546/16329 [1:54:02<23:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13546: train loss 1.20558. lr 3.793183e-04:  83%|████████▎ | 13547/16329 [1:54:02<23:01,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13547: train loss 1.19070. lr 3.792905e-04:  83%|████████▎ | 13547/16329 [1:54:02<23:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13547: train loss 1.19070. lr 3.792905e-04:  83%|████████▎ | 13548/16329 [1:54:02<23:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13548: train loss 1.16734. lr 3.792627e-04:  83%|████████▎ | 13548/16329 [1:54:03<23:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13548: train loss 1.16734. lr 3.792627e-04:  83%|████████▎ | 13549/16329 [1:54:03<23:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13549: train loss 1.16357. lr 3.792348e-04:  83%|████████▎ | 13549/16329 [1:54:03<23:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13549: train loss 1.16357. lr 3.792348e-04:  83%|████████▎ | 13550/16329 [1:54:03<23:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13550: train loss 1.15092. lr 3.792070e-04:  83%|████████▎ | 13550/16329 [1:54:04<23:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13550: train loss 1.15092. lr 3.792070e-04:  83%|████████▎ | 13551/16329 [1:54:04<23:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13551: train loss 1.17295. lr 3.791792e-04:  83%|████████▎ | 13551/16329 [1:54:04<23:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13551: train loss 1.17295. lr 3.791792e-04:  83%|████████▎ | 13552/16329 [1:54:04<23:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13552: train loss 1.16516. lr 3.791513e-04:  83%|████████▎ | 13552/16329 [1:54:05<23:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13552: train loss 1.16516. lr 3.791513e-04:  83%|████████▎ | 13553/16329 [1:54:05<22:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13553: train loss 1.17038. lr 3.791235e-04:  83%|████████▎ | 13553/16329 [1:54:05<22:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13553: train loss 1.17038. lr 3.791235e-04:  83%|████████▎ | 13554/16329 [1:54:05<22:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13554: train loss 1.16765. lr 3.790957e-04:  83%|████████▎ | 13554/16329 [1:54:06<22:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13554: train loss 1.16765. lr 3.790957e-04:  83%|████████▎ | 13555/16329 [1:54:06<22:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13555: train loss 1.15552. lr 3.790678e-04:  83%|████████▎ | 13555/16329 [1:54:06<22:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13555: train loss 1.15552. lr 3.790678e-04:  83%|████████▎ | 13556/16329 [1:54:06<22:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13556: train loss 1.14274. lr 3.790400e-04:  83%|████████▎ | 13556/16329 [1:54:07<22:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13556: train loss 1.14274. lr 3.790400e-04:  83%|████████▎ | 13557/16329 [1:54:07<25:54,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 13557: train loss 1.16181. lr 3.790121e-04:  83%|████████▎ | 13557/16329 [1:54:08<25:54,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 13557: train loss 1.16181. lr 3.790121e-04:  83%|████████▎ | 13558/16329 [1:54:08<25:01,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13558: train loss 1.19278. lr 3.789843e-04:  83%|████████▎ | 13558/16329 [1:54:08<25:01,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13558: train loss 1.19278. lr 3.789843e-04:  83%|████████▎ | 13559/16329 [1:54:08<24:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13559: train loss 1.17051. lr 3.789565e-04:  83%|████████▎ | 13559/16329 [1:54:09<24:22,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13559: train loss 1.17051. lr 3.789565e-04:  83%|████████▎ | 13560/16329 [1:54:09<23:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13560: train loss 1.15347. lr 3.789286e-04:  83%|████████▎ | 13560/16329 [1:54:09<23:57,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13560: train loss 1.15347. lr 3.789286e-04:  83%|████████▎ | 13561/16329 [1:54:09<23:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13561: train loss 1.16824. lr 3.789008e-04:  83%|████████▎ | 13561/16329 [1:54:10<23:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13561: train loss 1.16824. lr 3.789008e-04:  83%|████████▎ | 13562/16329 [1:54:10<24:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13562: train loss 1.17635. lr 3.788729e-04:  83%|████████▎ | 13562/16329 [1:54:10<24:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13562: train loss 1.17635. lr 3.788729e-04:  83%|████████▎ | 13563/16329 [1:54:10<24:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13563: train loss 1.18237. lr 3.788451e-04:  83%|████████▎ | 13563/16329 [1:54:11<24:32,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13563: train loss 1.18237. lr 3.788451e-04:  83%|████████▎ | 13564/16329 [1:54:11<24:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13564: train loss 1.18337. lr 3.788172e-04:  83%|████████▎ | 13564/16329 [1:54:11<24:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13564: train loss 1.18337. lr 3.788172e-04:  83%|████████▎ | 13565/16329 [1:54:11<24:29,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13565: train loss 1.13299. lr 3.787894e-04:  83%|████████▎ | 13565/16329 [1:54:12<24:29,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13565: train loss 1.13299. lr 3.787894e-04:  83%|████████▎ | 13566/16329 [1:54:12<24:16,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13566: train loss 1.14107. lr 3.787615e-04:  83%|████████▎ | 13566/16329 [1:54:12<24:16,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13566: train loss 1.14107. lr 3.787615e-04:  83%|████████▎ | 13567/16329 [1:54:12<24:05,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13567: train loss 1.19895. lr 3.787337e-04:  83%|████████▎ | 13567/16329 [1:54:13<24:05,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13567: train loss 1.19895. lr 3.787337e-04:  83%|████████▎ | 13568/16329 [1:54:13<23:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13568: train loss 1.16396. lr 3.787058e-04:  83%|████████▎ | 13568/16329 [1:54:13<23:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13568: train loss 1.16396. lr 3.787058e-04:  83%|████████▎ | 13569/16329 [1:54:13<23:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13569: train loss 1.14709. lr 3.786780e-04:  83%|████████▎ | 13569/16329 [1:54:14<23:37,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13569: train loss 1.14709. lr 3.786780e-04:  83%|████████▎ | 13570/16329 [1:54:14<23:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13570: train loss 1.17652. lr 3.786501e-04:  83%|████████▎ | 13570/16329 [1:54:14<23:24,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13570: train loss 1.17652. lr 3.786501e-04:  83%|████████▎ | 13571/16329 [1:54:14<23:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13571: train loss 1.15842. lr 3.786223e-04:  83%|████████▎ | 13571/16329 [1:54:15<23:15,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13571: train loss 1.15842. lr 3.786223e-04:  83%|████████▎ | 13572/16329 [1:54:15<23:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13572: train loss 1.13680. lr 3.785944e-04:  83%|████████▎ | 13572/16329 [1:54:15<23:05,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13572: train loss 1.13680. lr 3.785944e-04:  83%|████████▎ | 13573/16329 [1:54:15<23:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13573: train loss 1.15859. lr 3.785666e-04:  83%|████████▎ | 13573/16329 [1:54:16<23:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13573: train loss 1.15859. lr 3.785666e-04:  83%|████████▎ | 13574/16329 [1:54:16<22:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13574: train loss 1.15560. lr 3.785387e-04:  83%|████████▎ | 13574/16329 [1:54:16<22:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13574: train loss 1.15560. lr 3.785387e-04:  83%|████████▎ | 13575/16329 [1:54:16<22:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13575: train loss 1.17241. lr 3.785109e-04:  83%|████████▎ | 13575/16329 [1:54:17<22:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13575: train loss 1.17241. lr 3.785109e-04:  83%|████████▎ | 13576/16329 [1:54:17<22:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13576: train loss 1.15530. lr 3.784830e-04:  83%|████████▎ | 13576/16329 [1:54:17<22:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13576: train loss 1.15530. lr 3.784830e-04:  83%|████████▎ | 13577/16329 [1:54:17<22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13577: train loss 1.16636. lr 3.784552e-04:  83%|████████▎ | 13577/16329 [1:54:18<22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13577: train loss 1.16636. lr 3.784552e-04:  83%|████████▎ | 13578/16329 [1:54:18<22:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13578: train loss 1.18774. lr 3.784273e-04:  83%|████████▎ | 13578/16329 [1:54:18<22:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13578: train loss 1.18774. lr 3.784273e-04:  83%|████████▎ | 13579/16329 [1:54:18<22:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13579: train loss 1.17380. lr 3.783995e-04:  83%|████████▎ | 13579/16329 [1:54:19<22:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13579: train loss 1.17380. lr 3.783995e-04:  83%|████████▎ | 13580/16329 [1:54:19<22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13580: train loss 1.19093. lr 3.783716e-04:  83%|████████▎ | 13580/16329 [1:54:19<22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13580: train loss 1.19093. lr 3.783716e-04:  83%|████████▎ | 13581/16329 [1:54:19<22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13581: train loss 1.14830. lr 3.783437e-04:  83%|████████▎ | 13581/16329 [1:54:20<22:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13581: train loss 1.14830. lr 3.783437e-04:  83%|████████▎ | 13582/16329 [1:54:20<22:40,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13582: train loss 1.15757. lr 3.783159e-04:  83%|████████▎ | 13582/16329 [1:54:20<22:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13582: train loss 1.15757. lr 3.783159e-04:  83%|████████▎ | 13583/16329 [1:54:20<22:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13583: train loss 1.16409. lr 3.782880e-04:  83%|████████▎ | 13583/16329 [1:54:21<22:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13583: train loss 1.16409. lr 3.782880e-04:  83%|████████▎ | 13584/16329 [1:54:21<25:15,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13584: train loss 1.17782. lr 3.782602e-04:  83%|████████▎ | 13584/16329 [1:54:21<25:15,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13584: train loss 1.17782. lr 3.782602e-04:  83%|████████▎ | 13585/16329 [1:54:21<24:31,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13585: train loss 1.16439. lr 3.782323e-04:  83%|████████▎ | 13585/16329 [1:54:22<24:31,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13585: train loss 1.16439. lr 3.782323e-04:  83%|████████▎ | 13586/16329 [1:54:22<23:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13586: train loss 1.15327. lr 3.782044e-04:  83%|████████▎ | 13586/16329 [1:54:22<23:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13586: train loss 1.15327. lr 3.782044e-04:  83%|████████▎ | 13587/16329 [1:54:22<23:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13587: train loss 1.19692. lr 3.781766e-04:  83%|████████▎ | 13587/16329 [1:54:23<23:29,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13587: train loss 1.19692. lr 3.781766e-04:  83%|████████▎ | 13588/16329 [1:54:23<23:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13588: train loss 1.16139. lr 3.781487e-04:  83%|████████▎ | 13588/16329 [1:54:23<23:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13588: train loss 1.16139. lr 3.781487e-04:  83%|████████▎ | 13589/16329 [1:54:23<23:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13589: train loss 1.17971. lr 3.781208e-04:  83%|████████▎ | 13589/16329 [1:54:24<23:04,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13589: train loss 1.17971. lr 3.781208e-04:  83%|████████▎ | 13590/16329 [1:54:24<23:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13590: train loss 1.13181. lr 3.780930e-04:  83%|████████▎ | 13590/16329 [1:54:24<23:00,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13590: train loss 1.13181. lr 3.780930e-04:  83%|████████▎ | 13591/16329 [1:54:24<22:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13591: train loss 1.12790. lr 3.780651e-04:  83%|████████▎ | 13591/16329 [1:54:25<22:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13591: train loss 1.12790. lr 3.780651e-04:  83%|████████▎ | 13592/16329 [1:54:25<22:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13592: train loss 1.14883. lr 3.780372e-04:  83%|████████▎ | 13592/16329 [1:54:25<22:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13592: train loss 1.14883. lr 3.780372e-04:  83%|████████▎ | 13593/16329 [1:54:25<22:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13593: train loss 1.14915. lr 3.780094e-04:  83%|████████▎ | 13593/16329 [1:54:26<22:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13593: train loss 1.14915. lr 3.780094e-04:  83%|████████▎ | 13594/16329 [1:54:26<22:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13594: train loss 1.15056. lr 3.779815e-04:  83%|████████▎ | 13594/16329 [1:54:26<22:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13594: train loss 1.15056. lr 3.779815e-04:  83%|████████▎ | 13595/16329 [1:54:26<22:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13595: train loss 1.14822. lr 3.779536e-04:  83%|████████▎ | 13595/16329 [1:54:27<22:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13595: train loss 1.14822. lr 3.779536e-04:  83%|████████▎ | 13596/16329 [1:54:27<22:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13596: train loss 1.14128. lr 3.779258e-04:  83%|████████▎ | 13596/16329 [1:54:27<22:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13596: train loss 1.14128. lr 3.779258e-04:  83%|████████▎ | 13597/16329 [1:54:27<22:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13597: train loss 1.18822. lr 3.778979e-04:  83%|████████▎ | 13597/16329 [1:54:28<22:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13597: train loss 1.18822. lr 3.778979e-04:  83%|████████▎ | 13598/16329 [1:54:28<22:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13598: train loss 1.14647. lr 3.778700e-04:  83%|████████▎ | 13598/16329 [1:54:28<22:35,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13598: train loss 1.14647. lr 3.778700e-04:  83%|████████▎ | 13599/16329 [1:54:28<22:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13599: train loss 1.15537. lr 3.778422e-04:  83%|████████▎ | 13599/16329 [1:54:29<22:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13599: train loss 1.15537. lr 3.778422e-04:  83%|████████▎ | 13600/16329 [1:54:29<22:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13600: train loss 1.16659. lr 3.778143e-04:  83%|████████▎ | 13600/16329 [1:54:29<22:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13600: train loss 1.16659. lr 3.778143e-04:  83%|████████▎ | 13601/16329 [1:54:29<22:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13601: train loss 1.19687. lr 3.777864e-04:  83%|████████▎ | 13601/16329 [1:54:30<22:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13601: train loss 1.19687. lr 3.777864e-04:  83%|████████▎ | 13602/16329 [1:54:30<22:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13602: train loss 1.17173. lr 3.777585e-04:  83%|████████▎ | 13602/16329 [1:54:30<22:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13602: train loss 1.17173. lr 3.777585e-04:  83%|████████▎ | 13603/16329 [1:54:30<22:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13603: train loss 1.16817. lr 3.777307e-04:  83%|████████▎ | 13603/16329 [1:54:31<22:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13603: train loss 1.16817. lr 3.777307e-04:  83%|████████▎ | 13604/16329 [1:54:31<22:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13604: train loss 1.14973. lr 3.777028e-04:  83%|████████▎ | 13604/16329 [1:54:31<22:41,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13604: train loss 1.14973. lr 3.777028e-04:  83%|████████▎ | 13605/16329 [1:54:31<22:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13605: train loss 1.14462. lr 3.776749e-04:  83%|████████▎ | 13605/16329 [1:54:32<22:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13605: train loss 1.14462. lr 3.776749e-04:  83%|████████▎ | 13606/16329 [1:54:32<22:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13606: train loss 1.15026. lr 3.776470e-04:  83%|████████▎ | 13606/16329 [1:54:32<22:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13606: train loss 1.15026. lr 3.776470e-04:  83%|████████▎ | 13607/16329 [1:54:32<22:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13607: train loss 1.18892. lr 3.776192e-04:  83%|████████▎ | 13607/16329 [1:54:33<22:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13607: train loss 1.18892. lr 3.776192e-04:  83%|████████▎ | 13608/16329 [1:54:33<22:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13608: train loss 1.15345. lr 3.775913e-04:  83%|████████▎ | 13608/16329 [1:54:33<22:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13608: train loss 1.15345. lr 3.775913e-04:  83%|████████▎ | 13609/16329 [1:54:33<22:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13609: train loss 1.18414. lr 3.775634e-04:  83%|████████▎ | 13609/16329 [1:54:34<22:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13609: train loss 1.18414. lr 3.775634e-04:  83%|████████▎ | 13610/16329 [1:54:34<22:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13610: train loss 1.15414. lr 3.775355e-04:  83%|████████▎ | 13610/16329 [1:54:34<22:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13610: train loss 1.15414. lr 3.775355e-04:  83%|████████▎ | 13611/16329 [1:54:34<22:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13611: train loss 1.18573. lr 3.775076e-04:  83%|████████▎ | 13611/16329 [1:54:35<22:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13611: train loss 1.18573. lr 3.775076e-04:  83%|████████▎ | 13612/16329 [1:54:35<22:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13612: train loss 1.15276. lr 3.774798e-04:  83%|████████▎ | 13612/16329 [1:54:35<22:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13612: train loss 1.15276. lr 3.774798e-04:  83%|████████▎ | 13613/16329 [1:54:35<22:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13613: train loss 1.18853. lr 3.774519e-04:  83%|████████▎ | 13613/16329 [1:54:36<22:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13613: train loss 1.18853. lr 3.774519e-04:  83%|████████▎ | 13614/16329 [1:54:36<22:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13614: train loss 1.15453. lr 3.774240e-04:  83%|████████▎ | 13614/16329 [1:54:36<22:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13614: train loss 1.15453. lr 3.774240e-04:  83%|████████▎ | 13615/16329 [1:54:36<22:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13615: train loss 1.17271. lr 3.773961e-04:  83%|████████▎ | 13615/16329 [1:54:37<22:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13615: train loss 1.17271. lr 3.773961e-04:  83%|████████▎ | 13616/16329 [1:54:37<22:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13616: train loss 1.17745. lr 3.773682e-04:  83%|████████▎ | 13616/16329 [1:54:37<22:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13616: train loss 1.17745. lr 3.773682e-04:  83%|████████▎ | 13617/16329 [1:54:37<22:37,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13617: train loss 1.13826. lr 3.773403e-04:  83%|████████▎ | 13617/16329 [1:54:38<22:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13617: train loss 1.13826. lr 3.773403e-04:  83%|████████▎ | 13618/16329 [1:54:38<22:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13618: train loss 1.19082. lr 3.773125e-04:  83%|████████▎ | 13618/16329 [1:54:38<22:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13618: train loss 1.19082. lr 3.773125e-04:  83%|████████▎ | 13619/16329 [1:54:38<22:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13619: train loss 1.18248. lr 3.772846e-04:  83%|████████▎ | 13619/16329 [1:54:39<22:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13619: train loss 1.18248. lr 3.772846e-04:  83%|████████▎ | 13620/16329 [1:54:39<22:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13620: train loss 1.15316. lr 3.772567e-04:  83%|████████▎ | 13620/16329 [1:54:39<22:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13620: train loss 1.15316. lr 3.772567e-04:  83%|████████▎ | 13621/16329 [1:54:39<22:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13621: train loss 1.14389. lr 3.772288e-04:  83%|████████▎ | 13621/16329 [1:54:40<22:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13621: train loss 1.14389. lr 3.772288e-04:  83%|████████▎ | 13622/16329 [1:54:40<22:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13622: train loss 1.12998. lr 3.772009e-04:  83%|████████▎ | 13622/16329 [1:54:40<22:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13622: train loss 1.12998. lr 3.772009e-04:  83%|████████▎ | 13623/16329 [1:54:40<22:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13623: train loss 1.15959. lr 3.771730e-04:  83%|████████▎ | 13623/16329 [1:54:41<22:52,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13623: train loss 1.15959. lr 3.771730e-04:  83%|████████▎ | 13624/16329 [1:54:41<25:42,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 13624: train loss 1.15368. lr 3.771451e-04:  83%|████████▎ | 13624/16329 [1:54:42<25:42,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 13624: train loss 1.15368. lr 3.771451e-04:  83%|████████▎ | 13625/16329 [1:54:42<25:03,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13625: train loss 1.14067. lr 3.771172e-04:  83%|████████▎ | 13625/16329 [1:54:42<25:03,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13625: train loss 1.14067. lr 3.771172e-04:  83%|████████▎ | 13626/16329 [1:54:42<24:27,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 13626: train loss 1.15534. lr 3.770894e-04:  83%|████████▎ | 13626/16329 [1:54:43<24:27,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 13626: train loss 1.15534. lr 3.770894e-04:  83%|████████▎ | 13627/16329 [1:54:43<23:57,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13627: train loss 1.13102. lr 3.770615e-04:  83%|████████▎ | 13627/16329 [1:54:43<23:57,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13627: train loss 1.13102. lr 3.770615e-04:  83%|████████▎ | 13628/16329 [1:54:43<23:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13628: train loss 1.12524. lr 3.770336e-04:  83%|████████▎ | 13628/16329 [1:54:44<23:34,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13628: train loss 1.12524. lr 3.770336e-04:  83%|████████▎ | 13629/16329 [1:54:44<23:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13629: train loss 1.15862. lr 3.770057e-04:  83%|████████▎ | 13629/16329 [1:54:44<23:15,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13629: train loss 1.15862. lr 3.770057e-04:  83%|████████▎ | 13630/16329 [1:54:44<22:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13630: train loss 1.15599. lr 3.769778e-04:  83%|████████▎ | 13630/16329 [1:54:45<22:58,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13630: train loss 1.15599. lr 3.769778e-04:  83%|████████▎ | 13631/16329 [1:54:45<22:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13631: train loss 1.19107. lr 3.769499e-04:  83%|████████▎ | 13631/16329 [1:54:45<22:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13631: train loss 1.19107. lr 3.769499e-04:  83%|████████▎ | 13632/16329 [1:54:45<22:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13632: train loss 1.19181. lr 3.769220e-04:  83%|████████▎ | 13632/16329 [1:54:46<22:38,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13632: train loss 1.19181. lr 3.769220e-04:  83%|████████▎ | 13633/16329 [1:54:46<22:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13633: train loss 1.18429. lr 3.768941e-04:  83%|████████▎ | 13633/16329 [1:54:46<22:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13633: train loss 1.18429. lr 3.768941e-04:  83%|████████▎ | 13634/16329 [1:54:46<22:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13634: train loss 1.15731. lr 3.768662e-04:  83%|████████▎ | 13634/16329 [1:54:47<22:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13634: train loss 1.15731. lr 3.768662e-04:  84%|████████▎ | 13635/16329 [1:54:47<22:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13635: train loss 1.14879. lr 3.768383e-04:  84%|████████▎ | 13635/16329 [1:54:47<22:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13635: train loss 1.14879. lr 3.768383e-04:  84%|████████▎ | 13636/16329 [1:54:47<22:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13636: train loss 1.15463. lr 3.768104e-04:  84%|████████▎ | 13636/16329 [1:54:48<22:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13636: train loss 1.15463. lr 3.768104e-04:  84%|████████▎ | 13637/16329 [1:54:48<22:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13637: train loss 1.14641. lr 3.767825e-04:  84%|████████▎ | 13637/16329 [1:54:48<22:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13637: train loss 1.14641. lr 3.767825e-04:  84%|████████▎ | 13638/16329 [1:54:48<22:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13638: train loss 1.14592. lr 3.767546e-04:  84%|████████▎ | 13638/16329 [1:54:49<22:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13638: train loss 1.14592. lr 3.767546e-04:  84%|████████▎ | 13639/16329 [1:54:49<22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13639: train loss 1.14439. lr 3.767267e-04:  84%|████████▎ | 13639/16329 [1:54:49<22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13639: train loss 1.14439. lr 3.767267e-04:  84%|████████▎ | 13640/16329 [1:54:49<22:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13640: train loss 1.18709. lr 3.766988e-04:  84%|████████▎ | 13640/16329 [1:54:50<22:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13640: train loss 1.18709. lr 3.766988e-04:  84%|████████▎ | 13641/16329 [1:54:50<22:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13641: train loss 1.16805. lr 3.766709e-04:  84%|████████▎ | 13641/16329 [1:54:50<22:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13641: train loss 1.16805. lr 3.766709e-04:  84%|████████▎ | 13642/16329 [1:54:50<22:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13642: train loss 1.14765. lr 3.766430e-04:  84%|████████▎ | 13642/16329 [1:54:51<22:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13642: train loss 1.14765. lr 3.766430e-04:  84%|████████▎ | 13643/16329 [1:54:51<22:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13643: train loss 1.15878. lr 3.766151e-04:  84%|████████▎ | 13643/16329 [1:54:51<22:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13643: train loss 1.15878. lr 3.766151e-04:  84%|████████▎ | 13644/16329 [1:54:51<22:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13644: train loss 1.18077. lr 3.765872e-04:  84%|████████▎ | 13644/16329 [1:54:52<22:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13644: train loss 1.18077. lr 3.765872e-04:  84%|████████▎ | 13645/16329 [1:54:52<22:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13645: train loss 1.15441. lr 3.765593e-04:  84%|████████▎ | 13645/16329 [1:54:52<22:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13645: train loss 1.15441. lr 3.765593e-04:  84%|████████▎ | 13646/16329 [1:54:52<22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13646: train loss 1.15723. lr 3.765314e-04:  84%|████████▎ | 13646/16329 [1:54:53<22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13646: train loss 1.15723. lr 3.765314e-04:  84%|████████▎ | 13647/16329 [1:54:53<22:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13647: train loss 1.16749. lr 3.765035e-04:  84%|████████▎ | 13647/16329 [1:54:53<22:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13647: train loss 1.16749. lr 3.765035e-04:  84%|████████▎ | 13648/16329 [1:54:53<22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13648: train loss 1.14201. lr 3.764756e-04:  84%|████████▎ | 13648/16329 [1:54:54<22:10,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13648: train loss 1.14201. lr 3.764756e-04:  84%|████████▎ | 13649/16329 [1:54:54<22:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13649: train loss 1.16441. lr 3.764477e-04:  84%|████████▎ | 13649/16329 [1:54:54<22:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13649: train loss 1.16441. lr 3.764477e-04:  84%|████████▎ | 13650/16329 [1:54:54<22:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13650: train loss 1.14446. lr 3.764198e-04:  84%|████████▎ | 13650/16329 [1:54:55<22:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13650: train loss 1.14446. lr 3.764198e-04:  84%|████████▎ | 13651/16329 [1:54:55<22:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13651: train loss 1.15679. lr 3.763919e-04:  84%|████████▎ | 13651/16329 [1:54:55<22:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13651: train loss 1.15679. lr 3.763919e-04:  84%|████████▎ | 13652/16329 [1:54:55<22:09,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13652: train loss 1.15291. lr 3.763639e-04:  84%|████████▎ | 13652/16329 [1:54:56<22:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13652: train loss 1.15291. lr 3.763639e-04:  84%|████████▎ | 13653/16329 [1:54:56<22:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13653: train loss 1.16021. lr 3.763360e-04:  84%|████████▎ | 13653/16329 [1:54:56<22:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13653: train loss 1.16021. lr 3.763360e-04:  84%|████████▎ | 13654/16329 [1:54:56<22:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13654: train loss 1.16238. lr 3.763081e-04:  84%|████████▎ | 13654/16329 [1:54:57<22:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13654: train loss 1.16238. lr 3.763081e-04:  84%|████████▎ | 13655/16329 [1:54:57<22:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13655: train loss 1.15783. lr 3.762802e-04:  84%|████████▎ | 13655/16329 [1:54:57<22:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13655: train loss 1.15783. lr 3.762802e-04:  84%|████████▎ | 13656/16329 [1:54:57<22:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13656: train loss 1.17884. lr 3.762523e-04:  84%|████████▎ | 13656/16329 [1:54:58<22:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13656: train loss 1.17884. lr 3.762523e-04:  84%|████████▎ | 13657/16329 [1:54:58<22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13657: train loss 1.17427. lr 3.762244e-04:  84%|████████▎ | 13657/16329 [1:54:58<22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13657: train loss 1.17427. lr 3.762244e-04:  84%|████████▎ | 13658/16329 [1:54:58<22:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13658: train loss 1.17492. lr 3.761965e-04:  84%|████████▎ | 13658/16329 [1:54:59<22:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13658: train loss 1.17492. lr 3.761965e-04:  84%|████████▎ | 13659/16329 [1:54:59<24:23,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13659: train loss 1.20081. lr 3.761686e-04:  84%|████████▎ | 13659/16329 [1:54:59<24:23,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13659: train loss 1.20081. lr 3.761686e-04:  84%|████████▎ | 13660/16329 [1:54:59<23:43,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13660: train loss 1.17284. lr 3.761406e-04:  84%|████████▎ | 13660/16329 [1:55:00<23:43,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13660: train loss 1.17284. lr 3.761406e-04:  84%|████████▎ | 13661/16329 [1:55:00<23:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13661: train loss 1.13749. lr 3.761127e-04:  84%|████████▎ | 13661/16329 [1:55:00<23:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13661: train loss 1.13749. lr 3.761127e-04:  84%|████████▎ | 13662/16329 [1:55:00<22:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13662: train loss 1.15433. lr 3.760848e-04:  84%|████████▎ | 13662/16329 [1:55:01<22:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13662: train loss 1.15433. lr 3.760848e-04:  84%|████████▎ | 13663/16329 [1:55:01<22:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13663: train loss 1.16480. lr 3.760569e-04:  84%|████████▎ | 13663/16329 [1:55:01<22:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13663: train loss 1.16480. lr 3.760569e-04:  84%|████████▎ | 13664/16329 [1:55:01<22:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13664: train loss 1.16656. lr 3.760290e-04:  84%|████████▎ | 13664/16329 [1:55:02<22:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13664: train loss 1.16656. lr 3.760290e-04:  84%|████████▎ | 13665/16329 [1:55:02<22:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13665: train loss 1.14961. lr 3.760011e-04:  84%|████████▎ | 13665/16329 [1:55:02<22:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13665: train loss 1.14961. lr 3.760011e-04:  84%|████████▎ | 13666/16329 [1:55:02<22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13666: train loss 1.16842. lr 3.759731e-04:  84%|████████▎ | 13666/16329 [1:55:03<22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13666: train loss 1.16842. lr 3.759731e-04:  84%|████████▎ | 13667/16329 [1:55:03<22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13667: train loss 1.16299. lr 3.759452e-04:  84%|████████▎ | 13667/16329 [1:55:03<22:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13667: train loss 1.16299. lr 3.759452e-04:  84%|████████▎ | 13668/16329 [1:55:03<22:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13668: train loss 1.14751. lr 3.759173e-04:  84%|████████▎ | 13668/16329 [1:55:04<22:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13668: train loss 1.14751. lr 3.759173e-04:  84%|████████▎ | 13669/16329 [1:55:04<22:53,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13669: train loss 1.15381. lr 3.758894e-04:  84%|████████▎ | 13669/16329 [1:55:04<22:53,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13669: train loss 1.15381. lr 3.758894e-04:  84%|████████▎ | 13670/16329 [1:55:04<22:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13670: train loss 1.14722. lr 3.758615e-04:  84%|████████▎ | 13670/16329 [1:55:05<22:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13670: train loss 1.14722. lr 3.758615e-04:  84%|████████▎ | 13671/16329 [1:55:05<22:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13671: train loss 1.17460. lr 3.758335e-04:  84%|████████▎ | 13671/16329 [1:55:05<22:47,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13671: train loss 1.17460. lr 3.758335e-04:  84%|████████▎ | 13672/16329 [1:55:05<22:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13672: train loss 1.16636. lr 3.758056e-04:  84%|████████▎ | 13672/16329 [1:55:06<22:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13672: train loss 1.16636. lr 3.758056e-04:  84%|████████▎ | 13673/16329 [1:55:06<22:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13673: train loss 1.14790. lr 3.757777e-04:  84%|████████▎ | 13673/16329 [1:55:06<22:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13673: train loss 1.14790. lr 3.757777e-04:  84%|████████▎ | 13674/16329 [1:55:06<22:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13674: train loss 1.15791. lr 3.757498e-04:  84%|████████▎ | 13674/16329 [1:55:07<22:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13674: train loss 1.15791. lr 3.757498e-04:  84%|████████▎ | 13675/16329 [1:55:07<22:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13675: train loss 1.12335. lr 3.757218e-04:  84%|████████▎ | 13675/16329 [1:55:07<22:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13675: train loss 1.12335. lr 3.757218e-04:  84%|████████▍ | 13676/16329 [1:55:07<22:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13676: train loss 1.14649. lr 3.756939e-04:  84%|████████▍ | 13676/16329 [1:55:08<22:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13676: train loss 1.14649. lr 3.756939e-04:  84%|████████▍ | 13677/16329 [1:55:08<22:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13677: train loss 1.13716. lr 3.756660e-04:  84%|████████▍ | 13677/16329 [1:55:08<22:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13677: train loss 1.13716. lr 3.756660e-04:  84%|████████▍ | 13678/16329 [1:55:08<21:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13678: train loss 1.15742. lr 3.756381e-04:  84%|████████▍ | 13678/16329 [1:55:09<21:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13678: train loss 1.15742. lr 3.756381e-04:  84%|████████▍ | 13679/16329 [1:55:09<21:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13679: train loss 1.15282. lr 3.756101e-04:  84%|████████▍ | 13679/16329 [1:55:09<21:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13679: train loss 1.15282. lr 3.756101e-04:  84%|████████▍ | 13680/16329 [1:55:09<21:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13680: train loss 1.15522. lr 3.755822e-04:  84%|████████▍ | 13680/16329 [1:55:10<21:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13680: train loss 1.15522. lr 3.755822e-04:  84%|████████▍ | 13681/16329 [1:55:10<21:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13681: train loss 1.17560. lr 3.755543e-04:  84%|████████▍ | 13681/16329 [1:55:10<21:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13681: train loss 1.17560. lr 3.755543e-04:  84%|████████▍ | 13682/16329 [1:55:10<21:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13682: train loss 1.16192. lr 3.755263e-04:  84%|████████▍ | 13682/16329 [1:55:11<21:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13682: train loss 1.16192. lr 3.755263e-04:  84%|████████▍ | 13683/16329 [1:55:11<21:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13683: train loss 1.18092. lr 3.754984e-04:  84%|████████▍ | 13683/16329 [1:55:11<21:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13683: train loss 1.18092. lr 3.754984e-04:  84%|████████▍ | 13684/16329 [1:55:11<24:08,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13684: train loss 1.19879. lr 3.754705e-04:  84%|████████▍ | 13684/16329 [1:55:12<24:08,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13684: train loss 1.19879. lr 3.754705e-04:  84%|████████▍ | 13685/16329 [1:55:12<24:27,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13685: train loss 1.14583. lr 3.754425e-04:  84%|████████▍ | 13685/16329 [1:55:13<24:27,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13685: train loss 1.14583. lr 3.754425e-04:  84%|████████▍ | 13686/16329 [1:55:13<24:31,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13686: train loss 1.15658. lr 3.754146e-04:  84%|████████▍ | 13686/16329 [1:55:13<24:31,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13686: train loss 1.15658. lr 3.754146e-04:  84%|████████▍ | 13687/16329 [1:55:13<24:23,  1.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13687: train loss 1.14233. lr 3.753867e-04:  84%|████████▍ | 13687/16329 [1:55:14<24:23,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13687: train loss 1.14233. lr 3.753867e-04:  84%|████████▍ | 13688/16329 [1:55:14<24:01,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13688: train loss 1.17460. lr 3.753587e-04:  84%|████████▍ | 13688/16329 [1:55:14<24:01,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 13688: train loss 1.17460. lr 3.753587e-04:  84%|████████▍ | 13689/16329 [1:55:14<23:36,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13689: train loss 1.16760. lr 3.753308e-04:  84%|████████▍ | 13689/16329 [1:55:15<23:36,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13689: train loss 1.16760. lr 3.753308e-04:  84%|████████▍ | 13690/16329 [1:55:15<23:16,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13690: train loss 1.14358. lr 3.753029e-04:  84%|████████▍ | 13690/16329 [1:55:15<23:16,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13690: train loss 1.14358. lr 3.753029e-04:  84%|████████▍ | 13691/16329 [1:55:15<22:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13691: train loss 1.17029. lr 3.752749e-04:  84%|████████▍ | 13691/16329 [1:55:16<22:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13691: train loss 1.17029. lr 3.752749e-04:  84%|████████▍ | 13692/16329 [1:55:16<22:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13692: train loss 1.14341. lr 3.752470e-04:  84%|████████▍ | 13692/16329 [1:55:16<22:33,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13692: train loss 1.14341. lr 3.752470e-04:  84%|████████▍ | 13693/16329 [1:55:16<22:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13693: train loss 1.14075. lr 3.752191e-04:  84%|████████▍ | 13693/16329 [1:55:17<22:14,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13693: train loss 1.14075. lr 3.752191e-04:  84%|████████▍ | 13694/16329 [1:55:17<22:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13694: train loss 1.14945. lr 3.751911e-04:  84%|████████▍ | 13694/16329 [1:55:17<22:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13694: train loss 1.14945. lr 3.751911e-04:  84%|████████▍ | 13695/16329 [1:55:17<21:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13695: train loss 1.11413. lr 3.751632e-04:  84%|████████▍ | 13695/16329 [1:55:18<21:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13695: train loss 1.11413. lr 3.751632e-04:  84%|████████▍ | 13696/16329 [1:55:18<21:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13696: train loss 1.15234. lr 3.751352e-04:  84%|████████▍ | 13696/16329 [1:55:18<21:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13696: train loss 1.15234. lr 3.751352e-04:  84%|████████▍ | 13697/16329 [1:55:18<21:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13697: train loss 1.20102. lr 3.751073e-04:  84%|████████▍ | 13697/16329 [1:55:19<21:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13697: train loss 1.20102. lr 3.751073e-04:  84%|████████▍ | 13698/16329 [1:55:19<21:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13698: train loss 1.20775. lr 3.750794e-04:  84%|████████▍ | 13698/16329 [1:55:19<21:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13698: train loss 1.20775. lr 3.750794e-04:  84%|████████▍ | 13699/16329 [1:55:19<21:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13699: train loss 1.12272. lr 3.750514e-04:  84%|████████▍ | 13699/16329 [1:55:20<21:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13699: train loss 1.12272. lr 3.750514e-04:  84%|████████▍ | 13700/16329 [1:55:20<21:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13700: train loss 1.13641. lr 3.750235e-04:  84%|████████▍ | 13700/16329 [1:55:20<21:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13700: train loss 1.13641. lr 3.750235e-04:  84%|████████▍ | 13701/16329 [1:55:20<21:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13701: train loss 1.13713. lr 3.749955e-04:  84%|████████▍ | 13701/16329 [1:55:21<21:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13701: train loss 1.13713. lr 3.749955e-04:  84%|████████▍ | 13702/16329 [1:55:21<21:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13702: train loss 1.15966. lr 3.749676e-04:  84%|████████▍ | 13702/16329 [1:55:21<21:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13702: train loss 1.15966. lr 3.749676e-04:  84%|████████▍ | 13703/16329 [1:55:21<21:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13703: train loss 1.12568. lr 3.749396e-04:  84%|████████▍ | 13703/16329 [1:55:22<21:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13703: train loss 1.12568. lr 3.749396e-04:  84%|████████▍ | 13704/16329 [1:55:22<21:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13704: train loss 1.13866. lr 3.749117e-04:  84%|████████▍ | 13704/16329 [1:55:22<21:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13704: train loss 1.13866. lr 3.749117e-04:  84%|████████▍ | 13705/16329 [1:55:22<21:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13705: train loss 1.14441. lr 3.748837e-04:  84%|████████▍ | 13705/16329 [1:55:23<21:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13705: train loss 1.14441. lr 3.748837e-04:  84%|████████▍ | 13706/16329 [1:55:23<21:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13706: train loss 1.19985. lr 3.748558e-04:  84%|████████▍ | 13706/16329 [1:55:23<21:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13706: train loss 1.19985. lr 3.748558e-04:  84%|████████▍ | 13707/16329 [1:55:23<21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13707: train loss 1.15339. lr 3.748279e-04:  84%|████████▍ | 13707/16329 [1:55:24<21:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13707: train loss 1.15339. lr 3.748279e-04:  84%|████████▍ | 13708/16329 [1:55:24<22:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13708: train loss 1.18977. lr 3.747999e-04:  84%|████████▍ | 13708/16329 [1:55:24<22:15,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13708: train loss 1.18977. lr 3.747999e-04:  84%|████████▍ | 13709/16329 [1:55:24<22:41,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13709: train loss 1.16427. lr 3.747720e-04:  84%|████████▍ | 13709/16329 [1:55:25<22:41,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13709: train loss 1.16427. lr 3.747720e-04:  84%|████████▍ | 13710/16329 [1:55:25<22:52,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13710: train loss 1.16642. lr 3.747440e-04:  84%|████████▍ | 13710/16329 [1:55:25<22:52,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13710: train loss 1.16642. lr 3.747440e-04:  84%|████████▍ | 13711/16329 [1:55:25<25:04,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 13711: train loss 1.12838. lr 3.747161e-04:  84%|████████▍ | 13711/16329 [1:55:26<25:04,  1.74it/s]\u001b[A\n",
      "epoch 1 iter 13711: train loss 1.12838. lr 3.747161e-04:  84%|████████▍ | 13712/16329 [1:55:26<24:12,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13712: train loss 1.14508. lr 3.746881e-04:  84%|████████▍ | 13712/16329 [1:55:26<24:12,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 13712: train loss 1.14508. lr 3.746881e-04:  84%|████████▍ | 13713/16329 [1:55:26<23:33,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13713: train loss 1.15111. lr 3.746602e-04:  84%|████████▍ | 13713/16329 [1:55:27<23:33,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13713: train loss 1.15111. lr 3.746602e-04:  84%|████████▍ | 13714/16329 [1:55:27<22:55,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13714: train loss 1.15470. lr 3.746322e-04:  84%|████████▍ | 13714/16329 [1:55:27<22:55,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13714: train loss 1.15470. lr 3.746322e-04:  84%|████████▍ | 13715/16329 [1:55:27<22:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13715: train loss 1.16985. lr 3.746042e-04:  84%|████████▍ | 13715/16329 [1:55:28<22:27,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13715: train loss 1.16985. lr 3.746042e-04:  84%|████████▍ | 13716/16329 [1:55:28<22:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13716: train loss 1.19336. lr 3.745763e-04:  84%|████████▍ | 13716/16329 [1:55:28<22:12,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13716: train loss 1.19336. lr 3.745763e-04:  84%|████████▍ | 13717/16329 [1:55:28<21:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13717: train loss 1.15537. lr 3.745483e-04:  84%|████████▍ | 13717/16329 [1:55:29<21:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13717: train loss 1.15537. lr 3.745483e-04:  84%|████████▍ | 13718/16329 [1:55:29<21:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13718: train loss 1.13466. lr 3.745204e-04:  84%|████████▍ | 13718/16329 [1:55:29<21:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13718: train loss 1.13466. lr 3.745204e-04:  84%|████████▍ | 13719/16329 [1:55:29<21:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13719: train loss 1.19076. lr 3.744924e-04:  84%|████████▍ | 13719/16329 [1:55:30<21:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13719: train loss 1.19076. lr 3.744924e-04:  84%|████████▍ | 13720/16329 [1:55:30<21:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13720: train loss 1.18643. lr 3.744645e-04:  84%|████████▍ | 13720/16329 [1:55:30<21:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13720: train loss 1.18643. lr 3.744645e-04:  84%|████████▍ | 13721/16329 [1:55:30<21:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13721: train loss 1.14650. lr 3.744365e-04:  84%|████████▍ | 13721/16329 [1:55:31<21:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13721: train loss 1.14650. lr 3.744365e-04:  84%|████████▍ | 13722/16329 [1:55:31<21:33,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13722: train loss 1.15250. lr 3.744086e-04:  84%|████████▍ | 13722/16329 [1:55:31<21:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13722: train loss 1.15250. lr 3.744086e-04:  84%|████████▍ | 13723/16329 [1:55:31<21:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13723: train loss 1.17806. lr 3.743806e-04:  84%|████████▍ | 13723/16329 [1:55:32<21:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13723: train loss 1.17806. lr 3.743806e-04:  84%|████████▍ | 13724/16329 [1:55:32<21:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13724: train loss 1.18032. lr 3.743526e-04:  84%|████████▍ | 13724/16329 [1:55:32<21:30,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13724: train loss 1.18032. lr 3.743526e-04:  84%|████████▍ | 13725/16329 [1:55:32<21:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13725: train loss 1.19908. lr 3.743247e-04:  84%|████████▍ | 13725/16329 [1:55:33<21:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13725: train loss 1.19908. lr 3.743247e-04:  84%|████████▍ | 13726/16329 [1:55:33<21:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13726: train loss 1.14971. lr 3.742967e-04:  84%|████████▍ | 13726/16329 [1:55:33<21:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13726: train loss 1.14971. lr 3.742967e-04:  84%|████████▍ | 13727/16329 [1:55:33<21:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13727: train loss 1.13757. lr 3.742688e-04:  84%|████████▍ | 13727/16329 [1:55:34<21:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13727: train loss 1.13757. lr 3.742688e-04:  84%|████████▍ | 13728/16329 [1:55:34<21:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13728: train loss 1.13375. lr 3.742408e-04:  84%|████████▍ | 13728/16329 [1:55:34<21:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13728: train loss 1.13375. lr 3.742408e-04:  84%|████████▍ | 13729/16329 [1:55:34<21:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13729: train loss 1.16108. lr 3.742128e-04:  84%|████████▍ | 13729/16329 [1:55:35<21:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13729: train loss 1.16108. lr 3.742128e-04:  84%|████████▍ | 13730/16329 [1:55:35<21:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13730: train loss 1.12731. lr 3.741849e-04:  84%|████████▍ | 13730/16329 [1:55:35<21:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13730: train loss 1.12731. lr 3.741849e-04:  84%|████████▍ | 13731/16329 [1:55:35<21:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13731: train loss 1.13685. lr 3.741569e-04:  84%|████████▍ | 13731/16329 [1:55:36<21:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13731: train loss 1.13685. lr 3.741569e-04:  84%|████████▍ | 13732/16329 [1:55:36<21:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13732: train loss 1.18181. lr 3.741289e-04:  84%|████████▍ | 13732/16329 [1:55:36<21:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13732: train loss 1.18181. lr 3.741289e-04:  84%|████████▍ | 13733/16329 [1:55:36<21:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13733: train loss 1.14099. lr 3.741010e-04:  84%|████████▍ | 13733/16329 [1:55:37<21:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13733: train loss 1.14099. lr 3.741010e-04:  84%|████████▍ | 13734/16329 [1:55:37<21:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13734: train loss 1.16114. lr 3.740730e-04:  84%|████████▍ | 13734/16329 [1:55:37<21:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13734: train loss 1.16114. lr 3.740730e-04:  84%|████████▍ | 13735/16329 [1:55:37<21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13735: train loss 1.14931. lr 3.740450e-04:  84%|████████▍ | 13735/16329 [1:55:38<21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13735: train loss 1.14931. lr 3.740450e-04:  84%|████████▍ | 13736/16329 [1:55:38<21:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13736: train loss 1.15568. lr 3.740171e-04:  84%|████████▍ | 13736/16329 [1:55:38<21:25,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13736: train loss 1.15568. lr 3.740171e-04:  84%|████████▍ | 13737/16329 [1:55:38<21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13737: train loss 1.14741. lr 3.739891e-04:  84%|████████▍ | 13737/16329 [1:55:39<21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13737: train loss 1.14741. lr 3.739891e-04:  84%|████████▍ | 13738/16329 [1:55:39<21:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13738: train loss 1.16663. lr 3.739611e-04:  84%|████████▍ | 13738/16329 [1:55:39<21:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13738: train loss 1.16663. lr 3.739611e-04:  84%|████████▍ | 13739/16329 [1:55:39<21:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13739: train loss 1.15033. lr 3.739332e-04:  84%|████████▍ | 13739/16329 [1:55:40<21:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13739: train loss 1.15033. lr 3.739332e-04:  84%|████████▍ | 13740/16329 [1:55:40<21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13740: train loss 1.13438. lr 3.739052e-04:  84%|████████▍ | 13740/16329 [1:55:40<21:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13740: train loss 1.13438. lr 3.739052e-04:  84%|████████▍ | 13741/16329 [1:55:40<21:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13741: train loss 1.13575. lr 3.738772e-04:  84%|████████▍ | 13741/16329 [1:55:41<21:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13741: train loss 1.13575. lr 3.738772e-04:  84%|████████▍ | 13742/16329 [1:55:41<21:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13742: train loss 1.15587. lr 3.738492e-04:  84%|████████▍ | 13742/16329 [1:55:41<21:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13742: train loss 1.15587. lr 3.738492e-04:  84%|████████▍ | 13743/16329 [1:55:41<21:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13743: train loss 1.16623. lr 3.738213e-04:  84%|████████▍ | 13743/16329 [1:55:42<21:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13743: train loss 1.16623. lr 3.738213e-04:  84%|████████▍ | 13744/16329 [1:55:42<21:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13744: train loss 1.20543. lr 3.737933e-04:  84%|████████▍ | 13744/16329 [1:55:42<21:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13744: train loss 1.20543. lr 3.737933e-04:  84%|████████▍ | 13745/16329 [1:55:42<21:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13745: train loss 1.13795. lr 3.737653e-04:  84%|████████▍ | 13745/16329 [1:55:43<21:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13745: train loss 1.13795. lr 3.737653e-04:  84%|████████▍ | 13746/16329 [1:55:43<21:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13746: train loss 1.16163. lr 3.737374e-04:  84%|████████▍ | 13746/16329 [1:55:43<21:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13746: train loss 1.16163. lr 3.737374e-04:  84%|████████▍ | 13747/16329 [1:55:43<21:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13747: train loss 1.16012. lr 3.737094e-04:  84%|████████▍ | 13747/16329 [1:55:44<21:48,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13747: train loss 1.16012. lr 3.737094e-04:  84%|████████▍ | 13748/16329 [1:55:44<22:00,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13748: train loss 1.15743. lr 3.736814e-04:  84%|████████▍ | 13748/16329 [1:55:44<22:00,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13748: train loss 1.15743. lr 3.736814e-04:  84%|████████▍ | 13749/16329 [1:55:44<22:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13749: train loss 1.15215. lr 3.736534e-04:  84%|████████▍ | 13749/16329 [1:55:45<22:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13749: train loss 1.15215. lr 3.736534e-04:  84%|████████▍ | 13750/16329 [1:55:45<22:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13750: train loss 1.13968. lr 3.736254e-04:  84%|████████▍ | 13750/16329 [1:55:46<22:03,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13750: train loss 1.13968. lr 3.736254e-04:  84%|████████▍ | 13751/16329 [1:55:46<24:10,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 13751: train loss 1.15610. lr 3.735975e-04:  84%|████████▍ | 13751/16329 [1:55:46<24:10,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 13751: train loss 1.15610. lr 3.735975e-04:  84%|████████▍ | 13752/16329 [1:55:46<23:22,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 13752: train loss 1.14522. lr 3.735695e-04:  84%|████████▍ | 13752/16329 [1:55:47<23:22,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 13752: train loss 1.14522. lr 3.735695e-04:  84%|████████▍ | 13753/16329 [1:55:47<22:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13753: train loss 1.15141. lr 3.735415e-04:  84%|████████▍ | 13753/16329 [1:55:47<22:46,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13753: train loss 1.15141. lr 3.735415e-04:  84%|████████▍ | 13754/16329 [1:55:47<22:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13754: train loss 1.13548. lr 3.735135e-04:  84%|████████▍ | 13754/16329 [1:55:48<22:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13754: train loss 1.13548. lr 3.735135e-04:  84%|████████▍ | 13755/16329 [1:55:48<22:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13755: train loss 1.15666. lr 3.734855e-04:  84%|████████▍ | 13755/16329 [1:55:48<22:05,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13755: train loss 1.15666. lr 3.734855e-04:  84%|████████▍ | 13756/16329 [1:55:48<21:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13756: train loss 1.15008. lr 3.734576e-04:  84%|████████▍ | 13756/16329 [1:55:49<21:47,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13756: train loss 1.15008. lr 3.734576e-04:  84%|████████▍ | 13757/16329 [1:55:49<21:41,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13757: train loss 1.15997. lr 3.734296e-04:  84%|████████▍ | 13757/16329 [1:55:49<21:41,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13757: train loss 1.15997. lr 3.734296e-04:  84%|████████▍ | 13758/16329 [1:55:49<21:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13758: train loss 1.14218. lr 3.734016e-04:  84%|████████▍ | 13758/16329 [1:55:50<21:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13758: train loss 1.14218. lr 3.734016e-04:  84%|████████▍ | 13759/16329 [1:55:50<21:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13759: train loss 1.14739. lr 3.733736e-04:  84%|████████▍ | 13759/16329 [1:55:50<21:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13759: train loss 1.14739. lr 3.733736e-04:  84%|████████▍ | 13760/16329 [1:55:50<22:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13760: train loss 1.18219. lr 3.733456e-04:  84%|████████▍ | 13760/16329 [1:55:51<22:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13760: train loss 1.18219. lr 3.733456e-04:  84%|████████▍ | 13761/16329 [1:55:51<22:32,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13761: train loss 1.14649. lr 3.733176e-04:  84%|████████▍ | 13761/16329 [1:55:51<22:32,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13761: train loss 1.14649. lr 3.733176e-04:  84%|████████▍ | 13762/16329 [1:55:51<22:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13762: train loss 1.13710. lr 3.732897e-04:  84%|████████▍ | 13762/16329 [1:55:52<22:41,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13762: train loss 1.13710. lr 3.732897e-04:  84%|████████▍ | 13763/16329 [1:55:52<22:36,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13763: train loss 1.14886. lr 3.732617e-04:  84%|████████▍ | 13763/16329 [1:55:52<22:36,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13763: train loss 1.14886. lr 3.732617e-04:  84%|████████▍ | 13764/16329 [1:55:52<22:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13764: train loss 1.15156. lr 3.732337e-04:  84%|████████▍ | 13764/16329 [1:55:53<22:23,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13764: train loss 1.15156. lr 3.732337e-04:  84%|████████▍ | 13765/16329 [1:55:53<22:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13765: train loss 1.17327. lr 3.732057e-04:  84%|████████▍ | 13765/16329 [1:55:53<22:16,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13765: train loss 1.17327. lr 3.732057e-04:  84%|████████▍ | 13766/16329 [1:55:53<22:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13766: train loss 1.15976. lr 3.731777e-04:  84%|████████▍ | 13766/16329 [1:55:54<22:05,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13766: train loss 1.15976. lr 3.731777e-04:  84%|████████▍ | 13767/16329 [1:55:54<21:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13767: train loss 1.17911. lr 3.731497e-04:  84%|████████▍ | 13767/16329 [1:55:54<21:54,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13767: train loss 1.17911. lr 3.731497e-04:  84%|████████▍ | 13768/16329 [1:55:54<21:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13768: train loss 1.15716. lr 3.731217e-04:  84%|████████▍ | 13768/16329 [1:55:55<21:44,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13768: train loss 1.15716. lr 3.731217e-04:  84%|████████▍ | 13769/16329 [1:55:55<21:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13769: train loss 1.16606. lr 3.730937e-04:  84%|████████▍ | 13769/16329 [1:55:55<21:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13769: train loss 1.16606. lr 3.730937e-04:  84%|████████▍ | 13770/16329 [1:55:55<21:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13770: train loss 1.17353. lr 3.730658e-04:  84%|████████▍ | 13770/16329 [1:55:56<21:26,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13770: train loss 1.17353. lr 3.730658e-04:  84%|████████▍ | 13771/16329 [1:55:56<21:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13771: train loss 1.14037. lr 3.730378e-04:  84%|████████▍ | 13771/16329 [1:55:56<21:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13771: train loss 1.14037. lr 3.730378e-04:  84%|████████▍ | 13772/16329 [1:55:56<21:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13772: train loss 1.15188. lr 3.730098e-04:  84%|████████▍ | 13772/16329 [1:55:57<21:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13772: train loss 1.15188. lr 3.730098e-04:  84%|████████▍ | 13773/16329 [1:55:57<21:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13773: train loss 1.15786. lr 3.729818e-04:  84%|████████▍ | 13773/16329 [1:55:57<21:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13773: train loss 1.15786. lr 3.729818e-04:  84%|████████▍ | 13774/16329 [1:55:57<21:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13774: train loss 1.13353. lr 3.729538e-04:  84%|████████▍ | 13774/16329 [1:55:58<21:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13774: train loss 1.13353. lr 3.729538e-04:  84%|████████▍ | 13775/16329 [1:55:58<21:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13775: train loss 1.14319. lr 3.729258e-04:  84%|████████▍ | 13775/16329 [1:55:58<21:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13775: train loss 1.14319. lr 3.729258e-04:  84%|████████▍ | 13776/16329 [1:55:58<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13776: train loss 1.16781. lr 3.728978e-04:  84%|████████▍ | 13776/16329 [1:55:59<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13776: train loss 1.16781. lr 3.728978e-04:  84%|████████▍ | 13777/16329 [1:55:59<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13777: train loss 1.16571. lr 3.728698e-04:  84%|████████▍ | 13777/16329 [1:55:59<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13777: train loss 1.16571. lr 3.728698e-04:  84%|████████▍ | 13778/16329 [1:55:59<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13778: train loss 1.10715. lr 3.728418e-04:  84%|████████▍ | 13778/16329 [1:56:00<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13778: train loss 1.10715. lr 3.728418e-04:  84%|████████▍ | 13779/16329 [1:56:00<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13779: train loss 1.15340. lr 3.728138e-04:  84%|████████▍ | 13779/16329 [1:56:00<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13779: train loss 1.15340. lr 3.728138e-04:  84%|████████▍ | 13780/16329 [1:56:00<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13780: train loss 1.17274. lr 3.727858e-04:  84%|████████▍ | 13780/16329 [1:56:01<21:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13780: train loss 1.17274. lr 3.727858e-04:  84%|████████▍ | 13781/16329 [1:56:01<21:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13781: train loss 1.11441. lr 3.727578e-04:  84%|████████▍ | 13781/16329 [1:56:01<21:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13781: train loss 1.11441. lr 3.727578e-04:  84%|████████▍ | 13782/16329 [1:56:01<21:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13782: train loss 1.14532. lr 3.727298e-04:  84%|████████▍ | 13782/16329 [1:56:02<21:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13782: train loss 1.14532. lr 3.727298e-04:  84%|████████▍ | 13783/16329 [1:56:02<21:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13783: train loss 1.15951. lr 3.727018e-04:  84%|████████▍ | 13783/16329 [1:56:02<21:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13783: train loss 1.15951. lr 3.727018e-04:  84%|████████▍ | 13784/16329 [1:56:02<21:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13784: train loss 1.13526. lr 3.726738e-04:  84%|████████▍ | 13784/16329 [1:56:03<21:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13784: train loss 1.13526. lr 3.726738e-04:  84%|████████▍ | 13785/16329 [1:56:03<21:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13785: train loss 1.19313. lr 3.726458e-04:  84%|████████▍ | 13785/16329 [1:56:03<21:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13785: train loss 1.19313. lr 3.726458e-04:  84%|████████▍ | 13786/16329 [1:56:03<23:20,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13786: train loss 1.16643. lr 3.726178e-04:  84%|████████▍ | 13786/16329 [1:56:04<23:20,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13786: train loss 1.16643. lr 3.726178e-04:  84%|████████▍ | 13787/16329 [1:56:04<22:36,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13787: train loss 1.14150. lr 3.725898e-04:  84%|████████▍ | 13787/16329 [1:56:04<22:36,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13787: train loss 1.14150. lr 3.725898e-04:  84%|████████▍ | 13788/16329 [1:56:04<22:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13788: train loss 1.12679. lr 3.725618e-04:  84%|████████▍ | 13788/16329 [1:56:05<22:09,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13788: train loss 1.12679. lr 3.725618e-04:  84%|████████▍ | 13789/16329 [1:56:05<21:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13789: train loss 1.15557. lr 3.725338e-04:  84%|████████▍ | 13789/16329 [1:56:05<21:48,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13789: train loss 1.15557. lr 3.725338e-04:  84%|████████▍ | 13790/16329 [1:56:05<21:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13790: train loss 1.15247. lr 3.725058e-04:  84%|████████▍ | 13790/16329 [1:56:06<21:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13790: train loss 1.15247. lr 3.725058e-04:  84%|████████▍ | 13791/16329 [1:56:06<21:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13791: train loss 1.13740. lr 3.724778e-04:  84%|████████▍ | 13791/16329 [1:56:06<21:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13791: train loss 1.13740. lr 3.724778e-04:  84%|████████▍ | 13792/16329 [1:56:06<21:18,  1.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13792: train loss 1.17008. lr 3.724498e-04:  84%|████████▍ | 13792/16329 [1:56:07<21:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13792: train loss 1.17008. lr 3.724498e-04:  84%|████████▍ | 13793/16329 [1:56:07<21:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13793: train loss 1.14647. lr 3.724218e-04:  84%|████████▍ | 13793/16329 [1:56:07<21:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13793: train loss 1.14647. lr 3.724218e-04:  84%|████████▍ | 13794/16329 [1:56:07<21:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13794: train loss 1.17077. lr 3.723938e-04:  84%|████████▍ | 13794/16329 [1:56:08<21:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13794: train loss 1.17077. lr 3.723938e-04:  84%|████████▍ | 13795/16329 [1:56:08<21:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13795: train loss 1.15004. lr 3.723658e-04:  84%|████████▍ | 13795/16329 [1:56:08<21:10,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13795: train loss 1.15004. lr 3.723658e-04:  84%|████████▍ | 13796/16329 [1:56:08<21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13796: train loss 1.14198. lr 3.723378e-04:  84%|████████▍ | 13796/16329 [1:56:09<21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13796: train loss 1.14198. lr 3.723378e-04:  84%|████████▍ | 13797/16329 [1:56:09<21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13797: train loss 1.16620. lr 3.723097e-04:  84%|████████▍ | 13797/16329 [1:56:09<21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13797: train loss 1.16620. lr 3.723097e-04:  84%|████████▍ | 13798/16329 [1:56:09<21:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13798: train loss 1.16634. lr 3.722817e-04:  84%|████████▍ | 13798/16329 [1:56:10<21:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13798: train loss 1.16634. lr 3.722817e-04:  85%|████████▍ | 13799/16329 [1:56:10<21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13799: train loss 1.16621. lr 3.722537e-04:  85%|████████▍ | 13799/16329 [1:56:10<21:04,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13799: train loss 1.16621. lr 3.722537e-04:  85%|████████▍ | 13800/16329 [1:56:10<21:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13800: train loss 1.12984. lr 3.722257e-04:  85%|████████▍ | 13800/16329 [1:56:11<21:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13800: train loss 1.12984. lr 3.722257e-04:  85%|████████▍ | 13801/16329 [1:56:11<20:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13801: train loss 1.16053. lr 3.721977e-04:  85%|████████▍ | 13801/16329 [1:56:11<20:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13801: train loss 1.16053. lr 3.721977e-04:  85%|████████▍ | 13802/16329 [1:56:11<20:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13802: train loss 1.14410. lr 3.721697e-04:  85%|████████▍ | 13802/16329 [1:56:12<20:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13802: train loss 1.14410. lr 3.721697e-04:  85%|████████▍ | 13803/16329 [1:56:12<20:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13803: train loss 1.17736. lr 3.721417e-04:  85%|████████▍ | 13803/16329 [1:56:12<20:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13803: train loss 1.17736. lr 3.721417e-04:  85%|████████▍ | 13804/16329 [1:56:12<20:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13804: train loss 1.14662. lr 3.721137e-04:  85%|████████▍ | 13804/16329 [1:56:13<20:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13804: train loss 1.14662. lr 3.721137e-04:  85%|████████▍ | 13805/16329 [1:56:13<21:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13805: train loss 1.14787. lr 3.720856e-04:  85%|████████▍ | 13805/16329 [1:56:13<21:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13805: train loss 1.14787. lr 3.720856e-04:  85%|████████▍ | 13806/16329 [1:56:13<21:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13806: train loss 1.16072. lr 3.720576e-04:  85%|████████▍ | 13806/16329 [1:56:14<21:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13806: train loss 1.16072. lr 3.720576e-04:  85%|████████▍ | 13807/16329 [1:56:14<20:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13807: train loss 1.16357. lr 3.720296e-04:  85%|████████▍ | 13807/16329 [1:56:14<20:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13807: train loss 1.16357. lr 3.720296e-04:  85%|████████▍ | 13808/16329 [1:56:14<20:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13808: train loss 1.13797. lr 3.720016e-04:  85%|████████▍ | 13808/16329 [1:56:15<20:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13808: train loss 1.13797. lr 3.720016e-04:  85%|████████▍ | 13809/16329 [1:56:15<20:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13809: train loss 1.17216. lr 3.719736e-04:  85%|████████▍ | 13809/16329 [1:56:15<20:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13809: train loss 1.17216. lr 3.719736e-04:  85%|████████▍ | 13810/16329 [1:56:15<20:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13810: train loss 1.14877. lr 3.719456e-04:  85%|████████▍ | 13810/16329 [1:56:16<20:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13810: train loss 1.14877. lr 3.719456e-04:  85%|████████▍ | 13811/16329 [1:56:16<23:04,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13811: train loss 1.16083. lr 3.719175e-04:  85%|████████▍ | 13811/16329 [1:56:16<23:04,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13811: train loss 1.16083. lr 3.719175e-04:  85%|████████▍ | 13812/16329 [1:56:16<22:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13812: train loss 1.13890. lr 3.718895e-04:  85%|████████▍ | 13812/16329 [1:56:17<22:21,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 13812: train loss 1.13890. lr 3.718895e-04:  85%|████████▍ | 13813/16329 [1:56:17<21:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13813: train loss 1.14054. lr 3.718615e-04:  85%|████████▍ | 13813/16329 [1:56:17<21:53,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13813: train loss 1.14054. lr 3.718615e-04:  85%|████████▍ | 13814/16329 [1:56:17<21:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13814: train loss 1.09172. lr 3.718335e-04:  85%|████████▍ | 13814/16329 [1:56:18<21:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13814: train loss 1.09172. lr 3.718335e-04:  85%|████████▍ | 13815/16329 [1:56:18<21:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13815: train loss 1.17066. lr 3.718055e-04:  85%|████████▍ | 13815/16329 [1:56:18<21:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13815: train loss 1.17066. lr 3.718055e-04:  85%|████████▍ | 13816/16329 [1:56:18<21:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13816: train loss 1.16658. lr 3.717774e-04:  85%|████████▍ | 13816/16329 [1:56:19<21:10,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13816: train loss 1.16658. lr 3.717774e-04:  85%|████████▍ | 13817/16329 [1:56:19<21:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13817: train loss 1.14717. lr 3.717494e-04:  85%|████████▍ | 13817/16329 [1:56:19<21:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13817: train loss 1.14717. lr 3.717494e-04:  85%|████████▍ | 13818/16329 [1:56:19<21:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13818: train loss 1.17120. lr 3.717214e-04:  85%|████████▍ | 13818/16329 [1:56:20<21:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13818: train loss 1.17120. lr 3.717214e-04:  85%|████████▍ | 13819/16329 [1:56:20<20:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13819: train loss 1.14976. lr 3.716934e-04:  85%|████████▍ | 13819/16329 [1:56:20<20:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13819: train loss 1.14976. lr 3.716934e-04:  85%|████████▍ | 13820/16329 [1:56:20<20:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13820: train loss 1.14111. lr 3.716654e-04:  85%|████████▍ | 13820/16329 [1:56:21<20:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13820: train loss 1.14111. lr 3.716654e-04:  85%|████████▍ | 13821/16329 [1:56:21<20:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13821: train loss 1.16754. lr 3.716373e-04:  85%|████████▍ | 13821/16329 [1:56:21<20:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13821: train loss 1.16754. lr 3.716373e-04:  85%|████████▍ | 13822/16329 [1:56:21<20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13822: train loss 1.16185. lr 3.716093e-04:  85%|████████▍ | 13822/16329 [1:56:22<20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13822: train loss 1.16185. lr 3.716093e-04:  85%|████████▍ | 13823/16329 [1:56:22<20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13823: train loss 1.19282. lr 3.715813e-04:  85%|████████▍ | 13823/16329 [1:56:22<20:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13823: train loss 1.19282. lr 3.715813e-04:  85%|████████▍ | 13824/16329 [1:56:22<20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13824: train loss 1.15797. lr 3.715532e-04:  85%|████████▍ | 13824/16329 [1:56:23<20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13824: train loss 1.15797. lr 3.715532e-04:  85%|████████▍ | 13825/16329 [1:56:23<20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13825: train loss 1.15247. lr 3.715252e-04:  85%|████████▍ | 13825/16329 [1:56:23<20:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13825: train loss 1.15247. lr 3.715252e-04:  85%|████████▍ | 13826/16329 [1:56:23<20:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13826: train loss 1.13108. lr 3.714972e-04:  85%|████████▍ | 13826/16329 [1:56:24<20:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13826: train loss 1.13108. lr 3.714972e-04:  85%|████████▍ | 13827/16329 [1:56:24<20:40,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13827: train loss 1.12824. lr 3.714692e-04:  85%|████████▍ | 13827/16329 [1:56:24<20:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13827: train loss 1.12824. lr 3.714692e-04:  85%|████████▍ | 13828/16329 [1:56:24<20:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13828: train loss 1.11791. lr 3.714411e-04:  85%|████████▍ | 13828/16329 [1:56:25<20:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13828: train loss 1.11791. lr 3.714411e-04:  85%|████████▍ | 13829/16329 [1:56:25<20:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13829: train loss 1.15968. lr 3.714131e-04:  85%|████████▍ | 13829/16329 [1:56:25<20:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13829: train loss 1.15968. lr 3.714131e-04:  85%|████████▍ | 13830/16329 [1:56:25<20:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13830: train loss 1.14341. lr 3.713851e-04:  85%|████████▍ | 13830/16329 [1:56:26<20:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13830: train loss 1.14341. lr 3.713851e-04:  85%|████████▍ | 13831/16329 [1:56:26<20:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13831: train loss 1.15135. lr 3.713570e-04:  85%|████████▍ | 13831/16329 [1:56:26<20:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13831: train loss 1.15135. lr 3.713570e-04:  85%|████████▍ | 13832/16329 [1:56:26<20:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13832: train loss 1.12853. lr 3.713290e-04:  85%|████████▍ | 13832/16329 [1:56:27<20:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13832: train loss 1.12853. lr 3.713290e-04:  85%|████████▍ | 13833/16329 [1:56:27<20:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13833: train loss 1.15024. lr 3.713010e-04:  85%|████████▍ | 13833/16329 [1:56:27<20:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13833: train loss 1.15024. lr 3.713010e-04:  85%|████████▍ | 13834/16329 [1:56:27<20:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13834: train loss 1.12939. lr 3.712729e-04:  85%|████████▍ | 13834/16329 [1:56:28<20:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13834: train loss 1.12939. lr 3.712729e-04:  85%|████████▍ | 13835/16329 [1:56:28<20:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13835: train loss 1.14050. lr 3.712449e-04:  85%|████████▍ | 13835/16329 [1:56:28<20:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13835: train loss 1.14050. lr 3.712449e-04:  85%|████████▍ | 13836/16329 [1:56:28<20:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13836: train loss 1.15733. lr 3.712169e-04:  85%|████████▍ | 13836/16329 [1:56:29<20:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13836: train loss 1.15733. lr 3.712169e-04:  85%|████████▍ | 13837/16329 [1:56:29<20:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13837: train loss 1.14292. lr 3.711888e-04:  85%|████████▍ | 13837/16329 [1:56:30<20:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13837: train loss 1.14292. lr 3.711888e-04:  85%|████████▍ | 13838/16329 [1:56:30<22:58,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13838: train loss 1.16307. lr 3.711608e-04:  85%|████████▍ | 13838/16329 [1:56:30<22:58,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13838: train loss 1.16307. lr 3.711608e-04:  85%|████████▍ | 13839/16329 [1:56:30<22:19,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13839: train loss 1.16552. lr 3.711328e-04:  85%|████████▍ | 13839/16329 [1:56:31<22:19,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13839: train loss 1.16552. lr 3.711328e-04:  85%|████████▍ | 13840/16329 [1:56:31<21:46,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13840: train loss 1.14843. lr 3.711047e-04:  85%|████████▍ | 13840/16329 [1:56:31<21:46,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13840: train loss 1.14843. lr 3.711047e-04:  85%|████████▍ | 13841/16329 [1:56:31<21:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13841: train loss 1.16231. lr 3.710767e-04:  85%|████████▍ | 13841/16329 [1:56:32<21:24,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13841: train loss 1.16231. lr 3.710767e-04:  85%|████████▍ | 13842/16329 [1:56:32<21:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13842: train loss 1.12592. lr 3.710486e-04:  85%|████████▍ | 13842/16329 [1:56:32<21:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13842: train loss 1.12592. lr 3.710486e-04:  85%|████████▍ | 13843/16329 [1:56:32<20:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13843: train loss 1.11303. lr 3.710206e-04:  85%|████████▍ | 13843/16329 [1:56:33<20:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13843: train loss 1.11303. lr 3.710206e-04:  85%|████████▍ | 13844/16329 [1:56:33<20:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13844: train loss 1.14023. lr 3.709926e-04:  85%|████████▍ | 13844/16329 [1:56:33<20:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13844: train loss 1.14023. lr 3.709926e-04:  85%|████████▍ | 13845/16329 [1:56:33<20:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13845: train loss 1.15463. lr 3.709645e-04:  85%|████████▍ | 13845/16329 [1:56:34<20:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13845: train loss 1.15463. lr 3.709645e-04:  85%|████████▍ | 13846/16329 [1:56:34<20:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13846: train loss 1.14007. lr 3.709365e-04:  85%|████████▍ | 13846/16329 [1:56:34<20:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13846: train loss 1.14007. lr 3.709365e-04:  85%|████████▍ | 13847/16329 [1:56:34<20:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13847: train loss 1.16688. lr 3.709084e-04:  85%|████████▍ | 13847/16329 [1:56:35<20:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13847: train loss 1.16688. lr 3.709084e-04:  85%|████████▍ | 13848/16329 [1:56:35<20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13848: train loss 1.14001. lr 3.708804e-04:  85%|████████▍ | 13848/16329 [1:56:35<20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13848: train loss 1.14001. lr 3.708804e-04:  85%|████████▍ | 13849/16329 [1:56:35<20:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13849: train loss 1.12114. lr 3.708524e-04:  85%|████████▍ | 13849/16329 [1:56:36<20:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13849: train loss 1.12114. lr 3.708524e-04:  85%|████████▍ | 13850/16329 [1:56:36<20:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13850: train loss 1.15209. lr 3.708243e-04:  85%|████████▍ | 13850/16329 [1:56:36<20:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13850: train loss 1.15209. lr 3.708243e-04:  85%|████████▍ | 13851/16329 [1:56:36<20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13851: train loss 1.15186. lr 3.707963e-04:  85%|████████▍ | 13851/16329 [1:56:37<20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13851: train loss 1.15186. lr 3.707963e-04:  85%|████████▍ | 13852/16329 [1:56:37<20:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13852: train loss 1.13830. lr 3.707682e-04:  85%|████████▍ | 13852/16329 [1:56:37<20:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13852: train loss 1.13830. lr 3.707682e-04:  85%|████████▍ | 13853/16329 [1:56:37<20:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13853: train loss 1.13911. lr 3.707402e-04:  85%|████████▍ | 13853/16329 [1:56:38<20:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13853: train loss 1.13911. lr 3.707402e-04:  85%|████████▍ | 13854/16329 [1:56:38<20:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13854: train loss 1.14718. lr 3.707121e-04:  85%|████████▍ | 13854/16329 [1:56:38<20:35,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13854: train loss 1.14718. lr 3.707121e-04:  85%|████████▍ | 13855/16329 [1:56:38<20:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13855: train loss 1.15589. lr 3.706841e-04:  85%|████████▍ | 13855/16329 [1:56:39<20:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13855: train loss 1.15589. lr 3.706841e-04:  85%|████████▍ | 13856/16329 [1:56:39<20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13856: train loss 1.14604. lr 3.706560e-04:  85%|████████▍ | 13856/16329 [1:56:39<20:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13856: train loss 1.14604. lr 3.706560e-04:  85%|████████▍ | 13857/16329 [1:56:39<20:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13857: train loss 1.15910. lr 3.706280e-04:  85%|████████▍ | 13857/16329 [1:56:40<20:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13857: train loss 1.15910. lr 3.706280e-04:  85%|████████▍ | 13858/16329 [1:56:40<20:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13858: train loss 1.13678. lr 3.705999e-04:  85%|████████▍ | 13858/16329 [1:56:40<20:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13858: train loss 1.13678. lr 3.705999e-04:  85%|████████▍ | 13859/16329 [1:56:40<20:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13859: train loss 1.16636. lr 3.705719e-04:  85%|████████▍ | 13859/16329 [1:56:41<20:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13859: train loss 1.16636. lr 3.705719e-04:  85%|████████▍ | 13860/16329 [1:56:41<20:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13860: train loss 1.10146. lr 3.705438e-04:  85%|████████▍ | 13860/16329 [1:56:41<20:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13860: train loss 1.10146. lr 3.705438e-04:  85%|████████▍ | 13861/16329 [1:56:41<20:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13861: train loss 1.16371. lr 3.705158e-04:  85%|████████▍ | 13861/16329 [1:56:42<20:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13861: train loss 1.16371. lr 3.705158e-04:  85%|████████▍ | 13862/16329 [1:56:42<20:24,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13862: train loss 1.13737. lr 3.704877e-04:  85%|████████▍ | 13862/16329 [1:56:42<20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13862: train loss 1.13737. lr 3.704877e-04:  85%|████████▍ | 13863/16329 [1:56:42<20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13863: train loss 1.14184. lr 3.704597e-04:  85%|████████▍ | 13863/16329 [1:56:43<20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13863: train loss 1.14184. lr 3.704597e-04:  85%|████████▍ | 13864/16329 [1:56:43<20:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13864: train loss 1.13129. lr 3.704316e-04:  85%|████████▍ | 13864/16329 [1:56:43<20:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13864: train loss 1.13129. lr 3.704316e-04:  85%|████████▍ | 13865/16329 [1:56:43<20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13865: train loss 1.17329. lr 3.704036e-04:  85%|████████▍ | 13865/16329 [1:56:44<20:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13865: train loss 1.17329. lr 3.704036e-04:  85%|████████▍ | 13866/16329 [1:56:44<20:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13866: train loss 1.13549. lr 3.703755e-04:  85%|████████▍ | 13866/16329 [1:56:44<20:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13866: train loss 1.13549. lr 3.703755e-04:  85%|████████▍ | 13867/16329 [1:56:44<20:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13867: train loss 1.13612. lr 3.703475e-04:  85%|████████▍ | 13867/16329 [1:56:44<20:20,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13867: train loss 1.13612. lr 3.703475e-04:  85%|████████▍ | 13868/16329 [1:56:45<20:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13868: train loss 1.16447. lr 3.703194e-04:  85%|████████▍ | 13868/16329 [1:56:45<20:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13868: train loss 1.16447. lr 3.703194e-04:  85%|████████▍ | 13869/16329 [1:56:45<20:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13869: train loss 1.14733. lr 3.702913e-04:  85%|████████▍ | 13869/16329 [1:56:45<20:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13869: train loss 1.14733. lr 3.702913e-04:  85%|████████▍ | 13870/16329 [1:56:45<20:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13870: train loss 1.16803. lr 3.702633e-04:  85%|████████▍ | 13870/16329 [1:56:46<20:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13870: train loss 1.16803. lr 3.702633e-04:  85%|████████▍ | 13871/16329 [1:56:46<20:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13871: train loss 1.14044. lr 3.702352e-04:  85%|████████▍ | 13871/16329 [1:56:47<20:58,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13871: train loss 1.14044. lr 3.702352e-04:  85%|████████▍ | 13872/16329 [1:56:47<21:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13872: train loss 1.13762. lr 3.702072e-04:  85%|████████▍ | 13872/16329 [1:56:47<21:09,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13872: train loss 1.13762. lr 3.702072e-04:  85%|████████▍ | 13873/16329 [1:56:47<21:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13873: train loss 1.14334. lr 3.701791e-04:  85%|████████▍ | 13873/16329 [1:56:48<21:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13873: train loss 1.14334. lr 3.701791e-04:  85%|████████▍ | 13874/16329 [1:56:48<21:06,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13874: train loss 1.14276. lr 3.701511e-04:  85%|████████▍ | 13874/16329 [1:56:48<21:06,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13874: train loss 1.14276. lr 3.701511e-04:  85%|████████▍ | 13875/16329 [1:56:48<20:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13875: train loss 1.14060. lr 3.701230e-04:  85%|████████▍ | 13875/16329 [1:56:49<20:59,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13875: train loss 1.14060. lr 3.701230e-04:  85%|████████▍ | 13876/16329 [1:56:49<20:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13876: train loss 1.10626. lr 3.700949e-04:  85%|████████▍ | 13876/16329 [1:56:49<20:53,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13876: train loss 1.10626. lr 3.700949e-04:  85%|████████▍ | 13877/16329 [1:56:49<20:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13877: train loss 1.17063. lr 3.700669e-04:  85%|████████▍ | 13877/16329 [1:56:50<20:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13877: train loss 1.17063. lr 3.700669e-04:  85%|████████▍ | 13878/16329 [1:56:50<22:45,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13878: train loss 1.12850. lr 3.700388e-04:  85%|████████▍ | 13878/16329 [1:56:50<22:45,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 13878: train loss 1.12850. lr 3.700388e-04:  85%|████████▍ | 13879/16329 [1:56:50<21:58,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13879: train loss 1.16680. lr 3.700107e-04:  85%|████████▍ | 13879/16329 [1:56:51<21:58,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13879: train loss 1.16680. lr 3.700107e-04:  85%|████████▌ | 13880/16329 [1:56:51<21:28,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13880: train loss 1.12669. lr 3.699827e-04:  85%|████████▌ | 13880/16329 [1:56:51<21:28,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13880: train loss 1.12669. lr 3.699827e-04:  85%|████████▌ | 13881/16329 [1:56:51<21:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13881: train loss 1.13559. lr 3.699546e-04:  85%|████████▌ | 13881/16329 [1:56:52<21:09,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13881: train loss 1.13559. lr 3.699546e-04:  85%|████████▌ | 13882/16329 [1:56:52<20:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13882: train loss 1.15052. lr 3.699266e-04:  85%|████████▌ | 13882/16329 [1:56:52<20:49,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13882: train loss 1.15052. lr 3.699266e-04:  85%|████████▌ | 13883/16329 [1:56:52<21:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13883: train loss 1.15857. lr 3.698985e-04:  85%|████████▌ | 13883/16329 [1:56:53<21:06,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13883: train loss 1.15857. lr 3.698985e-04:  85%|████████▌ | 13884/16329 [1:56:53<21:21,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13884: train loss 1.14396. lr 3.698704e-04:  85%|████████▌ | 13884/16329 [1:56:53<21:21,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13884: train loss 1.14396. lr 3.698704e-04:  85%|████████▌ | 13885/16329 [1:56:53<21:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13885: train loss 1.12739. lr 3.698424e-04:  85%|████████▌ | 13885/16329 [1:56:54<21:24,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13885: train loss 1.12739. lr 3.698424e-04:  85%|████████▌ | 13886/16329 [1:56:54<21:17,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13886: train loss 1.14364. lr 3.698143e-04:  85%|████████▌ | 13886/16329 [1:56:54<21:17,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13886: train loss 1.14364. lr 3.698143e-04:  85%|████████▌ | 13887/16329 [1:56:54<21:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13887: train loss 1.12240. lr 3.697862e-04:  85%|████████▌ | 13887/16329 [1:56:55<21:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 13887: train loss 1.12240. lr 3.697862e-04:  85%|████████▌ | 13888/16329 [1:56:55<21:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13888: train loss 1.14922. lr 3.697582e-04:  85%|████████▌ | 13888/16329 [1:56:55<21:02,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13888: train loss 1.14922. lr 3.697582e-04:  85%|████████▌ | 13889/16329 [1:56:55<20:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13889: train loss 1.14943. lr 3.697301e-04:  85%|████████▌ | 13889/16329 [1:56:56<20:54,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13889: train loss 1.14943. lr 3.697301e-04:  85%|████████▌ | 13890/16329 [1:56:56<20:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13890: train loss 1.12935. lr 3.697020e-04:  85%|████████▌ | 13890/16329 [1:56:56<20:48,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 13890: train loss 1.12935. lr 3.697020e-04:  85%|████████▌ | 13891/16329 [1:56:56<20:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13891: train loss 1.14727. lr 3.696739e-04:  85%|████████▌ | 13891/16329 [1:56:57<20:41,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13891: train loss 1.14727. lr 3.696739e-04:  85%|████████▌ | 13892/16329 [1:56:57<20:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13892: train loss 1.12518. lr 3.696459e-04:  85%|████████▌ | 13892/16329 [1:56:57<20:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13892: train loss 1.12518. lr 3.696459e-04:  85%|████████▌ | 13893/16329 [1:56:57<20:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13893: train loss 1.15142. lr 3.696178e-04:  85%|████████▌ | 13893/16329 [1:56:58<20:28,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13893: train loss 1.15142. lr 3.696178e-04:  85%|████████▌ | 13894/16329 [1:56:58<20:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13894: train loss 1.16708. lr 3.695897e-04:  85%|████████▌ | 13894/16329 [1:56:58<20:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13894: train loss 1.16708. lr 3.695897e-04:  85%|████████▌ | 13895/16329 [1:56:58<20:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13895: train loss 1.17454. lr 3.695617e-04:  85%|████████▌ | 13895/16329 [1:56:59<20:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13895: train loss 1.17454. lr 3.695617e-04:  85%|████████▌ | 13896/16329 [1:56:59<20:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13896: train loss 1.10931. lr 3.695336e-04:  85%|████████▌ | 13896/16329 [1:56:59<20:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13896: train loss 1.10931. lr 3.695336e-04:  85%|████████▌ | 13897/16329 [1:56:59<20:14,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13897: train loss 1.16462. lr 3.695055e-04:  85%|████████▌ | 13897/16329 [1:57:00<20:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13897: train loss 1.16462. lr 3.695055e-04:  85%|████████▌ | 13898/16329 [1:57:00<20:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13898: train loss 1.13630. lr 3.694774e-04:  85%|████████▌ | 13898/16329 [1:57:00<20:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13898: train loss 1.13630. lr 3.694774e-04:  85%|████████▌ | 13899/16329 [1:57:00<20:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13899: train loss 1.16365. lr 3.694493e-04:  85%|████████▌ | 13899/16329 [1:57:01<20:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13899: train loss 1.16365. lr 3.694493e-04:  85%|████████▌ | 13900/16329 [1:57:01<20:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13900: train loss 1.15679. lr 3.694213e-04:  85%|████████▌ | 13900/16329 [1:57:01<20:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13900: train loss 1.15679. lr 3.694213e-04:  85%|████████▌ | 13901/16329 [1:57:01<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13901: train loss 1.17233. lr 3.693932e-04:  85%|████████▌ | 13901/16329 [1:57:02<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13901: train loss 1.17233. lr 3.693932e-04:  85%|████████▌ | 13902/16329 [1:57:02<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13902: train loss 1.16661. lr 3.693651e-04:  85%|████████▌ | 13902/16329 [1:57:02<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13902: train loss 1.16661. lr 3.693651e-04:  85%|████████▌ | 13903/16329 [1:57:02<20:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13903: train loss 1.14206. lr 3.693370e-04:  85%|████████▌ | 13903/16329 [1:57:03<20:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13903: train loss 1.14206. lr 3.693370e-04:  85%|████████▌ | 13904/16329 [1:57:03<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13904: train loss 1.16079. lr 3.693090e-04:  85%|████████▌ | 13904/16329 [1:57:03<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13904: train loss 1.16079. lr 3.693090e-04:  85%|████████▌ | 13905/16329 [1:57:03<20:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13905: train loss 1.13301. lr 3.692809e-04:  85%|████████▌ | 13905/16329 [1:57:04<20:02,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13905: train loss 1.13301. lr 3.692809e-04:  85%|████████▌ | 13906/16329 [1:57:04<20:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13906: train loss 1.17007. lr 3.692528e-04:  85%|████████▌ | 13906/16329 [1:57:04<20:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13906: train loss 1.17007. lr 3.692528e-04:  85%|████████▌ | 13907/16329 [1:57:04<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13907: train loss 1.16517. lr 3.692247e-04:  85%|████████▌ | 13907/16329 [1:57:05<20:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13907: train loss 1.16517. lr 3.692247e-04:  85%|████████▌ | 13908/16329 [1:57:05<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13908: train loss 1.15049. lr 3.691966e-04:  85%|████████▌ | 13908/16329 [1:57:05<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13908: train loss 1.15049. lr 3.691966e-04:  85%|████████▌ | 13909/16329 [1:57:05<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13909: train loss 1.14493. lr 3.691686e-04:  85%|████████▌ | 13909/16329 [1:57:06<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13909: train loss 1.14493. lr 3.691686e-04:  85%|████████▌ | 13910/16329 [1:57:06<19:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13910: train loss 1.17041. lr 3.691405e-04:  85%|████████▌ | 13910/16329 [1:57:06<19:59,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13910: train loss 1.17041. lr 3.691405e-04:  85%|████████▌ | 13911/16329 [1:57:06<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13911: train loss 1.13761. lr 3.691124e-04:  85%|████████▌ | 13911/16329 [1:57:07<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13911: train loss 1.13761. lr 3.691124e-04:  85%|████████▌ | 13912/16329 [1:57:07<19:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13912: train loss 1.14978. lr 3.690843e-04:  85%|████████▌ | 13912/16329 [1:57:08<19:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13912: train loss 1.14978. lr 3.690843e-04:  85%|████████▌ | 13913/16329 [1:57:08<22:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13913: train loss 1.13602. lr 3.690562e-04:  85%|████████▌ | 13913/16329 [1:57:08<22:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 13913: train loss 1.13602. lr 3.690562e-04:  85%|████████▌ | 13914/16329 [1:57:08<21:31,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13914: train loss 1.15740. lr 3.690281e-04:  85%|████████▌ | 13914/16329 [1:57:09<21:31,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 13914: train loss 1.15740. lr 3.690281e-04:  85%|████████▌ | 13915/16329 [1:57:09<21:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13915: train loss 1.14332. lr 3.690000e-04:  85%|████████▌ | 13915/16329 [1:57:09<21:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 13915: train loss 1.14332. lr 3.690000e-04:  85%|████████▌ | 13916/16329 [1:57:09<20:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13916: train loss 1.15944. lr 3.689720e-04:  85%|████████▌ | 13916/16329 [1:57:10<20:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13916: train loss 1.15944. lr 3.689720e-04:  85%|████████▌ | 13917/16329 [1:57:10<20:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13917: train loss 1.13617. lr 3.689439e-04:  85%|████████▌ | 13917/16329 [1:57:10<20:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13917: train loss 1.13617. lr 3.689439e-04:  85%|████████▌ | 13918/16329 [1:57:10<20:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13918: train loss 1.15685. lr 3.689158e-04:  85%|████████▌ | 13918/16329 [1:57:11<20:18,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13918: train loss 1.15685. lr 3.689158e-04:  85%|████████▌ | 13919/16329 [1:57:11<20:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13919: train loss 1.14749. lr 3.688877e-04:  85%|████████▌ | 13919/16329 [1:57:11<20:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13919: train loss 1.14749. lr 3.688877e-04:  85%|████████▌ | 13920/16329 [1:57:11<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13920: train loss 1.10504. lr 3.688596e-04:  85%|████████▌ | 13920/16329 [1:57:12<20:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13920: train loss 1.10504. lr 3.688596e-04:  85%|████████▌ | 13921/16329 [1:57:12<20:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13921: train loss 1.16169. lr 3.688315e-04:  85%|████████▌ | 13921/16329 [1:57:12<20:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13921: train loss 1.16169. lr 3.688315e-04:  85%|████████▌ | 13922/16329 [1:57:12<20:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13922: train loss 1.14718. lr 3.688034e-04:  85%|████████▌ | 13922/16329 [1:57:13<20:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13922: train loss 1.14718. lr 3.688034e-04:  85%|████████▌ | 13923/16329 [1:57:13<20:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13923: train loss 1.17954. lr 3.687753e-04:  85%|████████▌ | 13923/16329 [1:57:13<20:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13923: train loss 1.17954. lr 3.687753e-04:  85%|████████▌ | 13924/16329 [1:57:13<19:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13924: train loss 1.14724. lr 3.687472e-04:  85%|████████▌ | 13924/16329 [1:57:13<19:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13924: train loss 1.14724. lr 3.687472e-04:  85%|████████▌ | 13925/16329 [1:57:13<19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13925: train loss 1.12890. lr 3.687191e-04:  85%|████████▌ | 13925/16329 [1:57:14<19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13925: train loss 1.12890. lr 3.687191e-04:  85%|████████▌ | 13926/16329 [1:57:14<19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13926: train loss 1.16122. lr 3.686911e-04:  85%|████████▌ | 13926/16329 [1:57:14<19:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13926: train loss 1.16122. lr 3.686911e-04:  85%|████████▌ | 13927/16329 [1:57:14<19:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13927: train loss 1.15171. lr 3.686630e-04:  85%|████████▌ | 13927/16329 [1:57:15<19:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13927: train loss 1.15171. lr 3.686630e-04:  85%|████████▌ | 13928/16329 [1:57:15<19:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13928: train loss 1.12586. lr 3.686349e-04:  85%|████████▌ | 13928/16329 [1:57:15<19:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13928: train loss 1.12586. lr 3.686349e-04:  85%|████████▌ | 13929/16329 [1:57:15<19:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13929: train loss 1.13408. lr 3.686068e-04:  85%|████████▌ | 13929/16329 [1:57:16<19:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13929: train loss 1.13408. lr 3.686068e-04:  85%|████████▌ | 13930/16329 [1:57:16<19:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13930: train loss 1.15195. lr 3.685787e-04:  85%|████████▌ | 13930/16329 [1:57:16<19:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13930: train loss 1.15195. lr 3.685787e-04:  85%|████████▌ | 13931/16329 [1:57:16<19:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13931: train loss 1.15128. lr 3.685506e-04:  85%|████████▌ | 13931/16329 [1:57:17<19:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13931: train loss 1.15128. lr 3.685506e-04:  85%|████████▌ | 13932/16329 [1:57:17<19:47,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13932: train loss 1.13244. lr 3.685225e-04:  85%|████████▌ | 13932/16329 [1:57:17<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13932: train loss 1.13244. lr 3.685225e-04:  85%|████████▌ | 13933/16329 [1:57:17<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13933: train loss 1.14526. lr 3.684944e-04:  85%|████████▌ | 13933/16329 [1:57:18<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13933: train loss 1.14526. lr 3.684944e-04:  85%|████████▌ | 13934/16329 [1:57:18<19:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13934: train loss 1.12838. lr 3.684663e-04:  85%|████████▌ | 13934/16329 [1:57:18<19:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13934: train loss 1.12838. lr 3.684663e-04:  85%|████████▌ | 13935/16329 [1:57:18<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13935: train loss 1.13138. lr 3.684382e-04:  85%|████████▌ | 13935/16329 [1:57:19<19:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13935: train loss 1.13138. lr 3.684382e-04:  85%|████████▌ | 13936/16329 [1:57:19<19:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13936: train loss 1.13853. lr 3.684101e-04:  85%|████████▌ | 13936/16329 [1:57:19<19:48,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13936: train loss 1.13853. lr 3.684101e-04:  85%|████████▌ | 13937/16329 [1:57:19<19:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13937: train loss 1.15439. lr 3.683820e-04:  85%|████████▌ | 13937/16329 [1:57:20<19:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13937: train loss 1.15439. lr 3.683820e-04:  85%|████████▌ | 13938/16329 [1:57:20<22:24,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 13938: train loss 1.12323. lr 3.683539e-04:  85%|████████▌ | 13938/16329 [1:57:21<22:24,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 13938: train loss 1.12323. lr 3.683539e-04:  85%|████████▌ | 13939/16329 [1:57:21<21:32,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13939: train loss 1.16304. lr 3.683258e-04:  85%|████████▌ | 13939/16329 [1:57:21<21:32,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 13939: train loss 1.16304. lr 3.683258e-04:  85%|████████▌ | 13940/16329 [1:57:21<21:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13940: train loss 1.11006. lr 3.682977e-04:  85%|████████▌ | 13940/16329 [1:57:22<21:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 13940: train loss 1.11006. lr 3.682977e-04:  85%|████████▌ | 13941/16329 [1:57:22<20:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13941: train loss 1.17092. lr 3.682696e-04:  85%|████████▌ | 13941/16329 [1:57:22<20:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 13941: train loss 1.17092. lr 3.682696e-04:  85%|████████▌ | 13942/16329 [1:57:22<20:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13942: train loss 1.14032. lr 3.682415e-04:  85%|████████▌ | 13942/16329 [1:57:23<20:20,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13942: train loss 1.14032. lr 3.682415e-04:  85%|████████▌ | 13943/16329 [1:57:23<20:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13943: train loss 1.16431. lr 3.682134e-04:  85%|████████▌ | 13943/16329 [1:57:23<20:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 13943: train loss 1.16431. lr 3.682134e-04:  85%|████████▌ | 13944/16329 [1:57:23<20:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13944: train loss 1.13049. lr 3.681853e-04:  85%|████████▌ | 13944/16329 [1:57:24<20:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13944: train loss 1.13049. lr 3.681853e-04:  85%|████████▌ | 13945/16329 [1:57:24<19:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13945: train loss 1.13851. lr 3.681572e-04:  85%|████████▌ | 13945/16329 [1:57:24<19:58,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13945: train loss 1.13851. lr 3.681572e-04:  85%|████████▌ | 13946/16329 [1:57:24<19:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13946: train loss 1.11488. lr 3.681291e-04:  85%|████████▌ | 13946/16329 [1:57:25<19:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13946: train loss 1.11488. lr 3.681291e-04:  85%|████████▌ | 13947/16329 [1:57:25<19:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13947: train loss 1.13922. lr 3.681010e-04:  85%|████████▌ | 13947/16329 [1:57:25<19:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13947: train loss 1.13922. lr 3.681010e-04:  85%|████████▌ | 13948/16329 [1:57:25<19:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13948: train loss 1.10738. lr 3.680728e-04:  85%|████████▌ | 13948/16329 [1:57:26<19:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13948: train loss 1.10738. lr 3.680728e-04:  85%|████████▌ | 13949/16329 [1:57:26<19:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13949: train loss 1.11482. lr 3.680447e-04:  85%|████████▌ | 13949/16329 [1:57:26<19:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13949: train loss 1.11482. lr 3.680447e-04:  85%|████████▌ | 13950/16329 [1:57:26<19:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13950: train loss 1.14302. lr 3.680166e-04:  85%|████████▌ | 13950/16329 [1:57:27<19:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13950: train loss 1.14302. lr 3.680166e-04:  85%|████████▌ | 13951/16329 [1:57:27<19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13951: train loss 1.13278. lr 3.679885e-04:  85%|████████▌ | 13951/16329 [1:57:27<19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13951: train loss 1.13278. lr 3.679885e-04:  85%|████████▌ | 13952/16329 [1:57:27<19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13952: train loss 1.13509. lr 3.679604e-04:  85%|████████▌ | 13952/16329 [1:57:28<19:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13952: train loss 1.13509. lr 3.679604e-04:  85%|████████▌ | 13953/16329 [1:57:28<19:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13953: train loss 1.14427. lr 3.679323e-04:  85%|████████▌ | 13953/16329 [1:57:28<19:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13953: train loss 1.14427. lr 3.679323e-04:  85%|████████▌ | 13954/16329 [1:57:28<19:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13954: train loss 1.16407. lr 3.679042e-04:  85%|████████▌ | 13954/16329 [1:57:29<19:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13954: train loss 1.16407. lr 3.679042e-04:  85%|████████▌ | 13955/16329 [1:57:29<19:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13955: train loss 1.18377. lr 3.678761e-04:  85%|████████▌ | 13955/16329 [1:57:29<19:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13955: train loss 1.18377. lr 3.678761e-04:  85%|████████▌ | 13956/16329 [1:57:29<19:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13956: train loss 1.14583. lr 3.678480e-04:  85%|████████▌ | 13956/16329 [1:57:30<19:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13956: train loss 1.14583. lr 3.678480e-04:  85%|████████▌ | 13957/16329 [1:57:30<19:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13957: train loss 1.13988. lr 3.678199e-04:  85%|████████▌ | 13957/16329 [1:57:30<19:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13957: train loss 1.13988. lr 3.678199e-04:  85%|████████▌ | 13958/16329 [1:57:30<19:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13958: train loss 1.11507. lr 3.677917e-04:  85%|████████▌ | 13958/16329 [1:57:31<19:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13958: train loss 1.11507. lr 3.677917e-04:  85%|████████▌ | 13959/16329 [1:57:31<19:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13959: train loss 1.16393. lr 3.677636e-04:  85%|████████▌ | 13959/16329 [1:57:31<19:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13959: train loss 1.16393. lr 3.677636e-04:  85%|████████▌ | 13960/16329 [1:57:31<19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13960: train loss 1.16042. lr 3.677355e-04:  85%|████████▌ | 13960/16329 [1:57:32<19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13960: train loss 1.16042. lr 3.677355e-04:  85%|████████▌ | 13961/16329 [1:57:32<19:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13961: train loss 1.14666. lr 3.677074e-04:  85%|████████▌ | 13961/16329 [1:57:32<19:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13961: train loss 1.14666. lr 3.677074e-04:  86%|████████▌ | 13962/16329 [1:57:32<19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13962: train loss 1.13555. lr 3.676793e-04:  86%|████████▌ | 13962/16329 [1:57:33<19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13962: train loss 1.13555. lr 3.676793e-04:  86%|████████▌ | 13963/16329 [1:57:33<19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13963: train loss 1.14550. lr 3.676512e-04:  86%|████████▌ | 13963/16329 [1:57:33<19:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13963: train loss 1.14550. lr 3.676512e-04:  86%|████████▌ | 13964/16329 [1:57:33<19:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13964: train loss 1.14685. lr 3.676230e-04:  86%|████████▌ | 13964/16329 [1:57:34<19:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13964: train loss 1.14685. lr 3.676230e-04:  86%|████████▌ | 13965/16329 [1:57:34<21:49,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13965: train loss 1.16031. lr 3.675949e-04:  86%|████████▌ | 13965/16329 [1:57:34<21:49,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 13965: train loss 1.16031. lr 3.675949e-04:  86%|████████▌ | 13966/16329 [1:57:34<21:10,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13966: train loss 1.16619. lr 3.675668e-04:  86%|████████▌ | 13966/16329 [1:57:35<21:10,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 13966: train loss 1.16619. lr 3.675668e-04:  86%|████████▌ | 13967/16329 [1:57:35<20:40,  1.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 13967: train loss 1.15752. lr 3.675387e-04:  86%|████████▌ | 13967/16329 [1:57:35<20:40,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 13967: train loss 1.15752. lr 3.675387e-04:  86%|████████▌ | 13968/16329 [1:57:35<20:22,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13968: train loss 1.12114. lr 3.675106e-04:  86%|████████▌ | 13968/16329 [1:57:36<20:22,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 13968: train loss 1.12114. lr 3.675106e-04:  86%|████████▌ | 13969/16329 [1:57:36<20:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13969: train loss 1.12844. lr 3.674824e-04:  86%|████████▌ | 13969/16329 [1:57:36<20:04,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 13969: train loss 1.12844. lr 3.674824e-04:  86%|████████▌ | 13970/16329 [1:57:36<19:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13970: train loss 1.12475. lr 3.674543e-04:  86%|████████▌ | 13970/16329 [1:57:37<19:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 13970: train loss 1.12475. lr 3.674543e-04:  86%|████████▌ | 13971/16329 [1:57:37<19:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13971: train loss 1.13160. lr 3.674262e-04:  86%|████████▌ | 13971/16329 [1:57:37<19:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 13971: train loss 1.13160. lr 3.674262e-04:  86%|████████▌ | 13972/16329 [1:57:37<19:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13972: train loss 1.13270. lr 3.673981e-04:  86%|████████▌ | 13972/16329 [1:57:38<19:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13972: train loss 1.13270. lr 3.673981e-04:  86%|████████▌ | 13973/16329 [1:57:38<19:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13973: train loss 1.13759. lr 3.673700e-04:  86%|████████▌ | 13973/16329 [1:57:38<19:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13973: train loss 1.13759. lr 3.673700e-04:  86%|████████▌ | 13974/16329 [1:57:38<19:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13974: train loss 1.13987. lr 3.673418e-04:  86%|████████▌ | 13974/16329 [1:57:39<19:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13974: train loss 1.13987. lr 3.673418e-04:  86%|████████▌ | 13975/16329 [1:57:39<19:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13975: train loss 1.12053. lr 3.673137e-04:  86%|████████▌ | 13975/16329 [1:57:39<19:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13975: train loss 1.12053. lr 3.673137e-04:  86%|████████▌ | 13976/16329 [1:57:39<19:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13976: train loss 1.13507. lr 3.672856e-04:  86%|████████▌ | 13976/16329 [1:57:40<19:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13976: train loss 1.13507. lr 3.672856e-04:  86%|████████▌ | 13977/16329 [1:57:40<19:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13977: train loss 1.17282. lr 3.672575e-04:  86%|████████▌ | 13977/16329 [1:57:40<19:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13977: train loss 1.17282. lr 3.672575e-04:  86%|████████▌ | 13978/16329 [1:57:40<19:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13978: train loss 1.12583. lr 3.672293e-04:  86%|████████▌ | 13978/16329 [1:57:41<19:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13978: train loss 1.12583. lr 3.672293e-04:  86%|████████▌ | 13979/16329 [1:57:41<19:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13979: train loss 1.15060. lr 3.672012e-04:  86%|████████▌ | 13979/16329 [1:57:41<19:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13979: train loss 1.15060. lr 3.672012e-04:  86%|████████▌ | 13980/16329 [1:57:41<19:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13980: train loss 1.13306. lr 3.671731e-04:  86%|████████▌ | 13980/16329 [1:57:42<19:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13980: train loss 1.13306. lr 3.671731e-04:  86%|████████▌ | 13981/16329 [1:57:42<19:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13981: train loss 1.12021. lr 3.671450e-04:  86%|████████▌ | 13981/16329 [1:57:42<19:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13981: train loss 1.12021. lr 3.671450e-04:  86%|████████▌ | 13982/16329 [1:57:42<19:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13982: train loss 1.13550. lr 3.671168e-04:  86%|████████▌ | 13982/16329 [1:57:43<19:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13982: train loss 1.13550. lr 3.671168e-04:  86%|████████▌ | 13983/16329 [1:57:43<19:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13983: train loss 1.13230. lr 3.670887e-04:  86%|████████▌ | 13983/16329 [1:57:43<19:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13983: train loss 1.13230. lr 3.670887e-04:  86%|████████▌ | 13984/16329 [1:57:43<19:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13984: train loss 1.12708. lr 3.670606e-04:  86%|████████▌ | 13984/16329 [1:57:44<19:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13984: train loss 1.12708. lr 3.670606e-04:  86%|████████▌ | 13985/16329 [1:57:44<19:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13985: train loss 1.13364. lr 3.670324e-04:  86%|████████▌ | 13985/16329 [1:57:44<19:22,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13985: train loss 1.13364. lr 3.670324e-04:  86%|████████▌ | 13986/16329 [1:57:44<19:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13986: train loss 1.15868. lr 3.670043e-04:  86%|████████▌ | 13986/16329 [1:57:45<19:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13986: train loss 1.15868. lr 3.670043e-04:  86%|████████▌ | 13987/16329 [1:57:45<19:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13987: train loss 1.12328. lr 3.669762e-04:  86%|████████▌ | 13987/16329 [1:57:45<19:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13987: train loss 1.12328. lr 3.669762e-04:  86%|████████▌ | 13988/16329 [1:57:45<19:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13988: train loss 1.13672. lr 3.669480e-04:  86%|████████▌ | 13988/16329 [1:57:46<19:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13988: train loss 1.13672. lr 3.669480e-04:  86%|████████▌ | 13989/16329 [1:57:46<19:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13989: train loss 1.11337. lr 3.669199e-04:  86%|████████▌ | 13989/16329 [1:57:46<19:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13989: train loss 1.11337. lr 3.669199e-04:  86%|████████▌ | 13990/16329 [1:57:46<19:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13990: train loss 1.17846. lr 3.668918e-04:  86%|████████▌ | 13990/16329 [1:57:47<19:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13990: train loss 1.17846. lr 3.668918e-04:  86%|████████▌ | 13991/16329 [1:57:47<19:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13991: train loss 1.14191. lr 3.668636e-04:  86%|████████▌ | 13991/16329 [1:57:47<19:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13991: train loss 1.14191. lr 3.668636e-04:  86%|████████▌ | 13992/16329 [1:57:47<19:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13992: train loss 1.16225. lr 3.668355e-04:  86%|████████▌ | 13992/16329 [1:57:48<19:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13992: train loss 1.16225. lr 3.668355e-04:  86%|████████▌ | 13993/16329 [1:57:48<19:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13993: train loss 1.12637. lr 3.668074e-04:  86%|████████▌ | 13993/16329 [1:57:48<19:18,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 13993: train loss 1.12637. lr 3.668074e-04:  86%|████████▌ | 13994/16329 [1:57:48<19:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13994: train loss 1.15125. lr 3.667792e-04:  86%|████████▌ | 13994/16329 [1:57:49<19:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13994: train loss 1.15125. lr 3.667792e-04:  86%|████████▌ | 13995/16329 [1:57:49<19:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13995: train loss 1.10339. lr 3.667511e-04:  86%|████████▌ | 13995/16329 [1:57:49<19:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13995: train loss 1.10339. lr 3.667511e-04:  86%|████████▌ | 13996/16329 [1:57:49<19:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13996: train loss 1.14293. lr 3.667230e-04:  86%|████████▌ | 13996/16329 [1:57:50<19:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13996: train loss 1.14293. lr 3.667230e-04:  86%|████████▌ | 13997/16329 [1:57:50<19:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13997: train loss 1.17002. lr 3.666948e-04:  86%|████████▌ | 13997/16329 [1:57:50<19:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13997: train loss 1.17002. lr 3.666948e-04:  86%|████████▌ | 13998/16329 [1:57:50<19:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13998: train loss 1.17521. lr 3.666667e-04:  86%|████████▌ | 13998/16329 [1:57:51<19:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 13998: train loss 1.17521. lr 3.666667e-04:  86%|████████▌ | 13999/16329 [1:57:51<19:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13999: train loss 1.13613. lr 3.666385e-04:  86%|████████▌ | 13999/16329 [1:57:51<19:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 13999: train loss 1.13613. lr 3.666385e-04:  86%|████████▌ | 14000/16329 [1:57:51<19:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14000: train loss 1.15334. lr 3.666104e-04:  86%|████████▌ | 14000/16329 [1:57:52<19:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14000: train loss 1.15334. lr 3.666104e-04:  86%|████████▌ | 14001/16329 [1:57:52<19:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14001: train loss 1.10892. lr 3.665823e-04:  86%|████████▌ | 14001/16329 [1:57:52<19:23,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14001: train loss 1.10892. lr 3.665823e-04:  86%|████████▌ | 14002/16329 [1:57:52<19:24,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14002: train loss 1.13919. lr 3.665541e-04:  86%|████████▌ | 14002/16329 [1:57:53<19:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14002: train loss 1.13919. lr 3.665541e-04:  86%|████████▌ | 14003/16329 [1:57:53<19:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14003: train loss 1.10893. lr 3.665260e-04:  86%|████████▌ | 14003/16329 [1:57:53<19:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14003: train loss 1.10893. lr 3.665260e-04:  86%|████████▌ | 14004/16329 [1:57:53<19:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14004: train loss 1.14839. lr 3.664978e-04:  86%|████████▌ | 14004/16329 [1:57:54<19:21,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14004: train loss 1.14839. lr 3.664978e-04:  86%|████████▌ | 14005/16329 [1:57:54<21:21,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14005: train loss 1.11305. lr 3.664697e-04:  86%|████████▌ | 14005/16329 [1:57:54<21:21,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14005: train loss 1.11305. lr 3.664697e-04:  86%|████████▌ | 14006/16329 [1:57:54<20:43,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14006: train loss 1.14922. lr 3.664416e-04:  86%|████████▌ | 14006/16329 [1:57:55<20:43,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14006: train loss 1.14922. lr 3.664416e-04:  86%|████████▌ | 14007/16329 [1:57:55<20:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14007: train loss 1.09750. lr 3.664134e-04:  86%|████████▌ | 14007/16329 [1:57:55<20:15,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14007: train loss 1.09750. lr 3.664134e-04:  86%|████████▌ | 14008/16329 [1:57:55<19:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14008: train loss 1.13858. lr 3.663853e-04:  86%|████████▌ | 14008/16329 [1:57:56<19:57,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14008: train loss 1.13858. lr 3.663853e-04:  86%|████████▌ | 14009/16329 [1:57:56<19:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14009: train loss 1.17685. lr 3.663571e-04:  86%|████████▌ | 14009/16329 [1:57:56<19:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14009: train loss 1.17685. lr 3.663571e-04:  86%|████████▌ | 14010/16329 [1:57:56<19:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14010: train loss 1.15152. lr 3.663290e-04:  86%|████████▌ | 14010/16329 [1:57:57<19:36,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14010: train loss 1.15152. lr 3.663290e-04:  86%|████████▌ | 14011/16329 [1:57:57<19:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14011: train loss 1.11267. lr 3.663008e-04:  86%|████████▌ | 14011/16329 [1:57:57<19:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14011: train loss 1.11267. lr 3.663008e-04:  86%|████████▌ | 14012/16329 [1:57:57<19:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14012: train loss 1.14566. lr 3.662727e-04:  86%|████████▌ | 14012/16329 [1:57:58<19:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14012: train loss 1.14566. lr 3.662727e-04:  86%|████████▌ | 14013/16329 [1:57:58<19:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14013: train loss 1.15630. lr 3.662445e-04:  86%|████████▌ | 14013/16329 [1:57:58<19:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14013: train loss 1.15630. lr 3.662445e-04:  86%|████████▌ | 14014/16329 [1:57:58<19:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14014: train loss 1.14679. lr 3.662164e-04:  86%|████████▌ | 14014/16329 [1:57:59<19:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14014: train loss 1.14679. lr 3.662164e-04:  86%|████████▌ | 14015/16329 [1:57:59<19:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14015: train loss 1.16597. lr 3.661882e-04:  86%|████████▌ | 14015/16329 [1:57:59<19:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14015: train loss 1.16597. lr 3.661882e-04:  86%|████████▌ | 14016/16329 [1:57:59<20:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14016: train loss 1.12751. lr 3.661601e-04:  86%|████████▌ | 14016/16329 [1:58:00<20:13,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14016: train loss 1.12751. lr 3.661601e-04:  86%|████████▌ | 14017/16329 [1:58:00<20:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14017: train loss 1.13587. lr 3.661319e-04:  86%|████████▌ | 14017/16329 [1:58:00<20:23,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14017: train loss 1.13587. lr 3.661319e-04:  86%|████████▌ | 14018/16329 [1:58:00<20:19,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14018: train loss 1.15781. lr 3.661038e-04:  86%|████████▌ | 14018/16329 [1:58:01<20:19,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14018: train loss 1.15781. lr 3.661038e-04:  86%|████████▌ | 14019/16329 [1:58:01<20:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14019: train loss 1.12501. lr 3.660756e-04:  86%|████████▌ | 14019/16329 [1:58:02<20:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14019: train loss 1.12501. lr 3.660756e-04:  86%|████████▌ | 14020/16329 [1:58:02<20:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14020: train loss 1.18323. lr 3.660475e-04:  86%|████████▌ | 14020/16329 [1:58:02<20:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14020: train loss 1.18323. lr 3.660475e-04:  86%|████████▌ | 14021/16329 [1:58:02<19:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14021: train loss 1.14588. lr 3.660193e-04:  86%|████████▌ | 14021/16329 [1:58:03<19:51,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14021: train loss 1.14588. lr 3.660193e-04:  86%|████████▌ | 14022/16329 [1:58:03<19:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14022: train loss 1.11660. lr 3.659912e-04:  86%|████████▌ | 14022/16329 [1:58:03<19:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14022: train loss 1.11660. lr 3.659912e-04:  86%|████████▌ | 14023/16329 [1:58:03<19:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14023: train loss 1.15988. lr 3.659630e-04:  86%|████████▌ | 14023/16329 [1:58:04<19:32,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14023: train loss 1.15988. lr 3.659630e-04:  86%|████████▌ | 14024/16329 [1:58:04<19:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14024: train loss 1.14590. lr 3.659349e-04:  86%|████████▌ | 14024/16329 [1:58:04<19:25,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14024: train loss 1.14590. lr 3.659349e-04:  86%|████████▌ | 14025/16329 [1:58:04<19:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14025: train loss 1.12545. lr 3.659067e-04:  86%|████████▌ | 14025/16329 [1:58:05<19:20,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14025: train loss 1.12545. lr 3.659067e-04:  86%|████████▌ | 14026/16329 [1:58:05<19:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14026: train loss 1.14116. lr 3.658786e-04:  86%|████████▌ | 14026/16329 [1:58:05<19:16,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14026: train loss 1.14116. lr 3.658786e-04:  86%|████████▌ | 14027/16329 [1:58:05<19:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14027: train loss 1.13482. lr 3.658504e-04:  86%|████████▌ | 14027/16329 [1:58:06<19:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14027: train loss 1.13482. lr 3.658504e-04:  86%|████████▌ | 14028/16329 [1:58:06<19:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14028: train loss 1.15349. lr 3.658222e-04:  86%|████████▌ | 14028/16329 [1:58:06<19:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14028: train loss 1.15349. lr 3.658222e-04:  86%|████████▌ | 14029/16329 [1:58:06<19:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14029: train loss 1.11506. lr 3.657941e-04:  86%|████████▌ | 14029/16329 [1:58:07<19:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14029: train loss 1.11506. lr 3.657941e-04:  86%|████████▌ | 14030/16329 [1:58:07<19:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14030: train loss 1.14261. lr 3.657659e-04:  86%|████████▌ | 14030/16329 [1:58:07<19:06,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14030: train loss 1.14261. lr 3.657659e-04:  86%|████████▌ | 14031/16329 [1:58:07<19:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14031: train loss 1.14976. lr 3.657378e-04:  86%|████████▌ | 14031/16329 [1:58:08<19:59,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14031: train loss 1.14976. lr 3.657378e-04:  86%|████████▌ | 14032/16329 [1:58:08<20:28,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14032: train loss 1.15793. lr 3.657096e-04:  86%|████████▌ | 14032/16329 [1:58:08<20:28,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14032: train loss 1.15793. lr 3.657096e-04:  86%|████████▌ | 14033/16329 [1:58:08<20:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14033: train loss 1.15557. lr 3.656815e-04:  86%|████████▌ | 14033/16329 [1:58:09<20:35,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14033: train loss 1.15557. lr 3.656815e-04:  86%|████████▌ | 14034/16329 [1:58:09<20:32,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14034: train loss 1.11659. lr 3.656533e-04:  86%|████████▌ | 14034/16329 [1:58:09<20:32,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14034: train loss 1.11659. lr 3.656533e-04:  86%|████████▌ | 14035/16329 [1:58:09<20:23,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14035: train loss 1.14032. lr 3.656251e-04:  86%|████████▌ | 14035/16329 [1:58:10<20:23,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14035: train loss 1.14032. lr 3.656251e-04:  86%|████████▌ | 14036/16329 [1:58:10<20:12,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14036: train loss 1.12188. lr 3.655970e-04:  86%|████████▌ | 14036/16329 [1:58:10<20:12,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14036: train loss 1.12188. lr 3.655970e-04:  86%|████████▌ | 14037/16329 [1:58:10<19:57,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14037: train loss 1.14026. lr 3.655688e-04:  86%|████████▌ | 14037/16329 [1:58:11<19:57,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14037: train loss 1.14026. lr 3.655688e-04:  86%|████████▌ | 14038/16329 [1:58:11<19:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14038: train loss 1.13654. lr 3.655406e-04:  86%|████████▌ | 14038/16329 [1:58:11<19:44,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14038: train loss 1.13654. lr 3.655406e-04:  86%|████████▌ | 14039/16329 [1:58:11<19:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14039: train loss 1.12562. lr 3.655125e-04:  86%|████████▌ | 14039/16329 [1:58:12<19:34,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14039: train loss 1.12562. lr 3.655125e-04:  86%|████████▌ | 14040/16329 [1:58:12<21:29,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 14040: train loss 1.14043. lr 3.654843e-04:  86%|████████▌ | 14040/16329 [1:58:12<21:29,  1.78it/s]\u001b[A\n",
      "epoch 1 iter 14040: train loss 1.14043. lr 3.654843e-04:  86%|████████▌ | 14041/16329 [1:58:12<20:45,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14041: train loss 1.11281. lr 3.654562e-04:  86%|████████▌ | 14041/16329 [1:58:13<20:45,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14041: train loss 1.11281. lr 3.654562e-04:  86%|████████▌ | 14042/16329 [1:58:13<20:13,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14042: train loss 1.15140. lr 3.654280e-04:  86%|████████▌ | 14042/16329 [1:58:13<20:13,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14042: train loss 1.15140. lr 3.654280e-04:  86%|████████▌ | 14043/16329 [1:58:13<19:47,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14043: train loss 1.17011. lr 3.653998e-04:  86%|████████▌ | 14043/16329 [1:58:14<19:47,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14043: train loss 1.17011. lr 3.653998e-04:  86%|████████▌ | 14044/16329 [1:58:14<19:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14044: train loss 1.13714. lr 3.653717e-04:  86%|████████▌ | 14044/16329 [1:58:14<19:32,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14044: train loss 1.13714. lr 3.653717e-04:  86%|████████▌ | 14045/16329 [1:58:14<19:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14045: train loss 1.15003. lr 3.653435e-04:  86%|████████▌ | 14045/16329 [1:58:15<19:19,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14045: train loss 1.15003. lr 3.653435e-04:  86%|████████▌ | 14046/16329 [1:58:15<19:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14046: train loss 1.13087. lr 3.653153e-04:  86%|████████▌ | 14046/16329 [1:58:15<19:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14046: train loss 1.13087. lr 3.653153e-04:  86%|████████▌ | 14047/16329 [1:58:15<19:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14047: train loss 1.14988. lr 3.652872e-04:  86%|████████▌ | 14047/16329 [1:58:16<19:04,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14047: train loss 1.14988. lr 3.652872e-04:  86%|████████▌ | 14048/16329 [1:58:16<18:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14048: train loss 1.13118. lr 3.652590e-04:  86%|████████▌ | 14048/16329 [1:58:16<18:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14048: train loss 1.13118. lr 3.652590e-04:  86%|████████▌ | 14049/16329 [1:58:16<18:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14049: train loss 1.13907. lr 3.652308e-04:  86%|████████▌ | 14049/16329 [1:58:17<18:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14049: train loss 1.13907. lr 3.652308e-04:  86%|████████▌ | 14050/16329 [1:58:17<18:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14050: train loss 1.14704. lr 3.652026e-04:  86%|████████▌ | 14050/16329 [1:58:17<18:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14050: train loss 1.14704. lr 3.652026e-04:  86%|████████▌ | 14051/16329 [1:58:17<18:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14051: train loss 1.12111. lr 3.651745e-04:  86%|████████▌ | 14051/16329 [1:58:18<18:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14051: train loss 1.12111. lr 3.651745e-04:  86%|████████▌ | 14052/16329 [1:58:18<18:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14052: train loss 1.11469. lr 3.651463e-04:  86%|████████▌ | 14052/16329 [1:58:18<18:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14052: train loss 1.11469. lr 3.651463e-04:  86%|████████▌ | 14053/16329 [1:58:18<18:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14053: train loss 1.17023. lr 3.651181e-04:  86%|████████▌ | 14053/16329 [1:58:19<18:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14053: train loss 1.17023. lr 3.651181e-04:  86%|████████▌ | 14054/16329 [1:58:19<18:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14054: train loss 1.12975. lr 3.650900e-04:  86%|████████▌ | 14054/16329 [1:58:19<18:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14054: train loss 1.12975. lr 3.650900e-04:  86%|████████▌ | 14055/16329 [1:58:19<18:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 14055: train loss 1.13346. lr 3.650618e-04:  86%|████████▌ | 14055/16329 [1:58:20<18:42,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 14055: train loss 1.13346. lr 3.650618e-04:  86%|████████▌ | 14056/16329 [1:58:20<18:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14056: train loss 1.12692. lr 3.650336e-04:  86%|████████▌ | 14056/16329 [1:58:20<18:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14056: train loss 1.12692. lr 3.650336e-04:  86%|████████▌ | 14057/16329 [1:58:20<18:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 14057: train loss 1.16604. lr 3.650054e-04:  86%|████████▌ | 14057/16329 [1:58:21<18:41,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 14057: train loss 1.16604. lr 3.650054e-04:  86%|████████▌ | 14058/16329 [1:58:21<18:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14058: train loss 1.11743. lr 3.649773e-04:  86%|████████▌ | 14058/16329 [1:58:21<18:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14058: train loss 1.11743. lr 3.649773e-04:  86%|████████▌ | 14059/16329 [1:58:21<18:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14059: train loss 1.13374. lr 3.649491e-04:  86%|████████▌ | 14059/16329 [1:58:22<18:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14059: train loss 1.13374. lr 3.649491e-04:  86%|████████▌ | 14060/16329 [1:58:22<18:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 14060: train loss 1.12286. lr 3.649209e-04:  86%|████████▌ | 14060/16329 [1:58:22<18:38,  2.03it/s]\u001b[A\n",
      "epoch 1 iter 14060: train loss 1.12286. lr 3.649209e-04:  86%|████████▌ | 14061/16329 [1:58:22<18:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14061: train loss 1.10302. lr 3.648927e-04:  86%|████████▌ | 14061/16329 [1:58:23<18:41,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14061: train loss 1.10302. lr 3.648927e-04:  86%|████████▌ | 14062/16329 [1:58:23<18:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14062: train loss 1.12078. lr 3.648646e-04:  86%|████████▌ | 14062/16329 [1:58:23<18:40,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14062: train loss 1.12078. lr 3.648646e-04:  86%|████████▌ | 14063/16329 [1:58:23<18:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14063: train loss 1.12583. lr 3.648364e-04:  86%|████████▌ | 14063/16329 [1:58:24<18:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14063: train loss 1.12583. lr 3.648364e-04:  86%|████████▌ | 14064/16329 [1:58:24<18:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14064: train loss 1.13547. lr 3.648082e-04:  86%|████████▌ | 14064/16329 [1:58:25<18:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14064: train loss 1.13547. lr 3.648082e-04:  86%|████████▌ | 14065/16329 [1:58:25<20:39,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 14065: train loss 1.12210. lr 3.647800e-04:  86%|████████▌ | 14065/16329 [1:58:25<20:39,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 14065: train loss 1.12210. lr 3.647800e-04:  86%|████████▌ | 14066/16329 [1:58:25<20:06,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14066: train loss 1.12646. lr 3.647518e-04:  86%|████████▌ | 14066/16329 [1:58:26<20:06,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14066: train loss 1.12646. lr 3.647518e-04:  86%|████████▌ | 14067/16329 [1:58:26<19:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14067: train loss 1.14678. lr 3.647237e-04:  86%|████████▌ | 14067/16329 [1:58:26<19:39,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14067: train loss 1.14678. lr 3.647237e-04:  86%|████████▌ | 14068/16329 [1:58:26<19:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14068: train loss 1.12576. lr 3.646955e-04:  86%|████████▌ | 14068/16329 [1:58:27<19:22,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14068: train loss 1.12576. lr 3.646955e-04:  86%|████████▌ | 14069/16329 [1:58:27<19:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14069: train loss 1.15159. lr 3.646673e-04:  86%|████████▌ | 14069/16329 [1:58:27<19:09,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14069: train loss 1.15159. lr 3.646673e-04:  86%|████████▌ | 14070/16329 [1:58:27<18:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14070: train loss 1.11255. lr 3.646391e-04:  86%|████████▌ | 14070/16329 [1:58:28<18:58,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14070: train loss 1.11255. lr 3.646391e-04:  86%|████████▌ | 14071/16329 [1:58:28<18:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14071: train loss 1.14667. lr 3.646109e-04:  86%|████████▌ | 14071/16329 [1:58:28<18:55,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14071: train loss 1.14667. lr 3.646109e-04:  86%|████████▌ | 14072/16329 [1:58:28<18:47,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14072: train loss 1.12909. lr 3.645828e-04:  86%|████████▌ | 14072/16329 [1:58:29<18:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14072: train loss 1.12909. lr 3.645828e-04:  86%|████████▌ | 14073/16329 [1:58:29<18:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14073: train loss 1.13564. lr 3.645546e-04:  86%|████████▌ | 14073/16329 [1:58:29<18:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14073: train loss 1.13564. lr 3.645546e-04:  86%|████████▌ | 14074/16329 [1:58:29<18:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14074: train loss 1.15242. lr 3.645264e-04:  86%|████████▌ | 14074/16329 [1:58:29<18:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14074: train loss 1.15242. lr 3.645264e-04:  86%|████████▌ | 14075/16329 [1:58:29<18:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14075: train loss 1.16379. lr 3.644982e-04:  86%|████████▌ | 14075/16329 [1:58:30<18:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14075: train loss 1.16379. lr 3.644982e-04:  86%|████████▌ | 14076/16329 [1:58:30<18:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14076: train loss 1.13357. lr 3.644700e-04:  86%|████████▌ | 14076/16329 [1:58:30<18:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14076: train loss 1.13357. lr 3.644700e-04:  86%|████████▌ | 14077/16329 [1:58:30<18:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14077: train loss 1.13730. lr 3.644418e-04:  86%|████████▌ | 14077/16329 [1:58:31<18:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14077: train loss 1.13730. lr 3.644418e-04:  86%|████████▌ | 14078/16329 [1:58:31<18:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14078: train loss 1.14326. lr 3.644136e-04:  86%|████████▌ | 14078/16329 [1:58:31<18:38,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14078: train loss 1.14326. lr 3.644136e-04:  86%|████████▌ | 14079/16329 [1:58:31<18:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14079: train loss 1.14444. lr 3.643855e-04:  86%|████████▌ | 14079/16329 [1:58:32<18:36,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14079: train loss 1.14444. lr 3.643855e-04:  86%|████████▌ | 14080/16329 [1:58:32<18:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14080: train loss 1.13882. lr 3.643573e-04:  86%|████████▌ | 14080/16329 [1:58:32<18:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14080: train loss 1.13882. lr 3.643573e-04:  86%|████████▌ | 14081/16329 [1:58:32<18:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14081: train loss 1.14653. lr 3.643291e-04:  86%|████████▌ | 14081/16329 [1:58:33<18:34,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14081: train loss 1.14653. lr 3.643291e-04:  86%|████████▌ | 14082/16329 [1:58:33<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14082: train loss 1.17489. lr 3.643009e-04:  86%|████████▌ | 14082/16329 [1:58:33<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14082: train loss 1.17489. lr 3.643009e-04:  86%|████████▌ | 14083/16329 [1:58:33<18:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14083: train loss 1.13178. lr 3.642727e-04:  86%|████████▌ | 14083/16329 [1:58:34<18:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14083: train loss 1.13178. lr 3.642727e-04:  86%|████████▋ | 14084/16329 [1:58:34<18:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14084: train loss 1.15448. lr 3.642445e-04:  86%|████████▋ | 14084/16329 [1:58:34<18:33,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14084: train loss 1.15448. lr 3.642445e-04:  86%|████████▋ | 14085/16329 [1:58:34<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14085: train loss 1.12397. lr 3.642163e-04:  86%|████████▋ | 14085/16329 [1:58:35<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14085: train loss 1.12397. lr 3.642163e-04:  86%|████████▋ | 14086/16329 [1:58:35<18:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14086: train loss 1.15783. lr 3.641881e-04:  86%|████████▋ | 14086/16329 [1:58:35<18:32,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14086: train loss 1.15783. lr 3.641881e-04:  86%|████████▋ | 14087/16329 [1:58:35<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14087: train loss 1.14972. lr 3.641599e-04:  86%|████████▋ | 14087/16329 [1:58:36<18:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14087: train loss 1.14972. lr 3.641599e-04:  86%|████████▋ | 14088/16329 [1:58:36<18:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14088: train loss 1.14715. lr 3.641317e-04:  86%|████████▋ | 14088/16329 [1:58:36<18:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14088: train loss 1.14715. lr 3.641317e-04:  86%|████████▋ | 14089/16329 [1:58:36<18:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14089: train loss 1.13370. lr 3.641035e-04:  86%|████████▋ | 14089/16329 [1:58:37<18:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14089: train loss 1.13370. lr 3.641035e-04:  86%|████████▋ | 14090/16329 [1:58:37<18:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14090: train loss 1.11502. lr 3.640753e-04:  86%|████████▋ | 14090/16329 [1:58:37<18:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14090: train loss 1.11502. lr 3.640753e-04:  86%|████████▋ | 14091/16329 [1:58:37<18:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14091: train loss 1.12315. lr 3.640472e-04:  86%|████████▋ | 14091/16329 [1:58:38<18:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14091: train loss 1.12315. lr 3.640472e-04:  86%|████████▋ | 14092/16329 [1:58:38<20:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14092: train loss 1.14520. lr 3.640190e-04:  86%|████████▋ | 14092/16329 [1:58:39<20:28,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14092: train loss 1.14520. lr 3.640190e-04:  86%|████████▋ | 14093/16329 [1:58:39<19:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14093: train loss 1.12564. lr 3.639908e-04:  86%|████████▋ | 14093/16329 [1:58:39<19:51,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14093: train loss 1.12564. lr 3.639908e-04:  86%|████████▋ | 14094/16329 [1:58:39<19:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14094: train loss 1.14665. lr 3.639626e-04:  86%|████████▋ | 14094/16329 [1:58:40<19:27,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14094: train loss 1.14665. lr 3.639626e-04:  86%|████████▋ | 14095/16329 [1:58:40<19:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14095: train loss 1.11855. lr 3.639344e-04:  86%|████████▋ | 14095/16329 [1:58:40<19:10,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14095: train loss 1.11855. lr 3.639344e-04:  86%|████████▋ | 14096/16329 [1:58:40<18:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14096: train loss 1.15695. lr 3.639062e-04:  86%|████████▋ | 14096/16329 [1:58:41<18:55,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14096: train loss 1.15695. lr 3.639062e-04:  86%|████████▋ | 14097/16329 [1:58:41<18:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14097: train loss 1.15821. lr 3.638780e-04:  86%|████████▋ | 14097/16329 [1:58:41<18:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14097: train loss 1.15821. lr 3.638780e-04:  86%|████████▋ | 14098/16329 [1:58:41<18:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14098: train loss 1.11945. lr 3.638498e-04:  86%|████████▋ | 14098/16329 [1:58:42<18:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14098: train loss 1.11945. lr 3.638498e-04:  86%|████████▋ | 14099/16329 [1:58:42<18:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14099: train loss 1.15459. lr 3.638216e-04:  86%|████████▋ | 14099/16329 [1:58:42<18:36,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14099: train loss 1.15459. lr 3.638216e-04:  86%|████████▋ | 14100/16329 [1:58:42<18:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14100: train loss 1.15244. lr 3.637934e-04:  86%|████████▋ | 14100/16329 [1:58:43<18:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14100: train loss 1.15244. lr 3.637934e-04:  86%|████████▋ | 14101/16329 [1:58:43<18:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14101: train loss 1.15053. lr 3.637652e-04:  86%|████████▋ | 14101/16329 [1:58:43<18:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14101: train loss 1.15053. lr 3.637652e-04:  86%|████████▋ | 14102/16329 [1:58:43<18:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14102: train loss 1.13263. lr 3.637370e-04:  86%|████████▋ | 14102/16329 [1:58:44<18:54,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14102: train loss 1.13263. lr 3.637370e-04:  86%|████████▋ | 14103/16329 [1:58:44<19:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14103: train loss 1.14144. lr 3.637088e-04:  86%|████████▋ | 14103/16329 [1:58:44<19:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14103: train loss 1.14144. lr 3.637088e-04:  86%|████████▋ | 14104/16329 [1:58:44<19:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14104: train loss 1.13696. lr 3.636806e-04:  86%|████████▋ | 14104/16329 [1:58:45<19:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14104: train loss 1.13696. lr 3.636806e-04:  86%|████████▋ | 14105/16329 [1:58:45<19:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14105: train loss 1.10331. lr 3.636524e-04:  86%|████████▋ | 14105/16329 [1:58:45<19:04,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14105: train loss 1.10331. lr 3.636524e-04:  86%|████████▋ | 14106/16329 [1:58:45<18:56,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14106: train loss 1.14757. lr 3.636242e-04:  86%|████████▋ | 14106/16329 [1:58:46<18:56,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14106: train loss 1.14757. lr 3.636242e-04:  86%|████████▋ | 14107/16329 [1:58:46<18:52,  1.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14107: train loss 1.11274. lr 3.635960e-04:  86%|████████▋ | 14107/16329 [1:58:46<18:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14107: train loss 1.11274. lr 3.635960e-04:  86%|████████▋ | 14108/16329 [1:58:46<18:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14108: train loss 1.15868. lr 3.635678e-04:  86%|████████▋ | 14108/16329 [1:58:47<18:45,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14108: train loss 1.15868. lr 3.635678e-04:  86%|████████▋ | 14109/16329 [1:58:47<18:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14109: train loss 1.13928. lr 3.635395e-04:  86%|████████▋ | 14109/16329 [1:58:47<18:40,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14109: train loss 1.13928. lr 3.635395e-04:  86%|████████▋ | 14110/16329 [1:58:47<18:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14110: train loss 1.16140. lr 3.635113e-04:  86%|████████▋ | 14110/16329 [1:58:48<18:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14110: train loss 1.16140. lr 3.635113e-04:  86%|████████▋ | 14111/16329 [1:58:48<18:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14111: train loss 1.14839. lr 3.634831e-04:  86%|████████▋ | 14111/16329 [1:58:48<18:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14111: train loss 1.14839. lr 3.634831e-04:  86%|████████▋ | 14112/16329 [1:58:48<18:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14112: train loss 1.12169. lr 3.634549e-04:  86%|████████▋ | 14112/16329 [1:58:49<18:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14112: train loss 1.12169. lr 3.634549e-04:  86%|████████▋ | 14113/16329 [1:58:49<18:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14113: train loss 1.13296. lr 3.634267e-04:  86%|████████▋ | 14113/16329 [1:58:49<18:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14113: train loss 1.13296. lr 3.634267e-04:  86%|████████▋ | 14114/16329 [1:58:49<18:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14114: train loss 1.12419. lr 3.633985e-04:  86%|████████▋ | 14114/16329 [1:58:50<18:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14114: train loss 1.12419. lr 3.633985e-04:  86%|████████▋ | 14115/16329 [1:58:50<18:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14115: train loss 1.16387. lr 3.633703e-04:  86%|████████▋ | 14115/16329 [1:58:50<18:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14115: train loss 1.16387. lr 3.633703e-04:  86%|████████▋ | 14116/16329 [1:58:50<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14116: train loss 1.10259. lr 3.633421e-04:  86%|████████▋ | 14116/16329 [1:58:51<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14116: train loss 1.10259. lr 3.633421e-04:  86%|████████▋ | 14117/16329 [1:58:51<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14117: train loss 1.13122. lr 3.633139e-04:  86%|████████▋ | 14117/16329 [1:58:51<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14117: train loss 1.13122. lr 3.633139e-04:  86%|████████▋ | 14118/16329 [1:58:51<18:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14118: train loss 1.10118. lr 3.632857e-04:  86%|████████▋ | 14118/16329 [1:58:52<18:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14118: train loss 1.10118. lr 3.632857e-04:  86%|████████▋ | 14119/16329 [1:58:52<18:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14119: train loss 1.12799. lr 3.632575e-04:  86%|████████▋ | 14119/16329 [1:58:52<18:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14119: train loss 1.12799. lr 3.632575e-04:  86%|████████▋ | 14120/16329 [1:58:52<18:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14120: train loss 1.11304. lr 3.632293e-04:  86%|████████▋ | 14120/16329 [1:58:53<18:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14120: train loss 1.11304. lr 3.632293e-04:  86%|████████▋ | 14121/16329 [1:58:53<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14121: train loss 1.14216. lr 3.632010e-04:  86%|████████▋ | 14121/16329 [1:58:53<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14121: train loss 1.14216. lr 3.632010e-04:  86%|████████▋ | 14122/16329 [1:58:53<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14122: train loss 1.12352. lr 3.631728e-04:  86%|████████▋ | 14122/16329 [1:58:54<18:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14122: train loss 1.12352. lr 3.631728e-04:  86%|████████▋ | 14123/16329 [1:58:54<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14123: train loss 1.12927. lr 3.631446e-04:  86%|████████▋ | 14123/16329 [1:58:54<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14123: train loss 1.12927. lr 3.631446e-04:  86%|████████▋ | 14124/16329 [1:58:54<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14124: train loss 1.14138. lr 3.631164e-04:  86%|████████▋ | 14124/16329 [1:58:55<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14124: train loss 1.14138. lr 3.631164e-04:  87%|████████▋ | 14125/16329 [1:58:55<18:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14125: train loss 1.12800. lr 3.630882e-04:  87%|████████▋ | 14125/16329 [1:58:55<18:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14125: train loss 1.12800. lr 3.630882e-04:  87%|████████▋ | 14126/16329 [1:58:55<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14126: train loss 1.14104. lr 3.630600e-04:  87%|████████▋ | 14126/16329 [1:58:56<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14126: train loss 1.14104. lr 3.630600e-04:  87%|████████▋ | 14127/16329 [1:58:56<18:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14127: train loss 1.13209. lr 3.630318e-04:  87%|████████▋ | 14127/16329 [1:58:56<18:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14127: train loss 1.13209. lr 3.630318e-04:  87%|████████▋ | 14128/16329 [1:58:56<18:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14128: train loss 1.15729. lr 3.630035e-04:  87%|████████▋ | 14128/16329 [1:58:57<18:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14128: train loss 1.15729. lr 3.630035e-04:  87%|████████▋ | 14129/16329 [1:58:57<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14129: train loss 1.13850. lr 3.629753e-04:  87%|████████▋ | 14129/16329 [1:58:57<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14129: train loss 1.13850. lr 3.629753e-04:  87%|████████▋ | 14130/16329 [1:58:57<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14130: train loss 1.12869. lr 3.629471e-04:  87%|████████▋ | 14130/16329 [1:58:58<18:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14130: train loss 1.12869. lr 3.629471e-04:  87%|████████▋ | 14131/16329 [1:58:58<18:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14131: train loss 1.17264. lr 3.629189e-04:  87%|████████▋ | 14131/16329 [1:58:58<18:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14131: train loss 1.17264. lr 3.629189e-04:  87%|████████▋ | 14132/16329 [1:58:58<20:09,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14132: train loss 1.11024. lr 3.628907e-04:  87%|████████▋ | 14132/16329 [1:58:59<20:09,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14132: train loss 1.11024. lr 3.628907e-04:  87%|████████▋ | 14133/16329 [1:58:59<19:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14133: train loss 1.10592. lr 3.628624e-04:  87%|████████▋ | 14133/16329 [1:58:59<19:34,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14133: train loss 1.10592. lr 3.628624e-04:  87%|████████▋ | 14134/16329 [1:58:59<19:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14134: train loss 1.11852. lr 3.628342e-04:  87%|████████▋ | 14134/16329 [1:59:00<19:08,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14134: train loss 1.11852. lr 3.628342e-04:  87%|████████▋ | 14135/16329 [1:59:00<18:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14135: train loss 1.13408. lr 3.628060e-04:  87%|████████▋ | 14135/16329 [1:59:00<18:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14135: train loss 1.13408. lr 3.628060e-04:  87%|████████▋ | 14136/16329 [1:59:00<18:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14136: train loss 1.11496. lr 3.627778e-04:  87%|████████▋ | 14136/16329 [1:59:01<18:39,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14136: train loss 1.11496. lr 3.627778e-04:  87%|████████▋ | 14137/16329 [1:59:01<18:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14137: train loss 1.14197. lr 3.627496e-04:  87%|████████▋ | 14137/16329 [1:59:01<18:27,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14137: train loss 1.14197. lr 3.627496e-04:  87%|████████▋ | 14138/16329 [1:59:01<18:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14138: train loss 1.15713. lr 3.627213e-04:  87%|████████▋ | 14138/16329 [1:59:02<18:22,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14138: train loss 1.15713. lr 3.627213e-04:  87%|████████▋ | 14139/16329 [1:59:02<18:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14139: train loss 1.13201. lr 3.626931e-04:  87%|████████▋ | 14139/16329 [1:59:02<18:16,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14139: train loss 1.13201. lr 3.626931e-04:  87%|████████▋ | 14140/16329 [1:59:02<18:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14140: train loss 1.12818. lr 3.626649e-04:  87%|████████▋ | 14140/16329 [1:59:03<18:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14140: train loss 1.12818. lr 3.626649e-04:  87%|████████▋ | 14141/16329 [1:59:03<18:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14141: train loss 1.11661. lr 3.626367e-04:  87%|████████▋ | 14141/16329 [1:59:03<18:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14141: train loss 1.11661. lr 3.626367e-04:  87%|████████▋ | 14142/16329 [1:59:03<18:04,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14142: train loss 1.10665. lr 3.626084e-04:  87%|████████▋ | 14142/16329 [1:59:04<18:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14142: train loss 1.10665. lr 3.626084e-04:  87%|████████▋ | 14143/16329 [1:59:04<18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14143: train loss 1.12539. lr 3.625802e-04:  87%|████████▋ | 14143/16329 [1:59:04<18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14143: train loss 1.12539. lr 3.625802e-04:  87%|████████▋ | 14144/16329 [1:59:04<18:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14144: train loss 1.14048. lr 3.625520e-04:  87%|████████▋ | 14144/16329 [1:59:05<18:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14144: train loss 1.14048. lr 3.625520e-04:  87%|████████▋ | 14145/16329 [1:59:05<18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14145: train loss 1.11697. lr 3.625238e-04:  87%|████████▋ | 14145/16329 [1:59:05<18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14145: train loss 1.11697. lr 3.625238e-04:  87%|████████▋ | 14146/16329 [1:59:05<18:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14146: train loss 1.13405. lr 3.624955e-04:  87%|████████▋ | 14146/16329 [1:59:06<18:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14146: train loss 1.13405. lr 3.624955e-04:  87%|████████▋ | 14147/16329 [1:59:06<18:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14147: train loss 1.15680. lr 3.624673e-04:  87%|████████▋ | 14147/16329 [1:59:06<18:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14147: train loss 1.15680. lr 3.624673e-04:  87%|████████▋ | 14148/16329 [1:59:06<18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14148: train loss 1.13136. lr 3.624391e-04:  87%|████████▋ | 14148/16329 [1:59:07<18:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14148: train loss 1.13136. lr 3.624391e-04:  87%|████████▋ | 14149/16329 [1:59:07<18:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14149: train loss 1.10890. lr 3.624109e-04:  87%|████████▋ | 14149/16329 [1:59:07<18:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14149: train loss 1.10890. lr 3.624109e-04:  87%|████████▋ | 14150/16329 [1:59:07<18:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14150: train loss 1.12708. lr 3.623826e-04:  87%|████████▋ | 14150/16329 [1:59:08<18:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14150: train loss 1.12708. lr 3.623826e-04:  87%|████████▋ | 14151/16329 [1:59:08<18:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14151: train loss 1.11088. lr 3.623544e-04:  87%|████████▋ | 14151/16329 [1:59:08<18:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14151: train loss 1.11088. lr 3.623544e-04:  87%|████████▋ | 14152/16329 [1:59:08<18:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14152: train loss 1.13925. lr 3.623262e-04:  87%|████████▋ | 14152/16329 [1:59:09<18:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14152: train loss 1.13925. lr 3.623262e-04:  87%|████████▋ | 14153/16329 [1:59:09<17:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14153: train loss 1.13776. lr 3.622979e-04:  87%|████████▋ | 14153/16329 [1:59:09<17:58,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14153: train loss 1.13776. lr 3.622979e-04:  87%|████████▋ | 14154/16329 [1:59:09<18:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14154: train loss 1.12513. lr 3.622697e-04:  87%|████████▋ | 14154/16329 [1:59:10<18:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14154: train loss 1.12513. lr 3.622697e-04:  87%|████████▋ | 14155/16329 [1:59:10<18:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14155: train loss 1.13798. lr 3.622415e-04:  87%|████████▋ | 14155/16329 [1:59:10<18:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14155: train loss 1.13798. lr 3.622415e-04:  87%|████████▋ | 14156/16329 [1:59:10<17:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14156: train loss 1.13078. lr 3.622132e-04:  87%|████████▋ | 14156/16329 [1:59:11<17:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14156: train loss 1.13078. lr 3.622132e-04:  87%|████████▋ | 14157/16329 [1:59:11<17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14157: train loss 1.14960. lr 3.621850e-04:  87%|████████▋ | 14157/16329 [1:59:11<17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14157: train loss 1.14960. lr 3.621850e-04:  87%|████████▋ | 14158/16329 [1:59:11<17:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14158: train loss 1.10407. lr 3.621568e-04:  87%|████████▋ | 14158/16329 [1:59:12<17:57,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14158: train loss 1.10407. lr 3.621568e-04:  87%|████████▋ | 14159/16329 [1:59:12<18:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14159: train loss 1.13130. lr 3.621285e-04:  87%|████████▋ | 14159/16329 [1:59:12<18:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14159: train loss 1.13130. lr 3.621285e-04:  87%|████████▋ | 14160/16329 [1:59:12<17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14160: train loss 1.12265. lr 3.621003e-04:  87%|████████▋ | 14160/16329 [1:59:13<17:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14160: train loss 1.12265. lr 3.621003e-04:  87%|████████▋ | 14161/16329 [1:59:13<17:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14161: train loss 1.11724. lr 3.620721e-04:  87%|████████▋ | 14161/16329 [1:59:13<17:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14161: train loss 1.11724. lr 3.620721e-04:  87%|████████▋ | 14162/16329 [1:59:13<17:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14162: train loss 1.14058. lr 3.620438e-04:  87%|████████▋ | 14162/16329 [1:59:14<17:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14162: train loss 1.14058. lr 3.620438e-04:  87%|████████▋ | 14163/16329 [1:59:14<17:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14163: train loss 1.14285. lr 3.620156e-04:  87%|████████▋ | 14163/16329 [1:59:14<17:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14163: train loss 1.14285. lr 3.620156e-04:  87%|████████▋ | 14164/16329 [1:59:14<17:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14164: train loss 1.14074. lr 3.619874e-04:  87%|████████▋ | 14164/16329 [1:59:15<17:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14164: train loss 1.14074. lr 3.619874e-04:  87%|████████▋ | 14165/16329 [1:59:15<17:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14165: train loss 1.12206. lr 3.619591e-04:  87%|████████▋ | 14165/16329 [1:59:15<17:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14165: train loss 1.12206. lr 3.619591e-04:  87%|████████▋ | 14166/16329 [1:59:15<17:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14166: train loss 1.12827. lr 3.619309e-04:  87%|████████▋ | 14166/16329 [1:59:16<17:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14166: train loss 1.12827. lr 3.619309e-04:  87%|████████▋ | 14167/16329 [1:59:16<19:50,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14167: train loss 1.12655. lr 3.619026e-04:  87%|████████▋ | 14167/16329 [1:59:16<19:50,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14167: train loss 1.12655. lr 3.619026e-04:  87%|████████▋ | 14168/16329 [1:59:16<19:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14168: train loss 1.13889. lr 3.618744e-04:  87%|████████▋ | 14168/16329 [1:59:17<19:11,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14168: train loss 1.13889. lr 3.618744e-04:  87%|████████▋ | 14169/16329 [1:59:17<18:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14169: train loss 1.13157. lr 3.618462e-04:  87%|████████▋ | 14169/16329 [1:59:17<18:49,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14169: train loss 1.13157. lr 3.618462e-04:  87%|████████▋ | 14170/16329 [1:59:17<18:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14170: train loss 1.09960. lr 3.618179e-04:  87%|████████▋ | 14170/16329 [1:59:18<18:32,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14170: train loss 1.09960. lr 3.618179e-04:  87%|████████▋ | 14171/16329 [1:59:18<18:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14171: train loss 1.12738. lr 3.617897e-04:  87%|████████▋ | 14171/16329 [1:59:18<18:22,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14171: train loss 1.12738. lr 3.617897e-04:  87%|████████▋ | 14172/16329 [1:59:18<18:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14172: train loss 1.15967. lr 3.617614e-04:  87%|████████▋ | 14172/16329 [1:59:19<18:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14172: train loss 1.15967. lr 3.617614e-04:  87%|████████▋ | 14173/16329 [1:59:19<18:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14173: train loss 1.11711. lr 3.617332e-04:  87%|████████▋ | 14173/16329 [1:59:19<18:07,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14173: train loss 1.11711. lr 3.617332e-04:  87%|████████▋ | 14174/16329 [1:59:19<18:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14174: train loss 1.17578. lr 3.617050e-04:  87%|████████▋ | 14174/16329 [1:59:20<18:03,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14174: train loss 1.17578. lr 3.617050e-04:  87%|████████▋ | 14175/16329 [1:59:20<18:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14175: train loss 1.12074. lr 3.616767e-04:  87%|████████▋ | 14175/16329 [1:59:20<18:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14175: train loss 1.12074. lr 3.616767e-04:  87%|████████▋ | 14176/16329 [1:59:20<18:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14176: train loss 1.15039. lr 3.616485e-04:  87%|████████▋ | 14176/16329 [1:59:21<18:00,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14176: train loss 1.15039. lr 3.616485e-04:  87%|████████▋ | 14177/16329 [1:59:21<17:56,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14177: train loss 1.09030. lr 3.616202e-04:  87%|████████▋ | 14177/16329 [1:59:21<17:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14177: train loss 1.09030. lr 3.616202e-04:  87%|████████▋ | 14178/16329 [1:59:21<17:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14178: train loss 1.14485. lr 3.615920e-04:  87%|████████▋ | 14178/16329 [1:59:22<17:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14178: train loss 1.14485. lr 3.615920e-04:  87%|████████▋ | 14179/16329 [1:59:22<17:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14179: train loss 1.12426. lr 3.615637e-04:  87%|████████▋ | 14179/16329 [1:59:22<17:56,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14179: train loss 1.12426. lr 3.615637e-04:  87%|████████▋ | 14180/16329 [1:59:22<17:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14180: train loss 1.15272. lr 3.615355e-04:  87%|████████▋ | 14180/16329 [1:59:23<17:55,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14180: train loss 1.15272. lr 3.615355e-04:  87%|████████▋ | 14181/16329 [1:59:23<17:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14181: train loss 1.13674. lr 3.615072e-04:  87%|████████▋ | 14181/16329 [1:59:23<17:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14181: train loss 1.13674. lr 3.615072e-04:  87%|████████▋ | 14182/16329 [1:59:23<17:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14182: train loss 1.11821. lr 3.614790e-04:  87%|████████▋ | 14182/16329 [1:59:24<17:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14182: train loss 1.11821. lr 3.614790e-04:  87%|████████▋ | 14183/16329 [1:59:24<17:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14183: train loss 1.12417. lr 3.614507e-04:  87%|████████▋ | 14183/16329 [1:59:24<17:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14183: train loss 1.12417. lr 3.614507e-04:  87%|████████▋ | 14184/16329 [1:59:24<17:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14184: train loss 1.10675. lr 3.614225e-04:  87%|████████▋ | 14184/16329 [1:59:25<17:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14184: train loss 1.10675. lr 3.614225e-04:  87%|████████▋ | 14185/16329 [1:59:25<17:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14185: train loss 1.14573. lr 3.613942e-04:  87%|████████▋ | 14185/16329 [1:59:25<17:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14185: train loss 1.14573. lr 3.613942e-04:  87%|████████▋ | 14186/16329 [1:59:25<18:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14186: train loss 1.10798. lr 3.613660e-04:  87%|████████▋ | 14186/16329 [1:59:26<18:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14186: train loss 1.10798. lr 3.613660e-04:  87%|████████▋ | 14187/16329 [1:59:26<18:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14187: train loss 1.11512. lr 3.613377e-04:  87%|████████▋ | 14187/16329 [1:59:26<18:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14187: train loss 1.11512. lr 3.613377e-04:  87%|████████▋ | 14188/16329 [1:59:26<18:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14188: train loss 1.15899. lr 3.613095e-04:  87%|████████▋ | 14188/16329 [1:59:27<18:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14188: train loss 1.15899. lr 3.613095e-04:  87%|████████▋ | 14189/16329 [1:59:27<18:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14189: train loss 1.13773. lr 3.612812e-04:  87%|████████▋ | 14189/16329 [1:59:27<18:15,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14189: train loss 1.13773. lr 3.612812e-04:  87%|████████▋ | 14190/16329 [1:59:27<18:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14190: train loss 1.14607. lr 3.612530e-04:  87%|████████▋ | 14190/16329 [1:59:28<18:08,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14190: train loss 1.14607. lr 3.612530e-04:  87%|████████▋ | 14191/16329 [1:59:28<18:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14191: train loss 1.14855. lr 3.612247e-04:  87%|████████▋ | 14191/16329 [1:59:29<18:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14191: train loss 1.14855. lr 3.612247e-04:  87%|████████▋ | 14192/16329 [1:59:29<19:54,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14192: train loss 1.15701. lr 3.611965e-04:  87%|████████▋ | 14192/16329 [1:59:29<19:54,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14192: train loss 1.15701. lr 3.611965e-04:  87%|████████▋ | 14193/16329 [1:59:29<19:13,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14193: train loss 1.09197. lr 3.611682e-04:  87%|████████▋ | 14193/16329 [1:59:30<19:13,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14193: train loss 1.09197. lr 3.611682e-04:  87%|████████▋ | 14194/16329 [1:59:30<18:48,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14194: train loss 1.13143. lr 3.611400e-04:  87%|████████▋ | 14194/16329 [1:59:30<18:48,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14194: train loss 1.13143. lr 3.611400e-04:  87%|████████▋ | 14195/16329 [1:59:30<18:25,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14195: train loss 1.09305. lr 3.611117e-04:  87%|████████▋ | 14195/16329 [1:59:31<18:25,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14195: train loss 1.09305. lr 3.611117e-04:  87%|████████▋ | 14196/16329 [1:59:31<18:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14196: train loss 1.13284. lr 3.610835e-04:  87%|████████▋ | 14196/16329 [1:59:31<18:13,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14196: train loss 1.13284. lr 3.610835e-04:  87%|████████▋ | 14197/16329 [1:59:31<18:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14197: train loss 1.13144. lr 3.610552e-04:  87%|████████▋ | 14197/16329 [1:59:32<18:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14197: train loss 1.13144. lr 3.610552e-04:  87%|████████▋ | 14198/16329 [1:59:32<17:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14198: train loss 1.15243. lr 3.610270e-04:  87%|████████▋ | 14198/16329 [1:59:32<17:54,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14198: train loss 1.15243. lr 3.610270e-04:  87%|████████▋ | 14199/16329 [1:59:32<17:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14199: train loss 1.13503. lr 3.609987e-04:  87%|████████▋ | 14199/16329 [1:59:33<17:47,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14199: train loss 1.13503. lr 3.609987e-04:  87%|████████▋ | 14200/16329 [1:59:33<17:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14200: train loss 1.14381. lr 3.609704e-04:  87%|████████▋ | 14200/16329 [1:59:33<17:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14200: train loss 1.14381. lr 3.609704e-04:  87%|████████▋ | 14201/16329 [1:59:33<17:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14201: train loss 1.12150. lr 3.609422e-04:  87%|████████▋ | 14201/16329 [1:59:34<17:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14201: train loss 1.12150. lr 3.609422e-04:  87%|████████▋ | 14202/16329 [1:59:34<17:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14202: train loss 1.13203. lr 3.609139e-04:  87%|████████▋ | 14202/16329 [1:59:34<17:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14202: train loss 1.13203. lr 3.609139e-04:  87%|████████▋ | 14203/16329 [1:59:34<17:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14203: train loss 1.14137. lr 3.608857e-04:  87%|████████▋ | 14203/16329 [1:59:35<17:58,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14203: train loss 1.14137. lr 3.608857e-04:  87%|████████▋ | 14204/16329 [1:59:35<18:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14204: train loss 1.09978. lr 3.608574e-04:  87%|████████▋ | 14204/16329 [1:59:35<18:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14204: train loss 1.09978. lr 3.608574e-04:  87%|████████▋ | 14205/16329 [1:59:35<18:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14205: train loss 1.11759. lr 3.608291e-04:  87%|████████▋ | 14205/16329 [1:59:36<18:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14205: train loss 1.11759. lr 3.608291e-04:  87%|████████▋ | 14206/16329 [1:59:36<18:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14206: train loss 1.17686. lr 3.608009e-04:  87%|████████▋ | 14206/16329 [1:59:36<18:13,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14206: train loss 1.17686. lr 3.608009e-04:  87%|████████▋ | 14207/16329 [1:59:36<18:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14207: train loss 1.12996. lr 3.607726e-04:  87%|████████▋ | 14207/16329 [1:59:37<18:09,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14207: train loss 1.12996. lr 3.607726e-04:  87%|████████▋ | 14208/16329 [1:59:37<18:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14208: train loss 1.12900. lr 3.607444e-04:  87%|████████▋ | 14208/16329 [1:59:37<18:03,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14208: train loss 1.12900. lr 3.607444e-04:  87%|████████▋ | 14209/16329 [1:59:37<17:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14209: train loss 1.16036. lr 3.607161e-04:  87%|████████▋ | 14209/16329 [1:59:38<17:59,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14209: train loss 1.16036. lr 3.607161e-04:  87%|████████▋ | 14210/16329 [1:59:38<17:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14210: train loss 1.14392. lr 3.606878e-04:  87%|████████▋ | 14210/16329 [1:59:38<17:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14210: train loss 1.14392. lr 3.606878e-04:  87%|████████▋ | 14211/16329 [1:59:38<17:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14211: train loss 1.12278. lr 3.606596e-04:  87%|████████▋ | 14211/16329 [1:59:39<17:47,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14211: train loss 1.12278. lr 3.606596e-04:  87%|████████▋ | 14212/16329 [1:59:39<17:39,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14212: train loss 1.11786. lr 3.606313e-04:  87%|████████▋ | 14212/16329 [1:59:39<17:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14212: train loss 1.11786. lr 3.606313e-04:  87%|████████▋ | 14213/16329 [1:59:39<17:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14213: train loss 1.11339. lr 3.606030e-04:  87%|████████▋ | 14213/16329 [1:59:40<17:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14213: train loss 1.11339. lr 3.606030e-04:  87%|████████▋ | 14214/16329 [1:59:40<17:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14214: train loss 1.11916. lr 3.605748e-04:  87%|████████▋ | 14214/16329 [1:59:40<17:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14214: train loss 1.11916. lr 3.605748e-04:  87%|████████▋ | 14215/16329 [1:59:40<17:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14215: train loss 1.13837. lr 3.605465e-04:  87%|████████▋ | 14215/16329 [1:59:41<17:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14215: train loss 1.13837. lr 3.605465e-04:  87%|████████▋ | 14216/16329 [1:59:41<17:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14216: train loss 1.12766. lr 3.605182e-04:  87%|████████▋ | 14216/16329 [1:59:41<17:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14216: train loss 1.12766. lr 3.605182e-04:  87%|████████▋ | 14217/16329 [1:59:41<17:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14217: train loss 1.12661. lr 3.604900e-04:  87%|████████▋ | 14217/16329 [1:59:42<17:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14217: train loss 1.12661. lr 3.604900e-04:  87%|████████▋ | 14218/16329 [1:59:42<17:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14218: train loss 1.12236. lr 3.604617e-04:  87%|████████▋ | 14218/16329 [1:59:42<17:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14218: train loss 1.12236. lr 3.604617e-04:  87%|████████▋ | 14219/16329 [1:59:42<19:39,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14219: train loss 1.11998. lr 3.604334e-04:  87%|████████▋ | 14219/16329 [1:59:43<19:39,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14219: train loss 1.11998. lr 3.604334e-04:  87%|████████▋ | 14220/16329 [1:59:43<19:00,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14220: train loss 1.14626. lr 3.604052e-04:  87%|████████▋ | 14220/16329 [1:59:43<19:00,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14220: train loss 1.14626. lr 3.604052e-04:  87%|████████▋ | 14221/16329 [1:59:43<18:29,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14221: train loss 1.15765. lr 3.603769e-04:  87%|████████▋ | 14221/16329 [1:59:44<18:29,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14221: train loss 1.15765. lr 3.603769e-04:  87%|████████▋ | 14222/16329 [1:59:44<18:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14222: train loss 1.11135. lr 3.603486e-04:  87%|████████▋ | 14222/16329 [1:59:44<18:08,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14222: train loss 1.11135. lr 3.603486e-04:  87%|████████▋ | 14223/16329 [1:59:44<17:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14223: train loss 1.10419. lr 3.603204e-04:  87%|████████▋ | 14223/16329 [1:59:45<17:55,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14223: train loss 1.10419. lr 3.603204e-04:  87%|████████▋ | 14224/16329 [1:59:45<17:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14224: train loss 1.16295. lr 3.602921e-04:  87%|████████▋ | 14224/16329 [1:59:45<17:43,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14224: train loss 1.16295. lr 3.602921e-04:  87%|████████▋ | 14225/16329 [1:59:45<17:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14225: train loss 1.15450. lr 3.602638e-04:  87%|████████▋ | 14225/16329 [1:59:46<17:38,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14225: train loss 1.15450. lr 3.602638e-04:  87%|████████▋ | 14226/16329 [1:59:46<17:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14226: train loss 1.11480. lr 3.602355e-04:  87%|████████▋ | 14226/16329 [1:59:46<17:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14226: train loss 1.11480. lr 3.602355e-04:  87%|████████▋ | 14227/16329 [1:59:46<17:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14227: train loss 1.10633. lr 3.602073e-04:  87%|████████▋ | 14227/16329 [1:59:47<17:30,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14227: train loss 1.10633. lr 3.602073e-04:  87%|████████▋ | 14228/16329 [1:59:47<17:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14228: train loss 1.15716. lr 3.601790e-04:  87%|████████▋ | 14228/16329 [1:59:47<17:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14228: train loss 1.15716. lr 3.601790e-04:  87%|████████▋ | 14229/16329 [1:59:47<17:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14229: train loss 1.12330. lr 3.601507e-04:  87%|████████▋ | 14229/16329 [1:59:48<17:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14229: train loss 1.12330. lr 3.601507e-04:  87%|████████▋ | 14230/16329 [1:59:48<17:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14230: train loss 1.12170. lr 3.601224e-04:  87%|████████▋ | 14230/16329 [1:59:48<17:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14230: train loss 1.12170. lr 3.601224e-04:  87%|████████▋ | 14231/16329 [1:59:48<17:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14231: train loss 1.14679. lr 3.600942e-04:  87%|████████▋ | 14231/16329 [1:59:49<17:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14231: train loss 1.14679. lr 3.600942e-04:  87%|████████▋ | 14232/16329 [1:59:49<17:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14232: train loss 1.11321. lr 3.600659e-04:  87%|████████▋ | 14232/16329 [1:59:49<17:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14232: train loss 1.11321. lr 3.600659e-04:  87%|████████▋ | 14233/16329 [1:59:49<17:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14233: train loss 1.09661. lr 3.600376e-04:  87%|████████▋ | 14233/16329 [1:59:50<17:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14233: train loss 1.09661. lr 3.600376e-04:  87%|████████▋ | 14234/16329 [1:59:50<17:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14234: train loss 1.18228. lr 3.600093e-04:  87%|████████▋ | 14234/16329 [1:59:50<17:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14234: train loss 1.18228. lr 3.600093e-04:  87%|████████▋ | 14235/16329 [1:59:50<17:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14235: train loss 1.11271. lr 3.599811e-04:  87%|████████▋ | 14235/16329 [1:59:51<17:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14235: train loss 1.11271. lr 3.599811e-04:  87%|████████▋ | 14236/16329 [1:59:51<17:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14236: train loss 1.15110. lr 3.599528e-04:  87%|████████▋ | 14236/16329 [1:59:51<17:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14236: train loss 1.15110. lr 3.599528e-04:  87%|████████▋ | 14237/16329 [1:59:51<17:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14237: train loss 1.12302. lr 3.599245e-04:  87%|████████▋ | 14237/16329 [1:59:52<17:17,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14237: train loss 1.12302. lr 3.599245e-04:  87%|████████▋ | 14238/16329 [1:59:52<17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14238: train loss 1.11680. lr 3.598962e-04:  87%|████████▋ | 14238/16329 [1:59:52<17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14238: train loss 1.11680. lr 3.598962e-04:  87%|████████▋ | 14239/16329 [1:59:52<17:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14239: train loss 1.11772. lr 3.598680e-04:  87%|████████▋ | 14239/16329 [1:59:53<17:16,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14239: train loss 1.11772. lr 3.598680e-04:  87%|████████▋ | 14240/16329 [1:59:53<17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14240: train loss 1.12462. lr 3.598397e-04:  87%|████████▋ | 14240/16329 [1:59:53<17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14240: train loss 1.12462. lr 3.598397e-04:  87%|████████▋ | 14241/16329 [1:59:53<17:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14241: train loss 1.13587. lr 3.598114e-04:  87%|████████▋ | 14241/16329 [1:59:54<17:13,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14241: train loss 1.13587. lr 3.598114e-04:  87%|████████▋ | 14242/16329 [1:59:54<17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14242: train loss 1.12846. lr 3.597831e-04:  87%|████████▋ | 14242/16329 [1:59:54<17:14,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14242: train loss 1.12846. lr 3.597831e-04:  87%|████████▋ | 14243/16329 [1:59:54<17:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14243: train loss 1.12383. lr 3.597548e-04:  87%|████████▋ | 14243/16329 [1:59:55<17:12,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14243: train loss 1.12383. lr 3.597548e-04:  87%|████████▋ | 14244/16329 [1:59:55<17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14244: train loss 1.14777. lr 3.597265e-04:  87%|████████▋ | 14244/16329 [1:59:55<17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14244: train loss 1.14777. lr 3.597265e-04:  87%|████████▋ | 14245/16329 [1:59:55<17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14245: train loss 1.14217. lr 3.596983e-04:  87%|████████▋ | 14245/16329 [1:59:56<17:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14245: train loss 1.14217. lr 3.596983e-04:  87%|████████▋ | 14246/16329 [1:59:56<17:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14246: train loss 1.12164. lr 3.596700e-04:  87%|████████▋ | 14246/16329 [1:59:56<17:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14246: train loss 1.12164. lr 3.596700e-04:  87%|████████▋ | 14247/16329 [1:59:56<17:13,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14247: train loss 1.15705. lr 3.596417e-04:  87%|████████▋ | 14247/16329 [1:59:57<17:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14247: train loss 1.15705. lr 3.596417e-04:  87%|████████▋ | 14248/16329 [1:59:57<17:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14248: train loss 1.13067. lr 3.596134e-04:  87%|████████▋ | 14248/16329 [1:59:57<17:11,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14248: train loss 1.13067. lr 3.596134e-04:  87%|████████▋ | 14249/16329 [1:59:57<17:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14249: train loss 1.12552. lr 3.595851e-04:  87%|████████▋ | 14249/16329 [1:59:58<17:09,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14249: train loss 1.12552. lr 3.595851e-04:  87%|████████▋ | 14250/16329 [1:59:58<17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14250: train loss 1.13642. lr 3.595568e-04:  87%|████████▋ | 14250/16329 [1:59:58<17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14250: train loss 1.13642. lr 3.595568e-04:  87%|████████▋ | 14251/16329 [1:59:58<17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14251: train loss 1.10949. lr 3.595286e-04:  87%|████████▋ | 14251/16329 [1:59:59<17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14251: train loss 1.10949. lr 3.595286e-04:  87%|████████▋ | 14252/16329 [1:59:59<17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14252: train loss 1.11537. lr 3.595003e-04:  87%|████████▋ | 14252/16329 [1:59:59<17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14252: train loss 1.11537. lr 3.595003e-04:  87%|████████▋ | 14253/16329 [1:59:59<17:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14253: train loss 1.10501. lr 3.594720e-04:  87%|████████▋ | 14253/16329 [2:00:00<17:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14253: train loss 1.10501. lr 3.594720e-04:  87%|████████▋ | 14254/16329 [2:00:00<17:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14254: train loss 1.12327. lr 3.594437e-04:  87%|████████▋ | 14254/16329 [2:00:00<17:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14254: train loss 1.12327. lr 3.594437e-04:  87%|████████▋ | 14255/16329 [2:00:00<17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14255: train loss 1.13776. lr 3.594154e-04:  87%|████████▋ | 14255/16329 [2:00:01<17:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14255: train loss 1.13776. lr 3.594154e-04:  87%|████████▋ | 14256/16329 [2:00:01<17:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14256: train loss 1.13710. lr 3.593871e-04:  87%|████████▋ | 14256/16329 [2:00:01<17:09,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14256: train loss 1.13710. lr 3.593871e-04:  87%|████████▋ | 14257/16329 [2:00:01<17:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14257: train loss 1.10719. lr 3.593588e-04:  87%|████████▋ | 14257/16329 [2:00:02<17:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14257: train loss 1.10719. lr 3.593588e-04:  87%|████████▋ | 14258/16329 [2:00:02<17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14258: train loss 1.12970. lr 3.593305e-04:  87%|████████▋ | 14258/16329 [2:00:02<17:11,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14258: train loss 1.12970. lr 3.593305e-04:  87%|████████▋ | 14259/16329 [2:00:02<19:16,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14259: train loss 1.10251. lr 3.593022e-04:  87%|████████▋ | 14259/16329 [2:00:03<19:16,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14259: train loss 1.10251. lr 3.593022e-04:  87%|████████▋ | 14260/16329 [2:00:03<18:38,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14260: train loss 1.12585. lr 3.592740e-04:  87%|████████▋ | 14260/16329 [2:00:03<18:38,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14260: train loss 1.12585. lr 3.592740e-04:  87%|████████▋ | 14261/16329 [2:00:03<18:10,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14261: train loss 1.13357. lr 3.592457e-04:  87%|████████▋ | 14261/16329 [2:00:04<18:10,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14261: train loss 1.13357. lr 3.592457e-04:  87%|████████▋ | 14262/16329 [2:00:04<17:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14262: train loss 1.13027. lr 3.592174e-04:  87%|████████▋ | 14262/16329 [2:00:04<17:49,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14262: train loss 1.13027. lr 3.592174e-04:  87%|████████▋ | 14263/16329 [2:00:04<17:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14263: train loss 1.09921. lr 3.591891e-04:  87%|████████▋ | 14263/16329 [2:00:05<17:36,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14263: train loss 1.09921. lr 3.591891e-04:  87%|████████▋ | 14264/16329 [2:00:05<17:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14264: train loss 1.09797. lr 3.591608e-04:  87%|████████▋ | 14264/16329 [2:00:05<17:22,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14264: train loss 1.09797. lr 3.591608e-04:  87%|████████▋ | 14265/16329 [2:00:05<17:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14265: train loss 1.16686. lr 3.591325e-04:  87%|████████▋ | 14265/16329 [2:00:06<17:18,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14265: train loss 1.16686. lr 3.591325e-04:  87%|████████▋ | 14266/16329 [2:00:06<17:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14266: train loss 1.12687. lr 3.591042e-04:  87%|████████▋ | 14266/16329 [2:00:06<17:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14266: train loss 1.12687. lr 3.591042e-04:  87%|████████▋ | 14267/16329 [2:00:06<17:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14267: train loss 1.14274. lr 3.590759e-04:  87%|████████▋ | 14267/16329 [2:00:07<17:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14267: train loss 1.14274. lr 3.590759e-04:  87%|████████▋ | 14268/16329 [2:00:07<17:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14268: train loss 1.15175. lr 3.590476e-04:  87%|████████▋ | 14268/16329 [2:00:07<17:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14268: train loss 1.15175. lr 3.590476e-04:  87%|████████▋ | 14269/16329 [2:00:07<17:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14269: train loss 1.11005. lr 3.590193e-04:  87%|████████▋ | 14269/16329 [2:00:08<17:01,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14269: train loss 1.11005. lr 3.590193e-04:  87%|████████▋ | 14270/16329 [2:00:08<17:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14270: train loss 1.12397. lr 3.589910e-04:  87%|████████▋ | 14270/16329 [2:00:08<17:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14270: train loss 1.12397. lr 3.589910e-04:  87%|████████▋ | 14271/16329 [2:00:08<17:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14271: train loss 1.12478. lr 3.589627e-04:  87%|████████▋ | 14271/16329 [2:00:09<17:00,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14271: train loss 1.12478. lr 3.589627e-04:  87%|████████▋ | 14272/16329 [2:00:09<17:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14272: train loss 1.14340. lr 3.589344e-04:  87%|████████▋ | 14272/16329 [2:00:09<17:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14272: train loss 1.14340. lr 3.589344e-04:  87%|████████▋ | 14273/16329 [2:00:09<17:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14273: train loss 1.12815. lr 3.589061e-04:  87%|████████▋ | 14273/16329 [2:00:10<17:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14273: train loss 1.12815. lr 3.589061e-04:  87%|████████▋ | 14274/16329 [2:00:10<17:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14274: train loss 1.12862. lr 3.588778e-04:  87%|████████▋ | 14274/16329 [2:00:10<17:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14274: train loss 1.12862. lr 3.588778e-04:  87%|████████▋ | 14275/16329 [2:00:10<17:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14275: train loss 1.14146. lr 3.588495e-04:  87%|████████▋ | 14275/16329 [2:00:11<17:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14275: train loss 1.14146. lr 3.588495e-04:  87%|████████▋ | 14276/16329 [2:00:11<16:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14276: train loss 1.11677. lr 3.588212e-04:  87%|████████▋ | 14276/16329 [2:00:11<16:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14276: train loss 1.11677. lr 3.588212e-04:  87%|████████▋ | 14277/16329 [2:00:11<16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14277: train loss 1.10514. lr 3.587929e-04:  87%|████████▋ | 14277/16329 [2:00:12<16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14277: train loss 1.10514. lr 3.587929e-04:  87%|████████▋ | 14278/16329 [2:00:12<16:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14278: train loss 1.10377. lr 3.587646e-04:  87%|████████▋ | 14278/16329 [2:00:12<16:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14278: train loss 1.10377. lr 3.587646e-04:  87%|████████▋ | 14279/16329 [2:00:12<16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14279: train loss 1.10435. lr 3.587363e-04:  87%|████████▋ | 14279/16329 [2:00:13<16:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14279: train loss 1.10435. lr 3.587363e-04:  87%|████████▋ | 14280/16329 [2:00:13<16:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14280: train loss 1.09940. lr 3.587080e-04:  87%|████████▋ | 14280/16329 [2:00:13<16:55,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14280: train loss 1.09940. lr 3.587080e-04:  87%|████████▋ | 14281/16329 [2:00:13<16:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14281: train loss 1.11426. lr 3.586797e-04:  87%|████████▋ | 14281/16329 [2:00:14<16:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14281: train loss 1.11426. lr 3.586797e-04:  87%|████████▋ | 14282/16329 [2:00:14<16:53,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14282: train loss 1.12491. lr 3.586514e-04:  87%|████████▋ | 14282/16329 [2:00:14<16:53,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14282: train loss 1.12491. lr 3.586514e-04:  87%|████████▋ | 14283/16329 [2:00:14<16:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14283: train loss 1.11752. lr 3.586231e-04:  87%|████████▋ | 14283/16329 [2:00:15<16:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14283: train loss 1.11752. lr 3.586231e-04:  87%|████████▋ | 14284/16329 [2:00:15<16:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14284: train loss 1.09571. lr 3.585948e-04:  87%|████████▋ | 14284/16329 [2:00:15<16:54,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14284: train loss 1.09571. lr 3.585948e-04:  87%|████████▋ | 14285/16329 [2:00:15<16:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14285: train loss 1.10787. lr 3.585665e-04:  87%|████████▋ | 14285/16329 [2:00:16<16:51,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14285: train loss 1.10787. lr 3.585665e-04:  87%|████████▋ | 14286/16329 [2:00:16<16:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14286: train loss 1.11348. lr 3.585382e-04:  87%|████████▋ | 14286/16329 [2:00:16<16:52,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14286: train loss 1.11348. lr 3.585382e-04:  87%|████████▋ | 14287/16329 [2:00:16<16:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14287: train loss 1.11962. lr 3.585099e-04:  87%|████████▋ | 14287/16329 [2:00:17<16:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14287: train loss 1.11962. lr 3.585099e-04:  88%|████████▊ | 14288/16329 [2:00:17<16:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14288: train loss 1.12286. lr 3.584816e-04:  88%|████████▊ | 14288/16329 [2:00:17<16:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14288: train loss 1.12286. lr 3.584816e-04:  88%|████████▊ | 14289/16329 [2:00:17<16:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14289: train loss 1.13594. lr 3.584533e-04:  88%|████████▊ | 14289/16329 [2:00:18<16:58,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14289: train loss 1.13594. lr 3.584533e-04:  88%|████████▊ | 14290/16329 [2:00:18<17:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14290: train loss 1.14264. lr 3.584250e-04:  88%|████████▊ | 14290/16329 [2:00:18<17:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14290: train loss 1.14264. lr 3.584250e-04:  88%|████████▊ | 14291/16329 [2:00:18<17:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14291: train loss 1.16562. lr 3.583967e-04:  88%|████████▊ | 14291/16329 [2:00:19<17:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14291: train loss 1.16562. lr 3.583967e-04:  88%|████████▊ | 14292/16329 [2:00:19<17:18,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14292: train loss 1.11180. lr 3.583684e-04:  88%|████████▊ | 14292/16329 [2:00:19<17:18,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14292: train loss 1.11180. lr 3.583684e-04:  88%|████████▊ | 14293/16329 [2:00:19<17:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14293: train loss 1.11038. lr 3.583400e-04:  88%|████████▊ | 14293/16329 [2:00:20<17:12,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14293: train loss 1.11038. lr 3.583400e-04:  88%|████████▊ | 14294/16329 [2:00:20<18:57,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14294: train loss 1.12907. lr 3.583117e-04:  88%|████████▊ | 14294/16329 [2:00:21<18:57,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14294: train loss 1.12907. lr 3.583117e-04:  88%|████████▊ | 14295/16329 [2:00:21<18:19,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14295: train loss 1.13992. lr 3.582834e-04:  88%|████████▊ | 14295/16329 [2:00:21<18:19,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14295: train loss 1.13992. lr 3.582834e-04:  88%|████████▊ | 14296/16329 [2:00:21<17:51,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14296: train loss 1.12918. lr 3.582551e-04:  88%|████████▊ | 14296/16329 [2:00:21<17:51,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14296: train loss 1.12918. lr 3.582551e-04:  88%|████████▊ | 14297/16329 [2:00:21<17:32,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14297: train loss 1.11314. lr 3.582268e-04:  88%|████████▊ | 14297/16329 [2:00:22<17:32,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14297: train loss 1.11314. lr 3.582268e-04:  88%|████████▊ | 14298/16329 [2:00:22<17:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14298: train loss 1.09414. lr 3.581985e-04:  88%|████████▊ | 14298/16329 [2:00:22<17:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14298: train loss 1.09414. lr 3.581985e-04:  88%|████████▊ | 14299/16329 [2:00:22<17:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14299: train loss 1.12471. lr 3.581702e-04:  88%|████████▊ | 14299/16329 [2:00:23<17:06,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14299: train loss 1.12471. lr 3.581702e-04:  88%|████████▊ | 14300/16329 [2:00:23<17:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14300: train loss 1.13552. lr 3.581419e-04:  88%|████████▊ | 14300/16329 [2:00:23<17:01,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14300: train loss 1.13552. lr 3.581419e-04:  88%|████████▊ | 14301/16329 [2:00:23<16:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14301: train loss 1.10978. lr 3.581136e-04:  88%|████████▊ | 14301/16329 [2:00:24<16:54,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14301: train loss 1.10978. lr 3.581136e-04:  88%|████████▊ | 14302/16329 [2:00:24<16:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14302: train loss 1.13937. lr 3.580852e-04:  88%|████████▊ | 14302/16329 [2:00:24<16:52,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14302: train loss 1.13937. lr 3.580852e-04:  88%|████████▊ | 14303/16329 [2:00:24<16:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14303: train loss 1.13371. lr 3.580569e-04:  88%|████████▊ | 14303/16329 [2:00:25<16:50,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14303: train loss 1.13371. lr 3.580569e-04:  88%|████████▊ | 14304/16329 [2:00:25<16:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14304: train loss 1.12141. lr 3.580286e-04:  88%|████████▊ | 14304/16329 [2:00:25<16:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14304: train loss 1.12141. lr 3.580286e-04:  88%|████████▊ | 14305/16329 [2:00:25<16:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14305: train loss 1.10890. lr 3.580003e-04:  88%|████████▊ | 14305/16329 [2:00:26<16:51,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14305: train loss 1.10890. lr 3.580003e-04:  88%|████████▊ | 14306/16329 [2:00:26<16:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14306: train loss 1.11910. lr 3.579720e-04:  88%|████████▊ | 14306/16329 [2:00:26<16:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14306: train loss 1.11910. lr 3.579720e-04:  88%|████████▊ | 14307/16329 [2:00:26<16:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14307: train loss 1.08979. lr 3.579437e-04:  88%|████████▊ | 14307/16329 [2:00:27<16:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14307: train loss 1.08979. lr 3.579437e-04:  88%|████████▊ | 14308/16329 [2:00:27<16:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14308: train loss 1.13000. lr 3.579153e-04:  88%|████████▊ | 14308/16329 [2:00:27<16:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14308: train loss 1.13000. lr 3.579153e-04:  88%|████████▊ | 14309/16329 [2:00:27<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14309: train loss 1.13228. lr 3.578870e-04:  88%|████████▊ | 14309/16329 [2:00:28<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14309: train loss 1.13228. lr 3.578870e-04:  88%|████████▊ | 14310/16329 [2:00:28<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14310: train loss 1.12140. lr 3.578587e-04:  88%|████████▊ | 14310/16329 [2:00:28<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14310: train loss 1.12140. lr 3.578587e-04:  88%|████████▊ | 14311/16329 [2:00:28<16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14311: train loss 1.09312. lr 3.578304e-04:  88%|████████▊ | 14311/16329 [2:00:29<16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14311: train loss 1.09312. lr 3.578304e-04:  88%|████████▊ | 14312/16329 [2:00:29<16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14312: train loss 1.11004. lr 3.578021e-04:  88%|████████▊ | 14312/16329 [2:00:29<16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14312: train loss 1.11004. lr 3.578021e-04:  88%|████████▊ | 14313/16329 [2:00:29<16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14313: train loss 1.10115. lr 3.577737e-04:  88%|████████▊ | 14313/16329 [2:00:30<16:38,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14313: train loss 1.10115. lr 3.577737e-04:  88%|████████▊ | 14314/16329 [2:00:30<16:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14314: train loss 1.11576. lr 3.577454e-04:  88%|████████▊ | 14314/16329 [2:00:30<16:39,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14314: train loss 1.11576. lr 3.577454e-04:  88%|████████▊ | 14315/16329 [2:00:30<16:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14315: train loss 1.12440. lr 3.577171e-04:  88%|████████▊ | 14315/16329 [2:00:31<16:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14315: train loss 1.12440. lr 3.577171e-04:  88%|████████▊ | 14316/16329 [2:00:31<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14316: train loss 1.12275. lr 3.576888e-04:  88%|████████▊ | 14316/16329 [2:00:31<16:43,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14316: train loss 1.12275. lr 3.576888e-04:  88%|████████▊ | 14317/16329 [2:00:31<16:44,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14317: train loss 1.12068. lr 3.576605e-04:  88%|████████▊ | 14317/16329 [2:00:32<16:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14317: train loss 1.12068. lr 3.576605e-04:  88%|████████▊ | 14318/16329 [2:00:32<16:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14318: train loss 1.12674. lr 3.576321e-04:  88%|████████▊ | 14318/16329 [2:00:33<16:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14318: train loss 1.12674. lr 3.576321e-04:  88%|████████▊ | 14319/16329 [2:00:33<18:26,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14319: train loss 1.14033. lr 3.576038e-04:  88%|████████▊ | 14319/16329 [2:00:33<18:26,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14319: train loss 1.14033. lr 3.576038e-04:  88%|████████▊ | 14320/16329 [2:00:33<17:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14320: train loss 1.11814. lr 3.575755e-04:  88%|████████▊ | 14320/16329 [2:00:34<17:50,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14320: train loss 1.11814. lr 3.575755e-04:  88%|████████▊ | 14321/16329 [2:00:34<17:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14321: train loss 1.11942. lr 3.575472e-04:  88%|████████▊ | 14321/16329 [2:00:34<17:27,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14321: train loss 1.11942. lr 3.575472e-04:  88%|████████▊ | 14322/16329 [2:00:34<17:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14322: train loss 1.10513. lr 3.575188e-04:  88%|████████▊ | 14322/16329 [2:00:35<17:11,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14322: train loss 1.10513. lr 3.575188e-04:  88%|████████▊ | 14323/16329 [2:00:35<16:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14323: train loss 1.12663. lr 3.574905e-04:  88%|████████▊ | 14323/16329 [2:00:35<16:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14323: train loss 1.12663. lr 3.574905e-04:  88%|████████▊ | 14324/16329 [2:00:35<16:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14324: train loss 1.16094. lr 3.574622e-04:  88%|████████▊ | 14324/16329 [2:00:36<16:53,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14324: train loss 1.16094. lr 3.574622e-04:  88%|████████▊ | 14325/16329 [2:00:36<16:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14325: train loss 1.14017. lr 3.574339e-04:  88%|████████▊ | 14325/16329 [2:00:36<16:46,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14325: train loss 1.14017. lr 3.574339e-04:  88%|████████▊ | 14326/16329 [2:00:36<16:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14326: train loss 1.15137. lr 3.574055e-04:  88%|████████▊ | 14326/16329 [2:00:37<16:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14326: train loss 1.15137. lr 3.574055e-04:  88%|████████▊ | 14327/16329 [2:00:37<16:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14327: train loss 1.13742. lr 3.573772e-04:  88%|████████▊ | 14327/16329 [2:00:37<16:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14327: train loss 1.13742. lr 3.573772e-04:  88%|████████▊ | 14328/16329 [2:00:37<16:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14328: train loss 1.12151. lr 3.573489e-04:  88%|████████▊ | 14328/16329 [2:00:38<16:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14328: train loss 1.12151. lr 3.573489e-04:  88%|████████▊ | 14329/16329 [2:00:38<16:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14329: train loss 1.11903. lr 3.573206e-04:  88%|████████▊ | 14329/16329 [2:00:38<16:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14329: train loss 1.11903. lr 3.573206e-04:  88%|████████▊ | 14330/16329 [2:00:38<16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14330: train loss 1.11207. lr 3.572922e-04:  88%|████████▊ | 14330/16329 [2:00:39<16:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14330: train loss 1.11207. lr 3.572922e-04:  88%|████████▊ | 14331/16329 [2:00:39<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14331: train loss 1.12715. lr 3.572639e-04:  88%|████████▊ | 14331/16329 [2:00:39<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14331: train loss 1.12715. lr 3.572639e-04:  88%|████████▊ | 14332/16329 [2:00:39<16:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14332: train loss 1.10981. lr 3.572356e-04:  88%|████████▊ | 14332/16329 [2:00:40<16:29,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14332: train loss 1.10981. lr 3.572356e-04:  88%|████████▊ | 14333/16329 [2:00:40<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14333: train loss 1.15509. lr 3.572072e-04:  88%|████████▊ | 14333/16329 [2:00:40<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14333: train loss 1.15509. lr 3.572072e-04:  88%|████████▊ | 14334/16329 [2:00:40<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14334: train loss 1.09558. lr 3.571789e-04:  88%|████████▊ | 14334/16329 [2:00:41<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14334: train loss 1.09558. lr 3.571789e-04:  88%|████████▊ | 14335/16329 [2:00:41<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14335: train loss 1.13781. lr 3.571506e-04:  88%|████████▊ | 14335/16329 [2:00:41<16:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14335: train loss 1.13781. lr 3.571506e-04:  88%|████████▊ | 14336/16329 [2:00:41<16:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14336: train loss 1.13767. lr 3.571222e-04:  88%|████████▊ | 14336/16329 [2:00:42<16:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14336: train loss 1.13767. lr 3.571222e-04:  88%|████████▊ | 14337/16329 [2:00:42<16:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14337: train loss 1.13030. lr 3.570939e-04:  88%|████████▊ | 14337/16329 [2:00:42<16:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14337: train loss 1.13030. lr 3.570939e-04:  88%|████████▊ | 14338/16329 [2:00:42<16:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14338: train loss 1.12497. lr 3.570656e-04:  88%|████████▊ | 14338/16329 [2:00:43<16:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14338: train loss 1.12497. lr 3.570656e-04:  88%|████████▊ | 14339/16329 [2:00:43<16:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14339: train loss 1.11064. lr 3.570372e-04:  88%|████████▊ | 14339/16329 [2:00:43<16:32,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14339: train loss 1.11064. lr 3.570372e-04:  88%|████████▊ | 14340/16329 [2:00:43<16:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14340: train loss 1.13242. lr 3.570089e-04:  88%|████████▊ | 14340/16329 [2:00:44<16:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14340: train loss 1.13242. lr 3.570089e-04:  88%|████████▊ | 14341/16329 [2:00:44<16:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14341: train loss 1.11714. lr 3.569806e-04:  88%|████████▊ | 14341/16329 [2:00:44<16:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14341: train loss 1.11714. lr 3.569806e-04:  88%|████████▊ | 14342/16329 [2:00:44<16:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14342: train loss 1.09837. lr 3.569522e-04:  88%|████████▊ | 14342/16329 [2:00:45<16:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14342: train loss 1.09837. lr 3.569522e-04:  88%|████████▊ | 14343/16329 [2:00:45<16:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14343: train loss 1.15277. lr 3.569239e-04:  88%|████████▊ | 14343/16329 [2:00:45<16:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14343: train loss 1.15277. lr 3.569239e-04:  88%|████████▊ | 14344/16329 [2:00:45<16:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14344: train loss 1.11575. lr 3.568956e-04:  88%|████████▊ | 14344/16329 [2:00:46<16:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14344: train loss 1.11575. lr 3.568956e-04:  88%|████████▊ | 14345/16329 [2:00:46<16:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14345: train loss 1.11739. lr 3.568672e-04:  88%|████████▊ | 14345/16329 [2:00:46<16:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14345: train loss 1.11739. lr 3.568672e-04:  88%|████████▊ | 14346/16329 [2:00:46<18:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14346: train loss 1.13495. lr 3.568389e-04:  88%|████████▊ | 14346/16329 [2:00:47<18:12,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14346: train loss 1.13495. lr 3.568389e-04:  88%|████████▊ | 14347/16329 [2:00:47<17:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14347: train loss 1.11799. lr 3.568106e-04:  88%|████████▊ | 14347/16329 [2:00:47<17:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14347: train loss 1.11799. lr 3.568106e-04:  88%|████████▊ | 14348/16329 [2:00:47<17:14,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14348: train loss 1.13003. lr 3.567822e-04:  88%|████████▊ | 14348/16329 [2:00:48<17:14,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14348: train loss 1.13003. lr 3.567822e-04:  88%|████████▊ | 14349/16329 [2:00:48<16:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14349: train loss 1.13297. lr 3.567539e-04:  88%|████████▊ | 14349/16329 [2:00:48<16:57,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14349: train loss 1.13297. lr 3.567539e-04:  88%|████████▊ | 14350/16329 [2:00:48<16:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14350: train loss 1.11897. lr 3.567255e-04:  88%|████████▊ | 14350/16329 [2:00:49<16:50,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14350: train loss 1.11897. lr 3.567255e-04:  88%|████████▊ | 14351/16329 [2:00:49<17:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14351: train loss 1.13504. lr 3.566972e-04:  88%|████████▊ | 14351/16329 [2:00:49<17:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14351: train loss 1.13504. lr 3.566972e-04:  88%|████████▊ | 14352/16329 [2:00:49<16:59,  1.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14352: train loss 1.13034. lr 3.566689e-04:  88%|████████▊ | 14352/16329 [2:00:50<16:59,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14352: train loss 1.13034. lr 3.566689e-04:  88%|████████▊ | 14353/16329 [2:00:50<16:55,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14353: train loss 1.12640. lr 3.566405e-04:  88%|████████▊ | 14353/16329 [2:00:50<16:55,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14353: train loss 1.12640. lr 3.566405e-04:  88%|████████▊ | 14354/16329 [2:00:50<16:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14354: train loss 1.13490. lr 3.566122e-04:  88%|████████▊ | 14354/16329 [2:00:51<16:50,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14354: train loss 1.13490. lr 3.566122e-04:  88%|████████▊ | 14355/16329 [2:00:51<16:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14355: train loss 1.13058. lr 3.565838e-04:  88%|████████▊ | 14355/16329 [2:00:51<16:46,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14355: train loss 1.13058. lr 3.565838e-04:  88%|████████▊ | 14356/16329 [2:00:51<16:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14356: train loss 1.12406. lr 3.565555e-04:  88%|████████▊ | 14356/16329 [2:00:52<16:39,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14356: train loss 1.12406. lr 3.565555e-04:  88%|████████▊ | 14357/16329 [2:00:52<16:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14357: train loss 1.09191. lr 3.565272e-04:  88%|████████▊ | 14357/16329 [2:00:52<16:31,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14357: train loss 1.09191. lr 3.565272e-04:  88%|████████▊ | 14358/16329 [2:00:52<16:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14358: train loss 1.11478. lr 3.564988e-04:  88%|████████▊ | 14358/16329 [2:00:53<16:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14358: train loss 1.11478. lr 3.564988e-04:  88%|████████▊ | 14359/16329 [2:00:53<16:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14359: train loss 1.15172. lr 3.564705e-04:  88%|████████▊ | 14359/16329 [2:00:53<16:26,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14359: train loss 1.15172. lr 3.564705e-04:  88%|████████▊ | 14360/16329 [2:00:53<16:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14360: train loss 1.10158. lr 3.564421e-04:  88%|████████▊ | 14360/16329 [2:00:54<16:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14360: train loss 1.10158. lr 3.564421e-04:  88%|████████▊ | 14361/16329 [2:00:54<16:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14361: train loss 1.11268. lr 3.564138e-04:  88%|████████▊ | 14361/16329 [2:00:54<16:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14361: train loss 1.11268. lr 3.564138e-04:  88%|████████▊ | 14362/16329 [2:00:54<16:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14362: train loss 1.10983. lr 3.563854e-04:  88%|████████▊ | 14362/16329 [2:00:55<16:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14362: train loss 1.10983. lr 3.563854e-04:  88%|████████▊ | 14363/16329 [2:00:55<16:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14363: train loss 1.11346. lr 3.563571e-04:  88%|████████▊ | 14363/16329 [2:00:55<16:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14363: train loss 1.11346. lr 3.563571e-04:  88%|████████▊ | 14364/16329 [2:00:55<16:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14364: train loss 1.13226. lr 3.563287e-04:  88%|████████▊ | 14364/16329 [2:00:56<16:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14364: train loss 1.13226. lr 3.563287e-04:  88%|████████▊ | 14365/16329 [2:00:56<16:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14365: train loss 1.11901. lr 3.563004e-04:  88%|████████▊ | 14365/16329 [2:00:56<16:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14365: train loss 1.11901. lr 3.563004e-04:  88%|████████▊ | 14366/16329 [2:00:56<16:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14366: train loss 1.12877. lr 3.562720e-04:  88%|████████▊ | 14366/16329 [2:00:57<16:34,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14366: train loss 1.12877. lr 3.562720e-04:  88%|████████▊ | 14367/16329 [2:00:57<16:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14367: train loss 1.14499. lr 3.562437e-04:  88%|████████▊ | 14367/16329 [2:00:57<16:43,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14367: train loss 1.14499. lr 3.562437e-04:  88%|████████▊ | 14368/16329 [2:00:57<16:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14368: train loss 1.13460. lr 3.562153e-04:  88%|████████▊ | 14368/16329 [2:00:58<16:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14368: train loss 1.13460. lr 3.562153e-04:  88%|████████▊ | 14369/16329 [2:00:58<16:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14369: train loss 1.11565. lr 3.561870e-04:  88%|████████▊ | 14369/16329 [2:00:58<16:45,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14369: train loss 1.11565. lr 3.561870e-04:  88%|████████▊ | 14370/16329 [2:00:58<16:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14370: train loss 1.10057. lr 3.561586e-04:  88%|████████▊ | 14370/16329 [2:00:59<16:38,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14370: train loss 1.10057. lr 3.561586e-04:  88%|████████▊ | 14371/16329 [2:00:59<16:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14371: train loss 1.13697. lr 3.561303e-04:  88%|████████▊ | 14371/16329 [2:00:59<16:35,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14371: train loss 1.13697. lr 3.561303e-04:  88%|████████▊ | 14372/16329 [2:00:59<16:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14372: train loss 1.13180. lr 3.561019e-04:  88%|████████▊ | 14372/16329 [2:01:00<16:29,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14372: train loss 1.13180. lr 3.561019e-04:  88%|████████▊ | 14373/16329 [2:01:00<16:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14373: train loss 1.10331. lr 3.560736e-04:  88%|████████▊ | 14373/16329 [2:01:00<16:24,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14373: train loss 1.10331. lr 3.560736e-04:  88%|████████▊ | 14374/16329 [2:01:00<16:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14374: train loss 1.10897. lr 3.560452e-04:  88%|████████▊ | 14374/16329 [2:01:01<16:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14374: train loss 1.10897. lr 3.560452e-04:  88%|████████▊ | 14375/16329 [2:01:01<16:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14375: train loss 1.14077. lr 3.560169e-04:  88%|████████▊ | 14375/16329 [2:01:01<16:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14375: train loss 1.14077. lr 3.560169e-04:  88%|████████▊ | 14376/16329 [2:01:01<16:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14376: train loss 1.12374. lr 3.559885e-04:  88%|████████▊ | 14376/16329 [2:01:02<16:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14376: train loss 1.12374. lr 3.559885e-04:  88%|████████▊ | 14377/16329 [2:01:02<16:52,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14377: train loss 1.13467. lr 3.559602e-04:  88%|████████▊ | 14377/16329 [2:01:02<16:52,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14377: train loss 1.13467. lr 3.559602e-04:  88%|████████▊ | 14378/16329 [2:01:02<17:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14378: train loss 1.13063. lr 3.559318e-04:  88%|████████▊ | 14378/16329 [2:01:03<17:02,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14378: train loss 1.13063. lr 3.559318e-04:  88%|████████▊ | 14379/16329 [2:01:03<17:01,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14379: train loss 1.11189. lr 3.559035e-04:  88%|████████▊ | 14379/16329 [2:01:03<17:01,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14379: train loss 1.11189. lr 3.559035e-04:  88%|████████▊ | 14380/16329 [2:01:03<16:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14380: train loss 1.10887. lr 3.558751e-04:  88%|████████▊ | 14380/16329 [2:01:04<16:42,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14380: train loss 1.10887. lr 3.558751e-04:  88%|████████▊ | 14381/16329 [2:01:04<16:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14381: train loss 1.11332. lr 3.558468e-04:  88%|████████▊ | 14381/16329 [2:01:04<16:31,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14381: train loss 1.11332. lr 3.558468e-04:  88%|████████▊ | 14382/16329 [2:01:04<16:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14382: train loss 1.13327. lr 3.558184e-04:  88%|████████▊ | 14382/16329 [2:01:05<16:23,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14382: train loss 1.13327. lr 3.558184e-04:  88%|████████▊ | 14383/16329 [2:01:05<16:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14383: train loss 1.12652. lr 3.557900e-04:  88%|████████▊ | 14383/16329 [2:01:05<16:17,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14383: train loss 1.12652. lr 3.557900e-04:  88%|████████▊ | 14384/16329 [2:01:05<16:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14384: train loss 1.11254. lr 3.557617e-04:  88%|████████▊ | 14384/16329 [2:01:06<16:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14384: train loss 1.11254. lr 3.557617e-04:  88%|████████▊ | 14385/16329 [2:01:06<16:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14385: train loss 1.13177. lr 3.557333e-04:  88%|████████▊ | 14385/16329 [2:01:07<16:11,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14385: train loss 1.13177. lr 3.557333e-04:  88%|████████▊ | 14386/16329 [2:01:07<17:52,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14386: train loss 1.13890. lr 3.557050e-04:  88%|████████▊ | 14386/16329 [2:01:07<17:52,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14386: train loss 1.13890. lr 3.557050e-04:  88%|████████▊ | 14387/16329 [2:01:07<17:20,  1.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14387: train loss 1.11595. lr 3.556766e-04:  88%|████████▊ | 14387/16329 [2:01:08<17:20,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14387: train loss 1.11595. lr 3.556766e-04:  88%|████████▊ | 14388/16329 [2:01:08<16:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14388: train loss 1.12608. lr 3.556483e-04:  88%|████████▊ | 14388/16329 [2:01:08<16:56,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14388: train loss 1.12608. lr 3.556483e-04:  88%|████████▊ | 14389/16329 [2:01:08<16:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14389: train loss 1.12991. lr 3.556199e-04:  88%|████████▊ | 14389/16329 [2:01:09<16:41,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14389: train loss 1.12991. lr 3.556199e-04:  88%|████████▊ | 14390/16329 [2:01:09<16:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14390: train loss 1.13715. lr 3.555915e-04:  88%|████████▊ | 14390/16329 [2:01:09<16:28,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14390: train loss 1.13715. lr 3.555915e-04:  88%|████████▊ | 14391/16329 [2:01:09<16:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14391: train loss 1.12445. lr 3.555632e-04:  88%|████████▊ | 14391/16329 [2:01:10<16:22,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14391: train loss 1.12445. lr 3.555632e-04:  88%|████████▊ | 14392/16329 [2:01:10<16:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14392: train loss 1.15007. lr 3.555348e-04:  88%|████████▊ | 14392/16329 [2:01:10<16:14,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14392: train loss 1.15007. lr 3.555348e-04:  88%|████████▊ | 14393/16329 [2:01:10<16:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14393: train loss 1.11422. lr 3.555065e-04:  88%|████████▊ | 14393/16329 [2:01:11<16:09,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14393: train loss 1.11422. lr 3.555065e-04:  88%|████████▊ | 14394/16329 [2:01:11<16:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14394: train loss 1.10379. lr 3.554781e-04:  88%|████████▊ | 14394/16329 [2:01:11<16:07,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14394: train loss 1.10379. lr 3.554781e-04:  88%|████████▊ | 14395/16329 [2:01:11<16:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14395: train loss 1.11647. lr 3.554497e-04:  88%|████████▊ | 14395/16329 [2:01:12<16:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14395: train loss 1.11647. lr 3.554497e-04:  88%|████████▊ | 14396/16329 [2:01:12<16:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14396: train loss 1.16194. lr 3.554214e-04:  88%|████████▊ | 14396/16329 [2:01:12<16:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14396: train loss 1.16194. lr 3.554214e-04:  88%|████████▊ | 14397/16329 [2:01:12<16:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14397: train loss 1.10761. lr 3.553930e-04:  88%|████████▊ | 14397/16329 [2:01:13<16:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14397: train loss 1.10761. lr 3.553930e-04:  88%|████████▊ | 14398/16329 [2:01:13<16:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14398: train loss 1.10920. lr 3.553646e-04:  88%|████████▊ | 14398/16329 [2:01:13<16:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14398: train loss 1.10920. lr 3.553646e-04:  88%|████████▊ | 14399/16329 [2:01:13<16:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14399: train loss 1.11068. lr 3.553363e-04:  88%|████████▊ | 14399/16329 [2:01:14<16:00,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14399: train loss 1.11068. lr 3.553363e-04:  88%|████████▊ | 14400/16329 [2:01:14<15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14400: train loss 1.13939. lr 3.553079e-04:  88%|████████▊ | 14400/16329 [2:01:14<15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14400: train loss 1.13939. lr 3.553079e-04:  88%|████████▊ | 14401/16329 [2:01:14<15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14401: train loss 1.10888. lr 3.552795e-04:  88%|████████▊ | 14401/16329 [2:01:15<15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14401: train loss 1.10888. lr 3.552795e-04:  88%|████████▊ | 14402/16329 [2:01:15<15:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14402: train loss 1.08384. lr 3.552512e-04:  88%|████████▊ | 14402/16329 [2:01:15<15:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14402: train loss 1.08384. lr 3.552512e-04:  88%|████████▊ | 14403/16329 [2:01:15<15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14403: train loss 1.13815. lr 3.552228e-04:  88%|████████▊ | 14403/16329 [2:01:16<15:59,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14403: train loss 1.13815. lr 3.552228e-04:  88%|████████▊ | 14404/16329 [2:01:16<15:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14404: train loss 1.11032. lr 3.551944e-04:  88%|████████▊ | 14404/16329 [2:01:16<15:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14404: train loss 1.11032. lr 3.551944e-04:  88%|████████▊ | 14405/16329 [2:01:16<16:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14405: train loss 1.10041. lr 3.551661e-04:  88%|████████▊ | 14405/16329 [2:01:17<16:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14405: train loss 1.10041. lr 3.551661e-04:  88%|████████▊ | 14406/16329 [2:01:17<15:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14406: train loss 1.10059. lr 3.551377e-04:  88%|████████▊ | 14406/16329 [2:01:17<15:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14406: train loss 1.10059. lr 3.551377e-04:  88%|████████▊ | 14407/16329 [2:01:17<15:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14407: train loss 1.09694. lr 3.551093e-04:  88%|████████▊ | 14407/16329 [2:01:17<15:57,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14407: train loss 1.09694. lr 3.551093e-04:  88%|████████▊ | 14408/16329 [2:01:17<15:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14408: train loss 1.11175. lr 3.550810e-04:  88%|████████▊ | 14408/16329 [2:01:18<15:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14408: train loss 1.11175. lr 3.550810e-04:  88%|████████▊ | 14409/16329 [2:01:18<15:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14409: train loss 1.14630. lr 3.550526e-04:  88%|████████▊ | 14409/16329 [2:01:18<15:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14409: train loss 1.14630. lr 3.550526e-04:  88%|████████▊ | 14410/16329 [2:01:18<15:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14410: train loss 1.13421. lr 3.550242e-04:  88%|████████▊ | 14410/16329 [2:01:19<15:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14410: train loss 1.13421. lr 3.550242e-04:  88%|████████▊ | 14411/16329 [2:01:19<15:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14411: train loss 1.13785. lr 3.549959e-04:  88%|████████▊ | 14411/16329 [2:01:19<15:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14411: train loss 1.13785. lr 3.549959e-04:  88%|████████▊ | 14412/16329 [2:01:19<15:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14412: train loss 1.09401. lr 3.549675e-04:  88%|████████▊ | 14412/16329 [2:01:20<15:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14412: train loss 1.09401. lr 3.549675e-04:  88%|████████▊ | 14413/16329 [2:01:20<15:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14413: train loss 1.11417. lr 3.549391e-04:  88%|████████▊ | 14413/16329 [2:01:20<15:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14413: train loss 1.11417. lr 3.549391e-04:  88%|████████▊ | 14414/16329 [2:01:20<15:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14414: train loss 1.12113. lr 3.549107e-04:  88%|████████▊ | 14414/16329 [2:01:21<15:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14414: train loss 1.12113. lr 3.549107e-04:  88%|████████▊ | 14415/16329 [2:01:21<15:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14415: train loss 1.10424. lr 3.548824e-04:  88%|████████▊ | 14415/16329 [2:01:21<15:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14415: train loss 1.10424. lr 3.548824e-04:  88%|████████▊ | 14416/16329 [2:01:21<15:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14416: train loss 1.14539. lr 3.548540e-04:  88%|████████▊ | 14416/16329 [2:01:22<15:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14416: train loss 1.14539. lr 3.548540e-04:  88%|████████▊ | 14417/16329 [2:01:22<15:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14417: train loss 1.10756. lr 3.548256e-04:  88%|████████▊ | 14417/16329 [2:01:22<15:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14417: train loss 1.10756. lr 3.548256e-04:  88%|████████▊ | 14418/16329 [2:01:22<15:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14418: train loss 1.11721. lr 3.547972e-04:  88%|████████▊ | 14418/16329 [2:01:23<15:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14418: train loss 1.11721. lr 3.547972e-04:  88%|████████▊ | 14419/16329 [2:01:23<15:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14419: train loss 1.12396. lr 3.547689e-04:  88%|████████▊ | 14419/16329 [2:01:23<15:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14419: train loss 1.12396. lr 3.547689e-04:  88%|████████▊ | 14420/16329 [2:01:23<15:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14420: train loss 1.12594. lr 3.547405e-04:  88%|████████▊ | 14420/16329 [2:01:24<15:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14420: train loss 1.12594. lr 3.547405e-04:  88%|████████▊ | 14421/16329 [2:01:24<17:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14421: train loss 1.12506. lr 3.547121e-04:  88%|████████▊ | 14421/16329 [2:01:25<17:27,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14421: train loss 1.12506. lr 3.547121e-04:  88%|████████▊ | 14422/16329 [2:01:25<16:56,  1.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14422: train loss 1.12234. lr 3.546837e-04:  88%|████████▊ | 14422/16329 [2:01:25<16:56,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14422: train loss 1.12234. lr 3.546837e-04:  88%|████████▊ | 14423/16329 [2:01:25<16:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14423: train loss 1.09492. lr 3.546554e-04:  88%|████████▊ | 14423/16329 [2:01:26<16:34,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14423: train loss 1.09492. lr 3.546554e-04:  88%|████████▊ | 14424/16329 [2:01:26<16:21,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14424: train loss 1.09450. lr 3.546270e-04:  88%|████████▊ | 14424/16329 [2:01:26<16:21,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14424: train loss 1.09450. lr 3.546270e-04:  88%|████████▊ | 14425/16329 [2:01:26<16:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14425: train loss 1.14586. lr 3.545986e-04:  88%|████████▊ | 14425/16329 [2:01:27<16:09,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14425: train loss 1.14586. lr 3.545986e-04:  88%|████████▊ | 14426/16329 [2:01:27<15:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14426: train loss 1.10093. lr 3.545702e-04:  88%|████████▊ | 14426/16329 [2:01:27<15:59,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14426: train loss 1.10093. lr 3.545702e-04:  88%|████████▊ | 14427/16329 [2:01:27<15:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14427: train loss 1.10490. lr 3.545418e-04:  88%|████████▊ | 14427/16329 [2:01:28<15:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14427: train loss 1.10490. lr 3.545418e-04:  88%|████████▊ | 14428/16329 [2:01:28<15:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14428: train loss 1.10793. lr 3.545135e-04:  88%|████████▊ | 14428/16329 [2:01:28<15:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14428: train loss 1.10793. lr 3.545135e-04:  88%|████████▊ | 14429/16329 [2:01:28<15:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14429: train loss 1.11690. lr 3.544851e-04:  88%|████████▊ | 14429/16329 [2:01:29<15:49,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14429: train loss 1.11690. lr 3.544851e-04:  88%|████████▊ | 14430/16329 [2:01:29<15:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14430: train loss 1.08158. lr 3.544567e-04:  88%|████████▊ | 14430/16329 [2:01:29<15:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14430: train loss 1.08158. lr 3.544567e-04:  88%|████████▊ | 14431/16329 [2:01:29<15:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14431: train loss 1.10521. lr 3.544283e-04:  88%|████████▊ | 14431/16329 [2:01:30<15:48,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14431: train loss 1.10521. lr 3.544283e-04:  88%|████████▊ | 14432/16329 [2:01:30<15:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14432: train loss 1.12879. lr 3.543999e-04:  88%|████████▊ | 14432/16329 [2:01:30<15:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14432: train loss 1.12879. lr 3.543999e-04:  88%|████████▊ | 14433/16329 [2:01:30<15:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14433: train loss 1.12296. lr 3.543716e-04:  88%|████████▊ | 14433/16329 [2:01:31<15:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14433: train loss 1.12296. lr 3.543716e-04:  88%|████████▊ | 14434/16329 [2:01:31<15:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14434: train loss 1.14487. lr 3.543432e-04:  88%|████████▊ | 14434/16329 [2:01:31<15:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14434: train loss 1.14487. lr 3.543432e-04:  88%|████████▊ | 14435/16329 [2:01:31<15:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14435: train loss 1.10499. lr 3.543148e-04:  88%|████████▊ | 14435/16329 [2:01:32<15:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14435: train loss 1.10499. lr 3.543148e-04:  88%|████████▊ | 14436/16329 [2:01:32<15:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14436: train loss 1.13770. lr 3.542864e-04:  88%|████████▊ | 14436/16329 [2:01:32<15:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14436: train loss 1.13770. lr 3.542864e-04:  88%|████████▊ | 14437/16329 [2:01:32<15:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14437: train loss 1.10055. lr 3.542580e-04:  88%|████████▊ | 14437/16329 [2:01:33<15:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14437: train loss 1.10055. lr 3.542580e-04:  88%|████████▊ | 14438/16329 [2:01:33<15:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14438: train loss 1.10491. lr 3.542296e-04:  88%|████████▊ | 14438/16329 [2:01:33<15:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14438: train loss 1.10491. lr 3.542296e-04:  88%|████████▊ | 14439/16329 [2:01:33<15:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14439: train loss 1.08587. lr 3.542013e-04:  88%|████████▊ | 14439/16329 [2:01:34<15:40,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14439: train loss 1.08587. lr 3.542013e-04:  88%|████████▊ | 14440/16329 [2:01:34<15:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14440: train loss 1.11311. lr 3.541729e-04:  88%|████████▊ | 14440/16329 [2:01:34<15:37,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14440: train loss 1.11311. lr 3.541729e-04:  88%|████████▊ | 14441/16329 [2:01:34<15:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14441: train loss 1.14566. lr 3.541445e-04:  88%|████████▊ | 14441/16329 [2:01:35<15:59,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14441: train loss 1.14566. lr 3.541445e-04:  88%|████████▊ | 14442/16329 [2:01:35<16:17,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14442: train loss 1.12239. lr 3.541161e-04:  88%|████████▊ | 14442/16329 [2:01:35<16:17,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14442: train loss 1.12239. lr 3.541161e-04:  88%|████████▊ | 14443/16329 [2:01:35<16:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14443: train loss 1.10720. lr 3.540877e-04:  88%|████████▊ | 14443/16329 [2:01:36<16:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14443: train loss 1.10720. lr 3.540877e-04:  88%|████████▊ | 14444/16329 [2:01:36<16:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14444: train loss 1.10193. lr 3.540593e-04:  88%|████████▊ | 14444/16329 [2:01:36<16:23,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14444: train loss 1.10193. lr 3.540593e-04:  88%|████████▊ | 14445/16329 [2:01:36<16:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14445: train loss 1.10376. lr 3.540309e-04:  88%|████████▊ | 14445/16329 [2:01:37<16:20,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14445: train loss 1.10376. lr 3.540309e-04:  88%|████████▊ | 14446/16329 [2:01:37<17:54,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 14446: train loss 1.11856. lr 3.540026e-04:  88%|████████▊ | 14446/16329 [2:01:37<17:54,  1.75it/s]\u001b[A\n",
      "epoch 1 iter 14446: train loss 1.11856. lr 3.540026e-04:  88%|████████▊ | 14447/16329 [2:01:37<17:18,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14447: train loss 1.14170. lr 3.539742e-04:  88%|████████▊ | 14447/16329 [2:01:38<17:18,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14447: train loss 1.14170. lr 3.539742e-04:  88%|████████▊ | 14448/16329 [2:01:38<16:49,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14448: train loss 1.11708. lr 3.539458e-04:  88%|████████▊ | 14448/16329 [2:01:38<16:49,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14448: train loss 1.11708. lr 3.539458e-04:  88%|████████▊ | 14449/16329 [2:01:38<16:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14449: train loss 1.13947. lr 3.539174e-04:  88%|████████▊ | 14449/16329 [2:01:39<16:25,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14449: train loss 1.13947. lr 3.539174e-04:  88%|████████▊ | 14450/16329 [2:01:39<16:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14450: train loss 1.13375. lr 3.538890e-04:  88%|████████▊ | 14450/16329 [2:01:39<16:07,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14450: train loss 1.13375. lr 3.538890e-04:  88%|████████▊ | 14451/16329 [2:01:39<15:56,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14451: train loss 1.09798. lr 3.538606e-04:  88%|████████▊ | 14451/16329 [2:01:40<15:56,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14451: train loss 1.09798. lr 3.538606e-04:  89%|████████▊ | 14452/16329 [2:01:40<15:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14452: train loss 1.09699. lr 3.538322e-04:  89%|████████▊ | 14452/16329 [2:01:40<15:45,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14452: train loss 1.09699. lr 3.538322e-04:  89%|████████▊ | 14453/16329 [2:01:40<15:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14453: train loss 1.12955. lr 3.538038e-04:  89%|████████▊ | 14453/16329 [2:01:41<15:43,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14453: train loss 1.12955. lr 3.538038e-04:  89%|████████▊ | 14454/16329 [2:01:41<15:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14454: train loss 1.10078. lr 3.537754e-04:  89%|████████▊ | 14454/16329 [2:01:41<15:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14454: train loss 1.10078. lr 3.537754e-04:  89%|████████▊ | 14455/16329 [2:01:41<15:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14455: train loss 1.13108. lr 3.537470e-04:  89%|████████▊ | 14455/16329 [2:01:42<15:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14455: train loss 1.13108. lr 3.537470e-04:  89%|████████▊ | 14456/16329 [2:01:42<15:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14456: train loss 1.13478. lr 3.537186e-04:  89%|████████▊ | 14456/16329 [2:01:42<15:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14456: train loss 1.13478. lr 3.537186e-04:  89%|████████▊ | 14457/16329 [2:01:42<15:28,  2.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14457: train loss 1.14919. lr 3.536902e-04:  89%|████████▊ | 14457/16329 [2:01:43<15:28,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14457: train loss 1.14919. lr 3.536902e-04:  89%|████████▊ | 14458/16329 [2:01:43<15:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14458: train loss 1.11518. lr 3.536618e-04:  89%|████████▊ | 14458/16329 [2:01:43<15:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14458: train loss 1.11518. lr 3.536618e-04:  89%|████████▊ | 14459/16329 [2:01:43<15:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14459: train loss 1.11387. lr 3.536335e-04:  89%|████████▊ | 14459/16329 [2:01:44<15:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14459: train loss 1.11387. lr 3.536335e-04:  89%|████████▊ | 14460/16329 [2:01:44<15:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14460: train loss 1.08290. lr 3.536051e-04:  89%|████████▊ | 14460/16329 [2:01:44<15:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14460: train loss 1.08290. lr 3.536051e-04:  89%|████████▊ | 14461/16329 [2:01:44<15:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14461: train loss 1.12050. lr 3.535767e-04:  89%|████████▊ | 14461/16329 [2:01:45<15:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14461: train loss 1.12050. lr 3.535767e-04:  89%|████████▊ | 14462/16329 [2:01:45<15:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14462: train loss 1.10321. lr 3.535483e-04:  89%|████████▊ | 14462/16329 [2:01:45<15:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14462: train loss 1.10321. lr 3.535483e-04:  89%|████████▊ | 14463/16329 [2:01:45<15:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14463: train loss 1.12951. lr 3.535199e-04:  89%|████████▊ | 14463/16329 [2:01:46<15:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14463: train loss 1.12951. lr 3.535199e-04:  89%|████████▊ | 14464/16329 [2:01:46<15:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14464: train loss 1.13131. lr 3.534915e-04:  89%|████████▊ | 14464/16329 [2:01:46<15:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14464: train loss 1.13131. lr 3.534915e-04:  89%|████████▊ | 14465/16329 [2:01:46<15:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14465: train loss 1.12844. lr 3.534631e-04:  89%|████████▊ | 14465/16329 [2:01:47<15:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14465: train loss 1.12844. lr 3.534631e-04:  89%|████████▊ | 14466/16329 [2:01:47<15:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14466: train loss 1.10777. lr 3.534347e-04:  89%|████████▊ | 14466/16329 [2:01:47<15:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14466: train loss 1.10777. lr 3.534347e-04:  89%|████████▊ | 14467/16329 [2:01:47<16:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14467: train loss 1.08781. lr 3.534063e-04:  89%|████████▊ | 14467/16329 [2:01:48<16:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14467: train loss 1.08781. lr 3.534063e-04:  89%|████████▊ | 14468/16329 [2:01:48<16:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14468: train loss 1.11686. lr 3.533779e-04:  89%|████████▊ | 14468/16329 [2:01:48<16:00,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14468: train loss 1.11686. lr 3.533779e-04:  89%|████████▊ | 14469/16329 [2:01:48<15:58,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14469: train loss 1.10502. lr 3.533495e-04:  89%|████████▊ | 14469/16329 [2:01:49<15:58,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14469: train loss 1.10502. lr 3.533495e-04:  89%|████████▊ | 14470/16329 [2:01:49<15:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14470: train loss 1.11241. lr 3.533211e-04:  89%|████████▊ | 14470/16329 [2:01:49<15:53,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14470: train loss 1.11241. lr 3.533211e-04:  89%|████████▊ | 14471/16329 [2:01:49<15:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14471: train loss 1.08653. lr 3.532927e-04:  89%|████████▊ | 14471/16329 [2:01:50<15:47,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14471: train loss 1.08653. lr 3.532927e-04:  89%|████████▊ | 14472/16329 [2:01:50<15:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14472: train loss 1.11708. lr 3.532643e-04:  89%|████████▊ | 14472/16329 [2:01:51<15:41,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14472: train loss 1.11708. lr 3.532643e-04:  89%|████████▊ | 14473/16329 [2:01:51<17:29,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14473: train loss 1.14648. lr 3.532359e-04:  89%|████████▊ | 14473/16329 [2:01:51<17:29,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14473: train loss 1.14648. lr 3.532359e-04:  89%|████████▊ | 14474/16329 [2:01:51<16:50,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14474: train loss 1.13793. lr 3.532075e-04:  89%|████████▊ | 14474/16329 [2:01:52<16:50,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14474: train loss 1.13793. lr 3.532075e-04:  89%|████████▊ | 14475/16329 [2:01:52<16:24,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14475: train loss 1.13300. lr 3.531791e-04:  89%|████████▊ | 14475/16329 [2:01:52<16:24,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14475: train loss 1.13300. lr 3.531791e-04:  89%|████████▊ | 14476/16329 [2:01:52<16:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14476: train loss 1.10710. lr 3.531507e-04:  89%|████████▊ | 14476/16329 [2:01:53<16:01,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14476: train loss 1.10710. lr 3.531507e-04:  89%|████████▊ | 14477/16329 [2:01:53<15:49,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14477: train loss 1.10938. lr 3.531223e-04:  89%|████████▊ | 14477/16329 [2:01:53<15:49,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14477: train loss 1.10938. lr 3.531223e-04:  89%|████████▊ | 14478/16329 [2:01:53<15:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14478: train loss 1.13506. lr 3.530939e-04:  89%|████████▊ | 14478/16329 [2:01:54<15:42,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14478: train loss 1.13506. lr 3.530939e-04:  89%|████████▊ | 14479/16329 [2:01:54<15:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14479: train loss 1.11269. lr 3.530654e-04:  89%|████████▊ | 14479/16329 [2:01:54<15:36,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14479: train loss 1.11269. lr 3.530654e-04:  89%|████████▊ | 14480/16329 [2:01:54<15:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14480: train loss 1.13135. lr 3.530370e-04:  89%|████████▊ | 14480/16329 [2:01:55<15:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14480: train loss 1.13135. lr 3.530370e-04:  89%|████████▊ | 14481/16329 [2:01:55<15:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14481: train loss 1.12169. lr 3.530086e-04:  89%|████████▊ | 14481/16329 [2:01:55<15:32,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14481: train loss 1.12169. lr 3.530086e-04:  89%|████████▊ | 14482/16329 [2:01:55<15:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14482: train loss 1.11790. lr 3.529802e-04:  89%|████████▊ | 14482/16329 [2:01:56<15:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14482: train loss 1.11790. lr 3.529802e-04:  89%|████████▊ | 14483/16329 [2:01:56<15:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14483: train loss 1.09902. lr 3.529518e-04:  89%|████████▊ | 14483/16329 [2:01:56<15:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14483: train loss 1.09902. lr 3.529518e-04:  89%|████████▊ | 14484/16329 [2:01:56<15:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14484: train loss 1.08644. lr 3.529234e-04:  89%|████████▊ | 14484/16329 [2:01:57<15:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14484: train loss 1.08644. lr 3.529234e-04:  89%|████████▊ | 14485/16329 [2:01:57<15:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14485: train loss 1.13161. lr 3.528950e-04:  89%|████████▊ | 14485/16329 [2:01:57<15:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14485: train loss 1.13161. lr 3.528950e-04:  89%|████████▊ | 14486/16329 [2:01:57<15:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14486: train loss 1.10684. lr 3.528666e-04:  89%|████████▊ | 14486/16329 [2:01:58<15:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14486: train loss 1.10684. lr 3.528666e-04:  89%|████████▊ | 14487/16329 [2:01:58<15:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14487: train loss 1.09901. lr 3.528382e-04:  89%|████████▊ | 14487/16329 [2:01:58<15:15,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14487: train loss 1.09901. lr 3.528382e-04:  89%|████████▊ | 14488/16329 [2:01:58<15:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14488: train loss 1.11027. lr 3.528098e-04:  89%|████████▊ | 14488/16329 [2:01:59<15:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14488: train loss 1.11027. lr 3.528098e-04:  89%|████████▊ | 14489/16329 [2:01:59<15:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14489: train loss 1.12814. lr 3.527814e-04:  89%|████████▊ | 14489/16329 [2:01:59<15:25,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14489: train loss 1.12814. lr 3.527814e-04:  89%|████████▊ | 14490/16329 [2:01:59<15:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14490: train loss 1.12208. lr 3.527530e-04:  89%|████████▊ | 14490/16329 [2:02:00<15:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14490: train loss 1.12208. lr 3.527530e-04:  89%|████████▊ | 14491/16329 [2:02:00<15:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14491: train loss 1.12716. lr 3.527245e-04:  89%|████████▊ | 14491/16329 [2:02:00<15:18,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14491: train loss 1.12716. lr 3.527245e-04:  89%|████████▉ | 14492/16329 [2:02:00<15:14,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14492: train loss 1.10780. lr 3.526961e-04:  89%|████████▉ | 14492/16329 [2:02:01<15:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14492: train loss 1.10780. lr 3.526961e-04:  89%|████████▉ | 14493/16329 [2:02:01<15:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14493: train loss 1.13147. lr 3.526677e-04:  89%|████████▉ | 14493/16329 [2:02:01<15:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14493: train loss 1.13147. lr 3.526677e-04:  89%|████████▉ | 14494/16329 [2:02:01<15:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14494: train loss 1.10487. lr 3.526393e-04:  89%|████████▉ | 14494/16329 [2:02:02<15:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14494: train loss 1.10487. lr 3.526393e-04:  89%|████████▉ | 14495/16329 [2:02:02<15:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14495: train loss 1.09432. lr 3.526109e-04:  89%|████████▉ | 14495/16329 [2:02:02<15:07,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14495: train loss 1.09432. lr 3.526109e-04:  89%|████████▉ | 14496/16329 [2:02:02<15:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14496: train loss 1.12368. lr 3.525825e-04:  89%|████████▉ | 14496/16329 [2:02:03<15:08,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14496: train loss 1.12368. lr 3.525825e-04:  89%|████████▉ | 14497/16329 [2:02:03<15:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14497: train loss 1.11600. lr 3.525541e-04:  89%|████████▉ | 14497/16329 [2:02:03<15:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14497: train loss 1.11600. lr 3.525541e-04:  89%|████████▉ | 14498/16329 [2:02:03<15:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14498: train loss 1.10086. lr 3.525257e-04:  89%|████████▉ | 14498/16329 [2:02:04<15:14,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14498: train loss 1.10086. lr 3.525257e-04:  89%|████████▉ | 14499/16329 [2:02:04<15:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14499: train loss 1.13744. lr 3.524972e-04:  89%|████████▉ | 14499/16329 [2:02:04<15:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14499: train loss 1.13744. lr 3.524972e-04:  89%|████████▉ | 14500/16329 [2:02:04<15:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14500: train loss 1.12545. lr 3.524688e-04:  89%|████████▉ | 14500/16329 [2:02:05<15:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14500: train loss 1.12545. lr 3.524688e-04:  89%|████████▉ | 14501/16329 [2:02:05<15:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14501: train loss 1.12793. lr 3.524404e-04:  89%|████████▉ | 14501/16329 [2:02:05<15:12,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14501: train loss 1.12793. lr 3.524404e-04:  89%|████████▉ | 14502/16329 [2:02:05<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14502: train loss 1.10753. lr 3.524120e-04:  89%|████████▉ | 14502/16329 [2:02:06<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14502: train loss 1.10753. lr 3.524120e-04:  89%|████████▉ | 14503/16329 [2:02:06<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14503: train loss 1.11314. lr 3.523836e-04:  89%|████████▉ | 14503/16329 [2:02:06<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14503: train loss 1.11314. lr 3.523836e-04:  89%|████████▉ | 14504/16329 [2:02:06<15:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14504: train loss 1.12229. lr 3.523552e-04:  89%|████████▉ | 14504/16329 [2:02:07<15:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14504: train loss 1.12229. lr 3.523552e-04:  89%|████████▉ | 14505/16329 [2:02:07<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14505: train loss 1.10239. lr 3.523267e-04:  89%|████████▉ | 14505/16329 [2:02:07<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14505: train loss 1.10239. lr 3.523267e-04:  89%|████████▉ | 14506/16329 [2:02:07<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14506: train loss 1.10808. lr 3.522983e-04:  89%|████████▉ | 14506/16329 [2:02:08<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14506: train loss 1.10808. lr 3.522983e-04:  89%|████████▉ | 14507/16329 [2:02:08<15:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14507: train loss 1.12239. lr 3.522699e-04:  89%|████████▉ | 14507/16329 [2:02:08<15:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14507: train loss 1.12239. lr 3.522699e-04:  89%|████████▉ | 14508/16329 [2:02:08<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14508: train loss 1.08573. lr 3.522415e-04:  89%|████████▉ | 14508/16329 [2:02:09<15:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14508: train loss 1.08573. lr 3.522415e-04:  89%|████████▉ | 14509/16329 [2:02:09<15:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14509: train loss 1.09639. lr 3.522131e-04:  89%|████████▉ | 14509/16329 [2:02:09<15:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14509: train loss 1.09639. lr 3.522131e-04:  89%|████████▉ | 14510/16329 [2:02:09<15:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14510: train loss 1.10029. lr 3.521847e-04:  89%|████████▉ | 14510/16329 [2:02:10<15:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14510: train loss 1.10029. lr 3.521847e-04:  89%|████████▉ | 14511/16329 [2:02:10<15:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14511: train loss 1.10276. lr 3.521562e-04:  89%|████████▉ | 14511/16329 [2:02:10<15:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14511: train loss 1.10276. lr 3.521562e-04:  89%|████████▉ | 14512/16329 [2:02:10<15:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14512: train loss 1.06543. lr 3.521278e-04:  89%|████████▉ | 14512/16329 [2:02:11<15:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14512: train loss 1.06543. lr 3.521278e-04:  89%|████████▉ | 14513/16329 [2:02:11<17:04,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14513: train loss 1.11229. lr 3.520994e-04:  89%|████████▉ | 14513/16329 [2:02:11<17:04,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14513: train loss 1.11229. lr 3.520994e-04:  89%|████████▉ | 14514/16329 [2:02:11<16:26,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14514: train loss 1.09723. lr 3.520710e-04:  89%|████████▉ | 14514/16329 [2:02:12<16:26,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14514: train loss 1.09723. lr 3.520710e-04:  89%|████████▉ | 14515/16329 [2:02:12<16:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14515: train loss 1.12260. lr 3.520425e-04:  89%|████████▉ | 14515/16329 [2:02:12<16:00,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14515: train loss 1.12260. lr 3.520425e-04:  89%|████████▉ | 14516/16329 [2:02:12<15:39,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14516: train loss 1.13496. lr 3.520141e-04:  89%|████████▉ | 14516/16329 [2:02:13<15:39,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14516: train loss 1.13496. lr 3.520141e-04:  89%|████████▉ | 14517/16329 [2:02:13<15:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14517: train loss 1.10598. lr 3.519857e-04:  89%|████████▉ | 14517/16329 [2:02:13<15:27,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14517: train loss 1.10598. lr 3.519857e-04:  89%|████████▉ | 14518/16329 [2:02:13<15:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14518: train loss 1.10797. lr 3.519573e-04:  89%|████████▉ | 14518/16329 [2:02:14<15:17,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14518: train loss 1.10797. lr 3.519573e-04:  89%|████████▉ | 14519/16329 [2:02:14<15:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14519: train loss 1.10799. lr 3.519288e-04:  89%|████████▉ | 14519/16329 [2:02:14<15:11,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14519: train loss 1.10799. lr 3.519288e-04:  89%|████████▉ | 14520/16329 [2:02:14<15:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14520: train loss 1.11489. lr 3.519004e-04:  89%|████████▉ | 14520/16329 [2:02:15<15:05,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14520: train loss 1.11489. lr 3.519004e-04:  89%|████████▉ | 14521/16329 [2:02:15<15:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14521: train loss 1.10057. lr 3.518720e-04:  89%|████████▉ | 14521/16329 [2:02:15<15:01,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14521: train loss 1.10057. lr 3.518720e-04:  89%|████████▉ | 14522/16329 [2:02:15<14:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14522: train loss 1.15286. lr 3.518436e-04:  89%|████████▉ | 14522/16329 [2:02:16<14:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14522: train loss 1.15286. lr 3.518436e-04:  89%|████████▉ | 14523/16329 [2:02:16<14:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14523: train loss 1.08503. lr 3.518151e-04:  89%|████████▉ | 14523/16329 [2:02:16<14:56,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14523: train loss 1.08503. lr 3.518151e-04:  89%|████████▉ | 14524/16329 [2:02:16<14:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14524: train loss 1.09449. lr 3.517867e-04:  89%|████████▉ | 14524/16329 [2:02:17<14:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14524: train loss 1.09449. lr 3.517867e-04:  89%|████████▉ | 14525/16329 [2:02:17<14:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14525: train loss 1.12331. lr 3.517583e-04:  89%|████████▉ | 14525/16329 [2:02:17<14:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14525: train loss 1.12331. lr 3.517583e-04:  89%|████████▉ | 14526/16329 [2:02:17<14:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14526: train loss 1.07591. lr 3.517299e-04:  89%|████████▉ | 14526/16329 [2:02:18<14:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14526: train loss 1.07591. lr 3.517299e-04:  89%|████████▉ | 14527/16329 [2:02:18<14:55,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14527: train loss 1.11119. lr 3.517014e-04:  89%|████████▉ | 14527/16329 [2:02:18<14:55,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14527: train loss 1.11119. lr 3.517014e-04:  89%|████████▉ | 14528/16329 [2:02:18<14:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14528: train loss 1.11851. lr 3.516730e-04:  89%|████████▉ | 14528/16329 [2:02:19<14:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14528: train loss 1.11851. lr 3.516730e-04:  89%|████████▉ | 14529/16329 [2:02:19<14:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14529: train loss 1.12403. lr 3.516446e-04:  89%|████████▉ | 14529/16329 [2:02:19<14:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14529: train loss 1.12403. lr 3.516446e-04:  89%|████████▉ | 14530/16329 [2:02:19<14:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14530: train loss 1.11307. lr 3.516161e-04:  89%|████████▉ | 14530/16329 [2:02:20<14:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14530: train loss 1.11307. lr 3.516161e-04:  89%|████████▉ | 14531/16329 [2:02:20<14:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14531: train loss 1.08817. lr 3.515877e-04:  89%|████████▉ | 14531/16329 [2:02:20<14:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14531: train loss 1.08817. lr 3.515877e-04:  89%|████████▉ | 14532/16329 [2:02:20<14:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14532: train loss 1.10527. lr 3.515593e-04:  89%|████████▉ | 14532/16329 [2:02:21<14:50,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14532: train loss 1.10527. lr 3.515593e-04:  89%|████████▉ | 14533/16329 [2:02:21<14:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14533: train loss 1.11158. lr 3.515309e-04:  89%|████████▉ | 14533/16329 [2:02:21<14:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14533: train loss 1.11158. lr 3.515309e-04:  89%|████████▉ | 14534/16329 [2:02:21<14:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14534: train loss 1.11866. lr 3.515024e-04:  89%|████████▉ | 14534/16329 [2:02:22<14:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14534: train loss 1.11866. lr 3.515024e-04:  89%|████████▉ | 14535/16329 [2:02:22<14:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14535: train loss 1.14172. lr 3.514740e-04:  89%|████████▉ | 14535/16329 [2:02:22<14:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14535: train loss 1.14172. lr 3.514740e-04:  89%|████████▉ | 14536/16329 [2:02:22<14:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14536: train loss 1.13178. lr 3.514456e-04:  89%|████████▉ | 14536/16329 [2:02:23<14:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14536: train loss 1.13178. lr 3.514456e-04:  89%|████████▉ | 14537/16329 [2:02:23<14:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14537: train loss 1.11161. lr 3.514171e-04:  89%|████████▉ | 14537/16329 [2:02:23<14:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14537: train loss 1.11161. lr 3.514171e-04:  89%|████████▉ | 14538/16329 [2:02:23<14:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14538: train loss 1.12518. lr 3.513887e-04:  89%|████████▉ | 14538/16329 [2:02:24<14:50,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14538: train loss 1.12518. lr 3.513887e-04:  89%|████████▉ | 14539/16329 [2:02:24<14:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14539: train loss 1.11380. lr 3.513603e-04:  89%|████████▉ | 14539/16329 [2:02:24<14:47,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14539: train loss 1.11380. lr 3.513603e-04:  89%|████████▉ | 14540/16329 [2:02:24<14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14540: train loss 1.12763. lr 3.513318e-04:  89%|████████▉ | 14540/16329 [2:02:25<14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14540: train loss 1.12763. lr 3.513318e-04:  89%|████████▉ | 14541/16329 [2:02:25<14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14541: train loss 1.08743. lr 3.513034e-04:  89%|████████▉ | 14541/16329 [2:02:25<14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14541: train loss 1.08743. lr 3.513034e-04:  89%|████████▉ | 14542/16329 [2:02:25<14:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14542: train loss 1.11857. lr 3.512750e-04:  89%|████████▉ | 14542/16329 [2:02:26<14:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14542: train loss 1.11857. lr 3.512750e-04:  89%|████████▉ | 14543/16329 [2:02:26<14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14543: train loss 1.08138. lr 3.512465e-04:  89%|████████▉ | 14543/16329 [2:02:26<14:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14543: train loss 1.08138. lr 3.512465e-04:  89%|████████▉ | 14544/16329 [2:02:26<14:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14544: train loss 1.08248. lr 3.512181e-04:  89%|████████▉ | 14544/16329 [2:02:27<14:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14544: train loss 1.08248. lr 3.512181e-04:  89%|████████▉ | 14545/16329 [2:02:27<14:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14545: train loss 1.10854. lr 3.511896e-04:  89%|████████▉ | 14545/16329 [2:02:27<14:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14545: train loss 1.10854. lr 3.511896e-04:  89%|████████▉ | 14546/16329 [2:02:27<14:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14546: train loss 1.08781. lr 3.511612e-04:  89%|████████▉ | 14546/16329 [2:02:28<14:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14546: train loss 1.08781. lr 3.511612e-04:  89%|████████▉ | 14547/16329 [2:02:28<14:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14547: train loss 1.08714. lr 3.511328e-04:  89%|████████▉ | 14547/16329 [2:02:28<14:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14547: train loss 1.08714. lr 3.511328e-04:  89%|████████▉ | 14548/16329 [2:02:28<16:21,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14548: train loss 1.08575. lr 3.511043e-04:  89%|████████▉ | 14548/16329 [2:02:29<16:21,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14548: train loss 1.08575. lr 3.511043e-04:  89%|████████▉ | 14549/16329 [2:02:29<15:53,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14549: train loss 1.08495. lr 3.510759e-04:  89%|████████▉ | 14549/16329 [2:02:29<15:53,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14549: train loss 1.08495. lr 3.510759e-04:  89%|████████▉ | 14550/16329 [2:02:29<15:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14550: train loss 1.13832. lr 3.510475e-04:  89%|████████▉ | 14550/16329 [2:02:30<15:31,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14550: train loss 1.13832. lr 3.510475e-04:  89%|████████▉ | 14551/16329 [2:02:30<15:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14551: train loss 1.13270. lr 3.510190e-04:  89%|████████▉ | 14551/16329 [2:02:30<15:16,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14551: train loss 1.13270. lr 3.510190e-04:  89%|████████▉ | 14552/16329 [2:02:30<15:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14552: train loss 1.08976. lr 3.509906e-04:  89%|████████▉ | 14552/16329 [2:02:31<15:03,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14552: train loss 1.08976. lr 3.509906e-04:  89%|████████▉ | 14553/16329 [2:02:31<14:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14553: train loss 1.12839. lr 3.509621e-04:  89%|████████▉ | 14553/16329 [2:02:31<14:57,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14553: train loss 1.12839. lr 3.509621e-04:  89%|████████▉ | 14554/16329 [2:02:31<14:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14554: train loss 1.09503. lr 3.509337e-04:  89%|████████▉ | 14554/16329 [2:02:32<14:53,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14554: train loss 1.09503. lr 3.509337e-04:  89%|████████▉ | 14555/16329 [2:02:32<14:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14555: train loss 1.07594. lr 3.509053e-04:  89%|████████▉ | 14555/16329 [2:02:32<14:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14555: train loss 1.07594. lr 3.509053e-04:  89%|████████▉ | 14556/16329 [2:02:32<14:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14556: train loss 1.09839. lr 3.508768e-04:  89%|████████▉ | 14556/16329 [2:02:33<14:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14556: train loss 1.09839. lr 3.508768e-04:  89%|████████▉ | 14557/16329 [2:02:33<14:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14557: train loss 1.12071. lr 3.508484e-04:  89%|████████▉ | 14557/16329 [2:02:33<14:48,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14557: train loss 1.12071. lr 3.508484e-04:  89%|████████▉ | 14558/16329 [2:02:33<14:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14558: train loss 1.13678. lr 3.508199e-04:  89%|████████▉ | 14558/16329 [2:02:34<14:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14558: train loss 1.13678. lr 3.508199e-04:  89%|████████▉ | 14559/16329 [2:02:34<14:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14559: train loss 1.11518. lr 3.507915e-04:  89%|████████▉ | 14559/16329 [2:02:34<14:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14559: train loss 1.11518. lr 3.507915e-04:  89%|████████▉ | 14560/16329 [2:02:34<14:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14560: train loss 1.10931. lr 3.507630e-04:  89%|████████▉ | 14560/16329 [2:02:35<14:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14560: train loss 1.10931. lr 3.507630e-04:  89%|████████▉ | 14561/16329 [2:02:35<14:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14561: train loss 1.11403. lr 3.507346e-04:  89%|████████▉ | 14561/16329 [2:02:35<14:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14561: train loss 1.11403. lr 3.507346e-04:  89%|████████▉ | 14562/16329 [2:02:35<14:44,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14562: train loss 1.09118. lr 3.507061e-04:  89%|████████▉ | 14562/16329 [2:02:36<14:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14562: train loss 1.09118. lr 3.507061e-04:  89%|████████▉ | 14563/16329 [2:02:36<14:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14563: train loss 1.11528. lr 3.506777e-04:  89%|████████▉ | 14563/16329 [2:02:36<14:49,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14563: train loss 1.11528. lr 3.506777e-04:  89%|████████▉ | 14564/16329 [2:02:36<14:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14564: train loss 1.08966. lr 3.506493e-04:  89%|████████▉ | 14564/16329 [2:02:37<14:50,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14564: train loss 1.08966. lr 3.506493e-04:  89%|████████▉ | 14565/16329 [2:02:37<14:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14565: train loss 1.07801. lr 3.506208e-04:  89%|████████▉ | 14565/16329 [2:02:37<14:45,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14565: train loss 1.07801. lr 3.506208e-04:  89%|████████▉ | 14566/16329 [2:02:37<14:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14566: train loss 1.10660. lr 3.505924e-04:  89%|████████▉ | 14566/16329 [2:02:38<14:43,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14566: train loss 1.10660. lr 3.505924e-04:  89%|████████▉ | 14567/16329 [2:02:38<14:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14567: train loss 1.10781. lr 3.505639e-04:  89%|████████▉ | 14567/16329 [2:02:38<14:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14567: train loss 1.10781. lr 3.505639e-04:  89%|████████▉ | 14568/16329 [2:02:38<14:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14568: train loss 1.10348. lr 3.505355e-04:  89%|████████▉ | 14568/16329 [2:02:39<14:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14568: train loss 1.10348. lr 3.505355e-04:  89%|████████▉ | 14569/16329 [2:02:39<14:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14569: train loss 1.12445. lr 3.505070e-04:  89%|████████▉ | 14569/16329 [2:02:39<14:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14569: train loss 1.12445. lr 3.505070e-04:  89%|████████▉ | 14570/16329 [2:02:39<14:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14570: train loss 1.13133. lr 3.504786e-04:  89%|████████▉ | 14570/16329 [2:02:40<14:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14570: train loss 1.13133. lr 3.504786e-04:  89%|████████▉ | 14571/16329 [2:02:40<14:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14571: train loss 1.13592. lr 3.504501e-04:  89%|████████▉ | 14571/16329 [2:02:40<14:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14571: train loss 1.13592. lr 3.504501e-04:  89%|████████▉ | 14572/16329 [2:02:40<14:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14572: train loss 1.09457. lr 3.504217e-04:  89%|████████▉ | 14572/16329 [2:02:41<14:31,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14572: train loss 1.09457. lr 3.504217e-04:  89%|████████▉ | 14573/16329 [2:02:41<16:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14573: train loss 1.09849. lr 3.503932e-04:  89%|████████▉ | 14573/16329 [2:02:41<16:06,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14573: train loss 1.09849. lr 3.503932e-04:  89%|████████▉ | 14574/16329 [2:02:41<15:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14574: train loss 1.13563. lr 3.503648e-04:  89%|████████▉ | 14574/16329 [2:02:42<15:38,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14574: train loss 1.13563. lr 3.503648e-04:  89%|████████▉ | 14575/16329 [2:02:42<15:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14575: train loss 1.13840. lr 3.503363e-04:  89%|████████▉ | 14575/16329 [2:02:42<15:14,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14575: train loss 1.13840. lr 3.503363e-04:  89%|████████▉ | 14576/16329 [2:02:42<15:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14576: train loss 1.08572. lr 3.503079e-04:  89%|████████▉ | 14576/16329 [2:02:43<15:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14576: train loss 1.08572. lr 3.503079e-04:  89%|████████▉ | 14577/16329 [2:02:43<14:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14577: train loss 1.12835. lr 3.502794e-04:  89%|████████▉ | 14577/16329 [2:02:43<14:52,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14577: train loss 1.12835. lr 3.502794e-04:  89%|████████▉ | 14578/16329 [2:02:43<14:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14578: train loss 1.08299. lr 3.502510e-04:  89%|████████▉ | 14578/16329 [2:02:44<14:46,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14578: train loss 1.08299. lr 3.502510e-04:  89%|████████▉ | 14579/16329 [2:02:44<14:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14579: train loss 1.09840. lr 3.502225e-04:  89%|████████▉ | 14579/16329 [2:02:44<14:40,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14579: train loss 1.09840. lr 3.502225e-04:  89%|████████▉ | 14580/16329 [2:02:44<14:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14580: train loss 1.11471. lr 3.501941e-04:  89%|████████▉ | 14580/16329 [2:02:45<14:34,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14580: train loss 1.11471. lr 3.501941e-04:  89%|████████▉ | 14581/16329 [2:02:45<14:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14581: train loss 1.10078. lr 3.501656e-04:  89%|████████▉ | 14581/16329 [2:02:45<14:33,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14581: train loss 1.10078. lr 3.501656e-04:  89%|████████▉ | 14582/16329 [2:02:45<14:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14582: train loss 1.08868. lr 3.501372e-04:  89%|████████▉ | 14582/16329 [2:02:46<14:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14582: train loss 1.08868. lr 3.501372e-04:  89%|████████▉ | 14583/16329 [2:02:46<14:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14583: train loss 1.12994. lr 3.501087e-04:  89%|████████▉ | 14583/16329 [2:02:46<14:31,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14583: train loss 1.12994. lr 3.501087e-04:  89%|████████▉ | 14584/16329 [2:02:46<14:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14584: train loss 1.08370. lr 3.500802e-04:  89%|████████▉ | 14584/16329 [2:02:47<14:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14584: train loss 1.08370. lr 3.500802e-04:  89%|████████▉ | 14585/16329 [2:02:47<14:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14585: train loss 1.12253. lr 3.500518e-04:  89%|████████▉ | 14585/16329 [2:02:47<14:28,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14585: train loss 1.12253. lr 3.500518e-04:  89%|████████▉ | 14586/16329 [2:02:47<14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14586: train loss 1.09248. lr 3.500233e-04:  89%|████████▉ | 14586/16329 [2:02:48<14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14586: train loss 1.09248. lr 3.500233e-04:  89%|████████▉ | 14587/16329 [2:02:48<14:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14587: train loss 1.11370. lr 3.499949e-04:  89%|████████▉ | 14587/16329 [2:02:48<14:24,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14587: train loss 1.11370. lr 3.499949e-04:  89%|████████▉ | 14588/16329 [2:02:48<14:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14588: train loss 1.11222. lr 3.499664e-04:  89%|████████▉ | 14588/16329 [2:02:49<14:23,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14588: train loss 1.11222. lr 3.499664e-04:  89%|████████▉ | 14589/16329 [2:02:49<14:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14589: train loss 1.10558. lr 3.499380e-04:  89%|████████▉ | 14589/16329 [2:02:49<14:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14589: train loss 1.10558. lr 3.499380e-04:  89%|████████▉ | 14590/16329 [2:02:49<14:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14590: train loss 1.12300. lr 3.499095e-04:  89%|████████▉ | 14590/16329 [2:02:50<14:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14590: train loss 1.12300. lr 3.499095e-04:  89%|████████▉ | 14591/16329 [2:02:50<14:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14591: train loss 1.08368. lr 3.498810e-04:  89%|████████▉ | 14591/16329 [2:02:50<14:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14591: train loss 1.08368. lr 3.498810e-04:  89%|████████▉ | 14592/16329 [2:02:50<14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14592: train loss 1.09842. lr 3.498526e-04:  89%|████████▉ | 14592/16329 [2:02:51<14:26,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14592: train loss 1.09842. lr 3.498526e-04:  89%|████████▉ | 14593/16329 [2:02:51<14:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14593: train loss 1.08334. lr 3.498241e-04:  89%|████████▉ | 14593/16329 [2:02:51<14:24,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14593: train loss 1.08334. lr 3.498241e-04:  89%|████████▉ | 14594/16329 [2:02:51<14:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14594: train loss 1.09135. lr 3.497957e-04:  89%|████████▉ | 14594/16329 [2:02:52<14:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14594: train loss 1.09135. lr 3.497957e-04:  89%|████████▉ | 14595/16329 [2:02:52<14:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14595: train loss 1.11149. lr 3.497672e-04:  89%|████████▉ | 14595/16329 [2:02:52<14:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14595: train loss 1.11149. lr 3.497672e-04:  89%|████████▉ | 14596/16329 [2:02:52<14:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14596: train loss 1.13326. lr 3.497387e-04:  89%|████████▉ | 14596/16329 [2:02:53<14:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14596: train loss 1.13326. lr 3.497387e-04:  89%|████████▉ | 14597/16329 [2:02:53<14:24,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14597: train loss 1.12235. lr 3.497103e-04:  89%|████████▉ | 14597/16329 [2:02:53<14:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14597: train loss 1.12235. lr 3.497103e-04:  89%|████████▉ | 14598/16329 [2:02:53<14:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14598: train loss 1.12944. lr 3.496818e-04:  89%|████████▉ | 14598/16329 [2:02:54<14:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14598: train loss 1.12944. lr 3.496818e-04:  89%|████████▉ | 14599/16329 [2:02:54<14:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14599: train loss 1.10826. lr 3.496534e-04:  89%|████████▉ | 14599/16329 [2:02:55<14:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14599: train loss 1.10826. lr 3.496534e-04:  89%|████████▉ | 14600/16329 [2:02:55<15:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14600: train loss 1.13571. lr 3.496249e-04:  89%|████████▉ | 14600/16329 [2:02:55<15:54,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14600: train loss 1.13571. lr 3.496249e-04:  89%|████████▉ | 14601/16329 [2:02:55<15:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14601: train loss 1.12618. lr 3.495964e-04:  89%|████████▉ | 14601/16329 [2:02:56<15:22,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14601: train loss 1.12618. lr 3.495964e-04:  89%|████████▉ | 14602/16329 [2:02:56<15:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14602: train loss 1.08967. lr 3.495680e-04:  89%|████████▉ | 14602/16329 [2:02:56<15:03,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14602: train loss 1.08967. lr 3.495680e-04:  89%|████████▉ | 14603/16329 [2:02:56<14:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14603: train loss 1.13155. lr 3.495395e-04:  89%|████████▉ | 14603/16329 [2:02:57<14:49,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14603: train loss 1.13155. lr 3.495395e-04:  89%|████████▉ | 14604/16329 [2:02:57<14:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14604: train loss 1.11785. lr 3.495110e-04:  89%|████████▉ | 14604/16329 [2:02:57<14:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14604: train loss 1.11785. lr 3.495110e-04:  89%|████████▉ | 14605/16329 [2:02:57<14:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14605: train loss 1.10269. lr 3.494826e-04:  89%|████████▉ | 14605/16329 [2:02:58<14:33,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14605: train loss 1.10269. lr 3.494826e-04:  89%|████████▉ | 14606/16329 [2:02:58<14:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14606: train loss 1.11688. lr 3.494541e-04:  89%|████████▉ | 14606/16329 [2:02:58<14:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14606: train loss 1.11688. lr 3.494541e-04:  89%|████████▉ | 14607/16329 [2:02:58<14:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14607: train loss 1.10224. lr 3.494256e-04:  89%|████████▉ | 14607/16329 [2:02:59<14:40,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14607: train loss 1.10224. lr 3.494256e-04:  89%|████████▉ | 14608/16329 [2:02:59<14:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14608: train loss 1.11007. lr 3.493972e-04:  89%|████████▉ | 14608/16329 [2:02:59<14:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14608: train loss 1.11007. lr 3.493972e-04:  89%|████████▉ | 14609/16329 [2:02:59<14:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14609: train loss 1.09236. lr 3.493687e-04:  89%|████████▉ | 14609/16329 [2:03:00<14:45,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14609: train loss 1.09236. lr 3.493687e-04:  89%|████████▉ | 14610/16329 [2:03:00<14:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14610: train loss 1.10479. lr 3.493402e-04:  89%|████████▉ | 14610/16329 [2:03:00<14:42,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14610: train loss 1.10479. lr 3.493402e-04:  89%|████████▉ | 14611/16329 [2:03:00<14:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14611: train loss 1.09962. lr 3.493118e-04:  89%|████████▉ | 14611/16329 [2:03:01<14:35,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14611: train loss 1.09962. lr 3.493118e-04:  89%|████████▉ | 14612/16329 [2:03:01<14:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14612: train loss 1.08756. lr 3.492833e-04:  89%|████████▉ | 14612/16329 [2:03:01<14:31,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14612: train loss 1.08756. lr 3.492833e-04:  89%|████████▉ | 14613/16329 [2:03:01<14:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14613: train loss 1.10991. lr 3.492548e-04:  89%|████████▉ | 14613/16329 [2:03:02<14:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14613: train loss 1.10991. lr 3.492548e-04:  89%|████████▉ | 14614/16329 [2:03:02<14:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14614: train loss 1.09076. lr 3.492264e-04:  89%|████████▉ | 14614/16329 [2:03:02<14:23,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14614: train loss 1.09076. lr 3.492264e-04:  90%|████████▉ | 14615/16329 [2:03:02<14:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14615: train loss 1.13451. lr 3.491979e-04:  90%|████████▉ | 14615/16329 [2:03:03<14:21,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14615: train loss 1.13451. lr 3.491979e-04:  90%|████████▉ | 14616/16329 [2:03:03<14:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14616: train loss 1.12204. lr 3.491694e-04:  90%|████████▉ | 14616/16329 [2:03:03<14:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14616: train loss 1.12204. lr 3.491694e-04:  90%|████████▉ | 14617/16329 [2:03:03<14:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14617: train loss 1.11044. lr 3.491410e-04:  90%|████████▉ | 14617/16329 [2:03:04<14:15,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14617: train loss 1.11044. lr 3.491410e-04:  90%|████████▉ | 14618/16329 [2:03:04<14:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14618: train loss 1.09026. lr 3.491125e-04:  90%|████████▉ | 14618/16329 [2:03:04<14:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14618: train loss 1.09026. lr 3.491125e-04:  90%|████████▉ | 14619/16329 [2:03:04<14:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14619: train loss 1.11475. lr 3.490840e-04:  90%|████████▉ | 14619/16329 [2:03:05<14:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14619: train loss 1.11475. lr 3.490840e-04:  90%|████████▉ | 14620/16329 [2:03:05<14:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14620: train loss 1.10883. lr 3.490556e-04:  90%|████████▉ | 14620/16329 [2:03:05<14:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14620: train loss 1.10883. lr 3.490556e-04:  90%|████████▉ | 14621/16329 [2:03:05<14:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14621: train loss 1.07436. lr 3.490271e-04:  90%|████████▉ | 14621/16329 [2:03:06<14:06,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14621: train loss 1.07436. lr 3.490271e-04:  90%|████████▉ | 14622/16329 [2:03:06<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14622: train loss 1.09202. lr 3.489986e-04:  90%|████████▉ | 14622/16329 [2:03:06<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14622: train loss 1.09202. lr 3.489986e-04:  90%|████████▉ | 14623/16329 [2:03:06<14:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14623: train loss 1.10766. lr 3.489701e-04:  90%|████████▉ | 14623/16329 [2:03:07<14:05,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14623: train loss 1.10766. lr 3.489701e-04:  90%|████████▉ | 14624/16329 [2:03:07<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14624: train loss 1.11133. lr 3.489417e-04:  90%|████████▉ | 14624/16329 [2:03:07<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14624: train loss 1.11133. lr 3.489417e-04:  90%|████████▉ | 14625/16329 [2:03:07<14:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14625: train loss 1.07236. lr 3.489132e-04:  90%|████████▉ | 14625/16329 [2:03:08<14:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14625: train loss 1.07236. lr 3.489132e-04:  90%|████████▉ | 14626/16329 [2:03:08<14:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14626: train loss 1.08697. lr 3.488847e-04:  90%|████████▉ | 14626/16329 [2:03:08<14:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14626: train loss 1.08697. lr 3.488847e-04:  90%|████████▉ | 14627/16329 [2:03:08<14:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14627: train loss 1.06726. lr 3.488562e-04:  90%|████████▉ | 14627/16329 [2:03:09<14:10,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14627: train loss 1.06726. lr 3.488562e-04:  90%|████████▉ | 14628/16329 [2:03:09<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14628: train loss 1.12910. lr 3.488278e-04:  90%|████████▉ | 14628/16329 [2:03:09<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14628: train loss 1.12910. lr 3.488278e-04:  90%|████████▉ | 14629/16329 [2:03:09<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14629: train loss 1.11390. lr 3.487993e-04:  90%|████████▉ | 14629/16329 [2:03:10<14:07,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14629: train loss 1.11390. lr 3.487993e-04:  90%|████████▉ | 14630/16329 [2:03:10<14:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14630: train loss 1.11893. lr 3.487708e-04:  90%|████████▉ | 14630/16329 [2:03:10<14:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14630: train loss 1.11893. lr 3.487708e-04:  90%|████████▉ | 14631/16329 [2:03:10<14:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14631: train loss 1.09831. lr 3.487423e-04:  90%|████████▉ | 14631/16329 [2:03:11<14:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14631: train loss 1.09831. lr 3.487423e-04:  90%|████████▉ | 14632/16329 [2:03:11<14:03,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14632: train loss 1.11520. lr 3.487139e-04:  90%|████████▉ | 14632/16329 [2:03:11<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14632: train loss 1.11520. lr 3.487139e-04:  90%|████████▉ | 14633/16329 [2:03:11<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14633: train loss 1.11139. lr 3.486854e-04:  90%|████████▉ | 14633/16329 [2:03:12<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14633: train loss 1.11139. lr 3.486854e-04:  90%|████████▉ | 14634/16329 [2:03:12<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14634: train loss 1.10445. lr 3.486569e-04:  90%|████████▉ | 14634/16329 [2:03:12<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14634: train loss 1.10445. lr 3.486569e-04:  90%|████████▉ | 14635/16329 [2:03:12<14:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14635: train loss 1.11804. lr 3.486284e-04:  90%|████████▉ | 14635/16329 [2:03:13<14:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14635: train loss 1.11804. lr 3.486284e-04:  90%|████████▉ | 14636/16329 [2:03:13<14:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14636: train loss 1.09191. lr 3.485999e-04:  90%|████████▉ | 14636/16329 [2:03:13<14:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14636: train loss 1.09191. lr 3.485999e-04:  90%|████████▉ | 14637/16329 [2:03:13<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14637: train loss 1.09477. lr 3.485715e-04:  90%|████████▉ | 14637/16329 [2:03:14<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14637: train loss 1.09477. lr 3.485715e-04:  90%|████████▉ | 14638/16329 [2:03:14<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14638: train loss 1.09361. lr 3.485430e-04:  90%|████████▉ | 14638/16329 [2:03:14<14:03,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14638: train loss 1.09361. lr 3.485430e-04:  90%|████████▉ | 14639/16329 [2:03:14<14:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14639: train loss 1.08777. lr 3.485145e-04:  90%|████████▉ | 14639/16329 [2:03:15<14:03,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14639: train loss 1.08777. lr 3.485145e-04:  90%|████████▉ | 14640/16329 [2:03:15<15:31,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14640: train loss 1.08122. lr 3.484860e-04:  90%|████████▉ | 14640/16329 [2:03:15<15:31,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14640: train loss 1.08122. lr 3.484860e-04:  90%|████████▉ | 14641/16329 [2:03:15<15:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14641: train loss 1.11393. lr 3.484575e-04:  90%|████████▉ | 14641/16329 [2:03:16<15:04,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14641: train loss 1.11393. lr 3.484575e-04:  90%|████████▉ | 14642/16329 [2:03:16<14:41,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14642: train loss 1.10161. lr 3.484291e-04:  90%|████████▉ | 14642/16329 [2:03:16<14:41,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14642: train loss 1.10161. lr 3.484291e-04:  90%|████████▉ | 14643/16329 [2:03:16<14:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14643: train loss 1.13575. lr 3.484006e-04:  90%|████████▉ | 14643/16329 [2:03:17<14:30,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14643: train loss 1.13575. lr 3.484006e-04:  90%|████████▉ | 14644/16329 [2:03:17<14:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14644: train loss 1.13131. lr 3.483721e-04:  90%|████████▉ | 14644/16329 [2:03:17<14:17,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14644: train loss 1.13131. lr 3.483721e-04:  90%|████████▉ | 14645/16329 [2:03:17<14:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14645: train loss 1.12874. lr 3.483436e-04:  90%|████████▉ | 14645/16329 [2:03:18<14:11,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14645: train loss 1.12874. lr 3.483436e-04:  90%|████████▉ | 14646/16329 [2:03:18<14:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14646: train loss 1.10326. lr 3.483151e-04:  90%|████████▉ | 14646/16329 [2:03:18<14:06,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14646: train loss 1.10326. lr 3.483151e-04:  90%|████████▉ | 14647/16329 [2:03:18<14:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14647: train loss 1.11140. lr 3.482866e-04:  90%|████████▉ | 14647/16329 [2:03:19<14:01,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14647: train loss 1.11140. lr 3.482866e-04:  90%|████████▉ | 14648/16329 [2:03:19<14:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14648: train loss 1.10284. lr 3.482582e-04:  90%|████████▉ | 14648/16329 [2:03:19<14:00,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14648: train loss 1.10284. lr 3.482582e-04:  90%|████████▉ | 14649/16329 [2:03:19<13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14649: train loss 1.09111. lr 3.482297e-04:  90%|████████▉ | 14649/16329 [2:03:20<13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14649: train loss 1.09111. lr 3.482297e-04:  90%|████████▉ | 14650/16329 [2:03:20<13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14650: train loss 1.11391. lr 3.482012e-04:  90%|████████▉ | 14650/16329 [2:03:20<13:56,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14650: train loss 1.11391. lr 3.482012e-04:  90%|████████▉ | 14651/16329 [2:03:20<13:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14651: train loss 1.12627. lr 3.481727e-04:  90%|████████▉ | 14651/16329 [2:03:21<13:53,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14651: train loss 1.12627. lr 3.481727e-04:  90%|████████▉ | 14652/16329 [2:03:21<13:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14652: train loss 1.11155. lr 3.481442e-04:  90%|████████▉ | 14652/16329 [2:03:21<13:54,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14652: train loss 1.11155. lr 3.481442e-04:  90%|████████▉ | 14653/16329 [2:03:21<13:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14653: train loss 1.11297. lr 3.481157e-04:  90%|████████▉ | 14653/16329 [2:03:22<13:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14653: train loss 1.11297. lr 3.481157e-04:  90%|████████▉ | 14654/16329 [2:03:22<13:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14654: train loss 1.10646. lr 3.480872e-04:  90%|████████▉ | 14654/16329 [2:03:22<13:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14654: train loss 1.10646. lr 3.480872e-04:  90%|████████▉ | 14655/16329 [2:03:22<13:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14655: train loss 1.13258. lr 3.480588e-04:  90%|████████▉ | 14655/16329 [2:03:23<13:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14655: train loss 1.13258. lr 3.480588e-04:  90%|████████▉ | 14656/16329 [2:03:23<13:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14656: train loss 1.06768. lr 3.480303e-04:  90%|████████▉ | 14656/16329 [2:03:23<13:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14656: train loss 1.06768. lr 3.480303e-04:  90%|████████▉ | 14657/16329 [2:03:23<13:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14657: train loss 1.10307. lr 3.480018e-04:  90%|████████▉ | 14657/16329 [2:03:24<13:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14657: train loss 1.10307. lr 3.480018e-04:  90%|████████▉ | 14658/16329 [2:03:24<13:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14658: train loss 1.11719. lr 3.479733e-04:  90%|████████▉ | 14658/16329 [2:03:24<13:49,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14658: train loss 1.11719. lr 3.479733e-04:  90%|████████▉ | 14659/16329 [2:03:24<13:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14659: train loss 1.09398. lr 3.479448e-04:  90%|████████▉ | 14659/16329 [2:03:25<13:48,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14659: train loss 1.09398. lr 3.479448e-04:  90%|████████▉ | 14660/16329 [2:03:25<13:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14660: train loss 1.10389. lr 3.479163e-04:  90%|████████▉ | 14660/16329 [2:03:25<13:46,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14660: train loss 1.10389. lr 3.479163e-04:  90%|████████▉ | 14661/16329 [2:03:25<13:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14661: train loss 1.10185. lr 3.478878e-04:  90%|████████▉ | 14661/16329 [2:03:26<13:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14661: train loss 1.10185. lr 3.478878e-04:  90%|████████▉ | 14662/16329 [2:03:26<13:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14662: train loss 1.13838. lr 3.478593e-04:  90%|████████▉ | 14662/16329 [2:03:26<13:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14662: train loss 1.13838. lr 3.478593e-04:  90%|████████▉ | 14663/16329 [2:03:26<13:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14663: train loss 1.12971. lr 3.478308e-04:  90%|████████▉ | 14663/16329 [2:03:27<13:46,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14663: train loss 1.12971. lr 3.478308e-04:  90%|████████▉ | 14664/16329 [2:03:27<13:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14664: train loss 1.09933. lr 3.478024e-04:  90%|████████▉ | 14664/16329 [2:03:27<13:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14664: train loss 1.09933. lr 3.478024e-04:  90%|████████▉ | 14665/16329 [2:03:27<13:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14665: train loss 1.11537. lr 3.477739e-04:  90%|████████▉ | 14665/16329 [2:03:28<13:47,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14665: train loss 1.11537. lr 3.477739e-04:  90%|████████▉ | 14666/16329 [2:03:28<13:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14666: train loss 1.09467. lr 3.477454e-04:  90%|████████▉ | 14666/16329 [2:03:28<13:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14666: train loss 1.09467. lr 3.477454e-04:  90%|████████▉ | 14667/16329 [2:03:28<13:45,  2.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14667: train loss 1.10297. lr 3.477169e-04:  90%|████████▉ | 14667/16329 [2:03:29<13:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14667: train loss 1.10297. lr 3.477169e-04:  90%|████████▉ | 14668/16329 [2:03:29<13:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14668: train loss 1.10393. lr 3.476884e-04:  90%|████████▉ | 14668/16329 [2:03:29<13:42,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14668: train loss 1.10393. lr 3.476884e-04:  90%|████████▉ | 14669/16329 [2:03:29<13:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14669: train loss 1.07701. lr 3.476599e-04:  90%|████████▉ | 14669/16329 [2:03:30<13:44,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14669: train loss 1.07701. lr 3.476599e-04:  90%|████████▉ | 14670/16329 [2:03:30<14:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14670: train loss 1.09814. lr 3.476314e-04:  90%|████████▉ | 14670/16329 [2:03:30<14:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14670: train loss 1.09814. lr 3.476314e-04:  90%|████████▉ | 14671/16329 [2:03:30<14:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14671: train loss 1.09167. lr 3.476029e-04:  90%|████████▉ | 14671/16329 [2:03:31<14:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14671: train loss 1.09167. lr 3.476029e-04:  90%|████████▉ | 14672/16329 [2:03:31<14:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14672: train loss 1.08906. lr 3.475744e-04:  90%|████████▉ | 14672/16329 [2:03:31<14:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14672: train loss 1.08906. lr 3.475744e-04:  90%|████████▉ | 14673/16329 [2:03:31<14:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14673: train loss 1.07449. lr 3.475459e-04:  90%|████████▉ | 14673/16329 [2:03:32<14:05,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14673: train loss 1.07449. lr 3.475459e-04:  90%|████████▉ | 14674/16329 [2:03:32<14:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14674: train loss 1.10595. lr 3.475174e-04:  90%|████████▉ | 14674/16329 [2:03:32<14:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14674: train loss 1.10595. lr 3.475174e-04:  90%|████████▉ | 14675/16329 [2:03:32<15:24,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14675: train loss 1.10689. lr 3.474889e-04:  90%|████████▉ | 14675/16329 [2:03:33<15:24,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14675: train loss 1.10689. lr 3.474889e-04:  90%|████████▉ | 14676/16329 [2:03:33<14:52,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14676: train loss 1.11208. lr 3.474604e-04:  90%|████████▉ | 14676/16329 [2:03:33<14:52,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14676: train loss 1.11208. lr 3.474604e-04:  90%|████████▉ | 14677/16329 [2:03:33<14:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14677: train loss 1.11097. lr 3.474319e-04:  90%|████████▉ | 14677/16329 [2:03:34<14:31,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14677: train loss 1.11097. lr 3.474319e-04:  90%|████████▉ | 14678/16329 [2:03:34<14:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14678: train loss 1.09424. lr 3.474034e-04:  90%|████████▉ | 14678/16329 [2:03:34<14:16,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14678: train loss 1.09424. lr 3.474034e-04:  90%|████████▉ | 14679/16329 [2:03:34<14:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14679: train loss 1.10732. lr 3.473749e-04:  90%|████████▉ | 14679/16329 [2:03:35<14:04,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14679: train loss 1.10732. lr 3.473749e-04:  90%|████████▉ | 14680/16329 [2:03:35<13:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14680: train loss 1.11350. lr 3.473464e-04:  90%|████████▉ | 14680/16329 [2:03:35<13:57,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14680: train loss 1.11350. lr 3.473464e-04:  90%|████████▉ | 14681/16329 [2:03:35<13:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14681: train loss 1.11622. lr 3.473179e-04:  90%|████████▉ | 14681/16329 [2:03:36<13:52,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14681: train loss 1.11622. lr 3.473179e-04:  90%|████████▉ | 14682/16329 [2:03:36<13:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14682: train loss 1.10221. lr 3.472894e-04:  90%|████████▉ | 14682/16329 [2:03:36<13:47,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14682: train loss 1.10221. lr 3.472894e-04:  90%|████████▉ | 14683/16329 [2:03:36<13:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14683: train loss 1.08759. lr 3.472609e-04:  90%|████████▉ | 14683/16329 [2:03:37<13:44,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14683: train loss 1.08759. lr 3.472609e-04:  90%|████████▉ | 14684/16329 [2:03:37<13:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14684: train loss 1.08806. lr 3.472324e-04:  90%|████████▉ | 14684/16329 [2:03:37<13:42,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14684: train loss 1.08806. lr 3.472324e-04:  90%|████████▉ | 14685/16329 [2:03:37<13:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14685: train loss 1.10997. lr 3.472039e-04:  90%|████████▉ | 14685/16329 [2:03:38<13:40,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14685: train loss 1.10997. lr 3.472039e-04:  90%|████████▉ | 14686/16329 [2:03:38<13:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14686: train loss 1.10337. lr 3.471754e-04:  90%|████████▉ | 14686/16329 [2:03:38<13:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14686: train loss 1.10337. lr 3.471754e-04:  90%|████████▉ | 14687/16329 [2:03:38<13:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14687: train loss 1.09053. lr 3.471469e-04:  90%|████████▉ | 14687/16329 [2:03:39<13:37,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14687: train loss 1.09053. lr 3.471469e-04:  90%|████████▉ | 14688/16329 [2:03:39<13:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14688: train loss 1.11283. lr 3.471184e-04:  90%|████████▉ | 14688/16329 [2:03:39<13:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14688: train loss 1.11283. lr 3.471184e-04:  90%|████████▉ | 14689/16329 [2:03:39<13:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14689: train loss 1.10037. lr 3.470899e-04:  90%|████████▉ | 14689/16329 [2:03:40<13:36,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14689: train loss 1.10037. lr 3.470899e-04:  90%|████████▉ | 14690/16329 [2:03:40<13:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14690: train loss 1.09446. lr 3.470614e-04:  90%|████████▉ | 14690/16329 [2:03:40<13:38,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14690: train loss 1.09446. lr 3.470614e-04:  90%|████████▉ | 14691/16329 [2:03:40<13:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14691: train loss 1.14433. lr 3.470329e-04:  90%|████████▉ | 14691/16329 [2:03:41<13:37,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14691: train loss 1.14433. lr 3.470329e-04:  90%|████████▉ | 14692/16329 [2:03:41<13:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14692: train loss 1.12271. lr 3.470044e-04:  90%|████████▉ | 14692/16329 [2:03:41<13:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14692: train loss 1.12271. lr 3.470044e-04:  90%|████████▉ | 14693/16329 [2:03:41<13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14693: train loss 1.10010. lr 3.469759e-04:  90%|████████▉ | 14693/16329 [2:03:42<13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14693: train loss 1.10010. lr 3.469759e-04:  90%|████████▉ | 14694/16329 [2:03:42<13:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14694: train loss 1.11305. lr 3.469474e-04:  90%|████████▉ | 14694/16329 [2:03:42<13:33,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14694: train loss 1.11305. lr 3.469474e-04:  90%|████████▉ | 14695/16329 [2:03:42<13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14695: train loss 1.09967. lr 3.469189e-04:  90%|████████▉ | 14695/16329 [2:03:43<13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14695: train loss 1.09967. lr 3.469189e-04:  90%|████████▉ | 14696/16329 [2:03:43<13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14696: train loss 1.14570. lr 3.468904e-04:  90%|████████▉ | 14696/16329 [2:03:43<13:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14696: train loss 1.14570. lr 3.468904e-04:  90%|█████████ | 14697/16329 [2:03:43<13:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14697: train loss 1.09102. lr 3.468619e-04:  90%|█████████ | 14697/16329 [2:03:44<13:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14697: train loss 1.09102. lr 3.468619e-04:  90%|█████████ | 14698/16329 [2:03:44<13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14698: train loss 1.10501. lr 3.468334e-04:  90%|█████████ | 14698/16329 [2:03:44<13:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14698: train loss 1.10501. lr 3.468334e-04:  90%|█████████ | 14699/16329 [2:03:44<13:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14699: train loss 1.12618. lr 3.468049e-04:  90%|█████████ | 14699/16329 [2:03:45<13:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14699: train loss 1.12618. lr 3.468049e-04:  90%|█████████ | 14700/16329 [2:03:45<15:46,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 14700: train loss 1.10955. lr 3.467764e-04:  90%|█████████ | 14700/16329 [2:03:46<15:46,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 14700: train loss 1.10955. lr 3.467764e-04:  90%|█████████ | 14701/16329 [2:03:46<15:05,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 14701: train loss 1.12326. lr 3.467479e-04:  90%|█████████ | 14701/16329 [2:03:46<15:05,  1.80it/s]\u001b[A\n",
      "epoch 1 iter 14701: train loss 1.12326. lr 3.467479e-04:  90%|█████████ | 14702/16329 [2:03:46<14:37,  1.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14702: train loss 1.10658. lr 3.467194e-04:  90%|█████████ | 14702/16329 [2:03:47<14:37,  1.85it/s]\u001b[A\n",
      "epoch 1 iter 14702: train loss 1.10658. lr 3.467194e-04:  90%|█████████ | 14703/16329 [2:03:47<14:14,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14703: train loss 1.11485. lr 3.466908e-04:  90%|█████████ | 14703/16329 [2:03:47<14:14,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14703: train loss 1.11485. lr 3.466908e-04:  90%|█████████ | 14704/16329 [2:03:47<13:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14704: train loss 1.08860. lr 3.466623e-04:  90%|█████████ | 14704/16329 [2:03:48<13:56,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14704: train loss 1.08860. lr 3.466623e-04:  90%|█████████ | 14705/16329 [2:03:48<13:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14705: train loss 1.09954. lr 3.466338e-04:  90%|█████████ | 14705/16329 [2:03:48<13:48,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14705: train loss 1.09954. lr 3.466338e-04:  90%|█████████ | 14706/16329 [2:03:48<13:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14706: train loss 1.07986. lr 3.466053e-04:  90%|█████████ | 14706/16329 [2:03:49<13:42,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14706: train loss 1.07986. lr 3.466053e-04:  90%|█████████ | 14707/16329 [2:03:49<13:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14707: train loss 1.11456. lr 3.465768e-04:  90%|█████████ | 14707/16329 [2:03:49<13:37,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14707: train loss 1.11456. lr 3.465768e-04:  90%|█████████ | 14708/16329 [2:03:49<13:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14708: train loss 1.12290. lr 3.465483e-04:  90%|█████████ | 14708/16329 [2:03:50<13:33,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14708: train loss 1.12290. lr 3.465483e-04:  90%|█████████ | 14709/16329 [2:03:50<13:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14709: train loss 1.11335. lr 3.465198e-04:  90%|█████████ | 14709/16329 [2:03:50<13:29,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14709: train loss 1.11335. lr 3.465198e-04:  90%|█████████ | 14710/16329 [2:03:50<13:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14710: train loss 1.12492. lr 3.464913e-04:  90%|█████████ | 14710/16329 [2:03:51<13:27,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14710: train loss 1.12492. lr 3.464913e-04:  90%|█████████ | 14711/16329 [2:03:51<13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14711: train loss 1.12575. lr 3.464628e-04:  90%|█████████ | 14711/16329 [2:03:51<13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14711: train loss 1.12575. lr 3.464628e-04:  90%|█████████ | 14712/16329 [2:03:51<13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14712: train loss 1.08305. lr 3.464343e-04:  90%|█████████ | 14712/16329 [2:03:52<13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14712: train loss 1.08305. lr 3.464343e-04:  90%|█████████ | 14713/16329 [2:03:52<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14713: train loss 1.09829. lr 3.464057e-04:  90%|█████████ | 14713/16329 [2:03:52<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14713: train loss 1.09829. lr 3.464057e-04:  90%|█████████ | 14714/16329 [2:03:52<13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14714: train loss 1.12386. lr 3.463772e-04:  90%|█████████ | 14714/16329 [2:03:53<13:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14714: train loss 1.12386. lr 3.463772e-04:  90%|█████████ | 14715/16329 [2:03:53<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14715: train loss 1.10610. lr 3.463487e-04:  90%|█████████ | 14715/16329 [2:03:53<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14715: train loss 1.10610. lr 3.463487e-04:  90%|█████████ | 14716/16329 [2:03:53<13:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14716: train loss 1.10364. lr 3.463202e-04:  90%|█████████ | 14716/16329 [2:03:54<13:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14716: train loss 1.10364. lr 3.463202e-04:  90%|█████████ | 14717/16329 [2:03:54<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14717: train loss 1.08201. lr 3.462917e-04:  90%|█████████ | 14717/16329 [2:03:54<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14717: train loss 1.08201. lr 3.462917e-04:  90%|█████████ | 14718/16329 [2:03:54<13:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14718: train loss 1.09600. lr 3.462632e-04:  90%|█████████ | 14718/16329 [2:03:55<13:21,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14718: train loss 1.09600. lr 3.462632e-04:  90%|█████████ | 14719/16329 [2:03:55<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14719: train loss 1.09383. lr 3.462347e-04:  90%|█████████ | 14719/16329 [2:03:55<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14719: train loss 1.09383. lr 3.462347e-04:  90%|█████████ | 14720/16329 [2:03:55<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14720: train loss 1.09470. lr 3.462061e-04:  90%|█████████ | 14720/16329 [2:03:56<13:22,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14720: train loss 1.09470. lr 3.462061e-04:  90%|█████████ | 14721/16329 [2:03:56<13:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14721: train loss 1.12432. lr 3.461776e-04:  90%|█████████ | 14721/16329 [2:03:56<13:22,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14721: train loss 1.12432. lr 3.461776e-04:  90%|█████████ | 14722/16329 [2:03:56<13:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14722: train loss 1.09871. lr 3.461491e-04:  90%|█████████ | 14722/16329 [2:03:57<13:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14722: train loss 1.09871. lr 3.461491e-04:  90%|█████████ | 14723/16329 [2:03:57<13:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14723: train loss 1.10295. lr 3.461206e-04:  90%|█████████ | 14723/16329 [2:03:57<13:19,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14723: train loss 1.10295. lr 3.461206e-04:  90%|█████████ | 14724/16329 [2:03:57<13:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14724: train loss 1.10071. lr 3.460921e-04:  90%|█████████ | 14724/16329 [2:03:58<13:18,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14724: train loss 1.10071. lr 3.460921e-04:  90%|█████████ | 14725/16329 [2:03:58<13:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14725: train loss 1.08148. lr 3.460636e-04:  90%|█████████ | 14725/16329 [2:03:58<13:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14725: train loss 1.08148. lr 3.460636e-04:  90%|█████████ | 14726/16329 [2:03:58<13:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14726: train loss 1.10727. lr 3.460350e-04:  90%|█████████ | 14726/16329 [2:03:59<13:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14726: train loss 1.10727. lr 3.460350e-04:  90%|█████████ | 14727/16329 [2:03:59<15:05,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14727: train loss 1.07917. lr 3.460065e-04:  90%|█████████ | 14727/16329 [2:03:59<15:05,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14727: train loss 1.07917. lr 3.460065e-04:  90%|█████████ | 14728/16329 [2:03:59<14:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 14728: train loss 1.13105. lr 3.459780e-04:  90%|█████████ | 14728/16329 [2:04:00<14:33,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 14728: train loss 1.13105. lr 3.459780e-04:  90%|█████████ | 14729/16329 [2:04:00<14:08,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14729: train loss 1.10077. lr 3.459495e-04:  90%|█████████ | 14729/16329 [2:04:00<14:08,  1.89it/s]\u001b[A\n",
      "epoch 1 iter 14729: train loss 1.10077. lr 3.459495e-04:  90%|█████████ | 14730/16329 [2:04:00<13:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14730: train loss 1.11158. lr 3.459210e-04:  90%|█████████ | 14730/16329 [2:04:01<13:52,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14730: train loss 1.11158. lr 3.459210e-04:  90%|█████████ | 14731/16329 [2:04:01<13:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14731: train loss 1.10311. lr 3.458924e-04:  90%|█████████ | 14731/16329 [2:04:01<13:41,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14731: train loss 1.10311. lr 3.458924e-04:  90%|█████████ | 14732/16329 [2:04:01<13:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14732: train loss 1.15999. lr 3.458639e-04:  90%|█████████ | 14732/16329 [2:04:02<13:33,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14732: train loss 1.15999. lr 3.458639e-04:  90%|█████████ | 14733/16329 [2:04:02<13:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14733: train loss 1.09056. lr 3.458354e-04:  90%|█████████ | 14733/16329 [2:04:02<13:26,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14733: train loss 1.09056. lr 3.458354e-04:  90%|█████████ | 14734/16329 [2:04:02<13:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14734: train loss 1.11220. lr 3.458069e-04:  90%|█████████ | 14734/16329 [2:04:03<13:20,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14734: train loss 1.11220. lr 3.458069e-04:  90%|█████████ | 14735/16329 [2:04:03<13:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14735: train loss 1.11507. lr 3.457784e-04:  90%|█████████ | 14735/16329 [2:04:03<13:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14735: train loss 1.11507. lr 3.457784e-04:  90%|█████████ | 14736/16329 [2:04:03<13:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14736: train loss 1.10973. lr 3.457498e-04:  90%|█████████ | 14736/16329 [2:04:04<13:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14736: train loss 1.10973. lr 3.457498e-04:  90%|█████████ | 14737/16329 [2:04:04<13:17,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14737: train loss 1.07224. lr 3.457213e-04:  90%|█████████ | 14737/16329 [2:04:04<13:17,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14737: train loss 1.07224. lr 3.457213e-04:  90%|█████████ | 14738/16329 [2:04:04<13:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14738: train loss 1.08994. lr 3.456928e-04:  90%|█████████ | 14738/16329 [2:04:05<13:13,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14738: train loss 1.08994. lr 3.456928e-04:  90%|█████████ | 14739/16329 [2:04:05<13:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14739: train loss 1.10138. lr 3.456643e-04:  90%|█████████ | 14739/16329 [2:04:05<13:12,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14739: train loss 1.10138. lr 3.456643e-04:  90%|█████████ | 14740/16329 [2:04:05<13:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14740: train loss 1.08387. lr 3.456357e-04:  90%|█████████ | 14740/16329 [2:04:06<13:10,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14740: train loss 1.08387. lr 3.456357e-04:  90%|█████████ | 14741/16329 [2:04:06<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14741: train loss 1.07065. lr 3.456072e-04:  90%|█████████ | 14741/16329 [2:04:06<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14741: train loss 1.07065. lr 3.456072e-04:  90%|█████████ | 14742/16329 [2:04:06<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14742: train loss 1.08297. lr 3.455787e-04:  90%|█████████ | 14742/16329 [2:04:07<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14742: train loss 1.08297. lr 3.455787e-04:  90%|█████████ | 14743/16329 [2:04:07<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14743: train loss 1.11064. lr 3.455502e-04:  90%|█████████ | 14743/16329 [2:04:07<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14743: train loss 1.11064. lr 3.455502e-04:  90%|█████████ | 14744/16329 [2:04:07<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14744: train loss 1.09066. lr 3.455216e-04:  90%|█████████ | 14744/16329 [2:04:08<13:08,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14744: train loss 1.09066. lr 3.455216e-04:  90%|█████████ | 14745/16329 [2:04:08<13:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14745: train loss 1.11729. lr 3.454931e-04:  90%|█████████ | 14745/16329 [2:04:08<13:06,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14745: train loss 1.11729. lr 3.454931e-04:  90%|█████████ | 14746/16329 [2:04:08<13:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14746: train loss 1.08321. lr 3.454646e-04:  90%|█████████ | 14746/16329 [2:04:09<13:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14746: train loss 1.08321. lr 3.454646e-04:  90%|█████████ | 14747/16329 [2:04:09<13:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14747: train loss 1.10743. lr 3.454361e-04:  90%|█████████ | 14747/16329 [2:04:09<13:04,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14747: train loss 1.10743. lr 3.454361e-04:  90%|█████████ | 14748/16329 [2:04:09<13:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14748: train loss 1.09694. lr 3.454075e-04:  90%|█████████ | 14748/16329 [2:04:10<13:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14748: train loss 1.09694. lr 3.454075e-04:  90%|█████████ | 14749/16329 [2:04:10<13:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14749: train loss 1.07596. lr 3.453790e-04:  90%|█████████ | 14749/16329 [2:04:10<13:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14749: train loss 1.07596. lr 3.453790e-04:  90%|█████████ | 14750/16329 [2:04:10<13:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14750: train loss 1.07497. lr 3.453505e-04:  90%|█████████ | 14750/16329 [2:04:11<13:03,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14750: train loss 1.07497. lr 3.453505e-04:  90%|█████████ | 14751/16329 [2:04:11<13:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14751: train loss 1.11311. lr 3.453219e-04:  90%|█████████ | 14751/16329 [2:04:11<13:04,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14751: train loss 1.11311. lr 3.453219e-04:  90%|█████████ | 14752/16329 [2:04:11<13:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14752: train loss 1.07832. lr 3.452934e-04:  90%|█████████ | 14752/16329 [2:04:12<13:05,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14752: train loss 1.07832. lr 3.452934e-04:  90%|█████████ | 14753/16329 [2:04:12<13:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14753: train loss 1.07190. lr 3.452649e-04:  90%|█████████ | 14753/16329 [2:04:12<13:02,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14753: train loss 1.07190. lr 3.452649e-04:  90%|█████████ | 14754/16329 [2:04:12<13:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14754: train loss 1.08826. lr 3.452364e-04:  90%|█████████ | 14754/16329 [2:04:13<13:33,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14754: train loss 1.08826. lr 3.452364e-04:  90%|█████████ | 14755/16329 [2:04:13<13:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14755: train loss 1.10024. lr 3.452078e-04:  90%|█████████ | 14755/16329 [2:04:13<13:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14755: train loss 1.10024. lr 3.452078e-04:  90%|█████████ | 14756/16329 [2:04:13<14:04,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14756: train loss 1.12550. lr 3.451793e-04:  90%|█████████ | 14756/16329 [2:04:14<14:04,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14756: train loss 1.12550. lr 3.451793e-04:  90%|█████████ | 14757/16329 [2:04:14<14:01,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14757: train loss 1.13354. lr 3.451508e-04:  90%|█████████ | 14757/16329 [2:04:14<14:01,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14757: train loss 1.13354. lr 3.451508e-04:  90%|█████████ | 14758/16329 [2:04:14<13:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14758: train loss 1.12490. lr 3.451222e-04:  90%|█████████ | 14758/16329 [2:04:15<13:55,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14758: train loss 1.12490. lr 3.451222e-04:  90%|█████████ | 14759/16329 [2:04:15<13:46,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14759: train loss 1.11259. lr 3.450937e-04:  90%|█████████ | 14759/16329 [2:04:15<13:46,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14759: train loss 1.11259. lr 3.450937e-04:  90%|█████████ | 14760/16329 [2:04:15<13:38,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14760: train loss 1.06184. lr 3.450652e-04:  90%|█████████ | 14760/16329 [2:04:16<13:38,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14760: train loss 1.06184. lr 3.450652e-04:  90%|█████████ | 14761/16329 [2:04:16<13:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14761: train loss 1.07736. lr 3.450366e-04:  90%|█████████ | 14761/16329 [2:04:16<13:31,  1.93it/s]\u001b[A\n",
      "epoch 1 iter 14761: train loss 1.07736. lr 3.450366e-04:  90%|█████████ | 14762/16329 [2:04:16<13:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14762: train loss 1.08040. lr 3.450081e-04:  90%|█████████ | 14762/16329 [2:04:17<13:24,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14762: train loss 1.08040. lr 3.450081e-04:  90%|█████████ | 14763/16329 [2:04:17<13:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14763: train loss 1.12501. lr 3.449796e-04:  90%|█████████ | 14763/16329 [2:04:17<13:13,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14763: train loss 1.12501. lr 3.449796e-04:  90%|█████████ | 14764/16329 [2:04:17<13:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14764: train loss 1.09258. lr 3.449510e-04:  90%|█████████ | 14764/16329 [2:04:18<13:07,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14764: train loss 1.09258. lr 3.449510e-04:  90%|█████████ | 14765/16329 [2:04:18<13:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14765: train loss 1.08963. lr 3.449225e-04:  90%|█████████ | 14765/16329 [2:04:18<13:02,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14765: train loss 1.08963. lr 3.449225e-04:  90%|█████████ | 14766/16329 [2:04:18<12:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14766: train loss 1.13763. lr 3.448940e-04:  90%|█████████ | 14766/16329 [2:04:19<12:58,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14766: train loss 1.13763. lr 3.448940e-04:  90%|█████████ | 14767/16329 [2:04:19<15:07,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 14767: train loss 1.13113. lr 3.448654e-04:  90%|█████████ | 14767/16329 [2:04:20<15:07,  1.72it/s]\u001b[A\n",
      "epoch 1 iter 14767: train loss 1.13113. lr 3.448654e-04:  90%|█████████ | 14768/16329 [2:04:20<14:40,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14768: train loss 1.11749. lr 3.448369e-04:  90%|█████████ | 14768/16329 [2:04:20<14:40,  1.77it/s]\u001b[A\n",
      "epoch 1 iter 14768: train loss 1.11749. lr 3.448369e-04:  90%|█████████ | 14769/16329 [2:04:20<14:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14769: train loss 1.12345. lr 3.448084e-04:  90%|█████████ | 14769/16329 [2:04:21<14:17,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14769: train loss 1.12345. lr 3.448084e-04:  90%|█████████ | 14770/16329 [2:04:21<13:59,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14770: train loss 1.14139. lr 3.447798e-04:  90%|█████████ | 14770/16329 [2:04:21<13:59,  1.86it/s]\u001b[A\n",
      "epoch 1 iter 14770: train loss 1.14139. lr 3.447798e-04:  90%|█████████ | 14771/16329 [2:04:21<13:42,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14771: train loss 1.08506. lr 3.447513e-04:  90%|█████████ | 14771/16329 [2:04:22<13:42,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14771: train loss 1.08506. lr 3.447513e-04:  90%|█████████ | 14772/16329 [2:04:22<13:31,  1.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14772: train loss 1.12586. lr 3.447227e-04:  90%|█████████ | 14772/16329 [2:04:22<13:31,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14772: train loss 1.12586. lr 3.447227e-04:  90%|█████████ | 14773/16329 [2:04:22<13:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14773: train loss 1.08820. lr 3.446942e-04:  90%|█████████ | 14773/16329 [2:04:23<13:19,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14773: train loss 1.08820. lr 3.446942e-04:  90%|█████████ | 14774/16329 [2:04:23<13:13,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14774: train loss 1.10124. lr 3.446657e-04:  90%|█████████ | 14774/16329 [2:04:23<13:13,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14774: train loss 1.10124. lr 3.446657e-04:  90%|█████████ | 14775/16329 [2:04:23<13:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14775: train loss 1.10261. lr 3.446371e-04:  90%|█████████ | 14775/16329 [2:04:24<13:05,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14775: train loss 1.10261. lr 3.446371e-04:  90%|█████████ | 14776/16329 [2:04:24<12:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14776: train loss 1.08837. lr 3.446086e-04:  90%|█████████ | 14776/16329 [2:04:24<12:59,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14776: train loss 1.08837. lr 3.446086e-04:  90%|█████████ | 14777/16329 [2:04:24<12:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14777: train loss 1.10291. lr 3.445800e-04:  90%|█████████ | 14777/16329 [2:04:25<12:57,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14777: train loss 1.10291. lr 3.445800e-04:  91%|█████████ | 14778/16329 [2:04:25<12:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14778: train loss 1.09369. lr 3.445515e-04:  91%|█████████ | 14778/16329 [2:04:25<12:52,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14778: train loss 1.09369. lr 3.445515e-04:  91%|█████████ | 14779/16329 [2:04:25<12:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14779: train loss 1.09940. lr 3.445230e-04:  91%|█████████ | 14779/16329 [2:04:26<12:51,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14779: train loss 1.09940. lr 3.445230e-04:  91%|█████████ | 14780/16329 [2:04:26<12:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14780: train loss 1.10480. lr 3.444944e-04:  91%|█████████ | 14780/16329 [2:04:26<12:49,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14780: train loss 1.10480. lr 3.444944e-04:  91%|█████████ | 14781/16329 [2:04:26<12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14781: train loss 1.09227. lr 3.444659e-04:  91%|█████████ | 14781/16329 [2:04:27<12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14781: train loss 1.09227. lr 3.444659e-04:  91%|█████████ | 14782/16329 [2:04:27<12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14782: train loss 1.11520. lr 3.444373e-04:  91%|█████████ | 14782/16329 [2:04:27<12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14782: train loss 1.11520. lr 3.444373e-04:  91%|█████████ | 14783/16329 [2:04:27<12:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14783: train loss 1.10188. lr 3.444088e-04:  91%|█████████ | 14783/16329 [2:04:28<12:43,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14783: train loss 1.10188. lr 3.444088e-04:  91%|█████████ | 14784/16329 [2:04:28<12:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14784: train loss 1.08539. lr 3.443803e-04:  91%|█████████ | 14784/16329 [2:04:28<12:44,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14784: train loss 1.08539. lr 3.443803e-04:  91%|█████████ | 14785/16329 [2:04:28<12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14785: train loss 1.10404. lr 3.443517e-04:  91%|█████████ | 14785/16329 [2:04:29<12:45,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14785: train loss 1.10404. lr 3.443517e-04:  91%|█████████ | 14786/16329 [2:04:29<12:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14786: train loss 1.08657. lr 3.443232e-04:  91%|█████████ | 14786/16329 [2:04:29<12:45,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14786: train loss 1.08657. lr 3.443232e-04:  91%|█████████ | 14787/16329 [2:04:29<13:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14787: train loss 1.11115. lr 3.442946e-04:  91%|█████████ | 14787/16329 [2:04:30<13:01,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14787: train loss 1.11115. lr 3.442946e-04:  91%|█████████ | 14788/16329 [2:04:30<13:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14788: train loss 1.11336. lr 3.442661e-04:  91%|█████████ | 14788/16329 [2:04:30<13:07,  1.96it/s]\u001b[A\n",
      "epoch 1 iter 14788: train loss 1.11336. lr 3.442661e-04:  91%|█████████ | 14789/16329 [2:04:30<13:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14789: train loss 1.10965. lr 3.442375e-04:  91%|█████████ | 14789/16329 [2:04:31<13:08,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14789: train loss 1.10965. lr 3.442375e-04:  91%|█████████ | 14790/16329 [2:04:31<13:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14790: train loss 1.09637. lr 3.442090e-04:  91%|█████████ | 14790/16329 [2:04:31<13:07,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14790: train loss 1.09637. lr 3.442090e-04:  91%|█████████ | 14791/16329 [2:04:31<13:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14791: train loss 1.12095. lr 3.441804e-04:  91%|█████████ | 14791/16329 [2:04:32<13:02,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14791: train loss 1.12095. lr 3.441804e-04:  91%|█████████ | 14792/16329 [2:04:32<13:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14792: train loss 1.09250. lr 3.441519e-04:  91%|█████████ | 14792/16329 [2:04:32<13:00,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14792: train loss 1.09250. lr 3.441519e-04:  91%|█████████ | 14793/16329 [2:04:32<12:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14793: train loss 1.09724. lr 3.441234e-04:  91%|█████████ | 14793/16329 [2:04:33<12:56,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14793: train loss 1.09724. lr 3.441234e-04:  91%|█████████ | 14794/16329 [2:04:33<12:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14794: train loss 1.08580. lr 3.440948e-04:  91%|█████████ | 14794/16329 [2:04:33<12:52,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14794: train loss 1.08580. lr 3.440948e-04:  91%|█████████ | 14795/16329 [2:04:33<12:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14795: train loss 1.11175. lr 3.440663e-04:  91%|█████████ | 14795/16329 [2:04:34<12:50,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14795: train loss 1.11175. lr 3.440663e-04:  91%|█████████ | 14796/16329 [2:04:34<12:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14796: train loss 1.12192. lr 3.440377e-04:  91%|█████████ | 14796/16329 [2:04:34<12:46,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14796: train loss 1.12192. lr 3.440377e-04:  91%|█████████ | 14797/16329 [2:04:34<12:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14797: train loss 1.07727. lr 3.440092e-04:  91%|█████████ | 14797/16329 [2:04:35<12:45,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14797: train loss 1.07727. lr 3.440092e-04:  91%|█████████ | 14798/16329 [2:04:35<12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14798: train loss 1.13216. lr 3.439806e-04:  91%|█████████ | 14798/16329 [2:04:35<12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14798: train loss 1.13216. lr 3.439806e-04:  91%|█████████ | 14799/16329 [2:04:35<12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14799: train loss 1.08370. lr 3.439521e-04:  91%|█████████ | 14799/16329 [2:04:36<12:42,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14799: train loss 1.08370. lr 3.439521e-04:  91%|█████████ | 14800/16329 [2:04:36<12:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14800: train loss 1.13033. lr 3.439235e-04:  91%|█████████ | 14800/16329 [2:04:36<12:41,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14800: train loss 1.13033. lr 3.439235e-04:  91%|█████████ | 14801/16329 [2:04:36<12:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14801: train loss 1.09496. lr 3.438950e-04:  91%|█████████ | 14801/16329 [2:04:37<12:39,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14801: train loss 1.09496. lr 3.438950e-04:  91%|█████████ | 14802/16329 [2:04:37<14:26,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 14802: train loss 1.10245. lr 3.438664e-04:  91%|█████████ | 14802/16329 [2:04:38<14:26,  1.76it/s]\u001b[A\n",
      "epoch 1 iter 14802: train loss 1.10245. lr 3.438664e-04:  91%|█████████ | 14803/16329 [2:04:38<14:13,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14803: train loss 1.10777. lr 3.438379e-04:  91%|█████████ | 14803/16329 [2:04:38<14:13,  1.79it/s]\u001b[A\n",
      "epoch 1 iter 14803: train loss 1.10777. lr 3.438379e-04:  91%|█████████ | 14804/16329 [2:04:38<13:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14804: train loss 1.06542. lr 3.438093e-04:  91%|█████████ | 14804/16329 [2:04:39<13:59,  1.82it/s]\u001b[A\n",
      "epoch 1 iter 14804: train loss 1.06542. lr 3.438093e-04:  91%|█████████ | 14805/16329 [2:04:39<13:46,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14805: train loss 1.11263. lr 3.437808e-04:  91%|█████████ | 14805/16329 [2:04:39<13:46,  1.84it/s]\u001b[A\n",
      "epoch 1 iter 14805: train loss 1.11263. lr 3.437808e-04:  91%|█████████ | 14806/16329 [2:04:39<13:35,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14806: train loss 1.08460. lr 3.437522e-04:  91%|█████████ | 14806/16329 [2:04:40<13:35,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14806: train loss 1.08460. lr 3.437522e-04:  91%|█████████ | 14807/16329 [2:04:40<13:21,  1.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14807: train loss 1.12266. lr 3.437237e-04:  91%|█████████ | 14807/16329 [2:04:40<13:21,  1.90it/s]\u001b[A\n",
      "epoch 1 iter 14807: train loss 1.12266. lr 3.437237e-04:  91%|█████████ | 14808/16329 [2:04:40<13:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14808: train loss 1.08393. lr 3.436951e-04:  91%|█████████ | 14808/16329 [2:04:41<13:10,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14808: train loss 1.08393. lr 3.436951e-04:  91%|█████████ | 14809/16329 [2:04:41<13:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14809: train loss 1.09962. lr 3.436666e-04:  91%|█████████ | 14809/16329 [2:04:41<13:02,  1.94it/s]\u001b[A\n",
      "epoch 1 iter 14809: train loss 1.09962. lr 3.436666e-04:  91%|█████████ | 14810/16329 [2:04:41<12:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14810: train loss 1.07891. lr 3.436380e-04:  91%|█████████ | 14810/16329 [2:04:42<12:51,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14810: train loss 1.07891. lr 3.436380e-04:  91%|█████████ | 14811/16329 [2:04:42<12:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14811: train loss 1.07368. lr 3.436095e-04:  91%|█████████ | 14811/16329 [2:04:42<12:44,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14811: train loss 1.07368. lr 3.436095e-04:  91%|█████████ | 14812/16329 [2:04:42<12:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14812: train loss 1.14049. lr 3.435809e-04:  91%|█████████ | 14812/16329 [2:04:43<12:39,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14812: train loss 1.14049. lr 3.435809e-04:  91%|█████████ | 14813/16329 [2:04:43<12:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14813: train loss 1.08232. lr 3.435523e-04:  91%|█████████ | 14813/16329 [2:04:43<12:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14813: train loss 1.08232. lr 3.435523e-04:  91%|█████████ | 14814/16329 [2:04:43<12:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14814: train loss 1.10866. lr 3.435238e-04:  91%|█████████ | 14814/16329 [2:04:44<12:35,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14814: train loss 1.10866. lr 3.435238e-04:  91%|█████████ | 14815/16329 [2:04:44<12:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14815: train loss 1.09330. lr 3.434952e-04:  91%|█████████ | 14815/16329 [2:04:44<12:34,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14815: train loss 1.09330. lr 3.434952e-04:  91%|█████████ | 14816/16329 [2:04:44<12:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14816: train loss 1.10636. lr 3.434667e-04:  91%|█████████ | 14816/16329 [2:04:45<12:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14816: train loss 1.10636. lr 3.434667e-04:  91%|█████████ | 14817/16329 [2:04:45<12:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14817: train loss 1.09657. lr 3.434381e-04:  91%|█████████ | 14817/16329 [2:04:45<12:32,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14817: train loss 1.09657. lr 3.434381e-04:  91%|█████████ | 14818/16329 [2:04:45<12:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14818: train loss 1.09407. lr 3.434096e-04:  91%|█████████ | 14818/16329 [2:04:46<12:31,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14818: train loss 1.09407. lr 3.434096e-04:  91%|█████████ | 14819/16329 [2:04:46<12:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14819: train loss 1.09121. lr 3.433810e-04:  91%|█████████ | 14819/16329 [2:04:46<12:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14819: train loss 1.09121. lr 3.433810e-04:  91%|█████████ | 14820/16329 [2:04:46<12:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14820: train loss 1.10720. lr 3.433525e-04:  91%|█████████ | 14820/16329 [2:04:47<12:27,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14820: train loss 1.10720. lr 3.433525e-04:  91%|█████████ | 14821/16329 [2:04:47<12:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14821: train loss 1.09080. lr 3.433239e-04:  91%|█████████ | 14821/16329 [2:04:47<12:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14821: train loss 1.09080. lr 3.433239e-04:  91%|█████████ | 14822/16329 [2:04:47<12:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14822: train loss 1.13602. lr 3.432953e-04:  91%|█████████ | 14822/16329 [2:04:48<12:29,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14822: train loss 1.13602. lr 3.432953e-04:  91%|█████████ | 14823/16329 [2:04:48<12:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14823: train loss 1.09120. lr 3.432668e-04:  91%|█████████ | 14823/16329 [2:04:48<12:30,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14823: train loss 1.09120. lr 3.432668e-04:  91%|█████████ | 14824/16329 [2:04:48<12:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14824: train loss 1.09734. lr 3.432382e-04:  91%|█████████ | 14824/16329 [2:04:49<12:27,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14824: train loss 1.09734. lr 3.432382e-04:  91%|█████████ | 14825/16329 [2:04:49<12:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14825: train loss 1.11756. lr 3.432097e-04:  91%|█████████ | 14825/16329 [2:04:49<12:26,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14825: train loss 1.11756. lr 3.432097e-04:  91%|█████████ | 14826/16329 [2:04:49<12:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14826: train loss 1.09695. lr 3.431811e-04:  91%|█████████ | 14826/16329 [2:04:50<12:25,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14826: train loss 1.09695. lr 3.431811e-04:  91%|█████████ | 14827/16329 [2:04:50<13:42,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 14827: train loss 1.06746. lr 3.431525e-04:  91%|█████████ | 14827/16329 [2:04:50<13:42,  1.83it/s]\u001b[A\n",
      "epoch 1 iter 14827: train loss 1.06746. lr 3.431525e-04:  91%|█████████ | 14828/16329 [2:04:50<13:19,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14828: train loss 1.08318. lr 3.431240e-04:  91%|█████████ | 14828/16329 [2:04:51<13:19,  1.88it/s]\u001b[A\n",
      "epoch 1 iter 14828: train loss 1.08318. lr 3.431240e-04:  91%|█████████ | 14829/16329 [2:04:51<13:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14829: train loss 1.10170. lr 3.430954e-04:  91%|█████████ | 14829/16329 [2:04:51<13:02,  1.92it/s]\u001b[A\n",
      "epoch 1 iter 14829: train loss 1.10170. lr 3.430954e-04:  91%|█████████ | 14830/16329 [2:04:51<12:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14830: train loss 1.11632. lr 3.430669e-04:  91%|█████████ | 14830/16329 [2:04:52<12:47,  1.95it/s]\u001b[A\n",
      "epoch 1 iter 14830: train loss 1.11632. lr 3.430669e-04:  91%|█████████ | 14831/16329 [2:04:52<12:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14831: train loss 1.11984. lr 3.430383e-04:  91%|█████████ | 14831/16329 [2:04:52<12:40,  1.97it/s]\u001b[A\n",
      "epoch 1 iter 14831: train loss 1.11984. lr 3.430383e-04:  91%|█████████ | 14832/16329 [2:04:52<12:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14832: train loss 1.09132. lr 3.430097e-04:  91%|█████████ | 14832/16329 [2:04:53<12:34,  1.98it/s]\u001b[A\n",
      "epoch 1 iter 14832: train loss 1.09132. lr 3.430097e-04:  91%|█████████ | 14833/16329 [2:04:53<12:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14833: train loss 1.08395. lr 3.429812e-04:  91%|█████████ | 14833/16329 [2:04:53<12:32,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14833: train loss 1.08395. lr 3.429812e-04:  91%|█████████ | 14834/16329 [2:04:53<12:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14834: train loss 1.11990. lr 3.429526e-04:  91%|█████████ | 14834/16329 [2:04:54<12:28,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14834: train loss 1.11990. lr 3.429526e-04:  91%|█████████ | 14835/16329 [2:04:54<12:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14835: train loss 1.08229. lr 3.429240e-04:  91%|█████████ | 14835/16329 [2:04:54<12:25,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14835: train loss 1.08229. lr 3.429240e-04:  91%|█████████ | 14836/16329 [2:04:54<12:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14836: train loss 1.09907. lr 3.428955e-04:  91%|█████████ | 14836/16329 [2:04:55<12:23,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14836: train loss 1.09907. lr 3.428955e-04:  91%|█████████ | 14837/16329 [2:04:55<12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14837: train loss 1.08370. lr 3.428669e-04:  91%|█████████ | 14837/16329 [2:04:55<12:19,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14837: train loss 1.08370. lr 3.428669e-04:  91%|█████████ | 14838/16329 [2:04:55<12:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14838: train loss 1.08514. lr 3.428384e-04:  91%|█████████ | 14838/16329 [2:04:56<12:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14838: train loss 1.08514. lr 3.428384e-04:  91%|█████████ | 14839/16329 [2:04:56<12:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14839: train loss 1.08964. lr 3.428098e-04:  91%|█████████ | 14839/16329 [2:04:56<12:27,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14839: train loss 1.08964. lr 3.428098e-04:  91%|█████████ | 14840/16329 [2:04:56<12:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14840: train loss 1.07405. lr 3.427812e-04:  91%|█████████ | 14840/16329 [2:04:57<12:29,  1.99it/s]\u001b[A\n",
      "epoch 1 iter 14840: train loss 1.07405. lr 3.427812e-04:  91%|█████████ | 14841/16329 [2:04:57<12:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14841: train loss 1.08224. lr 3.427527e-04:  91%|█████████ | 14841/16329 [2:04:57<12:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14841: train loss 1.08224. lr 3.427527e-04:  91%|█████████ | 14842/16329 [2:04:57<12:24,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 14842: train loss 1.10611. lr 3.427241e-04:  91%|█████████ | 14842/16329 [2:04:58<12:24,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14842: train loss 1.10611. lr 3.427241e-04:  91%|█████████ | 14843/16329 [2:04:58<12:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14843: train loss 1.12382. lr 3.426955e-04:  91%|█████████ | 14843/16329 [2:04:58<12:20,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14843: train loss 1.12382. lr 3.426955e-04:  91%|█████████ | 14844/16329 [2:04:58<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14844: train loss 1.10368. lr 3.426670e-04:  91%|█████████ | 14844/16329 [2:04:59<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14844: train loss 1.10368. lr 3.426670e-04:  91%|█████████ | 14845/16329 [2:04:59<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14845: train loss 1.09262. lr 3.426384e-04:  91%|█████████ | 14845/16329 [2:04:59<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14845: train loss 1.09262. lr 3.426384e-04:  91%|█████████ | 14846/16329 [2:04:59<12:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14846: train loss 1.11365. lr 3.426098e-04:  91%|█████████ | 14846/16329 [2:05:00<12:15,  2.02it/s]\u001b[A\n",
      "epoch 1 iter 14846: train loss 1.11365. lr 3.426098e-04:  91%|█████████ | 14847/16329 [2:05:00<12:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14847: train loss 1.07521. lr 3.425813e-04:  91%|█████████ | 14847/16329 [2:05:00<12:16,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14847: train loss 1.07521. lr 3.425813e-04:  91%|█████████ | 14848/16329 [2:05:00<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14848: train loss 1.10766. lr 3.425527e-04:  91%|█████████ | 14848/16329 [2:05:01<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14848: train loss 1.10766. lr 3.425527e-04:  91%|█████████ | 14849/16329 [2:05:01<12:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14849: train loss 1.09440. lr 3.425241e-04:  91%|█████████ | 14849/16329 [2:05:01<12:19,  2.00it/s]\u001b[A\n",
      "epoch 1 iter 14849: train loss 1.09440. lr 3.425241e-04:  91%|█████████ | 14850/16329 [2:05:01<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14850: train loss 1.09525. lr 3.424956e-04:  91%|█████████ | 14850/16329 [2:05:02<12:17,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14850: train loss 1.09525. lr 3.424956e-04:  91%|█████████ | 14851/16329 [2:05:02<12:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14851: train loss 1.06376. lr 3.424670e-04:  91%|█████████ | 14851/16329 [2:05:02<12:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14851: train loss 1.06376. lr 3.424670e-04:  91%|█████████ | 14852/16329 [2:05:02<12:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14852: train loss 1.08254. lr 3.424384e-04:  91%|█████████ | 14852/16329 [2:05:03<12:14,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14852: train loss 1.08254. lr 3.424384e-04:  91%|█████████ | 14853/16329 [2:05:03<12:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14853: train loss 1.06181. lr 3.424098e-04:  91%|█████████ | 14853/16329 [2:05:03<12:13,  2.01it/s]\u001b[A\n",
      "epoch 1 iter 14853: train loss 1.06181. lr 3.424098e-04:  91%|█████████ | 14854/16329 [2:05:03<13:32,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14854: train loss 1.09398. lr 3.423813e-04:  91%|█████████ | 14854/16329 [2:05:04<13:32,  1.81it/s]\u001b[A\n",
      "epoch 1 iter 14854: train loss 1.09398. lr 3.423813e-04:  91%|█████████ | 14855/16329 [2:05:04<13:08,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14855: train loss 1.11623. lr 3.423527e-04:  91%|█████████ | 14855/16329 [2:05:04<13:08,  1.87it/s]\u001b[A\n",
      "epoch 1 iter 14855: train loss 1.11623. lr 3.423527e-04:  91%|█████████ | 14856/16329 [2:05:04<12:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14856: train loss 1.10079. lr 3.423241e-04:  91%|█████████ | 14856/16329 [2:05:05<12:50,  1.91it/s]\u001b[A\n",
      "epoch 1 iter 14856: train loss 1.10079. lr 3.423241e-04:  91%|█████████ | 14857/16329 [2:05:05<12:38,  1.94it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for train_text_file in tqdm.tqdm(listdir(pathjoin(GENRE_DATA_DIR, LANG))):\n",
    "    label = train_text_file[:-4]\n",
    "    train_gpt_generator(\n",
    "        pathjoin(GENRE_DATA_DIR, LANG, train_text_file),\n",
    "        pathjoin(GPT_MODELS_DIR, LANG, label)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
