{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pathjoin\n",
    "from data_processing import *\n",
    "from interpretation import *\n",
    "from models import *\n",
    "from training import *\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data/'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "transformer_model = 'DeepPavlov/rubert-base-cased'\n",
    "MAX_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arhitecture' 'business' 'crime' 'education' 'games' 'literature' 'music'\n",
      " 'politics' 'sport' 'travel']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_generated_df = pd.read_csv(pathjoin(DATA_DIR, 'min_gpt_bpe/ru_train_topic_big_sep_generators.csv'))\n",
    "topic_list = np.unique(topic_generated_df.topic.values)\n",
    "\n",
    "print(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>726</td>\n",
       "      <td>A7</td>\n",
       "      <td>Глава 1 Приступая к работе 1.1 Знакомство с те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1871</td>\n",
       "      <td>A17</td>\n",
       "      <td>Kawasaki D-Tracker С недавних пор Kawasaki d-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1265</td>\n",
       "      <td>A17</td>\n",
       "      <td>По моему , вполне достойные книги , может и не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205</td>\n",
       "      <td>A11</td>\n",
       "      <td>Тест-драйв Lada Granta : новая надежда автогра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>A8</td>\n",
       "      <td>среда , 2 декабря 2009 года , 12.33 Бумага всё...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 target                                               text\n",
       "0         726     A7  Глава 1 Приступая к работе 1.1 Знакомство с те...\n",
       "1        1871    A17  Kawasaki D-Tracker С недавних пор Kawasaki d-t...\n",
       "2        1265    A17  По моему , вполне достойные книги , может и не...\n",
       "3         205    A11  Тест-драйв Lada Granta : новая надежда автогра...\n",
       "4         141     A8  среда , 2 декабря 2009 года , 12.33 Бумага всё..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(pathjoin(DATA_DIR, \"ru_test\"))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_topic(topic, calc_triggers):\n",
    "    MODEL_ID = f'allennlp_rubert_from_topic_generated_{topic}'\n",
    "    CHECKPOINTS_DIR = pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints')\n",
    "    BEST_MODEL = pathjoin(CHECKPOINTS_DIR, 'best.th')\n",
    "    \n",
    "    vocab = Vocabulary().from_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))\n",
    "    model = build_transformer_model(vocab, transformer_model)\n",
    "    if torch.cuda.is_available():\n",
    "        cuda_device = 1\n",
    "    else:\n",
    "        cuda_device = -1\n",
    "    model.load_state_dict(torch.load(BEST_MODEL, map_location=f'cuda:{cuda_device}'))\n",
    "    \n",
    "    dataset_reader = build_transformer_dataset_reader(transformer_model, MAX_TOKENS)\n",
    "    predictor = TextClassifierPredictor(model, dataset_reader=dataset_reader)\n",
    "    predicted_classes = np.array(predict_classes(test_df.text.values, predictor, vocab))\n",
    "    good_sentences = get_all_correctly_predicted_sentences(\n",
    "        test_df.text.values, test_df.target.values, predicted_classes\n",
    "    )\n",
    "    smooth_grad = SmoothGradient(predictor)\n",
    "    triggers = []\n",
    "    if calc_triggers:\n",
    "        triggers = get_most_frequent_trigger_words(good_sentences, dataset_reader.tokenizer, 50, smooth_grad)\n",
    "        \n",
    "    return accuracy_score(test_df.target.values, predicted_classes), triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_words = {}\n",
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [43:08<6:28:13, 2588.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [1:24:23<5:40:34, 2554.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [1:26:18<3:32:37, 1822.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [1:28:14<2:11:02, 1310.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [1:30:05<1:19:14, 950.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [1:31:59<46:38, 699.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [1:33:50<26:09, 523.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [2:15:04<36:56, 1108.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [2:16:59<13:30, 810.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:18:52<00:00, 833.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for topic in tqdm.tqdm(topic_list):\n",
    "    cur_accuracy, cur_triggers = interpret_topic(topic, topic in ['arhitecture', 'business', 'politics'])\n",
    "    accuracy[topic] = cur_accuracy\n",
    "    trigger_words[topic] = cur_triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arhitecture': 0.7681159420289855, 'business': 0.7598343685300207, 'crime': 0.7184265010351967, 'education': 0.7329192546583851, 'games': 0.7204968944099379, 'literature': 0.7329192546583851, 'music': 0.7370600414078675, 'politics': 0.7494824016563147, 'sport': 0.7329192546583851, 'travel': 0.7329192546583851}\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('topic_accuracy_results.txt', 'w').write(str(accuracy))\n",
    "open('topic_trigger_words_results.txt', 'w').write(str(trigger_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arhitecture \n",
      " ['.', ',', '[SEP]', '[CLS]', '-', 'в', '>', '<', '\"', 'росс', 'заявил', ')', ':', 'я', 'мы', '(', '##еи', '##и', ';', '/', 'и', 'на', 'br', 'вы', '##ои', '!', '?', 'сегодня', 'котор', 'президент', 'москв', '##ии', 'вам', 'позволяет', 'россия', 'не', 'этом', '##p', 'это', 'с', 'будет', 'что', 'р', 'как', 'меня', 'украин', 'сказал', 'европ', 'для', 'можно', '##а', 'деи', 'по', 'компании', '#', 'президента', 'ga', 'компания', '[', 'а', '«', 'словам', '2', 'модели', '»', 'сш', '*', 'ее', 'сообщает', 'се', 'нас', 'пресс', 'сообщил', 'новости', '##ев', '—', 'напомним', 'вас', '##ф', '1', 'все', 'он', 'отметил', 'технология', 'просто', '##мите', 'года', 'очень', '3', 'является', '##ичас', 'можете', 'кажд', '##ическо', 'мне', 'будут', 'са', '2011', '2013', 'наша']\n",
      "business \n",
      " ['.', ',', '[SEP]', '[CLS]', 'в', '\"', '-', 'росс', ':', 'и', '<', '##и', 'президент', 'заявил', '>', '(', ';', ')', '/', 'я', 'москв', 'мы', '!', '##еи', 'не', 'на', 'что', 'можно', 'br', 'сегодня', '?', '[', 'котор', 'кита', 'статья', 'сш', 'вы', 'позволяет', '#', 'украин', 'модели', 'модель', '##ои', 'как', '2', '##ф', 'россия', 'по', 'словам', 'сказал', 'медвед', 'меня', 'этом', 'наша', 'ga', 'ее', 'европ', '##p', 'для', 'он', 'компании', 'еще', 'деи', 'мне', '##ии', 'с', 'р', '##а', 'компания', 'вполне', '##ичас', 'нужно', 'сообщил', 'новости', 'владимир', 'очень', '1', 'является', 'отметил', 'а', 'если', 'может', 'се', 'будет', '–', '«', '##мит', 'глава', 'массаж', 'конечно', 'но', 'это', 'современ', 'александр', 'президента', 'лек', 'то', 'п', 'ранее', 'экспорт']\n",
      "crime \n",
      " []\n",
      "education \n",
      " []\n",
      "games \n",
      " []\n",
      "literature \n",
      " []\n",
      "music \n",
      " []\n",
      "politics \n",
      " ['.', ',', '[SEP]', '[CLS]', 'в', 'росс', '##и', '\"', ':', '-', 'и', ')', '!', '<', 'на', '(', '##еи', 'br', 'заявил', ';', '>', '/', 'москв', 'мы', '[', '?', 'по', 'с', 'украин', '##ои', '##ии', 'не', 'сш', 'вам', 'президент', '##ф', 'кита', 'я', '##p', 'это', '*', 'европ', 'сегодня', 'деи', 'что', 'для', 'ga', 'как', 'вы', 'компания', 'котор', 'очень', 'ее', 'р', 'этом', 'сообщил', 'к', '#', '—', '##ичас', 'еще', 'сообщает', 'безопасности', 'россия', '»', 'компании', 'словам', 'медвед', '1', 'но', 'будет', '##а', '##ны', 'модели', ']', 'д', 'можно', 'напомним', 'анд', '##мите', '##ы', '3', 'его', 'позволяет', '«', 'владимир', 'модель', 'вас', 'новости', 'он', '##мит', 'федерации', '##ическо', 'можете', 'современ', 'было', 'глава', 'люб', 'диз', '##ющ']\n",
      "sport \n",
      " []\n",
      "travel \n",
      " []\n"
     ]
    }
   ],
   "source": [
    "for key, value in trigger_words.items():\n",
    "    print(key, '\\n', [pair[0] for pair in value][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
