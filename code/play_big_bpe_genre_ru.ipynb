{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a character-level GPT on some text data\n",
    "\n",
    "The inputs here are simple text files, which we chop up to individual characters and then train GPT on. So you could say this is a char-transformer instead of a char-rnn. Doesn't quite roll off the tongue as well. In this example we will feed it some Shakespeare, which we'll get it to predict character-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import TokenIndexer, PretrainedTransformerIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, PretrainedTransformerTokenizer\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join as pathjoin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "from minGPT.mingpt.model import GPT, GPTConfig\n",
    "from minGPT.mingpt.trainer import Trainer, TrainerConfig\n",
    "# make deterministic\n",
    "from minGPT.mingpt.utils import sample, set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data/big'\n",
    "#MODELS_DIR = '/home/mlepekhin/models/big'\n",
    "transformer_model = 'DeepPavlov/rubert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def detokenize(tokens):\n",
    "    return ' '.join([str(x) for x in tokens[1:-1]]).replace(' ##', '')\n",
    "\n",
    "class BPEDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)\n",
    "#indexer = PretrainedTransformerIndexer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt_generator(train_text_file, state_dict_file, n_layer=8, n_head=8, n_embd=512,\n",
    "                        max_epochs=1, batch_size=256):\n",
    "    text_sentences = nltk.tokenize.sent_tokenize(open(train_text_file, 'r').read())\n",
    "    tokens = np.concatenate([tokenizer.tokenize(sent)[1:-1] for sent in text_sentences])\n",
    "    tokens = [str(token) for token in tokens]\n",
    "    train_dataset = BPEDataset(tokens, block_size) \n",
    "    \n",
    "    mconf = GPTConfig(\n",
    "        train_dataset.vocab_size, train_dataset.block_size,\n",
    "        n_layer=n_layer, n_head=n_head, n_embd=n_embd\n",
    "    )\n",
    "    model = GPT(mconf)\n",
    "    tconf = TrainerConfig(\n",
    "        max_epochs=max_epochs, batch_size=batch_size, learning_rate=6e-4,\n",
    "        lr_decay=True, warmup_tokens=batch_size*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "        num_workers=3\n",
    "    )\n",
    "    trainer = Trainer(model, train_dataset, None, tconf)\n",
    "    trainer.train()\n",
    "    torch.save(model.state_dict(), state_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_DATA_DIR = '/home/mlepekhin/data/big/genre'\n",
    "GPT_MODELS_DIR = '/home/mlepekhin/models/mini_gpt_big_bpe/'\n",
    "LANG = 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_gpt_generator(\n",
    "#        pathjoin(GENRE_DATA_DIR, LANG, 'A1.txt'),\n",
    "#        pathjoin(GPT_MODELS_DIR, LANG, 'A1')\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 732852 characters, 38863 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2863 [00:00<?, ?it/s]\u001b[A/home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "epoch 1 iter 0: train loss 10.66786. lr 6.000000e-04:   0%|          | 0/2863 [00:07<?, ?it/s]\u001b[A\n",
      "epoch 1 iter 0: train loss 10.66786. lr 6.000000e-04:   0%|          | 1/2863 [00:07<6:16:40,  7.90s/it]\u001b[A\n",
      "epoch 1 iter 1: train loss 9.92521. lr 5.999998e-04:   0%|          | 1/2863 [00:08<6:16:40,  7.90s/it] \u001b[A\n",
      "epoch 1 iter 1: train loss 9.92521. lr 5.999998e-04:   0%|          | 2/2863 [00:08<4:33:06,  5.73s/it]\u001b[A\n",
      "epoch 1 iter 2: train loss 9.49199. lr 5.999996e-04:   0%|          | 2/2863 [00:09<4:33:06,  5.73s/it]\u001b[A\n",
      "epoch 1 iter 2: train loss 9.49199. lr 5.999996e-04:   0%|          | 3/2863 [00:09<3:20:35,  4.21s/it]\u001b[A\n",
      "epoch 1 iter 3: train loss 9.22060. lr 5.999993e-04:   0%|          | 3/2863 [00:09<3:20:35,  4.21s/it]\u001b[A\n",
      "epoch 1 iter 3: train loss 9.22060. lr 5.999993e-04:   0%|          | 4/2863 [00:09<2:29:50,  3.14s/it]\u001b[A\n",
      "epoch 1 iter 4: train loss 8.97282. lr 5.999989e-04:   0%|          | 4/2863 [00:10<2:29:50,  3.14s/it]\u001b[A\n",
      "epoch 1 iter 4: train loss 8.97282. lr 5.999989e-04:   0%|          | 5/2863 [00:10<1:54:20,  2.40s/it]\u001b[A\n",
      "epoch 1 iter 5: train loss 8.77729. lr 5.999985e-04:   0%|          | 5/2863 [00:11<1:54:20,  2.40s/it]\u001b[A\n",
      "epoch 1 iter 5: train loss 8.77729. lr 5.999985e-04:   0%|          | 6/2863 [00:11<1:29:30,  1.88s/it]\u001b[A\n",
      "epoch 1 iter 6: train loss 8.55841. lr 5.999979e-04:   0%|          | 6/2863 [00:11<1:29:30,  1.88s/it]\u001b[A\n",
      "epoch 1 iter 6: train loss 8.55841. lr 5.999979e-04:   0%|          | 7/2863 [00:11<1:12:04,  1.51s/it]\u001b[A\n",
      "epoch 1 iter 7: train loss 8.34962. lr 5.999972e-04:   0%|          | 7/2863 [00:12<1:12:04,  1.51s/it]\u001b[A\n",
      "epoch 1 iter 7: train loss 8.34962. lr 5.999972e-04:   0%|          | 8/2863 [00:12<59:53,  1.26s/it]  \u001b[A\n",
      "epoch 1 iter 8: train loss 8.19700. lr 5.999965e-04:   0%|          | 8/2863 [00:13<59:53,  1.26s/it]\u001b[A\n",
      "epoch 1 iter 8: train loss 8.19700. lr 5.999965e-04:   0%|          | 9/2863 [00:13<51:20,  1.08s/it]\u001b[A\n",
      "epoch 1 iter 9: train loss 8.07607. lr 5.999956e-04:   0%|          | 9/2863 [00:13<51:20,  1.08s/it]\u001b[A\n",
      "epoch 1 iter 9: train loss 8.07607. lr 5.999956e-04:   0%|          | 10/2863 [00:13<45:23,  1.05it/s]\u001b[A\n",
      "epoch 1 iter 10: train loss 7.96550. lr 5.999947e-04:   0%|          | 10/2863 [00:14<45:23,  1.05it/s]\u001b[A\n",
      "epoch 1 iter 10: train loss 7.96550. lr 5.999947e-04:   0%|          | 11/2863 [00:14<41:11,  1.15it/s]\u001b[A\n",
      "epoch 1 iter 11: train loss 7.83158. lr 5.999937e-04:   0%|          | 11/2863 [00:15<41:11,  1.15it/s]\u001b[A\n",
      "epoch 1 iter 11: train loss 7.83158. lr 5.999937e-04:   0%|          | 12/2863 [00:15<38:15,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 12: train loss 7.80339. lr 5.999925e-04:   0%|          | 12/2863 [00:15<38:15,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 12: train loss 7.80339. lr 5.999925e-04:   0%|          | 13/2863 [00:15<36:10,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 13: train loss 7.68632. lr 5.999913e-04:   0%|          | 13/2863 [00:16<36:10,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 13: train loss 7.68632. lr 5.999913e-04:   0%|          | 14/2863 [00:16<34:43,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 14: train loss 7.69579. lr 5.999900e-04:   0%|          | 14/2863 [00:17<34:43,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 14: train loss 7.69579. lr 5.999900e-04:   1%|          | 15/2863 [00:17<33:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 15: train loss 7.72225. lr 5.999887e-04:   1%|          | 15/2863 [00:17<33:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 15: train loss 7.72225. lr 5.999887e-04:   1%|          | 16/2863 [00:17<33:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 16: train loss 7.75294. lr 5.999872e-04:   1%|          | 16/2863 [00:18<33:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 16: train loss 7.75294. lr 5.999872e-04:   1%|          | 17/2863 [00:18<32:31,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 17: train loss 7.74360. lr 5.999856e-04:   1%|          | 17/2863 [00:19<32:31,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 17: train loss 7.74360. lr 5.999856e-04:   1%|          | 18/2863 [00:19<32:10,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 18: train loss 7.69322. lr 5.999840e-04:   1%|          | 18/2863 [00:19<32:10,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 18: train loss 7.69322. lr 5.999840e-04:   1%|          | 19/2863 [00:19<31:53,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 19: train loss 7.71288. lr 5.999822e-04:   1%|          | 19/2863 [00:20<31:53,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 19: train loss 7.71288. lr 5.999822e-04:   1%|          | 20/2863 [00:20<31:43,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 20: train loss 7.69590. lr 5.999804e-04:   1%|          | 20/2863 [00:21<31:43,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 20: train loss 7.69590. lr 5.999804e-04:   1%|          | 21/2863 [00:21<31:35,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 21: train loss 7.67342. lr 5.999784e-04:   1%|          | 21/2863 [00:21<31:35,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 21: train loss 7.67342. lr 5.999784e-04:   1%|          | 22/2863 [00:21<31:28,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 22: train loss 7.68437. lr 5.999764e-04:   1%|          | 22/2863 [00:22<31:28,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 22: train loss 7.68437. lr 5.999764e-04:   1%|          | 23/2863 [00:22<31:25,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 23: train loss 7.90661. lr 5.999743e-04:   1%|          | 23/2863 [00:23<31:25,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 23: train loss 7.90661. lr 5.999743e-04:   1%|          | 24/2863 [00:23<31:23,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 24: train loss 7.64334. lr 5.999721e-04:   1%|          | 24/2863 [00:23<31:23,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 24: train loss 7.64334. lr 5.999721e-04:   1%|          | 25/2863 [00:23<31:20,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 25: train loss 7.67529. lr 5.999698e-04:   1%|          | 25/2863 [00:24<31:20,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 25: train loss 7.67529. lr 5.999698e-04:   1%|          | 26/2863 [00:24<31:18,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 26: train loss 7.62975. lr 5.999674e-04:   1%|          | 26/2863 [00:25<31:18,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 26: train loss 7.62975. lr 5.999674e-04:   1%|          | 27/2863 [00:25<31:17,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 27: train loss 7.65090. lr 5.999650e-04:   1%|          | 27/2863 [00:25<31:17,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 27: train loss 7.65090. lr 5.999650e-04:   1%|          | 28/2863 [00:25<31:17,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 28: train loss 7.60575. lr 5.999624e-04:   1%|          | 28/2863 [00:26<31:17,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 28: train loss 7.60575. lr 5.999624e-04:   1%|          | 29/2863 [00:26<31:15,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 29: train loss 7.63272. lr 5.999598e-04:   1%|          | 29/2863 [00:27<31:15,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 29: train loss 7.63272. lr 5.999598e-04:   1%|          | 30/2863 [00:27<31:14,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 30: train loss 7.60817. lr 5.999570e-04:   1%|          | 30/2863 [00:27<31:14,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 30: train loss 7.60817. lr 5.999570e-04:   1%|          | 31/2863 [00:27<31:13,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 31: train loss 7.61217. lr 5.999542e-04:   1%|          | 31/2863 [00:28<31:13,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 31: train loss 7.61217. lr 5.999542e-04:   1%|          | 32/2863 [00:28<31:14,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 32: train loss 7.58566. lr 5.999513e-04:   1%|          | 32/2863 [00:29<31:14,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 32: train loss 7.58566. lr 5.999513e-04:   1%|          | 33/2863 [00:29<31:12,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 33: train loss 7.58206. lr 5.999483e-04:   1%|          | 33/2863 [00:29<31:12,  1.51it/s]\u001b[A\n",
      "epoch 1 iter 33: train loss 7.58206. lr 5.999483e-04:   1%|          | 34/2863 [00:29<32:13,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 34: train loss 7.54023. lr 5.999451e-04:   1%|          | 34/2863 [00:30<32:13,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 34: train loss 7.54023. lr 5.999451e-04:   1%|          | 35/2863 [00:30<33:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 35: train loss 7.57142. lr 5.999420e-04:   1%|          | 35/2863 [00:31<33:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 35: train loss 7.57142. lr 5.999420e-04:   1%|▏         | 36/2863 [00:31<33:51,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 36: train loss 7.53150. lr 5.999387e-04:   1%|▏         | 36/2863 [00:32<33:51,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 36: train loss 7.53150. lr 5.999387e-04:   1%|▏         | 37/2863 [00:32<34:18,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 37: train loss 7.51890. lr 5.999353e-04:   1%|▏         | 37/2863 [00:32<34:18,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 37: train loss 7.51890. lr 5.999353e-04:   1%|▏         | 38/2863 [00:32<34:38,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 38: train loss 7.47893. lr 5.999318e-04:   1%|▏         | 38/2863 [00:33<34:38,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 38: train loss 7.47893. lr 5.999318e-04:   1%|▏         | 39/2863 [00:33<34:44,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 39: train loss 7.53272. lr 5.999283e-04:   1%|▏         | 39/2863 [00:34<34:44,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 39: train loss 7.53272. lr 5.999283e-04:   1%|▏         | 40/2863 [00:34<34:53,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 40: train loss 7.46947. lr 5.999246e-04:   1%|▏         | 40/2863 [00:35<34:53,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 40: train loss 7.46947. lr 5.999246e-04:   1%|▏         | 41/2863 [00:35<35:04,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 41: train loss 7.43743. lr 5.999209e-04:   1%|▏         | 41/2863 [00:35<35:04,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 41: train loss 7.43743. lr 5.999209e-04:   1%|▏         | 42/2863 [00:35<35:11,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 42: train loss 7.46158. lr 5.999171e-04:   1%|▏         | 42/2863 [00:36<35:11,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 42: train loss 7.46158. lr 5.999171e-04:   2%|▏         | 43/2863 [00:36<35:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 43: train loss 7.42600. lr 5.999132e-04:   2%|▏         | 43/2863 [00:37<35:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 43: train loss 7.42600. lr 5.999132e-04:   2%|▏         | 44/2863 [00:37<35:06,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 44: train loss 7.42038. lr 5.999091e-04:   2%|▏         | 44/2863 [00:38<35:06,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 44: train loss 7.42038. lr 5.999091e-04:   2%|▏         | 45/2863 [00:38<35:06,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 45: train loss 7.43873. lr 5.999051e-04:   2%|▏         | 45/2863 [00:38<35:06,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 45: train loss 7.43873. lr 5.999051e-04:   2%|▏         | 46/2863 [00:38<35:08,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 46: train loss 7.43876. lr 5.999009e-04:   2%|▏         | 46/2863 [00:39<35:08,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 46: train loss 7.43876. lr 5.999009e-04:   2%|▏         | 47/2863 [00:39<37:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 47: train loss 7.36494. lr 5.998966e-04:   2%|▏         | 47/2863 [00:40<37:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 47: train loss 7.36494. lr 5.998966e-04:   2%|▏         | 48/2863 [00:40<36:44,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 48: train loss 7.38867. lr 5.998922e-04:   2%|▏         | 48/2863 [00:41<36:44,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 48: train loss 7.38867. lr 5.998922e-04:   2%|▏         | 49/2863 [00:41<36:05,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 49: train loss 7.40459. lr 5.998878e-04:   2%|▏         | 49/2863 [00:41<36:05,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 49: train loss 7.40459. lr 5.998878e-04:   2%|▏         | 50/2863 [00:41<35:45,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 50: train loss 7.41298. lr 5.998832e-04:   2%|▏         | 50/2863 [00:42<35:45,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 50: train loss 7.41298. lr 5.998832e-04:   2%|▏         | 51/2863 [00:42<35:43,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 51: train loss 7.34230. lr 5.998786e-04:   2%|▏         | 51/2863 [00:43<35:43,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 51: train loss 7.34230. lr 5.998786e-04:   2%|▏         | 52/2863 [00:43<35:33,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 52: train loss 7.32695. lr 5.998738e-04:   2%|▏         | 52/2863 [00:44<35:33,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 52: train loss 7.32695. lr 5.998738e-04:   2%|▏         | 53/2863 [00:44<35:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 53: train loss 7.34919. lr 5.998690e-04:   2%|▏         | 53/2863 [00:44<35:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 53: train loss 7.34919. lr 5.998690e-04:   2%|▏         | 54/2863 [00:44<35:27,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 54: train loss 7.29024. lr 5.998641e-04:   2%|▏         | 54/2863 [00:45<35:27,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 54: train loss 7.29024. lr 5.998641e-04:   2%|▏         | 55/2863 [00:45<35:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 55: train loss 7.35744. lr 5.998591e-04:   2%|▏         | 55/2863 [00:46<35:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 55: train loss 7.35744. lr 5.998591e-04:   2%|▏         | 56/2863 [00:46<35:15,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 56: train loss 7.31873. lr 5.998540e-04:   2%|▏         | 56/2863 [00:47<35:15,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 56: train loss 7.31873. lr 5.998540e-04:   2%|▏         | 57/2863 [00:47<35:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 57: train loss 7.30372. lr 5.998488e-04:   2%|▏         | 57/2863 [00:47<35:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 57: train loss 7.30372. lr 5.998488e-04:   2%|▏         | 58/2863 [00:47<35:13,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 58: train loss 7.25303. lr 5.998436e-04:   2%|▏         | 58/2863 [00:48<35:13,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 58: train loss 7.25303. lr 5.998436e-04:   2%|▏         | 59/2863 [00:48<35:21,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 59: train loss 7.27448. lr 5.998382e-04:   2%|▏         | 59/2863 [00:49<35:21,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 59: train loss 7.27448. lr 5.998382e-04:   2%|▏         | 60/2863 [00:49<35:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 60: train loss 7.25802. lr 5.998328e-04:   2%|▏         | 60/2863 [00:50<35:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 60: train loss 7.25802. lr 5.998328e-04:   2%|▏         | 61/2863 [00:50<35:14,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 61: train loss 7.25779. lr 5.998272e-04:   2%|▏         | 61/2863 [00:51<35:14,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 61: train loss 7.25779. lr 5.998272e-04:   2%|▏         | 62/2863 [00:51<35:13,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 62: train loss 7.22876. lr 5.998216e-04:   2%|▏         | 62/2863 [00:51<35:13,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 62: train loss 7.22876. lr 5.998216e-04:   2%|▏         | 63/2863 [00:51<35:10,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 63: train loss 7.25039. lr 5.998159e-04:   2%|▏         | 63/2863 [00:52<35:10,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 63: train loss 7.25039. lr 5.998159e-04:   2%|▏         | 64/2863 [00:52<35:11,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 64: train loss 7.22112. lr 5.998100e-04:   2%|▏         | 64/2863 [00:53<35:11,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 64: train loss 7.22112. lr 5.998100e-04:   2%|▏         | 65/2863 [00:53<35:06,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 65: train loss 7.27313. lr 5.998041e-04:   2%|▏         | 65/2863 [00:54<35:06,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 65: train loss 7.27313. lr 5.998041e-04:   2%|▏         | 66/2863 [00:54<35:08,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 66: train loss 7.21984. lr 5.997982e-04:   2%|▏         | 66/2863 [00:54<35:08,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 66: train loss 7.21984. lr 5.997982e-04:   2%|▏         | 67/2863 [00:54<35:10,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 67: train loss 7.16888. lr 5.997921e-04:   2%|▏         | 67/2863 [00:55<35:10,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 67: train loss 7.16888. lr 5.997921e-04:   2%|▏         | 68/2863 [00:55<35:09,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 68: train loss 7.15303. lr 5.997859e-04:   2%|▏         | 68/2863 [00:56<35:09,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 68: train loss 7.15303. lr 5.997859e-04:   2%|▏         | 69/2863 [00:56<35:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 69: train loss 7.13144. lr 5.997796e-04:   2%|▏         | 69/2863 [00:57<35:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 69: train loss 7.13144. lr 5.997796e-04:   2%|▏         | 70/2863 [00:57<35:06,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 70: train loss 7.20504. lr 5.997733e-04:   2%|▏         | 70/2863 [00:57<35:06,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 70: train loss 7.20504. lr 5.997733e-04:   2%|▏         | 71/2863 [00:57<35:06,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 71: train loss 7.14483. lr 5.997668e-04:   2%|▏         | 71/2863 [00:58<35:06,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 71: train loss 7.14483. lr 5.997668e-04:   3%|▎         | 72/2863 [00:58<35:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 72: train loss 7.19755. lr 5.997603e-04:   3%|▎         | 72/2863 [00:59<35:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 72: train loss 7.19755. lr 5.997603e-04:   3%|▎         | 73/2863 [00:59<35:13,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 73: train loss 7.12096. lr 5.997537e-04:   3%|▎         | 73/2863 [01:00<35:13,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 73: train loss 7.12096. lr 5.997537e-04:   3%|▎         | 74/2863 [01:00<35:17,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 74: train loss 7.12664. lr 5.997470e-04:   3%|▎         | 74/2863 [01:00<35:17,  1.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 74: train loss 7.12664. lr 5.997470e-04:   3%|▎         | 75/2863 [01:00<35:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 75: train loss 7.16155. lr 5.997401e-04:   3%|▎         | 75/2863 [01:01<35:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 75: train loss 7.16155. lr 5.997401e-04:   3%|▎         | 76/2863 [01:01<35:05,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 76: train loss 7.12394. lr 5.997332e-04:   3%|▎         | 76/2863 [01:02<35:05,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 76: train loss 7.12394. lr 5.997332e-04:   3%|▎         | 77/2863 [01:02<35:09,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 77: train loss 7.14290. lr 5.997263e-04:   3%|▎         | 77/2863 [01:03<35:09,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 77: train loss 7.14290. lr 5.997263e-04:   3%|▎         | 78/2863 [01:03<35:08,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 78: train loss 7.13642. lr 5.997192e-04:   3%|▎         | 78/2863 [01:03<35:08,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 78: train loss 7.13642. lr 5.997192e-04:   3%|▎         | 79/2863 [01:03<35:03,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 79: train loss 7.07333. lr 5.997120e-04:   3%|▎         | 79/2863 [01:04<35:03,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 79: train loss 7.07333. lr 5.997120e-04:   3%|▎         | 80/2863 [01:04<35:08,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 80: train loss 7.05375. lr 5.997048e-04:   3%|▎         | 80/2863 [01:05<35:08,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 80: train loss 7.05375. lr 5.997048e-04:   3%|▎         | 81/2863 [01:05<34:58,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 81: train loss 7.10385. lr 5.996974e-04:   3%|▎         | 81/2863 [01:06<34:58,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 81: train loss 7.10385. lr 5.996974e-04:   3%|▎         | 82/2863 [01:06<36:34,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 82: train loss 6.98313. lr 5.996900e-04:   3%|▎         | 82/2863 [01:06<36:34,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 82: train loss 6.98313. lr 5.996900e-04:   3%|▎         | 83/2863 [01:07<36:08,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 83: train loss 6.98817. lr 5.996824e-04:   3%|▎         | 83/2863 [01:07<36:08,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 83: train loss 6.98817. lr 5.996824e-04:   3%|▎         | 84/2863 [01:07<35:52,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 84: train loss 7.00351. lr 5.996748e-04:   3%|▎         | 84/2863 [01:08<35:52,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 84: train loss 7.00351. lr 5.996748e-04:   3%|▎         | 85/2863 [01:08<35:37,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 85: train loss 7.09378. lr 5.996671e-04:   3%|▎         | 85/2863 [01:09<35:37,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 85: train loss 7.09378. lr 5.996671e-04:   3%|▎         | 86/2863 [01:09<35:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 86: train loss 7.07882. lr 5.996593e-04:   3%|▎         | 86/2863 [01:10<35:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 86: train loss 7.07882. lr 5.996593e-04:   3%|▎         | 87/2863 [01:10<35:17,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 87: train loss 6.99650. lr 5.996514e-04:   3%|▎         | 87/2863 [01:10<35:17,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 87: train loss 6.99650. lr 5.996514e-04:   3%|▎         | 88/2863 [01:10<35:15,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 88: train loss 6.92855. lr 5.996434e-04:   3%|▎         | 88/2863 [01:11<35:15,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 88: train loss 6.92855. lr 5.996434e-04:   3%|▎         | 89/2863 [01:11<35:11,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 89: train loss 6.97331. lr 5.996354e-04:   3%|▎         | 89/2863 [01:12<35:11,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 89: train loss 6.97331. lr 5.996354e-04:   3%|▎         | 90/2863 [01:12<35:09,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 90: train loss 6.97575. lr 5.996272e-04:   3%|▎         | 90/2863 [01:13<35:09,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 90: train loss 6.97575. lr 5.996272e-04:   3%|▎         | 91/2863 [01:13<34:59,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 91: train loss 6.98841. lr 5.996190e-04:   3%|▎         | 91/2863 [01:13<34:59,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 91: train loss 6.98841. lr 5.996190e-04:   3%|▎         | 92/2863 [01:13<34:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 92: train loss 6.94867. lr 5.996106e-04:   3%|▎         | 92/2863 [01:14<34:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 92: train loss 6.94867. lr 5.996106e-04:   3%|▎         | 93/2863 [01:14<34:59,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 93: train loss 6.91844. lr 5.996022e-04:   3%|▎         | 93/2863 [01:15<34:59,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 93: train loss 6.91844. lr 5.996022e-04:   3%|▎         | 94/2863 [01:15<34:55,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 94: train loss 6.93484. lr 5.995937e-04:   3%|▎         | 94/2863 [01:16<34:55,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 94: train loss 6.93484. lr 5.995937e-04:   3%|▎         | 95/2863 [01:16<34:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 95: train loss 6.89638. lr 5.995851e-04:   3%|▎         | 95/2863 [01:16<34:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 95: train loss 6.89638. lr 5.995851e-04:   3%|▎         | 96/2863 [01:16<34:49,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 96: train loss 6.93820. lr 5.995764e-04:   3%|▎         | 96/2863 [01:17<34:49,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 96: train loss 6.93820. lr 5.995764e-04:   3%|▎         | 97/2863 [01:17<34:44,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 97: train loss 6.93996. lr 5.995676e-04:   3%|▎         | 97/2863 [01:18<34:44,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 97: train loss 6.93996. lr 5.995676e-04:   3%|▎         | 98/2863 [01:18<34:49,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 98: train loss 6.83602. lr 5.995587e-04:   3%|▎         | 98/2863 [01:19<34:49,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 98: train loss 6.83602. lr 5.995587e-04:   3%|▎         | 99/2863 [01:19<34:50,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 99: train loss 6.91911. lr 5.995497e-04:   3%|▎         | 99/2863 [01:19<34:50,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 99: train loss 6.91911. lr 5.995497e-04:   3%|▎         | 100/2863 [01:19<34:51,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 100: train loss 6.88486. lr 5.995407e-04:   3%|▎         | 100/2863 [01:20<34:51,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 100: train loss 6.88486. lr 5.995407e-04:   4%|▎         | 101/2863 [01:20<34:51,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 101: train loss 6.89810. lr 5.995315e-04:   4%|▎         | 101/2863 [01:21<34:51,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 101: train loss 6.89810. lr 5.995315e-04:   4%|▎         | 102/2863 [01:21<34:47,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 102: train loss 6.87224. lr 5.995223e-04:   4%|▎         | 102/2863 [01:22<34:47,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 102: train loss 6.87224. lr 5.995223e-04:   4%|▎         | 103/2863 [01:22<34:52,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 103: train loss 6.81732. lr 5.995129e-04:   4%|▎         | 103/2863 [01:22<34:52,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 103: train loss 6.81732. lr 5.995129e-04:   4%|▎         | 104/2863 [01:22<34:56,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 104: train loss 6.89236. lr 5.995035e-04:   4%|▎         | 104/2863 [01:23<34:56,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 104: train loss 6.89236. lr 5.995035e-04:   4%|▎         | 105/2863 [01:23<34:58,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 105: train loss 6.84312. lr 5.994940e-04:   4%|▎         | 105/2863 [01:24<34:58,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 105: train loss 6.84312. lr 5.994940e-04:   4%|▎         | 106/2863 [01:24<34:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 106: train loss 6.81412. lr 5.994844e-04:   4%|▎         | 106/2863 [01:25<34:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 106: train loss 6.81412. lr 5.994844e-04:   4%|▎         | 107/2863 [01:25<34:52,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 107: train loss 6.81103. lr 5.994747e-04:   4%|▎         | 107/2863 [01:25<34:52,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 107: train loss 6.81103. lr 5.994747e-04:   4%|▍         | 108/2863 [01:25<34:47,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 108: train loss 6.82239. lr 5.994649e-04:   4%|▍         | 108/2863 [01:26<34:47,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 108: train loss 6.82239. lr 5.994649e-04:   4%|▍         | 109/2863 [01:26<36:46,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 109: train loss 6.83127. lr 5.994550e-04:   4%|▍         | 109/2863 [01:27<36:46,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 109: train loss 6.83127. lr 5.994550e-04:   4%|▍         | 110/2863 [01:27<36:09,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 110: train loss 6.80824. lr 5.994451e-04:   4%|▍         | 110/2863 [01:28<36:09,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 110: train loss 6.80824. lr 5.994451e-04:   4%|▍         | 111/2863 [01:28<35:49,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 111: train loss 6.75105. lr 5.994350e-04:   4%|▍         | 111/2863 [01:29<35:49,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 111: train loss 6.75105. lr 5.994350e-04:   4%|▍         | 112/2863 [01:29<35:25,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 112: train loss 6.77600. lr 5.994249e-04:   4%|▍         | 112/2863 [01:29<35:25,  1.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 112: train loss 6.77600. lr 5.994249e-04:   4%|▍         | 113/2863 [01:29<35:10,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 113: train loss 6.76185. lr 5.994146e-04:   4%|▍         | 113/2863 [01:30<35:10,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 113: train loss 6.76185. lr 5.994146e-04:   4%|▍         | 114/2863 [01:30<35:01,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 114: train loss 6.79693. lr 5.994043e-04:   4%|▍         | 114/2863 [01:31<35:01,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 114: train loss 6.79693. lr 5.994043e-04:   4%|▍         | 115/2863 [01:31<34:59,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 115: train loss 6.73730. lr 5.993939e-04:   4%|▍         | 115/2863 [01:32<34:59,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 115: train loss 6.73730. lr 5.993939e-04:   4%|▍         | 116/2863 [01:32<34:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 116: train loss 6.77495. lr 5.993834e-04:   4%|▍         | 116/2863 [01:32<34:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 116: train loss 6.77495. lr 5.993834e-04:   4%|▍         | 117/2863 [01:32<34:41,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 117: train loss 6.71760. lr 5.993728e-04:   4%|▍         | 117/2863 [01:33<34:41,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 117: train loss 6.71760. lr 5.993728e-04:   4%|▍         | 118/2863 [01:33<34:40,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 118: train loss 6.76285. lr 5.993621e-04:   4%|▍         | 118/2863 [01:34<34:40,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 118: train loss 6.76285. lr 5.993621e-04:   4%|▍         | 119/2863 [01:34<34:41,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 119: train loss 6.70486. lr 5.993513e-04:   4%|▍         | 119/2863 [01:35<34:41,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 119: train loss 6.70486. lr 5.993513e-04:   4%|▍         | 120/2863 [01:35<34:40,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 120: train loss 6.67930. lr 5.993405e-04:   4%|▍         | 120/2863 [01:35<34:40,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 120: train loss 6.67930. lr 5.993405e-04:   4%|▍         | 121/2863 [01:35<34:36,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 121: train loss 6.66214. lr 5.993295e-04:   4%|▍         | 121/2863 [01:36<34:36,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 121: train loss 6.66214. lr 5.993295e-04:   4%|▍         | 122/2863 [01:36<34:39,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 122: train loss 6.70525. lr 5.993185e-04:   4%|▍         | 122/2863 [01:37<34:39,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 122: train loss 6.70525. lr 5.993185e-04:   4%|▍         | 123/2863 [01:37<34:34,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 123: train loss 6.70200. lr 5.993073e-04:   4%|▍         | 123/2863 [01:38<34:34,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 123: train loss 6.70200. lr 5.993073e-04:   4%|▍         | 124/2863 [01:38<34:35,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 124: train loss 6.65695. lr 5.992961e-04:   4%|▍         | 124/2863 [01:38<34:35,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 124: train loss 6.65695. lr 5.992961e-04:   4%|▍         | 125/2863 [01:38<34:37,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 125: train loss 6.63527. lr 5.992848e-04:   4%|▍         | 125/2863 [01:39<34:37,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 125: train loss 6.63527. lr 5.992848e-04:   4%|▍         | 126/2863 [01:39<34:37,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 6.67643. lr 5.992734e-04:   4%|▍         | 126/2863 [01:40<34:37,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 126: train loss 6.67643. lr 5.992734e-04:   4%|▍         | 127/2863 [01:40<34:34,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 6.63661. lr 5.992619e-04:   4%|▍         | 127/2863 [01:41<34:34,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 127: train loss 6.63661. lr 5.992619e-04:   4%|▍         | 128/2863 [01:41<34:31,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 6.69066. lr 5.992503e-04:   4%|▍         | 128/2863 [01:41<34:31,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 128: train loss 6.69066. lr 5.992503e-04:   5%|▍         | 129/2863 [01:41<34:32,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 6.63776. lr 5.992386e-04:   5%|▍         | 129/2863 [01:42<34:32,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 129: train loss 6.63776. lr 5.992386e-04:   5%|▍         | 130/2863 [01:42<34:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 6.70252. lr 5.992268e-04:   5%|▍         | 130/2863 [01:43<34:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 130: train loss 6.70252. lr 5.992268e-04:   5%|▍         | 131/2863 [01:43<34:32,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 6.60870. lr 5.992150e-04:   5%|▍         | 131/2863 [01:44<34:32,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 131: train loss 6.60870. lr 5.992150e-04:   5%|▍         | 132/2863 [01:44<34:29,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 6.67920. lr 5.992030e-04:   5%|▍         | 132/2863 [01:45<34:29,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 132: train loss 6.67920. lr 5.992030e-04:   5%|▍         | 133/2863 [01:45<34:22,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 6.57684. lr 5.991910e-04:   5%|▍         | 133/2863 [01:45<34:22,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 133: train loss 6.57684. lr 5.991910e-04:   5%|▍         | 134/2863 [01:45<34:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 6.63023. lr 5.991789e-04:   5%|▍         | 134/2863 [01:46<34:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 134: train loss 6.63023. lr 5.991789e-04:   5%|▍         | 135/2863 [01:46<34:21,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 6.59453. lr 5.991666e-04:   5%|▍         | 135/2863 [01:47<34:21,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 135: train loss 6.59453. lr 5.991666e-04:   5%|▍         | 136/2863 [01:47<34:22,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 6.58292. lr 5.991543e-04:   5%|▍         | 136/2863 [01:48<34:22,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 136: train loss 6.58292. lr 5.991543e-04:   5%|▍         | 137/2863 [01:48<34:22,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 6.62097. lr 5.991419e-04:   5%|▍         | 137/2863 [01:48<34:22,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 137: train loss 6.62097. lr 5.991419e-04:   5%|▍         | 138/2863 [01:48<34:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 6.57793. lr 5.991294e-04:   5%|▍         | 138/2863 [01:49<34:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 138: train loss 6.57793. lr 5.991294e-04:   5%|▍         | 139/2863 [01:49<33:07,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 6.55836. lr 5.991169e-04:   5%|▍         | 139/2863 [01:50<33:07,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 139: train loss 6.55836. lr 5.991169e-04:   5%|▍         | 140/2863 [01:50<32:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 6.56841. lr 5.991042e-04:   5%|▍         | 140/2863 [01:50<32:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 140: train loss 6.56841. lr 5.991042e-04:   5%|▍         | 141/2863 [01:50<31:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 6.54064. lr 5.990914e-04:   5%|▍         | 141/2863 [01:51<31:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 141: train loss 6.54064. lr 5.990914e-04:   5%|▍         | 142/2863 [01:51<31:11,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 6.52570. lr 5.990786e-04:   5%|▍         | 142/2863 [01:52<31:11,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 142: train loss 6.52570. lr 5.990786e-04:   5%|▍         | 143/2863 [01:52<30:53,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 6.54680. lr 5.990656e-04:   5%|▍         | 143/2863 [01:52<30:53,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 143: train loss 6.54680. lr 5.990656e-04:   5%|▌         | 144/2863 [01:52<30:40,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 6.52490. lr 5.990526e-04:   5%|▌         | 144/2863 [01:53<30:40,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 144: train loss 6.52490. lr 5.990526e-04:   5%|▌         | 145/2863 [01:53<30:30,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 6.53364. lr 5.990395e-04:   5%|▌         | 145/2863 [01:54<30:30,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 145: train loss 6.53364. lr 5.990395e-04:   5%|▌         | 146/2863 [01:54<30:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 6.54659. lr 5.990263e-04:   5%|▌         | 146/2863 [01:54<30:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 146: train loss 6.54659. lr 5.990263e-04:   5%|▌         | 147/2863 [01:54<30:18,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 6.55377. lr 5.990130e-04:   5%|▌         | 147/2863 [01:55<30:18,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 147: train loss 6.55377. lr 5.990130e-04:   5%|▌         | 148/2863 [01:55<30:16,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 6.50295. lr 5.989996e-04:   5%|▌         | 148/2863 [01:56<30:16,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 148: train loss 6.50295. lr 5.989996e-04:   5%|▌         | 149/2863 [01:56<32:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 6.53464. lr 5.989861e-04:   5%|▌         | 149/2863 [01:56<32:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 149: train loss 6.53464. lr 5.989861e-04:   5%|▌         | 150/2863 [01:56<31:33,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 150: train loss 6.49547. lr 5.989726e-04:   5%|▌         | 150/2863 [01:57<31:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 150: train loss 6.49547. lr 5.989726e-04:   5%|▌         | 151/2863 [01:57<31:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 6.46092. lr 5.989589e-04:   5%|▌         | 151/2863 [01:58<31:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 151: train loss 6.46092. lr 5.989589e-04:   5%|▌         | 152/2863 [01:58<30:47,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 6.48244. lr 5.989451e-04:   5%|▌         | 152/2863 [01:58<30:47,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 152: train loss 6.48244. lr 5.989451e-04:   5%|▌         | 153/2863 [01:58<30:34,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 6.52008. lr 5.989313e-04:   5%|▌         | 153/2863 [01:59<30:34,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 153: train loss 6.52008. lr 5.989313e-04:   5%|▌         | 154/2863 [01:59<30:25,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 6.47863. lr 5.989174e-04:   5%|▌         | 154/2863 [02:00<30:25,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 154: train loss 6.47863. lr 5.989174e-04:   5%|▌         | 155/2863 [02:00<30:18,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 6.50782. lr 5.989034e-04:   5%|▌         | 155/2863 [02:00<30:18,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 155: train loss 6.50782. lr 5.989034e-04:   5%|▌         | 156/2863 [02:00<30:14,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 6.48635. lr 5.988892e-04:   5%|▌         | 156/2863 [02:01<30:14,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 156: train loss 6.48635. lr 5.988892e-04:   5%|▌         | 157/2863 [02:01<30:10,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 6.48995. lr 5.988750e-04:   5%|▌         | 157/2863 [02:02<30:10,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 157: train loss 6.48995. lr 5.988750e-04:   6%|▌         | 158/2863 [02:02<30:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 6.44256. lr 5.988608e-04:   6%|▌         | 158/2863 [02:02<30:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 158: train loss 6.44256. lr 5.988608e-04:   6%|▌         | 159/2863 [02:02<30:06,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 6.47475. lr 5.988464e-04:   6%|▌         | 159/2863 [02:03<30:06,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 159: train loss 6.47475. lr 5.988464e-04:   6%|▌         | 160/2863 [02:03<30:04,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 6.41231. lr 5.988319e-04:   6%|▌         | 160/2863 [02:04<30:04,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 160: train loss 6.41231. lr 5.988319e-04:   6%|▌         | 161/2863 [02:04<30:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 6.45421. lr 5.988173e-04:   6%|▌         | 161/2863 [02:04<30:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 161: train loss 6.45421. lr 5.988173e-04:   6%|▌         | 162/2863 [02:04<30:02,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 6.44510. lr 5.988027e-04:   6%|▌         | 162/2863 [02:05<30:02,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 162: train loss 6.44510. lr 5.988027e-04:   6%|▌         | 163/2863 [02:05<30:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 6.40685. lr 5.987879e-04:   6%|▌         | 163/2863 [02:06<30:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 163: train loss 6.40685. lr 5.987879e-04:   6%|▌         | 164/2863 [02:06<30:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 6.37825. lr 5.987731e-04:   6%|▌         | 164/2863 [02:06<30:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 164: train loss 6.37825. lr 5.987731e-04:   6%|▌         | 165/2863 [02:06<30:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 6.41818. lr 5.987582e-04:   6%|▌         | 165/2863 [02:07<30:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 165: train loss 6.41818. lr 5.987582e-04:   6%|▌         | 166/2863 [02:07<29:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 6.36726. lr 5.987432e-04:   6%|▌         | 166/2863 [02:08<29:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 166: train loss 6.36726. lr 5.987432e-04:   6%|▌         | 167/2863 [02:08<29:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 6.39225. lr 5.987281e-04:   6%|▌         | 167/2863 [02:08<29:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 167: train loss 6.39225. lr 5.987281e-04:   6%|▌         | 168/2863 [02:08<29:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 6.42555. lr 5.987129e-04:   6%|▌         | 168/2863 [02:09<29:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 168: train loss 6.42555. lr 5.987129e-04:   6%|▌         | 169/2863 [02:09<29:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 6.37213. lr 5.986976e-04:   6%|▌         | 169/2863 [02:10<29:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 169: train loss 6.37213. lr 5.986976e-04:   6%|▌         | 170/2863 [02:10<29:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 6.34330. lr 5.986822e-04:   6%|▌         | 170/2863 [02:10<29:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 170: train loss 6.34330. lr 5.986822e-04:   6%|▌         | 171/2863 [02:10<29:57,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 6.37943. lr 5.986668e-04:   6%|▌         | 171/2863 [02:11<29:57,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 171: train loss 6.37943. lr 5.986668e-04:   6%|▌         | 172/2863 [02:11<29:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 6.41463. lr 5.986512e-04:   6%|▌         | 172/2863 [02:12<29:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 172: train loss 6.41463. lr 5.986512e-04:   6%|▌         | 173/2863 [02:12<29:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 6.36690. lr 5.986356e-04:   6%|▌         | 173/2863 [02:12<29:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 173: train loss 6.36690. lr 5.986356e-04:   6%|▌         | 174/2863 [02:12<29:54,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 6.40708. lr 5.986199e-04:   6%|▌         | 174/2863 [02:13<29:54,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 174: train loss 6.40708. lr 5.986199e-04:   6%|▌         | 175/2863 [02:13<29:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 6.37368. lr 5.986040e-04:   6%|▌         | 175/2863 [02:14<29:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 175: train loss 6.37368. lr 5.986040e-04:   6%|▌         | 176/2863 [02:14<29:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 6.40264. lr 5.985881e-04:   6%|▌         | 176/2863 [02:14<29:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 176: train loss 6.40264. lr 5.985881e-04:   6%|▌         | 177/2863 [02:14<29:52,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 6.27900. lr 5.985721e-04:   6%|▌         | 177/2863 [02:15<29:52,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 177: train loss 6.27900. lr 5.985721e-04:   6%|▌         | 178/2863 [02:15<29:51,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 6.32240. lr 5.985560e-04:   6%|▌         | 178/2863 [02:16<29:51,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 178: train loss 6.32240. lr 5.985560e-04:   6%|▋         | 179/2863 [02:16<29:50,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 6.33687. lr 5.985399e-04:   6%|▋         | 179/2863 [02:16<29:50,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 179: train loss 6.33687. lr 5.985399e-04:   6%|▋         | 180/2863 [02:16<29:50,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 6.33340. lr 5.985236e-04:   6%|▋         | 180/2863 [02:17<29:50,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 180: train loss 6.33340. lr 5.985236e-04:   6%|▋         | 181/2863 [02:17<29:49,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 6.29041. lr 5.985072e-04:   6%|▋         | 181/2863 [02:18<29:49,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 181: train loss 6.29041. lr 5.985072e-04:   6%|▋         | 182/2863 [02:18<31:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 6.34781. lr 5.984908e-04:   6%|▋         | 182/2863 [02:19<31:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 182: train loss 6.34781. lr 5.984908e-04:   6%|▋         | 183/2863 [02:19<30:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 6.26942. lr 5.984743e-04:   6%|▋         | 183/2863 [02:19<30:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 183: train loss 6.26942. lr 5.984743e-04:   6%|▋         | 184/2863 [02:19<30:36,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 6.29138. lr 5.984576e-04:   6%|▋         | 184/2863 [02:20<30:36,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 184: train loss 6.29138. lr 5.984576e-04:   6%|▋         | 185/2863 [02:20<30:20,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 6.30284. lr 5.984409e-04:   6%|▋         | 185/2863 [02:21<30:20,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 185: train loss 6.30284. lr 5.984409e-04:   6%|▋         | 186/2863 [02:21<30:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 6.33691. lr 5.984241e-04:   6%|▋         | 186/2863 [02:21<30:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 186: train loss 6.33691. lr 5.984241e-04:   7%|▋         | 187/2863 [02:21<30:02,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 187: train loss 6.24769. lr 5.984072e-04:   7%|▋         | 187/2863 [02:22<30:02,  1.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 187: train loss 6.24769. lr 5.984072e-04:   7%|▋         | 188/2863 [02:22<29:56,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 6.25062. lr 5.983902e-04:   7%|▋         | 188/2863 [02:23<29:56,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 188: train loss 6.25062. lr 5.983902e-04:   7%|▋         | 189/2863 [02:23<29:52,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 6.25623. lr 5.983731e-04:   7%|▋         | 189/2863 [02:23<29:52,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 189: train loss 6.25623. lr 5.983731e-04:   7%|▋         | 190/2863 [02:23<29:49,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 6.30489. lr 5.983560e-04:   7%|▋         | 190/2863 [02:24<29:49,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 190: train loss 6.30489. lr 5.983560e-04:   7%|▋         | 191/2863 [02:24<29:47,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 6.27813. lr 5.983387e-04:   7%|▋         | 191/2863 [02:25<29:47,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 191: train loss 6.27813. lr 5.983387e-04:   7%|▋         | 192/2863 [02:25<29:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 6.22791. lr 5.983214e-04:   7%|▋         | 192/2863 [02:25<29:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 192: train loss 6.22791. lr 5.983214e-04:   7%|▋         | 193/2863 [02:25<29:43,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 6.22125. lr 5.983039e-04:   7%|▋         | 193/2863 [02:26<29:43,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 193: train loss 6.22125. lr 5.983039e-04:   7%|▋         | 194/2863 [02:26<29:42,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 6.25256. lr 5.982864e-04:   7%|▋         | 194/2863 [02:27<29:42,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 194: train loss 6.25256. lr 5.982864e-04:   7%|▋         | 195/2863 [02:27<29:40,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 6.21127. lr 5.982688e-04:   7%|▋         | 195/2863 [02:27<29:40,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 195: train loss 6.21127. lr 5.982688e-04:   7%|▋         | 196/2863 [02:27<29:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 6.26642. lr 5.982511e-04:   7%|▋         | 196/2863 [02:28<29:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 196: train loss 6.26642. lr 5.982511e-04:   7%|▋         | 197/2863 [02:28<29:38,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 6.24400. lr 5.982333e-04:   7%|▋         | 197/2863 [02:29<29:38,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 197: train loss 6.24400. lr 5.982333e-04:   7%|▋         | 198/2863 [02:29<29:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 6.20363. lr 5.982154e-04:   7%|▋         | 198/2863 [02:29<29:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 198: train loss 6.20363. lr 5.982154e-04:   7%|▋         | 199/2863 [02:29<29:36,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 6.22813. lr 5.981974e-04:   7%|▋         | 199/2863 [02:30<29:36,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 199: train loss 6.22813. lr 5.981974e-04:   7%|▋         | 200/2863 [02:30<29:35,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 6.23648. lr 5.981793e-04:   7%|▋         | 200/2863 [02:31<29:35,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 200: train loss 6.23648. lr 5.981793e-04:   7%|▋         | 201/2863 [02:31<29:34,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 6.25591. lr 5.981612e-04:   7%|▋         | 201/2863 [02:31<29:34,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 201: train loss 6.25591. lr 5.981612e-04:   7%|▋         | 202/2863 [02:31<29:33,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 6.23040. lr 5.981429e-04:   7%|▋         | 202/2863 [02:32<29:33,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 202: train loss 6.23040. lr 5.981429e-04:   7%|▋         | 203/2863 [02:32<29:32,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 6.16993. lr 5.981246e-04:   7%|▋         | 203/2863 [02:33<29:32,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 203: train loss 6.16993. lr 5.981246e-04:   7%|▋         | 204/2863 [02:33<29:32,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 6.16195. lr 5.981062e-04:   7%|▋         | 204/2863 [02:33<29:32,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 204: train loss 6.16195. lr 5.981062e-04:   7%|▋         | 205/2863 [02:33<29:31,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 6.18115. lr 5.980877e-04:   7%|▋         | 205/2863 [02:34<29:31,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 205: train loss 6.18115. lr 5.980877e-04:   7%|▋         | 206/2863 [02:34<29:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 6.20595. lr 5.980690e-04:   7%|▋         | 206/2863 [02:35<29:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 206: train loss 6.20595. lr 5.980690e-04:   7%|▋         | 207/2863 [02:35<29:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 6.21734. lr 5.980503e-04:   7%|▋         | 207/2863 [02:35<29:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 207: train loss 6.21734. lr 5.980503e-04:   7%|▋         | 208/2863 [02:35<29:29,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 6.17251. lr 5.980316e-04:   7%|▋         | 208/2863 [02:36<29:29,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 208: train loss 6.17251. lr 5.980316e-04:   7%|▋         | 209/2863 [02:36<29:29,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 6.16251. lr 5.980127e-04:   7%|▋         | 209/2863 [02:37<29:29,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 209: train loss 6.16251. lr 5.980127e-04:   7%|▋         | 210/2863 [02:37<31:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 6.17742. lr 5.979937e-04:   7%|▋         | 210/2863 [02:37<31:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 210: train loss 6.17742. lr 5.979937e-04:   7%|▋         | 211/2863 [02:37<30:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 6.14893. lr 5.979747e-04:   7%|▋         | 211/2863 [02:38<30:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 211: train loss 6.14893. lr 5.979747e-04:   7%|▋         | 212/2863 [02:38<30:14,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 6.14523. lr 5.979555e-04:   7%|▋         | 212/2863 [02:39<30:14,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 212: train loss 6.14523. lr 5.979555e-04:   7%|▋         | 213/2863 [02:39<29:59,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 6.10231. lr 5.979363e-04:   7%|▋         | 213/2863 [02:39<29:59,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 213: train loss 6.10231. lr 5.979363e-04:   7%|▋         | 214/2863 [02:39<29:49,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 6.18048. lr 5.979170e-04:   7%|▋         | 214/2863 [02:40<29:49,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 214: train loss 6.18048. lr 5.979170e-04:   8%|▊         | 215/2863 [02:40<29:41,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 6.11635. lr 5.978976e-04:   8%|▊         | 215/2863 [02:41<29:41,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 215: train loss 6.11635. lr 5.978976e-04:   8%|▊         | 216/2863 [02:41<29:37,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 6.15797. lr 5.978781e-04:   8%|▊         | 216/2863 [02:41<29:37,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 216: train loss 6.15797. lr 5.978781e-04:   8%|▊         | 217/2863 [02:41<29:33,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 6.10366. lr 5.978585e-04:   8%|▊         | 217/2863 [02:42<29:33,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 217: train loss 6.10366. lr 5.978585e-04:   8%|▊         | 218/2863 [02:42<29:29,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 6.13849. lr 5.978388e-04:   8%|▊         | 218/2863 [02:43<29:29,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 218: train loss 6.13849. lr 5.978388e-04:   8%|▊         | 219/2863 [02:43<29:26,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 6.16192. lr 5.978190e-04:   8%|▊         | 219/2863 [02:43<29:26,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 219: train loss 6.16192. lr 5.978190e-04:   8%|▊         | 220/2863 [02:43<29:25,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 6.10022. lr 5.977991e-04:   8%|▊         | 220/2863 [02:44<29:25,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 220: train loss 6.10022. lr 5.977991e-04:   8%|▊         | 221/2863 [02:44<29:22,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 6.08700. lr 5.977792e-04:   8%|▊         | 221/2863 [02:45<29:22,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 221: train loss 6.08700. lr 5.977792e-04:   8%|▊         | 222/2863 [02:45<29:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 6.11909. lr 5.977591e-04:   8%|▊         | 222/2863 [02:45<29:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 222: train loss 6.11909. lr 5.977591e-04:   8%|▊         | 223/2863 [02:45<29:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 6.06596. lr 5.977390e-04:   8%|▊         | 223/2863 [02:46<29:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 223: train loss 6.06596. lr 5.977390e-04:   8%|▊         | 224/2863 [02:46<29:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 6.12754. lr 5.977188e-04:   8%|▊         | 224/2863 [02:47<29:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 224: train loss 6.12754. lr 5.977188e-04:   8%|▊         | 225/2863 [02:47<29:20,  1.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 225: train loss 6.10261. lr 5.976985e-04:   8%|▊         | 225/2863 [02:47<29:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 225: train loss 6.10261. lr 5.976985e-04:   8%|▊         | 226/2863 [02:47<29:19,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 6.05043. lr 5.976781e-04:   8%|▊         | 226/2863 [02:48<29:19,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 226: train loss 6.05043. lr 5.976781e-04:   8%|▊         | 227/2863 [02:48<29:18,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 6.08620. lr 5.976576e-04:   8%|▊         | 227/2863 [02:49<29:18,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 227: train loss 6.08620. lr 5.976576e-04:   8%|▊         | 228/2863 [02:49<29:17,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 6.11020. lr 5.976370e-04:   8%|▊         | 228/2863 [02:49<29:17,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 228: train loss 6.11020. lr 5.976370e-04:   8%|▊         | 229/2863 [02:49<29:16,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 6.04832. lr 5.976163e-04:   8%|▊         | 229/2863 [02:50<29:16,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 229: train loss 6.04832. lr 5.976163e-04:   8%|▊         | 230/2863 [02:50<29:15,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 6.00808. lr 5.975956e-04:   8%|▊         | 230/2863 [02:51<29:15,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 230: train loss 6.00808. lr 5.975956e-04:   8%|▊         | 231/2863 [02:51<29:15,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 6.05817. lr 5.975747e-04:   8%|▊         | 231/2863 [02:51<29:15,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 231: train loss 6.05817. lr 5.975747e-04:   8%|▊         | 232/2863 [02:51<29:14,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 6.08163. lr 5.975538e-04:   8%|▊         | 232/2863 [02:52<29:14,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 232: train loss 6.08163. lr 5.975538e-04:   8%|▊         | 233/2863 [02:52<29:14,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 6.06903. lr 5.975328e-04:   8%|▊         | 233/2863 [02:53<29:14,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 233: train loss 6.06903. lr 5.975328e-04:   8%|▊         | 234/2863 [02:53<29:13,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 6.06871. lr 5.975117e-04:   8%|▊         | 234/2863 [02:53<29:13,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 234: train loss 6.06871. lr 5.975117e-04:   8%|▊         | 235/2863 [02:53<29:13,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 6.00903. lr 5.974904e-04:   8%|▊         | 235/2863 [02:54<29:13,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 235: train loss 6.00903. lr 5.974904e-04:   8%|▊         | 236/2863 [02:54<29:12,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 6.01949. lr 5.974692e-04:   8%|▊         | 236/2863 [02:55<29:12,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 236: train loss 6.01949. lr 5.974692e-04:   8%|▊         | 237/2863 [02:55<29:12,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 5.96602. lr 5.974478e-04:   8%|▊         | 237/2863 [02:56<29:12,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 237: train loss 5.96602. lr 5.974478e-04:   8%|▊         | 238/2863 [02:56<31:06,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 5.92919. lr 5.974263e-04:   8%|▊         | 238/2863 [02:56<31:06,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 238: train loss 5.92919. lr 5.974263e-04:   8%|▊         | 239/2863 [02:56<30:30,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 6.01213. lr 5.974047e-04:   8%|▊         | 239/2863 [02:57<30:30,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 239: train loss 6.01213. lr 5.974047e-04:   8%|▊         | 240/2863 [02:57<30:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 6.01083. lr 5.973831e-04:   8%|▊         | 240/2863 [02:58<30:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 240: train loss 6.01083. lr 5.973831e-04:   8%|▊         | 241/2863 [02:58<29:47,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 5.97024. lr 5.973613e-04:   8%|▊         | 241/2863 [02:58<29:47,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 241: train loss 5.97024. lr 5.973613e-04:   8%|▊         | 242/2863 [02:58<29:34,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 5.99745. lr 5.973395e-04:   8%|▊         | 242/2863 [02:59<29:34,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 242: train loss 5.99745. lr 5.973395e-04:   8%|▊         | 243/2863 [02:59<29:25,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 5.97698. lr 5.973176e-04:   8%|▊         | 243/2863 [03:00<29:25,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 243: train loss 5.97698. lr 5.973176e-04:   9%|▊         | 244/2863 [03:00<29:19,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 5.99872. lr 5.972956e-04:   9%|▊         | 244/2863 [03:00<29:19,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 244: train loss 5.99872. lr 5.972956e-04:   9%|▊         | 245/2863 [03:00<29:14,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 5.94288. lr 5.972735e-04:   9%|▊         | 245/2863 [03:01<29:14,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 245: train loss 5.94288. lr 5.972735e-04:   9%|▊         | 246/2863 [03:01<29:11,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 5.98925. lr 5.972513e-04:   9%|▊         | 246/2863 [03:02<29:11,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 246: train loss 5.98925. lr 5.972513e-04:   9%|▊         | 247/2863 [03:02<29:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 5.97852. lr 5.972290e-04:   9%|▊         | 247/2863 [03:02<29:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 247: train loss 5.97852. lr 5.972290e-04:   9%|▊         | 248/2863 [03:02<29:06,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 5.96903. lr 5.972066e-04:   9%|▊         | 248/2863 [03:03<29:06,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 248: train loss 5.96903. lr 5.972066e-04:   9%|▊         | 249/2863 [03:03<29:05,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 5.96574. lr 5.971841e-04:   9%|▊         | 249/2863 [03:04<29:05,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 249: train loss 5.96574. lr 5.971841e-04:   9%|▊         | 250/2863 [03:04<29:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 5.95748. lr 5.971616e-04:   9%|▊         | 250/2863 [03:04<29:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 250: train loss 5.95748. lr 5.971616e-04:   9%|▉         | 251/2863 [03:04<29:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 5.92232. lr 5.971390e-04:   9%|▉         | 251/2863 [03:05<29:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 251: train loss 5.92232. lr 5.971390e-04:   9%|▉         | 252/2863 [03:05<29:01,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 6.04357. lr 5.971162e-04:   9%|▉         | 252/2863 [03:06<29:01,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 252: train loss 6.04357. lr 5.971162e-04:   9%|▉         | 253/2863 [03:06<29:01,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 5.95824. lr 5.970934e-04:   9%|▉         | 253/2863 [03:06<29:01,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 253: train loss 5.95824. lr 5.970934e-04:   9%|▉         | 254/2863 [03:06<29:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 5.93417. lr 5.970705e-04:   9%|▉         | 254/2863 [03:07<29:00,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 254: train loss 5.93417. lr 5.970705e-04:   9%|▉         | 255/2863 [03:07<28:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 5.85268. lr 5.970475e-04:   9%|▉         | 255/2863 [03:08<28:59,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 255: train loss 5.85268. lr 5.970475e-04:   9%|▉         | 256/2863 [03:08<28:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 5.95800. lr 5.970244e-04:   9%|▉         | 256/2863 [03:08<28:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 256: train loss 5.95800. lr 5.970244e-04:   9%|▉         | 257/2863 [03:08<28:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 5.94563. lr 5.970012e-04:   9%|▉         | 257/2863 [03:09<28:58,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 257: train loss 5.94563. lr 5.970012e-04:   9%|▉         | 258/2863 [03:09<28:57,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 5.90623. lr 5.969780e-04:   9%|▉         | 258/2863 [03:10<28:57,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 258: train loss 5.90623. lr 5.969780e-04:   9%|▉         | 259/2863 [03:10<28:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 5.93684. lr 5.969546e-04:   9%|▉         | 259/2863 [03:10<28:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 259: train loss 5.93684. lr 5.969546e-04:   9%|▉         | 260/2863 [03:10<28:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 5.94076. lr 5.969312e-04:   9%|▉         | 260/2863 [03:11<28:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 260: train loss 5.94076. lr 5.969312e-04:   9%|▉         | 261/2863 [03:11<28:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 5.90021. lr 5.969076e-04:   9%|▉         | 261/2863 [03:12<28:56,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 261: train loss 5.90021. lr 5.969076e-04:   9%|▉         | 262/2863 [03:12<28:54,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 262: train loss 5.89503. lr 5.968840e-04:   9%|▉         | 262/2863 [03:12<28:54,  1.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 262: train loss 5.89503. lr 5.968840e-04:   9%|▉         | 263/2863 [03:12<28:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 5.90340. lr 5.968603e-04:   9%|▉         | 263/2863 [03:13<28:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 263: train loss 5.90340. lr 5.968603e-04:   9%|▉         | 264/2863 [03:13<28:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 5.87131. lr 5.968365e-04:   9%|▉         | 264/2863 [03:14<28:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 264: train loss 5.87131. lr 5.968365e-04:   9%|▉         | 265/2863 [03:14<28:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 5.92271. lr 5.968126e-04:   9%|▉         | 265/2863 [03:14<28:53,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 265: train loss 5.92271. lr 5.968126e-04:   9%|▉         | 266/2863 [03:14<30:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 5.86969. lr 5.967886e-04:   9%|▉         | 266/2863 [03:15<30:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 266: train loss 5.86969. lr 5.967886e-04:   9%|▉         | 267/2863 [03:15<29:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 5.88911. lr 5.967646e-04:   9%|▉         | 267/2863 [03:16<29:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 267: train loss 5.88911. lr 5.967646e-04:   9%|▉         | 268/2863 [03:16<29:36,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 5.85084. lr 5.967404e-04:   9%|▉         | 268/2863 [03:16<29:36,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 268: train loss 5.85084. lr 5.967404e-04:   9%|▉         | 269/2863 [03:16<29:22,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 5.84238. lr 5.967161e-04:   9%|▉         | 269/2863 [03:17<29:22,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 269: train loss 5.84238. lr 5.967161e-04:   9%|▉         | 270/2863 [03:17<29:12,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 5.87366. lr 5.966918e-04:   9%|▉         | 270/2863 [03:18<29:12,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 270: train loss 5.87366. lr 5.966918e-04:   9%|▉         | 271/2863 [03:18<29:05,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 5.84670. lr 5.966674e-04:   9%|▉         | 271/2863 [03:18<29:05,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 271: train loss 5.84670. lr 5.966674e-04:  10%|▉         | 272/2863 [03:18<28:59,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 5.84174. lr 5.966429e-04:  10%|▉         | 272/2863 [03:19<28:59,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 272: train loss 5.84174. lr 5.966429e-04:  10%|▉         | 273/2863 [03:19<28:55,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 5.82782. lr 5.966182e-04:  10%|▉         | 273/2863 [03:20<28:55,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 273: train loss 5.82782. lr 5.966182e-04:  10%|▉         | 274/2863 [03:20<28:53,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 5.88678. lr 5.965936e-04:  10%|▉         | 274/2863 [03:20<28:53,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 274: train loss 5.88678. lr 5.965936e-04:  10%|▉         | 275/2863 [03:20<28:50,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 5.81830. lr 5.965688e-04:  10%|▉         | 275/2863 [03:21<28:50,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 275: train loss 5.81830. lr 5.965688e-04:  10%|▉         | 276/2863 [03:21<28:49,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 5.83745. lr 5.965439e-04:  10%|▉         | 276/2863 [03:22<28:49,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 276: train loss 5.83745. lr 5.965439e-04:  10%|▉         | 277/2863 [03:22<28:48,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 5.87869. lr 5.965189e-04:  10%|▉         | 277/2863 [03:22<28:48,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 277: train loss 5.87869. lr 5.965189e-04:  10%|▉         | 278/2863 [03:22<28:46,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 5.84236. lr 5.964939e-04:  10%|▉         | 278/2863 [03:23<28:46,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 278: train loss 5.84236. lr 5.964939e-04:  10%|▉         | 279/2863 [03:23<28:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 5.84643. lr 5.964687e-04:  10%|▉         | 279/2863 [03:24<28:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 279: train loss 5.84643. lr 5.964687e-04:  10%|▉         | 280/2863 [03:24<28:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 5.84164. lr 5.964435e-04:  10%|▉         | 280/2863 [03:24<28:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 280: train loss 5.84164. lr 5.964435e-04:  10%|▉         | 281/2863 [03:24<28:43,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 5.79854. lr 5.964182e-04:  10%|▉         | 281/2863 [03:25<28:43,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 281: train loss 5.79854. lr 5.964182e-04:  10%|▉         | 282/2863 [03:25<28:42,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 5.80071. lr 5.963928e-04:  10%|▉         | 282/2863 [03:26<28:42,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 282: train loss 5.80071. lr 5.963928e-04:  10%|▉         | 283/2863 [03:26<28:42,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 5.79671. lr 5.963673e-04:  10%|▉         | 283/2863 [03:26<28:42,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 283: train loss 5.79671. lr 5.963673e-04:  10%|▉         | 284/2863 [03:26<28:41,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 5.77224. lr 5.963417e-04:  10%|▉         | 284/2863 [03:27<28:41,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 284: train loss 5.77224. lr 5.963417e-04:  10%|▉         | 285/2863 [03:27<28:40,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 5.81312. lr 5.963160e-04:  10%|▉         | 285/2863 [03:28<28:40,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 285: train loss 5.81312. lr 5.963160e-04:  10%|▉         | 286/2863 [03:28<28:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 5.77190. lr 5.962902e-04:  10%|▉         | 286/2863 [03:28<28:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 286: train loss 5.77190. lr 5.962902e-04:  10%|█         | 287/2863 [03:28<28:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 5.83730. lr 5.962644e-04:  10%|█         | 287/2863 [03:29<28:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 287: train loss 5.83730. lr 5.962644e-04:  10%|█         | 288/2863 [03:29<28:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 5.76586. lr 5.962384e-04:  10%|█         | 288/2863 [03:30<28:39,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 288: train loss 5.76586. lr 5.962384e-04:  10%|█         | 289/2863 [03:30<28:38,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 5.77992. lr 5.962124e-04:  10%|█         | 289/2863 [03:30<28:38,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 289: train loss 5.77992. lr 5.962124e-04:  10%|█         | 290/2863 [03:30<28:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 5.75068. lr 5.961863e-04:  10%|█         | 290/2863 [03:31<28:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 290: train loss 5.75068. lr 5.961863e-04:  10%|█         | 291/2863 [03:31<28:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 5.72659. lr 5.961600e-04:  10%|█         | 291/2863 [03:32<28:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 291: train loss 5.72659. lr 5.961600e-04:  10%|█         | 292/2863 [03:32<28:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 5.75153. lr 5.961337e-04:  10%|█         | 292/2863 [03:32<28:37,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 292: train loss 5.75153. lr 5.961337e-04:  10%|█         | 293/2863 [03:32<28:35,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 5.74729. lr 5.961074e-04:  10%|█         | 293/2863 [03:33<28:35,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 293: train loss 5.74729. lr 5.961074e-04:  10%|█         | 294/2863 [03:33<30:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 5.74240. lr 5.960809e-04:  10%|█         | 294/2863 [03:34<30:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 294: train loss 5.74240. lr 5.960809e-04:  10%|█         | 295/2863 [03:34<29:36,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 5.75822. lr 5.960543e-04:  10%|█         | 295/2863 [03:34<29:36,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 295: train loss 5.75822. lr 5.960543e-04:  10%|█         | 296/2863 [03:34<29:17,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 5.72540. lr 5.960276e-04:  10%|█         | 296/2863 [03:35<29:17,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 296: train loss 5.72540. lr 5.960276e-04:  10%|█         | 297/2863 [03:35<29:04,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 5.71899. lr 5.960009e-04:  10%|█         | 297/2863 [03:36<29:04,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 297: train loss 5.71899. lr 5.960009e-04:  10%|█         | 298/2863 [03:36<28:54,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 5.75035. lr 5.959740e-04:  10%|█         | 298/2863 [03:36<28:54,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 298: train loss 5.75035. lr 5.959740e-04:  10%|█         | 299/2863 [03:36<28:47,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 5.68717. lr 5.959471e-04:  10%|█         | 299/2863 [03:37<28:47,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 299: train loss 5.68717. lr 5.959471e-04:  10%|█         | 300/2863 [03:37<28:42,  1.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 300: train loss 5.71467. lr 5.959201e-04:  10%|█         | 300/2863 [03:38<28:42,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 300: train loss 5.71467. lr 5.959201e-04:  11%|█         | 301/2863 [03:38<28:38,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 5.67439. lr 5.958930e-04:  11%|█         | 301/2863 [03:38<28:38,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 301: train loss 5.67439. lr 5.958930e-04:  11%|█         | 302/2863 [03:38<28:34,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 5.72518. lr 5.958658e-04:  11%|█         | 302/2863 [03:39<28:34,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 302: train loss 5.72518. lr 5.958658e-04:  11%|█         | 303/2863 [03:39<28:31,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 5.70361. lr 5.958385e-04:  11%|█         | 303/2863 [03:40<28:31,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 303: train loss 5.70361. lr 5.958385e-04:  11%|█         | 304/2863 [03:40<28:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 5.70855. lr 5.958111e-04:  11%|█         | 304/2863 [03:40<28:30,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 304: train loss 5.70855. lr 5.958111e-04:  11%|█         | 305/2863 [03:40<28:28,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 5.73280. lr 5.957837e-04:  11%|█         | 305/2863 [03:41<28:28,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 305: train loss 5.73280. lr 5.957837e-04:  11%|█         | 306/2863 [03:41<28:27,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 5.65075. lr 5.957561e-04:  11%|█         | 306/2863 [03:42<28:27,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 306: train loss 5.65075. lr 5.957561e-04:  11%|█         | 307/2863 [03:42<28:27,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 5.65924. lr 5.957285e-04:  11%|█         | 307/2863 [03:42<28:27,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 307: train loss 5.65924. lr 5.957285e-04:  11%|█         | 308/2863 [03:42<28:26,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 5.72200. lr 5.957008e-04:  11%|█         | 308/2863 [03:43<28:26,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 308: train loss 5.72200. lr 5.957008e-04:  11%|█         | 309/2863 [03:43<28:26,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 5.64364. lr 5.956729e-04:  11%|█         | 309/2863 [03:44<28:26,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 309: train loss 5.64364. lr 5.956729e-04:  11%|█         | 310/2863 [03:44<28:24,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 5.65564. lr 5.956450e-04:  11%|█         | 310/2863 [03:44<28:24,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 310: train loss 5.65564. lr 5.956450e-04:  11%|█         | 311/2863 [03:44<28:22,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 5.70220. lr 5.956170e-04:  11%|█         | 311/2863 [03:45<28:22,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 311: train loss 5.70220. lr 5.956170e-04:  11%|█         | 312/2863 [03:45<28:23,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 5.68339. lr 5.955890e-04:  11%|█         | 312/2863 [03:46<28:23,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 312: train loss 5.68339. lr 5.955890e-04:  11%|█         | 313/2863 [03:46<28:22,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 5.66677. lr 5.955608e-04:  11%|█         | 313/2863 [03:46<28:22,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 313: train loss 5.66677. lr 5.955608e-04:  11%|█         | 314/2863 [03:46<28:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 5.66152. lr 5.955325e-04:  11%|█         | 314/2863 [03:47<28:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 314: train loss 5.66152. lr 5.955325e-04:  11%|█         | 315/2863 [03:47<28:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 5.61118. lr 5.955042e-04:  11%|█         | 315/2863 [03:48<28:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 315: train loss 5.61118. lr 5.955042e-04:  11%|█         | 316/2863 [03:48<28:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 316: train loss 5.64927. lr 5.954757e-04:  11%|█         | 316/2863 [03:48<28:21,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 316: train loss 5.64927. lr 5.954757e-04:  11%|█         | 317/2863 [03:48<28:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 317: train loss 5.64983. lr 5.954472e-04:  11%|█         | 317/2863 [03:49<28:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 317: train loss 5.64983. lr 5.954472e-04:  11%|█         | 318/2863 [03:49<28:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 318: train loss 5.64327. lr 5.954186e-04:  11%|█         | 318/2863 [03:50<28:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 318: train loss 5.64327. lr 5.954186e-04:  11%|█         | 319/2863 [03:50<28:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 319: train loss 5.60181. lr 5.953899e-04:  11%|█         | 319/2863 [03:50<28:20,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 319: train loss 5.60181. lr 5.953899e-04:  11%|█         | 320/2863 [03:50<28:19,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 320: train loss 5.64827. lr 5.953611e-04:  11%|█         | 320/2863 [03:51<28:19,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 320: train loss 5.64827. lr 5.953611e-04:  11%|█         | 321/2863 [03:51<28:20,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 321: train loss 5.62970. lr 5.953322e-04:  11%|█         | 321/2863 [03:52<28:20,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 321: train loss 5.62970. lr 5.953322e-04:  11%|█         | 322/2863 [03:52<30:11,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 322: train loss 5.62246. lr 5.953032e-04:  11%|█         | 322/2863 [03:53<30:11,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 322: train loss 5.62246. lr 5.953032e-04:  11%|█▏        | 323/2863 [03:53<29:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 323: train loss 5.61232. lr 5.952741e-04:  11%|█▏        | 323/2863 [03:53<29:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 323: train loss 5.61232. lr 5.952741e-04:  11%|█▏        | 324/2863 [03:53<29:11,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 324: train loss 5.58085. lr 5.952450e-04:  11%|█▏        | 324/2863 [03:54<29:11,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 324: train loss 5.58085. lr 5.952450e-04:  11%|█▏        | 325/2863 [03:54<28:53,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 325: train loss 5.58659. lr 5.952157e-04:  11%|█▏        | 325/2863 [03:55<28:53,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 325: train loss 5.58659. lr 5.952157e-04:  11%|█▏        | 326/2863 [03:55<28:42,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 326: train loss 5.60355. lr 5.951864e-04:  11%|█▏        | 326/2863 [03:55<28:42,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 326: train loss 5.60355. lr 5.951864e-04:  11%|█▏        | 327/2863 [03:55<28:33,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 327: train loss 5.59430. lr 5.951570e-04:  11%|█▏        | 327/2863 [03:56<28:33,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 327: train loss 5.59430. lr 5.951570e-04:  11%|█▏        | 328/2863 [03:56<28:28,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 328: train loss 5.60892. lr 5.951275e-04:  11%|█▏        | 328/2863 [03:57<28:28,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 328: train loss 5.60892. lr 5.951275e-04:  11%|█▏        | 329/2863 [03:57<28:24,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 329: train loss 5.54285. lr 5.950979e-04:  11%|█▏        | 329/2863 [03:57<28:24,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 329: train loss 5.54285. lr 5.950979e-04:  12%|█▏        | 330/2863 [03:57<28:20,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 330: train loss 5.49853. lr 5.950682e-04:  12%|█▏        | 330/2863 [03:58<28:20,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 330: train loss 5.49853. lr 5.950682e-04:  12%|█▏        | 331/2863 [03:58<28:18,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 331: train loss 5.55145. lr 5.950384e-04:  12%|█▏        | 331/2863 [03:59<28:18,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 331: train loss 5.55145. lr 5.950384e-04:  12%|█▏        | 332/2863 [03:59<28:16,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 332: train loss 5.57988. lr 5.950086e-04:  12%|█▏        | 332/2863 [03:59<28:16,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 332: train loss 5.57988. lr 5.950086e-04:  12%|█▏        | 333/2863 [03:59<28:14,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 333: train loss 5.57938. lr 5.949786e-04:  12%|█▏        | 333/2863 [04:00<28:14,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 333: train loss 5.57938. lr 5.949786e-04:  12%|█▏        | 334/2863 [04:00<28:12,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 334: train loss 5.52467. lr 5.949486e-04:  12%|█▏        | 334/2863 [04:01<28:12,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 334: train loss 5.52467. lr 5.949486e-04:  12%|█▏        | 335/2863 [04:01<28:10,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 335: train loss 5.52874. lr 5.949184e-04:  12%|█▏        | 335/2863 [04:01<28:10,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 335: train loss 5.52874. lr 5.949184e-04:  12%|█▏        | 336/2863 [04:01<28:10,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 336: train loss 5.54933. lr 5.948882e-04:  12%|█▏        | 336/2863 [04:02<28:10,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 336: train loss 5.54933. lr 5.948882e-04:  12%|█▏        | 337/2863 [04:02<28:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 337: train loss 5.47733. lr 5.948579e-04:  12%|█▏        | 337/2863 [04:03<28:08,  1.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 337: train loss 5.47733. lr 5.948579e-04:  12%|█▏        | 338/2863 [04:03<28:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 338: train loss 5.57617. lr 5.948275e-04:  12%|█▏        | 338/2863 [04:03<28:08,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 338: train loss 5.57617. lr 5.948275e-04:  12%|█▏        | 339/2863 [04:03<28:07,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 339: train loss 5.51888. lr 5.947970e-04:  12%|█▏        | 339/2863 [04:04<28:07,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 339: train loss 5.51888. lr 5.947970e-04:  12%|█▏        | 340/2863 [04:04<28:07,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 340: train loss 5.58917. lr 5.947664e-04:  12%|█▏        | 340/2863 [04:05<28:07,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 340: train loss 5.58917. lr 5.947664e-04:  12%|█▏        | 341/2863 [04:05<28:07,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 341: train loss 5.43871. lr 5.947358e-04:  12%|█▏        | 341/2863 [04:05<28:07,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 341: train loss 5.43871. lr 5.947358e-04:  12%|█▏        | 342/2863 [04:05<28:07,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 342: train loss 5.47805. lr 5.947050e-04:  12%|█▏        | 342/2863 [04:06<28:07,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 342: train loss 5.47805. lr 5.947050e-04:  12%|█▏        | 343/2863 [04:06<28:06,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 343: train loss 5.45242. lr 5.946742e-04:  12%|█▏        | 343/2863 [04:07<28:06,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 343: train loss 5.45242. lr 5.946742e-04:  12%|█▏        | 344/2863 [04:07<28:06,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 344: train loss 5.48453. lr 5.946432e-04:  12%|█▏        | 344/2863 [04:07<28:06,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 344: train loss 5.48453. lr 5.946432e-04:  12%|█▏        | 345/2863 [04:07<28:05,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 345: train loss 5.46150. lr 5.946122e-04:  12%|█▏        | 345/2863 [04:08<28:05,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 345: train loss 5.46150. lr 5.946122e-04:  12%|█▏        | 346/2863 [04:08<28:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 346: train loss 5.46175. lr 5.945811e-04:  12%|█▏        | 346/2863 [04:09<28:03,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 346: train loss 5.46175. lr 5.945811e-04:  12%|█▏        | 347/2863 [04:09<28:02,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 347: train loss 5.49820. lr 5.945499e-04:  12%|█▏        | 347/2863 [04:09<28:02,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 347: train loss 5.49820. lr 5.945499e-04:  12%|█▏        | 348/2863 [04:09<28:01,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 348: train loss 5.54025. lr 5.945186e-04:  12%|█▏        | 348/2863 [04:10<28:01,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 348: train loss 5.54025. lr 5.945186e-04:  12%|█▏        | 349/2863 [04:10<28:01,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 349: train loss 5.44276. lr 5.944873e-04:  12%|█▏        | 349/2863 [04:11<28:01,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 349: train loss 5.44276. lr 5.944873e-04:  12%|█▏        | 350/2863 [04:11<29:30,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 350: train loss 5.46375. lr 5.944558e-04:  12%|█▏        | 350/2863 [04:11<29:30,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 350: train loss 5.46375. lr 5.944558e-04:  12%|█▏        | 351/2863 [04:11<29:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 351: train loss 5.50313. lr 5.944242e-04:  12%|█▏        | 351/2863 [04:12<29:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 351: train loss 5.50313. lr 5.944242e-04:  12%|█▏        | 352/2863 [04:12<28:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 352: train loss 5.46323. lr 5.943926e-04:  12%|█▏        | 352/2863 [04:13<28:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 352: train loss 5.46323. lr 5.943926e-04:  12%|█▏        | 353/2863 [04:13<28:30,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 353: train loss 5.45628. lr 5.943609e-04:  12%|█▏        | 353/2863 [04:13<28:30,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 353: train loss 5.45628. lr 5.943609e-04:  12%|█▏        | 354/2863 [04:13<28:19,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 354: train loss 5.42412. lr 5.943291e-04:  12%|█▏        | 354/2863 [04:14<28:19,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 354: train loss 5.42412. lr 5.943291e-04:  12%|█▏        | 355/2863 [04:14<28:12,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 355: train loss 5.44710. lr 5.942972e-04:  12%|█▏        | 355/2863 [04:15<28:12,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 355: train loss 5.44710. lr 5.942972e-04:  12%|█▏        | 356/2863 [04:15<28:06,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 356: train loss 5.38687. lr 5.942652e-04:  12%|█▏        | 356/2863 [04:15<28:06,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 356: train loss 5.38687. lr 5.942652e-04:  12%|█▏        | 357/2863 [04:15<28:01,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 357: train loss 5.40484. lr 5.942331e-04:  12%|█▏        | 357/2863 [04:16<28:01,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 357: train loss 5.40484. lr 5.942331e-04:  13%|█▎        | 358/2863 [04:16<27:59,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 358: train loss 5.43556. lr 5.942009e-04:  13%|█▎        | 358/2863 [04:17<27:59,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 358: train loss 5.43556. lr 5.942009e-04:  13%|█▎        | 359/2863 [04:17<27:56,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 359: train loss 5.44467. lr 5.941686e-04:  13%|█▎        | 359/2863 [04:17<27:56,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 359: train loss 5.44467. lr 5.941686e-04:  13%|█▎        | 360/2863 [04:17<27:54,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 360: train loss 5.40601. lr 5.941363e-04:  13%|█▎        | 360/2863 [04:18<27:54,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 360: train loss 5.40601. lr 5.941363e-04:  13%|█▎        | 361/2863 [04:18<27:54,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 361: train loss 5.40866. lr 5.941039e-04:  13%|█▎        | 361/2863 [04:19<27:54,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 361: train loss 5.40866. lr 5.941039e-04:  13%|█▎        | 362/2863 [04:19<27:52,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 362: train loss 5.43330. lr 5.940713e-04:  13%|█▎        | 362/2863 [04:20<27:52,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 362: train loss 5.43330. lr 5.940713e-04:  13%|█▎        | 363/2863 [04:20<27:52,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 363: train loss 5.43462. lr 5.940387e-04:  13%|█▎        | 363/2863 [04:20<27:52,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 363: train loss 5.43462. lr 5.940387e-04:  13%|█▎        | 364/2863 [04:20<27:51,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 364: train loss 5.36200. lr 5.940060e-04:  13%|█▎        | 364/2863 [04:21<27:51,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 364: train loss 5.36200. lr 5.940060e-04:  13%|█▎        | 365/2863 [04:21<27:51,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 365: train loss 5.36559. lr 5.939732e-04:  13%|█▎        | 365/2863 [04:22<27:51,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 365: train loss 5.36559. lr 5.939732e-04:  13%|█▎        | 366/2863 [04:22<27:50,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 366: train loss 5.35821. lr 5.939403e-04:  13%|█▎        | 366/2863 [04:22<27:50,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 366: train loss 5.35821. lr 5.939403e-04:  13%|█▎        | 367/2863 [04:22<27:50,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 367: train loss 5.37693. lr 5.939074e-04:  13%|█▎        | 367/2863 [04:23<27:50,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 367: train loss 5.37693. lr 5.939074e-04:  13%|█▎        | 368/2863 [04:23<27:50,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 368: train loss 5.39416. lr 5.938743e-04:  13%|█▎        | 368/2863 [04:24<27:50,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 368: train loss 5.39416. lr 5.938743e-04:  13%|█▎        | 369/2863 [04:24<27:49,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 369: train loss 5.33031. lr 5.938412e-04:  13%|█▎        | 369/2863 [04:24<27:49,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 369: train loss 5.33031. lr 5.938412e-04:  13%|█▎        | 370/2863 [04:24<27:48,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 370: train loss 5.30778. lr 5.938079e-04:  13%|█▎        | 370/2863 [04:25<27:48,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 370: train loss 5.30778. lr 5.938079e-04:  13%|█▎        | 371/2863 [04:25<27:46,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 371: train loss 5.36192. lr 5.937746e-04:  13%|█▎        | 371/2863 [04:26<27:46,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 371: train loss 5.36192. lr 5.937746e-04:  13%|█▎        | 372/2863 [04:26<27:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 372: train loss 5.29521. lr 5.937412e-04:  13%|█▎        | 372/2863 [04:26<27:45,  1.50it/s]\u001b[A\n",
      "epoch 1 iter 372: train loss 5.29521. lr 5.937412e-04:  13%|█▎        | 373/2863 [04:26<28:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 373: train loss 5.32604. lr 5.937077e-04:  13%|█▎        | 373/2863 [04:27<28:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 373: train loss 5.32604. lr 5.937077e-04:  13%|█▎        | 374/2863 [04:27<29:38,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 374: train loss 5.33467. lr 5.936741e-04:  13%|█▎        | 374/2863 [04:28<29:38,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 374: train loss 5.33467. lr 5.936741e-04:  13%|█▎        | 375/2863 [04:28<30:11,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 375: train loss 5.34986. lr 5.936404e-04:  13%|█▎        | 375/2863 [04:29<30:11,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 375: train loss 5.34986. lr 5.936404e-04:  13%|█▎        | 376/2863 [04:29<30:36,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 376: train loss 5.39611. lr 5.936067e-04:  13%|█▎        | 376/2863 [04:29<30:36,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 376: train loss 5.39611. lr 5.936067e-04:  13%|█▎        | 377/2863 [04:29<30:55,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 377: train loss 5.31446. lr 5.935728e-04:  13%|█▎        | 377/2863 [04:30<30:55,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 377: train loss 5.31446. lr 5.935728e-04:  13%|█▎        | 378/2863 [04:30<32:30,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 378: train loss 5.35244. lr 5.935389e-04:  13%|█▎        | 378/2863 [04:31<32:30,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 378: train loss 5.35244. lr 5.935389e-04:  13%|█▎        | 379/2863 [04:31<32:08,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 379: train loss 5.30113. lr 5.935048e-04:  13%|█▎        | 379/2863 [04:32<32:08,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 379: train loss 5.30113. lr 5.935048e-04:  13%|█▎        | 380/2863 [04:32<31:58,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 380: train loss 5.25543. lr 5.934707e-04:  13%|█▎        | 380/2863 [04:32<31:58,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 380: train loss 5.25543. lr 5.934707e-04:  13%|█▎        | 381/2863 [04:32<31:50,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 381: train loss 5.32502. lr 5.934365e-04:  13%|█▎        | 381/2863 [04:33<31:50,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 381: train loss 5.32502. lr 5.934365e-04:  13%|█▎        | 382/2863 [04:33<31:47,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 382: train loss 5.33569. lr 5.934022e-04:  13%|█▎        | 382/2863 [04:34<31:47,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 382: train loss 5.33569. lr 5.934022e-04:  13%|█▎        | 383/2863 [04:34<31:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 383: train loss 5.33761. lr 5.933678e-04:  13%|█▎        | 383/2863 [04:35<31:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 383: train loss 5.33761. lr 5.933678e-04:  13%|█▎        | 384/2863 [04:35<31:36,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 384: train loss 5.24619. lr 5.933334e-04:  13%|█▎        | 384/2863 [04:36<31:36,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 384: train loss 5.24619. lr 5.933334e-04:  13%|█▎        | 385/2863 [04:36<31:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 385: train loss 5.27755. lr 5.932988e-04:  13%|█▎        | 385/2863 [04:36<31:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 385: train loss 5.27755. lr 5.932988e-04:  13%|█▎        | 386/2863 [04:36<31:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 386: train loss 5.26396. lr 5.932641e-04:  13%|█▎        | 386/2863 [04:37<31:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 386: train loss 5.26396. lr 5.932641e-04:  14%|█▎        | 387/2863 [04:37<31:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 387: train loss 5.30557. lr 5.932294e-04:  14%|█▎        | 387/2863 [04:38<31:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 387: train loss 5.30557. lr 5.932294e-04:  14%|█▎        | 388/2863 [04:38<31:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 388: train loss 5.26946. lr 5.931946e-04:  14%|█▎        | 388/2863 [04:39<31:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 388: train loss 5.26946. lr 5.931946e-04:  14%|█▎        | 389/2863 [04:39<31:18,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 389: train loss 5.23298. lr 5.931597e-04:  14%|█▎        | 389/2863 [04:39<31:18,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 389: train loss 5.23298. lr 5.931597e-04:  14%|█▎        | 390/2863 [04:39<31:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 390: train loss 5.27563. lr 5.931247e-04:  14%|█▎        | 390/2863 [04:40<31:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 390: train loss 5.27563. lr 5.931247e-04:  14%|█▎        | 391/2863 [04:40<31:20,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 391: train loss 5.28118. lr 5.930896e-04:  14%|█▎        | 391/2863 [04:41<31:20,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 391: train loss 5.28118. lr 5.930896e-04:  14%|█▎        | 392/2863 [04:41<31:24,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 392: train loss 5.25557. lr 5.930544e-04:  14%|█▎        | 392/2863 [04:42<31:24,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 392: train loss 5.25557. lr 5.930544e-04:  14%|█▎        | 393/2863 [04:42<31:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 393: train loss 5.23898. lr 5.930191e-04:  14%|█▎        | 393/2863 [04:42<31:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 393: train loss 5.23898. lr 5.930191e-04:  14%|█▍        | 394/2863 [04:42<31:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 394: train loss 5.23761. lr 5.929838e-04:  14%|█▍        | 394/2863 [04:43<31:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 394: train loss 5.23761. lr 5.929838e-04:  14%|█▍        | 395/2863 [04:43<31:19,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 395: train loss 5.29017. lr 5.929483e-04:  14%|█▍        | 395/2863 [04:44<31:19,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 395: train loss 5.29017. lr 5.929483e-04:  14%|█▍        | 396/2863 [04:44<31:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 396: train loss 5.19315. lr 5.929128e-04:  14%|█▍        | 396/2863 [04:45<31:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 396: train loss 5.19315. lr 5.929128e-04:  14%|█▍        | 397/2863 [04:45<31:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 397: train loss 5.18887. lr 5.928772e-04:  14%|█▍        | 397/2863 [04:45<31:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 397: train loss 5.18887. lr 5.928772e-04:  14%|█▍        | 398/2863 [04:45<31:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 398: train loss 5.20971. lr 5.928415e-04:  14%|█▍        | 398/2863 [04:46<31:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 398: train loss 5.20971. lr 5.928415e-04:  14%|█▍        | 399/2863 [04:46<31:22,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 399: train loss 5.25783. lr 5.928057e-04:  14%|█▍        | 399/2863 [04:47<31:22,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 399: train loss 5.25783. lr 5.928057e-04:  14%|█▍        | 400/2863 [04:47<31:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 400: train loss 5.18482. lr 5.927698e-04:  14%|█▍        | 400/2863 [04:48<31:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 400: train loss 5.18482. lr 5.927698e-04:  14%|█▍        | 401/2863 [04:48<31:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 401: train loss 5.21501. lr 5.927338e-04:  14%|█▍        | 401/2863 [04:48<31:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 401: train loss 5.21501. lr 5.927338e-04:  14%|█▍        | 402/2863 [04:48<31:13,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 402: train loss 5.17830. lr 5.926977e-04:  14%|█▍        | 402/2863 [04:49<31:13,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 402: train loss 5.17830. lr 5.926977e-04:  14%|█▍        | 403/2863 [04:49<31:14,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 403: train loss 5.18625. lr 5.926616e-04:  14%|█▍        | 403/2863 [04:50<31:14,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 403: train loss 5.18625. lr 5.926616e-04:  14%|█▍        | 404/2863 [04:50<31:13,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 404: train loss 5.20920. lr 5.926254e-04:  14%|█▍        | 404/2863 [04:51<31:13,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 404: train loss 5.20920. lr 5.926254e-04:  14%|█▍        | 405/2863 [04:51<31:11,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 405: train loss 5.14515. lr 5.925890e-04:  14%|█▍        | 405/2863 [04:52<31:11,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 405: train loss 5.14515. lr 5.925890e-04:  14%|█▍        | 406/2863 [04:52<32:31,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 406: train loss 5.16185. lr 5.925526e-04:  14%|█▍        | 406/2863 [04:52<32:31,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 406: train loss 5.16185. lr 5.925526e-04:  14%|█▍        | 407/2863 [04:52<32:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 407: train loss 5.13322. lr 5.925161e-04:  14%|█▍        | 407/2863 [04:53<32:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 407: train loss 5.13322. lr 5.925161e-04:  14%|█▍        | 408/2863 [04:53<31:49,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 408: train loss 5.17234. lr 5.924795e-04:  14%|█▍        | 408/2863 [04:54<31:49,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 408: train loss 5.17234. lr 5.924795e-04:  14%|█▍        | 409/2863 [04:54<31:36,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 409: train loss 5.19458. lr 5.924428e-04:  14%|█▍        | 409/2863 [04:55<31:36,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 409: train loss 5.19458. lr 5.924428e-04:  14%|█▍        | 410/2863 [04:55<31:28,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 410: train loss 5.12392. lr 5.924061e-04:  14%|█▍        | 410/2863 [04:55<31:28,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 410: train loss 5.12392. lr 5.924061e-04:  14%|█▍        | 411/2863 [04:55<31:22,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 411: train loss 5.12838. lr 5.923692e-04:  14%|█▍        | 411/2863 [04:56<31:22,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 411: train loss 5.12838. lr 5.923692e-04:  14%|█▍        | 412/2863 [04:56<31:17,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 412: train loss 5.14287. lr 5.923323e-04:  14%|█▍        | 412/2863 [04:57<31:17,  1.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 412: train loss 5.14287. lr 5.923323e-04:  14%|█▍        | 413/2863 [04:57<31:16,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 413: train loss 5.10982. lr 5.922952e-04:  14%|█▍        | 413/2863 [04:58<31:16,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 413: train loss 5.10982. lr 5.922952e-04:  14%|█▍        | 414/2863 [04:58<31:14,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 414: train loss 5.12314. lr 5.922581e-04:  14%|█▍        | 414/2863 [04:59<31:14,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 414: train loss 5.12314. lr 5.922581e-04:  14%|█▍        | 415/2863 [04:59<31:12,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 415: train loss 5.09799. lr 5.922209e-04:  14%|█▍        | 415/2863 [04:59<31:12,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 415: train loss 5.09799. lr 5.922209e-04:  15%|█▍        | 416/2863 [04:59<31:04,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 416: train loss 5.14946. lr 5.921836e-04:  15%|█▍        | 416/2863 [05:00<31:04,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 416: train loss 5.14946. lr 5.921836e-04:  15%|█▍        | 417/2863 [05:00<31:02,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 417: train loss 5.16160. lr 5.921462e-04:  15%|█▍        | 417/2863 [05:01<31:02,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 417: train loss 5.16160. lr 5.921462e-04:  15%|█▍        | 418/2863 [05:01<31:07,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 418: train loss 5.07376. lr 5.921088e-04:  15%|█▍        | 418/2863 [05:02<31:07,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 418: train loss 5.07376. lr 5.921088e-04:  15%|█▍        | 419/2863 [05:02<31:08,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 419: train loss 5.08159. lr 5.920712e-04:  15%|█▍        | 419/2863 [05:02<31:08,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 419: train loss 5.08159. lr 5.920712e-04:  15%|█▍        | 420/2863 [05:02<31:07,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 420: train loss 5.06514. lr 5.920336e-04:  15%|█▍        | 420/2863 [05:03<31:07,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 420: train loss 5.06514. lr 5.920336e-04:  15%|█▍        | 421/2863 [05:03<31:08,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 421: train loss 5.09092. lr 5.919958e-04:  15%|█▍        | 421/2863 [05:04<31:08,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 421: train loss 5.09092. lr 5.919958e-04:  15%|█▍        | 422/2863 [05:04<31:06,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 422: train loss 5.07374. lr 5.919580e-04:  15%|█▍        | 422/2863 [05:05<31:06,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 422: train loss 5.07374. lr 5.919580e-04:  15%|█▍        | 423/2863 [05:05<31:03,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 423: train loss 5.10725. lr 5.919201e-04:  15%|█▍        | 423/2863 [05:05<31:03,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 423: train loss 5.10725. lr 5.919201e-04:  15%|█▍        | 424/2863 [05:05<31:04,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 424: train loss 5.10612. lr 5.918821e-04:  15%|█▍        | 424/2863 [05:06<31:04,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 424: train loss 5.10612. lr 5.918821e-04:  15%|█▍        | 425/2863 [05:06<31:06,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 425: train loss 5.08164. lr 5.918440e-04:  15%|█▍        | 425/2863 [05:07<31:06,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 425: train loss 5.08164. lr 5.918440e-04:  15%|█▍        | 426/2863 [05:07<31:06,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 426: train loss 5.03994. lr 5.918058e-04:  15%|█▍        | 426/2863 [05:08<31:06,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 426: train loss 5.03994. lr 5.918058e-04:  15%|█▍        | 427/2863 [05:08<30:55,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 427: train loss 5.06896. lr 5.917676e-04:  15%|█▍        | 427/2863 [05:08<30:55,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 427: train loss 5.06896. lr 5.917676e-04:  15%|█▍        | 428/2863 [05:08<30:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 428: train loss 5.04955. lr 5.917292e-04:  15%|█▍        | 428/2863 [05:09<30:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 428: train loss 5.04955. lr 5.917292e-04:  15%|█▍        | 429/2863 [05:09<30:55,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 429: train loss 5.05354. lr 5.916908e-04:  15%|█▍        | 429/2863 [05:10<30:55,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 429: train loss 5.05354. lr 5.916908e-04:  15%|█▌        | 430/2863 [05:10<30:56,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 430: train loss 5.04431. lr 5.916523e-04:  15%|█▌        | 430/2863 [05:11<30:56,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 430: train loss 5.04431. lr 5.916523e-04:  15%|█▌        | 431/2863 [05:11<30:57,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 431: train loss 5.03888. lr 5.916136e-04:  15%|█▌        | 431/2863 [05:11<30:57,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 431: train loss 5.03888. lr 5.916136e-04:  15%|█▌        | 432/2863 [05:11<30:55,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 432: train loss 5.01322. lr 5.915749e-04:  15%|█▌        | 432/2863 [05:12<30:55,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 432: train loss 5.01322. lr 5.915749e-04:  15%|█▌        | 433/2863 [05:12<30:52,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 433: train loss 5.01664. lr 5.915362e-04:  15%|█▌        | 433/2863 [05:13<30:52,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 433: train loss 5.01664. lr 5.915362e-04:  15%|█▌        | 434/2863 [05:13<32:39,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 434: train loss 5.00678. lr 5.914973e-04:  15%|█▌        | 434/2863 [05:14<32:39,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 434: train loss 5.00678. lr 5.914973e-04:  15%|█▌        | 435/2863 [05:14<32:08,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 435: train loss 5.03481. lr 5.914583e-04:  15%|█▌        | 435/2863 [05:15<32:08,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 435: train loss 5.03481. lr 5.914583e-04:  15%|█▌        | 436/2863 [05:15<31:45,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 436: train loss 5.00596. lr 5.914193e-04:  15%|█▌        | 436/2863 [05:15<31:45,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 436: train loss 5.00596. lr 5.914193e-04:  15%|█▌        | 437/2863 [05:15<31:27,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 437: train loss 4.94621. lr 5.913801e-04:  15%|█▌        | 437/2863 [05:16<31:27,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 437: train loss 4.94621. lr 5.913801e-04:  15%|█▌        | 438/2863 [05:16<31:10,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 438: train loss 4.99892. lr 5.913409e-04:  15%|█▌        | 438/2863 [05:17<31:10,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 438: train loss 4.99892. lr 5.913409e-04:  15%|█▌        | 439/2863 [05:17<31:00,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 439: train loss 4.97753. lr 5.913016e-04:  15%|█▌        | 439/2863 [05:18<31:00,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 439: train loss 4.97753. lr 5.913016e-04:  15%|█▌        | 440/2863 [05:18<30:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 440: train loss 4.98249. lr 5.912622e-04:  15%|█▌        | 440/2863 [05:18<30:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 440: train loss 4.98249. lr 5.912622e-04:  15%|█▌        | 441/2863 [05:18<30:50,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 441: train loss 4.95554. lr 5.912227e-04:  15%|█▌        | 441/2863 [05:19<30:50,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 441: train loss 4.95554. lr 5.912227e-04:  15%|█▌        | 442/2863 [05:19<30:48,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 442: train loss 4.99420. lr 5.911831e-04:  15%|█▌        | 442/2863 [05:20<30:48,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 442: train loss 4.99420. lr 5.911831e-04:  15%|█▌        | 443/2863 [05:20<30:45,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 443: train loss 4.99789. lr 5.911434e-04:  15%|█▌        | 443/2863 [05:21<30:45,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 443: train loss 4.99789. lr 5.911434e-04:  16%|█▌        | 444/2863 [05:21<30:38,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 444: train loss 4.98439. lr 5.911037e-04:  16%|█▌        | 444/2863 [05:22<30:38,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 444: train loss 4.98439. lr 5.911037e-04:  16%|█▌        | 445/2863 [05:22<30:39,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 445: train loss 4.95939. lr 5.910638e-04:  16%|█▌        | 445/2863 [05:22<30:39,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 445: train loss 4.95939. lr 5.910638e-04:  16%|█▌        | 446/2863 [05:22<30:40,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 446: train loss 5.01628. lr 5.910239e-04:  16%|█▌        | 446/2863 [05:23<30:40,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 446: train loss 5.01628. lr 5.910239e-04:  16%|█▌        | 447/2863 [05:23<30:42,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 447: train loss 4.84953. lr 5.909839e-04:  16%|█▌        | 447/2863 [05:24<30:42,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 447: train loss 4.84953. lr 5.909839e-04:  16%|█▌        | 448/2863 [05:24<30:43,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 448: train loss 5.01871. lr 5.909438e-04:  16%|█▌        | 448/2863 [05:25<30:43,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 448: train loss 5.01871. lr 5.909438e-04:  16%|█▌        | 449/2863 [05:25<30:36,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 449: train loss 4.89463. lr 5.909036e-04:  16%|█▌        | 449/2863 [05:25<30:36,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 449: train loss 4.89463. lr 5.909036e-04:  16%|█▌        | 450/2863 [05:25<30:35,  1.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 450: train loss 4.95840. lr 5.908633e-04:  16%|█▌        | 450/2863 [05:26<30:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 450: train loss 4.95840. lr 5.908633e-04:  16%|█▌        | 451/2863 [05:26<30:34,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 451: train loss 4.88680. lr 5.908229e-04:  16%|█▌        | 451/2863 [05:27<30:34,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 451: train loss 4.88680. lr 5.908229e-04:  16%|█▌        | 452/2863 [05:27<30:37,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 452: train loss 4.93602. lr 5.907825e-04:  16%|█▌        | 452/2863 [05:28<30:37,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 452: train loss 4.93602. lr 5.907825e-04:  16%|█▌        | 453/2863 [05:28<30:41,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 453: train loss 4.97150. lr 5.907419e-04:  16%|█▌        | 453/2863 [05:28<30:41,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 453: train loss 4.97150. lr 5.907419e-04:  16%|█▌        | 454/2863 [05:28<30:40,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 454: train loss 4.90617. lr 5.907013e-04:  16%|█▌        | 454/2863 [05:29<30:40,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 454: train loss 4.90617. lr 5.907013e-04:  16%|█▌        | 455/2863 [05:29<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 455: train loss 4.92668. lr 5.906606e-04:  16%|█▌        | 455/2863 [05:30<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 455: train loss 4.92668. lr 5.906606e-04:  16%|█▌        | 456/2863 [05:30<30:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 456: train loss 4.90523. lr 5.906198e-04:  16%|█▌        | 456/2863 [05:31<30:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 456: train loss 4.90523. lr 5.906198e-04:  16%|█▌        | 457/2863 [05:31<30:37,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 457: train loss 4.84752. lr 5.905789e-04:  16%|█▌        | 457/2863 [05:31<30:37,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 457: train loss 4.84752. lr 5.905789e-04:  16%|█▌        | 458/2863 [05:31<30:38,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 458: train loss 4.87536. lr 5.905379e-04:  16%|█▌        | 458/2863 [05:32<30:38,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 458: train loss 4.87536. lr 5.905379e-04:  16%|█▌        | 459/2863 [05:32<30:38,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 459: train loss 4.91833. lr 5.904968e-04:  16%|█▌        | 459/2863 [05:33<30:38,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 459: train loss 4.91833. lr 5.904968e-04:  16%|█▌        | 460/2863 [05:33<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 460: train loss 4.89404. lr 5.904557e-04:  16%|█▌        | 460/2863 [05:34<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 460: train loss 4.89404. lr 5.904557e-04:  16%|█▌        | 461/2863 [05:34<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 461: train loss 4.88580. lr 5.904144e-04:  16%|█▌        | 461/2863 [05:35<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 461: train loss 4.88580. lr 5.904144e-04:  16%|█▌        | 462/2863 [05:35<31:52,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 462: train loss 4.87416. lr 5.903731e-04:  16%|█▌        | 462/2863 [05:35<31:52,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 462: train loss 4.87416. lr 5.903731e-04:  16%|█▌        | 463/2863 [05:35<31:28,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 463: train loss 4.86441. lr 5.903317e-04:  16%|█▌        | 463/2863 [05:36<31:28,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 463: train loss 4.86441. lr 5.903317e-04:  16%|█▌        | 464/2863 [05:36<31:14,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 464: train loss 4.85557. lr 5.902902e-04:  16%|█▌        | 464/2863 [05:37<31:14,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 464: train loss 4.85557. lr 5.902902e-04:  16%|█▌        | 465/2863 [05:37<30:51,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 465: train loss 4.85006. lr 5.902486e-04:  16%|█▌        | 465/2863 [05:38<30:51,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 465: train loss 4.85006. lr 5.902486e-04:  16%|█▋        | 466/2863 [05:38<30:40,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 466: train loss 4.82982. lr 5.902069e-04:  16%|█▋        | 466/2863 [05:38<30:40,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 466: train loss 4.82982. lr 5.902069e-04:  16%|█▋        | 467/2863 [05:38<30:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 467: train loss 4.80510. lr 5.901651e-04:  16%|█▋        | 467/2863 [05:39<30:35,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 467: train loss 4.80510. lr 5.901651e-04:  16%|█▋        | 468/2863 [05:39<30:33,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 468: train loss 4.85669. lr 5.901233e-04:  16%|█▋        | 468/2863 [05:40<30:33,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 468: train loss 4.85669. lr 5.901233e-04:  16%|█▋        | 469/2863 [05:40<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 469: train loss 4.88019. lr 5.900813e-04:  16%|█▋        | 469/2863 [05:41<30:32,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 469: train loss 4.88019. lr 5.900813e-04:  16%|█▋        | 470/2863 [05:41<30:30,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 470: train loss 4.88648. lr 5.900393e-04:  16%|█▋        | 470/2863 [05:41<30:30,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 470: train loss 4.88648. lr 5.900393e-04:  16%|█▋        | 471/2863 [05:41<30:26,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 471: train loss 4.83234. lr 5.899972e-04:  16%|█▋        | 471/2863 [05:42<30:26,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 471: train loss 4.83234. lr 5.899972e-04:  16%|█▋        | 472/2863 [05:42<30:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 472: train loss 4.81614. lr 5.899550e-04:  16%|█▋        | 472/2863 [05:43<30:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 472: train loss 4.81614. lr 5.899550e-04:  17%|█▋        | 473/2863 [05:43<30:28,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 473: train loss 4.86964. lr 5.899127e-04:  17%|█▋        | 473/2863 [05:44<30:28,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 473: train loss 4.86964. lr 5.899127e-04:  17%|█▋        | 474/2863 [05:44<30:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 474: train loss 4.77488. lr 5.898703e-04:  17%|█▋        | 474/2863 [05:45<30:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 474: train loss 4.77488. lr 5.898703e-04:  17%|█▋        | 475/2863 [05:45<30:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 475: train loss 4.85145. lr 5.898278e-04:  17%|█▋        | 475/2863 [05:45<30:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 475: train loss 4.85145. lr 5.898278e-04:  17%|█▋        | 476/2863 [05:45<30:19,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 476: train loss 4.81814. lr 5.897853e-04:  17%|█▋        | 476/2863 [05:46<30:19,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 476: train loss 4.81814. lr 5.897853e-04:  17%|█▋        | 477/2863 [05:46<30:18,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 477: train loss 4.76725. lr 5.897427e-04:  17%|█▋        | 477/2863 [05:47<30:18,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 477: train loss 4.76725. lr 5.897427e-04:  17%|█▋        | 478/2863 [05:47<30:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 478: train loss 4.79184. lr 5.896999e-04:  17%|█▋        | 478/2863 [05:48<30:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 478: train loss 4.79184. lr 5.896999e-04:  17%|█▋        | 479/2863 [05:48<30:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 479: train loss 4.80437. lr 5.896571e-04:  17%|█▋        | 479/2863 [05:48<30:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 479: train loss 4.80437. lr 5.896571e-04:  17%|█▋        | 480/2863 [05:48<30:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 480: train loss 4.73109. lr 5.896142e-04:  17%|█▋        | 480/2863 [05:49<30:23,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 480: train loss 4.73109. lr 5.896142e-04:  17%|█▋        | 481/2863 [05:49<30:24,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 481: train loss 4.74141. lr 5.895712e-04:  17%|█▋        | 481/2863 [05:50<30:24,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 481: train loss 4.74141. lr 5.895712e-04:  17%|█▋        | 482/2863 [05:50<29:39,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 482: train loss 4.74111. lr 5.895281e-04:  17%|█▋        | 482/2863 [05:50<29:39,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 482: train loss 4.74111. lr 5.895281e-04:  17%|█▋        | 483/2863 [05:50<28:42,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 483: train loss 4.78417. lr 5.894850e-04:  17%|█▋        | 483/2863 [05:51<28:42,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 483: train loss 4.78417. lr 5.894850e-04:  17%|█▋        | 484/2863 [05:51<28:05,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 484: train loss 4.72599. lr 5.894417e-04:  17%|█▋        | 484/2863 [05:52<28:05,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 484: train loss 4.72599. lr 5.894417e-04:  17%|█▋        | 485/2863 [05:52<27:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 485: train loss 4.78953. lr 5.893984e-04:  17%|█▋        | 485/2863 [05:53<27:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 485: train loss 4.78953. lr 5.893984e-04:  17%|█▋        | 486/2863 [05:53<27:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 486: train loss 4.74528. lr 5.893549e-04:  17%|█▋        | 486/2863 [05:53<27:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 486: train loss 4.74528. lr 5.893549e-04:  17%|█▋        | 487/2863 [05:53<27:07,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 487: train loss 4.72469. lr 5.893114e-04:  17%|█▋        | 487/2863 [05:54<27:07,  1.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 487: train loss 4.72469. lr 5.893114e-04:  17%|█▋        | 488/2863 [05:54<26:57,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 488: train loss 4.69134. lr 5.892678e-04:  17%|█▋        | 488/2863 [05:55<26:57,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 488: train loss 4.69134. lr 5.892678e-04:  17%|█▋        | 489/2863 [05:55<26:50,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 489: train loss 4.66252. lr 5.892241e-04:  17%|█▋        | 489/2863 [05:55<26:50,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 489: train loss 4.66252. lr 5.892241e-04:  17%|█▋        | 490/2863 [05:55<28:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 490: train loss 4.69366. lr 5.891804e-04:  17%|█▋        | 490/2863 [05:56<28:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 490: train loss 4.69366. lr 5.891804e-04:  17%|█▋        | 491/2863 [05:56<27:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 491: train loss 4.71170. lr 5.891365e-04:  17%|█▋        | 491/2863 [05:57<27:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 491: train loss 4.71170. lr 5.891365e-04:  17%|█▋        | 492/2863 [05:57<27:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 492: train loss 4.70152. lr 5.890926e-04:  17%|█▋        | 492/2863 [05:57<27:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 492: train loss 4.70152. lr 5.890926e-04:  17%|█▋        | 493/2863 [05:57<27:06,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 493: train loss 4.73067. lr 5.890485e-04:  17%|█▋        | 493/2863 [05:58<27:06,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 493: train loss 4.73067. lr 5.890485e-04:  17%|█▋        | 494/2863 [05:58<26:55,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 494: train loss 4.76378. lr 5.890044e-04:  17%|█▋        | 494/2863 [05:59<26:55,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 494: train loss 4.76378. lr 5.890044e-04:  17%|█▋        | 495/2863 [05:59<26:48,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 495: train loss 4.67302. lr 5.889602e-04:  17%|█▋        | 495/2863 [05:59<26:48,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 495: train loss 4.67302. lr 5.889602e-04:  17%|█▋        | 496/2863 [05:59<26:43,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 496: train loss 4.65818. lr 5.889159e-04:  17%|█▋        | 496/2863 [06:00<26:43,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 496: train loss 4.65818. lr 5.889159e-04:  17%|█▋        | 497/2863 [06:00<26:37,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 497: train loss 4.68073. lr 5.888715e-04:  17%|█▋        | 497/2863 [06:01<26:37,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 497: train loss 4.68073. lr 5.888715e-04:  17%|█▋        | 498/2863 [06:01<26:33,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 498: train loss 4.69726. lr 5.888270e-04:  17%|█▋        | 498/2863 [06:01<26:33,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 498: train loss 4.69726. lr 5.888270e-04:  17%|█▋        | 499/2863 [06:01<26:33,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 499: train loss 4.61880. lr 5.887825e-04:  17%|█▋        | 499/2863 [06:02<26:33,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 499: train loss 4.61880. lr 5.887825e-04:  17%|█▋        | 500/2863 [06:02<26:31,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 500: train loss 4.63130. lr 5.887378e-04:  17%|█▋        | 500/2863 [06:03<26:31,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 500: train loss 4.63130. lr 5.887378e-04:  17%|█▋        | 501/2863 [06:03<26:28,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 501: train loss 4.65124. lr 5.886931e-04:  17%|█▋        | 501/2863 [06:03<26:28,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 501: train loss 4.65124. lr 5.886931e-04:  18%|█▊        | 502/2863 [06:03<26:27,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 502: train loss 4.65348. lr 5.886483e-04:  18%|█▊        | 502/2863 [06:04<26:27,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 502: train loss 4.65348. lr 5.886483e-04:  18%|█▊        | 503/2863 [06:04<26:27,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 503: train loss 4.68604. lr 5.886034e-04:  18%|█▊        | 503/2863 [06:05<26:27,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 503: train loss 4.68604. lr 5.886034e-04:  18%|█▊        | 504/2863 [06:05<26:27,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 504: train loss 4.66032. lr 5.885584e-04:  18%|█▊        | 504/2863 [06:05<26:27,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 504: train loss 4.66032. lr 5.885584e-04:  18%|█▊        | 505/2863 [06:05<26:25,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 505: train loss 4.67723. lr 5.885133e-04:  18%|█▊        | 505/2863 [06:06<26:25,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 505: train loss 4.67723. lr 5.885133e-04:  18%|█▊        | 506/2863 [06:06<26:24,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 506: train loss 4.66064. lr 5.884681e-04:  18%|█▊        | 506/2863 [06:07<26:24,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 506: train loss 4.66064. lr 5.884681e-04:  18%|█▊        | 507/2863 [06:07<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 507: train loss 4.70658. lr 5.884229e-04:  18%|█▊        | 507/2863 [06:07<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 507: train loss 4.70658. lr 5.884229e-04:  18%|█▊        | 508/2863 [06:07<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 508: train loss 4.65301. lr 5.883775e-04:  18%|█▊        | 508/2863 [06:08<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 508: train loss 4.65301. lr 5.883775e-04:  18%|█▊        | 509/2863 [06:08<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 509: train loss 4.64787. lr 5.883321e-04:  18%|█▊        | 509/2863 [06:09<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 509: train loss 4.64787. lr 5.883321e-04:  18%|█▊        | 510/2863 [06:09<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 510: train loss 4.63425. lr 5.882866e-04:  18%|█▊        | 510/2863 [06:09<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 510: train loss 4.63425. lr 5.882866e-04:  18%|█▊        | 511/2863 [06:09<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 511: train loss 4.59325. lr 5.882410e-04:  18%|█▊        | 511/2863 [06:10<26:23,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 511: train loss 4.59325. lr 5.882410e-04:  18%|█▊        | 512/2863 [06:10<26:22,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 512: train loss 4.58579. lr 5.881953e-04:  18%|█▊        | 512/2863 [06:11<26:22,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 512: train loss 4.58579. lr 5.881953e-04:  18%|█▊        | 513/2863 [06:11<26:21,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 513: train loss 4.65306. lr 5.881495e-04:  18%|█▊        | 513/2863 [06:11<26:21,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 513: train loss 4.65306. lr 5.881495e-04:  18%|█▊        | 514/2863 [06:11<26:21,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 514: train loss 4.55816. lr 5.881037e-04:  18%|█▊        | 514/2863 [06:12<26:21,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 514: train loss 4.55816. lr 5.881037e-04:  18%|█▊        | 515/2863 [06:12<26:19,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 515: train loss 4.57342. lr 5.880577e-04:  18%|█▊        | 515/2863 [06:13<26:19,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 515: train loss 4.57342. lr 5.880577e-04:  18%|█▊        | 516/2863 [06:13<26:19,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 516: train loss 4.56687. lr 5.880117e-04:  18%|█▊        | 516/2863 [06:13<26:19,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 516: train loss 4.56687. lr 5.880117e-04:  18%|█▊        | 517/2863 [06:13<26:21,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 517: train loss 4.57173. lr 5.879656e-04:  18%|█▊        | 517/2863 [06:14<26:21,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 517: train loss 4.57173. lr 5.879656e-04:  18%|█▊        | 518/2863 [06:14<28:08,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 518: train loss 4.50588. lr 5.879193e-04:  18%|█▊        | 518/2863 [06:15<28:08,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 518: train loss 4.50588. lr 5.879193e-04:  18%|█▊        | 519/2863 [06:15<27:36,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 519: train loss 4.54434. lr 5.878730e-04:  18%|█▊        | 519/2863 [06:16<27:36,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 519: train loss 4.54434. lr 5.878730e-04:  18%|█▊        | 520/2863 [06:16<27:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 520: train loss 4.52772. lr 5.878267e-04:  18%|█▊        | 520/2863 [06:16<27:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 520: train loss 4.52772. lr 5.878267e-04:  18%|█▊        | 521/2863 [06:16<26:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 521: train loss 4.48012. lr 5.877802e-04:  18%|█▊        | 521/2863 [06:17<26:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 521: train loss 4.48012. lr 5.877802e-04:  18%|█▊        | 522/2863 [06:17<26:42,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 522: train loss 4.52574. lr 5.877336e-04:  18%|█▊        | 522/2863 [06:18<26:42,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 522: train loss 4.52574. lr 5.877336e-04:  18%|█▊        | 523/2863 [06:18<26:34,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 523: train loss 4.53253. lr 5.876870e-04:  18%|█▊        | 523/2863 [06:18<26:34,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 523: train loss 4.53253. lr 5.876870e-04:  18%|█▊        | 524/2863 [06:18<26:27,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 524: train loss 4.55743. lr 5.876403e-04:  18%|█▊        | 524/2863 [06:19<26:27,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 524: train loss 4.55743. lr 5.876403e-04:  18%|█▊        | 525/2863 [06:19<26:22,  1.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 525: train loss 4.56385. lr 5.875935e-04:  18%|█▊        | 525/2863 [06:20<26:22,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 525: train loss 4.56385. lr 5.875935e-04:  18%|█▊        | 526/2863 [06:20<26:21,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 526: train loss 4.50236. lr 5.875466e-04:  18%|█▊        | 526/2863 [06:20<26:21,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 526: train loss 4.50236. lr 5.875466e-04:  18%|█▊        | 527/2863 [06:20<26:17,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 527: train loss 4.49952. lr 5.874996e-04:  18%|█▊        | 527/2863 [06:21<26:17,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 527: train loss 4.49952. lr 5.874996e-04:  18%|█▊        | 528/2863 [06:21<26:15,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 528: train loss 4.56316. lr 5.874525e-04:  18%|█▊        | 528/2863 [06:22<26:15,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 528: train loss 4.56316. lr 5.874525e-04:  18%|█▊        | 529/2863 [06:22<26:14,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 529: train loss 4.51968. lr 5.874053e-04:  18%|█▊        | 529/2863 [06:22<26:14,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 529: train loss 4.51968. lr 5.874053e-04:  19%|█▊        | 530/2863 [06:22<26:13,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 530: train loss 4.53318. lr 5.873581e-04:  19%|█▊        | 530/2863 [06:23<26:13,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 530: train loss 4.53318. lr 5.873581e-04:  19%|█▊        | 531/2863 [06:23<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 531: train loss 4.45985. lr 5.873107e-04:  19%|█▊        | 531/2863 [06:24<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 531: train loss 4.45985. lr 5.873107e-04:  19%|█▊        | 532/2863 [06:24<26:09,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 532: train loss 4.55187. lr 5.872633e-04:  19%|█▊        | 532/2863 [06:24<26:09,  1.49it/s]\u001b[A\n",
      "epoch 1 iter 532: train loss 4.55187. lr 5.872633e-04:  19%|█▊        | 533/2863 [06:24<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 533: train loss 4.50323. lr 5.872158e-04:  19%|█▊        | 533/2863 [06:25<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 533: train loss 4.50323. lr 5.872158e-04:  19%|█▊        | 534/2863 [06:25<26:08,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 534: train loss 4.50829. lr 5.871682e-04:  19%|█▊        | 534/2863 [06:26<26:08,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 534: train loss 4.50829. lr 5.871682e-04:  19%|█▊        | 535/2863 [06:26<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 535: train loss 4.53345. lr 5.871205e-04:  19%|█▊        | 535/2863 [06:26<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 535: train loss 4.53345. lr 5.871205e-04:  19%|█▊        | 536/2863 [06:26<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 536: train loss 4.48825. lr 5.870728e-04:  19%|█▊        | 536/2863 [06:27<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 536: train loss 4.48825. lr 5.870728e-04:  19%|█▉        | 537/2863 [06:27<26:08,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 537: train loss 4.46184. lr 5.870249e-04:  19%|█▉        | 537/2863 [06:28<26:08,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 537: train loss 4.46184. lr 5.870249e-04:  19%|█▉        | 538/2863 [06:28<26:07,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 538: train loss 4.46663. lr 5.869770e-04:  19%|█▉        | 538/2863 [06:28<26:07,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 538: train loss 4.46663. lr 5.869770e-04:  19%|█▉        | 539/2863 [06:28<26:09,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 539: train loss 4.45839. lr 5.869289e-04:  19%|█▉        | 539/2863 [06:29<26:09,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 539: train loss 4.45839. lr 5.869289e-04:  19%|█▉        | 540/2863 [06:29<26:09,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 540: train loss 4.45578. lr 5.868808e-04:  19%|█▉        | 540/2863 [06:30<26:09,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 540: train loss 4.45578. lr 5.868808e-04:  19%|█▉        | 541/2863 [06:30<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 541: train loss 4.47969. lr 5.868326e-04:  19%|█▉        | 541/2863 [06:30<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 541: train loss 4.47969. lr 5.868326e-04:  19%|█▉        | 542/2863 [06:30<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 542: train loss 4.41698. lr 5.867843e-04:  19%|█▉        | 542/2863 [06:31<26:10,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 542: train loss 4.41698. lr 5.867843e-04:  19%|█▉        | 543/2863 [06:31<26:12,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 543: train loss 4.44704. lr 5.867360e-04:  19%|█▉        | 543/2863 [06:32<26:12,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 543: train loss 4.44704. lr 5.867360e-04:  19%|█▉        | 544/2863 [06:32<26:08,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 544: train loss 4.45226. lr 5.866875e-04:  19%|█▉        | 544/2863 [06:33<26:08,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 544: train loss 4.45226. lr 5.866875e-04:  19%|█▉        | 545/2863 [06:33<26:11,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 545: train loss 4.37933. lr 5.866390e-04:  19%|█▉        | 545/2863 [06:33<26:11,  1.48it/s]\u001b[A\n",
      "epoch 1 iter 545: train loss 4.37933. lr 5.866390e-04:  19%|█▉        | 546/2863 [06:33<27:30,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 546: train loss 4.48487. lr 5.865903e-04:  19%|█▉        | 546/2863 [06:34<27:30,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 546: train loss 4.48487. lr 5.865903e-04:  19%|█▉        | 547/2863 [06:34<27:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 547: train loss 4.36808. lr 5.865416e-04:  19%|█▉        | 547/2863 [06:35<27:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 547: train loss 4.36808. lr 5.865416e-04:  19%|█▉        | 548/2863 [06:35<26:48,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 548: train loss 4.39080. lr 5.864928e-04:  19%|█▉        | 548/2863 [06:35<26:48,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 548: train loss 4.39080. lr 5.864928e-04:  19%|█▉        | 549/2863 [06:35<26:37,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 549: train loss 4.38502. lr 5.864439e-04:  19%|█▉        | 549/2863 [06:36<26:37,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 549: train loss 4.38502. lr 5.864439e-04:  19%|█▉        | 550/2863 [06:36<26:27,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 550: train loss 4.31045. lr 5.863949e-04:  19%|█▉        | 550/2863 [06:37<26:27,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 550: train loss 4.31045. lr 5.863949e-04:  19%|█▉        | 551/2863 [06:37<26:20,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 551: train loss 4.36570. lr 5.863459e-04:  19%|█▉        | 551/2863 [06:37<26:20,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 551: train loss 4.36570. lr 5.863459e-04:  19%|█▉        | 552/2863 [06:37<26:16,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 552: train loss 4.34485. lr 5.862967e-04:  19%|█▉        | 552/2863 [06:38<26:16,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 552: train loss 4.34485. lr 5.862967e-04:  19%|█▉        | 553/2863 [06:38<26:16,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 553: train loss 4.41683. lr 5.862475e-04:  19%|█▉        | 553/2863 [06:39<26:16,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 553: train loss 4.41683. lr 5.862475e-04:  19%|█▉        | 554/2863 [06:39<26:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 554: train loss 4.36704. lr 5.861982e-04:  19%|█▉        | 554/2863 [06:40<26:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 554: train loss 4.36704. lr 5.861982e-04:  19%|█▉        | 555/2863 [06:40<26:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 555: train loss 4.33521. lr 5.861488e-04:  19%|█▉        | 555/2863 [06:40<26:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 555: train loss 4.33521. lr 5.861488e-04:  19%|█▉        | 556/2863 [06:40<26:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 556: train loss 4.32773. lr 5.860993e-04:  19%|█▉        | 556/2863 [06:41<26:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 556: train loss 4.32773. lr 5.860993e-04:  19%|█▉        | 557/2863 [06:41<26:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 557: train loss 4.33202. lr 5.860497e-04:  19%|█▉        | 557/2863 [06:42<26:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 557: train loss 4.33202. lr 5.860497e-04:  19%|█▉        | 558/2863 [06:42<26:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 558: train loss 4.35203. lr 5.860000e-04:  19%|█▉        | 558/2863 [06:42<26:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 558: train loss 4.35203. lr 5.860000e-04:  20%|█▉        | 559/2863 [06:42<26:23,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 559: train loss 4.35837. lr 5.859503e-04:  20%|█▉        | 559/2863 [06:43<26:23,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 559: train loss 4.35837. lr 5.859503e-04:  20%|█▉        | 560/2863 [06:43<26:19,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 560: train loss 4.36947. lr 5.859004e-04:  20%|█▉        | 560/2863 [06:44<26:19,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 560: train loss 4.36947. lr 5.859004e-04:  20%|█▉        | 561/2863 [06:44<26:20,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 561: train loss 4.32184. lr 5.858505e-04:  20%|█▉        | 561/2863 [06:44<26:20,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 561: train loss 4.32184. lr 5.858505e-04:  20%|█▉        | 562/2863 [06:44<26:14,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 562: train loss 4.31588. lr 5.858005e-04:  20%|█▉        | 562/2863 [06:45<26:14,  1.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 562: train loss 4.31588. lr 5.858005e-04:  20%|█▉        | 563/2863 [06:45<26:13,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 563: train loss 4.31544. lr 5.857504e-04:  20%|█▉        | 563/2863 [06:46<26:13,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 563: train loss 4.31544. lr 5.857504e-04:  20%|█▉        | 564/2863 [06:46<26:13,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 564: train loss 4.30887. lr 5.857002e-04:  20%|█▉        | 564/2863 [06:46<26:13,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 564: train loss 4.30887. lr 5.857002e-04:  20%|█▉        | 565/2863 [06:46<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 565: train loss 4.32631. lr 5.856499e-04:  20%|█▉        | 565/2863 [06:47<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 565: train loss 4.32631. lr 5.856499e-04:  20%|█▉        | 566/2863 [06:47<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 566: train loss 4.26401. lr 5.855996e-04:  20%|█▉        | 566/2863 [06:48<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 566: train loss 4.26401. lr 5.855996e-04:  20%|█▉        | 567/2863 [06:48<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 567: train loss 4.28513. lr 5.855491e-04:  20%|█▉        | 567/2863 [06:48<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 567: train loss 4.28513. lr 5.855491e-04:  20%|█▉        | 568/2863 [06:48<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 568: train loss 4.29171. lr 5.854986e-04:  20%|█▉        | 568/2863 [06:49<26:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 568: train loss 4.29171. lr 5.854986e-04:  20%|█▉        | 569/2863 [06:49<26:08,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 569: train loss 4.29063. lr 5.854480e-04:  20%|█▉        | 569/2863 [06:50<26:08,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 569: train loss 4.29063. lr 5.854480e-04:  20%|█▉        | 570/2863 [06:50<26:05,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 570: train loss 4.25914. lr 5.853973e-04:  20%|█▉        | 570/2863 [06:50<26:05,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 570: train loss 4.25914. lr 5.853973e-04:  20%|█▉        | 571/2863 [06:50<26:02,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 571: train loss 4.24124. lr 5.853465e-04:  20%|█▉        | 571/2863 [06:51<26:02,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 571: train loss 4.24124. lr 5.853465e-04:  20%|█▉        | 572/2863 [06:51<26:04,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 572: train loss 4.26043. lr 5.852956e-04:  20%|█▉        | 572/2863 [06:52<26:04,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 572: train loss 4.26043. lr 5.852956e-04:  20%|██        | 573/2863 [06:52<26:03,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 573: train loss 4.29842. lr 5.852447e-04:  20%|██        | 573/2863 [06:53<26:03,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 573: train loss 4.29842. lr 5.852447e-04:  20%|██        | 574/2863 [06:53<27:22,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 574: train loss 4.23060. lr 5.851936e-04:  20%|██        | 574/2863 [06:53<27:22,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 574: train loss 4.23060. lr 5.851936e-04:  20%|██        | 575/2863 [06:53<26:57,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 575: train loss 4.20271. lr 5.851425e-04:  20%|██        | 575/2863 [06:54<26:57,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 575: train loss 4.20271. lr 5.851425e-04:  20%|██        | 576/2863 [06:54<26:40,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 576: train loss 4.24236. lr 5.850913e-04:  20%|██        | 576/2863 [06:55<26:40,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 576: train loss 4.24236. lr 5.850913e-04:  20%|██        | 577/2863 [06:55<26:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 577: train loss 4.24537. lr 5.850400e-04:  20%|██        | 577/2863 [06:55<26:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 577: train loss 4.24537. lr 5.850400e-04:  20%|██        | 578/2863 [06:55<26:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 578: train loss 4.27526. lr 5.849886e-04:  20%|██        | 578/2863 [06:56<26:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 578: train loss 4.27526. lr 5.849886e-04:  20%|██        | 579/2863 [06:56<26:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 579: train loss 4.25479. lr 5.849371e-04:  20%|██        | 579/2863 [06:57<26:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 579: train loss 4.25479. lr 5.849371e-04:  20%|██        | 580/2863 [06:57<26:14,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 580: train loss 4.20443. lr 5.848856e-04:  20%|██        | 580/2863 [06:57<26:14,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 580: train loss 4.20443. lr 5.848856e-04:  20%|██        | 581/2863 [06:57<26:09,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 581: train loss 4.26617. lr 5.848339e-04:  20%|██        | 581/2863 [06:58<26:09,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 581: train loss 4.26617. lr 5.848339e-04:  20%|██        | 582/2863 [06:58<26:07,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 582: train loss 4.14944. lr 5.847822e-04:  20%|██        | 582/2863 [06:59<26:07,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 582: train loss 4.14944. lr 5.847822e-04:  20%|██        | 583/2863 [06:59<26:05,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 583: train loss 4.17673. lr 5.847304e-04:  20%|██        | 583/2863 [06:59<26:05,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 583: train loss 4.17673. lr 5.847304e-04:  20%|██        | 584/2863 [06:59<26:00,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 584: train loss 4.19955. lr 5.846785e-04:  20%|██        | 584/2863 [07:00<26:00,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 584: train loss 4.19955. lr 5.846785e-04:  20%|██        | 585/2863 [07:00<25:58,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 585: train loss 4.13359. lr 5.846265e-04:  20%|██        | 585/2863 [07:01<25:58,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 585: train loss 4.13359. lr 5.846265e-04:  20%|██        | 586/2863 [07:01<25:54,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 586: train loss 4.15739. lr 5.845744e-04:  20%|██        | 586/2863 [07:02<25:54,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 586: train loss 4.15739. lr 5.845744e-04:  21%|██        | 587/2863 [07:02<25:55,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 587: train loss 4.13643. lr 5.845223e-04:  21%|██        | 587/2863 [07:02<25:55,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 587: train loss 4.13643. lr 5.845223e-04:  21%|██        | 588/2863 [07:02<25:55,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 588: train loss 4.21285. lr 5.844700e-04:  21%|██        | 588/2863 [07:03<25:55,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 588: train loss 4.21285. lr 5.844700e-04:  21%|██        | 589/2863 [07:03<25:54,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 589: train loss 4.18341. lr 5.844177e-04:  21%|██        | 589/2863 [07:04<25:54,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 589: train loss 4.18341. lr 5.844177e-04:  21%|██        | 590/2863 [07:04<25:50,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 590: train loss 4.14880. lr 5.843653e-04:  21%|██        | 590/2863 [07:04<25:50,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 590: train loss 4.14880. lr 5.843653e-04:  21%|██        | 591/2863 [07:04<25:52,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 591: train loss 4.10673. lr 5.843128e-04:  21%|██        | 591/2863 [07:05<25:52,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 591: train loss 4.10673. lr 5.843128e-04:  21%|██        | 592/2863 [07:05<25:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 592: train loss 4.17348. lr 5.842602e-04:  21%|██        | 592/2863 [07:06<25:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 592: train loss 4.17348. lr 5.842602e-04:  21%|██        | 593/2863 [07:06<25:51,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 593: train loss 4.13773. lr 5.842075e-04:  21%|██        | 593/2863 [07:06<25:51,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 593: train loss 4.13773. lr 5.842075e-04:  21%|██        | 594/2863 [07:06<25:54,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 594: train loss 4.19425. lr 5.841548e-04:  21%|██        | 594/2863 [07:07<25:54,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 594: train loss 4.19425. lr 5.841548e-04:  21%|██        | 595/2863 [07:07<25:53,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 595: train loss 4.12074. lr 5.841019e-04:  21%|██        | 595/2863 [07:08<25:53,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 595: train loss 4.12074. lr 5.841019e-04:  21%|██        | 596/2863 [07:08<25:52,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 596: train loss 4.13372. lr 5.840490e-04:  21%|██        | 596/2863 [07:08<25:52,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 596: train loss 4.13372. lr 5.840490e-04:  21%|██        | 597/2863 [07:08<25:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 597: train loss 4.09166. lr 5.839960e-04:  21%|██        | 597/2863 [07:09<25:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 597: train loss 4.09166. lr 5.839960e-04:  21%|██        | 598/2863 [07:09<25:48,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 598: train loss 4.12677. lr 5.839429e-04:  21%|██        | 598/2863 [07:10<25:48,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 598: train loss 4.12677. lr 5.839429e-04:  21%|██        | 599/2863 [07:10<25:47,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 599: train loss 4.07965. lr 5.838897e-04:  21%|██        | 599/2863 [07:10<25:47,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 599: train loss 4.07965. lr 5.838897e-04:  21%|██        | 600/2863 [07:10<25:45,  1.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 600: train loss 4.16497. lr 5.838364e-04:  21%|██        | 600/2863 [07:11<25:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 600: train loss 4.16497. lr 5.838364e-04:  21%|██        | 601/2863 [07:11<25:43,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 601: train loss 4.09710. lr 5.837830e-04:  21%|██        | 601/2863 [07:12<25:43,  1.47it/s]\u001b[A\n",
      "epoch 1 iter 601: train loss 4.09710. lr 5.837830e-04:  21%|██        | 602/2863 [07:12<27:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 602: train loss 4.03142. lr 5.837296e-04:  21%|██        | 602/2863 [07:13<27:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 602: train loss 4.03142. lr 5.837296e-04:  21%|██        | 603/2863 [07:13<26:42,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 603: train loss 4.10220. lr 5.836761e-04:  21%|██        | 603/2863 [07:13<26:42,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 603: train loss 4.10220. lr 5.836761e-04:  21%|██        | 604/2863 [07:13<26:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 604: train loss 4.08735. lr 5.836225e-04:  21%|██        | 604/2863 [07:14<26:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 604: train loss 4.08735. lr 5.836225e-04:  21%|██        | 605/2863 [07:14<26:16,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 605: train loss 4.05796. lr 5.835688e-04:  21%|██        | 605/2863 [07:15<26:16,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 605: train loss 4.05796. lr 5.835688e-04:  21%|██        | 606/2863 [07:15<26:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 606: train loss 4.05003. lr 5.835150e-04:  21%|██        | 606/2863 [07:15<26:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 606: train loss 4.05003. lr 5.835150e-04:  21%|██        | 607/2863 [07:15<25:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 607: train loss 4.05812. lr 5.834611e-04:  21%|██        | 607/2863 [07:16<25:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 607: train loss 4.05812. lr 5.834611e-04:  21%|██        | 608/2863 [07:16<25:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 608: train loss 4.03368. lr 5.834072e-04:  21%|██        | 608/2863 [07:17<25:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 608: train loss 4.03368. lr 5.834072e-04:  21%|██▏       | 609/2863 [07:17<25:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 609: train loss 4.03301. lr 5.833531e-04:  21%|██▏       | 609/2863 [07:17<25:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 609: train loss 4.03301. lr 5.833531e-04:  21%|██▏       | 610/2863 [07:17<25:43,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 610: train loss 4.05398. lr 5.832990e-04:  21%|██▏       | 610/2863 [07:18<25:43,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 610: train loss 4.05398. lr 5.832990e-04:  21%|██▏       | 611/2863 [07:18<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 611: train loss 4.08977. lr 5.832448e-04:  21%|██▏       | 611/2863 [07:19<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 611: train loss 4.08977. lr 5.832448e-04:  21%|██▏       | 612/2863 [07:19<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 612: train loss 3.97815. lr 5.831905e-04:  21%|██▏       | 612/2863 [07:19<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 612: train loss 3.97815. lr 5.831905e-04:  21%|██▏       | 613/2863 [07:19<25:43,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 613: train loss 4.02580. lr 5.831361e-04:  21%|██▏       | 613/2863 [07:20<25:43,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 613: train loss 4.02580. lr 5.831361e-04:  21%|██▏       | 614/2863 [07:20<25:43,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 614: train loss 4.02302. lr 5.830816e-04:  21%|██▏       | 614/2863 [07:21<25:43,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 614: train loss 4.02302. lr 5.830816e-04:  21%|██▏       | 615/2863 [07:21<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 615: train loss 4.02208. lr 5.830271e-04:  21%|██▏       | 615/2863 [07:21<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 615: train loss 4.02208. lr 5.830271e-04:  22%|██▏       | 616/2863 [07:21<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 616: train loss 4.04867. lr 5.829724e-04:  22%|██▏       | 616/2863 [07:22<25:41,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 616: train loss 4.04867. lr 5.829724e-04:  22%|██▏       | 617/2863 [07:22<25:37,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 617: train loss 3.96906. lr 5.829177e-04:  22%|██▏       | 617/2863 [07:23<25:37,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 617: train loss 3.96906. lr 5.829177e-04:  22%|██▏       | 618/2863 [07:23<25:37,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 618: train loss 4.03478. lr 5.828629e-04:  22%|██▏       | 618/2863 [07:24<25:37,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 618: train loss 4.03478. lr 5.828629e-04:  22%|██▏       | 619/2863 [07:24<25:42,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 619: train loss 3.94738. lr 5.828080e-04:  22%|██▏       | 619/2863 [07:24<25:42,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 619: train loss 3.94738. lr 5.828080e-04:  22%|██▏       | 620/2863 [07:24<25:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 620: train loss 3.98589. lr 5.827530e-04:  22%|██▏       | 620/2863 [07:25<25:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 620: train loss 3.98589. lr 5.827530e-04:  22%|██▏       | 621/2863 [07:25<25:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 621: train loss 3.95717. lr 5.826980e-04:  22%|██▏       | 621/2863 [07:26<25:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 621: train loss 3.95717. lr 5.826980e-04:  22%|██▏       | 622/2863 [07:26<25:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 622: train loss 3.97468. lr 5.826428e-04:  22%|██▏       | 622/2863 [07:26<25:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 622: train loss 3.97468. lr 5.826428e-04:  22%|██▏       | 623/2863 [07:26<25:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 623: train loss 3.99054. lr 5.825876e-04:  22%|██▏       | 623/2863 [07:27<25:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 623: train loss 3.99054. lr 5.825876e-04:  22%|██▏       | 624/2863 [07:27<25:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 624: train loss 3.98773. lr 5.825323e-04:  22%|██▏       | 624/2863 [07:28<25:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 624: train loss 3.98773. lr 5.825323e-04:  22%|██▏       | 625/2863 [07:28<25:38,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 625: train loss 3.97325. lr 5.824769e-04:  22%|██▏       | 625/2863 [07:28<25:38,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 625: train loss 3.97325. lr 5.824769e-04:  22%|██▏       | 626/2863 [07:28<25:34,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 626: train loss 3.97260. lr 5.824214e-04:  22%|██▏       | 626/2863 [07:29<25:34,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 626: train loss 3.97260. lr 5.824214e-04:  22%|██▏       | 627/2863 [07:29<25:28,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 627: train loss 3.92624. lr 5.823658e-04:  22%|██▏       | 627/2863 [07:30<25:28,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 627: train loss 3.92624. lr 5.823658e-04:  22%|██▏       | 628/2863 [07:30<25:26,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 628: train loss 3.97277. lr 5.823101e-04:  22%|██▏       | 628/2863 [07:30<25:26,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 628: train loss 3.97277. lr 5.823101e-04:  22%|██▏       | 629/2863 [07:30<25:25,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 629: train loss 3.89730. lr 5.822544e-04:  22%|██▏       | 629/2863 [07:31<25:25,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 629: train loss 3.89730. lr 5.822544e-04:  22%|██▏       | 630/2863 [07:31<27:08,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 630: train loss 3.93932. lr 5.821986e-04:  22%|██▏       | 630/2863 [07:32<27:08,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 630: train loss 3.93932. lr 5.821986e-04:  22%|██▏       | 631/2863 [07:32<26:46,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 631: train loss 3.89472. lr 5.821427e-04:  22%|██▏       | 631/2863 [07:33<26:46,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 631: train loss 3.89472. lr 5.821427e-04:  22%|██▏       | 632/2863 [07:33<26:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 632: train loss 3.91808. lr 5.820867e-04:  22%|██▏       | 632/2863 [07:33<26:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 632: train loss 3.91808. lr 5.820867e-04:  22%|██▏       | 633/2863 [07:33<26:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 633: train loss 3.96714. lr 5.820306e-04:  22%|██▏       | 633/2863 [07:34<26:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 633: train loss 3.96714. lr 5.820306e-04:  22%|██▏       | 634/2863 [07:34<26:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 634: train loss 3.97759. lr 5.819744e-04:  22%|██▏       | 634/2863 [07:35<26:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 634: train loss 3.97759. lr 5.819744e-04:  22%|██▏       | 635/2863 [07:35<26:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 635: train loss 3.94944. lr 5.819181e-04:  22%|██▏       | 635/2863 [07:35<26:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 635: train loss 3.94944. lr 5.819181e-04:  22%|██▏       | 636/2863 [07:35<26:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 636: train loss 3.89497. lr 5.818618e-04:  22%|██▏       | 636/2863 [07:36<26:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 636: train loss 3.89497. lr 5.818618e-04:  22%|██▏       | 637/2863 [07:36<26:12,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 637: train loss 3.88535. lr 5.818054e-04:  22%|██▏       | 637/2863 [07:37<26:12,  1.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 637: train loss 3.88535. lr 5.818054e-04:  22%|██▏       | 638/2863 [07:37<26:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 638: train loss 3.88620. lr 5.817489e-04:  22%|██▏       | 638/2863 [07:38<26:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 638: train loss 3.88620. lr 5.817489e-04:  22%|██▏       | 639/2863 [07:38<26:08,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 639: train loss 3.85816. lr 5.816923e-04:  22%|██▏       | 639/2863 [07:38<26:08,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 639: train loss 3.85816. lr 5.816923e-04:  22%|██▏       | 640/2863 [07:38<26:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 640: train loss 3.86717. lr 5.816356e-04:  22%|██▏       | 640/2863 [07:39<26:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 640: train loss 3.86717. lr 5.816356e-04:  22%|██▏       | 641/2863 [07:39<25:53,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 641: train loss 3.88137. lr 5.815788e-04:  22%|██▏       | 641/2863 [07:40<25:53,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 641: train loss 3.88137. lr 5.815788e-04:  22%|██▏       | 642/2863 [07:40<25:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 642: train loss 3.88276. lr 5.815220e-04:  22%|██▏       | 642/2863 [07:40<25:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 642: train loss 3.88276. lr 5.815220e-04:  22%|██▏       | 643/2863 [07:40<25:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 643: train loss 3.87287. lr 5.814651e-04:  22%|██▏       | 643/2863 [07:41<25:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 643: train loss 3.87287. lr 5.814651e-04:  22%|██▏       | 644/2863 [07:41<25:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 644: train loss 3.87133. lr 5.814080e-04:  22%|██▏       | 644/2863 [07:42<25:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 644: train loss 3.87133. lr 5.814080e-04:  23%|██▎       | 645/2863 [07:42<25:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 645: train loss 3.88048. lr 5.813509e-04:  23%|██▎       | 645/2863 [07:42<25:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 645: train loss 3.88048. lr 5.813509e-04:  23%|██▎       | 646/2863 [07:42<25:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 646: train loss 3.87095. lr 5.812937e-04:  23%|██▎       | 646/2863 [07:43<25:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 646: train loss 3.87095. lr 5.812937e-04:  23%|██▎       | 647/2863 [07:43<25:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 647: train loss 3.76317. lr 5.812365e-04:  23%|██▎       | 647/2863 [07:44<25:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 647: train loss 3.76317. lr 5.812365e-04:  23%|██▎       | 648/2863 [07:44<25:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 648: train loss 3.83504. lr 5.811791e-04:  23%|██▎       | 648/2863 [07:44<25:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 648: train loss 3.83504. lr 5.811791e-04:  23%|██▎       | 649/2863 [07:44<25:29,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 649: train loss 3.78752. lr 5.811217e-04:  23%|██▎       | 649/2863 [07:45<25:29,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 649: train loss 3.78752. lr 5.811217e-04:  23%|██▎       | 650/2863 [07:45<25:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 650: train loss 3.80456. lr 5.810642e-04:  23%|██▎       | 650/2863 [07:46<25:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 650: train loss 3.80456. lr 5.810642e-04:  23%|██▎       | 651/2863 [07:46<25:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 651: train loss 3.80880. lr 5.810065e-04:  23%|██▎       | 651/2863 [07:47<25:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 651: train loss 3.80880. lr 5.810065e-04:  23%|██▎       | 652/2863 [07:47<25:21,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 652: train loss 3.84638. lr 5.809488e-04:  23%|██▎       | 652/2863 [07:47<25:21,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 652: train loss 3.84638. lr 5.809488e-04:  23%|██▎       | 653/2863 [07:47<25:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 653: train loss 3.77149. lr 5.808911e-04:  23%|██▎       | 653/2863 [07:48<25:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 653: train loss 3.77149. lr 5.808911e-04:  23%|██▎       | 654/2863 [07:48<25:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 654: train loss 3.80294. lr 5.808332e-04:  23%|██▎       | 654/2863 [07:49<25:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 654: train loss 3.80294. lr 5.808332e-04:  23%|██▎       | 655/2863 [07:49<25:12,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 655: train loss 3.77320. lr 5.807753e-04:  23%|██▎       | 655/2863 [07:49<25:12,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 655: train loss 3.77320. lr 5.807753e-04:  23%|██▎       | 656/2863 [07:49<25:12,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 656: train loss 3.71483. lr 5.807172e-04:  23%|██▎       | 656/2863 [07:50<25:12,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 656: train loss 3.71483. lr 5.807172e-04:  23%|██▎       | 657/2863 [07:50<25:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 657: train loss 3.75844. lr 5.806591e-04:  23%|██▎       | 657/2863 [07:51<25:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 657: train loss 3.75844. lr 5.806591e-04:  23%|██▎       | 658/2863 [07:51<26:45,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 658: train loss 3.79241. lr 5.806009e-04:  23%|██▎       | 658/2863 [07:51<26:45,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 658: train loss 3.79241. lr 5.806009e-04:  23%|██▎       | 659/2863 [07:51<26:31,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 659: train loss 3.72573. lr 5.805426e-04:  23%|██▎       | 659/2863 [07:52<26:31,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 659: train loss 3.72573. lr 5.805426e-04:  23%|██▎       | 660/2863 [07:52<26:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 660: train loss 3.76986. lr 5.804842e-04:  23%|██▎       | 660/2863 [07:53<26:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 660: train loss 3.76986. lr 5.804842e-04:  23%|██▎       | 661/2863 [07:53<26:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 661: train loss 3.81902. lr 5.804258e-04:  23%|██▎       | 661/2863 [07:54<26:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 661: train loss 3.81902. lr 5.804258e-04:  23%|██▎       | 662/2863 [07:54<26:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 662: train loss 3.86890. lr 5.803672e-04:  23%|██▎       | 662/2863 [07:54<26:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 662: train loss 3.86890. lr 5.803672e-04:  23%|██▎       | 663/2863 [07:54<25:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 663: train loss 3.75934. lr 5.803086e-04:  23%|██▎       | 663/2863 [07:55<25:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 663: train loss 3.75934. lr 5.803086e-04:  23%|██▎       | 664/2863 [07:55<25:44,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 664: train loss 3.72289. lr 5.802499e-04:  23%|██▎       | 664/2863 [07:56<25:44,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 664: train loss 3.72289. lr 5.802499e-04:  23%|██▎       | 665/2863 [07:56<25:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 665: train loss 3.73449. lr 5.801911e-04:  23%|██▎       | 665/2863 [07:56<25:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 665: train loss 3.73449. lr 5.801911e-04:  23%|██▎       | 666/2863 [07:56<25:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 666: train loss 3.67530. lr 5.801322e-04:  23%|██▎       | 666/2863 [07:57<25:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 666: train loss 3.67530. lr 5.801322e-04:  23%|██▎       | 667/2863 [07:57<25:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 667: train loss 3.75240. lr 5.800733e-04:  23%|██▎       | 667/2863 [07:58<25:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 667: train loss 3.75240. lr 5.800733e-04:  23%|██▎       | 668/2863 [07:58<25:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 668: train loss 3.72788. lr 5.800142e-04:  23%|██▎       | 668/2863 [07:58<25:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 668: train loss 3.72788. lr 5.800142e-04:  23%|██▎       | 669/2863 [07:58<25:36,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 669: train loss 3.70938. lr 5.799551e-04:  23%|██▎       | 669/2863 [07:59<25:36,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 669: train loss 3.70938. lr 5.799551e-04:  23%|██▎       | 670/2863 [07:59<25:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 670: train loss 3.75258. lr 5.798959e-04:  23%|██▎       | 670/2863 [08:00<25:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 670: train loss 3.75258. lr 5.798959e-04:  23%|██▎       | 671/2863 [08:00<25:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 671: train loss 3.68811. lr 5.798366e-04:  23%|██▎       | 671/2863 [08:01<25:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 671: train loss 3.68811. lr 5.798366e-04:  23%|██▎       | 672/2863 [08:01<25:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 672: train loss 3.71653. lr 5.797772e-04:  23%|██▎       | 672/2863 [08:01<25:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 672: train loss 3.71653. lr 5.797772e-04:  24%|██▎       | 673/2863 [08:01<25:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 673: train loss 3.68155. lr 5.797177e-04:  24%|██▎       | 673/2863 [08:02<25:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 673: train loss 3.68155. lr 5.797177e-04:  24%|██▎       | 674/2863 [08:02<25:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 674: train loss 3.65736. lr 5.796582e-04:  24%|██▎       | 674/2863 [08:03<25:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 674: train loss 3.65736. lr 5.796582e-04:  24%|██▎       | 675/2863 [08:03<25:34,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 675: train loss 3.66609. lr 5.795985e-04:  24%|██▎       | 675/2863 [08:03<25:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 675: train loss 3.66609. lr 5.795985e-04:  24%|██▎       | 676/2863 [08:03<26:53,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 676: train loss 3.68601. lr 5.795388e-04:  24%|██▎       | 676/2863 [08:04<26:53,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 676: train loss 3.68601. lr 5.795388e-04:  24%|██▎       | 677/2863 [08:04<27:11,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 677: train loss 3.68198. lr 5.794790e-04:  24%|██▎       | 677/2863 [08:05<27:11,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 677: train loss 3.68198. lr 5.794790e-04:  24%|██▎       | 678/2863 [08:05<26:45,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 678: train loss 3.65761. lr 5.794191e-04:  24%|██▎       | 678/2863 [08:06<26:45,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 678: train loss 3.65761. lr 5.794191e-04:  24%|██▎       | 679/2863 [08:06<26:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 679: train loss 3.66877. lr 5.793591e-04:  24%|██▎       | 679/2863 [08:06<26:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 679: train loss 3.66877. lr 5.793591e-04:  24%|██▍       | 680/2863 [08:06<25:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 680: train loss 3.69951. lr 5.792991e-04:  24%|██▍       | 680/2863 [08:07<25:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 680: train loss 3.69951. lr 5.792991e-04:  24%|██▍       | 681/2863 [08:07<25:31,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 681: train loss 3.65634. lr 5.792389e-04:  24%|██▍       | 681/2863 [08:08<25:31,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 681: train loss 3.65634. lr 5.792389e-04:  24%|██▍       | 682/2863 [08:08<25:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 682: train loss 3.69917. lr 5.791787e-04:  24%|██▍       | 682/2863 [08:08<25:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 682: train loss 3.69917. lr 5.791787e-04:  24%|██▍       | 683/2863 [08:08<25:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 683: train loss 3.63578. lr 5.791184e-04:  24%|██▍       | 683/2863 [08:09<25:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 683: train loss 3.63578. lr 5.791184e-04:  24%|██▍       | 684/2863 [08:09<25:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 684: train loss 3.60124. lr 5.790580e-04:  24%|██▍       | 684/2863 [08:10<25:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 684: train loss 3.60124. lr 5.790580e-04:  24%|██▍       | 685/2863 [08:10<25:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 685: train loss 3.63933. lr 5.789975e-04:  24%|██▍       | 685/2863 [08:11<25:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 685: train loss 3.63933. lr 5.789975e-04:  24%|██▍       | 686/2863 [08:11<26:26,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 686: train loss 3.62211. lr 5.789370e-04:  24%|██▍       | 686/2863 [08:11<26:26,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 686: train loss 3.62211. lr 5.789370e-04:  24%|██▍       | 687/2863 [08:11<26:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 687: train loss 3.60250. lr 5.788763e-04:  24%|██▍       | 687/2863 [08:12<26:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 687: train loss 3.60250. lr 5.788763e-04:  24%|██▍       | 688/2863 [08:12<25:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 688: train loss 3.58802. lr 5.788156e-04:  24%|██▍       | 688/2863 [08:13<25:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 688: train loss 3.58802. lr 5.788156e-04:  24%|██▍       | 689/2863 [08:13<25:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 689: train loss 3.60318. lr 5.787548e-04:  24%|██▍       | 689/2863 [08:13<25:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 689: train loss 3.60318. lr 5.787548e-04:  24%|██▍       | 690/2863 [08:13<25:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 690: train loss 3.60984. lr 5.786939e-04:  24%|██▍       | 690/2863 [08:14<25:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 690: train loss 3.60984. lr 5.786939e-04:  24%|██▍       | 691/2863 [08:14<25:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 691: train loss 3.59165. lr 5.786329e-04:  24%|██▍       | 691/2863 [08:15<25:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 691: train loss 3.59165. lr 5.786329e-04:  24%|██▍       | 692/2863 [08:15<25:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 692: train loss 3.61640. lr 5.785718e-04:  24%|██▍       | 692/2863 [08:15<25:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 692: train loss 3.61640. lr 5.785718e-04:  24%|██▍       | 693/2863 [08:15<25:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 693: train loss 3.54845. lr 5.785107e-04:  24%|██▍       | 693/2863 [08:16<25:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 693: train loss 3.54845. lr 5.785107e-04:  24%|██▍       | 694/2863 [08:16<25:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 694: train loss 3.55224. lr 5.784494e-04:  24%|██▍       | 694/2863 [08:17<25:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 694: train loss 3.55224. lr 5.784494e-04:  24%|██▍       | 695/2863 [08:17<26:37,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 695: train loss 3.47023. lr 5.783881e-04:  24%|██▍       | 695/2863 [08:18<26:37,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 695: train loss 3.47023. lr 5.783881e-04:  24%|██▍       | 696/2863 [08:18<27:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 696: train loss 3.53503. lr 5.783267e-04:  24%|██▍       | 696/2863 [08:19<27:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 696: train loss 3.53503. lr 5.783267e-04:  24%|██▍       | 697/2863 [08:19<27:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 697: train loss 3.55716. lr 5.782652e-04:  24%|██▍       | 697/2863 [08:19<27:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 697: train loss 3.55716. lr 5.782652e-04:  24%|██▍       | 698/2863 [08:19<27:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 698: train loss 3.57389. lr 5.782037e-04:  24%|██▍       | 698/2863 [08:20<27:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 698: train loss 3.57389. lr 5.782037e-04:  24%|██▍       | 699/2863 [08:20<26:56,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 699: train loss 3.56647. lr 5.781420e-04:  24%|██▍       | 699/2863 [08:21<26:56,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 699: train loss 3.56647. lr 5.781420e-04:  24%|██▍       | 700/2863 [08:21<26:28,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 700: train loss 3.53083. lr 5.780803e-04:  24%|██▍       | 700/2863 [08:21<26:28,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 700: train loss 3.53083. lr 5.780803e-04:  24%|██▍       | 701/2863 [08:21<25:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 701: train loss 3.49633. lr 5.780184e-04:  24%|██▍       | 701/2863 [08:22<25:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 701: train loss 3.49633. lr 5.780184e-04:  25%|██▍       | 702/2863 [08:22<25:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 702: train loss 3.52427. lr 5.779565e-04:  25%|██▍       | 702/2863 [08:23<25:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 702: train loss 3.52427. lr 5.779565e-04:  25%|██▍       | 703/2863 [08:23<25:29,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 703: train loss 3.49637. lr 5.778946e-04:  25%|██▍       | 703/2863 [08:23<25:29,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 703: train loss 3.49637. lr 5.778946e-04:  25%|██▍       | 704/2863 [08:24<25:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 704: train loss 3.53341. lr 5.778325e-04:  25%|██▍       | 704/2863 [08:24<25:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 704: train loss 3.53341. lr 5.778325e-04:  25%|██▍       | 705/2863 [08:24<25:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 705: train loss 3.47198. lr 5.777703e-04:  25%|██▍       | 705/2863 [08:25<25:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 705: train loss 3.47198. lr 5.777703e-04:  25%|██▍       | 706/2863 [08:25<25:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 706: train loss 3.49709. lr 5.777081e-04:  25%|██▍       | 706/2863 [08:26<25:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 706: train loss 3.49709. lr 5.777081e-04:  25%|██▍       | 707/2863 [08:26<24:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 707: train loss 3.47345. lr 5.776458e-04:  25%|██▍       | 707/2863 [08:26<24:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 707: train loss 3.47345. lr 5.776458e-04:  25%|██▍       | 708/2863 [08:26<24:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 708: train loss 3.51118. lr 5.775834e-04:  25%|██▍       | 708/2863 [08:27<24:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 708: train loss 3.51118. lr 5.775834e-04:  25%|██▍       | 709/2863 [08:27<24:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 709: train loss 3.52675. lr 5.775209e-04:  25%|██▍       | 709/2863 [08:28<24:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 709: train loss 3.52675. lr 5.775209e-04:  25%|██▍       | 710/2863 [08:28<24:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 710: train loss 3.45536. lr 5.774583e-04:  25%|██▍       | 710/2863 [08:28<24:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 710: train loss 3.45536. lr 5.774583e-04:  25%|██▍       | 711/2863 [08:28<24:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 711: train loss 3.53891. lr 5.773956e-04:  25%|██▍       | 711/2863 [08:29<24:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 711: train loss 3.53891. lr 5.773956e-04:  25%|██▍       | 712/2863 [08:29<24:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 712: train loss 3.46509. lr 5.773329e-04:  25%|██▍       | 712/2863 [08:30<24:42,  1.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 712: train loss 3.46509. lr 5.773329e-04:  25%|██▍       | 713/2863 [08:30<24:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 713: train loss 3.44614. lr 5.772701e-04:  25%|██▍       | 713/2863 [08:31<24:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 713: train loss 3.44614. lr 5.772701e-04:  25%|██▍       | 714/2863 [08:31<26:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 714: train loss 3.46853. lr 5.772072e-04:  25%|██▍       | 714/2863 [08:31<26:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 714: train loss 3.46853. lr 5.772072e-04:  25%|██▍       | 715/2863 [08:31<25:42,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 715: train loss 3.46720. lr 5.771442e-04:  25%|██▍       | 715/2863 [08:32<25:42,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 715: train loss 3.46720. lr 5.771442e-04:  25%|██▌       | 716/2863 [08:32<25:27,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 716: train loss 3.47367. lr 5.770811e-04:  25%|██▌       | 716/2863 [08:33<25:27,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 716: train loss 3.47367. lr 5.770811e-04:  25%|██▌       | 717/2863 [08:33<25:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 717: train loss 3.41839. lr 5.770179e-04:  25%|██▌       | 717/2863 [08:33<25:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 717: train loss 3.41839. lr 5.770179e-04:  25%|██▌       | 718/2863 [08:33<25:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 718: train loss 3.42432. lr 5.769547e-04:  25%|██▌       | 718/2863 [08:34<25:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 718: train loss 3.42432. lr 5.769547e-04:  25%|██▌       | 719/2863 [08:34<24:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 719: train loss 3.40662. lr 5.768914e-04:  25%|██▌       | 719/2863 [08:35<24:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 719: train loss 3.40662. lr 5.768914e-04:  25%|██▌       | 720/2863 [08:35<25:03,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 720: train loss 3.41701. lr 5.768280e-04:  25%|██▌       | 720/2863 [08:35<25:03,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 720: train loss 3.41701. lr 5.768280e-04:  25%|██▌       | 721/2863 [08:35<25:05,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 721: train loss 3.39570. lr 5.767645e-04:  25%|██▌       | 721/2863 [08:36<25:05,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 721: train loss 3.39570. lr 5.767645e-04:  25%|██▌       | 722/2863 [08:36<25:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 722: train loss 3.40740. lr 5.767009e-04:  25%|██▌       | 722/2863 [08:37<25:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 722: train loss 3.40740. lr 5.767009e-04:  25%|██▌       | 723/2863 [08:37<25:44,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 723: train loss 3.39287. lr 5.766372e-04:  25%|██▌       | 723/2863 [08:38<25:44,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 723: train loss 3.39287. lr 5.766372e-04:  25%|██▌       | 724/2863 [08:38<25:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 724: train loss 3.44933. lr 5.765735e-04:  25%|██▌       | 724/2863 [08:38<25:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 724: train loss 3.44933. lr 5.765735e-04:  25%|██▌       | 725/2863 [08:38<25:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 725: train loss 3.39598. lr 5.765097e-04:  25%|██▌       | 725/2863 [08:39<25:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 725: train loss 3.39598. lr 5.765097e-04:  25%|██▌       | 726/2863 [08:39<25:57,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 726: train loss 3.36943. lr 5.764458e-04:  25%|██▌       | 726/2863 [08:40<25:57,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 726: train loss 3.36943. lr 5.764458e-04:  25%|██▌       | 727/2863 [08:40<25:46,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 727: train loss 3.35436. lr 5.763818e-04:  25%|██▌       | 727/2863 [08:40<25:46,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 727: train loss 3.35436. lr 5.763818e-04:  25%|██▌       | 728/2863 [08:40<25:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 728: train loss 3.37524. lr 5.763177e-04:  25%|██▌       | 728/2863 [08:41<25:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 728: train loss 3.37524. lr 5.763177e-04:  25%|██▌       | 729/2863 [08:41<25:21,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 729: train loss 3.35502. lr 5.762535e-04:  25%|██▌       | 729/2863 [08:42<25:21,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 729: train loss 3.35502. lr 5.762535e-04:  25%|██▌       | 730/2863 [08:42<25:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 730: train loss 3.33012. lr 5.761893e-04:  25%|██▌       | 730/2863 [08:43<25:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 730: train loss 3.33012. lr 5.761893e-04:  26%|██▌       | 731/2863 [08:43<25:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 731: train loss 3.37644. lr 5.761250e-04:  26%|██▌       | 731/2863 [08:43<25:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 731: train loss 3.37644. lr 5.761250e-04:  26%|██▌       | 732/2863 [08:43<24:56,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 732: train loss 3.35221. lr 5.760605e-04:  26%|██▌       | 732/2863 [08:44<24:56,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 732: train loss 3.35221. lr 5.760605e-04:  26%|██▌       | 733/2863 [08:44<24:45,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 733: train loss 3.34540. lr 5.759961e-04:  26%|██▌       | 733/2863 [08:45<24:45,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 733: train loss 3.34540. lr 5.759961e-04:  26%|██▌       | 734/2863 [08:45<24:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 734: train loss 3.33179. lr 5.759315e-04:  26%|██▌       | 734/2863 [08:45<24:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 734: train loss 3.33179. lr 5.759315e-04:  26%|██▌       | 735/2863 [08:45<24:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 735: train loss 3.35643. lr 5.758668e-04:  26%|██▌       | 735/2863 [08:46<24:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 735: train loss 3.35643. lr 5.758668e-04:  26%|██▌       | 736/2863 [08:46<24:45,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 736: train loss 3.31104. lr 5.758021e-04:  26%|██▌       | 736/2863 [08:47<24:45,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 736: train loss 3.31104. lr 5.758021e-04:  26%|██▌       | 737/2863 [08:47<24:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 737: train loss 3.34604. lr 5.757373e-04:  26%|██▌       | 737/2863 [08:47<24:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 737: train loss 3.34604. lr 5.757373e-04:  26%|██▌       | 738/2863 [08:47<24:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 738: train loss 3.31906. lr 5.756724e-04:  26%|██▌       | 738/2863 [08:48<24:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 738: train loss 3.31906. lr 5.756724e-04:  26%|██▌       | 739/2863 [08:48<24:31,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 739: train loss 3.32751. lr 5.756074e-04:  26%|██▌       | 739/2863 [08:49<24:31,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 739: train loss 3.32751. lr 5.756074e-04:  26%|██▌       | 740/2863 [08:49<24:24,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 740: train loss 3.31403. lr 5.755423e-04:  26%|██▌       | 740/2863 [08:49<24:24,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 740: train loss 3.31403. lr 5.755423e-04:  26%|██▌       | 741/2863 [08:49<24:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 741: train loss 3.25315. lr 5.754771e-04:  26%|██▌       | 741/2863 [08:50<24:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 741: train loss 3.25315. lr 5.754771e-04:  26%|██▌       | 742/2863 [08:50<25:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 742: train loss 3.29676. lr 5.754119e-04:  26%|██▌       | 742/2863 [08:51<25:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 742: train loss 3.29676. lr 5.754119e-04:  26%|██▌       | 743/2863 [08:51<25:30,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 743: train loss 3.28782. lr 5.753466e-04:  26%|██▌       | 743/2863 [08:52<25:30,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 743: train loss 3.28782. lr 5.753466e-04:  26%|██▌       | 744/2863 [08:52<25:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 744: train loss 3.26045. lr 5.752812e-04:  26%|██▌       | 744/2863 [08:52<25:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 744: train loss 3.26045. lr 5.752812e-04:  26%|██▌       | 745/2863 [08:52<24:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 745: train loss 3.24822. lr 5.752157e-04:  26%|██▌       | 745/2863 [08:53<24:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 745: train loss 3.24822. lr 5.752157e-04:  26%|██▌       | 746/2863 [08:53<24:43,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 746: train loss 3.32333. lr 5.751501e-04:  26%|██▌       | 746/2863 [08:54<24:43,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 746: train loss 3.32333. lr 5.751501e-04:  26%|██▌       | 747/2863 [08:54<24:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 747: train loss 3.19766. lr 5.750845e-04:  26%|██▌       | 747/2863 [08:54<24:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 747: train loss 3.19766. lr 5.750845e-04:  26%|██▌       | 748/2863 [08:54<24:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 748: train loss 3.21167. lr 5.750187e-04:  26%|██▌       | 748/2863 [08:55<24:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 748: train loss 3.21167. lr 5.750187e-04:  26%|██▌       | 749/2863 [08:55<24:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 749: train loss 3.27165. lr 5.749529e-04:  26%|██▌       | 749/2863 [08:56<24:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 749: train loss 3.27165. lr 5.749529e-04:  26%|██▌       | 750/2863 [08:56<24:35,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 750: train loss 3.33260. lr 5.748870e-04:  26%|██▌       | 750/2863 [08:57<24:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 750: train loss 3.33260. lr 5.748870e-04:  26%|██▌       | 751/2863 [08:57<24:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 751: train loss 3.21545. lr 5.748210e-04:  26%|██▌       | 751/2863 [08:57<24:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 751: train loss 3.21545. lr 5.748210e-04:  26%|██▋       | 752/2863 [08:57<24:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 752: train loss 3.28474. lr 5.747549e-04:  26%|██▋       | 752/2863 [08:58<24:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 752: train loss 3.28474. lr 5.747549e-04:  26%|██▋       | 753/2863 [08:58<24:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 753: train loss 3.21723. lr 5.746888e-04:  26%|██▋       | 753/2863 [08:59<24:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 753: train loss 3.21723. lr 5.746888e-04:  26%|██▋       | 754/2863 [08:59<24:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 754: train loss 3.23615. lr 5.746226e-04:  26%|██▋       | 754/2863 [08:59<24:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 754: train loss 3.23615. lr 5.746226e-04:  26%|██▋       | 755/2863 [08:59<25:07,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 755: train loss 3.23783. lr 5.745562e-04:  26%|██▋       | 755/2863 [09:00<25:07,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 755: train loss 3.23783. lr 5.745562e-04:  26%|██▋       | 756/2863 [09:00<25:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 756: train loss 3.17094. lr 5.744898e-04:  26%|██▋       | 756/2863 [09:01<25:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 756: train loss 3.17094. lr 5.744898e-04:  26%|██▋       | 757/2863 [09:01<25:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 757: train loss 3.23374. lr 5.744234e-04:  26%|██▋       | 757/2863 [09:02<25:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 757: train loss 3.23374. lr 5.744234e-04:  26%|██▋       | 758/2863 [09:02<25:00,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 758: train loss 3.19960. lr 5.743568e-04:  26%|██▋       | 758/2863 [09:02<25:00,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 758: train loss 3.19960. lr 5.743568e-04:  27%|██▋       | 759/2863 [09:02<24:55,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 759: train loss 3.23153. lr 5.742902e-04:  27%|██▋       | 759/2863 [09:03<24:55,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 759: train loss 3.23153. lr 5.742902e-04:  27%|██▋       | 760/2863 [09:03<24:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 760: train loss 3.18093. lr 5.742234e-04:  27%|██▋       | 760/2863 [09:04<24:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 760: train loss 3.18093. lr 5.742234e-04:  27%|██▋       | 761/2863 [09:04<24:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 761: train loss 3.20940. lr 5.741566e-04:  27%|██▋       | 761/2863 [09:04<24:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 761: train loss 3.20940. lr 5.741566e-04:  27%|██▋       | 762/2863 [09:04<24:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 762: train loss 3.15246. lr 5.740897e-04:  27%|██▋       | 762/2863 [09:05<24:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 762: train loss 3.15246. lr 5.740897e-04:  27%|██▋       | 763/2863 [09:05<24:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 763: train loss 3.15416. lr 5.740227e-04:  27%|██▋       | 763/2863 [09:06<24:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 763: train loss 3.15416. lr 5.740227e-04:  27%|██▋       | 764/2863 [09:06<24:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 764: train loss 3.18244. lr 5.739557e-04:  27%|██▋       | 764/2863 [09:06<24:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 764: train loss 3.18244. lr 5.739557e-04:  27%|██▋       | 765/2863 [09:06<24:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 765: train loss 3.11232. lr 5.738885e-04:  27%|██▋       | 765/2863 [09:07<24:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 765: train loss 3.11232. lr 5.738885e-04:  27%|██▋       | 766/2863 [09:07<24:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 766: train loss 3.10659. lr 5.738213e-04:  27%|██▋       | 766/2863 [09:08<24:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 766: train loss 3.10659. lr 5.738213e-04:  27%|██▋       | 767/2863 [09:08<24:46,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 767: train loss 3.10089. lr 5.737540e-04:  27%|██▋       | 767/2863 [09:09<24:46,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 767: train loss 3.10089. lr 5.737540e-04:  27%|██▋       | 768/2863 [09:09<25:00,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 768: train loss 3.13910. lr 5.736866e-04:  27%|██▋       | 768/2863 [09:09<25:00,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 768: train loss 3.13910. lr 5.736866e-04:  27%|██▋       | 769/2863 [09:09<24:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 769: train loss 3.12612. lr 5.736191e-04:  27%|██▋       | 769/2863 [09:10<24:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 769: train loss 3.12612. lr 5.736191e-04:  27%|██▋       | 770/2863 [09:10<26:03,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 770: train loss 3.12329. lr 5.735516e-04:  27%|██▋       | 770/2863 [09:11<26:03,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 770: train loss 3.12329. lr 5.735516e-04:  27%|██▋       | 771/2863 [09:11<25:35,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 771: train loss 3.05286. lr 5.734840e-04:  27%|██▋       | 771/2863 [09:12<25:35,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 771: train loss 3.05286. lr 5.734840e-04:  27%|██▋       | 772/2863 [09:12<25:52,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 772: train loss 3.08555. lr 5.734162e-04:  27%|██▋       | 772/2863 [09:12<25:52,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 772: train loss 3.08555. lr 5.734162e-04:  27%|██▋       | 773/2863 [09:12<25:51,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 773: train loss 3.07177. lr 5.733484e-04:  27%|██▋       | 773/2863 [09:13<25:51,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 773: train loss 3.07177. lr 5.733484e-04:  27%|██▋       | 774/2863 [09:13<25:42,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 774: train loss 3.15102. lr 5.732806e-04:  27%|██▋       | 774/2863 [09:14<25:42,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 774: train loss 3.15102. lr 5.732806e-04:  27%|██▋       | 775/2863 [09:14<25:31,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 775: train loss 3.04860. lr 5.732126e-04:  27%|██▋       | 775/2863 [09:14<25:31,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 775: train loss 3.04860. lr 5.732126e-04:  27%|██▋       | 776/2863 [09:14<25:13,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 776: train loss 3.08047. lr 5.731445e-04:  27%|██▋       | 776/2863 [09:15<25:13,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 776: train loss 3.08047. lr 5.731445e-04:  27%|██▋       | 777/2863 [09:15<24:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 777: train loss 3.03979. lr 5.730764e-04:  27%|██▋       | 777/2863 [09:16<24:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 777: train loss 3.03979. lr 5.730764e-04:  27%|██▋       | 778/2863 [09:16<24:47,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 778: train loss 3.06223. lr 5.730082e-04:  27%|██▋       | 778/2863 [09:17<24:47,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 778: train loss 3.06223. lr 5.730082e-04:  27%|██▋       | 779/2863 [09:17<24:38,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 779: train loss 3.08359. lr 5.729399e-04:  27%|██▋       | 779/2863 [09:17<24:38,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 779: train loss 3.08359. lr 5.729399e-04:  27%|██▋       | 780/2863 [09:17<24:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 780: train loss 3.06915. lr 5.728715e-04:  27%|██▋       | 780/2863 [09:18<24:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 780: train loss 3.06915. lr 5.728715e-04:  27%|██▋       | 781/2863 [09:18<24:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 781: train loss 3.12266. lr 5.728031e-04:  27%|██▋       | 781/2863 [09:19<24:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 781: train loss 3.12266. lr 5.728031e-04:  27%|██▋       | 782/2863 [09:19<24:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 782: train loss 3.05943. lr 5.727345e-04:  27%|██▋       | 782/2863 [09:19<24:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 782: train loss 3.05943. lr 5.727345e-04:  27%|██▋       | 783/2863 [09:19<24:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 783: train loss 3.04373. lr 5.726659e-04:  27%|██▋       | 783/2863 [09:20<24:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 783: train loss 3.04373. lr 5.726659e-04:  27%|██▋       | 784/2863 [09:20<24:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 784: train loss 3.02112. lr 5.725972e-04:  27%|██▋       | 784/2863 [09:21<24:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 784: train loss 3.02112. lr 5.725972e-04:  27%|██▋       | 785/2863 [09:21<24:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 785: train loss 3.05974. lr 5.725284e-04:  27%|██▋       | 785/2863 [09:21<24:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 785: train loss 3.05974. lr 5.725284e-04:  27%|██▋       | 786/2863 [09:21<24:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 786: train loss 3.08092. lr 5.724595e-04:  27%|██▋       | 786/2863 [09:22<24:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 786: train loss 3.08092. lr 5.724595e-04:  27%|██▋       | 787/2863 [09:22<24:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 787: train loss 3.05766. lr 5.723906e-04:  27%|██▋       | 787/2863 [09:23<24:17,  1.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 787: train loss 3.05766. lr 5.723906e-04:  28%|██▊       | 788/2863 [09:23<24:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 788: train loss 3.07522. lr 5.723215e-04:  28%|██▊       | 788/2863 [09:24<24:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 788: train loss 3.07522. lr 5.723215e-04:  28%|██▊       | 789/2863 [09:24<24:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 789: train loss 3.07450. lr 5.722524e-04:  28%|██▊       | 789/2863 [09:24<24:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 789: train loss 3.07450. lr 5.722524e-04:  28%|██▊       | 790/2863 [09:24<24:16,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 790: train loss 3.02818. lr 5.721832e-04:  28%|██▊       | 790/2863 [09:25<24:16,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 790: train loss 3.02818. lr 5.721832e-04:  28%|██▊       | 791/2863 [09:25<24:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 791: train loss 2.96947. lr 5.721140e-04:  28%|██▊       | 791/2863 [09:26<24:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 791: train loss 2.96947. lr 5.721140e-04:  28%|██▊       | 792/2863 [09:26<25:24,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 792: train loss 3.01367. lr 5.720446e-04:  28%|██▊       | 792/2863 [09:27<25:24,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 792: train loss 3.01367. lr 5.720446e-04:  28%|██▊       | 793/2863 [09:27<25:44,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 793: train loss 3.03942. lr 5.719751e-04:  28%|██▊       | 793/2863 [09:27<25:44,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 793: train loss 3.03942. lr 5.719751e-04:  28%|██▊       | 794/2863 [09:27<25:26,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 794: train loss 2.98599. lr 5.719056e-04:  28%|██▊       | 794/2863 [09:28<25:26,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 794: train loss 2.98599. lr 5.719056e-04:  28%|██▊       | 795/2863 [09:28<24:52,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 795: train loss 3.03573. lr 5.718360e-04:  28%|██▊       | 795/2863 [09:29<24:52,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 795: train loss 3.03573. lr 5.718360e-04:  28%|██▊       | 796/2863 [09:29<24:42,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 796: train loss 2.92298. lr 5.717663e-04:  28%|██▊       | 796/2863 [09:29<24:42,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 796: train loss 2.92298. lr 5.717663e-04:  28%|██▊       | 797/2863 [09:29<24:36,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 797: train loss 3.05352. lr 5.716966e-04:  28%|██▊       | 797/2863 [09:30<24:36,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 797: train loss 3.05352. lr 5.716966e-04:  28%|██▊       | 798/2863 [09:30<25:41,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 798: train loss 2.91300. lr 5.716267e-04:  28%|██▊       | 798/2863 [09:31<25:41,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 798: train loss 2.91300. lr 5.716267e-04:  28%|██▊       | 799/2863 [09:31<25:14,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 799: train loss 3.01503. lr 5.715568e-04:  28%|██▊       | 799/2863 [09:32<25:14,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 799: train loss 3.01503. lr 5.715568e-04:  28%|██▊       | 800/2863 [09:32<24:46,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 800: train loss 2.94720. lr 5.714867e-04:  28%|██▊       | 800/2863 [09:32<24:46,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 800: train loss 2.94720. lr 5.714867e-04:  28%|██▊       | 801/2863 [09:32<24:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 801: train loss 2.93905. lr 5.714166e-04:  28%|██▊       | 801/2863 [09:33<24:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 801: train loss 2.93905. lr 5.714166e-04:  28%|██▊       | 802/2863 [09:33<24:16,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 802: train loss 2.97170. lr 5.713465e-04:  28%|██▊       | 802/2863 [09:34<24:16,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 802: train loss 2.97170. lr 5.713465e-04:  28%|██▊       | 803/2863 [09:34<24:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 803: train loss 2.92404. lr 5.712762e-04:  28%|██▊       | 803/2863 [09:34<24:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 803: train loss 2.92404. lr 5.712762e-04:  28%|██▊       | 804/2863 [09:34<24:17,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 804: train loss 2.86493. lr 5.712059e-04:  28%|██▊       | 804/2863 [09:35<24:17,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 804: train loss 2.86493. lr 5.712059e-04:  28%|██▊       | 805/2863 [09:35<24:18,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 805: train loss 2.91961. lr 5.711354e-04:  28%|██▊       | 805/2863 [09:36<24:18,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 805: train loss 2.91961. lr 5.711354e-04:  28%|██▊       | 806/2863 [09:36<24:14,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 806: train loss 2.97396. lr 5.710649e-04:  28%|██▊       | 806/2863 [09:37<24:14,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 806: train loss 2.97396. lr 5.710649e-04:  28%|██▊       | 807/2863 [09:37<24:07,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 807: train loss 2.92207. lr 5.709943e-04:  28%|██▊       | 807/2863 [09:37<24:07,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 807: train loss 2.92207. lr 5.709943e-04:  28%|██▊       | 808/2863 [09:37<24:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 808: train loss 2.96398. lr 5.709237e-04:  28%|██▊       | 808/2863 [09:38<24:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 808: train loss 2.96398. lr 5.709237e-04:  28%|██▊       | 809/2863 [09:38<24:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 809: train loss 2.95324. lr 5.708529e-04:  28%|██▊       | 809/2863 [09:39<24:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 809: train loss 2.95324. lr 5.708529e-04:  28%|██▊       | 810/2863 [09:39<23:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 810: train loss 2.87748. lr 5.707821e-04:  28%|██▊       | 810/2863 [09:39<23:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 810: train loss 2.87748. lr 5.707821e-04:  28%|██▊       | 811/2863 [09:39<23:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 811: train loss 2.88802. lr 5.707112e-04:  28%|██▊       | 811/2863 [09:40<23:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 811: train loss 2.88802. lr 5.707112e-04:  28%|██▊       | 812/2863 [09:40<23:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 812: train loss 2.91448. lr 5.706402e-04:  28%|██▊       | 812/2863 [09:41<23:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 812: train loss 2.91448. lr 5.706402e-04:  28%|██▊       | 813/2863 [09:41<23:44,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 813: train loss 2.92735. lr 5.705691e-04:  28%|██▊       | 813/2863 [09:41<23:44,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 813: train loss 2.92735. lr 5.705691e-04:  28%|██▊       | 814/2863 [09:41<23:44,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 814: train loss 2.91878. lr 5.704979e-04:  28%|██▊       | 814/2863 [09:42<23:44,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 814: train loss 2.91878. lr 5.704979e-04:  28%|██▊       | 815/2863 [09:42<23:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 815: train loss 2.85764. lr 5.704267e-04:  28%|██▊       | 815/2863 [09:43<23:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 815: train loss 2.85764. lr 5.704267e-04:  29%|██▊       | 816/2863 [09:43<24:00,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 816: train loss 2.84988. lr 5.703554e-04:  29%|██▊       | 816/2863 [09:44<24:00,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 816: train loss 2.84988. lr 5.703554e-04:  29%|██▊       | 817/2863 [09:44<24:01,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 817: train loss 2.84590. lr 5.702840e-04:  29%|██▊       | 817/2863 [09:44<24:01,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 817: train loss 2.84590. lr 5.702840e-04:  29%|██▊       | 818/2863 [09:44<23:59,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 818: train loss 2.80120. lr 5.702125e-04:  29%|██▊       | 818/2863 [09:45<23:59,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 818: train loss 2.80120. lr 5.702125e-04:  29%|██▊       | 819/2863 [09:45<23:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 819: train loss 2.92396. lr 5.701409e-04:  29%|██▊       | 819/2863 [09:46<23:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 819: train loss 2.92396. lr 5.701409e-04:  29%|██▊       | 820/2863 [09:46<23:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 820: train loss 2.80353. lr 5.700693e-04:  29%|██▊       | 820/2863 [09:46<23:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 820: train loss 2.80353. lr 5.700693e-04:  29%|██▊       | 821/2863 [09:46<23:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 821: train loss 2.85081. lr 5.699975e-04:  29%|██▊       | 821/2863 [09:47<23:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 821: train loss 2.85081. lr 5.699975e-04:  29%|██▊       | 822/2863 [09:47<23:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 822: train loss 2.83500. lr 5.699257e-04:  29%|██▊       | 822/2863 [09:48<23:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 822: train loss 2.83500. lr 5.699257e-04:  29%|██▊       | 823/2863 [09:48<23:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 823: train loss 2.81541. lr 5.698538e-04:  29%|██▊       | 823/2863 [09:48<23:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 823: train loss 2.81541. lr 5.698538e-04:  29%|██▉       | 824/2863 [09:48<23:55,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 824: train loss 2.84151. lr 5.697819e-04:  29%|██▉       | 824/2863 [09:49<23:55,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 824: train loss 2.84151. lr 5.697819e-04:  29%|██▉       | 825/2863 [09:49<24:04,  1.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 825: train loss 2.80579. lr 5.697098e-04:  29%|██▉       | 825/2863 [09:50<24:04,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 825: train loss 2.80579. lr 5.697098e-04:  29%|██▉       | 826/2863 [09:50<25:12,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 826: train loss 2.84977. lr 5.696377e-04:  29%|██▉       | 826/2863 [09:51<25:12,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 826: train loss 2.84977. lr 5.696377e-04:  29%|██▉       | 827/2863 [09:51<25:09,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 827: train loss 2.82144. lr 5.695654e-04:  29%|██▉       | 827/2863 [09:51<25:09,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 827: train loss 2.82144. lr 5.695654e-04:  29%|██▉       | 828/2863 [09:51<25:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 828: train loss 2.74593. lr 5.694931e-04:  29%|██▉       | 828/2863 [09:52<25:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 828: train loss 2.74593. lr 5.694931e-04:  29%|██▉       | 829/2863 [09:52<25:09,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 829: train loss 2.75625. lr 5.694208e-04:  29%|██▉       | 829/2863 [09:53<25:09,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 829: train loss 2.75625. lr 5.694208e-04:  29%|██▉       | 830/2863 [09:53<24:43,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 830: train loss 2.85732. lr 5.693483e-04:  29%|██▉       | 830/2863 [09:54<24:43,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 830: train loss 2.85732. lr 5.693483e-04:  29%|██▉       | 831/2863 [09:54<24:19,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 831: train loss 2.70545. lr 5.692758e-04:  29%|██▉       | 831/2863 [09:54<24:19,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 831: train loss 2.70545. lr 5.692758e-04:  29%|██▉       | 832/2863 [09:54<24:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 832: train loss 2.84703. lr 5.692031e-04:  29%|██▉       | 832/2863 [09:55<24:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 832: train loss 2.84703. lr 5.692031e-04:  29%|██▉       | 833/2863 [09:55<23:51,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 833: train loss 2.76081. lr 5.691304e-04:  29%|██▉       | 833/2863 [09:56<23:51,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 833: train loss 2.76081. lr 5.691304e-04:  29%|██▉       | 834/2863 [09:56<23:46,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 834: train loss 2.75267. lr 5.690577e-04:  29%|██▉       | 834/2863 [09:56<23:46,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 834: train loss 2.75267. lr 5.690577e-04:  29%|██▉       | 835/2863 [09:56<23:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 835: train loss 2.73710. lr 5.689848e-04:  29%|██▉       | 835/2863 [09:57<23:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 835: train loss 2.73710. lr 5.689848e-04:  29%|██▉       | 836/2863 [09:57<23:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 836: train loss 2.78247. lr 5.689118e-04:  29%|██▉       | 836/2863 [09:58<23:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 836: train loss 2.78247. lr 5.689118e-04:  29%|██▉       | 837/2863 [09:58<23:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 837: train loss 2.75508. lr 5.688388e-04:  29%|██▉       | 837/2863 [09:58<23:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 837: train loss 2.75508. lr 5.688388e-04:  29%|██▉       | 838/2863 [09:58<23:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 838: train loss 2.77903. lr 5.687657e-04:  29%|██▉       | 838/2863 [09:59<23:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 838: train loss 2.77903. lr 5.687657e-04:  29%|██▉       | 839/2863 [09:59<23:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 839: train loss 2.79110. lr 5.686925e-04:  29%|██▉       | 839/2863 [10:00<23:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 839: train loss 2.79110. lr 5.686925e-04:  29%|██▉       | 840/2863 [10:00<23:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 840: train loss 2.69987. lr 5.686192e-04:  29%|██▉       | 840/2863 [10:01<23:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 840: train loss 2.69987. lr 5.686192e-04:  29%|██▉       | 841/2863 [10:01<23:40,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 841: train loss 2.69697. lr 5.685459e-04:  29%|██▉       | 841/2863 [10:01<23:40,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 841: train loss 2.69697. lr 5.685459e-04:  29%|██▉       | 842/2863 [10:01<23:46,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 842: train loss 2.78018. lr 5.684725e-04:  29%|██▉       | 842/2863 [10:02<23:46,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 842: train loss 2.78018. lr 5.684725e-04:  29%|██▉       | 843/2863 [10:02<23:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 843: train loss 2.72569. lr 5.683989e-04:  29%|██▉       | 843/2863 [10:03<23:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 843: train loss 2.72569. lr 5.683989e-04:  29%|██▉       | 844/2863 [10:03<24:05,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 844: train loss 2.72514. lr 5.683253e-04:  29%|██▉       | 844/2863 [10:03<24:05,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 844: train loss 2.72514. lr 5.683253e-04:  30%|██▉       | 845/2863 [10:03<24:25,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 845: train loss 2.72162. lr 5.682517e-04:  30%|██▉       | 845/2863 [10:04<24:25,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 845: train loss 2.72162. lr 5.682517e-04:  30%|██▉       | 846/2863 [10:04<24:33,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 846: train loss 2.73720. lr 5.681779e-04:  30%|██▉       | 846/2863 [10:05<24:33,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 846: train loss 2.73720. lr 5.681779e-04:  30%|██▉       | 847/2863 [10:05<24:33,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 847: train loss 2.77680. lr 5.681041e-04:  30%|██▉       | 847/2863 [10:06<24:33,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 847: train loss 2.77680. lr 5.681041e-04:  30%|██▉       | 848/2863 [10:06<24:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 848: train loss 2.72918. lr 5.680302e-04:  30%|██▉       | 848/2863 [10:06<24:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 848: train loss 2.72918. lr 5.680302e-04:  30%|██▉       | 849/2863 [10:06<24:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 849: train loss 2.70945. lr 5.679562e-04:  30%|██▉       | 849/2863 [10:07<24:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 849: train loss 2.70945. lr 5.679562e-04:  30%|██▉       | 850/2863 [10:07<23:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 850: train loss 2.76390. lr 5.678821e-04:  30%|██▉       | 850/2863 [10:08<23:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 850: train loss 2.76390. lr 5.678821e-04:  30%|██▉       | 851/2863 [10:08<23:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 851: train loss 2.66332. lr 5.678079e-04:  30%|██▉       | 851/2863 [10:08<23:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 851: train loss 2.66332. lr 5.678079e-04:  30%|██▉       | 852/2863 [10:08<23:34,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 852: train loss 2.65825. lr 5.677337e-04:  30%|██▉       | 852/2863 [10:09<23:34,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 852: train loss 2.65825. lr 5.677337e-04:  30%|██▉       | 853/2863 [10:09<23:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 853: train loss 2.70307. lr 5.676594e-04:  30%|██▉       | 853/2863 [10:10<23:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 853: train loss 2.70307. lr 5.676594e-04:  30%|██▉       | 854/2863 [10:10<24:55,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 854: train loss 2.64885. lr 5.675850e-04:  30%|██▉       | 854/2863 [10:11<24:55,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 854: train loss 2.64885. lr 5.675850e-04:  30%|██▉       | 855/2863 [10:11<24:35,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 855: train loss 2.67213. lr 5.675105e-04:  30%|██▉       | 855/2863 [10:11<24:35,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 855: train loss 2.67213. lr 5.675105e-04:  30%|██▉       | 856/2863 [10:11<24:14,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 856: train loss 2.66283. lr 5.674359e-04:  30%|██▉       | 856/2863 [10:12<24:14,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 856: train loss 2.66283. lr 5.674359e-04:  30%|██▉       | 857/2863 [10:12<24:00,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 857: train loss 2.66825. lr 5.673613e-04:  30%|██▉       | 857/2863 [10:13<24:00,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 857: train loss 2.66825. lr 5.673613e-04:  30%|██▉       | 858/2863 [10:13<23:46,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 858: train loss 2.67057. lr 5.672865e-04:  30%|██▉       | 858/2863 [10:14<23:46,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 858: train loss 2.67057. lr 5.672865e-04:  30%|███       | 859/2863 [10:14<24:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 859: train loss 2.56888. lr 5.672117e-04:  30%|███       | 859/2863 [10:14<24:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 859: train loss 2.56888. lr 5.672117e-04:  30%|███       | 860/2863 [10:14<24:23,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 860: train loss 2.61739. lr 5.671368e-04:  30%|███       | 860/2863 [10:15<24:23,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 860: train loss 2.61739. lr 5.671368e-04:  30%|███       | 861/2863 [10:15<24:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 861: train loss 2.57108. lr 5.670619e-04:  30%|███       | 861/2863 [10:16<24:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 861: train loss 2.57108. lr 5.670619e-04:  30%|███       | 862/2863 [10:16<23:50,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 862: train loss 2.69867. lr 5.669868e-04:  30%|███       | 862/2863 [10:16<23:50,  1.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 862: train loss 2.69867. lr 5.669868e-04:  30%|███       | 863/2863 [10:16<23:45,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 863: train loss 2.59821. lr 5.669117e-04:  30%|███       | 863/2863 [10:17<23:45,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 863: train loss 2.59821. lr 5.669117e-04:  30%|███       | 864/2863 [10:17<24:32,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 864: train loss 2.65920. lr 5.668365e-04:  30%|███       | 864/2863 [10:18<24:32,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 864: train loss 2.65920. lr 5.668365e-04:  30%|███       | 865/2863 [10:18<24:50,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 865: train loss 2.62110. lr 5.667612e-04:  30%|███       | 865/2863 [10:19<24:50,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 865: train loss 2.62110. lr 5.667612e-04:  30%|███       | 866/2863 [10:19<24:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 866: train loss 2.56855. lr 5.666858e-04:  30%|███       | 866/2863 [10:19<24:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 866: train loss 2.56855. lr 5.666858e-04:  30%|███       | 867/2863 [10:19<24:04,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 867: train loss 2.56781. lr 5.666104e-04:  30%|███       | 867/2863 [10:20<24:04,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 867: train loss 2.56781. lr 5.666104e-04:  30%|███       | 868/2863 [10:20<24:19,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 868: train loss 2.55320. lr 5.665349e-04:  30%|███       | 868/2863 [10:21<24:19,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 868: train loss 2.55320. lr 5.665349e-04:  30%|███       | 869/2863 [10:21<24:43,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 869: train loss 2.59565. lr 5.664593e-04:  30%|███       | 869/2863 [10:22<24:43,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 869: train loss 2.59565. lr 5.664593e-04:  30%|███       | 870/2863 [10:22<25:00,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 870: train loss 2.60859. lr 5.663836e-04:  30%|███       | 870/2863 [10:22<25:00,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 870: train loss 2.60859. lr 5.663836e-04:  30%|███       | 871/2863 [10:22<25:12,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 871: train loss 2.56652. lr 5.663078e-04:  30%|███       | 871/2863 [10:23<25:12,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 871: train loss 2.56652. lr 5.663078e-04:  30%|███       | 872/2863 [10:23<25:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 872: train loss 2.55079. lr 5.662320e-04:  30%|███       | 872/2863 [10:24<25:21,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 872: train loss 2.55079. lr 5.662320e-04:  30%|███       | 873/2863 [10:24<25:17,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 873: train loss 2.58488. lr 5.661560e-04:  30%|███       | 873/2863 [10:25<25:17,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 873: train loss 2.58488. lr 5.661560e-04:  31%|███       | 874/2863 [10:25<25:18,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 874: train loss 2.51750. lr 5.660800e-04:  31%|███       | 874/2863 [10:26<25:18,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 874: train loss 2.51750. lr 5.660800e-04:  31%|███       | 875/2863 [10:26<26:30,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 875: train loss 2.55196. lr 5.660039e-04:  31%|███       | 875/2863 [10:26<26:30,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 875: train loss 2.55196. lr 5.660039e-04:  31%|███       | 876/2863 [10:26<26:44,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 876: train loss 2.52269. lr 5.659278e-04:  31%|███       | 876/2863 [10:27<26:44,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 876: train loss 2.52269. lr 5.659278e-04:  31%|███       | 877/2863 [10:27<26:29,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 877: train loss 2.56107. lr 5.658515e-04:  31%|███       | 877/2863 [10:28<26:29,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 877: train loss 2.56107. lr 5.658515e-04:  31%|███       | 878/2863 [10:28<26:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 878: train loss 2.57053. lr 5.657752e-04:  31%|███       | 878/2863 [10:29<26:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 878: train loss 2.57053. lr 5.657752e-04:  31%|███       | 879/2863 [10:29<25:50,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 879: train loss 2.54586. lr 5.656988e-04:  31%|███       | 879/2863 [10:30<25:50,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 879: train loss 2.54586. lr 5.656988e-04:  31%|███       | 880/2863 [10:30<25:42,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 880: train loss 2.45596. lr 5.656223e-04:  31%|███       | 880/2863 [10:30<25:42,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 880: train loss 2.45596. lr 5.656223e-04:  31%|███       | 881/2863 [10:30<25:45,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 881: train loss 2.49303. lr 5.655457e-04:  31%|███       | 881/2863 [10:31<25:45,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 881: train loss 2.49303. lr 5.655457e-04:  31%|███       | 882/2863 [10:31<26:47,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 882: train loss 2.43950. lr 5.654691e-04:  31%|███       | 882/2863 [10:32<26:47,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 882: train loss 2.43950. lr 5.654691e-04:  31%|███       | 883/2863 [10:32<26:23,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 883: train loss 2.50751. lr 5.653923e-04:  31%|███       | 883/2863 [10:33<26:23,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 883: train loss 2.50751. lr 5.653923e-04:  31%|███       | 884/2863 [10:33<26:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 884: train loss 2.46914. lr 5.653155e-04:  31%|███       | 884/2863 [10:34<26:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 884: train loss 2.46914. lr 5.653155e-04:  31%|███       | 885/2863 [10:34<26:00,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 885: train loss 2.50164. lr 5.652386e-04:  31%|███       | 885/2863 [10:34<26:00,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 885: train loss 2.50164. lr 5.652386e-04:  31%|███       | 886/2863 [10:34<25:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 886: train loss 2.51325. lr 5.651617e-04:  31%|███       | 886/2863 [10:35<25:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 886: train loss 2.51325. lr 5.651617e-04:  31%|███       | 887/2863 [10:35<25:43,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 887: train loss 2.49337. lr 5.650846e-04:  31%|███       | 887/2863 [10:36<25:43,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 887: train loss 2.49337. lr 5.650846e-04:  31%|███       | 888/2863 [10:36<25:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 888: train loss 2.49278. lr 5.650075e-04:  31%|███       | 888/2863 [10:37<25:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 888: train loss 2.49278. lr 5.650075e-04:  31%|███       | 889/2863 [10:37<25:40,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 889: train loss 2.42632. lr 5.649303e-04:  31%|███       | 889/2863 [10:37<25:40,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 889: train loss 2.42632. lr 5.649303e-04:  31%|███       | 890/2863 [10:37<25:30,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 890: train loss 2.42741. lr 5.648530e-04:  31%|███       | 890/2863 [10:38<25:30,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 890: train loss 2.42741. lr 5.648530e-04:  31%|███       | 891/2863 [10:38<25:31,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 891: train loss 2.43525. lr 5.647756e-04:  31%|███       | 891/2863 [10:39<25:31,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 891: train loss 2.43525. lr 5.647756e-04:  31%|███       | 892/2863 [10:39<25:33,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 892: train loss 2.49155. lr 5.646982e-04:  31%|███       | 892/2863 [10:40<25:33,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 892: train loss 2.49155. lr 5.646982e-04:  31%|███       | 893/2863 [10:40<25:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 893: train loss 2.39770. lr 5.646206e-04:  31%|███       | 893/2863 [10:41<25:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 893: train loss 2.39770. lr 5.646206e-04:  31%|███       | 894/2863 [10:41<25:39,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 894: train loss 2.45467. lr 5.645430e-04:  31%|███       | 894/2863 [10:41<25:39,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 894: train loss 2.45467. lr 5.645430e-04:  31%|███▏      | 895/2863 [10:41<25:31,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 895: train loss 2.46603. lr 5.644653e-04:  31%|███▏      | 895/2863 [10:42<25:31,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 895: train loss 2.46603. lr 5.644653e-04:  31%|███▏      | 896/2863 [10:42<25:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 896: train loss 2.39809. lr 5.643876e-04:  31%|███▏      | 896/2863 [10:43<25:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 896: train loss 2.39809. lr 5.643876e-04:  31%|███▏      | 897/2863 [10:43<25:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 897: train loss 2.45806. lr 5.643097e-04:  31%|███▏      | 897/2863 [10:44<25:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 897: train loss 2.45806. lr 5.643097e-04:  31%|███▏      | 898/2863 [10:44<25:37,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 898: train loss 2.44885. lr 5.642318e-04:  31%|███▏      | 898/2863 [10:44<25:37,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 898: train loss 2.44885. lr 5.642318e-04:  31%|███▏      | 899/2863 [10:44<25:43,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 899: train loss 2.40790. lr 5.641538e-04:  31%|███▏      | 899/2863 [10:45<25:43,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 899: train loss 2.40790. lr 5.641538e-04:  31%|███▏      | 900/2863 [10:45<25:26,  1.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 900: train loss 2.35993. lr 5.640757e-04:  31%|███▏      | 900/2863 [10:46<25:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 900: train loss 2.35993. lr 5.640757e-04:  31%|███▏      | 901/2863 [10:46<25:17,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 901: train loss 2.41635. lr 5.639975e-04:  31%|███▏      | 901/2863 [10:47<25:17,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 901: train loss 2.41635. lr 5.639975e-04:  32%|███▏      | 902/2863 [10:47<25:17,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 902: train loss 2.41363. lr 5.639193e-04:  32%|███▏      | 902/2863 [10:48<25:17,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 902: train loss 2.41363. lr 5.639193e-04:  32%|███▏      | 903/2863 [10:48<25:26,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 903: train loss 2.42945. lr 5.638410e-04:  32%|███▏      | 903/2863 [10:48<25:26,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 903: train loss 2.42945. lr 5.638410e-04:  32%|███▏      | 904/2863 [10:48<25:31,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 904: train loss 2.46283. lr 5.637626e-04:  32%|███▏      | 904/2863 [10:49<25:31,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 904: train loss 2.46283. lr 5.637626e-04:  32%|███▏      | 905/2863 [10:49<25:28,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 905: train loss 2.33590. lr 5.636841e-04:  32%|███▏      | 905/2863 [10:50<25:28,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 905: train loss 2.33590. lr 5.636841e-04:  32%|███▏      | 906/2863 [10:50<25:18,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 906: train loss 2.41080. lr 5.636055e-04:  32%|███▏      | 906/2863 [10:51<25:18,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 906: train loss 2.41080. lr 5.636055e-04:  32%|███▏      | 907/2863 [10:51<25:19,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 907: train loss 2.34747. lr 5.635269e-04:  32%|███▏      | 907/2863 [10:51<25:19,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 907: train loss 2.34747. lr 5.635269e-04:  32%|███▏      | 908/2863 [10:51<25:29,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 908: train loss 2.31534. lr 5.634482e-04:  32%|███▏      | 908/2863 [10:52<25:29,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 908: train loss 2.31534. lr 5.634482e-04:  32%|███▏      | 909/2863 [10:52<25:33,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 909: train loss 2.33951. lr 5.633694e-04:  32%|███▏      | 909/2863 [10:53<25:33,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 909: train loss 2.33951. lr 5.633694e-04:  32%|███▏      | 910/2863 [10:53<26:36,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 910: train loss 2.37457. lr 5.632905e-04:  32%|███▏      | 910/2863 [10:54<26:36,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 910: train loss 2.37457. lr 5.632905e-04:  32%|███▏      | 911/2863 [10:54<26:13,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 911: train loss 2.36782. lr 5.632115e-04:  32%|███▏      | 911/2863 [10:55<26:13,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 911: train loss 2.36782. lr 5.632115e-04:  32%|███▏      | 912/2863 [10:55<26:06,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 912: train loss 2.30908. lr 5.631325e-04:  32%|███▏      | 912/2863 [10:55<26:06,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 912: train loss 2.30908. lr 5.631325e-04:  32%|███▏      | 913/2863 [10:55<25:56,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 913: train loss 2.30329. lr 5.630534e-04:  32%|███▏      | 913/2863 [10:56<25:56,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 913: train loss 2.30329. lr 5.630534e-04:  32%|███▏      | 914/2863 [10:56<25:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 914: train loss 2.32546. lr 5.629742e-04:  32%|███▏      | 914/2863 [10:57<25:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 914: train loss 2.32546. lr 5.629742e-04:  32%|███▏      | 915/2863 [10:57<25:38,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 915: train loss 2.35055. lr 5.628949e-04:  32%|███▏      | 915/2863 [10:58<25:38,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 915: train loss 2.35055. lr 5.628949e-04:  32%|███▏      | 916/2863 [10:58<25:37,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 916: train loss 2.28295. lr 5.628155e-04:  32%|███▏      | 916/2863 [10:59<25:37,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 916: train loss 2.28295. lr 5.628155e-04:  32%|███▏      | 917/2863 [10:59<25:30,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 917: train loss 2.39108. lr 5.627361e-04:  32%|███▏      | 917/2863 [10:59<25:30,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 917: train loss 2.39108. lr 5.627361e-04:  32%|███▏      | 918/2863 [10:59<25:37,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 918: train loss 2.36176. lr 5.626566e-04:  32%|███▏      | 918/2863 [11:00<25:37,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 918: train loss 2.36176. lr 5.626566e-04:  32%|███▏      | 919/2863 [11:00<25:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 919: train loss 2.32189. lr 5.625770e-04:  32%|███▏      | 919/2863 [11:01<25:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 919: train loss 2.32189. lr 5.625770e-04:  32%|███▏      | 920/2863 [11:01<25:40,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 920: train loss 2.28307. lr 5.624973e-04:  32%|███▏      | 920/2863 [11:02<25:40,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 920: train loss 2.28307. lr 5.624973e-04:  32%|███▏      | 921/2863 [11:02<25:38,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 921: train loss 2.35648. lr 5.624176e-04:  32%|███▏      | 921/2863 [11:03<25:38,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 921: train loss 2.35648. lr 5.624176e-04:  32%|███▏      | 922/2863 [11:03<25:39,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 922: train loss 2.28478. lr 5.623377e-04:  32%|███▏      | 922/2863 [11:03<25:39,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 922: train loss 2.28478. lr 5.623377e-04:  32%|███▏      | 923/2863 [11:03<25:34,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 923: train loss 2.36523. lr 5.622578e-04:  32%|███▏      | 923/2863 [11:04<25:34,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 923: train loss 2.36523. lr 5.622578e-04:  32%|███▏      | 924/2863 [11:04<25:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 924: train loss 2.24520. lr 5.621778e-04:  32%|███▏      | 924/2863 [11:05<25:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 924: train loss 2.24520. lr 5.621778e-04:  32%|███▏      | 925/2863 [11:05<25:35,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 925: train loss 2.27044. lr 5.620978e-04:  32%|███▏      | 925/2863 [11:06<25:35,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 925: train loss 2.27044. lr 5.620978e-04:  32%|███▏      | 926/2863 [11:06<25:38,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 926: train loss 2.34067. lr 5.620176e-04:  32%|███▏      | 926/2863 [11:07<25:38,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 926: train loss 2.34067. lr 5.620176e-04:  32%|███▏      | 927/2863 [11:07<25:37,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 927: train loss 2.32859. lr 5.619374e-04:  32%|███▏      | 927/2863 [11:07<25:37,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 927: train loss 2.32859. lr 5.619374e-04:  32%|███▏      | 928/2863 [11:07<25:25,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 928: train loss 2.23542. lr 5.618571e-04:  32%|███▏      | 928/2863 [11:08<25:25,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 928: train loss 2.23542. lr 5.618571e-04:  32%|███▏      | 929/2863 [11:08<25:27,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 929: train loss 2.25938. lr 5.617767e-04:  32%|███▏      | 929/2863 [11:09<25:27,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 929: train loss 2.25938. lr 5.617767e-04:  32%|███▏      | 930/2863 [11:09<25:33,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 930: train loss 2.29763. lr 5.616962e-04:  32%|███▏      | 930/2863 [11:10<25:33,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 930: train loss 2.29763. lr 5.616962e-04:  33%|███▎      | 931/2863 [11:10<25:30,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 931: train loss 2.19845. lr 5.616157e-04:  33%|███▎      | 931/2863 [11:11<25:30,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 931: train loss 2.19845. lr 5.616157e-04:  33%|███▎      | 932/2863 [11:11<25:33,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 932: train loss 2.25184. lr 5.615351e-04:  33%|███▎      | 932/2863 [11:11<25:33,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 932: train loss 2.25184. lr 5.615351e-04:  33%|███▎      | 933/2863 [11:11<25:36,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 933: train loss 2.26485. lr 5.614544e-04:  33%|███▎      | 933/2863 [11:12<25:36,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 933: train loss 2.26485. lr 5.614544e-04:  33%|███▎      | 934/2863 [11:12<25:30,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 934: train loss 2.26800. lr 5.613736e-04:  33%|███▎      | 934/2863 [11:13<25:30,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 934: train loss 2.26800. lr 5.613736e-04:  33%|███▎      | 935/2863 [11:13<25:25,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 935: train loss 2.19726. lr 5.612928e-04:  33%|███▎      | 935/2863 [11:14<25:25,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 935: train loss 2.19726. lr 5.612928e-04:  33%|███▎      | 936/2863 [11:14<25:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 936: train loss 2.27886. lr 5.612118e-04:  33%|███▎      | 936/2863 [11:14<25:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 936: train loss 2.27886. lr 5.612118e-04:  33%|███▎      | 937/2863 [11:14<25:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 937: train loss 2.26741. lr 5.611308e-04:  33%|███▎      | 937/2863 [11:15<25:19,  1.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 937: train loss 2.26741. lr 5.611308e-04:  33%|███▎      | 938/2863 [11:15<26:18,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 938: train loss 2.26830. lr 5.610497e-04:  33%|███▎      | 938/2863 [11:16<26:18,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 938: train loss 2.26830. lr 5.610497e-04:  33%|███▎      | 939/2863 [11:16<25:57,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 939: train loss 2.17876. lr 5.609685e-04:  33%|███▎      | 939/2863 [11:17<25:57,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 939: train loss 2.17876. lr 5.609685e-04:  33%|███▎      | 940/2863 [11:17<25:47,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 940: train loss 2.19383. lr 5.608873e-04:  33%|███▎      | 940/2863 [11:18<25:47,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 940: train loss 2.19383. lr 5.608873e-04:  33%|███▎      | 941/2863 [11:18<25:41,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 941: train loss 2.17068. lr 5.608060e-04:  33%|███▎      | 941/2863 [11:19<25:41,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 941: train loss 2.17068. lr 5.608060e-04:  33%|███▎      | 942/2863 [11:19<25:34,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 942: train loss 2.19783. lr 5.607246e-04:  33%|███▎      | 942/2863 [11:19<25:34,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 942: train loss 2.19783. lr 5.607246e-04:  33%|███▎      | 943/2863 [11:19<25:24,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 943: train loss 2.18417. lr 5.606431e-04:  33%|███▎      | 943/2863 [11:20<25:24,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 943: train loss 2.18417. lr 5.606431e-04:  33%|███▎      | 944/2863 [11:20<25:24,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 944: train loss 2.22315. lr 5.605615e-04:  33%|███▎      | 944/2863 [11:21<25:24,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 944: train loss 2.22315. lr 5.605615e-04:  33%|███▎      | 945/2863 [11:21<25:24,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 945: train loss 2.19614. lr 5.604799e-04:  33%|███▎      | 945/2863 [11:22<25:24,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 945: train loss 2.19614. lr 5.604799e-04:  33%|███▎      | 946/2863 [11:22<25:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 946: train loss 2.19557. lr 5.603981e-04:  33%|███▎      | 946/2863 [11:22<25:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 946: train loss 2.19557. lr 5.603981e-04:  33%|███▎      | 947/2863 [11:22<25:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 947: train loss 2.14060. lr 5.603163e-04:  33%|███▎      | 947/2863 [11:23<25:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 947: train loss 2.14060. lr 5.603163e-04:  33%|███▎      | 948/2863 [11:23<25:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 948: train loss 2.14211. lr 5.602345e-04:  33%|███▎      | 948/2863 [11:24<25:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 948: train loss 2.14211. lr 5.602345e-04:  33%|███▎      | 949/2863 [11:24<25:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 949: train loss 2.21055. lr 5.601525e-04:  33%|███▎      | 949/2863 [11:25<25:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 949: train loss 2.21055. lr 5.601525e-04:  33%|███▎      | 950/2863 [11:25<25:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 950: train loss 2.21328. lr 5.600705e-04:  33%|███▎      | 950/2863 [11:26<25:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 950: train loss 2.21328. lr 5.600705e-04:  33%|███▎      | 951/2863 [11:26<25:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 951: train loss 2.18305. lr 5.599884e-04:  33%|███▎      | 951/2863 [11:26<25:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 951: train loss 2.18305. lr 5.599884e-04:  33%|███▎      | 952/2863 [11:26<25:16,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 952: train loss 2.09724. lr 5.599062e-04:  33%|███▎      | 952/2863 [11:27<25:16,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 952: train loss 2.09724. lr 5.599062e-04:  33%|███▎      | 953/2863 [11:27<25:14,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 953: train loss 2.15827. lr 5.598239e-04:  33%|███▎      | 953/2863 [11:28<25:14,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 953: train loss 2.15827. lr 5.598239e-04:  33%|███▎      | 954/2863 [11:28<25:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 954: train loss 2.16411. lr 5.597416e-04:  33%|███▎      | 954/2863 [11:29<25:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 954: train loss 2.16411. lr 5.597416e-04:  33%|███▎      | 955/2863 [11:29<24:56,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 955: train loss 2.14200. lr 5.596591e-04:  33%|███▎      | 955/2863 [11:30<24:56,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 955: train loss 2.14200. lr 5.596591e-04:  33%|███▎      | 956/2863 [11:30<25:02,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 956: train loss 2.15049. lr 5.595766e-04:  33%|███▎      | 956/2863 [11:30<25:02,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 956: train loss 2.15049. lr 5.595766e-04:  33%|███▎      | 957/2863 [11:30<25:08,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 957: train loss 2.13783. lr 5.594941e-04:  33%|███▎      | 957/2863 [11:31<25:08,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 957: train loss 2.13783. lr 5.594941e-04:  33%|███▎      | 958/2863 [11:31<25:18,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 958: train loss 2.08678. lr 5.594114e-04:  33%|███▎      | 958/2863 [11:32<25:18,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 958: train loss 2.08678. lr 5.594114e-04:  33%|███▎      | 959/2863 [11:32<25:10,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 959: train loss 2.08025. lr 5.593287e-04:  33%|███▎      | 959/2863 [11:33<25:10,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 959: train loss 2.08025. lr 5.593287e-04:  34%|███▎      | 960/2863 [11:33<25:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 960: train loss 2.17994. lr 5.592458e-04:  34%|███▎      | 960/2863 [11:34<25:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 960: train loss 2.17994. lr 5.592458e-04:  34%|███▎      | 961/2863 [11:34<25:01,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 961: train loss 2.12299. lr 5.591629e-04:  34%|███▎      | 961/2863 [11:34<25:01,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 961: train loss 2.12299. lr 5.591629e-04:  34%|███▎      | 962/2863 [11:34<25:06,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 962: train loss 2.11915. lr 5.590800e-04:  34%|███▎      | 962/2863 [11:35<25:06,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 962: train loss 2.11915. lr 5.590800e-04:  34%|███▎      | 963/2863 [11:35<25:15,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 963: train loss 2.11303. lr 5.589969e-04:  34%|███▎      | 963/2863 [11:36<25:15,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 963: train loss 2.11303. lr 5.589969e-04:  34%|███▎      | 964/2863 [11:36<25:10,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 964: train loss 2.09835. lr 5.589138e-04:  34%|███▎      | 964/2863 [11:37<25:10,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 964: train loss 2.09835. lr 5.589138e-04:  34%|███▎      | 965/2863 [11:37<25:08,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 965: train loss 2.09606. lr 5.588306e-04:  34%|███▎      | 965/2863 [11:38<25:08,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 965: train loss 2.09606. lr 5.588306e-04:  34%|███▎      | 966/2863 [11:38<26:28,  1.19it/s]\u001b[A\n",
      "epoch 1 iter 966: train loss 2.09963. lr 5.587473e-04:  34%|███▎      | 966/2863 [11:38<26:28,  1.19it/s]\u001b[A\n",
      "epoch 1 iter 966: train loss 2.09963. lr 5.587473e-04:  34%|███▍      | 967/2863 [11:38<25:56,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 967: train loss 2.09476. lr 5.586639e-04:  34%|███▍      | 967/2863 [11:39<25:56,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 967: train loss 2.09476. lr 5.586639e-04:  34%|███▍      | 968/2863 [11:39<25:44,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 968: train loss 2.09674. lr 5.585805e-04:  34%|███▍      | 968/2863 [11:40<25:44,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 968: train loss 2.09674. lr 5.585805e-04:  34%|███▍      | 969/2863 [11:40<25:39,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 969: train loss 2.04579. lr 5.584970e-04:  34%|███▍      | 969/2863 [11:41<25:39,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 969: train loss 2.04579. lr 5.584970e-04:  34%|███▍      | 970/2863 [11:41<25:23,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 970: train loss 2.10974. lr 5.584134e-04:  34%|███▍      | 970/2863 [11:42<25:23,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 970: train loss 2.10974. lr 5.584134e-04:  34%|███▍      | 971/2863 [11:42<25:16,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 971: train loss 2.08351. lr 5.583297e-04:  34%|███▍      | 971/2863 [11:42<25:16,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 971: train loss 2.08351. lr 5.583297e-04:  34%|███▍      | 972/2863 [11:42<25:15,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 972: train loss 2.06402. lr 5.582460e-04:  34%|███▍      | 972/2863 [11:43<25:15,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 972: train loss 2.06402. lr 5.582460e-04:  34%|███▍      | 973/2863 [11:43<25:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 973: train loss 2.02754. lr 5.581621e-04:  34%|███▍      | 973/2863 [11:44<25:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 973: train loss 2.02754. lr 5.581621e-04:  34%|███▍      | 974/2863 [11:44<25:04,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 974: train loss 2.07530. lr 5.580782e-04:  34%|███▍      | 974/2863 [11:45<25:04,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 974: train loss 2.07530. lr 5.580782e-04:  34%|███▍      | 975/2863 [11:45<24:59,  1.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 975: train loss 2.01166. lr 5.579942e-04:  34%|███▍      | 975/2863 [11:46<24:59,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 975: train loss 2.01166. lr 5.579942e-04:  34%|███▍      | 976/2863 [11:46<24:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 976: train loss 2.04251. lr 5.579102e-04:  34%|███▍      | 976/2863 [11:46<24:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 976: train loss 2.04251. lr 5.579102e-04:  34%|███▍      | 977/2863 [11:46<24:08,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 977: train loss 2.02280. lr 5.578260e-04:  34%|███▍      | 977/2863 [11:47<24:08,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 977: train loss 2.02280. lr 5.578260e-04:  34%|███▍      | 978/2863 [11:47<23:36,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 978: train loss 2.06348. lr 5.577418e-04:  34%|███▍      | 978/2863 [11:48<23:36,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 978: train loss 2.06348. lr 5.577418e-04:  34%|███▍      | 979/2863 [11:48<23:09,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 979: train loss 1.99259. lr 5.576575e-04:  34%|███▍      | 979/2863 [11:48<23:09,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 979: train loss 1.99259. lr 5.576575e-04:  34%|███▍      | 980/2863 [11:48<22:47,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 980: train loss 2.02304. lr 5.575732e-04:  34%|███▍      | 980/2863 [11:49<22:47,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 980: train loss 2.02304. lr 5.575732e-04:  34%|███▍      | 981/2863 [11:49<22:34,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 981: train loss 2.02554. lr 5.574887e-04:  34%|███▍      | 981/2863 [11:50<22:34,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 981: train loss 2.02554. lr 5.574887e-04:  34%|███▍      | 982/2863 [11:50<22:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 982: train loss 2.05506. lr 5.574042e-04:  34%|███▍      | 982/2863 [11:51<22:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 982: train loss 2.05506. lr 5.574042e-04:  34%|███▍      | 983/2863 [11:51<22:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 983: train loss 1.98544. lr 5.573196e-04:  34%|███▍      | 983/2863 [11:51<22:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 983: train loss 1.98544. lr 5.573196e-04:  34%|███▍      | 984/2863 [11:51<22:07,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 984: train loss 1.96923. lr 5.572349e-04:  34%|███▍      | 984/2863 [11:52<22:07,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 984: train loss 1.96923. lr 5.572349e-04:  34%|███▍      | 985/2863 [11:52<22:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 985: train loss 1.95511. lr 5.571501e-04:  34%|███▍      | 985/2863 [11:53<22:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 985: train loss 1.95511. lr 5.571501e-04:  34%|███▍      | 986/2863 [11:53<22:01,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 986: train loss 2.01930. lr 5.570653e-04:  34%|███▍      | 986/2863 [11:53<22:01,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 986: train loss 2.01930. lr 5.570653e-04:  34%|███▍      | 987/2863 [11:53<22:45,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 987: train loss 1.92062. lr 5.569804e-04:  34%|███▍      | 987/2863 [11:54<22:45,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 987: train loss 1.92062. lr 5.569804e-04:  35%|███▍      | 988/2863 [11:54<23:26,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 988: train loss 1.98681. lr 5.568954e-04:  35%|███▍      | 988/2863 [11:55<23:26,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 988: train loss 1.98681. lr 5.568954e-04:  35%|███▍      | 989/2863 [11:55<23:44,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 989: train loss 2.01552. lr 5.568103e-04:  35%|███▍      | 989/2863 [11:56<23:44,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 989: train loss 2.01552. lr 5.568103e-04:  35%|███▍      | 990/2863 [11:56<23:44,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 990: train loss 2.04059. lr 5.567252e-04:  35%|███▍      | 990/2863 [11:56<23:44,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 990: train loss 2.04059. lr 5.567252e-04:  35%|███▍      | 991/2863 [11:56<23:31,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 991: train loss 1.96495. lr 5.566399e-04:  35%|███▍      | 991/2863 [11:57<23:31,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 991: train loss 1.96495. lr 5.566399e-04:  35%|███▍      | 992/2863 [11:57<23:26,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 992: train loss 1.91785. lr 5.565546e-04:  35%|███▍      | 992/2863 [11:58<23:26,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 992: train loss 1.91785. lr 5.565546e-04:  35%|███▍      | 993/2863 [11:58<23:08,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 993: train loss 1.95718. lr 5.564693e-04:  35%|███▍      | 993/2863 [11:59<23:08,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 993: train loss 1.95718. lr 5.564693e-04:  35%|███▍      | 994/2863 [11:59<23:57,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 994: train loss 1.93905. lr 5.563838e-04:  35%|███▍      | 994/2863 [12:00<23:57,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 994: train loss 1.93905. lr 5.563838e-04:  35%|███▍      | 995/2863 [12:00<23:49,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 995: train loss 1.96879. lr 5.562983e-04:  35%|███▍      | 995/2863 [12:00<23:49,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 995: train loss 1.96879. lr 5.562983e-04:  35%|███▍      | 996/2863 [12:00<23:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 996: train loss 1.95480. lr 5.562127e-04:  35%|███▍      | 996/2863 [12:01<23:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 996: train loss 1.95480. lr 5.562127e-04:  35%|███▍      | 997/2863 [12:01<22:43,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 997: train loss 1.92122. lr 5.561270e-04:  35%|███▍      | 997/2863 [12:02<22:43,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 997: train loss 1.92122. lr 5.561270e-04:  35%|███▍      | 998/2863 [12:02<22:23,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 998: train loss 1.93727. lr 5.560412e-04:  35%|███▍      | 998/2863 [12:02<22:23,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 998: train loss 1.93727. lr 5.560412e-04:  35%|███▍      | 999/2863 [12:02<22:07,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 999: train loss 1.92159. lr 5.559554e-04:  35%|███▍      | 999/2863 [12:03<22:07,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 999: train loss 1.92159. lr 5.559554e-04:  35%|███▍      | 1000/2863 [12:03<21:56,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1000: train loss 1.95031. lr 5.558694e-04:  35%|███▍      | 1000/2863 [12:04<21:56,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1000: train loss 1.95031. lr 5.558694e-04:  35%|███▍      | 1001/2863 [12:04<21:53,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1001: train loss 1.90520. lr 5.557834e-04:  35%|███▍      | 1001/2863 [12:04<21:53,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1001: train loss 1.90520. lr 5.557834e-04:  35%|███▍      | 1002/2863 [12:04<21:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1002: train loss 1.88925. lr 5.556974e-04:  35%|███▍      | 1002/2863 [12:05<21:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1002: train loss 1.88925. lr 5.556974e-04:  35%|███▌      | 1003/2863 [12:05<22:00,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1003: train loss 1.94310. lr 5.556112e-04:  35%|███▌      | 1003/2863 [12:06<22:00,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1003: train loss 1.94310. lr 5.556112e-04:  35%|███▌      | 1004/2863 [12:06<22:22,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1004: train loss 1.85157. lr 5.555250e-04:  35%|███▌      | 1004/2863 [12:07<22:22,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1004: train loss 1.85157. lr 5.555250e-04:  35%|███▌      | 1005/2863 [12:07<22:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1005: train loss 1.93186. lr 5.554387e-04:  35%|███▌      | 1005/2863 [12:07<22:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1005: train loss 1.93186. lr 5.554387e-04:  35%|███▌      | 1006/2863 [12:07<21:55,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1006: train loss 1.90833. lr 5.553523e-04:  35%|███▌      | 1006/2863 [12:08<21:55,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1006: train loss 1.90833. lr 5.553523e-04:  35%|███▌      | 1007/2863 [12:08<22:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1007: train loss 1.89407. lr 5.552658e-04:  35%|███▌      | 1007/2863 [12:09<22:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1007: train loss 1.89407. lr 5.552658e-04:  35%|███▌      | 1008/2863 [12:09<22:28,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1008: train loss 1.88731. lr 5.551793e-04:  35%|███▌      | 1008/2863 [12:10<22:28,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1008: train loss 1.88731. lr 5.551793e-04:  35%|███▌      | 1009/2863 [12:10<22:38,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1009: train loss 1.85819. lr 5.550927e-04:  35%|███▌      | 1009/2863 [12:10<22:38,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1009: train loss 1.85819. lr 5.550927e-04:  35%|███▌      | 1010/2863 [12:10<22:31,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1010: train loss 1.89094. lr 5.550060e-04:  35%|███▌      | 1010/2863 [12:11<22:31,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1010: train loss 1.89094. lr 5.550060e-04:  35%|███▌      | 1011/2863 [12:11<22:52,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1011: train loss 1.85258. lr 5.549192e-04:  35%|███▌      | 1011/2863 [12:12<22:52,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1011: train loss 1.85258. lr 5.549192e-04:  35%|███▌      | 1012/2863 [12:12<22:42,  1.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1012: train loss 1.86569. lr 5.548324e-04:  35%|███▌      | 1012/2863 [12:12<22:42,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1012: train loss 1.86569. lr 5.548324e-04:  35%|███▌      | 1013/2863 [12:12<22:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1013: train loss 1.84363. lr 5.547455e-04:  35%|███▌      | 1013/2863 [12:13<22:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1013: train loss 1.84363. lr 5.547455e-04:  35%|███▌      | 1014/2863 [12:13<22:03,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1014: train loss 1.87550. lr 5.546585e-04:  35%|███▌      | 1014/2863 [12:14<22:03,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1014: train loss 1.87550. lr 5.546585e-04:  35%|███▌      | 1015/2863 [12:14<21:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1015: train loss 1.81581. lr 5.545714e-04:  35%|███▌      | 1015/2863 [12:15<21:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1015: train loss 1.81581. lr 5.545714e-04:  35%|███▌      | 1016/2863 [12:15<21:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1016: train loss 1.82141. lr 5.544843e-04:  35%|███▌      | 1016/2863 [12:15<21:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1016: train loss 1.82141. lr 5.544843e-04:  36%|███▌      | 1017/2863 [12:15<21:40,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1017: train loss 1.85687. lr 5.543970e-04:  36%|███▌      | 1017/2863 [12:16<21:40,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1017: train loss 1.85687. lr 5.543970e-04:  36%|███▌      | 1018/2863 [12:16<21:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1018: train loss 1.80122. lr 5.543097e-04:  36%|███▌      | 1018/2863 [12:17<21:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1018: train loss 1.80122. lr 5.543097e-04:  36%|███▌      | 1019/2863 [12:17<22:28,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1019: train loss 1.88373. lr 5.542224e-04:  36%|███▌      | 1019/2863 [12:18<22:28,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1019: train loss 1.88373. lr 5.542224e-04:  36%|███▌      | 1020/2863 [12:18<22:51,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1020: train loss 1.86362. lr 5.541349e-04:  36%|███▌      | 1020/2863 [12:18<22:51,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1020: train loss 1.86362. lr 5.541349e-04:  36%|███▌      | 1021/2863 [12:18<23:01,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1021: train loss 1.79869. lr 5.540474e-04:  36%|███▌      | 1021/2863 [12:19<23:01,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1021: train loss 1.79869. lr 5.540474e-04:  36%|███▌      | 1022/2863 [12:19<23:57,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1022: train loss 1.87983. lr 5.539598e-04:  36%|███▌      | 1022/2863 [12:20<23:57,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1022: train loss 1.87983. lr 5.539598e-04:  36%|███▌      | 1023/2863 [12:20<23:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1023: train loss 1.80506. lr 5.538721e-04:  36%|███▌      | 1023/2863 [12:21<23:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1023: train loss 1.80506. lr 5.538721e-04:  36%|███▌      | 1024/2863 [12:21<24:20,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1024: train loss 1.85155. lr 5.537843e-04:  36%|███▌      | 1024/2863 [12:22<24:20,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1024: train loss 1.85155. lr 5.537843e-04:  36%|███▌      | 1025/2863 [12:22<24:48,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1025: train loss 1.86109. lr 5.536965e-04:  36%|███▌      | 1025/2863 [12:22<24:48,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1025: train loss 1.86109. lr 5.536965e-04:  36%|███▌      | 1026/2863 [12:22<24:27,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1026: train loss 1.82026. lr 5.536086e-04:  36%|███▌      | 1026/2863 [12:23<24:27,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1026: train loss 1.82026. lr 5.536086e-04:  36%|███▌      | 1027/2863 [12:23<24:04,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1027: train loss 1.79483. lr 5.535206e-04:  36%|███▌      | 1027/2863 [12:24<24:04,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1027: train loss 1.79483. lr 5.535206e-04:  36%|███▌      | 1028/2863 [12:24<23:22,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1028: train loss 1.81557. lr 5.534325e-04:  36%|███▌      | 1028/2863 [12:25<23:22,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1028: train loss 1.81557. lr 5.534325e-04:  36%|███▌      | 1029/2863 [12:25<22:41,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1029: train loss 1.76822. lr 5.533444e-04:  36%|███▌      | 1029/2863 [12:25<22:41,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1029: train loss 1.76822. lr 5.533444e-04:  36%|███▌      | 1030/2863 [12:25<22:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1030: train loss 1.81861. lr 5.532561e-04:  36%|███▌      | 1030/2863 [12:26<22:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1030: train loss 1.81861. lr 5.532561e-04:  36%|███▌      | 1031/2863 [12:26<22:33,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1031: train loss 1.80283. lr 5.531678e-04:  36%|███▌      | 1031/2863 [12:27<22:33,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1031: train loss 1.80283. lr 5.531678e-04:  36%|███▌      | 1032/2863 [12:27<22:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1032: train loss 1.82537. lr 5.530795e-04:  36%|███▌      | 1032/2863 [12:27<22:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1032: train loss 1.82537. lr 5.530795e-04:  36%|███▌      | 1033/2863 [12:27<21:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1033: train loss 1.76701. lr 5.529910e-04:  36%|███▌      | 1033/2863 [12:28<21:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1033: train loss 1.76701. lr 5.529910e-04:  36%|███▌      | 1034/2863 [12:28<22:04,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1034: train loss 1.80944. lr 5.529025e-04:  36%|███▌      | 1034/2863 [12:29<22:04,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1034: train loss 1.80944. lr 5.529025e-04:  36%|███▌      | 1035/2863 [12:29<22:18,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1035: train loss 1.76699. lr 5.528139e-04:  36%|███▌      | 1035/2863 [12:30<22:18,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1035: train loss 1.76699. lr 5.528139e-04:  36%|███▌      | 1036/2863 [12:30<21:58,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1036: train loss 1.79775. lr 5.527252e-04:  36%|███▌      | 1036/2863 [12:30<21:58,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1036: train loss 1.79775. lr 5.527252e-04:  36%|███▌      | 1037/2863 [12:30<21:43,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1037: train loss 1.77061. lr 5.526365e-04:  36%|███▌      | 1037/2863 [12:31<21:43,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1037: train loss 1.77061. lr 5.526365e-04:  36%|███▋      | 1038/2863 [12:31<21:30,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1038: train loss 1.76779. lr 5.525476e-04:  36%|███▋      | 1038/2863 [12:32<21:30,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1038: train loss 1.76779. lr 5.525476e-04:  36%|███▋      | 1039/2863 [12:32<22:03,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1039: train loss 1.69092. lr 5.524587e-04:  36%|███▋      | 1039/2863 [12:32<22:03,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1039: train loss 1.69092. lr 5.524587e-04:  36%|███▋      | 1040/2863 [12:32<22:22,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1040: train loss 1.67567. lr 5.523697e-04:  36%|███▋      | 1040/2863 [12:33<22:22,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1040: train loss 1.67567. lr 5.523697e-04:  36%|███▋      | 1041/2863 [12:33<22:35,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1041: train loss 1.74723. lr 5.522807e-04:  36%|███▋      | 1041/2863 [12:34<22:35,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1041: train loss 1.74723. lr 5.522807e-04:  36%|███▋      | 1042/2863 [12:34<22:33,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1042: train loss 1.71620. lr 5.521915e-04:  36%|███▋      | 1042/2863 [12:35<22:33,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1042: train loss 1.71620. lr 5.521915e-04:  36%|███▋      | 1043/2863 [12:35<22:38,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1043: train loss 1.70420. lr 5.521023e-04:  36%|███▋      | 1043/2863 [12:36<22:38,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1043: train loss 1.70420. lr 5.521023e-04:  36%|███▋      | 1044/2863 [12:36<22:48,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1044: train loss 1.81917. lr 5.520130e-04:  36%|███▋      | 1044/2863 [12:36<22:48,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1044: train loss 1.81917. lr 5.520130e-04:  37%|███▋      | 1045/2863 [12:36<22:42,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1045: train loss 1.78661. lr 5.519237e-04:  37%|███▋      | 1045/2863 [12:37<22:42,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1045: train loss 1.78661. lr 5.519237e-04:  37%|███▋      | 1046/2863 [12:37<23:28,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1046: train loss 1.74746. lr 5.518343e-04:  37%|███▋      | 1046/2863 [12:38<23:28,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1046: train loss 1.74746. lr 5.518343e-04:  37%|███▋      | 1047/2863 [12:38<23:57,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1047: train loss 1.66596. lr 5.517447e-04:  37%|███▋      | 1047/2863 [12:39<23:57,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1047: train loss 1.66596. lr 5.517447e-04:  37%|███▋      | 1048/2863 [12:39<23:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1048: train loss 1.66248. lr 5.516551e-04:  37%|███▋      | 1048/2863 [12:39<23:52,  1.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1048: train loss 1.66248. lr 5.516551e-04:  37%|███▋      | 1049/2863 [12:39<23:13,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1049: train loss 1.72743. lr 5.515655e-04:  37%|███▋      | 1049/2863 [12:40<23:13,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1049: train loss 1.72743. lr 5.515655e-04:  37%|███▋      | 1050/2863 [12:40<23:47,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1050: train loss 1.76295. lr 5.514757e-04:  37%|███▋      | 1050/2863 [12:41<23:47,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1050: train loss 1.76295. lr 5.514757e-04:  37%|███▋      | 1051/2863 [12:41<23:03,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1051: train loss 1.73266. lr 5.513859e-04:  37%|███▋      | 1051/2863 [12:42<23:03,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1051: train loss 1.73266. lr 5.513859e-04:  37%|███▋      | 1052/2863 [12:42<22:30,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1052: train loss 1.65312. lr 5.512960e-04:  37%|███▋      | 1052/2863 [12:42<22:30,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1052: train loss 1.65312. lr 5.512960e-04:  37%|███▋      | 1053/2863 [12:42<22:08,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1053: train loss 1.69840. lr 5.512061e-04:  37%|███▋      | 1053/2863 [12:43<22:08,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1053: train loss 1.69840. lr 5.512061e-04:  37%|███▋      | 1054/2863 [12:43<21:48,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1054: train loss 1.69049. lr 5.511160e-04:  37%|███▋      | 1054/2863 [12:44<21:48,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1054: train loss 1.69049. lr 5.511160e-04:  37%|███▋      | 1055/2863 [12:44<21:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1055: train loss 1.68369. lr 5.510259e-04:  37%|███▋      | 1055/2863 [12:45<21:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1055: train loss 1.68369. lr 5.510259e-04:  37%|███▋      | 1056/2863 [12:45<21:49,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1056: train loss 1.71633. lr 5.509357e-04:  37%|███▋      | 1056/2863 [12:45<21:49,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1056: train loss 1.71633. lr 5.509357e-04:  37%|███▋      | 1057/2863 [12:45<22:00,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1057: train loss 1.70846. lr 5.508454e-04:  37%|███▋      | 1057/2863 [12:46<22:00,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1057: train loss 1.70846. lr 5.508454e-04:  37%|███▋      | 1058/2863 [12:46<21:39,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1058: train loss 1.68393. lr 5.507551e-04:  37%|███▋      | 1058/2863 [12:47<21:39,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1058: train loss 1.68393. lr 5.507551e-04:  37%|███▋      | 1059/2863 [12:47<21:28,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1059: train loss 1.65519. lr 5.506647e-04:  37%|███▋      | 1059/2863 [12:47<21:28,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1059: train loss 1.65519. lr 5.506647e-04:  37%|███▋      | 1060/2863 [12:47<21:20,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1060: train loss 1.62856. lr 5.505742e-04:  37%|███▋      | 1060/2863 [12:48<21:20,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1060: train loss 1.62856. lr 5.505742e-04:  37%|███▋      | 1061/2863 [12:48<21:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1061: train loss 1.66866. lr 5.504836e-04:  37%|███▋      | 1061/2863 [12:49<21:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1061: train loss 1.66866. lr 5.504836e-04:  37%|███▋      | 1062/2863 [12:49<21:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1062: train loss 1.56781. lr 5.503929e-04:  37%|███▋      | 1062/2863 [12:50<21:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1062: train loss 1.56781. lr 5.503929e-04:  37%|███▋      | 1063/2863 [12:50<21:30,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1063: train loss 1.67942. lr 5.503022e-04:  37%|███▋      | 1063/2863 [12:50<21:30,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1063: train loss 1.67942. lr 5.503022e-04:  37%|███▋      | 1064/2863 [12:50<21:28,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1064: train loss 1.66641. lr 5.502114e-04:  37%|███▋      | 1064/2863 [12:51<21:28,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1064: train loss 1.66641. lr 5.502114e-04:  37%|███▋      | 1065/2863 [12:51<21:16,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1065: train loss 1.60875. lr 5.501206e-04:  37%|███▋      | 1065/2863 [12:52<21:16,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1065: train loss 1.60875. lr 5.501206e-04:  37%|███▋      | 1066/2863 [12:52<21:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1066: train loss 1.63041. lr 5.500296e-04:  37%|███▋      | 1066/2863 [12:52<21:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1066: train loss 1.63041. lr 5.500296e-04:  37%|███▋      | 1067/2863 [12:52<22:02,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1067: train loss 1.66624. lr 5.499386e-04:  37%|███▋      | 1067/2863 [12:53<22:02,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1067: train loss 1.66624. lr 5.499386e-04:  37%|███▋      | 1068/2863 [12:53<21:47,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1068: train loss 1.70149. lr 5.498475e-04:  37%|███▋      | 1068/2863 [12:54<21:47,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1068: train loss 1.70149. lr 5.498475e-04:  37%|███▋      | 1069/2863 [12:54<21:33,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1069: train loss 1.63230. lr 5.497563e-04:  37%|███▋      | 1069/2863 [12:55<21:33,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1069: train loss 1.63230. lr 5.497563e-04:  37%|███▋      | 1070/2863 [12:55<21:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1070: train loss 1.60002. lr 5.496651e-04:  37%|███▋      | 1070/2863 [12:55<21:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1070: train loss 1.60002. lr 5.496651e-04:  37%|███▋      | 1071/2863 [12:55<22:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1071: train loss 1.60641. lr 5.495737e-04:  37%|███▋      | 1071/2863 [12:56<22:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1071: train loss 1.60641. lr 5.495737e-04:  37%|███▋      | 1072/2863 [12:56<22:24,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1072: train loss 1.59816. lr 5.494823e-04:  37%|███▋      | 1072/2863 [12:57<22:24,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1072: train loss 1.59816. lr 5.494823e-04:  37%|███▋      | 1073/2863 [12:57<21:56,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1073: train loss 1.61185. lr 5.493908e-04:  37%|███▋      | 1073/2863 [12:58<21:56,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1073: train loss 1.61185. lr 5.493908e-04:  38%|███▊      | 1074/2863 [12:58<21:37,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1074: train loss 1.59184. lr 5.492993e-04:  38%|███▊      | 1074/2863 [12:58<21:37,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1074: train loss 1.59184. lr 5.492993e-04:  38%|███▊      | 1075/2863 [12:58<21:25,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1075: train loss 1.62432. lr 5.492077e-04:  38%|███▊      | 1075/2863 [12:59<21:25,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1075: train loss 1.62432. lr 5.492077e-04:  38%|███▊      | 1076/2863 [12:59<21:16,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1076: train loss 1.55744. lr 5.491160e-04:  38%|███▊      | 1076/2863 [13:00<21:16,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1076: train loss 1.55744. lr 5.491160e-04:  38%|███▊      | 1077/2863 [13:00<21:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1077: train loss 1.55492. lr 5.490242e-04:  38%|███▊      | 1077/2863 [13:00<21:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1077: train loss 1.55492. lr 5.490242e-04:  38%|███▊      | 1078/2863 [13:00<22:26,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1078: train loss 1.56280. lr 5.489323e-04:  38%|███▊      | 1078/2863 [13:01<22:26,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1078: train loss 1.56280. lr 5.489323e-04:  38%|███▊      | 1079/2863 [13:01<22:02,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1079: train loss 1.59006. lr 5.488404e-04:  38%|███▊      | 1079/2863 [13:02<22:02,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1079: train loss 1.59006. lr 5.488404e-04:  38%|███▊      | 1080/2863 [13:02<21:39,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1080: train loss 1.60729. lr 5.487484e-04:  38%|███▊      | 1080/2863 [13:03<21:39,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1080: train loss 1.60729. lr 5.487484e-04:  38%|███▊      | 1081/2863 [13:03<22:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1081: train loss 1.60157. lr 5.486563e-04:  38%|███▊      | 1081/2863 [13:03<22:24,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1081: train loss 1.60157. lr 5.486563e-04:  38%|███▊      | 1082/2863 [13:03<22:29,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1082: train loss 1.58129. lr 5.485642e-04:  38%|███▊      | 1082/2863 [13:04<22:29,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1082: train loss 1.58129. lr 5.485642e-04:  38%|███▊      | 1083/2863 [13:04<22:01,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1083: train loss 1.60363. lr 5.484720e-04:  38%|███▊      | 1083/2863 [13:05<22:01,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1083: train loss 1.60363. lr 5.484720e-04:  38%|███▊      | 1084/2863 [13:05<21:47,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1084: train loss 1.56633. lr 5.483797e-04:  38%|███▊      | 1084/2863 [13:06<21:47,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1084: train loss 1.56633. lr 5.483797e-04:  38%|███▊      | 1085/2863 [13:06<21:43,  1.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1085: train loss 1.58479. lr 5.482873e-04:  38%|███▊      | 1085/2863 [13:06<21:43,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1085: train loss 1.58479. lr 5.482873e-04:  38%|███▊      | 1086/2863 [13:06<21:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1086: train loss 1.51994. lr 5.481948e-04:  38%|███▊      | 1086/2863 [13:07<21:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1086: train loss 1.51994. lr 5.481948e-04:  38%|███▊      | 1087/2863 [13:07<21:31,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1087: train loss 1.55061. lr 5.481023e-04:  38%|███▊      | 1087/2863 [13:08<21:31,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1087: train loss 1.55061. lr 5.481023e-04:  38%|███▊      | 1088/2863 [13:08<21:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1088: train loss 1.56923. lr 5.480097e-04:  38%|███▊      | 1088/2863 [13:09<21:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1088: train loss 1.56923. lr 5.480097e-04:  38%|███▊      | 1089/2863 [13:09<22:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1089: train loss 1.55612. lr 5.479170e-04:  38%|███▊      | 1089/2863 [13:09<22:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1089: train loss 1.55612. lr 5.479170e-04:  38%|███▊      | 1090/2863 [13:09<23:11,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1090: train loss 1.57339. lr 5.478243e-04:  38%|███▊      | 1090/2863 [13:10<23:11,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1090: train loss 1.57339. lr 5.478243e-04:  38%|███▊      | 1091/2863 [13:10<23:04,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1091: train loss 1.57599. lr 5.477315e-04:  38%|███▊      | 1091/2863 [13:11<23:04,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1091: train loss 1.57599. lr 5.477315e-04:  38%|███▊      | 1092/2863 [13:11<22:19,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1092: train loss 1.54137. lr 5.476386e-04:  38%|███▊      | 1092/2863 [13:12<22:19,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1092: train loss 1.54137. lr 5.476386e-04:  38%|███▊      | 1093/2863 [13:12<21:52,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1093: train loss 1.52889. lr 5.475456e-04:  38%|███▊      | 1093/2863 [13:12<21:52,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1093: train loss 1.52889. lr 5.475456e-04:  38%|███▊      | 1094/2863 [13:12<21:24,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1094: train loss 1.53678. lr 5.474525e-04:  38%|███▊      | 1094/2863 [13:13<21:24,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1094: train loss 1.53678. lr 5.474525e-04:  38%|███▊      | 1095/2863 [13:13<22:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1095: train loss 1.48259. lr 5.473594e-04:  38%|███▊      | 1095/2863 [13:14<22:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1095: train loss 1.48259. lr 5.473594e-04:  38%|███▊      | 1096/2863 [13:14<22:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1096: train loss 1.56416. lr 5.472662e-04:  38%|███▊      | 1096/2863 [13:15<22:15,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1096: train loss 1.56416. lr 5.472662e-04:  38%|███▊      | 1097/2863 [13:15<21:47,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1097: train loss 1.55310. lr 5.471729e-04:  38%|███▊      | 1097/2863 [13:15<21:47,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1097: train loss 1.55310. lr 5.471729e-04:  38%|███▊      | 1098/2863 [13:15<21:25,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1098: train loss 1.53320. lr 5.470796e-04:  38%|███▊      | 1098/2863 [13:16<21:25,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1098: train loss 1.53320. lr 5.470796e-04:  38%|███▊      | 1099/2863 [13:16<21:06,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1099: train loss 1.47813. lr 5.469862e-04:  38%|███▊      | 1099/2863 [13:17<21:06,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1099: train loss 1.47813. lr 5.469862e-04:  38%|███▊      | 1100/2863 [13:17<20:51,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1100: train loss 1.53968. lr 5.468927e-04:  38%|███▊      | 1100/2863 [13:17<20:51,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1100: train loss 1.53968. lr 5.468927e-04:  38%|███▊      | 1101/2863 [13:17<20:55,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1101: train loss 1.50991. lr 5.467991e-04:  38%|███▊      | 1101/2863 [13:18<20:55,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1101: train loss 1.50991. lr 5.467991e-04:  38%|███▊      | 1102/2863 [13:18<21:40,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1102: train loss 1.49135. lr 5.467055e-04:  38%|███▊      | 1102/2863 [13:19<21:40,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1102: train loss 1.49135. lr 5.467055e-04:  39%|███▊      | 1103/2863 [13:19<21:27,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1103: train loss 1.49465. lr 5.466118e-04:  39%|███▊      | 1103/2863 [13:20<21:27,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1103: train loss 1.49465. lr 5.466118e-04:  39%|███▊      | 1104/2863 [13:20<21:19,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1104: train loss 1.47376. lr 5.465180e-04:  39%|███▊      | 1104/2863 [13:20<21:19,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1104: train loss 1.47376. lr 5.465180e-04:  39%|███▊      | 1105/2863 [13:20<21:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1105: train loss 1.51992. lr 5.464241e-04:  39%|███▊      | 1105/2863 [13:21<21:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1105: train loss 1.51992. lr 5.464241e-04:  39%|███▊      | 1106/2863 [13:21<22:13,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1106: train loss 1.50873. lr 5.463302e-04:  39%|███▊      | 1106/2863 [13:22<22:13,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1106: train loss 1.50873. lr 5.463302e-04:  39%|███▊      | 1107/2863 [13:22<22:01,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1107: train loss 1.43652. lr 5.462361e-04:  39%|███▊      | 1107/2863 [13:23<22:01,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1107: train loss 1.43652. lr 5.462361e-04:  39%|███▊      | 1108/2863 [13:23<21:47,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1108: train loss 1.49057. lr 5.461421e-04:  39%|███▊      | 1108/2863 [13:23<21:47,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1108: train loss 1.49057. lr 5.461421e-04:  39%|███▊      | 1109/2863 [13:23<21:31,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1109: train loss 1.46432. lr 5.460479e-04:  39%|███▊      | 1109/2863 [13:24<21:31,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1109: train loss 1.46432. lr 5.460479e-04:  39%|███▉      | 1110/2863 [13:24<21:10,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1110: train loss 1.43855. lr 5.459537e-04:  39%|███▉      | 1110/2863 [13:25<21:10,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1110: train loss 1.43855. lr 5.459537e-04:  39%|███▉      | 1111/2863 [13:25<21:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1111: train loss 1.48842. lr 5.458593e-04:  39%|███▉      | 1111/2863 [13:26<21:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1111: train loss 1.48842. lr 5.458593e-04:  39%|███▉      | 1112/2863 [13:26<21:31,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1112: train loss 1.43044. lr 5.457650e-04:  39%|███▉      | 1112/2863 [13:26<21:31,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1112: train loss 1.43044. lr 5.457650e-04:  39%|███▉      | 1113/2863 [13:26<21:13,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1113: train loss 1.44366. lr 5.456705e-04:  39%|███▉      | 1113/2863 [13:27<21:13,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1113: train loss 1.44366. lr 5.456705e-04:  39%|███▉      | 1114/2863 [13:27<20:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1114: train loss 1.46002. lr 5.455760e-04:  39%|███▉      | 1114/2863 [13:28<20:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1114: train loss 1.46002. lr 5.455760e-04:  39%|███▉      | 1115/2863 [13:28<20:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1115: train loss 1.43728. lr 5.454814e-04:  39%|███▉      | 1115/2863 [13:28<20:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1115: train loss 1.43728. lr 5.454814e-04:  39%|███▉      | 1116/2863 [13:28<21:12,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1116: train loss 1.46435. lr 5.453867e-04:  39%|███▉      | 1116/2863 [13:29<21:12,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1116: train loss 1.46435. lr 5.453867e-04:  39%|███▉      | 1117/2863 [13:29<20:53,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1117: train loss 1.42276. lr 5.452919e-04:  39%|███▉      | 1117/2863 [13:30<20:53,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1117: train loss 1.42276. lr 5.452919e-04:  39%|███▉      | 1118/2863 [13:30<20:40,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1118: train loss 1.45971. lr 5.451971e-04:  39%|███▉      | 1118/2863 [13:31<20:40,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1118: train loss 1.45971. lr 5.451971e-04:  39%|███▉      | 1119/2863 [13:31<20:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1119: train loss 1.42419. lr 5.451022e-04:  39%|███▉      | 1119/2863 [13:31<20:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1119: train loss 1.42419. lr 5.451022e-04:  39%|███▉      | 1120/2863 [13:31<20:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1120: train loss 1.40233. lr 5.450072e-04:  39%|███▉      | 1120/2863 [13:32<20:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1120: train loss 1.40233. lr 5.450072e-04:  39%|███▉      | 1121/2863 [13:32<20:48,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1121: train loss 1.44033. lr 5.449122e-04:  39%|███▉      | 1121/2863 [13:33<20:48,  1.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1121: train loss 1.44033. lr 5.449122e-04:  39%|███▉      | 1122/2863 [13:33<21:45,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1122: train loss 1.42607. lr 5.448170e-04:  39%|███▉      | 1122/2863 [13:34<21:45,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1122: train loss 1.42607. lr 5.448170e-04:  39%|███▉      | 1123/2863 [13:34<21:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1123: train loss 1.44140. lr 5.447218e-04:  39%|███▉      | 1123/2863 [13:34<21:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1123: train loss 1.44140. lr 5.447218e-04:  39%|███▉      | 1124/2863 [13:34<21:46,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1124: train loss 1.46040. lr 5.446266e-04:  39%|███▉      | 1124/2863 [13:35<21:46,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1124: train loss 1.46040. lr 5.446266e-04:  39%|███▉      | 1125/2863 [13:35<21:31,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1125: train loss 1.46338. lr 5.445312e-04:  39%|███▉      | 1125/2863 [13:36<21:31,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1125: train loss 1.46338. lr 5.445312e-04:  39%|███▉      | 1126/2863 [13:36<21:11,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1126: train loss 1.39031. lr 5.444358e-04:  39%|███▉      | 1126/2863 [13:37<21:11,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1126: train loss 1.39031. lr 5.444358e-04:  39%|███▉      | 1127/2863 [13:37<21:13,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1127: train loss 1.39436. lr 5.443403e-04:  39%|███▉      | 1127/2863 [13:37<21:13,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1127: train loss 1.39436. lr 5.443403e-04:  39%|███▉      | 1128/2863 [13:37<21:11,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1128: train loss 1.43049. lr 5.442447e-04:  39%|███▉      | 1128/2863 [13:38<21:11,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1128: train loss 1.43049. lr 5.442447e-04:  39%|███▉      | 1129/2863 [13:38<20:54,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1129: train loss 1.39408. lr 5.441491e-04:  39%|███▉      | 1129/2863 [13:39<20:54,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1129: train loss 1.39408. lr 5.441491e-04:  39%|███▉      | 1130/2863 [13:39<21:33,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1130: train loss 1.43463. lr 5.440534e-04:  39%|███▉      | 1130/2863 [13:40<21:33,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1130: train loss 1.43463. lr 5.440534e-04:  40%|███▉      | 1131/2863 [13:40<21:43,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1131: train loss 1.42515. lr 5.439576e-04:  40%|███▉      | 1131/2863 [13:40<21:43,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1131: train loss 1.42515. lr 5.439576e-04:  40%|███▉      | 1132/2863 [13:40<21:51,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1132: train loss 1.39923. lr 5.438617e-04:  40%|███▉      | 1132/2863 [13:41<21:51,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1132: train loss 1.39923. lr 5.438617e-04:  40%|███▉      | 1133/2863 [13:41<21:47,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1133: train loss 1.39454. lr 5.437658e-04:  40%|███▉      | 1133/2863 [13:42<21:47,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1133: train loss 1.39454. lr 5.437658e-04:  40%|███▉      | 1134/2863 [13:42<22:26,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1134: train loss 1.40823. lr 5.436698e-04:  40%|███▉      | 1134/2863 [13:43<22:26,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1134: train loss 1.40823. lr 5.436698e-04:  40%|███▉      | 1135/2863 [13:43<21:49,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1135: train loss 1.39418. lr 5.435737e-04:  40%|███▉      | 1135/2863 [13:43<21:49,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1135: train loss 1.39418. lr 5.435737e-04:  40%|███▉      | 1136/2863 [13:43<21:20,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1136: train loss 1.42019. lr 5.434776e-04:  40%|███▉      | 1136/2863 [13:44<21:20,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1136: train loss 1.42019. lr 5.434776e-04:  40%|███▉      | 1137/2863 [13:44<22:00,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1137: train loss 1.36188. lr 5.433813e-04:  40%|███▉      | 1137/2863 [13:45<22:00,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1137: train loss 1.36188. lr 5.433813e-04:  40%|███▉      | 1138/2863 [13:45<21:56,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1138: train loss 1.40721. lr 5.432850e-04:  40%|███▉      | 1138/2863 [13:46<21:56,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1138: train loss 1.40721. lr 5.432850e-04:  40%|███▉      | 1139/2863 [13:46<21:20,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1139: train loss 1.33837. lr 5.431887e-04:  40%|███▉      | 1139/2863 [13:46<21:20,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1139: train loss 1.33837. lr 5.431887e-04:  40%|███▉      | 1140/2863 [13:46<20:57,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1140: train loss 1.37360. lr 5.430922e-04:  40%|███▉      | 1140/2863 [13:47<20:57,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1140: train loss 1.37360. lr 5.430922e-04:  40%|███▉      | 1141/2863 [13:47<20:36,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1141: train loss 1.36859. lr 5.429957e-04:  40%|███▉      | 1141/2863 [13:48<20:36,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1141: train loss 1.36859. lr 5.429957e-04:  40%|███▉      | 1142/2863 [13:48<21:14,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1142: train loss 1.40699. lr 5.428991e-04:  40%|███▉      | 1142/2863 [13:48<21:14,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1142: train loss 1.40699. lr 5.428991e-04:  40%|███▉      | 1143/2863 [13:48<20:57,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1143: train loss 1.36530. lr 5.428024e-04:  40%|███▉      | 1143/2863 [13:49<20:57,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1143: train loss 1.36530. lr 5.428024e-04:  40%|███▉      | 1144/2863 [13:49<20:49,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1144: train loss 1.37658. lr 5.427057e-04:  40%|███▉      | 1144/2863 [13:50<20:49,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1144: train loss 1.37658. lr 5.427057e-04:  40%|███▉      | 1145/2863 [13:50<20:32,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1145: train loss 1.33833. lr 5.426089e-04:  40%|███▉      | 1145/2863 [13:51<20:32,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1145: train loss 1.33833. lr 5.426089e-04:  40%|████      | 1146/2863 [13:51<20:40,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1146: train loss 1.35470. lr 5.425120e-04:  40%|████      | 1146/2863 [13:51<20:40,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1146: train loss 1.35470. lr 5.425120e-04:  40%|████      | 1147/2863 [13:51<20:51,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1147: train loss 1.32910. lr 5.424150e-04:  40%|████      | 1147/2863 [13:52<20:51,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1147: train loss 1.32910. lr 5.424150e-04:  40%|████      | 1148/2863 [13:52<21:03,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1148: train loss 1.38968. lr 5.423180e-04:  40%|████      | 1148/2863 [13:53<21:03,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1148: train loss 1.38968. lr 5.423180e-04:  40%|████      | 1149/2863 [13:53<20:52,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1149: train loss 1.38275. lr 5.422209e-04:  40%|████      | 1149/2863 [13:54<20:52,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1149: train loss 1.38275. lr 5.422209e-04:  40%|████      | 1150/2863 [13:54<20:30,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1150: train loss 1.31149. lr 5.421237e-04:  40%|████      | 1150/2863 [13:54<20:30,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1150: train loss 1.31149. lr 5.421237e-04:  40%|████      | 1151/2863 [13:54<21:06,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1151: train loss 1.31655. lr 5.420265e-04:  40%|████      | 1151/2863 [13:55<21:06,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1151: train loss 1.31655. lr 5.420265e-04:  40%|████      | 1152/2863 [13:55<20:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1152: train loss 1.33433. lr 5.419292e-04:  40%|████      | 1152/2863 [13:56<20:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1152: train loss 1.33433. lr 5.419292e-04:  40%|████      | 1153/2863 [13:56<20:34,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1153: train loss 1.31945. lr 5.418318e-04:  40%|████      | 1153/2863 [13:56<20:34,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1153: train loss 1.31945. lr 5.418318e-04:  40%|████      | 1154/2863 [13:56<20:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1154: train loss 1.31034. lr 5.417343e-04:  40%|████      | 1154/2863 [13:57<20:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1154: train loss 1.31034. lr 5.417343e-04:  40%|████      | 1155/2863 [13:57<20:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1155: train loss 1.25574. lr 5.416367e-04:  40%|████      | 1155/2863 [13:58<20:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1155: train loss 1.25574. lr 5.416367e-04:  40%|████      | 1156/2863 [13:58<20:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1156: train loss 1.29250. lr 5.415391e-04:  40%|████      | 1156/2863 [13:59<20:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1156: train loss 1.29250. lr 5.415391e-04:  40%|████      | 1157/2863 [13:59<20:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1157: train loss 1.29708. lr 5.414414e-04:  40%|████      | 1157/2863 [13:59<20:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1157: train loss 1.29708. lr 5.414414e-04:  40%|████      | 1158/2863 [13:59<21:56,  1.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1158: train loss 1.26173. lr 5.413437e-04:  40%|████      | 1158/2863 [14:00<21:56,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1158: train loss 1.26173. lr 5.413437e-04:  40%|████      | 1159/2863 [14:00<22:32,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1159: train loss 1.32333. lr 5.412459e-04:  40%|████      | 1159/2863 [14:01<22:32,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1159: train loss 1.32333. lr 5.412459e-04:  41%|████      | 1160/2863 [14:01<22:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1160: train loss 1.33273. lr 5.411479e-04:  41%|████      | 1160/2863 [14:02<22:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1160: train loss 1.33273. lr 5.411479e-04:  41%|████      | 1161/2863 [14:02<22:02,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1161: train loss 1.31350. lr 5.410500e-04:  41%|████      | 1161/2863 [14:03<22:02,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1161: train loss 1.31350. lr 5.410500e-04:  41%|████      | 1162/2863 [14:03<22:28,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1162: train loss 1.28878. lr 5.409519e-04:  41%|████      | 1162/2863 [14:03<22:28,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1162: train loss 1.28878. lr 5.409519e-04:  41%|████      | 1163/2863 [14:03<21:38,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1163: train loss 1.31374. lr 5.408538e-04:  41%|████      | 1163/2863 [14:04<21:38,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1163: train loss 1.31374. lr 5.408538e-04:  41%|████      | 1164/2863 [14:04<21:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1164: train loss 1.30229. lr 5.407556e-04:  41%|████      | 1164/2863 [14:05<21:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1164: train loss 1.30229. lr 5.407556e-04:  41%|████      | 1165/2863 [14:05<21:41,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1165: train loss 1.33304. lr 5.406573e-04:  41%|████      | 1165/2863 [14:06<21:41,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1165: train loss 1.33304. lr 5.406573e-04:  41%|████      | 1166/2863 [14:06<21:16,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1166: train loss 1.20298. lr 5.405590e-04:  41%|████      | 1166/2863 [14:06<21:16,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1166: train loss 1.20298. lr 5.405590e-04:  41%|████      | 1167/2863 [14:06<20:44,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1167: train loss 1.28625. lr 5.404606e-04:  41%|████      | 1167/2863 [14:07<20:44,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1167: train loss 1.28625. lr 5.404606e-04:  41%|████      | 1168/2863 [14:07<21:16,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1168: train loss 1.26893. lr 5.403621e-04:  41%|████      | 1168/2863 [14:08<21:16,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1168: train loss 1.26893. lr 5.403621e-04:  41%|████      | 1169/2863 [14:08<21:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1169: train loss 1.25340. lr 5.402635e-04:  41%|████      | 1169/2863 [14:09<21:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1169: train loss 1.25340. lr 5.402635e-04:  41%|████      | 1170/2863 [14:09<21:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1170: train loss 1.27301. lr 5.401649e-04:  41%|████      | 1170/2863 [14:09<21:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1170: train loss 1.27301. lr 5.401649e-04:  41%|████      | 1171/2863 [14:09<21:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1171: train loss 1.26532. lr 5.400662e-04:  41%|████      | 1171/2863 [14:10<21:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1171: train loss 1.26532. lr 5.400662e-04:  41%|████      | 1172/2863 [14:10<20:55,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1172: train loss 1.27200. lr 5.399674e-04:  41%|████      | 1172/2863 [14:11<20:55,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1172: train loss 1.27200. lr 5.399674e-04:  41%|████      | 1173/2863 [14:11<21:34,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1173: train loss 1.26779. lr 5.398686e-04:  41%|████      | 1173/2863 [14:12<21:34,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1173: train loss 1.26779. lr 5.398686e-04:  41%|████      | 1174/2863 [14:12<21:30,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1174: train loss 1.24167. lr 5.397696e-04:  41%|████      | 1174/2863 [14:12<21:30,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1174: train loss 1.24167. lr 5.397696e-04:  41%|████      | 1175/2863 [14:12<20:55,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1175: train loss 1.27501. lr 5.396707e-04:  41%|████      | 1175/2863 [14:13<20:55,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1175: train loss 1.27501. lr 5.396707e-04:  41%|████      | 1176/2863 [14:13<20:32,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1176: train loss 1.27587. lr 5.395716e-04:  41%|████      | 1176/2863 [14:14<20:32,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1176: train loss 1.27587. lr 5.395716e-04:  41%|████      | 1177/2863 [14:14<20:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1177: train loss 1.26814. lr 5.394725e-04:  41%|████      | 1177/2863 [14:15<20:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1177: train loss 1.26814. lr 5.394725e-04:  41%|████      | 1178/2863 [14:15<20:42,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1178: train loss 1.24865. lr 5.393732e-04:  41%|████      | 1178/2863 [14:15<20:42,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1178: train loss 1.24865. lr 5.393732e-04:  41%|████      | 1179/2863 [14:15<20:20,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1179: train loss 1.25051. lr 5.392740e-04:  41%|████      | 1179/2863 [14:16<20:20,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1179: train loss 1.25051. lr 5.392740e-04:  41%|████      | 1180/2863 [14:16<20:08,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1180: train loss 1.25136. lr 5.391746e-04:  41%|████      | 1180/2863 [14:17<20:08,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1180: train loss 1.25136. lr 5.391746e-04:  41%|████▏     | 1181/2863 [14:17<19:54,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1181: train loss 1.21724. lr 5.390752e-04:  41%|████▏     | 1181/2863 [14:17<19:54,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1181: train loss 1.21724. lr 5.390752e-04:  41%|████▏     | 1182/2863 [14:17<20:27,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1182: train loss 1.23675. lr 5.389757e-04:  41%|████▏     | 1182/2863 [14:18<20:27,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1182: train loss 1.23675. lr 5.389757e-04:  41%|████▏     | 1183/2863 [14:18<20:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1183: train loss 1.23553. lr 5.388761e-04:  41%|████▏     | 1183/2863 [14:19<20:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1183: train loss 1.23553. lr 5.388761e-04:  41%|████▏     | 1184/2863 [14:19<20:09,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1184: train loss 1.20197. lr 5.387765e-04:  41%|████▏     | 1184/2863 [14:20<20:09,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1184: train loss 1.20197. lr 5.387765e-04:  41%|████▏     | 1185/2863 [14:20<19:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1185: train loss 1.25046. lr 5.386768e-04:  41%|████▏     | 1185/2863 [14:20<19:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1185: train loss 1.25046. lr 5.386768e-04:  41%|████▏     | 1186/2863 [14:20<19:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1186: train loss 1.17988. lr 5.385770e-04:  41%|████▏     | 1186/2863 [14:21<19:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1186: train loss 1.17988. lr 5.385770e-04:  41%|████▏     | 1187/2863 [14:21<19:40,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1187: train loss 1.23249. lr 5.384771e-04:  41%|████▏     | 1187/2863 [14:22<19:40,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1187: train loss 1.23249. lr 5.384771e-04:  41%|████▏     | 1188/2863 [14:22<19:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1188: train loss 1.20902. lr 5.383772e-04:  41%|████▏     | 1188/2863 [14:22<19:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1188: train loss 1.20902. lr 5.383772e-04:  42%|████▏     | 1189/2863 [14:22<19:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1189: train loss 1.19741. lr 5.382772e-04:  42%|████▏     | 1189/2863 [14:23<19:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1189: train loss 1.19741. lr 5.382772e-04:  42%|████▏     | 1190/2863 [14:23<20:52,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1190: train loss 1.23388. lr 5.381771e-04:  42%|████▏     | 1190/2863 [14:24<20:52,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1190: train loss 1.23388. lr 5.381771e-04:  42%|████▏     | 1191/2863 [14:24<20:54,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1191: train loss 1.21192. lr 5.380770e-04:  42%|████▏     | 1191/2863 [14:25<20:54,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1191: train loss 1.21192. lr 5.380770e-04:  42%|████▏     | 1192/2863 [14:25<20:30,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1192: train loss 1.19726. lr 5.379768e-04:  42%|████▏     | 1192/2863 [14:26<20:30,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1192: train loss 1.19726. lr 5.379768e-04:  42%|████▏     | 1193/2863 [14:26<21:27,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1193: train loss 1.18469. lr 5.378765e-04:  42%|████▏     | 1193/2863 [14:26<21:27,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1193: train loss 1.18469. lr 5.378765e-04:  42%|████▏     | 1194/2863 [14:26<21:38,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1194: train loss 1.17730. lr 5.377761e-04:  42%|████▏     | 1194/2863 [14:27<21:38,  1.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1194: train loss 1.17730. lr 5.377761e-04:  42%|████▏     | 1195/2863 [14:27<21:26,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1195: train loss 1.16320. lr 5.376757e-04:  42%|████▏     | 1195/2863 [14:28<21:26,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1195: train loss 1.16320. lr 5.376757e-04:  42%|████▏     | 1196/2863 [14:28<20:46,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1196: train loss 1.18416. lr 5.375752e-04:  42%|████▏     | 1196/2863 [14:28<20:46,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1196: train loss 1.18416. lr 5.375752e-04:  42%|████▏     | 1197/2863 [14:28<20:24,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1197: train loss 1.19029. lr 5.374746e-04:  42%|████▏     | 1197/2863 [14:29<20:24,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1197: train loss 1.19029. lr 5.374746e-04:  42%|████▏     | 1198/2863 [14:29<20:02,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1198: train loss 1.18354. lr 5.373740e-04:  42%|████▏     | 1198/2863 [14:30<20:02,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1198: train loss 1.18354. lr 5.373740e-04:  42%|████▏     | 1199/2863 [14:30<20:46,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1199: train loss 1.21119. lr 5.372733e-04:  42%|████▏     | 1199/2863 [14:31<20:46,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1199: train loss 1.21119. lr 5.372733e-04:  42%|████▏     | 1200/2863 [14:31<20:52,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1200: train loss 1.17090. lr 5.371725e-04:  42%|████▏     | 1200/2863 [14:32<20:52,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1200: train loss 1.17090. lr 5.371725e-04:  42%|████▏     | 1201/2863 [14:32<21:21,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1201: train loss 1.17892. lr 5.370716e-04:  42%|████▏     | 1201/2863 [14:32<21:21,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1201: train loss 1.17892. lr 5.370716e-04:  42%|████▏     | 1202/2863 [14:32<21:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1202: train loss 1.19053. lr 5.369707e-04:  42%|████▏     | 1202/2863 [14:33<21:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1202: train loss 1.19053. lr 5.369707e-04:  42%|████▏     | 1203/2863 [14:33<22:00,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1203: train loss 1.21707. lr 5.368697e-04:  42%|████▏     | 1203/2863 [14:34<22:00,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1203: train loss 1.21707. lr 5.368697e-04:  42%|████▏     | 1204/2863 [14:34<21:53,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1204: train loss 1.15138. lr 5.367686e-04:  42%|████▏     | 1204/2863 [14:35<21:53,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1204: train loss 1.15138. lr 5.367686e-04:  42%|████▏     | 1205/2863 [14:35<21:22,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1205: train loss 1.14723. lr 5.366675e-04:  42%|████▏     | 1205/2863 [14:35<21:22,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1205: train loss 1.14723. lr 5.366675e-04:  42%|████▏     | 1206/2863 [14:35<20:40,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1206: train loss 1.16655. lr 5.365662e-04:  42%|████▏     | 1206/2863 [14:36<20:40,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1206: train loss 1.16655. lr 5.365662e-04:  42%|████▏     | 1207/2863 [14:36<20:26,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1207: train loss 1.16402. lr 5.364649e-04:  42%|████▏     | 1207/2863 [14:37<20:26,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1207: train loss 1.16402. lr 5.364649e-04:  42%|████▏     | 1208/2863 [14:37<20:19,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1208: train loss 1.12389. lr 5.363636e-04:  42%|████▏     | 1208/2863 [14:38<20:19,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1208: train loss 1.12389. lr 5.363636e-04:  42%|████▏     | 1209/2863 [14:38<20:07,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1209: train loss 1.16262. lr 5.362622e-04:  42%|████▏     | 1209/2863 [14:38<20:07,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1209: train loss 1.16262. lr 5.362622e-04:  42%|████▏     | 1210/2863 [14:38<19:47,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1210: train loss 1.14722. lr 5.361607e-04:  42%|████▏     | 1210/2863 [14:39<19:47,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1210: train loss 1.14722. lr 5.361607e-04:  42%|████▏     | 1211/2863 [14:39<20:04,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1211: train loss 1.16594. lr 5.360591e-04:  42%|████▏     | 1211/2863 [14:40<20:04,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1211: train loss 1.16594. lr 5.360591e-04:  42%|████▏     | 1212/2863 [14:40<20:37,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1212: train loss 1.17004. lr 5.359574e-04:  42%|████▏     | 1212/2863 [14:41<20:37,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1212: train loss 1.17004. lr 5.359574e-04:  42%|████▏     | 1213/2863 [14:41<20:37,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1213: train loss 1.15606. lr 5.358557e-04:  42%|████▏     | 1213/2863 [14:41<20:37,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1213: train loss 1.15606. lr 5.358557e-04:  42%|████▏     | 1214/2863 [14:41<20:20,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1214: train loss 1.15636. lr 5.357539e-04:  42%|████▏     | 1214/2863 [14:42<20:20,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1214: train loss 1.15636. lr 5.357539e-04:  42%|████▏     | 1215/2863 [14:42<20:02,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1215: train loss 1.17332. lr 5.356521e-04:  42%|████▏     | 1215/2863 [14:43<20:02,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1215: train loss 1.17332. lr 5.356521e-04:  42%|████▏     | 1216/2863 [14:43<24:24,  1.12it/s]\u001b[A\n",
      "epoch 1 iter 1216: train loss 1.14709. lr 5.355502e-04:  42%|████▏     | 1216/2863 [14:44<24:24,  1.12it/s]\u001b[A\n",
      "epoch 1 iter 1216: train loss 1.14709. lr 5.355502e-04:  43%|████▎     | 1217/2863 [14:44<23:18,  1.18it/s]\u001b[A\n",
      "epoch 1 iter 1217: train loss 1.13681. lr 5.354482e-04:  43%|████▎     | 1217/2863 [14:45<23:18,  1.18it/s]\u001b[A\n",
      "epoch 1 iter 1217: train loss 1.13681. lr 5.354482e-04:  43%|████▎     | 1218/2863 [14:45<23:21,  1.17it/s]\u001b[A\n",
      "epoch 1 iter 1218: train loss 1.16340. lr 5.353461e-04:  43%|████▎     | 1218/2863 [14:46<23:21,  1.17it/s]\u001b[A\n",
      "epoch 1 iter 1218: train loss 1.16340. lr 5.353461e-04:  43%|████▎     | 1219/2863 [14:46<22:05,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1219: train loss 1.11079. lr 5.352440e-04:  43%|████▎     | 1219/2863 [14:46<22:05,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1219: train loss 1.11079. lr 5.352440e-04:  43%|████▎     | 1220/2863 [14:46<21:08,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1220: train loss 1.16117. lr 5.351417e-04:  43%|████▎     | 1220/2863 [14:47<21:08,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1220: train loss 1.16117. lr 5.351417e-04:  43%|████▎     | 1221/2863 [14:47<20:48,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1221: train loss 1.13187. lr 5.350395e-04:  43%|████▎     | 1221/2863 [14:48<20:48,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1221: train loss 1.13187. lr 5.350395e-04:  43%|████▎     | 1222/2863 [14:48<20:46,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1222: train loss 1.16912. lr 5.349371e-04:  43%|████▎     | 1222/2863 [14:48<20:46,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1222: train loss 1.16912. lr 5.349371e-04:  43%|████▎     | 1223/2863 [14:48<20:45,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1223: train loss 1.13658. lr 5.348347e-04:  43%|████▎     | 1223/2863 [14:49<20:45,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1223: train loss 1.13658. lr 5.348347e-04:  43%|████▎     | 1224/2863 [14:49<20:32,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1224: train loss 1.11310. lr 5.347322e-04:  43%|████▎     | 1224/2863 [14:50<20:32,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1224: train loss 1.11310. lr 5.347322e-04:  43%|████▎     | 1225/2863 [14:50<20:01,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1225: train loss 1.09897. lr 5.346296e-04:  43%|████▎     | 1225/2863 [14:51<20:01,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1225: train loss 1.09897. lr 5.346296e-04:  43%|████▎     | 1226/2863 [14:51<19:40,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1226: train loss 1.11067. lr 5.345270e-04:  43%|████▎     | 1226/2863 [14:51<19:40,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1226: train loss 1.11067. lr 5.345270e-04:  43%|████▎     | 1227/2863 [14:51<19:20,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1227: train loss 1.12556. lr 5.344243e-04:  43%|████▎     | 1227/2863 [14:52<19:20,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1227: train loss 1.12556. lr 5.344243e-04:  43%|████▎     | 1228/2863 [14:52<19:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1228: train loss 1.09021. lr 5.343215e-04:  43%|████▎     | 1228/2863 [14:53<19:10,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1228: train loss 1.09021. lr 5.343215e-04:  43%|████▎     | 1229/2863 [14:53<19:11,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1229: train loss 1.11178. lr 5.342187e-04:  43%|████▎     | 1229/2863 [14:53<19:11,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1229: train loss 1.11178. lr 5.342187e-04:  43%|████▎     | 1230/2863 [14:53<19:18,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1230: train loss 1.11711. lr 5.341157e-04:  43%|████▎     | 1230/2863 [14:54<19:18,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1230: train loss 1.11711. lr 5.341157e-04:  43%|████▎     | 1231/2863 [14:54<19:40,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1231: train loss 1.11789. lr 5.340128e-04:  43%|████▎     | 1231/2863 [14:55<19:40,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1231: train loss 1.11789. lr 5.340128e-04:  43%|████▎     | 1232/2863 [14:55<19:59,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1232: train loss 1.04680. lr 5.339097e-04:  43%|████▎     | 1232/2863 [14:56<19:59,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1232: train loss 1.04680. lr 5.339097e-04:  43%|████▎     | 1233/2863 [14:56<19:39,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1233: train loss 1.07316. lr 5.338066e-04:  43%|████▎     | 1233/2863 [14:56<19:39,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1233: train loss 1.07316. lr 5.338066e-04:  43%|████▎     | 1234/2863 [14:56<19:53,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1234: train loss 1.09763. lr 5.337034e-04:  43%|████▎     | 1234/2863 [14:57<19:53,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1234: train loss 1.09763. lr 5.337034e-04:  43%|████▎     | 1235/2863 [14:57<19:59,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1235: train loss 1.09609. lr 5.336001e-04:  43%|████▎     | 1235/2863 [14:58<19:59,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1235: train loss 1.09609. lr 5.336001e-04:  43%|████▎     | 1236/2863 [14:58<19:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1236: train loss 1.08470. lr 5.334968e-04:  43%|████▎     | 1236/2863 [14:59<19:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1236: train loss 1.08470. lr 5.334968e-04:  43%|████▎     | 1237/2863 [14:59<20:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1237: train loss 1.05047. lr 5.333933e-04:  43%|████▎     | 1237/2863 [14:59<20:17,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1237: train loss 1.05047. lr 5.333933e-04:  43%|████▎     | 1238/2863 [14:59<20:20,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1238: train loss 1.07459. lr 5.332899e-04:  43%|████▎     | 1238/2863 [15:00<20:20,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1238: train loss 1.07459. lr 5.332899e-04:  43%|████▎     | 1239/2863 [15:00<19:55,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1239: train loss 1.05821. lr 5.331863e-04:  43%|████▎     | 1239/2863 [15:01<19:55,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1239: train loss 1.05821. lr 5.331863e-04:  43%|████▎     | 1240/2863 [15:01<20:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1240: train loss 1.08408. lr 5.330827e-04:  43%|████▎     | 1240/2863 [15:02<20:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1240: train loss 1.08408. lr 5.330827e-04:  43%|████▎     | 1241/2863 [15:02<20:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1241: train loss 1.09574. lr 5.329790e-04:  43%|████▎     | 1241/2863 [15:02<20:30,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1241: train loss 1.09574. lr 5.329790e-04:  43%|████▎     | 1242/2863 [15:02<20:26,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1242: train loss 1.09161. lr 5.328752e-04:  43%|████▎     | 1242/2863 [15:03<20:26,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1242: train loss 1.09161. lr 5.328752e-04:  43%|████▎     | 1243/2863 [15:03<20:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1243: train loss 1.06141. lr 5.327714e-04:  43%|████▎     | 1243/2863 [15:04<20:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1243: train loss 1.06141. lr 5.327714e-04:  43%|████▎     | 1244/2863 [15:04<19:46,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1244: train loss 1.03396. lr 5.326675e-04:  43%|████▎     | 1244/2863 [15:05<19:46,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1244: train loss 1.03396. lr 5.326675e-04:  43%|████▎     | 1245/2863 [15:05<19:31,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1245: train loss 1.06747. lr 5.325635e-04:  43%|████▎     | 1245/2863 [15:05<19:31,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1245: train loss 1.06747. lr 5.325635e-04:  44%|████▎     | 1246/2863 [15:05<20:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1246: train loss 1.07387. lr 5.324595e-04:  44%|████▎     | 1246/2863 [15:06<20:14,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1246: train loss 1.07387. lr 5.324595e-04:  44%|████▎     | 1247/2863 [15:06<19:51,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1247: train loss 1.05853. lr 5.323554e-04:  44%|████▎     | 1247/2863 [15:07<19:51,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1247: train loss 1.05853. lr 5.323554e-04:  44%|████▎     | 1248/2863 [15:07<19:46,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1248: train loss 1.08428. lr 5.322512e-04:  44%|████▎     | 1248/2863 [15:08<19:46,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1248: train loss 1.08428. lr 5.322512e-04:  44%|████▎     | 1249/2863 [15:08<20:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1249: train loss 1.08057. lr 5.321469e-04:  44%|████▎     | 1249/2863 [15:08<20:12,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1249: train loss 1.08057. lr 5.321469e-04:  44%|████▎     | 1250/2863 [15:08<20:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1250: train loss 1.09071. lr 5.320426e-04:  44%|████▎     | 1250/2863 [15:09<20:45,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1250: train loss 1.09071. lr 5.320426e-04:  44%|████▎     | 1251/2863 [15:09<21:00,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1251: train loss 1.05122. lr 5.319382e-04:  44%|████▎     | 1251/2863 [15:10<21:00,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1251: train loss 1.05122. lr 5.319382e-04:  44%|████▎     | 1252/2863 [15:10<21:13,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1252: train loss 1.06349. lr 5.318338e-04:  44%|████▎     | 1252/2863 [15:11<21:13,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1252: train loss 1.06349. lr 5.318338e-04:  44%|████▍     | 1253/2863 [15:11<21:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1253: train loss 1.03511. lr 5.317292e-04:  44%|████▍     | 1253/2863 [15:12<21:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1253: train loss 1.03511. lr 5.317292e-04:  44%|████▍     | 1254/2863 [15:12<21:09,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1254: train loss 1.03276. lr 5.316246e-04:  44%|████▍     | 1254/2863 [15:12<21:09,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1254: train loss 1.03276. lr 5.316246e-04:  44%|████▍     | 1255/2863 [15:12<20:50,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1255: train loss 1.10519. lr 5.315200e-04:  44%|████▍     | 1255/2863 [15:13<20:50,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1255: train loss 1.10519. lr 5.315200e-04:  44%|████▍     | 1256/2863 [15:13<20:25,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1256: train loss 1.06603. lr 5.314152e-04:  44%|████▍     | 1256/2863 [15:14<20:25,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1256: train loss 1.06603. lr 5.314152e-04:  44%|████▍     | 1257/2863 [15:14<20:07,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1257: train loss 1.01963. lr 5.313104e-04:  44%|████▍     | 1257/2863 [15:15<20:07,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1257: train loss 1.01963. lr 5.313104e-04:  44%|████▍     | 1258/2863 [15:15<19:50,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1258: train loss 1.02781. lr 5.312055e-04:  44%|████▍     | 1258/2863 [15:15<19:50,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1258: train loss 1.02781. lr 5.312055e-04:  44%|████▍     | 1259/2863 [15:15<20:09,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1259: train loss 1.05613. lr 5.311006e-04:  44%|████▍     | 1259/2863 [15:16<20:09,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1259: train loss 1.05613. lr 5.311006e-04:  44%|████▍     | 1260/2863 [15:16<20:13,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1260: train loss 1.05448. lr 5.309956e-04:  44%|████▍     | 1260/2863 [15:17<20:13,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1260: train loss 1.05448. lr 5.309956e-04:  44%|████▍     | 1261/2863 [15:17<20:01,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1261: train loss 1.00456. lr 5.308905e-04:  44%|████▍     | 1261/2863 [15:18<20:01,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1261: train loss 1.00456. lr 5.308905e-04:  44%|████▍     | 1262/2863 [15:18<19:44,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1262: train loss 1.01322. lr 5.307853e-04:  44%|████▍     | 1262/2863 [15:18<19:44,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1262: train loss 1.01322. lr 5.307853e-04:  44%|████▍     | 1263/2863 [15:18<19:30,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1263: train loss 1.03863. lr 5.306801e-04:  44%|████▍     | 1263/2863 [15:19<19:30,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1263: train loss 1.03863. lr 5.306801e-04:  44%|████▍     | 1264/2863 [15:19<19:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1264: train loss 1.02190. lr 5.305748e-04:  44%|████▍     | 1264/2863 [15:20<19:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1264: train loss 1.02190. lr 5.305748e-04:  44%|████▍     | 1265/2863 [15:20<19:03,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1265: train loss 0.97222. lr 5.304694e-04:  44%|████▍     | 1265/2863 [15:20<19:03,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1265: train loss 0.97222. lr 5.304694e-04:  44%|████▍     | 1266/2863 [15:20<18:54,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1266: train loss 1.02678. lr 5.303640e-04:  44%|████▍     | 1266/2863 [15:21<18:54,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1266: train loss 1.02678. lr 5.303640e-04:  44%|████▍     | 1267/2863 [15:21<19:24,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1267: train loss 1.01185. lr 5.302585e-04:  44%|████▍     | 1267/2863 [15:22<19:24,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1267: train loss 1.01185. lr 5.302585e-04:  44%|████▍     | 1268/2863 [15:22<19:51,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1268: train loss 1.03269. lr 5.301529e-04:  44%|████▍     | 1268/2863 [15:23<19:51,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1268: train loss 1.03269. lr 5.301529e-04:  44%|████▍     | 1269/2863 [15:23<20:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1269: train loss 1.01017. lr 5.300472e-04:  44%|████▍     | 1269/2863 [15:23<20:11,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1269: train loss 1.01017. lr 5.300472e-04:  44%|████▍     | 1270/2863 [15:23<20:14,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1270: train loss 1.00083. lr 5.299415e-04:  44%|████▍     | 1270/2863 [15:24<20:14,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1270: train loss 1.00083. lr 5.299415e-04:  44%|████▍     | 1271/2863 [15:24<20:05,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1271: train loss 1.00082. lr 5.298357e-04:  44%|████▍     | 1271/2863 [15:25<20:05,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1271: train loss 1.00082. lr 5.298357e-04:  44%|████▍     | 1272/2863 [15:25<19:56,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1272: train loss 1.01228. lr 5.297299e-04:  44%|████▍     | 1272/2863 [15:26<19:56,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1272: train loss 1.01228. lr 5.297299e-04:  44%|████▍     | 1273/2863 [15:26<19:50,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1273: train loss 0.97819. lr 5.296240e-04:  44%|████▍     | 1273/2863 [15:27<19:50,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1273: train loss 0.97819. lr 5.296240e-04:  44%|████▍     | 1274/2863 [15:27<20:36,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1274: train loss 0.98719. lr 5.295180e-04:  44%|████▍     | 1274/2863 [15:27<20:36,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1274: train loss 0.98719. lr 5.295180e-04:  45%|████▍     | 1275/2863 [15:27<20:05,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1275: train loss 1.00076. lr 5.294119e-04:  45%|████▍     | 1275/2863 [15:28<20:05,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1275: train loss 1.00076. lr 5.294119e-04:  45%|████▍     | 1276/2863 [15:28<19:32,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1276: train loss 0.98777. lr 5.293058e-04:  45%|████▍     | 1276/2863 [15:29<19:32,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1276: train loss 0.98777. lr 5.293058e-04:  45%|████▍     | 1277/2863 [15:29<19:08,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1277: train loss 0.97693. lr 5.291996e-04:  45%|████▍     | 1277/2863 [15:29<19:08,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1277: train loss 0.97693. lr 5.291996e-04:  45%|████▍     | 1278/2863 [15:29<18:58,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1278: train loss 0.95710. lr 5.290933e-04:  45%|████▍     | 1278/2863 [15:30<18:58,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1278: train loss 0.95710. lr 5.290933e-04:  45%|████▍     | 1279/2863 [15:30<18:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1279: train loss 0.97698. lr 5.289870e-04:  45%|████▍     | 1279/2863 [15:31<18:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1279: train loss 0.97698. lr 5.289870e-04:  45%|████▍     | 1280/2863 [15:31<18:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1280: train loss 0.98152. lr 5.288806e-04:  45%|████▍     | 1280/2863 [15:31<18:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1280: train loss 0.98152. lr 5.288806e-04:  45%|████▍     | 1281/2863 [15:31<18:50,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1281: train loss 0.96483. lr 5.287741e-04:  45%|████▍     | 1281/2863 [15:32<18:50,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1281: train loss 0.96483. lr 5.287741e-04:  45%|████▍     | 1282/2863 [15:32<18:46,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1282: train loss 0.99804. lr 5.286676e-04:  45%|████▍     | 1282/2863 [15:33<18:46,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1282: train loss 0.99804. lr 5.286676e-04:  45%|████▍     | 1283/2863 [15:33<19:10,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1283: train loss 0.99405. lr 5.285610e-04:  45%|████▍     | 1283/2863 [15:34<19:10,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1283: train loss 0.99405. lr 5.285610e-04:  45%|████▍     | 1284/2863 [15:34<19:34,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1284: train loss 0.95125. lr 5.284543e-04:  45%|████▍     | 1284/2863 [15:34<19:34,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1284: train loss 0.95125. lr 5.284543e-04:  45%|████▍     | 1285/2863 [15:34<19:36,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1285: train loss 0.97004. lr 5.283475e-04:  45%|████▍     | 1285/2863 [15:35<19:36,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1285: train loss 0.97004. lr 5.283475e-04:  45%|████▍     | 1286/2863 [15:35<19:27,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1286: train loss 0.98242. lr 5.282407e-04:  45%|████▍     | 1286/2863 [15:36<19:27,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1286: train loss 0.98242. lr 5.282407e-04:  45%|████▍     | 1287/2863 [15:36<19:19,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1287: train loss 0.95379. lr 5.281338e-04:  45%|████▍     | 1287/2863 [15:37<19:19,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1287: train loss 0.95379. lr 5.281338e-04:  45%|████▍     | 1288/2863 [15:37<19:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1288: train loss 0.98178. lr 5.280269e-04:  45%|████▍     | 1288/2863 [15:37<19:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1288: train loss 0.98178. lr 5.280269e-04:  45%|████▌     | 1289/2863 [15:37<18:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1289: train loss 0.95423. lr 5.279198e-04:  45%|████▌     | 1289/2863 [15:38<18:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1289: train loss 0.95423. lr 5.279198e-04:  45%|████▌     | 1290/2863 [15:38<18:47,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1290: train loss 1.00313. lr 5.278127e-04:  45%|████▌     | 1290/2863 [15:39<18:47,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1290: train loss 1.00313. lr 5.278127e-04:  45%|████▌     | 1291/2863 [15:39<18:40,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1291: train loss 0.99942. lr 5.277056e-04:  45%|████▌     | 1291/2863 [15:39<18:40,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1291: train loss 0.99942. lr 5.277056e-04:  45%|████▌     | 1292/2863 [15:39<18:30,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1292: train loss 0.94870. lr 5.275984e-04:  45%|████▌     | 1292/2863 [15:40<18:30,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1292: train loss 0.94870. lr 5.275984e-04:  45%|████▌     | 1293/2863 [15:40<18:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1293: train loss 0.94566. lr 5.274911e-04:  45%|████▌     | 1293/2863 [15:41<18:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1293: train loss 0.94566. lr 5.274911e-04:  45%|████▌     | 1294/2863 [15:41<18:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1294: train loss 0.97754. lr 5.273837e-04:  45%|████▌     | 1294/2863 [15:42<18:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1294: train loss 0.97754. lr 5.273837e-04:  45%|████▌     | 1295/2863 [15:42<18:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1295: train loss 0.94723. lr 5.272762e-04:  45%|████▌     | 1295/2863 [15:42<18:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1295: train loss 0.94723. lr 5.272762e-04:  45%|████▌     | 1296/2863 [15:42<18:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1296: train loss 0.98065. lr 5.271687e-04:  45%|████▌     | 1296/2863 [15:43<18:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1296: train loss 0.98065. lr 5.271687e-04:  45%|████▌     | 1297/2863 [15:43<18:02,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1297: train loss 0.97481. lr 5.270612e-04:  45%|████▌     | 1297/2863 [15:44<18:02,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1297: train loss 0.97481. lr 5.270612e-04:  45%|████▌     | 1298/2863 [15:44<18:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1298: train loss 0.89739. lr 5.269535e-04:  45%|████▌     | 1298/2863 [15:44<18:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1298: train loss 0.89739. lr 5.269535e-04:  45%|████▌     | 1299/2863 [15:44<18:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1299: train loss 0.97013. lr 5.268458e-04:  45%|████▌     | 1299/2863 [15:45<18:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1299: train loss 0.97013. lr 5.268458e-04:  45%|████▌     | 1300/2863 [15:45<18:01,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1300: train loss 0.93384. lr 5.267380e-04:  45%|████▌     | 1300/2863 [15:46<18:01,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1300: train loss 0.93384. lr 5.267380e-04:  45%|████▌     | 1301/2863 [15:46<18:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1301: train loss 0.93950. lr 5.266302e-04:  45%|████▌     | 1301/2863 [15:46<18:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1301: train loss 0.93950. lr 5.266302e-04:  45%|████▌     | 1302/2863 [15:46<18:54,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1302: train loss 0.96212. lr 5.265223e-04:  45%|████▌     | 1302/2863 [15:47<18:54,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1302: train loss 0.96212. lr 5.265223e-04:  46%|████▌     | 1303/2863 [15:47<18:47,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1303: train loss 0.93212. lr 5.264143e-04:  46%|████▌     | 1303/2863 [15:48<18:47,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1303: train loss 0.93212. lr 5.264143e-04:  46%|████▌     | 1304/2863 [15:48<18:46,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1304: train loss 0.93123. lr 5.263062e-04:  46%|████▌     | 1304/2863 [15:49<18:46,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1304: train loss 0.93123. lr 5.263062e-04:  46%|████▌     | 1305/2863 [15:49<18:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1305: train loss 0.95064. lr 5.261981e-04:  46%|████▌     | 1305/2863 [15:49<18:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1305: train loss 0.95064. lr 5.261981e-04:  46%|████▌     | 1306/2863 [15:49<18:48,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1306: train loss 0.90155. lr 5.260899e-04:  46%|████▌     | 1306/2863 [15:50<18:48,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1306: train loss 0.90155. lr 5.260899e-04:  46%|████▌     | 1307/2863 [15:50<18:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1307: train loss 0.95684. lr 5.259817e-04:  46%|████▌     | 1307/2863 [15:51<18:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1307: train loss 0.95684. lr 5.259817e-04:  46%|████▌     | 1308/2863 [15:51<18:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1308: train loss 0.92326. lr 5.258734e-04:  46%|████▌     | 1308/2863 [15:51<18:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1308: train loss 0.92326. lr 5.258734e-04:  46%|████▌     | 1309/2863 [15:51<18:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1309: train loss 0.95292. lr 5.257650e-04:  46%|████▌     | 1309/2863 [15:52<18:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1309: train loss 0.95292. lr 5.257650e-04:  46%|████▌     | 1310/2863 [15:52<19:01,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1310: train loss 0.93390. lr 5.256565e-04:  46%|████▌     | 1310/2863 [15:53<19:01,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1310: train loss 0.93390. lr 5.256565e-04:  46%|████▌     | 1311/2863 [15:53<19:31,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1311: train loss 0.92413. lr 5.255480e-04:  46%|████▌     | 1311/2863 [15:54<19:31,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1311: train loss 0.92413. lr 5.255480e-04:  46%|████▌     | 1312/2863 [15:54<19:44,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1312: train loss 0.93120. lr 5.254394e-04:  46%|████▌     | 1312/2863 [15:55<19:44,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1312: train loss 0.93120. lr 5.254394e-04:  46%|████▌     | 1313/2863 [15:55<19:49,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1313: train loss 0.92708. lr 5.253307e-04:  46%|████▌     | 1313/2863 [15:55<19:49,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1313: train loss 0.92708. lr 5.253307e-04:  46%|████▌     | 1314/2863 [15:55<19:36,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1314: train loss 0.93928. lr 5.252220e-04:  46%|████▌     | 1314/2863 [15:56<19:36,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1314: train loss 0.93928. lr 5.252220e-04:  46%|████▌     | 1315/2863 [15:56<19:22,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1315: train loss 0.91057. lr 5.251132e-04:  46%|████▌     | 1315/2863 [15:57<19:22,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1315: train loss 0.91057. lr 5.251132e-04:  46%|████▌     | 1316/2863 [15:57<19:09,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1316: train loss 0.93957. lr 5.250043e-04:  46%|████▌     | 1316/2863 [15:57<19:09,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1316: train loss 0.93957. lr 5.250043e-04:  46%|████▌     | 1317/2863 [15:57<18:51,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1317: train loss 0.88703. lr 5.248954e-04:  46%|████▌     | 1317/2863 [15:58<18:51,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1317: train loss 0.88703. lr 5.248954e-04:  46%|████▌     | 1318/2863 [15:58<18:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1318: train loss 0.92669. lr 5.247864e-04:  46%|████▌     | 1318/2863 [15:59<18:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1318: train loss 0.92669. lr 5.247864e-04:  46%|████▌     | 1319/2863 [15:59<18:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1319: train loss 0.90867. lr 5.246773e-04:  46%|████▌     | 1319/2863 [16:00<18:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1319: train loss 0.90867. lr 5.246773e-04:  46%|████▌     | 1320/2863 [16:00<18:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1320: train loss 0.92031. lr 5.245682e-04:  46%|████▌     | 1320/2863 [16:00<18:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1320: train loss 0.92031. lr 5.245682e-04:  46%|████▌     | 1321/2863 [16:00<18:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1321: train loss 0.91069. lr 5.244590e-04:  46%|████▌     | 1321/2863 [16:01<18:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1321: train loss 0.91069. lr 5.244590e-04:  46%|████▌     | 1322/2863 [16:01<17:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1322: train loss 0.90731. lr 5.243497e-04:  46%|████▌     | 1322/2863 [16:02<17:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1322: train loss 0.90731. lr 5.243497e-04:  46%|████▌     | 1323/2863 [16:02<17:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1323: train loss 0.91200. lr 5.242404e-04:  46%|████▌     | 1323/2863 [16:02<17:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1323: train loss 0.91200. lr 5.242404e-04:  46%|████▌     | 1324/2863 [16:02<18:23,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1324: train loss 0.91867. lr 5.241310e-04:  46%|████▌     | 1324/2863 [16:03<18:23,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1324: train loss 0.91867. lr 5.241310e-04:  46%|████▋     | 1325/2863 [16:03<18:51,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1325: train loss 0.87273. lr 5.240215e-04:  46%|████▋     | 1325/2863 [16:04<18:51,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1325: train loss 0.87273. lr 5.240215e-04:  46%|████▋     | 1326/2863 [16:04<18:56,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1326: train loss 0.87198. lr 5.239119e-04:  46%|████▋     | 1326/2863 [16:05<18:56,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1326: train loss 0.87198. lr 5.239119e-04:  46%|████▋     | 1327/2863 [16:05<18:49,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1327: train loss 0.87669. lr 5.238023e-04:  46%|████▋     | 1327/2863 [16:05<18:49,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1327: train loss 0.87669. lr 5.238023e-04:  46%|████▋     | 1328/2863 [16:05<18:42,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1328: train loss 0.90633. lr 5.236926e-04:  46%|████▋     | 1328/2863 [16:06<18:42,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1328: train loss 0.90633. lr 5.236926e-04:  46%|████▋     | 1329/2863 [16:06<18:33,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1329: train loss 0.90419. lr 5.235829e-04:  46%|████▋     | 1329/2863 [16:07<18:33,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1329: train loss 0.90419. lr 5.235829e-04:  46%|████▋     | 1330/2863 [16:07<19:21,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1330: train loss 0.87875. lr 5.234731e-04:  46%|████▋     | 1330/2863 [16:08<19:21,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1330: train loss 0.87875. lr 5.234731e-04:  46%|████▋     | 1331/2863 [16:08<18:54,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1331: train loss 0.89971. lr 5.233632e-04:  46%|████▋     | 1331/2863 [16:08<18:54,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1331: train loss 0.89971. lr 5.233632e-04:  47%|████▋     | 1332/2863 [16:08<18:28,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1332: train loss 0.89223. lr 5.232533e-04:  47%|████▋     | 1332/2863 [16:09<18:28,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1332: train loss 0.89223. lr 5.232533e-04:  47%|████▋     | 1333/2863 [16:09<18:17,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1333: train loss 0.88331. lr 5.231432e-04:  47%|████▋     | 1333/2863 [16:10<18:17,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1333: train loss 0.88331. lr 5.231432e-04:  47%|████▋     | 1334/2863 [16:10<18:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1334: train loss 0.87547. lr 5.230332e-04:  47%|████▋     | 1334/2863 [16:10<18:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1334: train loss 0.87547. lr 5.230332e-04:  47%|████▋     | 1335/2863 [16:10<17:52,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1335: train loss 0.86925. lr 5.229230e-04:  47%|████▋     | 1335/2863 [16:11<17:52,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1335: train loss 0.86925. lr 5.229230e-04:  47%|████▋     | 1336/2863 [16:11<17:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1336: train loss 0.85742. lr 5.228128e-04:  47%|████▋     | 1336/2863 [16:12<17:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1336: train loss 0.85742. lr 5.228128e-04:  47%|████▋     | 1337/2863 [16:12<17:43,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1337: train loss 0.87951. lr 5.227025e-04:  47%|████▋     | 1337/2863 [16:12<17:43,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1337: train loss 0.87951. lr 5.227025e-04:  47%|████▋     | 1338/2863 [16:12<17:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1338: train loss 0.88657. lr 5.225922e-04:  47%|████▋     | 1338/2863 [16:13<17:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1338: train loss 0.88657. lr 5.225922e-04:  47%|████▋     | 1339/2863 [16:13<17:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1339: train loss 0.88541. lr 5.224818e-04:  47%|████▋     | 1339/2863 [16:14<17:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1339: train loss 0.88541. lr 5.224818e-04:  47%|████▋     | 1340/2863 [16:14<17:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1340: train loss 0.87432. lr 5.223713e-04:  47%|████▋     | 1340/2863 [16:15<17:41,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1340: train loss 0.87432. lr 5.223713e-04:  47%|████▋     | 1341/2863 [16:15<17:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1341: train loss 0.87347. lr 5.222607e-04:  47%|████▋     | 1341/2863 [16:15<17:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1341: train loss 0.87347. lr 5.222607e-04:  47%|████▋     | 1342/2863 [16:15<17:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1342: train loss 0.86836. lr 5.221501e-04:  47%|████▋     | 1342/2863 [16:16<17:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1342: train loss 0.86836. lr 5.221501e-04:  47%|████▋     | 1343/2863 [16:16<17:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1343: train loss 0.87592. lr 5.220394e-04:  47%|████▋     | 1343/2863 [16:17<17:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1343: train loss 0.87592. lr 5.220394e-04:  47%|████▋     | 1344/2863 [16:17<17:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1344: train loss 0.85379. lr 5.219287e-04:  47%|████▋     | 1344/2863 [16:17<17:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1344: train loss 0.85379. lr 5.219287e-04:  47%|████▋     | 1345/2863 [16:17<17:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1345: train loss 0.86580. lr 5.218178e-04:  47%|████▋     | 1345/2863 [16:18<17:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1345: train loss 0.86580. lr 5.218178e-04:  47%|████▋     | 1346/2863 [16:18<17:32,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1346: train loss 0.87176. lr 5.217070e-04:  47%|████▋     | 1346/2863 [16:19<17:32,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1346: train loss 0.87176. lr 5.217070e-04:  47%|████▋     | 1347/2863 [16:19<17:31,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1347: train loss 0.90803. lr 5.215960e-04:  47%|████▋     | 1347/2863 [16:19<17:31,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1347: train loss 0.90803. lr 5.215960e-04:  47%|████▋     | 1348/2863 [16:19<17:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1348: train loss 0.82587. lr 5.214850e-04:  47%|████▋     | 1348/2863 [16:20<17:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1348: train loss 0.82587. lr 5.214850e-04:  47%|████▋     | 1349/2863 [16:20<17:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1349: train loss 0.84414. lr 5.213739e-04:  47%|████▋     | 1349/2863 [16:21<17:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1349: train loss 0.84414. lr 5.213739e-04:  47%|████▋     | 1350/2863 [16:21<17:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1350: train loss 0.86298. lr 5.212627e-04:  47%|████▋     | 1350/2863 [16:22<17:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1350: train loss 0.86298. lr 5.212627e-04:  47%|████▋     | 1351/2863 [16:22<17:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1351: train loss 0.85682. lr 5.211515e-04:  47%|████▋     | 1351/2863 [16:22<17:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1351: train loss 0.85682. lr 5.211515e-04:  47%|████▋     | 1352/2863 [16:22<17:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1352: train loss 0.85604. lr 5.210402e-04:  47%|████▋     | 1352/2863 [16:23<17:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1352: train loss 0.85604. lr 5.210402e-04:  47%|████▋     | 1353/2863 [16:23<17:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1353: train loss 0.84615. lr 5.209289e-04:  47%|████▋     | 1353/2863 [16:24<17:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1353: train loss 0.84615. lr 5.209289e-04:  47%|████▋     | 1354/2863 [16:24<17:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1354: train loss 0.84965. lr 5.208175e-04:  47%|████▋     | 1354/2863 [16:24<17:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1354: train loss 0.84965. lr 5.208175e-04:  47%|████▋     | 1355/2863 [16:24<17:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1355: train loss 0.85465. lr 5.207060e-04:  47%|████▋     | 1355/2863 [16:25<17:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1355: train loss 0.85465. lr 5.207060e-04:  47%|████▋     | 1356/2863 [16:25<17:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1356: train loss 0.84872. lr 5.205944e-04:  47%|████▋     | 1356/2863 [16:26<17:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1356: train loss 0.84872. lr 5.205944e-04:  47%|████▋     | 1357/2863 [16:26<17:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1357: train loss 0.85544. lr 5.204828e-04:  47%|████▋     | 1357/2863 [16:27<17:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1357: train loss 0.85544. lr 5.204828e-04:  47%|████▋     | 1358/2863 [16:27<18:23,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1358: train loss 0.84543. lr 5.203711e-04:  47%|████▋     | 1358/2863 [16:27<18:23,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1358: train loss 0.84543. lr 5.203711e-04:  47%|████▋     | 1359/2863 [16:27<18:04,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1359: train loss 0.84037. lr 5.202594e-04:  47%|████▋     | 1359/2863 [16:28<18:04,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1359: train loss 0.84037. lr 5.202594e-04:  48%|████▊     | 1360/2863 [16:28<17:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1360: train loss 0.86673. lr 5.201476e-04:  48%|████▊     | 1360/2863 [16:29<17:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1360: train loss 0.86673. lr 5.201476e-04:  48%|████▊     | 1361/2863 [16:29<17:45,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1361: train loss 0.84668. lr 5.200357e-04:  48%|████▊     | 1361/2863 [16:29<17:45,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1361: train loss 0.84668. lr 5.200357e-04:  48%|████▊     | 1362/2863 [16:29<17:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1362: train loss 0.83107. lr 5.199237e-04:  48%|████▊     | 1362/2863 [16:30<17:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1362: train loss 0.83107. lr 5.199237e-04:  48%|████▊     | 1363/2863 [16:30<17:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1363: train loss 0.82369. lr 5.198117e-04:  48%|████▊     | 1363/2863 [16:31<17:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1363: train loss 0.82369. lr 5.198117e-04:  48%|████▊     | 1364/2863 [16:31<17:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1364: train loss 0.84609. lr 5.196996e-04:  48%|████▊     | 1364/2863 [16:31<17:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1364: train loss 0.84609. lr 5.196996e-04:  48%|████▊     | 1365/2863 [16:31<17:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1365: train loss 0.83654. lr 5.195875e-04:  48%|████▊     | 1365/2863 [16:32<17:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1365: train loss 0.83654. lr 5.195875e-04:  48%|████▊     | 1366/2863 [16:32<17:49,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1366: train loss 0.84719. lr 5.194753e-04:  48%|████▊     | 1366/2863 [16:33<17:49,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1366: train loss 0.84719. lr 5.194753e-04:  48%|████▊     | 1367/2863 [16:33<17:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1367: train loss 0.83273. lr 5.193630e-04:  48%|████▊     | 1367/2863 [16:34<17:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1367: train loss 0.83273. lr 5.193630e-04:  48%|████▊     | 1368/2863 [16:34<17:34,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1368: train loss 0.84690. lr 5.192506e-04:  48%|████▊     | 1368/2863 [16:34<17:34,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1368: train loss 0.84690. lr 5.192506e-04:  48%|████▊     | 1369/2863 [16:34<17:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1369: train loss 0.82904. lr 5.191382e-04:  48%|████▊     | 1369/2863 [16:35<17:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1369: train loss 0.82904. lr 5.191382e-04:  48%|████▊     | 1370/2863 [16:35<17:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1370: train loss 0.83494. lr 5.190257e-04:  48%|████▊     | 1370/2863 [16:36<17:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1370: train loss 0.83494. lr 5.190257e-04:  48%|████▊     | 1371/2863 [16:36<17:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1371: train loss 0.83820. lr 5.189132e-04:  48%|████▊     | 1371/2863 [16:36<17:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1371: train loss 0.83820. lr 5.189132e-04:  48%|████▊     | 1372/2863 [16:36<17:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1372: train loss 0.80902. lr 5.188006e-04:  48%|████▊     | 1372/2863 [16:37<17:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1372: train loss 0.80902. lr 5.188006e-04:  48%|████▊     | 1373/2863 [16:37<17:42,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1373: train loss 0.83127. lr 5.186879e-04:  48%|████▊     | 1373/2863 [16:38<17:42,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1373: train loss 0.83127. lr 5.186879e-04:  48%|████▊     | 1374/2863 [16:38<17:36,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1374: train loss 0.82720. lr 5.185752e-04:  48%|████▊     | 1374/2863 [16:38<17:36,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1374: train loss 0.82720. lr 5.185752e-04:  48%|████▊     | 1375/2863 [16:38<17:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1375: train loss 0.84572. lr 5.184624e-04:  48%|████▊     | 1375/2863 [16:39<17:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1375: train loss 0.84572. lr 5.184624e-04:  48%|████▊     | 1376/2863 [16:39<17:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1376: train loss 0.82639. lr 5.183495e-04:  48%|████▊     | 1376/2863 [16:40<17:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1376: train loss 0.82639. lr 5.183495e-04:  48%|████▊     | 1377/2863 [16:40<17:21,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1377: train loss 0.83286. lr 5.182365e-04:  48%|████▊     | 1377/2863 [16:41<17:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1377: train loss 0.83286. lr 5.182365e-04:  48%|████▊     | 1378/2863 [16:41<17:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1378: train loss 0.82072. lr 5.181235e-04:  48%|████▊     | 1378/2863 [16:41<17:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1378: train loss 0.82072. lr 5.181235e-04:  48%|████▊     | 1379/2863 [16:41<17:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1379: train loss 0.79767. lr 5.180105e-04:  48%|████▊     | 1379/2863 [16:42<17:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1379: train loss 0.79767. lr 5.180105e-04:  48%|████▊     | 1380/2863 [16:42<17:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1380: train loss 0.80585. lr 5.178973e-04:  48%|████▊     | 1380/2863 [16:43<17:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1380: train loss 0.80585. lr 5.178973e-04:  48%|████▊     | 1381/2863 [16:43<17:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1381: train loss 0.82164. lr 5.177841e-04:  48%|████▊     | 1381/2863 [16:43<17:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1381: train loss 0.82164. lr 5.177841e-04:  48%|████▊     | 1382/2863 [16:43<17:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1382: train loss 0.81747. lr 5.176709e-04:  48%|████▊     | 1382/2863 [16:44<17:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1382: train loss 0.81747. lr 5.176709e-04:  48%|████▊     | 1383/2863 [16:44<17:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1383: train loss 0.79567. lr 5.175575e-04:  48%|████▊     | 1383/2863 [16:45<17:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1383: train loss 0.79567. lr 5.175575e-04:  48%|████▊     | 1384/2863 [16:45<17:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1384: train loss 0.80582. lr 5.174441e-04:  48%|████▊     | 1384/2863 [16:45<17:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1384: train loss 0.80582. lr 5.174441e-04:  48%|████▊     | 1385/2863 [16:45<17:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1385: train loss 0.81828. lr 5.173307e-04:  48%|████▊     | 1385/2863 [16:46<17:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1385: train loss 0.81828. lr 5.173307e-04:  48%|████▊     | 1386/2863 [16:46<18:13,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1386: train loss 0.82605. lr 5.172171e-04:  48%|████▊     | 1386/2863 [16:47<18:13,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1386: train loss 0.82605. lr 5.172171e-04:  48%|████▊     | 1387/2863 [16:47<17:51,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1387: train loss 0.81643. lr 5.171035e-04:  48%|████▊     | 1387/2863 [16:48<17:51,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1387: train loss 0.81643. lr 5.171035e-04:  48%|████▊     | 1388/2863 [16:48<17:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1388: train loss 0.80948. lr 5.169899e-04:  48%|████▊     | 1388/2863 [16:48<17:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1388: train loss 0.80948. lr 5.169899e-04:  49%|████▊     | 1389/2863 [16:48<17:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1389: train loss 0.80525. lr 5.168761e-04:  49%|████▊     | 1389/2863 [16:49<17:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1389: train loss 0.80525. lr 5.168761e-04:  49%|████▊     | 1390/2863 [16:49<17:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1390: train loss 0.78608. lr 5.167624e-04:  49%|████▊     | 1390/2863 [16:50<17:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1390: train loss 0.78608. lr 5.167624e-04:  49%|████▊     | 1391/2863 [16:50<17:13,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1391: train loss 0.76101. lr 5.166485e-04:  49%|████▊     | 1391/2863 [16:50<17:13,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1391: train loss 0.76101. lr 5.166485e-04:  49%|████▊     | 1392/2863 [16:50<17:12,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1392: train loss 0.80353. lr 5.165346e-04:  49%|████▊     | 1392/2863 [16:51<17:12,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1392: train loss 0.80353. lr 5.165346e-04:  49%|████▊     | 1393/2863 [16:51<17:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1393: train loss 0.78053. lr 5.164206e-04:  49%|████▊     | 1393/2863 [16:52<17:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1393: train loss 0.78053. lr 5.164206e-04:  49%|████▊     | 1394/2863 [16:52<17:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1394: train loss 0.77742. lr 5.163065e-04:  49%|████▊     | 1394/2863 [16:53<17:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1394: train loss 0.77742. lr 5.163065e-04:  49%|████▊     | 1395/2863 [16:53<17:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1395: train loss 0.78628. lr 5.161924e-04:  49%|████▊     | 1395/2863 [16:53<17:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1395: train loss 0.78628. lr 5.161924e-04:  49%|████▉     | 1396/2863 [16:53<17:11,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1396: train loss 0.77080. lr 5.160782e-04:  49%|████▉     | 1396/2863 [16:54<17:11,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1396: train loss 0.77080. lr 5.160782e-04:  49%|████▉     | 1397/2863 [16:54<17:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1397: train loss 0.80238. lr 5.159640e-04:  49%|████▉     | 1397/2863 [16:55<17:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1397: train loss 0.80238. lr 5.159640e-04:  49%|████▉     | 1398/2863 [16:55<17:14,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1398: train loss 0.79906. lr 5.158497e-04:  49%|████▉     | 1398/2863 [16:55<17:14,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1398: train loss 0.79906. lr 5.158497e-04:  49%|████▉     | 1399/2863 [16:55<17:07,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1399: train loss 0.78241. lr 5.157353e-04:  49%|████▉     | 1399/2863 [16:56<17:07,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1399: train loss 0.78241. lr 5.157353e-04:  49%|████▉     | 1400/2863 [16:56<17:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1400: train loss 0.79361. lr 5.156208e-04:  49%|████▉     | 1400/2863 [16:57<17:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1400: train loss 0.79361. lr 5.156208e-04:  49%|████▉     | 1401/2863 [16:57<16:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1401: train loss 0.79117. lr 5.155063e-04:  49%|████▉     | 1401/2863 [16:57<16:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1401: train loss 0.79117. lr 5.155063e-04:  49%|████▉     | 1402/2863 [16:57<16:50,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1402: train loss 0.75562. lr 5.153918e-04:  49%|████▉     | 1402/2863 [16:58<16:50,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1402: train loss 0.75562. lr 5.153918e-04:  49%|████▉     | 1403/2863 [16:58<16:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1403: train loss 0.79358. lr 5.152771e-04:  49%|████▉     | 1403/2863 [16:59<16:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1403: train loss 0.79358. lr 5.152771e-04:  49%|████▉     | 1404/2863 [16:59<16:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1404: train loss 0.77116. lr 5.151624e-04:  49%|████▉     | 1404/2863 [17:00<16:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1404: train loss 0.77116. lr 5.151624e-04:  49%|████▉     | 1405/2863 [17:00<16:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1405: train loss 0.78141. lr 5.150477e-04:  49%|████▉     | 1405/2863 [17:00<16:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1405: train loss 0.78141. lr 5.150477e-04:  49%|████▉     | 1406/2863 [17:00<16:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1406: train loss 0.75578. lr 5.149328e-04:  49%|████▉     | 1406/2863 [17:01<16:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1406: train loss 0.75578. lr 5.149328e-04:  49%|████▉     | 1407/2863 [17:01<16:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1407: train loss 0.74968. lr 5.148179e-04:  49%|████▉     | 1407/2863 [17:02<16:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1407: train loss 0.74968. lr 5.148179e-04:  49%|████▉     | 1408/2863 [17:02<16:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1408: train loss 0.79292. lr 5.147030e-04:  49%|████▉     | 1408/2863 [17:02<16:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1408: train loss 0.79292. lr 5.147030e-04:  49%|████▉     | 1409/2863 [17:02<17:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1409: train loss 0.73486. lr 5.145879e-04:  49%|████▉     | 1409/2863 [17:03<17:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1409: train loss 0.73486. lr 5.145879e-04:  49%|████▉     | 1410/2863 [17:03<17:15,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1410: train loss 0.78324. lr 5.144728e-04:  49%|████▉     | 1410/2863 [17:04<17:15,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1410: train loss 0.78324. lr 5.144728e-04:  49%|████▉     | 1411/2863 [17:04<17:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1411: train loss 0.79120. lr 5.143577e-04:  49%|████▉     | 1411/2863 [17:04<17:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1411: train loss 0.79120. lr 5.143577e-04:  49%|████▉     | 1412/2863 [17:04<17:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1412: train loss 0.77426. lr 5.142425e-04:  49%|████▉     | 1412/2863 [17:05<17:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1412: train loss 0.77426. lr 5.142425e-04:  49%|████▉     | 1413/2863 [17:05<16:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1413: train loss 0.76628. lr 5.141272e-04:  49%|████▉     | 1413/2863 [17:06<16:57,  1.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1413: train loss 0.76628. lr 5.141272e-04:  49%|████▉     | 1414/2863 [17:06<18:00,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1414: train loss 0.73963. lr 5.140118e-04:  49%|████▉     | 1414/2863 [17:07<18:00,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1414: train loss 0.73963. lr 5.140118e-04:  49%|████▉     | 1415/2863 [17:07<17:50,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1415: train loss 0.75841. lr 5.138964e-04:  49%|████▉     | 1415/2863 [17:07<17:50,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1415: train loss 0.75841. lr 5.138964e-04:  49%|████▉     | 1416/2863 [17:07<17:44,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1416: train loss 0.77876. lr 5.137809e-04:  49%|████▉     | 1416/2863 [17:08<17:44,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1416: train loss 0.77876. lr 5.137809e-04:  49%|████▉     | 1417/2863 [17:08<17:34,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1417: train loss 0.76134. lr 5.136654e-04:  49%|████▉     | 1417/2863 [17:09<17:34,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1417: train loss 0.76134. lr 5.136654e-04:  50%|████▉     | 1418/2863 [17:09<17:26,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1418: train loss 0.78602. lr 5.135498e-04:  50%|████▉     | 1418/2863 [17:10<17:26,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1418: train loss 0.78602. lr 5.135498e-04:  50%|████▉     | 1419/2863 [17:10<17:17,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1419: train loss 0.73992. lr 5.134341e-04:  50%|████▉     | 1419/2863 [17:10<17:17,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1419: train loss 0.73992. lr 5.134341e-04:  50%|████▉     | 1420/2863 [17:10<17:11,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1420: train loss 0.75505. lr 5.133184e-04:  50%|████▉     | 1420/2863 [17:11<17:11,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1420: train loss 0.75505. lr 5.133184e-04:  50%|████▉     | 1421/2863 [17:11<17:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1421: train loss 0.76125. lr 5.132026e-04:  50%|████▉     | 1421/2863 [17:12<17:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1421: train loss 0.76125. lr 5.132026e-04:  50%|████▉     | 1422/2863 [17:12<16:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1422: train loss 0.74711. lr 5.130867e-04:  50%|████▉     | 1422/2863 [17:12<16:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1422: train loss 0.74711. lr 5.130867e-04:  50%|████▉     | 1423/2863 [17:12<16:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1423: train loss 0.75350. lr 5.129708e-04:  50%|████▉     | 1423/2863 [17:13<16:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1423: train loss 0.75350. lr 5.129708e-04:  50%|████▉     | 1424/2863 [17:13<16:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1424: train loss 0.76607. lr 5.128548e-04:  50%|████▉     | 1424/2863 [17:14<16:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1424: train loss 0.76607. lr 5.128548e-04:  50%|████▉     | 1425/2863 [17:14<16:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1425: train loss 0.76299. lr 5.127387e-04:  50%|████▉     | 1425/2863 [17:14<16:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1425: train loss 0.76299. lr 5.127387e-04:  50%|████▉     | 1426/2863 [17:14<16:49,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1426: train loss 0.78015. lr 5.126226e-04:  50%|████▉     | 1426/2863 [17:15<16:49,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1426: train loss 0.78015. lr 5.126226e-04:  50%|████▉     | 1427/2863 [17:15<16:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1427: train loss 0.75718. lr 5.125064e-04:  50%|████▉     | 1427/2863 [17:16<16:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1427: train loss 0.75718. lr 5.125064e-04:  50%|████▉     | 1428/2863 [17:16<16:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1428: train loss 0.76850. lr 5.123902e-04:  50%|████▉     | 1428/2863 [17:17<16:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1428: train loss 0.76850. lr 5.123902e-04:  50%|████▉     | 1429/2863 [17:17<16:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1429: train loss 0.73572. lr 5.122739e-04:  50%|████▉     | 1429/2863 [17:17<16:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1429: train loss 0.73572. lr 5.122739e-04:  50%|████▉     | 1430/2863 [17:17<16:43,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1430: train loss 0.73165. lr 5.121575e-04:  50%|████▉     | 1430/2863 [17:18<16:43,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1430: train loss 0.73165. lr 5.121575e-04:  50%|████▉     | 1431/2863 [17:18<16:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1431: train loss 0.74345. lr 5.120411e-04:  50%|████▉     | 1431/2863 [17:19<16:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1431: train loss 0.74345. lr 5.120411e-04:  50%|█████     | 1432/2863 [17:19<16:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1432: train loss 0.74638. lr 5.119246e-04:  50%|█████     | 1432/2863 [17:19<16:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1432: train loss 0.74638. lr 5.119246e-04:  50%|█████     | 1433/2863 [17:19<17:20,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1433: train loss 0.74658. lr 5.118080e-04:  50%|█████     | 1433/2863 [17:20<17:20,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1433: train loss 0.74658. lr 5.118080e-04:  50%|█████     | 1434/2863 [17:20<17:46,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1434: train loss 0.75089. lr 5.116914e-04:  50%|█████     | 1434/2863 [17:21<17:46,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1434: train loss 0.75089. lr 5.116914e-04:  50%|█████     | 1435/2863 [17:21<17:50,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1435: train loss 0.72334. lr 5.115747e-04:  50%|█████     | 1435/2863 [17:22<17:50,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1435: train loss 0.72334. lr 5.115747e-04:  50%|█████     | 1436/2863 [17:22<17:44,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1436: train loss 0.72452. lr 5.114579e-04:  50%|█████     | 1436/2863 [17:22<17:44,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1436: train loss 0.72452. lr 5.114579e-04:  50%|█████     | 1437/2863 [17:22<17:33,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1437: train loss 0.73202. lr 5.113411e-04:  50%|█████     | 1437/2863 [17:23<17:33,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1437: train loss 0.73202. lr 5.113411e-04:  50%|█████     | 1438/2863 [17:23<17:22,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1438: train loss 0.69761. lr 5.112242e-04:  50%|█████     | 1438/2863 [17:24<17:22,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1438: train loss 0.69761. lr 5.112242e-04:  50%|█████     | 1439/2863 [17:24<17:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1439: train loss 0.73516. lr 5.111072e-04:  50%|█████     | 1439/2863 [17:25<17:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1439: train loss 0.73516. lr 5.111072e-04:  50%|█████     | 1440/2863 [17:25<16:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1440: train loss 0.72884. lr 5.109902e-04:  50%|█████     | 1440/2863 [17:25<16:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1440: train loss 0.72884. lr 5.109902e-04:  50%|█████     | 1441/2863 [17:25<16:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1441: train loss 0.74279. lr 5.108731e-04:  50%|█████     | 1441/2863 [17:26<16:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1441: train loss 0.74279. lr 5.108731e-04:  50%|█████     | 1442/2863 [17:26<17:24,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1442: train loss 0.74979. lr 5.107560e-04:  50%|█████     | 1442/2863 [17:27<17:24,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1442: train loss 0.74979. lr 5.107560e-04:  50%|█████     | 1443/2863 [17:27<17:04,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1443: train loss 0.74788. lr 5.106388e-04:  50%|█████     | 1443/2863 [17:27<17:04,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1443: train loss 0.74788. lr 5.106388e-04:  50%|█████     | 1444/2863 [17:27<16:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1444: train loss 0.71625. lr 5.105215e-04:  50%|█████     | 1444/2863 [17:28<16:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1444: train loss 0.71625. lr 5.105215e-04:  50%|█████     | 1445/2863 [17:28<16:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1445: train loss 0.72301. lr 5.104042e-04:  50%|█████     | 1445/2863 [17:29<16:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1445: train loss 0.72301. lr 5.104042e-04:  51%|█████     | 1446/2863 [17:29<16:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1446: train loss 0.71407. lr 5.102868e-04:  51%|█████     | 1446/2863 [17:30<16:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1446: train loss 0.71407. lr 5.102868e-04:  51%|█████     | 1447/2863 [17:30<16:34,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1447: train loss 0.72168. lr 5.101693e-04:  51%|█████     | 1447/2863 [17:30<16:34,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1447: train loss 0.72168. lr 5.101693e-04:  51%|█████     | 1448/2863 [17:30<16:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1448: train loss 0.70186. lr 5.100518e-04:  51%|█████     | 1448/2863 [17:31<16:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1448: train loss 0.70186. lr 5.100518e-04:  51%|█████     | 1449/2863 [17:31<16:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1449: train loss 0.73181. lr 5.099342e-04:  51%|█████     | 1449/2863 [17:32<16:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1449: train loss 0.73181. lr 5.099342e-04:  51%|█████     | 1450/2863 [17:32<16:22,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1450: train loss 0.72015. lr 5.098166e-04:  51%|█████     | 1450/2863 [17:32<16:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1450: train loss 0.72015. lr 5.098166e-04:  51%|█████     | 1451/2863 [17:32<16:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1451: train loss 0.72938. lr 5.096989e-04:  51%|█████     | 1451/2863 [17:33<16:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1451: train loss 0.72938. lr 5.096989e-04:  51%|█████     | 1452/2863 [17:33<16:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1452: train loss 0.71430. lr 5.095811e-04:  51%|█████     | 1452/2863 [17:34<16:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1452: train loss 0.71430. lr 5.095811e-04:  51%|█████     | 1453/2863 [17:34<16:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1453: train loss 0.71744. lr 5.094633e-04:  51%|█████     | 1453/2863 [17:34<16:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1453: train loss 0.71744. lr 5.094633e-04:  51%|█████     | 1454/2863 [17:34<16:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1454: train loss 0.70759. lr 5.093454e-04:  51%|█████     | 1454/2863 [17:35<16:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1454: train loss 0.70759. lr 5.093454e-04:  51%|█████     | 1455/2863 [17:35<16:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1455: train loss 0.69659. lr 5.092274e-04:  51%|█████     | 1455/2863 [17:36<16:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1455: train loss 0.69659. lr 5.092274e-04:  51%|█████     | 1456/2863 [17:36<16:12,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1456: train loss 0.71276. lr 5.091094e-04:  51%|█████     | 1456/2863 [17:36<16:12,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1456: train loss 0.71276. lr 5.091094e-04:  51%|█████     | 1457/2863 [17:36<16:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1457: train loss 0.72848. lr 5.089913e-04:  51%|█████     | 1457/2863 [17:37<16:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1457: train loss 0.72848. lr 5.089913e-04:  51%|█████     | 1458/2863 [17:37<16:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1458: train loss 0.72705. lr 5.088731e-04:  51%|█████     | 1458/2863 [17:38<16:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1458: train loss 0.72705. lr 5.088731e-04:  51%|█████     | 1459/2863 [17:38<16:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1459: train loss 0.71161. lr 5.087549e-04:  51%|█████     | 1459/2863 [17:39<16:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1459: train loss 0.71161. lr 5.087549e-04:  51%|█████     | 1460/2863 [17:39<16:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1460: train loss 0.68980. lr 5.086366e-04:  51%|█████     | 1460/2863 [17:39<16:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1460: train loss 0.68980. lr 5.086366e-04:  51%|█████     | 1461/2863 [17:39<16:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1461: train loss 0.69130. lr 5.085183e-04:  51%|█████     | 1461/2863 [17:40<16:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1461: train loss 0.69130. lr 5.085183e-04:  51%|█████     | 1462/2863 [17:40<16:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1462: train loss 0.71489. lr 5.083999e-04:  51%|█████     | 1462/2863 [17:41<16:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1462: train loss 0.71489. lr 5.083999e-04:  51%|█████     | 1463/2863 [17:41<16:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1463: train loss 0.69493. lr 5.082814e-04:  51%|█████     | 1463/2863 [17:41<16:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1463: train loss 0.69493. lr 5.082814e-04:  51%|█████     | 1464/2863 [17:41<16:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1464: train loss 0.68826. lr 5.081629e-04:  51%|█████     | 1464/2863 [17:42<16:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1464: train loss 0.68826. lr 5.081629e-04:  51%|█████     | 1465/2863 [17:42<16:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1465: train loss 0.69749. lr 5.080443e-04:  51%|█████     | 1465/2863 [17:43<16:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1465: train loss 0.69749. lr 5.080443e-04:  51%|█████     | 1466/2863 [17:43<16:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1466: train loss 0.72483. lr 5.079257e-04:  51%|█████     | 1466/2863 [17:43<16:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1466: train loss 0.72483. lr 5.079257e-04:  51%|█████     | 1467/2863 [17:43<16:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1467: train loss 0.69492. lr 5.078069e-04:  51%|█████     | 1467/2863 [17:44<16:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1467: train loss 0.69492. lr 5.078069e-04:  51%|█████▏    | 1468/2863 [17:44<16:20,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1468: train loss 0.69975. lr 5.076882e-04:  51%|█████▏    | 1468/2863 [17:45<16:20,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1468: train loss 0.69975. lr 5.076882e-04:  51%|█████▏    | 1469/2863 [17:45<16:23,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1469: train loss 0.71644. lr 5.075693e-04:  51%|█████▏    | 1469/2863 [17:46<16:23,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1469: train loss 0.71644. lr 5.075693e-04:  51%|█████▏    | 1470/2863 [17:46<17:12,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1470: train loss 0.69859. lr 5.074504e-04:  51%|█████▏    | 1470/2863 [17:46<17:12,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1470: train loss 0.69859. lr 5.074504e-04:  51%|█████▏    | 1471/2863 [17:46<16:55,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1471: train loss 0.69956. lr 5.073314e-04:  51%|█████▏    | 1471/2863 [17:47<16:55,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1471: train loss 0.69956. lr 5.073314e-04:  51%|█████▏    | 1472/2863 [17:47<16:42,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1472: train loss 0.68265. lr 5.072124e-04:  51%|█████▏    | 1472/2863 [17:48<16:42,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1472: train loss 0.68265. lr 5.072124e-04:  51%|█████▏    | 1473/2863 [17:48<16:29,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1473: train loss 0.70134. lr 5.070933e-04:  51%|█████▏    | 1473/2863 [17:49<16:29,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1473: train loss 0.70134. lr 5.070933e-04:  51%|█████▏    | 1474/2863 [17:49<16:19,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1474: train loss 0.69936. lr 5.069742e-04:  51%|█████▏    | 1474/2863 [17:49<16:19,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1474: train loss 0.69936. lr 5.069742e-04:  52%|█████▏    | 1475/2863 [17:49<16:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1475: train loss 0.69059. lr 5.068549e-04:  52%|█████▏    | 1475/2863 [17:50<16:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1475: train loss 0.69059. lr 5.068549e-04:  52%|█████▏    | 1476/2863 [17:50<16:14,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1476: train loss 0.71423. lr 5.067357e-04:  52%|█████▏    | 1476/2863 [17:51<16:14,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1476: train loss 0.71423. lr 5.067357e-04:  52%|█████▏    | 1477/2863 [17:51<16:13,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1477: train loss 0.71721. lr 5.066163e-04:  52%|█████▏    | 1477/2863 [17:51<16:13,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1477: train loss 0.71721. lr 5.066163e-04:  52%|█████▏    | 1478/2863 [17:51<16:38,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1478: train loss 0.68699. lr 5.064969e-04:  52%|█████▏    | 1478/2863 [17:52<16:38,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1478: train loss 0.68699. lr 5.064969e-04:  52%|█████▏    | 1479/2863 [17:52<16:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1479: train loss 0.66381. lr 5.063775e-04:  52%|█████▏    | 1479/2863 [17:53<16:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1479: train loss 0.66381. lr 5.063775e-04:  52%|█████▏    | 1480/2863 [17:53<17:00,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1480: train loss 0.67674. lr 5.062579e-04:  52%|█████▏    | 1480/2863 [17:54<17:00,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1480: train loss 0.67674. lr 5.062579e-04:  52%|█████▏    | 1481/2863 [17:54<16:52,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1481: train loss 0.70011. lr 5.061383e-04:  52%|█████▏    | 1481/2863 [17:54<16:52,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1481: train loss 0.70011. lr 5.061383e-04:  52%|█████▏    | 1482/2863 [17:54<16:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1482: train loss 0.71278. lr 5.060187e-04:  52%|█████▏    | 1482/2863 [17:55<16:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1482: train loss 0.71278. lr 5.060187e-04:  52%|█████▏    | 1483/2863 [17:55<16:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1483: train loss 0.68316. lr 5.058990e-04:  52%|█████▏    | 1483/2863 [17:56<16:35,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1483: train loss 0.68316. lr 5.058990e-04:  52%|█████▏    | 1484/2863 [17:56<16:26,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1484: train loss 0.68397. lr 5.057792e-04:  52%|█████▏    | 1484/2863 [17:56<16:26,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1484: train loss 0.68397. lr 5.057792e-04:  52%|█████▏    | 1485/2863 [17:56<16:16,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1485: train loss 0.69865. lr 5.056593e-04:  52%|█████▏    | 1485/2863 [17:57<16:16,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1485: train loss 0.69865. lr 5.056593e-04:  52%|█████▏    | 1486/2863 [17:57<16:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1486: train loss 0.69264. lr 5.055394e-04:  52%|█████▏    | 1486/2863 [17:58<16:06,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1486: train loss 0.69264. lr 5.055394e-04:  52%|█████▏    | 1487/2863 [17:58<16:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1487: train loss 0.68479. lr 5.054195e-04:  52%|█████▏    | 1487/2863 [17:58<16:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1487: train loss 0.68479. lr 5.054195e-04:  52%|█████▏    | 1488/2863 [17:58<15:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1488: train loss 0.67216. lr 5.052995e-04:  52%|█████▏    | 1488/2863 [17:59<15:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1488: train loss 0.67216. lr 5.052995e-04:  52%|█████▏    | 1489/2863 [17:59<15:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1489: train loss 0.68720. lr 5.051794e-04:  52%|█████▏    | 1489/2863 [18:00<15:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1489: train loss 0.68720. lr 5.051794e-04:  52%|█████▏    | 1490/2863 [18:00<15:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1490: train loss 0.66206. lr 5.050592e-04:  52%|█████▏    | 1490/2863 [18:01<15:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1490: train loss 0.66206. lr 5.050592e-04:  52%|█████▏    | 1491/2863 [18:01<15:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1491: train loss 0.67095. lr 5.049390e-04:  52%|█████▏    | 1491/2863 [18:01<15:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1491: train loss 0.67095. lr 5.049390e-04:  52%|█████▏    | 1492/2863 [18:01<15:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1492: train loss 0.69169. lr 5.048187e-04:  52%|█████▏    | 1492/2863 [18:02<15:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1492: train loss 0.69169. lr 5.048187e-04:  52%|█████▏    | 1493/2863 [18:02<15:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1493: train loss 0.67425. lr 5.046984e-04:  52%|█████▏    | 1493/2863 [18:03<15:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1493: train loss 0.67425. lr 5.046984e-04:  52%|█████▏    | 1494/2863 [18:03<15:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1494: train loss 0.67469. lr 5.045780e-04:  52%|█████▏    | 1494/2863 [18:03<15:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1494: train loss 0.67469. lr 5.045780e-04:  52%|█████▏    | 1495/2863 [18:03<15:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1495: train loss 0.69915. lr 5.044576e-04:  52%|█████▏    | 1495/2863 [18:04<15:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1495: train loss 0.69915. lr 5.044576e-04:  52%|█████▏    | 1496/2863 [18:04<15:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1496: train loss 0.66054. lr 5.043370e-04:  52%|█████▏    | 1496/2863 [18:05<15:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1496: train loss 0.66054. lr 5.043370e-04:  52%|█████▏    | 1497/2863 [18:05<15:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1497: train loss 0.66358. lr 5.042165e-04:  52%|█████▏    | 1497/2863 [18:06<15:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1497: train loss 0.66358. lr 5.042165e-04:  52%|█████▏    | 1498/2863 [18:06<16:46,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1498: train loss 0.68639. lr 5.040958e-04:  52%|█████▏    | 1498/2863 [18:06<16:46,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1498: train loss 0.68639. lr 5.040958e-04:  52%|█████▏    | 1499/2863 [18:06<16:34,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1499: train loss 0.68182. lr 5.039751e-04:  52%|█████▏    | 1499/2863 [18:07<16:34,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1499: train loss 0.68182. lr 5.039751e-04:  52%|█████▏    | 1500/2863 [18:07<16:22,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1500: train loss 0.66519. lr 5.038544e-04:  52%|█████▏    | 1500/2863 [18:08<16:22,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1500: train loss 0.66519. lr 5.038544e-04:  52%|█████▏    | 1501/2863 [18:08<16:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1501: train loss 0.67423. lr 5.037335e-04:  52%|█████▏    | 1501/2863 [18:08<16:13,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1501: train loss 0.67423. lr 5.037335e-04:  52%|█████▏    | 1502/2863 [18:08<16:01,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1502: train loss 0.68691. lr 5.036126e-04:  52%|█████▏    | 1502/2863 [18:09<16:01,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1502: train loss 0.68691. lr 5.036126e-04:  52%|█████▏    | 1503/2863 [18:09<16:08,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1503: train loss 0.66480. lr 5.034917e-04:  52%|█████▏    | 1503/2863 [18:10<16:08,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1503: train loss 0.66480. lr 5.034917e-04:  53%|█████▎    | 1504/2863 [18:10<16:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1504: train loss 0.64507. lr 5.033707e-04:  53%|█████▎    | 1504/2863 [18:10<16:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1504: train loss 0.64507. lr 5.033707e-04:  53%|█████▎    | 1505/2863 [18:11<16:07,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1505: train loss 0.67613. lr 5.032496e-04:  53%|█████▎    | 1505/2863 [18:11<16:07,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1505: train loss 0.67613. lr 5.032496e-04:  53%|█████▎    | 1506/2863 [18:11<16:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1506: train loss 0.66289. lr 5.031285e-04:  53%|█████▎    | 1506/2863 [18:12<16:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1506: train loss 0.66289. lr 5.031285e-04:  53%|█████▎    | 1507/2863 [18:12<15:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1507: train loss 0.67553. lr 5.030073e-04:  53%|█████▎    | 1507/2863 [18:13<15:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1507: train loss 0.67553. lr 5.030073e-04:  53%|█████▎    | 1508/2863 [18:13<15:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1508: train loss 0.66992. lr 5.028860e-04:  53%|█████▎    | 1508/2863 [18:13<15:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1508: train loss 0.66992. lr 5.028860e-04:  53%|█████▎    | 1509/2863 [18:13<15:47,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1509: train loss 0.66286. lr 5.027647e-04:  53%|█████▎    | 1509/2863 [18:14<15:47,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1509: train loss 0.66286. lr 5.027647e-04:  53%|█████▎    | 1510/2863 [18:14<15:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1510: train loss 0.66243. lr 5.026433e-04:  53%|█████▎    | 1510/2863 [18:15<15:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1510: train loss 0.66243. lr 5.026433e-04:  53%|█████▎    | 1511/2863 [18:15<15:50,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1511: train loss 0.66629. lr 5.025219e-04:  53%|█████▎    | 1511/2863 [18:15<15:50,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1511: train loss 0.66629. lr 5.025219e-04:  53%|█████▎    | 1512/2863 [18:15<15:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1512: train loss 0.65781. lr 5.024004e-04:  53%|█████▎    | 1512/2863 [18:16<15:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1512: train loss 0.65781. lr 5.024004e-04:  53%|█████▎    | 1513/2863 [18:16<15:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1513: train loss 0.68447. lr 5.022788e-04:  53%|█████▎    | 1513/2863 [18:17<15:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1513: train loss 0.68447. lr 5.022788e-04:  53%|█████▎    | 1514/2863 [18:17<15:44,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1514: train loss 0.66775. lr 5.021572e-04:  53%|█████▎    | 1514/2863 [18:17<15:44,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1514: train loss 0.66775. lr 5.021572e-04:  53%|█████▎    | 1515/2863 [18:17<15:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1515: train loss 0.66922. lr 5.020355e-04:  53%|█████▎    | 1515/2863 [18:18<15:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1515: train loss 0.66922. lr 5.020355e-04:  53%|█████▎    | 1516/2863 [18:18<15:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1516: train loss 0.66118. lr 5.019138e-04:  53%|█████▎    | 1516/2863 [18:19<15:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1516: train loss 0.66118. lr 5.019138e-04:  53%|█████▎    | 1517/2863 [18:19<15:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1517: train loss 0.66335. lr 5.017920e-04:  53%|█████▎    | 1517/2863 [18:20<15:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1517: train loss 0.66335. lr 5.017920e-04:  53%|█████▎    | 1518/2863 [18:20<15:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1518: train loss 0.66627. lr 5.016701e-04:  53%|█████▎    | 1518/2863 [18:20<15:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1518: train loss 0.66627. lr 5.016701e-04:  53%|█████▎    | 1519/2863 [18:20<15:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1519: train loss 0.66125. lr 5.015482e-04:  53%|█████▎    | 1519/2863 [18:21<15:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1519: train loss 0.66125. lr 5.015482e-04:  53%|█████▎    | 1520/2863 [18:21<15:28,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1520: train loss 0.65683. lr 5.014262e-04:  53%|█████▎    | 1520/2863 [18:22<15:28,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1520: train loss 0.65683. lr 5.014262e-04:  53%|█████▎    | 1521/2863 [18:22<15:53,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1521: train loss 0.66340. lr 5.013042e-04:  53%|█████▎    | 1521/2863 [18:22<15:53,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1521: train loss 0.66340. lr 5.013042e-04:  53%|█████▎    | 1522/2863 [18:22<15:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1522: train loss 0.64305. lr 5.011821e-04:  53%|█████▎    | 1522/2863 [18:23<15:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1522: train loss 0.64305. lr 5.011821e-04:  53%|█████▎    | 1523/2863 [18:23<15:41,  1.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1523: train loss 0.65089. lr 5.010599e-04:  53%|█████▎    | 1523/2863 [18:24<15:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1523: train loss 0.65089. lr 5.010599e-04:  53%|█████▎    | 1524/2863 [18:24<15:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1524: train loss 0.65256. lr 5.009377e-04:  53%|█████▎    | 1524/2863 [18:24<15:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1524: train loss 0.65256. lr 5.009377e-04:  53%|█████▎    | 1525/2863 [18:24<15:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1525: train loss 0.64227. lr 5.008154e-04:  53%|█████▎    | 1525/2863 [18:25<15:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1525: train loss 0.64227. lr 5.008154e-04:  53%|█████▎    | 1526/2863 [18:25<16:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1526: train loss 0.64358. lr 5.006930e-04:  53%|█████▎    | 1526/2863 [18:26<16:16,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1526: train loss 0.64358. lr 5.006930e-04:  53%|█████▎    | 1527/2863 [18:26<16:01,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1527: train loss 0.64927. lr 5.005706e-04:  53%|█████▎    | 1527/2863 [18:27<16:01,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1527: train loss 0.64927. lr 5.005706e-04:  53%|█████▎    | 1528/2863 [18:27<15:50,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1528: train loss 0.65589. lr 5.004482e-04:  53%|█████▎    | 1528/2863 [18:27<15:50,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1528: train loss 0.65589. lr 5.004482e-04:  53%|█████▎    | 1529/2863 [18:27<15:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1529: train loss 0.65724. lr 5.003256e-04:  53%|█████▎    | 1529/2863 [18:28<15:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1529: train loss 0.65724. lr 5.003256e-04:  53%|█████▎    | 1530/2863 [18:28<15:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1530: train loss 0.63033. lr 5.002030e-04:  53%|█████▎    | 1530/2863 [18:29<15:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1530: train loss 0.63033. lr 5.002030e-04:  53%|█████▎    | 1531/2863 [18:29<15:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1531: train loss 0.63968. lr 5.000804e-04:  53%|█████▎    | 1531/2863 [18:29<15:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1531: train loss 0.63968. lr 5.000804e-04:  54%|█████▎    | 1532/2863 [18:29<15:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1532: train loss 0.64350. lr 4.999577e-04:  54%|█████▎    | 1532/2863 [18:30<15:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1532: train loss 0.64350. lr 4.999577e-04:  54%|█████▎    | 1533/2863 [18:30<15:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1533: train loss 0.64601. lr 4.998349e-04:  54%|█████▎    | 1533/2863 [18:31<15:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1533: train loss 0.64601. lr 4.998349e-04:  54%|█████▎    | 1534/2863 [18:31<15:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1534: train loss 0.66441. lr 4.997121e-04:  54%|█████▎    | 1534/2863 [18:32<15:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1534: train loss 0.66441. lr 4.997121e-04:  54%|█████▎    | 1535/2863 [18:32<15:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1535: train loss 0.64860. lr 4.995892e-04:  54%|█████▎    | 1535/2863 [18:32<15:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1535: train loss 0.64860. lr 4.995892e-04:  54%|█████▎    | 1536/2863 [18:32<15:24,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1536: train loss 0.64902. lr 4.994662e-04:  54%|█████▎    | 1536/2863 [18:33<15:24,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1536: train loss 0.64902. lr 4.994662e-04:  54%|█████▎    | 1537/2863 [18:33<15:24,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1537: train loss 0.62435. lr 4.993432e-04:  54%|█████▎    | 1537/2863 [18:34<15:24,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1537: train loss 0.62435. lr 4.993432e-04:  54%|█████▎    | 1538/2863 [18:34<15:24,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1538: train loss 0.64977. lr 4.992201e-04:  54%|█████▎    | 1538/2863 [18:34<15:24,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1538: train loss 0.64977. lr 4.992201e-04:  54%|█████▍    | 1539/2863 [18:34<15:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1539: train loss 0.64494. lr 4.990970e-04:  54%|█████▍    | 1539/2863 [18:35<15:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1539: train loss 0.64494. lr 4.990970e-04:  54%|█████▍    | 1540/2863 [18:35<15:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1540: train loss 0.64291. lr 4.989738e-04:  54%|█████▍    | 1540/2863 [18:36<15:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1540: train loss 0.64291. lr 4.989738e-04:  54%|█████▍    | 1541/2863 [18:36<15:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1541: train loss 0.65586. lr 4.988506e-04:  54%|█████▍    | 1541/2863 [18:36<15:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1541: train loss 0.65586. lr 4.988506e-04:  54%|█████▍    | 1542/2863 [18:36<15:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1542: train loss 0.62194. lr 4.987273e-04:  54%|█████▍    | 1542/2863 [18:37<15:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1542: train loss 0.62194. lr 4.987273e-04:  54%|█████▍    | 1543/2863 [18:37<15:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1543: train loss 0.65191. lr 4.986039e-04:  54%|█████▍    | 1543/2863 [18:38<15:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1543: train loss 0.65191. lr 4.986039e-04:  54%|█████▍    | 1544/2863 [18:38<15:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1544: train loss 0.63576. lr 4.984805e-04:  54%|█████▍    | 1544/2863 [18:38<15:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1544: train loss 0.63576. lr 4.984805e-04:  54%|█████▍    | 1545/2863 [18:38<15:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1545: train loss 0.64735. lr 4.983570e-04:  54%|█████▍    | 1545/2863 [18:39<15:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1545: train loss 0.64735. lr 4.983570e-04:  54%|█████▍    | 1546/2863 [18:39<15:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1546: train loss 0.62994. lr 4.982334e-04:  54%|█████▍    | 1546/2863 [18:40<15:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1546: train loss 0.62994. lr 4.982334e-04:  54%|█████▍    | 1547/2863 [18:40<15:11,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1547: train loss 0.63723. lr 4.981098e-04:  54%|█████▍    | 1547/2863 [18:41<15:11,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1547: train loss 0.63723. lr 4.981098e-04:  54%|█████▍    | 1548/2863 [18:41<15:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1548: train loss 0.65152. lr 4.979861e-04:  54%|█████▍    | 1548/2863 [18:41<15:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1548: train loss 0.65152. lr 4.979861e-04:  54%|█████▍    | 1549/2863 [18:41<15:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1549: train loss 0.62312. lr 4.978624e-04:  54%|█████▍    | 1549/2863 [18:42<15:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1549: train loss 0.62312. lr 4.978624e-04:  54%|█████▍    | 1550/2863 [18:42<15:05,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1550: train loss 0.63474. lr 4.977386e-04:  54%|█████▍    | 1550/2863 [18:43<15:05,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1550: train loss 0.63474. lr 4.977386e-04:  54%|█████▍    | 1551/2863 [18:43<15:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1551: train loss 0.63483. lr 4.976148e-04:  54%|█████▍    | 1551/2863 [18:44<15:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1551: train loss 0.63483. lr 4.976148e-04:  54%|█████▍    | 1552/2863 [18:44<16:23,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1552: train loss 0.62800. lr 4.974909e-04:  54%|█████▍    | 1552/2863 [18:44<16:23,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1552: train loss 0.62800. lr 4.974909e-04:  54%|█████▍    | 1553/2863 [18:44<16:46,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1553: train loss 0.62107. lr 4.973669e-04:  54%|█████▍    | 1553/2863 [18:45<16:46,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1553: train loss 0.62107. lr 4.973669e-04:  54%|█████▍    | 1554/2863 [18:45<17:23,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1554: train loss 0.61829. lr 4.972429e-04:  54%|█████▍    | 1554/2863 [18:46<17:23,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1554: train loss 0.61829. lr 4.972429e-04:  54%|█████▍    | 1555/2863 [18:46<16:55,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1555: train loss 0.63738. lr 4.971188e-04:  54%|█████▍    | 1555/2863 [18:47<16:55,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1555: train loss 0.63738. lr 4.971188e-04:  54%|█████▍    | 1556/2863 [18:47<16:31,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1556: train loss 0.62958. lr 4.969946e-04:  54%|█████▍    | 1556/2863 [18:47<16:31,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1556: train loss 0.62958. lr 4.969946e-04:  54%|█████▍    | 1557/2863 [18:47<16:11,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1557: train loss 0.61885. lr 4.968704e-04:  54%|█████▍    | 1557/2863 [18:48<16:11,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1557: train loss 0.61885. lr 4.968704e-04:  54%|█████▍    | 1558/2863 [18:48<15:55,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1558: train loss 0.61429. lr 4.967462e-04:  54%|█████▍    | 1558/2863 [18:49<15:55,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1558: train loss 0.61429. lr 4.967462e-04:  54%|█████▍    | 1559/2863 [18:49<15:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1559: train loss 0.61642. lr 4.966218e-04:  54%|█████▍    | 1559/2863 [18:49<15:41,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1559: train loss 0.61642. lr 4.966218e-04:  54%|█████▍    | 1560/2863 [18:49<15:32,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1560: train loss 0.62418. lr 4.964975e-04:  54%|█████▍    | 1560/2863 [18:50<15:32,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1560: train loss 0.62418. lr 4.964975e-04:  55%|█████▍    | 1561/2863 [18:50<15:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1561: train loss 0.61073. lr 4.963730e-04:  55%|█████▍    | 1561/2863 [18:51<15:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1561: train loss 0.61073. lr 4.963730e-04:  55%|█████▍    | 1562/2863 [18:51<15:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1562: train loss 0.63385. lr 4.962485e-04:  55%|█████▍    | 1562/2863 [18:52<15:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1562: train loss 0.63385. lr 4.962485e-04:  55%|█████▍    | 1563/2863 [18:52<15:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1563: train loss 0.60719. lr 4.961240e-04:  55%|█████▍    | 1563/2863 [18:52<15:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1563: train loss 0.60719. lr 4.961240e-04:  55%|█████▍    | 1564/2863 [18:52<15:14,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1564: train loss 0.60261. lr 4.959993e-04:  55%|█████▍    | 1564/2863 [18:53<15:14,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1564: train loss 0.60261. lr 4.959993e-04:  55%|█████▍    | 1565/2863 [18:53<15:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1565: train loss 0.61836. lr 4.958747e-04:  55%|█████▍    | 1565/2863 [18:54<15:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1565: train loss 0.61836. lr 4.958747e-04:  55%|█████▍    | 1566/2863 [18:54<15:36,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1566: train loss 0.61645. lr 4.957499e-04:  55%|█████▍    | 1566/2863 [18:54<15:36,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1566: train loss 0.61645. lr 4.957499e-04:  55%|█████▍    | 1567/2863 [18:54<15:36,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1567: train loss 0.62443. lr 4.956251e-04:  55%|█████▍    | 1567/2863 [18:55<15:36,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1567: train loss 0.62443. lr 4.956251e-04:  55%|█████▍    | 1568/2863 [18:55<15:34,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1568: train loss 0.62530. lr 4.955003e-04:  55%|█████▍    | 1568/2863 [18:56<15:34,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1568: train loss 0.62530. lr 4.955003e-04:  55%|█████▍    | 1569/2863 [18:56<15:28,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1569: train loss 0.62208. lr 4.953753e-04:  55%|█████▍    | 1569/2863 [18:57<15:28,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1569: train loss 0.62208. lr 4.953753e-04:  55%|█████▍    | 1570/2863 [18:57<15:23,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1570: train loss 0.63347. lr 4.952504e-04:  55%|█████▍    | 1570/2863 [18:57<15:23,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1570: train loss 0.63347. lr 4.952504e-04:  55%|█████▍    | 1571/2863 [18:57<15:18,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1571: train loss 0.60199. lr 4.951253e-04:  55%|█████▍    | 1571/2863 [18:58<15:18,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1571: train loss 0.60199. lr 4.951253e-04:  55%|█████▍    | 1572/2863 [18:58<15:11,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1572: train loss 0.60915. lr 4.950003e-04:  55%|█████▍    | 1572/2863 [18:59<15:11,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1572: train loss 0.60915. lr 4.950003e-04:  55%|█████▍    | 1573/2863 [18:59<15:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1573: train loss 0.60064. lr 4.948751e-04:  55%|█████▍    | 1573/2863 [18:59<15:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1573: train loss 0.60064. lr 4.948751e-04:  55%|█████▍    | 1574/2863 [18:59<14:54,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1574: train loss 0.62564. lr 4.947499e-04:  55%|█████▍    | 1574/2863 [19:00<14:54,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1574: train loss 0.62564. lr 4.947499e-04:  55%|█████▌    | 1575/2863 [19:00<14:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1575: train loss 0.62592. lr 4.946246e-04:  55%|█████▌    | 1575/2863 [19:01<14:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1575: train loss 0.62592. lr 4.946246e-04:  55%|█████▌    | 1576/2863 [19:01<14:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1576: train loss 0.59433. lr 4.944993e-04:  55%|█████▌    | 1576/2863 [19:01<14:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1576: train loss 0.59433. lr 4.944993e-04:  55%|█████▌    | 1577/2863 [19:01<14:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1577: train loss 0.60103. lr 4.943739e-04:  55%|█████▌    | 1577/2863 [19:02<14:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1577: train loss 0.60103. lr 4.943739e-04:  55%|█████▌    | 1578/2863 [19:02<14:55,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1578: train loss 0.62759. lr 4.942485e-04:  55%|█████▌    | 1578/2863 [19:03<14:55,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1578: train loss 0.62759. lr 4.942485e-04:  55%|█████▌    | 1579/2863 [19:03<15:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1579: train loss 0.61892. lr 4.941230e-04:  55%|█████▌    | 1579/2863 [19:04<15:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1579: train loss 0.61892. lr 4.941230e-04:  55%|█████▌    | 1580/2863 [19:04<15:04,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1580: train loss 0.60583. lr 4.939974e-04:  55%|█████▌    | 1580/2863 [19:04<15:04,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1580: train loss 0.60583. lr 4.939974e-04:  55%|█████▌    | 1581/2863 [19:04<15:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1581: train loss 0.58788. lr 4.938718e-04:  55%|█████▌    | 1581/2863 [19:05<15:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1581: train loss 0.58788. lr 4.938718e-04:  55%|█████▌    | 1582/2863 [19:05<15:45,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1582: train loss 0.60102. lr 4.937461e-04:  55%|█████▌    | 1582/2863 [19:06<15:45,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1582: train loss 0.60102. lr 4.937461e-04:  55%|█████▌    | 1583/2863 [19:06<15:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1583: train loss 0.60428. lr 4.936204e-04:  55%|█████▌    | 1583/2863 [19:06<15:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1583: train loss 0.60428. lr 4.936204e-04:  55%|█████▌    | 1584/2863 [19:06<15:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1584: train loss 0.60713. lr 4.934946e-04:  55%|█████▌    | 1584/2863 [19:07<15:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1584: train loss 0.60713. lr 4.934946e-04:  55%|█████▌    | 1585/2863 [19:07<15:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1585: train loss 0.63003. lr 4.933687e-04:  55%|█████▌    | 1585/2863 [19:08<15:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1585: train loss 0.63003. lr 4.933687e-04:  55%|█████▌    | 1586/2863 [19:08<15:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1586: train loss 0.59577. lr 4.932428e-04:  55%|█████▌    | 1586/2863 [19:09<15:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1586: train loss 0.59577. lr 4.932428e-04:  55%|█████▌    | 1587/2863 [19:09<15:14,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1587: train loss 0.61016. lr 4.931169e-04:  55%|█████▌    | 1587/2863 [19:09<15:14,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1587: train loss 0.61016. lr 4.931169e-04:  55%|█████▌    | 1588/2863 [19:09<15:04,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1588: train loss 0.60180. lr 4.929908e-04:  55%|█████▌    | 1588/2863 [19:10<15:04,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1588: train loss 0.60180. lr 4.929908e-04:  56%|█████▌    | 1589/2863 [19:10<14:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1589: train loss 0.59361. lr 4.928647e-04:  56%|█████▌    | 1589/2863 [19:11<14:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1589: train loss 0.59361. lr 4.928647e-04:  56%|█████▌    | 1590/2863 [19:11<14:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1590: train loss 0.60922. lr 4.927386e-04:  56%|█████▌    | 1590/2863 [19:11<14:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1590: train loss 0.60922. lr 4.927386e-04:  56%|█████▌    | 1591/2863 [19:11<14:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1591: train loss 0.59150. lr 4.926124e-04:  56%|█████▌    | 1591/2863 [19:12<14:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1591: train loss 0.59150. lr 4.926124e-04:  56%|█████▌    | 1592/2863 [19:12<14:47,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1592: train loss 0.60934. lr 4.924861e-04:  56%|█████▌    | 1592/2863 [19:13<14:47,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1592: train loss 0.60934. lr 4.924861e-04:  56%|█████▌    | 1593/2863 [19:13<14:45,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1593: train loss 0.60127. lr 4.923598e-04:  56%|█████▌    | 1593/2863 [19:13<14:45,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1593: train loss 0.60127. lr 4.923598e-04:  56%|█████▌    | 1594/2863 [19:13<14:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1594: train loss 0.58088. lr 4.922335e-04:  56%|█████▌    | 1594/2863 [19:14<14:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1594: train loss 0.58088. lr 4.922335e-04:  56%|█████▌    | 1595/2863 [19:14<14:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1595: train loss 0.59928. lr 4.921070e-04:  56%|█████▌    | 1595/2863 [19:15<14:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1595: train loss 0.59928. lr 4.921070e-04:  56%|█████▌    | 1596/2863 [19:15<14:40,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1596: train loss 0.59668. lr 4.919805e-04:  56%|█████▌    | 1596/2863 [19:16<14:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1596: train loss 0.59668. lr 4.919805e-04:  56%|█████▌    | 1597/2863 [19:16<14:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1597: train loss 0.60467. lr 4.918540e-04:  56%|█████▌    | 1597/2863 [19:16<14:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1597: train loss 0.60467. lr 4.918540e-04:  56%|█████▌    | 1598/2863 [19:16<14:33,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1598: train loss 0.57772. lr 4.917274e-04:  56%|█████▌    | 1598/2863 [19:17<14:33,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1598: train loss 0.57772. lr 4.917274e-04:  56%|█████▌    | 1599/2863 [19:17<14:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1599: train loss 0.58758. lr 4.916007e-04:  56%|█████▌    | 1599/2863 [19:18<14:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1599: train loss 0.58758. lr 4.916007e-04:  56%|█████▌    | 1600/2863 [19:18<14:33,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1600: train loss 0.58278. lr 4.914740e-04:  56%|█████▌    | 1600/2863 [19:18<14:33,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1600: train loss 0.58278. lr 4.914740e-04:  56%|█████▌    | 1601/2863 [19:18<14:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1601: train loss 0.60261. lr 4.913472e-04:  56%|█████▌    | 1601/2863 [19:19<14:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1601: train loss 0.60261. lr 4.913472e-04:  56%|█████▌    | 1602/2863 [19:19<14:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1602: train loss 0.58589. lr 4.912204e-04:  56%|█████▌    | 1602/2863 [19:20<14:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1602: train loss 0.58589. lr 4.912204e-04:  56%|█████▌    | 1603/2863 [19:20<15:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1603: train loss 0.59531. lr 4.910935e-04:  56%|█████▌    | 1603/2863 [19:21<15:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1603: train loss 0.59531. lr 4.910935e-04:  56%|█████▌    | 1604/2863 [19:21<15:13,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1604: train loss 0.60937. lr 4.909665e-04:  56%|█████▌    | 1604/2863 [19:21<15:13,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1604: train loss 0.60937. lr 4.909665e-04:  56%|█████▌    | 1605/2863 [19:21<15:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1605: train loss 0.57695. lr 4.908395e-04:  56%|█████▌    | 1605/2863 [19:22<15:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1605: train loss 0.57695. lr 4.908395e-04:  56%|█████▌    | 1606/2863 [19:22<14:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1606: train loss 0.59544. lr 4.907125e-04:  56%|█████▌    | 1606/2863 [19:23<14:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1606: train loss 0.59544. lr 4.907125e-04:  56%|█████▌    | 1607/2863 [19:23<14:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1607: train loss 0.60079. lr 4.905853e-04:  56%|█████▌    | 1607/2863 [19:23<14:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1607: train loss 0.60079. lr 4.905853e-04:  56%|█████▌    | 1608/2863 [19:23<14:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1608: train loss 0.60090. lr 4.904582e-04:  56%|█████▌    | 1608/2863 [19:24<14:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1608: train loss 0.60090. lr 4.904582e-04:  56%|█████▌    | 1609/2863 [19:24<14:31,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1609: train loss 0.58851. lr 4.903309e-04:  56%|█████▌    | 1609/2863 [19:25<14:31,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1609: train loss 0.58851. lr 4.903309e-04:  56%|█████▌    | 1610/2863 [19:25<15:11,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1610: train loss 0.58931. lr 4.902036e-04:  56%|█████▌    | 1610/2863 [19:26<15:11,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1610: train loss 0.58931. lr 4.902036e-04:  56%|█████▋    | 1611/2863 [19:26<14:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1611: train loss 0.59510. lr 4.900763e-04:  56%|█████▋    | 1611/2863 [19:26<14:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1611: train loss 0.59510. lr 4.900763e-04:  56%|█████▋    | 1612/2863 [19:26<14:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1612: train loss 0.58233. lr 4.899489e-04:  56%|█████▋    | 1612/2863 [19:27<14:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1612: train loss 0.58233. lr 4.899489e-04:  56%|█████▋    | 1613/2863 [19:27<14:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1613: train loss 0.58803. lr 4.898214e-04:  56%|█████▋    | 1613/2863 [19:28<14:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1613: train loss 0.58803. lr 4.898214e-04:  56%|█████▋    | 1614/2863 [19:28<14:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1614: train loss 0.60415. lr 4.896939e-04:  56%|█████▋    | 1614/2863 [19:28<14:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1614: train loss 0.60415. lr 4.896939e-04:  56%|█████▋    | 1615/2863 [19:28<14:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1615: train loss 0.59443. lr 4.895663e-04:  56%|█████▋    | 1615/2863 [19:29<14:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1615: train loss 0.59443. lr 4.895663e-04:  56%|█████▋    | 1616/2863 [19:29<14:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1616: train loss 0.59571. lr 4.894386e-04:  56%|█████▋    | 1616/2863 [19:30<14:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1616: train loss 0.59571. lr 4.894386e-04:  56%|█████▋    | 1617/2863 [19:30<14:17,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1617: train loss 0.57880. lr 4.893109e-04:  56%|█████▋    | 1617/2863 [19:30<14:17,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1617: train loss 0.57880. lr 4.893109e-04:  57%|█████▋    | 1618/2863 [19:30<14:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1618: train loss 0.58964. lr 4.891832e-04:  57%|█████▋    | 1618/2863 [19:31<14:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1618: train loss 0.58964. lr 4.891832e-04:  57%|█████▋    | 1619/2863 [19:31<14:16,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1619: train loss 0.56219. lr 4.890554e-04:  57%|█████▋    | 1619/2863 [19:32<14:16,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1619: train loss 0.56219. lr 4.890554e-04:  57%|█████▋    | 1620/2863 [19:32<14:17,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1620: train loss 0.58875. lr 4.889275e-04:  57%|█████▋    | 1620/2863 [19:32<14:17,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1620: train loss 0.58875. lr 4.889275e-04:  57%|█████▋    | 1621/2863 [19:32<14:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1621: train loss 0.60810. lr 4.887996e-04:  57%|█████▋    | 1621/2863 [19:33<14:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1621: train loss 0.60810. lr 4.887996e-04:  57%|█████▋    | 1622/2863 [19:33<14:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1622: train loss 0.57329. lr 4.886716e-04:  57%|█████▋    | 1622/2863 [19:34<14:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1622: train loss 0.57329. lr 4.886716e-04:  57%|█████▋    | 1623/2863 [19:34<14:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1623: train loss 0.59745. lr 4.885436e-04:  57%|█████▋    | 1623/2863 [19:35<14:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1623: train loss 0.59745. lr 4.885436e-04:  57%|█████▋    | 1624/2863 [19:35<14:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1624: train loss 0.56894. lr 4.884155e-04:  57%|█████▋    | 1624/2863 [19:35<14:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1624: train loss 0.56894. lr 4.884155e-04:  57%|█████▋    | 1625/2863 [19:35<14:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1625: train loss 0.59709. lr 4.882873e-04:  57%|█████▋    | 1625/2863 [19:36<14:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1625: train loss 0.59709. lr 4.882873e-04:  57%|█████▋    | 1626/2863 [19:36<14:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1626: train loss 0.59084. lr 4.881591e-04:  57%|█████▋    | 1626/2863 [19:37<14:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1626: train loss 0.59084. lr 4.881591e-04:  57%|█████▋    | 1627/2863 [19:37<14:20,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1627: train loss 0.57286. lr 4.880308e-04:  57%|█████▋    | 1627/2863 [19:37<14:20,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1627: train loss 0.57286. lr 4.880308e-04:  57%|█████▋    | 1628/2863 [19:37<14:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1628: train loss 0.58437. lr 4.879025e-04:  57%|█████▋    | 1628/2863 [19:38<14:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1628: train loss 0.58437. lr 4.879025e-04:  57%|█████▋    | 1629/2863 [19:38<14:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1629: train loss 0.56594. lr 4.877741e-04:  57%|█████▋    | 1629/2863 [19:39<14:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1629: train loss 0.56594. lr 4.877741e-04:  57%|█████▋    | 1630/2863 [19:39<14:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1630: train loss 0.58224. lr 4.876457e-04:  57%|█████▋    | 1630/2863 [19:39<14:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1630: train loss 0.58224. lr 4.876457e-04:  57%|█████▋    | 1631/2863 [19:39<14:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1631: train loss 0.56763. lr 4.875172e-04:  57%|█████▋    | 1631/2863 [19:40<14:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1631: train loss 0.56763. lr 4.875172e-04:  57%|█████▋    | 1632/2863 [19:40<14:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1632: train loss 0.57190. lr 4.873887e-04:  57%|█████▋    | 1632/2863 [19:41<14:17,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1632: train loss 0.57190. lr 4.873887e-04:  57%|█████▋    | 1633/2863 [19:41<14:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1633: train loss 0.57714. lr 4.872601e-04:  57%|█████▋    | 1633/2863 [19:41<14:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1633: train loss 0.57714. lr 4.872601e-04:  57%|█████▋    | 1634/2863 [19:41<14:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1634: train loss 0.57406. lr 4.871314e-04:  57%|█████▋    | 1634/2863 [19:42<14:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1634: train loss 0.57406. lr 4.871314e-04:  57%|█████▋    | 1635/2863 [19:42<14:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1635: train loss 0.56861. lr 4.870027e-04:  57%|█████▋    | 1635/2863 [19:43<14:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1635: train loss 0.56861. lr 4.870027e-04:  57%|█████▋    | 1636/2863 [19:43<14:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1636: train loss 0.56950. lr 4.868739e-04:  57%|█████▋    | 1636/2863 [19:44<14:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1636: train loss 0.56950. lr 4.868739e-04:  57%|█████▋    | 1637/2863 [19:44<14:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1637: train loss 0.57169. lr 4.867451e-04:  57%|█████▋    | 1637/2863 [19:44<14:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1637: train loss 0.57169. lr 4.867451e-04:  57%|█████▋    | 1638/2863 [19:44<15:08,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1638: train loss 0.57170. lr 4.866162e-04:  57%|█████▋    | 1638/2863 [19:45<15:08,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1638: train loss 0.57170. lr 4.866162e-04:  57%|█████▋    | 1639/2863 [19:45<14:52,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1639: train loss 0.57785. lr 4.864873e-04:  57%|█████▋    | 1639/2863 [19:46<14:52,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1639: train loss 0.57785. lr 4.864873e-04:  57%|█████▋    | 1640/2863 [19:46<14:38,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1640: train loss 0.56809. lr 4.863583e-04:  57%|█████▋    | 1640/2863 [19:47<14:38,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1640: train loss 0.56809. lr 4.863583e-04:  57%|█████▋    | 1641/2863 [19:47<14:28,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1641: train loss 0.57704. lr 4.862292e-04:  57%|█████▋    | 1641/2863 [19:47<14:28,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1641: train loss 0.57704. lr 4.862292e-04:  57%|█████▋    | 1642/2863 [19:47<14:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1642: train loss 0.57419. lr 4.861001e-04:  57%|█████▋    | 1642/2863 [19:48<14:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1642: train loss 0.57419. lr 4.861001e-04:  57%|█████▋    | 1643/2863 [19:48<14:12,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1643: train loss 0.56190. lr 4.859709e-04:  57%|█████▋    | 1643/2863 [19:49<14:12,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1643: train loss 0.56190. lr 4.859709e-04:  57%|█████▋    | 1644/2863 [19:49<14:07,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1644: train loss 0.56907. lr 4.858417e-04:  57%|█████▋    | 1644/2863 [19:49<14:07,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1644: train loss 0.56907. lr 4.858417e-04:  57%|█████▋    | 1645/2863 [19:49<14:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1645: train loss 0.57288. lr 4.857124e-04:  57%|█████▋    | 1645/2863 [19:50<14:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1645: train loss 0.57288. lr 4.857124e-04:  57%|█████▋    | 1646/2863 [19:50<14:01,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1646: train loss 0.57500. lr 4.855831e-04:  57%|█████▋    | 1646/2863 [19:51<14:01,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1646: train loss 0.57500. lr 4.855831e-04:  58%|█████▊    | 1647/2863 [19:51<14:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1647: train loss 0.56183. lr 4.854537e-04:  58%|█████▊    | 1647/2863 [19:51<14:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1647: train loss 0.56183. lr 4.854537e-04:  58%|█████▊    | 1648/2863 [19:51<14:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1648: train loss 0.58774. lr 4.853243e-04:  58%|█████▊    | 1648/2863 [19:52<14:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1648: train loss 0.58774. lr 4.853243e-04:  58%|█████▊    | 1649/2863 [19:52<14:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1649: train loss 0.57092. lr 4.851948e-04:  58%|█████▊    | 1649/2863 [19:53<14:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1649: train loss 0.57092. lr 4.851948e-04:  58%|█████▊    | 1650/2863 [19:53<14:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1650: train loss 0.56460. lr 4.850652e-04:  58%|█████▊    | 1650/2863 [19:53<14:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1650: train loss 0.56460. lr 4.850652e-04:  58%|█████▊    | 1651/2863 [19:53<13:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1651: train loss 0.57631. lr 4.849356e-04:  58%|█████▊    | 1651/2863 [19:54<13:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1651: train loss 0.57631. lr 4.849356e-04:  58%|█████▊    | 1652/2863 [19:54<14:00,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1652: train loss 0.55874. lr 4.848059e-04:  58%|█████▊    | 1652/2863 [19:55<14:00,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1652: train loss 0.55874. lr 4.848059e-04:  58%|█████▊    | 1653/2863 [19:55<13:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1653: train loss 0.57354. lr 4.846762e-04:  58%|█████▊    | 1653/2863 [19:55<13:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1653: train loss 0.57354. lr 4.846762e-04:  58%|█████▊    | 1654/2863 [19:56<13:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1654: train loss 0.57755. lr 4.845464e-04:  58%|█████▊    | 1654/2863 [19:56<13:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1654: train loss 0.57755. lr 4.845464e-04:  58%|█████▊    | 1655/2863 [19:56<13:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1655: train loss 0.56959. lr 4.844166e-04:  58%|█████▊    | 1655/2863 [19:57<13:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1655: train loss 0.56959. lr 4.844166e-04:  58%|█████▊    | 1656/2863 [19:57<14:14,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1656: train loss 0.56533. lr 4.842867e-04:  58%|█████▊    | 1656/2863 [19:58<14:14,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1656: train loss 0.56533. lr 4.842867e-04:  58%|█████▊    | 1657/2863 [19:58<14:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1657: train loss 0.54675. lr 4.841567e-04:  58%|█████▊    | 1657/2863 [19:58<14:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1657: train loss 0.54675. lr 4.841567e-04:  58%|█████▊    | 1658/2863 [19:58<14:05,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1658: train loss 0.56156. lr 4.840267e-04:  58%|█████▊    | 1658/2863 [19:59<14:05,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1658: train loss 0.56156. lr 4.840267e-04:  58%|█████▊    | 1659/2863 [19:59<13:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1659: train loss 0.56175. lr 4.838967e-04:  58%|█████▊    | 1659/2863 [20:00<13:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1659: train loss 0.56175. lr 4.838967e-04:  58%|█████▊    | 1660/2863 [20:00<13:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1660: train loss 0.53936. lr 4.837666e-04:  58%|█████▊    | 1660/2863 [20:00<13:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1660: train loss 0.53936. lr 4.837666e-04:  58%|█████▊    | 1661/2863 [20:00<13:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1661: train loss 0.54679. lr 4.836364e-04:  58%|█████▊    | 1661/2863 [20:01<13:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1661: train loss 0.54679. lr 4.836364e-04:  58%|█████▊    | 1662/2863 [20:01<13:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1662: train loss 0.54684. lr 4.835062e-04:  58%|█████▊    | 1662/2863 [20:02<13:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1662: train loss 0.54684. lr 4.835062e-04:  58%|█████▊    | 1663/2863 [20:02<13:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1663: train loss 0.54754. lr 4.833759e-04:  58%|█████▊    | 1663/2863 [20:02<13:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1663: train loss 0.54754. lr 4.833759e-04:  58%|█████▊    | 1664/2863 [20:02<13:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1664: train loss 0.55342. lr 4.832456e-04:  58%|█████▊    | 1664/2863 [20:03<13:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1664: train loss 0.55342. lr 4.832456e-04:  58%|█████▊    | 1665/2863 [20:03<13:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1665: train loss 0.56821. lr 4.831152e-04:  58%|█████▊    | 1665/2863 [20:04<13:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1665: train loss 0.56821. lr 4.831152e-04:  58%|█████▊    | 1666/2863 [20:04<14:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1666: train loss 0.53972. lr 4.829847e-04:  58%|█████▊    | 1666/2863 [20:05<14:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1666: train loss 0.53972. lr 4.829847e-04:  58%|█████▊    | 1667/2863 [20:05<14:14,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1667: train loss 0.55546. lr 4.828542e-04:  58%|█████▊    | 1667/2863 [20:05<14:14,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1667: train loss 0.55546. lr 4.828542e-04:  58%|█████▊    | 1668/2863 [20:05<14:05,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1668: train loss 0.54824. lr 4.827237e-04:  58%|█████▊    | 1668/2863 [20:06<14:05,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1668: train loss 0.54824. lr 4.827237e-04:  58%|█████▊    | 1669/2863 [20:06<13:55,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1669: train loss 0.55103. lr 4.825930e-04:  58%|█████▊    | 1669/2863 [20:07<13:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1669: train loss 0.55103. lr 4.825930e-04:  58%|█████▊    | 1670/2863 [20:07<13:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1670: train loss 0.55199. lr 4.824624e-04:  58%|█████▊    | 1670/2863 [20:07<13:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1670: train loss 0.55199. lr 4.824624e-04:  58%|█████▊    | 1671/2863 [20:07<13:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1671: train loss 0.56549. lr 4.823317e-04:  58%|█████▊    | 1671/2863 [20:08<13:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1671: train loss 0.56549. lr 4.823317e-04:  58%|█████▊    | 1672/2863 [20:08<13:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1672: train loss 0.54386. lr 4.822009e-04:  58%|█████▊    | 1672/2863 [20:09<13:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1672: train loss 0.54386. lr 4.822009e-04:  58%|█████▊    | 1673/2863 [20:09<13:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1673: train loss 0.55251. lr 4.820701e-04:  58%|█████▊    | 1673/2863 [20:09<13:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1673: train loss 0.55251. lr 4.820701e-04:  58%|█████▊    | 1674/2863 [20:09<13:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1674: train loss 0.55835. lr 4.819392e-04:  58%|█████▊    | 1674/2863 [20:10<13:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1674: train loss 0.55835. lr 4.819392e-04:  59%|█████▊    | 1675/2863 [20:10<14:17,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1675: train loss 0.54179. lr 4.818082e-04:  59%|█████▊    | 1675/2863 [20:11<14:17,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1675: train loss 0.54179. lr 4.818082e-04:  59%|█████▊    | 1676/2863 [20:11<14:39,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1676: train loss 0.53764. lr 4.816772e-04:  59%|█████▊    | 1676/2863 [20:12<14:39,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1676: train loss 0.53764. lr 4.816772e-04:  59%|█████▊    | 1677/2863 [20:12<14:47,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1677: train loss 0.52997. lr 4.815462e-04:  59%|█████▊    | 1677/2863 [20:13<14:47,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1677: train loss 0.52997. lr 4.815462e-04:  59%|█████▊    | 1678/2863 [20:13<14:44,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1678: train loss 0.55252. lr 4.814151e-04:  59%|█████▊    | 1678/2863 [20:13<14:44,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1678: train loss 0.55252. lr 4.814151e-04:  59%|█████▊    | 1679/2863 [20:13<14:38,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1679: train loss 0.54815. lr 4.812839e-04:  59%|█████▊    | 1679/2863 [20:14<14:38,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1679: train loss 0.54815. lr 4.812839e-04:  59%|█████▊    | 1680/2863 [20:14<14:32,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1680: train loss 0.54414. lr 4.811527e-04:  59%|█████▊    | 1680/2863 [20:15<14:32,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1680: train loss 0.54414. lr 4.811527e-04:  59%|█████▊    | 1681/2863 [20:15<14:23,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1681: train loss 0.53907. lr 4.810214e-04:  59%|█████▊    | 1681/2863 [20:15<14:23,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1681: train loss 0.53907. lr 4.810214e-04:  59%|█████▊    | 1682/2863 [20:15<14:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1682: train loss 0.55952. lr 4.808901e-04:  59%|█████▊    | 1682/2863 [20:16<14:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1682: train loss 0.55952. lr 4.808901e-04:  59%|█████▉    | 1683/2863 [20:16<14:09,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1683: train loss 0.55323. lr 4.807587e-04:  59%|█████▉    | 1683/2863 [20:17<14:09,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1683: train loss 0.55323. lr 4.807587e-04:  59%|█████▉    | 1684/2863 [20:17<14:02,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1684: train loss 0.55522. lr 4.806273e-04:  59%|█████▉    | 1684/2863 [20:18<14:02,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1684: train loss 0.55522. lr 4.806273e-04:  59%|█████▉    | 1685/2863 [20:18<13:55,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1685: train loss 0.53742. lr 4.804958e-04:  59%|█████▉    | 1685/2863 [20:18<13:55,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1685: train loss 0.53742. lr 4.804958e-04:  59%|█████▉    | 1686/2863 [20:18<13:50,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1686: train loss 0.54603. lr 4.803643e-04:  59%|█████▉    | 1686/2863 [20:19<13:50,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1686: train loss 0.54603. lr 4.803643e-04:  59%|█████▉    | 1687/2863 [20:19<13:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1687: train loss 0.53616. lr 4.802327e-04:  59%|█████▉    | 1687/2863 [20:20<13:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1687: train loss 0.53616. lr 4.802327e-04:  59%|█████▉    | 1688/2863 [20:20<13:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1688: train loss 0.54519. lr 4.801011e-04:  59%|█████▉    | 1688/2863 [20:20<13:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1688: train loss 0.54519. lr 4.801011e-04:  59%|█████▉    | 1689/2863 [20:20<13:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1689: train loss 0.53399. lr 4.799693e-04:  59%|█████▉    | 1689/2863 [20:21<13:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1689: train loss 0.53399. lr 4.799693e-04:  59%|█████▉    | 1690/2863 [20:21<13:45,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1690: train loss 0.54181. lr 4.798376e-04:  59%|█████▉    | 1690/2863 [20:22<13:45,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1690: train loss 0.54181. lr 4.798376e-04:  59%|█████▉    | 1691/2863 [20:22<13:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1691: train loss 0.56127. lr 4.797058e-04:  59%|█████▉    | 1691/2863 [20:22<13:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1691: train loss 0.56127. lr 4.797058e-04:  59%|█████▉    | 1692/2863 [20:22<13:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1692: train loss 0.54191. lr 4.795739e-04:  59%|█████▉    | 1692/2863 [20:23<13:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1692: train loss 0.54191. lr 4.795739e-04:  59%|█████▉    | 1693/2863 [20:23<13:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1693: train loss 0.53422. lr 4.794420e-04:  59%|█████▉    | 1693/2863 [20:24<13:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1693: train loss 0.53422. lr 4.794420e-04:  59%|█████▉    | 1694/2863 [20:24<14:15,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1694: train loss 0.54538. lr 4.793100e-04:  59%|█████▉    | 1694/2863 [20:25<14:15,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1694: train loss 0.54538. lr 4.793100e-04:  59%|█████▉    | 1695/2863 [20:25<14:07,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1695: train loss 0.54799. lr 4.791780e-04:  59%|█████▉    | 1695/2863 [20:25<14:07,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1695: train loss 0.54799. lr 4.791780e-04:  59%|█████▉    | 1696/2863 [20:25<13:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1696: train loss 0.55170. lr 4.790459e-04:  59%|█████▉    | 1696/2863 [20:26<13:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1696: train loss 0.55170. lr 4.790459e-04:  59%|█████▉    | 1697/2863 [20:26<13:48,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1697: train loss 0.53764. lr 4.789138e-04:  59%|█████▉    | 1697/2863 [20:27<13:48,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1697: train loss 0.53764. lr 4.789138e-04:  59%|█████▉    | 1698/2863 [20:27<13:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1698: train loss 0.55115. lr 4.787816e-04:  59%|█████▉    | 1698/2863 [20:27<13:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1698: train loss 0.55115. lr 4.787816e-04:  59%|█████▉    | 1699/2863 [20:27<13:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1699: train loss 0.52343. lr 4.786493e-04:  59%|█████▉    | 1699/2863 [20:28<13:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1699: train loss 0.52343. lr 4.786493e-04:  59%|█████▉    | 1700/2863 [20:28<13:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1700: train loss 0.53074. lr 4.785170e-04:  59%|█████▉    | 1700/2863 [20:29<13:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1700: train loss 0.53074. lr 4.785170e-04:  59%|█████▉    | 1701/2863 [20:29<13:37,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1701: train loss 0.53641. lr 4.783847e-04:  59%|█████▉    | 1701/2863 [20:30<13:37,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1701: train loss 0.53641. lr 4.783847e-04:  59%|█████▉    | 1702/2863 [20:30<13:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1702: train loss 0.52510. lr 4.782523e-04:  59%|█████▉    | 1702/2863 [20:30<13:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1702: train loss 0.52510. lr 4.782523e-04:  59%|█████▉    | 1703/2863 [20:30<13:36,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1703: train loss 0.53184. lr 4.781198e-04:  59%|█████▉    | 1703/2863 [20:31<13:36,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1703: train loss 0.53184. lr 4.781198e-04:  60%|█████▉    | 1704/2863 [20:31<13:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1704: train loss 0.53015. lr 4.779873e-04:  60%|█████▉    | 1704/2863 [20:32<13:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1704: train loss 0.53015. lr 4.779873e-04:  60%|█████▉    | 1705/2863 [20:32<13:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1705: train loss 0.54428. lr 4.778548e-04:  60%|█████▉    | 1705/2863 [20:32<13:26,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1705: train loss 0.54428. lr 4.778548e-04:  60%|█████▉    | 1706/2863 [20:32<13:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1706: train loss 0.54051. lr 4.777221e-04:  60%|█████▉    | 1706/2863 [20:33<13:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1706: train loss 0.54051. lr 4.777221e-04:  60%|█████▉    | 1707/2863 [20:33<13:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1707: train loss 0.52660. lr 4.775895e-04:  60%|█████▉    | 1707/2863 [20:34<13:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1707: train loss 0.52660. lr 4.775895e-04:  60%|█████▉    | 1708/2863 [20:34<13:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1708: train loss 0.54242. lr 4.774567e-04:  60%|█████▉    | 1708/2863 [20:34<13:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1708: train loss 0.54242. lr 4.774567e-04:  60%|█████▉    | 1709/2863 [20:34<13:15,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1709: train loss 0.53963. lr 4.773240e-04:  60%|█████▉    | 1709/2863 [20:35<13:15,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1709: train loss 0.53963. lr 4.773240e-04:  60%|█████▉    | 1710/2863 [20:35<13:15,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1710: train loss 0.52378. lr 4.771911e-04:  60%|█████▉    | 1710/2863 [20:36<13:15,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1710: train loss 0.52378. lr 4.771911e-04:  60%|█████▉    | 1711/2863 [20:36<13:20,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1711: train loss 0.54818. lr 4.770582e-04:  60%|█████▉    | 1711/2863 [20:36<13:20,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1711: train loss 0.54818. lr 4.770582e-04:  60%|█████▉    | 1712/2863 [20:36<13:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1712: train loss 0.52252. lr 4.769253e-04:  60%|█████▉    | 1712/2863 [20:37<13:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1712: train loss 0.52252. lr 4.769253e-04:  60%|█████▉    | 1713/2863 [20:37<13:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1713: train loss 0.52962. lr 4.767923e-04:  60%|█████▉    | 1713/2863 [20:38<13:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1713: train loss 0.52962. lr 4.767923e-04:  60%|█████▉    | 1714/2863 [20:38<13:14,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1714: train loss 0.54496. lr 4.766593e-04:  60%|█████▉    | 1714/2863 [20:39<13:14,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1714: train loss 0.54496. lr 4.766593e-04:  60%|█████▉    | 1715/2863 [20:39<13:13,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1715: train loss 0.54444. lr 4.765262e-04:  60%|█████▉    | 1715/2863 [20:39<13:13,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1715: train loss 0.54444. lr 4.765262e-04:  60%|█████▉    | 1716/2863 [20:39<13:10,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1716: train loss 0.54252. lr 4.763930e-04:  60%|█████▉    | 1716/2863 [20:40<13:10,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1716: train loss 0.54252. lr 4.763930e-04:  60%|█████▉    | 1717/2863 [20:40<13:08,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1717: train loss 0.51179. lr 4.762598e-04:  60%|█████▉    | 1717/2863 [20:41<13:08,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1717: train loss 0.51179. lr 4.762598e-04:  60%|██████    | 1718/2863 [20:41<13:08,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1718: train loss 0.51563. lr 4.761265e-04:  60%|██████    | 1718/2863 [20:41<13:08,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1718: train loss 0.51563. lr 4.761265e-04:  60%|██████    | 1719/2863 [20:41<13:53,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1719: train loss 0.53826. lr 4.759932e-04:  60%|██████    | 1719/2863 [20:42<13:53,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1719: train loss 0.53826. lr 4.759932e-04:  60%|██████    | 1720/2863 [20:42<14:22,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1720: train loss 0.52047. lr 4.758599e-04:  60%|██████    | 1720/2863 [20:43<14:22,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1720: train loss 0.52047. lr 4.758599e-04:  60%|██████    | 1721/2863 [20:43<14:23,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1721: train loss 0.53404. lr 4.757265e-04:  60%|██████    | 1721/2863 [20:44<14:23,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 1721: train loss 0.53404. lr 4.757265e-04:  60%|██████    | 1722/2863 [20:44<14:56,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1722: train loss 0.53540. lr 4.755930e-04:  60%|██████    | 1722/2863 [20:45<14:56,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1722: train loss 0.53540. lr 4.755930e-04:  60%|██████    | 1723/2863 [20:45<14:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1723: train loss 0.52839. lr 4.754595e-04:  60%|██████    | 1723/2863 [20:45<14:27,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1723: train loss 0.52839. lr 4.754595e-04:  60%|██████    | 1724/2863 [20:45<14:01,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1724: train loss 0.52850. lr 4.753259e-04:  60%|██████    | 1724/2863 [20:46<14:01,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1724: train loss 0.52850. lr 4.753259e-04:  60%|██████    | 1725/2863 [20:46<13:45,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1725: train loss 0.50879. lr 4.751923e-04:  60%|██████    | 1725/2863 [20:47<13:45,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1725: train loss 0.50879. lr 4.751923e-04:  60%|██████    | 1726/2863 [20:47<13:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1726: train loss 0.54295. lr 4.750586e-04:  60%|██████    | 1726/2863 [20:47<13:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1726: train loss 0.54295. lr 4.750586e-04:  60%|██████    | 1727/2863 [20:47<13:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1727: train loss 0.51800. lr 4.749248e-04:  60%|██████    | 1727/2863 [20:48<13:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1727: train loss 0.51800. lr 4.749248e-04:  60%|██████    | 1728/2863 [20:48<13:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1728: train loss 0.50815. lr 4.747911e-04:  60%|██████    | 1728/2863 [20:49<13:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1728: train loss 0.50815. lr 4.747911e-04:  60%|██████    | 1729/2863 [20:49<13:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1729: train loss 0.51319. lr 4.746572e-04:  60%|██████    | 1729/2863 [20:49<13:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1729: train loss 0.51319. lr 4.746572e-04:  60%|██████    | 1730/2863 [20:49<13:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1730: train loss 0.52046. lr 4.745233e-04:  60%|██████    | 1730/2863 [20:50<13:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1730: train loss 0.52046. lr 4.745233e-04:  60%|██████    | 1731/2863 [20:50<13:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1731: train loss 0.53412. lr 4.743894e-04:  60%|██████    | 1731/2863 [20:51<13:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1731: train loss 0.53412. lr 4.743894e-04:  60%|██████    | 1732/2863 [20:51<12:59,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1732: train loss 0.53066. lr 4.742554e-04:  60%|██████    | 1732/2863 [20:51<12:59,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1732: train loss 0.53066. lr 4.742554e-04:  61%|██████    | 1733/2863 [20:51<13:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1733: train loss 0.50607. lr 4.741213e-04:  61%|██████    | 1733/2863 [20:52<13:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1733: train loss 0.50607. lr 4.741213e-04:  61%|██████    | 1734/2863 [20:52<12:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1734: train loss 0.50898. lr 4.739872e-04:  61%|██████    | 1734/2863 [20:53<12:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1734: train loss 0.50898. lr 4.739872e-04:  61%|██████    | 1735/2863 [20:53<12:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1735: train loss 0.52773. lr 4.738531e-04:  61%|██████    | 1735/2863 [20:54<12:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1735: train loss 0.52773. lr 4.738531e-04:  61%|██████    | 1736/2863 [20:54<12:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1736: train loss 0.52092. lr 4.737189e-04:  61%|██████    | 1736/2863 [20:54<12:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1736: train loss 0.52092. lr 4.737189e-04:  61%|██████    | 1737/2863 [20:54<12:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1737: train loss 0.50471. lr 4.735846e-04:  61%|██████    | 1737/2863 [20:55<12:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1737: train loss 0.50471. lr 4.735846e-04:  61%|██████    | 1738/2863 [20:55<12:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1738: train loss 0.54344. lr 4.734503e-04:  61%|██████    | 1738/2863 [20:56<12:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1738: train loss 0.54344. lr 4.734503e-04:  61%|██████    | 1739/2863 [20:56<12:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1739: train loss 0.52884. lr 4.733159e-04:  61%|██████    | 1739/2863 [20:56<12:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1739: train loss 0.52884. lr 4.733159e-04:  61%|██████    | 1740/2863 [20:56<13:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1740: train loss 0.52015. lr 4.731815e-04:  61%|██████    | 1740/2863 [20:57<13:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1740: train loss 0.52015. lr 4.731815e-04:  61%|██████    | 1741/2863 [20:57<13:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1741: train loss 0.52111. lr 4.730470e-04:  61%|██████    | 1741/2863 [20:58<13:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1741: train loss 0.52111. lr 4.730470e-04:  61%|██████    | 1742/2863 [20:58<13:02,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1742: train loss 0.50173. lr 4.729125e-04:  61%|██████    | 1742/2863 [20:58<13:02,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1742: train loss 0.50173. lr 4.729125e-04:  61%|██████    | 1743/2863 [20:58<12:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1743: train loss 0.52347. lr 4.727779e-04:  61%|██████    | 1743/2863 [20:59<12:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1743: train loss 0.52347. lr 4.727779e-04:  61%|██████    | 1744/2863 [20:59<12:55,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1744: train loss 0.52997. lr 4.726433e-04:  61%|██████    | 1744/2863 [21:00<12:55,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1744: train loss 0.52997. lr 4.726433e-04:  61%|██████    | 1745/2863 [21:00<12:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1745: train loss 0.51850. lr 4.725086e-04:  61%|██████    | 1745/2863 [21:00<12:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1745: train loss 0.51850. lr 4.725086e-04:  61%|██████    | 1746/2863 [21:00<12:51,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1746: train loss 0.51208. lr 4.723739e-04:  61%|██████    | 1746/2863 [21:01<12:51,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1746: train loss 0.51208. lr 4.723739e-04:  61%|██████    | 1747/2863 [21:01<12:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1747: train loss 0.51574. lr 4.722391e-04:  61%|██████    | 1747/2863 [21:02<12:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1747: train loss 0.51574. lr 4.722391e-04:  61%|██████    | 1748/2863 [21:02<12:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1748: train loss 0.53657. lr 4.721043e-04:  61%|██████    | 1748/2863 [21:02<12:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1748: train loss 0.53657. lr 4.721043e-04:  61%|██████    | 1749/2863 [21:02<12:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1749: train loss 0.51212. lr 4.719694e-04:  61%|██████    | 1749/2863 [21:03<12:45,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1749: train loss 0.51212. lr 4.719694e-04:  61%|██████    | 1750/2863 [21:03<13:20,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1750: train loss 0.51445. lr 4.718345e-04:  61%|██████    | 1750/2863 [21:04<13:20,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1750: train loss 0.51445. lr 4.718345e-04:  61%|██████    | 1751/2863 [21:04<13:11,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1751: train loss 0.51854. lr 4.716995e-04:  61%|██████    | 1751/2863 [21:05<13:11,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1751: train loss 0.51854. lr 4.716995e-04:  61%|██████    | 1752/2863 [21:05<13:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1752: train loss 0.52510. lr 4.715645e-04:  61%|██████    | 1752/2863 [21:05<13:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1752: train loss 0.52510. lr 4.715645e-04:  61%|██████    | 1753/2863 [21:05<12:56,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1753: train loss 0.51465. lr 4.714294e-04:  61%|██████    | 1753/2863 [21:06<12:56,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1753: train loss 0.51465. lr 4.714294e-04:  61%|██████▏   | 1754/2863 [21:06<12:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1754: train loss 0.49780. lr 4.712942e-04:  61%|██████▏   | 1754/2863 [21:07<12:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1754: train loss 0.49780. lr 4.712942e-04:  61%|██████▏   | 1755/2863 [21:07<12:45,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1755: train loss 0.50570. lr 4.711590e-04:  61%|██████▏   | 1755/2863 [21:07<12:45,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1755: train loss 0.50570. lr 4.711590e-04:  61%|██████▏   | 1756/2863 [21:07<12:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1756: train loss 0.53436. lr 4.710238e-04:  61%|██████▏   | 1756/2863 [21:08<12:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1756: train loss 0.53436. lr 4.710238e-04:  61%|██████▏   | 1757/2863 [21:08<12:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1757: train loss 0.51079. lr 4.708885e-04:  61%|██████▏   | 1757/2863 [21:09<12:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1757: train loss 0.51079. lr 4.708885e-04:  61%|██████▏   | 1758/2863 [21:09<12:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1758: train loss 0.51372. lr 4.707531e-04:  61%|██████▏   | 1758/2863 [21:09<12:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1758: train loss 0.51372. lr 4.707531e-04:  61%|██████▏   | 1759/2863 [21:09<12:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1759: train loss 0.49394. lr 4.706177e-04:  61%|██████▏   | 1759/2863 [21:10<12:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1759: train loss 0.49394. lr 4.706177e-04:  61%|██████▏   | 1760/2863 [21:10<12:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1760: train loss 0.51222. lr 4.704823e-04:  61%|██████▏   | 1760/2863 [21:11<12:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1760: train loss 0.51222. lr 4.704823e-04:  62%|██████▏   | 1761/2863 [21:11<12:38,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1761: train loss 0.51736. lr 4.703468e-04:  62%|██████▏   | 1761/2863 [21:12<12:38,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1761: train loss 0.51736. lr 4.703468e-04:  62%|██████▏   | 1762/2863 [21:12<12:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1762: train loss 0.50020. lr 4.702112e-04:  62%|██████▏   | 1762/2863 [21:12<12:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1762: train loss 0.50020. lr 4.702112e-04:  62%|██████▏   | 1763/2863 [21:12<12:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1763: train loss 0.51925. lr 4.700756e-04:  62%|██████▏   | 1763/2863 [21:13<12:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1763: train loss 0.51925. lr 4.700756e-04:  62%|██████▏   | 1764/2863 [21:13<12:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1764: train loss 0.50780. lr 4.699400e-04:  62%|██████▏   | 1764/2863 [21:14<12:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1764: train loss 0.50780. lr 4.699400e-04:  62%|██████▏   | 1765/2863 [21:14<12:36,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1765: train loss 0.50236. lr 4.698043e-04:  62%|██████▏   | 1765/2863 [21:14<12:36,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1765: train loss 0.50236. lr 4.698043e-04:  62%|██████▏   | 1766/2863 [21:14<12:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1766: train loss 0.52388. lr 4.696685e-04:  62%|██████▏   | 1766/2863 [21:15<12:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1766: train loss 0.52388. lr 4.696685e-04:  62%|██████▏   | 1767/2863 [21:15<12:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1767: train loss 0.49981. lr 4.695327e-04:  62%|██████▏   | 1767/2863 [21:16<12:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1767: train loss 0.49981. lr 4.695327e-04:  62%|██████▏   | 1768/2863 [21:16<12:30,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1768: train loss 0.50160. lr 4.693968e-04:  62%|██████▏   | 1768/2863 [21:16<12:30,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1768: train loss 0.50160. lr 4.693968e-04:  62%|██████▏   | 1769/2863 [21:16<12:29,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1769: train loss 0.52388. lr 4.692609e-04:  62%|██████▏   | 1769/2863 [21:17<12:29,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 1769: train loss 0.52388. lr 4.692609e-04:  62%|██████▏   | 1770/2863 [21:17<12:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1770: train loss 0.50725. lr 4.691249e-04:  62%|██████▏   | 1770/2863 [21:18<12:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1770: train loss 0.50725. lr 4.691249e-04:  62%|██████▏   | 1771/2863 [21:18<12:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1771: train loss 0.51231. lr 4.689889e-04:  62%|██████▏   | 1771/2863 [21:18<12:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1771: train loss 0.51231. lr 4.689889e-04:  62%|██████▏   | 1772/2863 [21:18<12:30,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1772: train loss 0.49824. lr 4.688529e-04:  62%|██████▏   | 1772/2863 [21:19<12:30,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1772: train loss 0.49824. lr 4.688529e-04:  62%|██████▏   | 1773/2863 [21:19<12:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1773: train loss 0.49771. lr 4.687168e-04:  62%|██████▏   | 1773/2863 [21:20<12:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1773: train loss 0.49771. lr 4.687168e-04:  62%|██████▏   | 1774/2863 [21:20<12:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1774: train loss 0.52159. lr 4.685806e-04:  62%|██████▏   | 1774/2863 [21:21<12:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1774: train loss 0.52159. lr 4.685806e-04:  62%|██████▏   | 1775/2863 [21:21<12:40,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1775: train loss 0.49986. lr 4.684444e-04:  62%|██████▏   | 1775/2863 [21:21<12:40,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1775: train loss 0.49986. lr 4.684444e-04:  62%|██████▏   | 1776/2863 [21:21<12:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1776: train loss 0.51816. lr 4.683081e-04:  62%|██████▏   | 1776/2863 [21:22<12:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1776: train loss 0.51816. lr 4.683081e-04:  62%|██████▏   | 1777/2863 [21:22<12:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1777: train loss 0.50867. lr 4.681718e-04:  62%|██████▏   | 1777/2863 [21:23<12:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1777: train loss 0.50867. lr 4.681718e-04:  62%|██████▏   | 1778/2863 [21:23<13:11,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1778: train loss 0.49332. lr 4.680354e-04:  62%|██████▏   | 1778/2863 [21:23<13:11,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1778: train loss 0.49332. lr 4.680354e-04:  62%|██████▏   | 1779/2863 [21:23<12:56,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1779: train loss 0.49942. lr 4.678990e-04:  62%|██████▏   | 1779/2863 [21:24<12:56,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1779: train loss 0.49942. lr 4.678990e-04:  62%|██████▏   | 1780/2863 [21:24<13:09,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1780: train loss 0.49950. lr 4.677625e-04:  62%|██████▏   | 1780/2863 [21:25<13:09,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1780: train loss 0.49950. lr 4.677625e-04:  62%|██████▏   | 1781/2863 [21:25<13:00,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1781: train loss 0.48413. lr 4.676260e-04:  62%|██████▏   | 1781/2863 [21:26<13:00,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1781: train loss 0.48413. lr 4.676260e-04:  62%|██████▏   | 1782/2863 [21:26<12:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1782: train loss 0.49576. lr 4.674894e-04:  62%|██████▏   | 1782/2863 [21:26<12:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1782: train loss 0.49576. lr 4.674894e-04:  62%|██████▏   | 1783/2863 [21:26<12:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1783: train loss 0.50586. lr 4.673528e-04:  62%|██████▏   | 1783/2863 [21:27<12:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1783: train loss 0.50586. lr 4.673528e-04:  62%|██████▏   | 1784/2863 [21:27<12:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1784: train loss 0.50623. lr 4.672161e-04:  62%|██████▏   | 1784/2863 [21:28<12:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1784: train loss 0.50623. lr 4.672161e-04:  62%|██████▏   | 1785/2863 [21:28<12:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1785: train loss 0.50681. lr 4.670794e-04:  62%|██████▏   | 1785/2863 [21:28<12:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1785: train loss 0.50681. lr 4.670794e-04:  62%|██████▏   | 1786/2863 [21:28<12:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1786: train loss 0.48017. lr 4.669426e-04:  62%|██████▏   | 1786/2863 [21:29<12:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1786: train loss 0.48017. lr 4.669426e-04:  62%|██████▏   | 1787/2863 [21:29<12:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1787: train loss 0.50220. lr 4.668058e-04:  62%|██████▏   | 1787/2863 [21:30<12:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1787: train loss 0.50220. lr 4.668058e-04:  62%|██████▏   | 1788/2863 [21:30<12:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1788: train loss 0.48425. lr 4.666689e-04:  62%|██████▏   | 1788/2863 [21:30<12:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1788: train loss 0.48425. lr 4.666689e-04:  62%|██████▏   | 1789/2863 [21:30<12:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1789: train loss 0.48221. lr 4.665320e-04:  62%|██████▏   | 1789/2863 [21:31<12:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1789: train loss 0.48221. lr 4.665320e-04:  63%|██████▎   | 1790/2863 [21:31<12:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1790: train loss 0.48230. lr 4.663950e-04:  63%|██████▎   | 1790/2863 [21:32<12:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1790: train loss 0.48230. lr 4.663950e-04:  63%|██████▎   | 1791/2863 [21:32<12:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1791: train loss 0.49971. lr 4.662580e-04:  63%|██████▎   | 1791/2863 [21:33<12:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1791: train loss 0.49971. lr 4.662580e-04:  63%|██████▎   | 1792/2863 [21:33<12:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1792: train loss 0.48986. lr 4.661209e-04:  63%|██████▎   | 1792/2863 [21:33<12:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1792: train loss 0.48986. lr 4.661209e-04:  63%|██████▎   | 1793/2863 [21:33<12:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1793: train loss 0.50755. lr 4.659838e-04:  63%|██████▎   | 1793/2863 [21:34<12:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1793: train loss 0.50755. lr 4.659838e-04:  63%|██████▎   | 1794/2863 [21:34<12:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1794: train loss 0.48489. lr 4.658466e-04:  63%|██████▎   | 1794/2863 [21:35<12:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1794: train loss 0.48489. lr 4.658466e-04:  63%|██████▎   | 1795/2863 [21:35<12:45,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1795: train loss 0.49474. lr 4.657094e-04:  63%|██████▎   | 1795/2863 [21:35<12:45,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1795: train loss 0.49474. lr 4.657094e-04:  63%|██████▎   | 1796/2863 [21:35<13:01,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1796: train loss 0.49596. lr 4.655721e-04:  63%|██████▎   | 1796/2863 [21:36<13:01,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1796: train loss 0.49596. lr 4.655721e-04:  63%|██████▎   | 1797/2863 [21:36<13:15,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1797: train loss 0.49403. lr 4.654348e-04:  63%|██████▎   | 1797/2863 [21:37<13:15,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1797: train loss 0.49403. lr 4.654348e-04:  63%|██████▎   | 1798/2863 [21:37<13:22,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1798: train loss 0.47179. lr 4.652974e-04:  63%|██████▎   | 1798/2863 [21:38<13:22,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 1798: train loss 0.47179. lr 4.652974e-04:  63%|██████▎   | 1799/2863 [21:38<13:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1799: train loss 0.49104. lr 4.651600e-04:  63%|██████▎   | 1799/2863 [21:39<13:29,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1799: train loss 0.49104. lr 4.651600e-04:  63%|██████▎   | 1800/2863 [21:39<13:34,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1800: train loss 0.50029. lr 4.650225e-04:  63%|██████▎   | 1800/2863 [21:39<13:34,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 1800: train loss 0.50029. lr 4.650225e-04:  63%|██████▎   | 1801/2863 [21:39<13:36,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1801: train loss 0.49527. lr 4.648850e-04:  63%|██████▎   | 1801/2863 [21:40<13:36,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1801: train loss 0.49527. lr 4.648850e-04:  63%|██████▎   | 1802/2863 [21:40<13:37,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1802: train loss 0.49640. lr 4.647474e-04:  63%|██████▎   | 1802/2863 [21:41<13:37,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1802: train loss 0.49640. lr 4.647474e-04:  63%|██████▎   | 1803/2863 [21:41<13:38,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1803: train loss 0.49050. lr 4.646098e-04:  63%|██████▎   | 1803/2863 [21:42<13:38,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1803: train loss 0.49050. lr 4.646098e-04:  63%|██████▎   | 1804/2863 [21:42<13:39,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1804: train loss 0.49899. lr 4.644721e-04:  63%|██████▎   | 1804/2863 [21:42<13:39,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1804: train loss 0.49899. lr 4.644721e-04:  63%|██████▎   | 1805/2863 [21:42<13:42,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1805: train loss 0.49831. lr 4.643344e-04:  63%|██████▎   | 1805/2863 [21:43<13:42,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1805: train loss 0.49831. lr 4.643344e-04:  63%|██████▎   | 1806/2863 [21:43<14:24,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 1806: train loss 0.49878. lr 4.641966e-04:  63%|██████▎   | 1806/2863 [21:44<14:24,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 1806: train loss 0.49878. lr 4.641966e-04:  63%|██████▎   | 1807/2863 [21:44<14:08,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1807: train loss 0.49816. lr 4.640588e-04:  63%|██████▎   | 1807/2863 [21:45<14:08,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1807: train loss 0.49816. lr 4.640588e-04:  63%|██████▎   | 1808/2863 [21:45<14:02,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1808: train loss 0.48604. lr 4.639210e-04:  63%|██████▎   | 1808/2863 [21:46<14:02,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1808: train loss 0.48604. lr 4.639210e-04:  63%|██████▎   | 1809/2863 [21:46<13:55,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1809: train loss 0.48093. lr 4.637830e-04:  63%|██████▎   | 1809/2863 [21:46<13:55,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1809: train loss 0.48093. lr 4.637830e-04:  63%|██████▎   | 1810/2863 [21:46<13:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1810: train loss 0.48942. lr 4.636451e-04:  63%|██████▎   | 1810/2863 [21:47<13:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1810: train loss 0.48942. lr 4.636451e-04:  63%|██████▎   | 1811/2863 [21:47<13:43,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1811: train loss 0.49220. lr 4.635071e-04:  63%|██████▎   | 1811/2863 [21:48<13:43,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1811: train loss 0.49220. lr 4.635071e-04:  63%|██████▎   | 1812/2863 [21:48<13:37,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1812: train loss 0.51658. lr 4.633690e-04:  63%|██████▎   | 1812/2863 [21:49<13:37,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1812: train loss 0.51658. lr 4.633690e-04:  63%|██████▎   | 1813/2863 [21:49<13:36,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1813: train loss 0.47994. lr 4.632309e-04:  63%|██████▎   | 1813/2863 [21:50<13:36,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1813: train loss 0.47994. lr 4.632309e-04:  63%|██████▎   | 1814/2863 [21:50<13:34,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1814: train loss 0.48366. lr 4.630927e-04:  63%|██████▎   | 1814/2863 [21:50<13:34,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1814: train loss 0.48366. lr 4.630927e-04:  63%|██████▎   | 1815/2863 [21:50<13:31,  1.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1815: train loss 0.49795. lr 4.629545e-04:  63%|██████▎   | 1815/2863 [21:51<13:31,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1815: train loss 0.49795. lr 4.629545e-04:  63%|██████▎   | 1816/2863 [21:51<13:33,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1816: train loss 0.48109. lr 4.628162e-04:  63%|██████▎   | 1816/2863 [21:52<13:33,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1816: train loss 0.48109. lr 4.628162e-04:  63%|██████▎   | 1817/2863 [21:52<13:37,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1817: train loss 0.49574. lr 4.626779e-04:  63%|██████▎   | 1817/2863 [21:53<13:37,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1817: train loss 0.49574. lr 4.626779e-04:  63%|██████▎   | 1818/2863 [21:53<13:34,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1818: train loss 0.47440. lr 4.625395e-04:  63%|██████▎   | 1818/2863 [21:53<13:34,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1818: train loss 0.47440. lr 4.625395e-04:  64%|██████▎   | 1819/2863 [21:53<13:32,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1819: train loss 0.47864. lr 4.624011e-04:  64%|██████▎   | 1819/2863 [21:54<13:32,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1819: train loss 0.47864. lr 4.624011e-04:  64%|██████▎   | 1820/2863 [21:54<13:30,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1820: train loss 0.47657. lr 4.622627e-04:  64%|██████▎   | 1820/2863 [21:55<13:30,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1820: train loss 0.47657. lr 4.622627e-04:  64%|██████▎   | 1821/2863 [21:55<13:31,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1821: train loss 0.48714. lr 4.621242e-04:  64%|██████▎   | 1821/2863 [21:56<13:31,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1821: train loss 0.48714. lr 4.621242e-04:  64%|██████▎   | 1822/2863 [21:56<13:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1822: train loss 0.48238. lr 4.619856e-04:  64%|██████▎   | 1822/2863 [21:57<13:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1822: train loss 0.48238. lr 4.619856e-04:  64%|██████▎   | 1823/2863 [21:57<13:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1823: train loss 0.47431. lr 4.618470e-04:  64%|██████▎   | 1823/2863 [21:57<13:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1823: train loss 0.47431. lr 4.618470e-04:  64%|██████▎   | 1824/2863 [21:57<13:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1824: train loss 0.47907. lr 4.617083e-04:  64%|██████▎   | 1824/2863 [21:58<13:26,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1824: train loss 0.47907. lr 4.617083e-04:  64%|██████▎   | 1825/2863 [21:58<13:25,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1825: train loss 0.48365. lr 4.615696e-04:  64%|██████▎   | 1825/2863 [21:59<13:25,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 1825: train loss 0.48365. lr 4.615696e-04:  64%|██████▍   | 1826/2863 [21:59<13:33,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1826: train loss 0.46334. lr 4.614309e-04:  64%|██████▍   | 1826/2863 [22:00<13:33,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1826: train loss 0.46334. lr 4.614309e-04:  64%|██████▍   | 1827/2863 [22:00<13:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1827: train loss 0.48739. lr 4.612921e-04:  64%|██████▍   | 1827/2863 [22:00<13:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1827: train loss 0.48739. lr 4.612921e-04:  64%|██████▍   | 1828/2863 [22:00<13:32,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1828: train loss 0.47462. lr 4.611532e-04:  64%|██████▍   | 1828/2863 [22:01<13:32,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1828: train loss 0.47462. lr 4.611532e-04:  64%|██████▍   | 1829/2863 [22:01<13:32,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1829: train loss 0.47241. lr 4.610143e-04:  64%|██████▍   | 1829/2863 [22:02<13:32,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1829: train loss 0.47241. lr 4.610143e-04:  64%|██████▍   | 1830/2863 [22:02<13:28,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1830: train loss 0.49885. lr 4.608754e-04:  64%|██████▍   | 1830/2863 [22:03<13:28,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1830: train loss 0.49885. lr 4.608754e-04:  64%|██████▍   | 1831/2863 [22:03<13:24,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1831: train loss 0.47789. lr 4.607364e-04:  64%|██████▍   | 1831/2863 [22:04<13:24,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1831: train loss 0.47789. lr 4.607364e-04:  64%|██████▍   | 1832/2863 [22:04<13:32,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1832: train loss 0.48972. lr 4.605974e-04:  64%|██████▍   | 1832/2863 [22:04<13:32,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1832: train loss 0.48972. lr 4.605974e-04:  64%|██████▍   | 1833/2863 [22:04<13:28,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1833: train loss 0.48167. lr 4.604583e-04:  64%|██████▍   | 1833/2863 [22:05<13:28,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1833: train loss 0.48167. lr 4.604583e-04:  64%|██████▍   | 1834/2863 [22:05<14:02,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 1834: train loss 0.48326. lr 4.603191e-04:  64%|██████▍   | 1834/2863 [22:06<14:02,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 1834: train loss 0.48326. lr 4.603191e-04:  64%|██████▍   | 1835/2863 [22:06<13:48,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1835: train loss 0.48484. lr 4.601799e-04:  64%|██████▍   | 1835/2863 [22:07<13:48,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1835: train loss 0.48484. lr 4.601799e-04:  64%|██████▍   | 1836/2863 [22:07<13:40,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1836: train loss 0.47700. lr 4.600407e-04:  64%|██████▍   | 1836/2863 [22:08<13:40,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1836: train loss 0.47700. lr 4.600407e-04:  64%|██████▍   | 1837/2863 [22:08<13:36,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1837: train loss 0.49355. lr 4.599014e-04:  64%|██████▍   | 1837/2863 [22:08<13:36,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1837: train loss 0.49355. lr 4.599014e-04:  64%|██████▍   | 1838/2863 [22:08<13:35,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1838: train loss 0.48763. lr 4.597621e-04:  64%|██████▍   | 1838/2863 [22:09<13:35,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1838: train loss 0.48763. lr 4.597621e-04:  64%|██████▍   | 1839/2863 [22:09<13:30,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1839: train loss 0.47714. lr 4.596227e-04:  64%|██████▍   | 1839/2863 [22:10<13:30,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1839: train loss 0.47714. lr 4.596227e-04:  64%|██████▍   | 1840/2863 [22:10<13:18,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1840: train loss 0.47328. lr 4.594833e-04:  64%|██████▍   | 1840/2863 [22:11<13:18,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1840: train loss 0.47328. lr 4.594833e-04:  64%|██████▍   | 1841/2863 [22:11<13:16,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1841: train loss 0.46779. lr 4.593438e-04:  64%|██████▍   | 1841/2863 [22:12<13:16,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1841: train loss 0.46779. lr 4.593438e-04:  64%|██████▍   | 1842/2863 [22:12<13:19,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1842: train loss 0.48643. lr 4.592043e-04:  64%|██████▍   | 1842/2863 [22:12<13:19,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1842: train loss 0.48643. lr 4.592043e-04:  64%|██████▍   | 1843/2863 [22:12<13:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1843: train loss 0.48057. lr 4.590647e-04:  64%|██████▍   | 1843/2863 [22:13<13:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1843: train loss 0.48057. lr 4.590647e-04:  64%|██████▍   | 1844/2863 [22:13<13:22,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1844: train loss 0.47534. lr 4.589251e-04:  64%|██████▍   | 1844/2863 [22:14<13:22,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1844: train loss 0.47534. lr 4.589251e-04:  64%|██████▍   | 1845/2863 [22:14<13:17,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1845: train loss 0.46892. lr 4.587854e-04:  64%|██████▍   | 1845/2863 [22:15<13:17,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1845: train loss 0.46892. lr 4.587854e-04:  64%|██████▍   | 1846/2863 [22:15<13:14,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1846: train loss 0.48122. lr 4.586457e-04:  64%|██████▍   | 1846/2863 [22:15<13:14,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1846: train loss 0.48122. lr 4.586457e-04:  65%|██████▍   | 1847/2863 [22:15<13:13,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1847: train loss 0.46696. lr 4.585059e-04:  65%|██████▍   | 1847/2863 [22:16<13:13,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1847: train loss 0.46696. lr 4.585059e-04:  65%|██████▍   | 1848/2863 [22:16<13:16,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1848: train loss 0.47890. lr 4.583661e-04:  65%|██████▍   | 1848/2863 [22:17<13:16,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1848: train loss 0.47890. lr 4.583661e-04:  65%|██████▍   | 1849/2863 [22:17<13:21,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1849: train loss 0.48419. lr 4.582262e-04:  65%|██████▍   | 1849/2863 [22:18<13:21,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1849: train loss 0.48419. lr 4.582262e-04:  65%|██████▍   | 1850/2863 [22:18<13:17,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1850: train loss 0.47775. lr 4.580863e-04:  65%|██████▍   | 1850/2863 [22:19<13:17,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1850: train loss 0.47775. lr 4.580863e-04:  65%|██████▍   | 1851/2863 [22:19<13:12,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1851: train loss 0.48521. lr 4.579464e-04:  65%|██████▍   | 1851/2863 [22:19<13:12,  1.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1851: train loss 0.48521. lr 4.579464e-04:  65%|██████▍   | 1852/2863 [22:19<13:13,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1852: train loss 0.48168. lr 4.578064e-04:  65%|██████▍   | 1852/2863 [22:20<13:13,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1852: train loss 0.48168. lr 4.578064e-04:  65%|██████▍   | 1853/2863 [22:20<13:15,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1853: train loss 0.46758. lr 4.576663e-04:  65%|██████▍   | 1853/2863 [22:21<13:15,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1853: train loss 0.46758. lr 4.576663e-04:  65%|██████▍   | 1854/2863 [22:21<13:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1854: train loss 0.47686. lr 4.575262e-04:  65%|██████▍   | 1854/2863 [22:22<13:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1854: train loss 0.47686. lr 4.575262e-04:  65%|██████▍   | 1855/2863 [22:22<13:16,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1855: train loss 0.45808. lr 4.573861e-04:  65%|██████▍   | 1855/2863 [22:23<13:16,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1855: train loss 0.45808. lr 4.573861e-04:  65%|██████▍   | 1856/2863 [22:23<13:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1856: train loss 0.47256. lr 4.572459e-04:  65%|██████▍   | 1856/2863 [22:23<13:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1856: train loss 0.47256. lr 4.572459e-04:  65%|██████▍   | 1857/2863 [22:23<13:08,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1857: train loss 0.48510. lr 4.571056e-04:  65%|██████▍   | 1857/2863 [22:24<13:08,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1857: train loss 0.48510. lr 4.571056e-04:  65%|██████▍   | 1858/2863 [22:24<13:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1858: train loss 0.45679. lr 4.569654e-04:  65%|██████▍   | 1858/2863 [22:25<13:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1858: train loss 0.45679. lr 4.569654e-04:  65%|██████▍   | 1859/2863 [22:25<13:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1859: train loss 0.46813. lr 4.568250e-04:  65%|██████▍   | 1859/2863 [22:26<13:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1859: train loss 0.46813. lr 4.568250e-04:  65%|██████▍   | 1860/2863 [22:26<13:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1860: train loss 0.46669. lr 4.566846e-04:  65%|██████▍   | 1860/2863 [22:27<13:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1860: train loss 0.46669. lr 4.566846e-04:  65%|██████▌   | 1861/2863 [22:27<13:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1861: train loss 0.47152. lr 4.565442e-04:  65%|██████▌   | 1861/2863 [22:27<13:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1861: train loss 0.47152. lr 4.565442e-04:  65%|██████▌   | 1862/2863 [22:27<13:45,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 1862: train loss 0.46471. lr 4.564037e-04:  65%|██████▌   | 1862/2863 [22:28<13:45,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 1862: train loss 0.46471. lr 4.564037e-04:  65%|██████▌   | 1863/2863 [22:28<13:36,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1863: train loss 0.47166. lr 4.562632e-04:  65%|██████▌   | 1863/2863 [22:29<13:36,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1863: train loss 0.47166. lr 4.562632e-04:  65%|██████▌   | 1864/2863 [22:29<13:30,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1864: train loss 0.45465. lr 4.561226e-04:  65%|██████▌   | 1864/2863 [22:30<13:30,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1864: train loss 0.45465. lr 4.561226e-04:  65%|██████▌   | 1865/2863 [22:30<13:22,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1865: train loss 0.47401. lr 4.559820e-04:  65%|██████▌   | 1865/2863 [22:31<13:22,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1865: train loss 0.47401. lr 4.559820e-04:  65%|██████▌   | 1866/2863 [22:31<13:20,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1866: train loss 0.45814. lr 4.558414e-04:  65%|██████▌   | 1866/2863 [22:31<13:20,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1866: train loss 0.45814. lr 4.558414e-04:  65%|██████▌   | 1867/2863 [22:31<13:16,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1867: train loss 0.46067. lr 4.557006e-04:  65%|██████▌   | 1867/2863 [22:32<13:16,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1867: train loss 0.46067. lr 4.557006e-04:  65%|██████▌   | 1868/2863 [22:32<13:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1868: train loss 0.46626. lr 4.555599e-04:  65%|██████▌   | 1868/2863 [22:33<13:09,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1868: train loss 0.46626. lr 4.555599e-04:  65%|██████▌   | 1869/2863 [22:33<13:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1869: train loss 0.44889. lr 4.554191e-04:  65%|██████▌   | 1869/2863 [22:34<13:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1869: train loss 0.44889. lr 4.554191e-04:  65%|██████▌   | 1870/2863 [22:34<13:06,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1870: train loss 0.48371. lr 4.552782e-04:  65%|██████▌   | 1870/2863 [22:35<13:06,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1870: train loss 0.48371. lr 4.552782e-04:  65%|██████▌   | 1871/2863 [22:35<13:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1871: train loss 0.47297. lr 4.551373e-04:  65%|██████▌   | 1871/2863 [22:35<13:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1871: train loss 0.47297. lr 4.551373e-04:  65%|██████▌   | 1872/2863 [22:35<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1872: train loss 0.46286. lr 4.549964e-04:  65%|██████▌   | 1872/2863 [22:36<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1872: train loss 0.46286. lr 4.549964e-04:  65%|██████▌   | 1873/2863 [22:36<13:00,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1873: train loss 0.46065. lr 4.548554e-04:  65%|██████▌   | 1873/2863 [22:37<13:00,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1873: train loss 0.46065. lr 4.548554e-04:  65%|██████▌   | 1874/2863 [22:37<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1874: train loss 0.46029. lr 4.547143e-04:  65%|██████▌   | 1874/2863 [22:38<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1874: train loss 0.46029. lr 4.547143e-04:  65%|██████▌   | 1875/2863 [22:38<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1875: train loss 0.47255. lr 4.545733e-04:  65%|██████▌   | 1875/2863 [22:38<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1875: train loss 0.47255. lr 4.545733e-04:  66%|██████▌   | 1876/2863 [22:38<12:58,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1876: train loss 0.47154. lr 4.544321e-04:  66%|██████▌   | 1876/2863 [22:39<12:58,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1876: train loss 0.47154. lr 4.544321e-04:  66%|██████▌   | 1877/2863 [22:39<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1877: train loss 0.45648. lr 4.542909e-04:  66%|██████▌   | 1877/2863 [22:40<12:57,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1877: train loss 0.45648. lr 4.542909e-04:  66%|██████▌   | 1878/2863 [22:40<12:56,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1878: train loss 0.45909. lr 4.541497e-04:  66%|██████▌   | 1878/2863 [22:41<12:56,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1878: train loss 0.45909. lr 4.541497e-04:  66%|██████▌   | 1879/2863 [22:41<12:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1879: train loss 0.46835. lr 4.540085e-04:  66%|██████▌   | 1879/2863 [22:42<12:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1879: train loss 0.46835. lr 4.540085e-04:  66%|██████▌   | 1880/2863 [22:42<12:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1880: train loss 0.47034. lr 4.538671e-04:  66%|██████▌   | 1880/2863 [22:42<12:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1880: train loss 0.47034. lr 4.538671e-04:  66%|██████▌   | 1881/2863 [22:42<12:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1881: train loss 0.46688. lr 4.537258e-04:  66%|██████▌   | 1881/2863 [22:43<12:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1881: train loss 0.46688. lr 4.537258e-04:  66%|██████▌   | 1882/2863 [22:43<12:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1882: train loss 0.46471. lr 4.535844e-04:  66%|██████▌   | 1882/2863 [22:44<12:52,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1882: train loss 0.46471. lr 4.535844e-04:  66%|██████▌   | 1883/2863 [22:44<12:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1883: train loss 0.45645. lr 4.534429e-04:  66%|██████▌   | 1883/2863 [22:45<12:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1883: train loss 0.45645. lr 4.534429e-04:  66%|██████▌   | 1884/2863 [22:45<12:44,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1884: train loss 0.46944. lr 4.533014e-04:  66%|██████▌   | 1884/2863 [22:46<12:44,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 1884: train loss 0.46944. lr 4.533014e-04:  66%|██████▌   | 1885/2863 [22:46<12:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1885: train loss 0.46532. lr 4.531598e-04:  66%|██████▌   | 1885/2863 [22:46<12:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1885: train loss 0.46532. lr 4.531598e-04:  66%|██████▌   | 1886/2863 [22:46<12:49,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1886: train loss 0.45397. lr 4.530183e-04:  66%|██████▌   | 1886/2863 [22:47<12:49,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1886: train loss 0.45397. lr 4.530183e-04:  66%|██████▌   | 1887/2863 [22:47<12:46,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1887: train loss 0.46621. lr 4.528766e-04:  66%|██████▌   | 1887/2863 [22:48<12:46,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1887: train loss 0.46621. lr 4.528766e-04:  66%|██████▌   | 1888/2863 [22:48<12:46,  1.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1888: train loss 0.45490. lr 4.527349e-04:  66%|██████▌   | 1888/2863 [22:49<12:46,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1888: train loss 0.45490. lr 4.527349e-04:  66%|██████▌   | 1889/2863 [22:49<12:44,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1889: train loss 0.47021. lr 4.525932e-04:  66%|██████▌   | 1889/2863 [22:50<12:44,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1889: train loss 0.47021. lr 4.525932e-04:  66%|██████▌   | 1890/2863 [22:50<13:14,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1890: train loss 0.45787. lr 4.524514e-04:  66%|██████▌   | 1890/2863 [22:50<13:14,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1890: train loss 0.45787. lr 4.524514e-04:  66%|██████▌   | 1891/2863 [22:50<13:08,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1891: train loss 0.46595. lr 4.523096e-04:  66%|██████▌   | 1891/2863 [22:51<13:08,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 1891: train loss 0.46595. lr 4.523096e-04:  66%|██████▌   | 1892/2863 [22:51<13:03,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1892: train loss 0.45737. lr 4.521677e-04:  66%|██████▌   | 1892/2863 [22:52<13:03,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 1892: train loss 0.45737. lr 4.521677e-04:  66%|██████▌   | 1893/2863 [22:52<12:57,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1893: train loss 0.44103. lr 4.520258e-04:  66%|██████▌   | 1893/2863 [22:53<12:57,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 1893: train loss 0.44103. lr 4.520258e-04:  66%|██████▌   | 1894/2863 [22:53<12:50,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1894: train loss 0.46283. lr 4.518838e-04:  66%|██████▌   | 1894/2863 [22:54<12:50,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1894: train loss 0.46283. lr 4.518838e-04:  66%|██████▌   | 1895/2863 [22:54<12:49,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1895: train loss 0.45669. lr 4.517418e-04:  66%|██████▌   | 1895/2863 [22:54<12:49,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1895: train loss 0.45669. lr 4.517418e-04:  66%|██████▌   | 1896/2863 [22:54<12:47,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1896: train loss 0.44149. lr 4.515998e-04:  66%|██████▌   | 1896/2863 [22:55<12:47,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1896: train loss 0.44149. lr 4.515998e-04:  66%|██████▋   | 1897/2863 [22:55<12:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1897: train loss 0.45880. lr 4.514577e-04:  66%|██████▋   | 1897/2863 [22:56<12:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1897: train loss 0.45880. lr 4.514577e-04:  66%|██████▋   | 1898/2863 [22:56<12:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1898: train loss 0.44943. lr 4.513155e-04:  66%|██████▋   | 1898/2863 [22:57<12:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1898: train loss 0.44943. lr 4.513155e-04:  66%|██████▋   | 1899/2863 [22:57<12:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1899: train loss 0.45416. lr 4.511733e-04:  66%|██████▋   | 1899/2863 [22:57<12:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1899: train loss 0.45416. lr 4.511733e-04:  66%|██████▋   | 1900/2863 [22:57<12:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1900: train loss 0.46241. lr 4.510311e-04:  66%|██████▋   | 1900/2863 [22:58<12:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1900: train loss 0.46241. lr 4.510311e-04:  66%|██████▋   | 1901/2863 [22:58<12:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1901: train loss 0.46370. lr 4.508888e-04:  66%|██████▋   | 1901/2863 [22:59<12:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 1901: train loss 0.46370. lr 4.508888e-04:  66%|██████▋   | 1902/2863 [22:59<12:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1902: train loss 0.45070. lr 4.507465e-04:  66%|██████▋   | 1902/2863 [23:00<12:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1902: train loss 0.45070. lr 4.507465e-04:  66%|██████▋   | 1903/2863 [23:00<12:38,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1903: train loss 0.45287. lr 4.506041e-04:  66%|██████▋   | 1903/2863 [23:01<12:38,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1903: train loss 0.45287. lr 4.506041e-04:  67%|██████▋   | 1904/2863 [23:01<12:35,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1904: train loss 0.45126. lr 4.504617e-04:  67%|██████▋   | 1904/2863 [23:01<12:35,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 1904: train loss 0.45126. lr 4.504617e-04:  67%|██████▋   | 1905/2863 [23:01<12:17,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1905: train loss 0.43766. lr 4.503192e-04:  67%|██████▋   | 1905/2863 [23:02<12:17,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 1905: train loss 0.43766. lr 4.503192e-04:  67%|██████▋   | 1906/2863 [23:02<11:53,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1906: train loss 0.43866. lr 4.501767e-04:  67%|██████▋   | 1906/2863 [23:03<11:53,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 1906: train loss 0.43866. lr 4.501767e-04:  67%|██████▋   | 1907/2863 [23:03<11:38,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1907: train loss 0.44730. lr 4.500342e-04:  67%|██████▋   | 1907/2863 [23:04<11:38,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1907: train loss 0.44730. lr 4.500342e-04:  67%|██████▋   | 1908/2863 [23:04<11:47,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1908: train loss 0.45668. lr 4.498916e-04:  67%|██████▋   | 1908/2863 [23:04<11:47,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1908: train loss 0.45668. lr 4.498916e-04:  67%|██████▋   | 1909/2863 [23:04<11:45,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1909: train loss 0.45012. lr 4.497489e-04:  67%|██████▋   | 1909/2863 [23:05<11:45,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1909: train loss 0.45012. lr 4.497489e-04:  67%|██████▋   | 1910/2863 [23:05<11:39,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1910: train loss 0.46008. lr 4.496062e-04:  67%|██████▋   | 1910/2863 [23:06<11:39,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1910: train loss 0.46008. lr 4.496062e-04:  67%|██████▋   | 1911/2863 [23:06<11:25,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1911: train loss 0.47455. lr 4.494635e-04:  67%|██████▋   | 1911/2863 [23:06<11:25,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1911: train loss 0.47455. lr 4.494635e-04:  67%|██████▋   | 1912/2863 [23:06<11:14,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1912: train loss 0.48423. lr 4.493207e-04:  67%|██████▋   | 1912/2863 [23:07<11:14,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1912: train loss 0.48423. lr 4.493207e-04:  67%|██████▋   | 1913/2863 [23:07<11:08,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1913: train loss 0.45466. lr 4.491779e-04:  67%|██████▋   | 1913/2863 [23:08<11:08,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1913: train loss 0.45466. lr 4.491779e-04:  67%|██████▋   | 1914/2863 [23:08<11:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1914: train loss 0.44654. lr 4.490350e-04:  67%|██████▋   | 1914/2863 [23:08<11:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1914: train loss 0.44654. lr 4.490350e-04:  67%|██████▋   | 1915/2863 [23:08<11:00,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1915: train loss 0.44929. lr 4.488921e-04:  67%|██████▋   | 1915/2863 [23:09<11:00,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1915: train loss 0.44929. lr 4.488921e-04:  67%|██████▋   | 1916/2863 [23:09<10:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1916: train loss 0.42912. lr 4.487491e-04:  67%|██████▋   | 1916/2863 [23:10<10:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1916: train loss 0.42912. lr 4.487491e-04:  67%|██████▋   | 1917/2863 [23:10<11:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1917: train loss 0.46487. lr 4.486061e-04:  67%|██████▋   | 1917/2863 [23:11<11:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1917: train loss 0.46487. lr 4.486061e-04:  67%|██████▋   | 1918/2863 [23:11<11:33,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1918: train loss 0.45412. lr 4.484631e-04:  67%|██████▋   | 1918/2863 [23:11<11:33,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 1918: train loss 0.45412. lr 4.484631e-04:  67%|██████▋   | 1919/2863 [23:11<11:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1919: train loss 0.45873. lr 4.483200e-04:  67%|██████▋   | 1919/2863 [23:12<11:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1919: train loss 0.45873. lr 4.483200e-04:  67%|██████▋   | 1920/2863 [23:12<11:19,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1920: train loss 0.45491. lr 4.481769e-04:  67%|██████▋   | 1920/2863 [23:13<11:19,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1920: train loss 0.45491. lr 4.481769e-04:  67%|██████▋   | 1921/2863 [23:13<11:18,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1921: train loss 0.44754. lr 4.480337e-04:  67%|██████▋   | 1921/2863 [23:13<11:18,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1921: train loss 0.44754. lr 4.480337e-04:  67%|██████▋   | 1922/2863 [23:13<11:14,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1922: train loss 0.43845. lr 4.478904e-04:  67%|██████▋   | 1922/2863 [23:14<11:14,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1922: train loss 0.43845. lr 4.478904e-04:  67%|██████▋   | 1923/2863 [23:14<11:08,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1923: train loss 0.45900. lr 4.477472e-04:  67%|██████▋   | 1923/2863 [23:15<11:08,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1923: train loss 0.45900. lr 4.477472e-04:  67%|██████▋   | 1924/2863 [23:15<11:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1924: train loss 0.43362. lr 4.476039e-04:  67%|██████▋   | 1924/2863 [23:16<11:03,  1.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1924: train loss 0.43362. lr 4.476039e-04:  67%|██████▋   | 1925/2863 [23:16<10:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1925: train loss 0.44585. lr 4.474605e-04:  67%|██████▋   | 1925/2863 [23:16<10:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1925: train loss 0.44585. lr 4.474605e-04:  67%|██████▋   | 1926/2863 [23:16<10:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1926: train loss 0.44498. lr 4.473171e-04:  67%|██████▋   | 1926/2863 [23:17<10:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1926: train loss 0.44498. lr 4.473171e-04:  67%|██████▋   | 1927/2863 [23:17<11:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1927: train loss 0.45401. lr 4.471736e-04:  67%|██████▋   | 1927/2863 [23:18<11:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1927: train loss 0.45401. lr 4.471736e-04:  67%|██████▋   | 1928/2863 [23:18<11:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1928: train loss 0.45280. lr 4.470301e-04:  67%|██████▋   | 1928/2863 [23:18<11:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1928: train loss 0.45280. lr 4.470301e-04:  67%|██████▋   | 1929/2863 [23:18<11:01,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1929: train loss 0.44933. lr 4.468866e-04:  67%|██████▋   | 1929/2863 [23:19<11:01,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1929: train loss 0.44933. lr 4.468866e-04:  67%|██████▋   | 1930/2863 [23:19<10:58,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1930: train loss 0.44884. lr 4.467430e-04:  67%|██████▋   | 1930/2863 [23:20<10:58,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1930: train loss 0.44884. lr 4.467430e-04:  67%|██████▋   | 1931/2863 [23:20<10:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1931: train loss 0.45690. lr 4.465994e-04:  67%|██████▋   | 1931/2863 [23:20<10:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1931: train loss 0.45690. lr 4.465994e-04:  67%|██████▋   | 1932/2863 [23:20<10:50,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1932: train loss 0.45232. lr 4.464557e-04:  67%|██████▋   | 1932/2863 [23:21<10:50,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1932: train loss 0.45232. lr 4.464557e-04:  68%|██████▊   | 1933/2863 [23:21<10:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1933: train loss 0.45631. lr 4.463120e-04:  68%|██████▊   | 1933/2863 [23:22<10:48,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1933: train loss 0.45631. lr 4.463120e-04:  68%|██████▊   | 1934/2863 [23:22<10:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1934: train loss 0.43261. lr 4.461682e-04:  68%|██████▊   | 1934/2863 [23:23<10:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1934: train loss 0.43261. lr 4.461682e-04:  68%|██████▊   | 1935/2863 [23:23<10:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1935: train loss 0.46021. lr 4.460244e-04:  68%|██████▊   | 1935/2863 [23:23<10:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1935: train loss 0.46021. lr 4.460244e-04:  68%|██████▊   | 1936/2863 [23:23<10:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1936: train loss 0.44073. lr 4.458806e-04:  68%|██████▊   | 1936/2863 [23:24<10:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1936: train loss 0.44073. lr 4.458806e-04:  68%|██████▊   | 1937/2863 [23:24<10:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1937: train loss 0.44394. lr 4.457367e-04:  68%|██████▊   | 1937/2863 [23:25<10:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1937: train loss 0.44394. lr 4.457367e-04:  68%|██████▊   | 1938/2863 [23:25<10:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1938: train loss 0.44591. lr 4.455928e-04:  68%|██████▊   | 1938/2863 [23:25<10:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1938: train loss 0.44591. lr 4.455928e-04:  68%|██████▊   | 1939/2863 [23:25<10:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1939: train loss 0.45177. lr 4.454488e-04:  68%|██████▊   | 1939/2863 [23:26<10:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1939: train loss 0.45177. lr 4.454488e-04:  68%|██████▊   | 1940/2863 [23:26<10:36,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1940: train loss 0.44118. lr 4.453048e-04:  68%|██████▊   | 1940/2863 [23:27<10:36,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1940: train loss 0.44118. lr 4.453048e-04:  68%|██████▊   | 1941/2863 [23:27<10:35,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1941: train loss 0.44489. lr 4.451607e-04:  68%|██████▊   | 1941/2863 [23:27<10:35,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1941: train loss 0.44489. lr 4.451607e-04:  68%|██████▊   | 1942/2863 [23:27<10:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1942: train loss 0.45008. lr 4.450166e-04:  68%|██████▊   | 1942/2863 [23:28<10:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1942: train loss 0.45008. lr 4.450166e-04:  68%|██████▊   | 1943/2863 [23:28<10:32,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1943: train loss 0.45491. lr 4.448724e-04:  68%|██████▊   | 1943/2863 [23:29<10:32,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1943: train loss 0.45491. lr 4.448724e-04:  68%|██████▊   | 1944/2863 [23:29<10:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1944: train loss 0.44014. lr 4.447282e-04:  68%|██████▊   | 1944/2863 [23:29<10:34,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1944: train loss 0.44014. lr 4.447282e-04:  68%|██████▊   | 1945/2863 [23:29<10:35,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1945: train loss 0.42830. lr 4.445840e-04:  68%|██████▊   | 1945/2863 [23:30<10:35,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1945: train loss 0.42830. lr 4.445840e-04:  68%|██████▊   | 1946/2863 [23:30<11:05,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1946: train loss 0.43571. lr 4.444397e-04:  68%|██████▊   | 1946/2863 [23:31<11:05,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 1946: train loss 0.43571. lr 4.444397e-04:  68%|██████▊   | 1947/2863 [23:31<10:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1947: train loss 0.44243. lr 4.442954e-04:  68%|██████▊   | 1947/2863 [23:32<10:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1947: train loss 0.44243. lr 4.442954e-04:  68%|██████▊   | 1948/2863 [23:32<10:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1948: train loss 0.44098. lr 4.441510e-04:  68%|██████▊   | 1948/2863 [23:32<10:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1948: train loss 0.44098. lr 4.441510e-04:  68%|██████▊   | 1949/2863 [23:32<10:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1949: train loss 0.42305. lr 4.440066e-04:  68%|██████▊   | 1949/2863 [23:33<10:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1949: train loss 0.42305. lr 4.440066e-04:  68%|██████▊   | 1950/2863 [23:33<10:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1950: train loss 0.43666. lr 4.438621e-04:  68%|██████▊   | 1950/2863 [23:34<10:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1950: train loss 0.43666. lr 4.438621e-04:  68%|██████▊   | 1951/2863 [23:34<10:45,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1951: train loss 0.44986. lr 4.437176e-04:  68%|██████▊   | 1951/2863 [23:34<10:45,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1951: train loss 0.44986. lr 4.437176e-04:  68%|██████▊   | 1952/2863 [23:34<10:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1952: train loss 0.43588. lr 4.435731e-04:  68%|██████▊   | 1952/2863 [23:35<10:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1952: train loss 0.43588. lr 4.435731e-04:  68%|██████▊   | 1953/2863 [23:35<10:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1953: train loss 0.43058. lr 4.434285e-04:  68%|██████▊   | 1953/2863 [23:36<10:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1953: train loss 0.43058. lr 4.434285e-04:  68%|██████▊   | 1954/2863 [23:36<10:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1954: train loss 0.44134. lr 4.432839e-04:  68%|██████▊   | 1954/2863 [23:37<10:33,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1954: train loss 0.44134. lr 4.432839e-04:  68%|██████▊   | 1955/2863 [23:37<10:32,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1955: train loss 0.43503. lr 4.431392e-04:  68%|██████▊   | 1955/2863 [23:37<10:32,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1955: train loss 0.43503. lr 4.431392e-04:  68%|██████▊   | 1956/2863 [23:37<10:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1956: train loss 0.44102. lr 4.429945e-04:  68%|██████▊   | 1956/2863 [23:38<10:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1956: train loss 0.44102. lr 4.429945e-04:  68%|██████▊   | 1957/2863 [23:38<10:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1957: train loss 0.43334. lr 4.428497e-04:  68%|██████▊   | 1957/2863 [23:39<10:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1957: train loss 0.43334. lr 4.428497e-04:  68%|██████▊   | 1958/2863 [23:39<10:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1958: train loss 0.43783. lr 4.427049e-04:  68%|██████▊   | 1958/2863 [23:39<10:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1958: train loss 0.43783. lr 4.427049e-04:  68%|██████▊   | 1959/2863 [23:39<10:24,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1959: train loss 0.44820. lr 4.425601e-04:  68%|██████▊   | 1959/2863 [23:40<10:24,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1959: train loss 0.44820. lr 4.425601e-04:  68%|██████▊   | 1960/2863 [23:40<10:22,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1960: train loss 0.44116. lr 4.424152e-04:  68%|██████▊   | 1960/2863 [23:41<10:22,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1960: train loss 0.44116. lr 4.424152e-04:  68%|██████▊   | 1961/2863 [23:41<10:35,  1.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1961: train loss 0.43564. lr 4.422702e-04:  68%|██████▊   | 1961/2863 [23:41<10:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1961: train loss 0.43564. lr 4.422702e-04:  69%|██████▊   | 1962/2863 [23:41<10:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1962: train loss 0.44022. lr 4.421253e-04:  69%|██████▊   | 1962/2863 [23:42<10:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1962: train loss 0.44022. lr 4.421253e-04:  69%|██████▊   | 1963/2863 [23:42<10:38,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1963: train loss 0.43492. lr 4.419802e-04:  69%|██████▊   | 1963/2863 [23:43<10:38,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1963: train loss 0.43492. lr 4.419802e-04:  69%|██████▊   | 1964/2863 [23:43<10:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1964: train loss 0.43876. lr 4.418352e-04:  69%|██████▊   | 1964/2863 [23:44<10:37,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1964: train loss 0.43876. lr 4.418352e-04:  69%|██████▊   | 1965/2863 [23:44<10:31,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1965: train loss 0.44453. lr 4.416901e-04:  69%|██████▊   | 1965/2863 [23:44<10:31,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1965: train loss 0.44453. lr 4.416901e-04:  69%|██████▊   | 1966/2863 [23:44<10:29,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1966: train loss 0.43095. lr 4.415449e-04:  69%|██████▊   | 1966/2863 [23:45<10:29,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1966: train loss 0.43095. lr 4.415449e-04:  69%|██████▊   | 1967/2863 [23:45<10:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1967: train loss 0.42123. lr 4.413997e-04:  69%|██████▊   | 1967/2863 [23:46<10:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1967: train loss 0.42123. lr 4.413997e-04:  69%|██████▊   | 1968/2863 [23:46<10:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1968: train loss 0.43644. lr 4.412545e-04:  69%|██████▊   | 1968/2863 [23:46<10:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1968: train loss 0.43644. lr 4.412545e-04:  69%|██████▉   | 1969/2863 [23:46<10:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1969: train loss 0.41623. lr 4.411092e-04:  69%|██████▉   | 1969/2863 [23:47<10:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1969: train loss 0.41623. lr 4.411092e-04:  69%|██████▉   | 1970/2863 [23:47<10:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1970: train loss 0.42670. lr 4.409639e-04:  69%|██████▉   | 1970/2863 [23:48<10:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1970: train loss 0.42670. lr 4.409639e-04:  69%|██████▉   | 1971/2863 [23:48<10:20,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1971: train loss 0.43468. lr 4.408186e-04:  69%|██████▉   | 1971/2863 [23:48<10:20,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1971: train loss 0.43468. lr 4.408186e-04:  69%|██████▉   | 1972/2863 [23:48<10:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1972: train loss 0.43129. lr 4.406731e-04:  69%|██████▉   | 1972/2863 [23:49<10:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1972: train loss 0.43129. lr 4.406731e-04:  69%|██████▉   | 1973/2863 [23:49<10:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1973: train loss 0.43766. lr 4.405277e-04:  69%|██████▉   | 1973/2863 [23:50<10:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1973: train loss 0.43766. lr 4.405277e-04:  69%|██████▉   | 1974/2863 [23:50<10:59,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1974: train loss 0.43404. lr 4.403822e-04:  69%|██████▉   | 1974/2863 [23:51<10:59,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 1974: train loss 0.43404. lr 4.403822e-04:  69%|██████▉   | 1975/2863 [23:51<10:48,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1975: train loss 0.42995. lr 4.402367e-04:  69%|██████▉   | 1975/2863 [23:51<10:48,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 1975: train loss 0.42995. lr 4.402367e-04:  69%|██████▉   | 1976/2863 [23:51<10:40,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1976: train loss 0.42194. lr 4.400911e-04:  69%|██████▉   | 1976/2863 [23:52<10:40,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 1976: train loss 0.42194. lr 4.400911e-04:  69%|██████▉   | 1977/2863 [23:52<10:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1977: train loss 0.41763. lr 4.399455e-04:  69%|██████▉   | 1977/2863 [23:53<10:34,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1977: train loss 0.41763. lr 4.399455e-04:  69%|██████▉   | 1978/2863 [23:53<10:26,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1978: train loss 0.43093. lr 4.397998e-04:  69%|██████▉   | 1978/2863 [23:53<10:26,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1978: train loss 0.43093. lr 4.397998e-04:  69%|██████▉   | 1979/2863 [23:53<10:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1979: train loss 0.41830. lr 4.396542e-04:  69%|██████▉   | 1979/2863 [23:54<10:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1979: train loss 0.41830. lr 4.396542e-04:  69%|██████▉   | 1980/2863 [23:54<10:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1980: train loss 0.43448. lr 4.395084e-04:  69%|██████▉   | 1980/2863 [23:55<10:19,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1980: train loss 0.43448. lr 4.395084e-04:  69%|██████▉   | 1981/2863 [23:55<10:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1981: train loss 0.44548. lr 4.393626e-04:  69%|██████▉   | 1981/2863 [23:56<10:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1981: train loss 0.44548. lr 4.393626e-04:  69%|██████▉   | 1982/2863 [23:56<10:23,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1982: train loss 0.42323. lr 4.392168e-04:  69%|██████▉   | 1982/2863 [23:56<10:23,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1982: train loss 0.42323. lr 4.392168e-04:  69%|██████▉   | 1983/2863 [23:56<10:22,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1983: train loss 0.44075. lr 4.390709e-04:  69%|██████▉   | 1983/2863 [23:57<10:22,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1983: train loss 0.44075. lr 4.390709e-04:  69%|██████▉   | 1984/2863 [23:57<10:20,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1984: train loss 0.44245. lr 4.389250e-04:  69%|██████▉   | 1984/2863 [23:58<10:20,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1984: train loss 0.44245. lr 4.389250e-04:  69%|██████▉   | 1985/2863 [23:58<10:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1985: train loss 0.43346. lr 4.387791e-04:  69%|██████▉   | 1985/2863 [23:58<10:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1985: train loss 0.43346. lr 4.387791e-04:  69%|██████▉   | 1986/2863 [23:58<10:28,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1986: train loss 0.43333. lr 4.386331e-04:  69%|██████▉   | 1986/2863 [23:59<10:28,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1986: train loss 0.43333. lr 4.386331e-04:  69%|██████▉   | 1987/2863 [23:59<10:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1987: train loss 0.43174. lr 4.384871e-04:  69%|██████▉   | 1987/2863 [24:00<10:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1987: train loss 0.43174. lr 4.384871e-04:  69%|██████▉   | 1988/2863 [24:00<10:24,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1988: train loss 0.43253. lr 4.383410e-04:  69%|██████▉   | 1988/2863 [24:01<10:24,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 1988: train loss 0.43253. lr 4.383410e-04:  69%|██████▉   | 1989/2863 [24:01<10:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1989: train loss 0.41071. lr 4.381949e-04:  69%|██████▉   | 1989/2863 [24:01<10:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 1989: train loss 0.41071. lr 4.381949e-04:  70%|██████▉   | 1990/2863 [24:01<10:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1990: train loss 0.44796. lr 4.380487e-04:  70%|██████▉   | 1990/2863 [24:02<10:15,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 1990: train loss 0.44796. lr 4.380487e-04:  70%|██████▉   | 1991/2863 [24:02<10:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1991: train loss 0.43569. lr 4.379025e-04:  70%|██████▉   | 1991/2863 [24:03<10:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 1991: train loss 0.43569. lr 4.379025e-04:  70%|██████▉   | 1992/2863 [24:03<10:04,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1992: train loss 0.43335. lr 4.377563e-04:  70%|██████▉   | 1992/2863 [24:03<10:04,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1992: train loss 0.43335. lr 4.377563e-04:  70%|██████▉   | 1993/2863 [24:03<10:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1993: train loss 0.43607. lr 4.376100e-04:  70%|██████▉   | 1993/2863 [24:04<10:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 1993: train loss 0.43607. lr 4.376100e-04:  70%|██████▉   | 1994/2863 [24:04<09:59,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1994: train loss 0.41929. lr 4.374637e-04:  70%|██████▉   | 1994/2863 [24:05<09:59,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1994: train loss 0.41929. lr 4.374637e-04:  70%|██████▉   | 1995/2863 [24:05<09:57,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1995: train loss 0.43317. lr 4.373173e-04:  70%|██████▉   | 1995/2863 [24:05<09:57,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1995: train loss 0.43317. lr 4.373173e-04:  70%|██████▉   | 1996/2863 [24:05<09:59,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1996: train loss 0.41896. lr 4.371709e-04:  70%|██████▉   | 1996/2863 [24:06<09:59,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1996: train loss 0.41896. lr 4.371709e-04:  70%|██████▉   | 1997/2863 [24:06<09:57,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1997: train loss 0.42586. lr 4.370244e-04:  70%|██████▉   | 1997/2863 [24:07<09:57,  1.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1997: train loss 0.42586. lr 4.370244e-04:  70%|██████▉   | 1998/2863 [24:07<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1998: train loss 0.42793. lr 4.368780e-04:  70%|██████▉   | 1998/2863 [24:07<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1998: train loss 0.42793. lr 4.368780e-04:  70%|██████▉   | 1999/2863 [24:07<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1999: train loss 0.43811. lr 4.367314e-04:  70%|██████▉   | 1999/2863 [24:08<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 1999: train loss 0.43811. lr 4.367314e-04:  70%|██████▉   | 2000/2863 [24:08<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2000: train loss 0.42378. lr 4.365848e-04:  70%|██████▉   | 2000/2863 [24:09<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2000: train loss 0.42378. lr 4.365848e-04:  70%|██████▉   | 2001/2863 [24:09<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2001: train loss 0.42159. lr 4.364382e-04:  70%|██████▉   | 2001/2863 [24:10<09:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2001: train loss 0.42159. lr 4.364382e-04:  70%|██████▉   | 2002/2863 [24:10<10:28,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2002: train loss 0.43239. lr 4.362916e-04:  70%|██████▉   | 2002/2863 [24:10<10:28,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2002: train loss 0.43239. lr 4.362916e-04:  70%|██████▉   | 2003/2863 [24:10<10:18,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2003: train loss 0.43898. lr 4.361449e-04:  70%|██████▉   | 2003/2863 [24:11<10:18,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2003: train loss 0.43898. lr 4.361449e-04:  70%|██████▉   | 2004/2863 [24:11<10:10,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2004: train loss 0.41359. lr 4.359981e-04:  70%|██████▉   | 2004/2863 [24:12<10:10,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2004: train loss 0.41359. lr 4.359981e-04:  70%|███████   | 2005/2863 [24:12<10:04,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2005: train loss 0.41935. lr 4.358514e-04:  70%|███████   | 2005/2863 [24:12<10:04,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2005: train loss 0.41935. lr 4.358514e-04:  70%|███████   | 2006/2863 [24:12<10:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2006: train loss 0.42613. lr 4.357046e-04:  70%|███████   | 2006/2863 [24:13<10:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2006: train loss 0.42613. lr 4.357046e-04:  70%|███████   | 2007/2863 [24:13<09:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2007: train loss 0.41986. lr 4.355577e-04:  70%|███████   | 2007/2863 [24:14<09:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2007: train loss 0.41986. lr 4.355577e-04:  70%|███████   | 2008/2863 [24:14<09:54,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2008: train loss 0.41340. lr 4.354108e-04:  70%|███████   | 2008/2863 [24:15<09:54,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2008: train loss 0.41340. lr 4.354108e-04:  70%|███████   | 2009/2863 [24:15<09:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2009: train loss 0.42826. lr 4.352639e-04:  70%|███████   | 2009/2863 [24:15<09:51,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2009: train loss 0.42826. lr 4.352639e-04:  70%|███████   | 2010/2863 [24:15<09:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2010: train loss 0.41517. lr 4.351169e-04:  70%|███████   | 2010/2863 [24:16<09:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2010: train loss 0.41517. lr 4.351169e-04:  70%|███████   | 2011/2863 [24:16<09:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2011: train loss 0.43133. lr 4.349699e-04:  70%|███████   | 2011/2863 [24:17<09:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2011: train loss 0.43133. lr 4.349699e-04:  70%|███████   | 2012/2863 [24:17<09:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2012: train loss 0.43399. lr 4.348228e-04:  70%|███████   | 2012/2863 [24:17<09:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2012: train loss 0.43399. lr 4.348228e-04:  70%|███████   | 2013/2863 [24:17<09:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2013: train loss 0.42553. lr 4.346757e-04:  70%|███████   | 2013/2863 [24:18<09:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2013: train loss 0.42553. lr 4.346757e-04:  70%|███████   | 2014/2863 [24:18<09:45,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2014: train loss 0.41463. lr 4.345285e-04:  70%|███████   | 2014/2863 [24:19<09:45,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2014: train loss 0.41463. lr 4.345285e-04:  70%|███████   | 2015/2863 [24:19<09:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2015: train loss 0.42439. lr 4.343814e-04:  70%|███████   | 2015/2863 [24:19<09:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2015: train loss 0.42439. lr 4.343814e-04:  70%|███████   | 2016/2863 [24:19<09:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2016: train loss 0.43078. lr 4.342341e-04:  70%|███████   | 2016/2863 [24:20<09:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2016: train loss 0.43078. lr 4.342341e-04:  70%|███████   | 2017/2863 [24:20<09:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2017: train loss 0.42297. lr 4.340869e-04:  70%|███████   | 2017/2863 [24:21<09:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2017: train loss 0.42297. lr 4.340869e-04:  70%|███████   | 2018/2863 [24:21<09:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2018: train loss 0.44204. lr 4.339396e-04:  70%|███████   | 2018/2863 [24:21<09:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2018: train loss 0.44204. lr 4.339396e-04:  71%|███████   | 2019/2863 [24:21<09:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2019: train loss 0.41870. lr 4.337922e-04:  71%|███████   | 2019/2863 [24:22<09:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2019: train loss 0.41870. lr 4.337922e-04:  71%|███████   | 2020/2863 [24:22<09:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2020: train loss 0.42183. lr 4.336448e-04:  71%|███████   | 2020/2863 [24:23<09:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2020: train loss 0.42183. lr 4.336448e-04:  71%|███████   | 2021/2863 [24:23<09:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2021: train loss 0.42603. lr 4.334974e-04:  71%|███████   | 2021/2863 [24:24<09:42,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2021: train loss 0.42603. lr 4.334974e-04:  71%|███████   | 2022/2863 [24:24<09:51,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2022: train loss 0.43684. lr 4.333499e-04:  71%|███████   | 2022/2863 [24:24<09:51,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2022: train loss 0.43684. lr 4.333499e-04:  71%|███████   | 2023/2863 [24:24<09:58,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2023: train loss 0.41591. lr 4.332024e-04:  71%|███████   | 2023/2863 [24:25<09:58,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2023: train loss 0.41591. lr 4.332024e-04:  71%|███████   | 2024/2863 [24:25<09:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2024: train loss 0.42220. lr 4.330549e-04:  71%|███████   | 2024/2863 [24:26<09:59,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2024: train loss 0.42220. lr 4.330549e-04:  71%|███████   | 2025/2863 [24:26<09:58,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2025: train loss 0.42385. lr 4.329073e-04:  71%|███████   | 2025/2863 [24:26<09:58,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2025: train loss 0.42385. lr 4.329073e-04:  71%|███████   | 2026/2863 [24:26<09:56,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2026: train loss 0.42841. lr 4.327597e-04:  71%|███████   | 2026/2863 [24:27<09:56,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2026: train loss 0.42841. lr 4.327597e-04:  71%|███████   | 2027/2863 [24:27<09:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2027: train loss 0.41998. lr 4.326120e-04:  71%|███████   | 2027/2863 [24:28<09:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2027: train loss 0.41998. lr 4.326120e-04:  71%|███████   | 2028/2863 [24:28<09:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2028: train loss 0.41536. lr 4.324643e-04:  71%|███████   | 2028/2863 [24:29<09:52,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2028: train loss 0.41536. lr 4.324643e-04:  71%|███████   | 2029/2863 [24:29<09:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2029: train loss 0.40722. lr 4.323165e-04:  71%|███████   | 2029/2863 [24:29<09:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2029: train loss 0.40722. lr 4.323165e-04:  71%|███████   | 2030/2863 [24:29<10:25,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2030: train loss 0.42535. lr 4.321688e-04:  71%|███████   | 2030/2863 [24:30<10:25,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2030: train loss 0.42535. lr 4.321688e-04:  71%|███████   | 2031/2863 [24:30<10:14,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2031: train loss 0.41291. lr 4.320209e-04:  71%|███████   | 2031/2863 [24:31<10:14,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2031: train loss 0.41291. lr 4.320209e-04:  71%|███████   | 2032/2863 [24:31<10:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2032: train loss 0.41456. lr 4.318731e-04:  71%|███████   | 2032/2863 [24:32<10:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2032: train loss 0.41456. lr 4.318731e-04:  71%|███████   | 2033/2863 [24:32<10:03,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2033: train loss 0.41538. lr 4.317252e-04:  71%|███████   | 2033/2863 [24:32<10:03,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2033: train loss 0.41538. lr 4.317252e-04:  71%|███████   | 2034/2863 [24:32<10:00,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2034: train loss 0.41809. lr 4.315772e-04:  71%|███████   | 2034/2863 [24:33<10:00,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2034: train loss 0.41809. lr 4.315772e-04:  71%|███████   | 2035/2863 [24:33<09:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2035: train loss 0.42296. lr 4.314292e-04:  71%|███████   | 2035/2863 [24:34<09:57,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2035: train loss 0.42296. lr 4.314292e-04:  71%|███████   | 2036/2863 [24:34<09:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2036: train loss 0.42949. lr 4.312812e-04:  71%|███████   | 2036/2863 [24:34<09:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2036: train loss 0.42949. lr 4.312812e-04:  71%|███████   | 2037/2863 [24:34<09:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2037: train loss 0.40985. lr 4.311331e-04:  71%|███████   | 2037/2863 [24:35<09:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2037: train loss 0.40985. lr 4.311331e-04:  71%|███████   | 2038/2863 [24:35<09:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2038: train loss 0.41672. lr 4.309850e-04:  71%|███████   | 2038/2863 [24:36<09:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2038: train loss 0.41672. lr 4.309850e-04:  71%|███████   | 2039/2863 [24:36<09:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2039: train loss 0.41413. lr 4.308369e-04:  71%|███████   | 2039/2863 [24:36<09:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2039: train loss 0.41413. lr 4.308369e-04:  71%|███████▏  | 2040/2863 [24:36<09:29,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2040: train loss 0.42085. lr 4.306887e-04:  71%|███████▏  | 2040/2863 [24:37<09:29,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2040: train loss 0.42085. lr 4.306887e-04:  71%|███████▏  | 2041/2863 [24:37<09:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2041: train loss 0.41961. lr 4.305405e-04:  71%|███████▏  | 2041/2863 [24:38<09:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2041: train loss 0.41961. lr 4.305405e-04:  71%|███████▏  | 2042/2863 [24:38<09:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2042: train loss 0.41668. lr 4.303922e-04:  71%|███████▏  | 2042/2863 [24:38<09:27,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2042: train loss 0.41668. lr 4.303922e-04:  71%|███████▏  | 2043/2863 [24:38<09:25,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2043: train loss 0.41933. lr 4.302439e-04:  71%|███████▏  | 2043/2863 [24:39<09:25,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2043: train loss 0.41933. lr 4.302439e-04:  71%|███████▏  | 2044/2863 [24:39<09:25,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2044: train loss 0.41165. lr 4.300956e-04:  71%|███████▏  | 2044/2863 [24:40<09:25,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2044: train loss 0.41165. lr 4.300956e-04:  71%|███████▏  | 2045/2863 [24:40<09:25,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2045: train loss 0.41911. lr 4.299472e-04:  71%|███████▏  | 2045/2863 [24:41<09:25,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2045: train loss 0.41911. lr 4.299472e-04:  71%|███████▏  | 2046/2863 [24:41<09:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2046: train loss 0.42779. lr 4.297988e-04:  71%|███████▏  | 2046/2863 [24:41<09:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2046: train loss 0.42779. lr 4.297988e-04:  71%|███████▏  | 2047/2863 [24:41<09:30,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2047: train loss 0.42298. lr 4.296503e-04:  71%|███████▏  | 2047/2863 [24:42<09:30,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2047: train loss 0.42298. lr 4.296503e-04:  72%|███████▏  | 2048/2863 [24:42<09:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2048: train loss 0.41859. lr 4.295018e-04:  72%|███████▏  | 2048/2863 [24:43<09:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2048: train loss 0.41859. lr 4.295018e-04:  72%|███████▏  | 2049/2863 [24:43<09:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2049: train loss 0.42110. lr 4.293533e-04:  72%|███████▏  | 2049/2863 [24:43<09:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2049: train loss 0.42110. lr 4.293533e-04:  72%|███████▏  | 2050/2863 [24:43<09:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2050: train loss 0.40977. lr 4.292047e-04:  72%|███████▏  | 2050/2863 [24:44<09:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2050: train loss 0.40977. lr 4.292047e-04:  72%|███████▏  | 2051/2863 [24:44<09:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2051: train loss 0.41007. lr 4.290561e-04:  72%|███████▏  | 2051/2863 [24:45<09:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2051: train loss 0.41007. lr 4.290561e-04:  72%|███████▏  | 2052/2863 [24:45<09:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2052: train loss 0.41088. lr 4.289075e-04:  72%|███████▏  | 2052/2863 [24:45<09:23,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2052: train loss 0.41088. lr 4.289075e-04:  72%|███████▏  | 2053/2863 [24:45<09:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2053: train loss 0.43818. lr 4.287588e-04:  72%|███████▏  | 2053/2863 [24:46<09:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2053: train loss 0.43818. lr 4.287588e-04:  72%|███████▏  | 2054/2863 [24:46<09:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2054: train loss 0.40324. lr 4.286100e-04:  72%|███████▏  | 2054/2863 [24:47<09:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2054: train loss 0.40324. lr 4.286100e-04:  72%|███████▏  | 2055/2863 [24:47<09:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2055: train loss 0.41112. lr 4.284613e-04:  72%|███████▏  | 2055/2863 [24:47<09:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2055: train loss 0.41112. lr 4.284613e-04:  72%|███████▏  | 2056/2863 [24:47<09:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2056: train loss 0.41823. lr 4.283125e-04:  72%|███████▏  | 2056/2863 [24:48<09:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2056: train loss 0.41823. lr 4.283125e-04:  72%|███████▏  | 2057/2863 [24:48<09:17,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2057: train loss 0.40279. lr 4.281636e-04:  72%|███████▏  | 2057/2863 [24:49<09:17,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2057: train loss 0.40279. lr 4.281636e-04:  72%|███████▏  | 2058/2863 [24:49<09:42,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2058: train loss 0.41941. lr 4.280147e-04:  72%|███████▏  | 2058/2863 [24:50<09:42,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2058: train loss 0.41941. lr 4.280147e-04:  72%|███████▏  | 2059/2863 [24:50<09:35,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2059: train loss 0.41009. lr 4.278658e-04:  72%|███████▏  | 2059/2863 [24:50<09:35,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2059: train loss 0.41009. lr 4.278658e-04:  72%|███████▏  | 2060/2863 [24:50<09:28,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2060: train loss 0.41552. lr 4.277168e-04:  72%|███████▏  | 2060/2863 [24:51<09:28,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2060: train loss 0.41552. lr 4.277168e-04:  72%|███████▏  | 2061/2863 [24:51<09:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2061: train loss 0.40851. lr 4.275678e-04:  72%|███████▏  | 2061/2863 [24:52<09:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2061: train loss 0.40851. lr 4.275678e-04:  72%|███████▏  | 2062/2863 [24:52<09:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2062: train loss 0.40552. lr 4.274188e-04:  72%|███████▏  | 2062/2863 [24:52<09:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2062: train loss 0.40552. lr 4.274188e-04:  72%|███████▏  | 2063/2863 [24:52<09:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2063: train loss 0.40667. lr 4.272697e-04:  72%|███████▏  | 2063/2863 [24:53<09:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2063: train loss 0.40667. lr 4.272697e-04:  72%|███████▏  | 2064/2863 [24:53<09:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2064: train loss 0.40723. lr 4.271206e-04:  72%|███████▏  | 2064/2863 [24:54<09:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2064: train loss 0.40723. lr 4.271206e-04:  72%|███████▏  | 2065/2863 [24:54<09:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2065: train loss 0.41030. lr 4.269715e-04:  72%|███████▏  | 2065/2863 [24:55<09:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2065: train loss 0.41030. lr 4.269715e-04:  72%|███████▏  | 2066/2863 [24:55<09:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2066: train loss 0.41909. lr 4.268223e-04:  72%|███████▏  | 2066/2863 [24:55<09:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2066: train loss 0.41909. lr 4.268223e-04:  72%|███████▏  | 2067/2863 [24:55<09:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2067: train loss 0.40114. lr 4.266730e-04:  72%|███████▏  | 2067/2863 [24:56<09:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2067: train loss 0.40114. lr 4.266730e-04:  72%|███████▏  | 2068/2863 [24:56<09:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2068: train loss 0.40505. lr 4.265238e-04:  72%|███████▏  | 2068/2863 [24:57<09:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2068: train loss 0.40505. lr 4.265238e-04:  72%|███████▏  | 2069/2863 [24:57<09:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2069: train loss 0.42197. lr 4.263745e-04:  72%|███████▏  | 2069/2863 [24:57<09:13,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2069: train loss 0.42197. lr 4.263745e-04:  72%|███████▏  | 2070/2863 [24:57<09:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2070: train loss 0.39842. lr 4.262251e-04:  72%|███████▏  | 2070/2863 [24:58<09:10,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2070: train loss 0.39842. lr 4.262251e-04:  72%|███████▏  | 2071/2863 [24:58<09:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2071: train loss 0.40927. lr 4.260757e-04:  72%|███████▏  | 2071/2863 [24:59<09:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2071: train loss 0.40927. lr 4.260757e-04:  72%|███████▏  | 2072/2863 [24:59<09:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2072: train loss 0.41595. lr 4.259263e-04:  72%|███████▏  | 2072/2863 [24:59<09:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2072: train loss 0.41595. lr 4.259263e-04:  72%|███████▏  | 2073/2863 [24:59<09:12,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2073: train loss 0.41237. lr 4.257769e-04:  72%|███████▏  | 2073/2863 [25:00<09:12,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2073: train loss 0.41237. lr 4.257769e-04:  72%|███████▏  | 2074/2863 [25:00<09:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2074: train loss 0.40860. lr 4.256274e-04:  72%|███████▏  | 2074/2863 [25:01<09:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2074: train loss 0.40860. lr 4.256274e-04:  72%|███████▏  | 2075/2863 [25:01<09:07,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2075: train loss 0.40792. lr 4.254778e-04:  72%|███████▏  | 2075/2863 [25:02<09:07,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2075: train loss 0.40792. lr 4.254778e-04:  73%|███████▎  | 2076/2863 [25:02<09:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2076: train loss 0.40094. lr 4.253283e-04:  73%|███████▎  | 2076/2863 [25:02<09:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2076: train loss 0.40094. lr 4.253283e-04:  73%|███████▎  | 2077/2863 [25:02<09:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2077: train loss 0.39097. lr 4.251786e-04:  73%|███████▎  | 2077/2863 [25:03<09:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2077: train loss 0.39097. lr 4.251786e-04:  73%|███████▎  | 2078/2863 [25:03<09:04,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2078: train loss 0.40312. lr 4.250290e-04:  73%|███████▎  | 2078/2863 [25:04<09:04,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2078: train loss 0.40312. lr 4.250290e-04:  73%|███████▎  | 2079/2863 [25:04<09:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2079: train loss 0.41344. lr 4.248793e-04:  73%|███████▎  | 2079/2863 [25:04<09:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2079: train loss 0.41344. lr 4.248793e-04:  73%|███████▎  | 2080/2863 [25:04<09:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2080: train loss 0.39226. lr 4.247296e-04:  73%|███████▎  | 2080/2863 [25:05<09:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2080: train loss 0.39226. lr 4.247296e-04:  73%|███████▎  | 2081/2863 [25:05<09:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2081: train loss 0.39449. lr 4.245798e-04:  73%|███████▎  | 2081/2863 [25:06<09:09,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2081: train loss 0.39449. lr 4.245798e-04:  73%|███████▎  | 2082/2863 [25:06<09:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2082: train loss 0.40250. lr 4.244300e-04:  73%|███████▎  | 2082/2863 [25:06<09:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2082: train loss 0.40250. lr 4.244300e-04:  73%|███████▎  | 2083/2863 [25:06<09:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2083: train loss 0.39700. lr 4.242802e-04:  73%|███████▎  | 2083/2863 [25:07<09:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2083: train loss 0.39700. lr 4.242802e-04:  73%|███████▎  | 2084/2863 [25:07<09:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2084: train loss 0.40383. lr 4.241303e-04:  73%|███████▎  | 2084/2863 [25:08<09:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2084: train loss 0.40383. lr 4.241303e-04:  73%|███████▎  | 2085/2863 [25:08<08:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2085: train loss 0.40759. lr 4.239804e-04:  73%|███████▎  | 2085/2863 [25:09<08:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2085: train loss 0.40759. lr 4.239804e-04:  73%|███████▎  | 2086/2863 [25:09<09:25,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2086: train loss 0.39999. lr 4.238305e-04:  73%|███████▎  | 2086/2863 [25:09<09:25,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2086: train loss 0.39999. lr 4.238305e-04:  73%|███████▎  | 2087/2863 [25:09<09:18,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2087: train loss 0.40520. lr 4.236805e-04:  73%|███████▎  | 2087/2863 [25:10<09:18,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2087: train loss 0.40520. lr 4.236805e-04:  73%|███████▎  | 2088/2863 [25:10<09:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2088: train loss 0.40872. lr 4.235305e-04:  73%|███████▎  | 2088/2863 [25:11<09:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2088: train loss 0.40872. lr 4.235305e-04:  73%|███████▎  | 2089/2863 [25:11<09:45,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2089: train loss 0.41478. lr 4.233804e-04:  73%|███████▎  | 2089/2863 [25:12<09:45,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2089: train loss 0.41478. lr 4.233804e-04:  73%|███████▎  | 2090/2863 [25:12<09:35,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2090: train loss 0.40089. lr 4.232303e-04:  73%|███████▎  | 2090/2863 [25:12<09:35,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2090: train loss 0.40089. lr 4.232303e-04:  73%|███████▎  | 2091/2863 [25:12<09:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2091: train loss 0.39619. lr 4.230802e-04:  73%|███████▎  | 2091/2863 [25:13<09:21,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2091: train loss 0.39619. lr 4.230802e-04:  73%|███████▎  | 2092/2863 [25:13<09:19,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2092: train loss 0.41580. lr 4.229300e-04:  73%|███████▎  | 2092/2863 [25:14<09:19,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2092: train loss 0.41580. lr 4.229300e-04:  73%|███████▎  | 2093/2863 [25:14<09:17,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2093: train loss 0.40608. lr 4.227798e-04:  73%|███████▎  | 2093/2863 [25:14<09:17,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2093: train loss 0.40608. lr 4.227798e-04:  73%|███████▎  | 2094/2863 [25:14<09:13,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2094: train loss 0.40093. lr 4.226295e-04:  73%|███████▎  | 2094/2863 [25:15<09:13,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2094: train loss 0.40093. lr 4.226295e-04:  73%|███████▎  | 2095/2863 [25:15<09:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2095: train loss 0.39950. lr 4.224793e-04:  73%|███████▎  | 2095/2863 [25:16<09:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2095: train loss 0.39950. lr 4.224793e-04:  73%|███████▎  | 2096/2863 [25:16<09:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2096: train loss 0.40569. lr 4.223289e-04:  73%|███████▎  | 2096/2863 [25:17<09:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2096: train loss 0.40569. lr 4.223289e-04:  73%|███████▎  | 2097/2863 [25:17<09:05,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2097: train loss 0.39295. lr 4.221786e-04:  73%|███████▎  | 2097/2863 [25:17<09:05,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2097: train loss 0.39295. lr 4.221786e-04:  73%|███████▎  | 2098/2863 [25:17<09:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2098: train loss 0.39688. lr 4.220282e-04:  73%|███████▎  | 2098/2863 [25:18<09:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2098: train loss 0.39688. lr 4.220282e-04:  73%|███████▎  | 2099/2863 [25:18<09:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2099: train loss 0.40667. lr 4.218778e-04:  73%|███████▎  | 2099/2863 [25:19<09:02,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2099: train loss 0.40667. lr 4.218778e-04:  73%|███████▎  | 2100/2863 [25:19<08:59,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2100: train loss 0.40818. lr 4.217273e-04:  73%|███████▎  | 2100/2863 [25:19<08:59,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2100: train loss 0.40818. lr 4.217273e-04:  73%|███████▎  | 2101/2863 [25:19<08:56,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2101: train loss 0.39952. lr 4.215768e-04:  73%|███████▎  | 2101/2863 [25:20<08:56,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2101: train loss 0.39952. lr 4.215768e-04:  73%|███████▎  | 2102/2863 [25:20<08:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2102: train loss 0.40760. lr 4.214263e-04:  73%|███████▎  | 2102/2863 [25:21<08:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2102: train loss 0.40760. lr 4.214263e-04:  73%|███████▎  | 2103/2863 [25:21<08:52,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2103: train loss 0.39985. lr 4.212757e-04:  73%|███████▎  | 2103/2863 [25:21<08:52,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2103: train loss 0.39985. lr 4.212757e-04:  73%|███████▎  | 2104/2863 [25:21<08:52,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2104: train loss 0.40497. lr 4.211251e-04:  73%|███████▎  | 2104/2863 [25:22<08:52,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2104: train loss 0.40497. lr 4.211251e-04:  74%|███████▎  | 2105/2863 [25:22<08:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2105: train loss 0.39180. lr 4.209744e-04:  74%|███████▎  | 2105/2863 [25:23<08:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2105: train loss 0.39180. lr 4.209744e-04:  74%|███████▎  | 2106/2863 [25:23<08:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2106: train loss 0.40720. lr 4.208237e-04:  74%|███████▎  | 2106/2863 [25:24<08:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2106: train loss 0.40720. lr 4.208237e-04:  74%|███████▎  | 2107/2863 [25:24<08:45,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2107: train loss 0.41453. lr 4.206730e-04:  74%|███████▎  | 2107/2863 [25:24<08:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2107: train loss 0.41453. lr 4.206730e-04:  74%|███████▎  | 2108/2863 [25:24<08:44,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2108: train loss 0.39743. lr 4.205223e-04:  74%|███████▎  | 2108/2863 [25:25<08:44,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2108: train loss 0.39743. lr 4.205223e-04:  74%|███████▎  | 2109/2863 [25:25<08:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2109: train loss 0.39567. lr 4.203715e-04:  74%|███████▎  | 2109/2863 [25:26<08:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2109: train loss 0.39567. lr 4.203715e-04:  74%|███████▎  | 2110/2863 [25:26<08:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2110: train loss 0.39856. lr 4.202206e-04:  74%|███████▎  | 2110/2863 [25:26<08:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2110: train loss 0.39856. lr 4.202206e-04:  74%|███████▎  | 2111/2863 [25:26<08:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2111: train loss 0.40337. lr 4.200698e-04:  74%|███████▎  | 2111/2863 [25:27<08:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2111: train loss 0.40337. lr 4.200698e-04:  74%|███████▍  | 2112/2863 [25:27<08:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2112: train loss 0.40157. lr 4.199189e-04:  74%|███████▍  | 2112/2863 [25:28<08:39,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2112: train loss 0.40157. lr 4.199189e-04:  74%|███████▍  | 2113/2863 [25:28<08:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2113: train loss 0.39925. lr 4.197679e-04:  74%|███████▍  | 2113/2863 [25:28<08:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2113: train loss 0.39925. lr 4.197679e-04:  74%|███████▍  | 2114/2863 [25:29<09:04,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2114: train loss 0.40116. lr 4.196170e-04:  74%|███████▍  | 2114/2863 [25:29<09:04,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2114: train loss 0.40116. lr 4.196170e-04:  74%|███████▍  | 2115/2863 [25:29<08:55,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2115: train loss 0.40282. lr 4.194660e-04:  74%|███████▍  | 2115/2863 [25:30<08:55,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2115: train loss 0.40282. lr 4.194660e-04:  74%|███████▍  | 2116/2863 [25:30<08:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2116: train loss 0.39168. lr 4.193149e-04:  74%|███████▍  | 2116/2863 [25:31<08:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2116: train loss 0.39168. lr 4.193149e-04:  74%|███████▍  | 2117/2863 [25:31<08:45,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2117: train loss 0.40220. lr 4.191638e-04:  74%|███████▍  | 2117/2863 [25:31<08:45,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2117: train loss 0.40220. lr 4.191638e-04:  74%|███████▍  | 2118/2863 [25:31<08:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2118: train loss 0.39057. lr 4.190127e-04:  74%|███████▍  | 2118/2863 [25:32<08:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2118: train loss 0.39057. lr 4.190127e-04:  74%|███████▍  | 2119/2863 [25:32<08:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2119: train loss 0.38208. lr 4.188615e-04:  74%|███████▍  | 2119/2863 [25:33<08:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2119: train loss 0.38208. lr 4.188615e-04:  74%|███████▍  | 2120/2863 [25:33<08:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2120: train loss 0.40710. lr 4.187104e-04:  74%|███████▍  | 2120/2863 [25:33<08:34,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2120: train loss 0.40710. lr 4.187104e-04:  74%|███████▍  | 2121/2863 [25:33<08:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2121: train loss 0.40967. lr 4.185591e-04:  74%|███████▍  | 2121/2863 [25:34<08:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2121: train loss 0.40967. lr 4.185591e-04:  74%|███████▍  | 2122/2863 [25:34<08:32,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2122: train loss 0.37201. lr 4.184079e-04:  74%|███████▍  | 2122/2863 [25:35<08:32,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2122: train loss 0.37201. lr 4.184079e-04:  74%|███████▍  | 2123/2863 [25:35<08:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2123: train loss 0.40110. lr 4.182566e-04:  74%|███████▍  | 2123/2863 [25:35<08:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2123: train loss 0.40110. lr 4.182566e-04:  74%|███████▍  | 2124/2863 [25:35<08:39,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2124: train loss 0.40594. lr 4.181052e-04:  74%|███████▍  | 2124/2863 [25:36<08:39,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2124: train loss 0.40594. lr 4.181052e-04:  74%|███████▍  | 2125/2863 [25:36<08:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2125: train loss 0.39081. lr 4.179539e-04:  74%|███████▍  | 2125/2863 [25:37<08:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2125: train loss 0.39081. lr 4.179539e-04:  74%|███████▍  | 2126/2863 [25:37<08:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2126: train loss 0.39334. lr 4.178025e-04:  74%|███████▍  | 2126/2863 [25:38<08:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2126: train loss 0.39334. lr 4.178025e-04:  74%|███████▍  | 2127/2863 [25:38<08:39,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2127: train loss 0.38395. lr 4.176510e-04:  74%|███████▍  | 2127/2863 [25:38<08:39,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2127: train loss 0.38395. lr 4.176510e-04:  74%|███████▍  | 2128/2863 [25:38<08:51,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2128: train loss 0.39438. lr 4.174996e-04:  74%|███████▍  | 2128/2863 [25:39<08:51,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2128: train loss 0.39438. lr 4.174996e-04:  74%|███████▍  | 2129/2863 [25:39<08:48,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2129: train loss 0.38069. lr 4.173480e-04:  74%|███████▍  | 2129/2863 [25:40<08:48,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2129: train loss 0.38069. lr 4.173480e-04:  74%|███████▍  | 2130/2863 [25:40<08:40,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2130: train loss 0.37664. lr 4.171965e-04:  74%|███████▍  | 2130/2863 [25:40<08:40,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2130: train loss 0.37664. lr 4.171965e-04:  74%|███████▍  | 2131/2863 [25:40<08:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2131: train loss 0.38415. lr 4.170449e-04:  74%|███████▍  | 2131/2863 [25:41<08:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2131: train loss 0.38415. lr 4.170449e-04:  74%|███████▍  | 2132/2863 [25:41<08:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2132: train loss 0.38829. lr 4.168933e-04:  74%|███████▍  | 2132/2863 [25:42<08:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2132: train loss 0.38829. lr 4.168933e-04:  75%|███████▍  | 2133/2863 [25:42<08:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2133: train loss 0.40135. lr 4.167417e-04:  75%|███████▍  | 2133/2863 [25:42<08:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2133: train loss 0.40135. lr 4.167417e-04:  75%|███████▍  | 2134/2863 [25:42<08:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2134: train loss 0.39612. lr 4.165900e-04:  75%|███████▍  | 2134/2863 [25:43<08:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2134: train loss 0.39612. lr 4.165900e-04:  75%|███████▍  | 2135/2863 [25:43<08:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2135: train loss 0.38394. lr 4.164382e-04:  75%|███████▍  | 2135/2863 [25:44<08:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2135: train loss 0.38394. lr 4.164382e-04:  75%|███████▍  | 2136/2863 [25:44<08:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2136: train loss 0.39014. lr 4.162865e-04:  75%|███████▍  | 2136/2863 [25:45<08:26,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2136: train loss 0.39014. lr 4.162865e-04:  75%|███████▍  | 2137/2863 [25:45<08:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2137: train loss 0.39707. lr 4.161347e-04:  75%|███████▍  | 2137/2863 [25:45<08:22,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2137: train loss 0.39707. lr 4.161347e-04:  75%|███████▍  | 2138/2863 [25:45<08:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2138: train loss 0.39079. lr 4.159829e-04:  75%|███████▍  | 2138/2863 [25:46<08:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2138: train loss 0.39079. lr 4.159829e-04:  75%|███████▍  | 2139/2863 [25:46<08:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2139: train loss 0.38916. lr 4.158310e-04:  75%|███████▍  | 2139/2863 [25:47<08:20,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2139: train loss 0.38916. lr 4.158310e-04:  75%|███████▍  | 2140/2863 [25:47<08:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2140: train loss 0.39185. lr 4.156791e-04:  75%|███████▍  | 2140/2863 [25:47<08:19,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2140: train loss 0.39185. lr 4.156791e-04:  75%|███████▍  | 2141/2863 [25:47<08:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2141: train loss 0.39324. lr 4.155272e-04:  75%|███████▍  | 2141/2863 [25:48<08:18,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2141: train loss 0.39324. lr 4.155272e-04:  75%|███████▍  | 2142/2863 [25:48<08:51,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2142: train loss 0.38171. lr 4.153752e-04:  75%|███████▍  | 2142/2863 [25:49<08:51,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2142: train loss 0.38171. lr 4.153752e-04:  75%|███████▍  | 2143/2863 [25:49<08:41,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2143: train loss 0.38391. lr 4.152232e-04:  75%|███████▍  | 2143/2863 [25:50<08:41,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2143: train loss 0.38391. lr 4.152232e-04:  75%|███████▍  | 2144/2863 [25:50<08:32,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2144: train loss 0.39581. lr 4.150712e-04:  75%|███████▍  | 2144/2863 [25:50<08:32,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2144: train loss 0.39581. lr 4.150712e-04:  75%|███████▍  | 2145/2863 [25:50<08:27,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2145: train loss 0.36894. lr 4.149191e-04:  75%|███████▍  | 2145/2863 [25:51<08:27,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2145: train loss 0.36894. lr 4.149191e-04:  75%|███████▍  | 2146/2863 [25:51<08:50,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2146: train loss 0.39173. lr 4.147670e-04:  75%|███████▍  | 2146/2863 [25:52<08:50,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2146: train loss 0.39173. lr 4.147670e-04:  75%|███████▍  | 2147/2863 [25:52<09:04,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2147: train loss 0.38199. lr 4.146149e-04:  75%|███████▍  | 2147/2863 [25:53<09:04,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2147: train loss 0.38199. lr 4.146149e-04:  75%|███████▌  | 2148/2863 [25:53<09:03,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2148: train loss 0.38459. lr 4.144627e-04:  75%|███████▌  | 2148/2863 [25:53<09:03,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2148: train loss 0.38459. lr 4.144627e-04:  75%|███████▌  | 2149/2863 [25:53<09:00,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2149: train loss 0.37629. lr 4.143105e-04:  75%|███████▌  | 2149/2863 [25:54<09:00,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2149: train loss 0.37629. lr 4.143105e-04:  75%|███████▌  | 2150/2863 [25:54<08:53,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2150: train loss 0.39918. lr 4.141582e-04:  75%|███████▌  | 2150/2863 [25:55<08:53,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2150: train loss 0.39918. lr 4.141582e-04:  75%|███████▌  | 2151/2863 [25:55<08:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2151: train loss 0.39411. lr 4.140060e-04:  75%|███████▌  | 2151/2863 [25:55<08:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2151: train loss 0.39411. lr 4.140060e-04:  75%|███████▌  | 2152/2863 [25:55<08:30,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2152: train loss 0.37824. lr 4.138536e-04:  75%|███████▌  | 2152/2863 [25:56<08:30,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2152: train loss 0.37824. lr 4.138536e-04:  75%|███████▌  | 2153/2863 [25:56<08:23,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2153: train loss 0.39259. lr 4.137013e-04:  75%|███████▌  | 2153/2863 [25:57<08:23,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2153: train loss 0.39259. lr 4.137013e-04:  75%|███████▌  | 2154/2863 [25:57<08:16,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2154: train loss 0.38309. lr 4.135489e-04:  75%|███████▌  | 2154/2863 [25:58<08:16,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2154: train loss 0.38309. lr 4.135489e-04:  75%|███████▌  | 2155/2863 [25:58<08:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2155: train loss 0.38252. lr 4.133965e-04:  75%|███████▌  | 2155/2863 [25:58<08:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2155: train loss 0.38252. lr 4.133965e-04:  75%|███████▌  | 2156/2863 [25:58<08:11,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2156: train loss 0.38597. lr 4.132441e-04:  75%|███████▌  | 2156/2863 [25:59<08:11,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2156: train loss 0.38597. lr 4.132441e-04:  75%|███████▌  | 2157/2863 [25:59<08:09,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2157: train loss 0.39279. lr 4.130916e-04:  75%|███████▌  | 2157/2863 [26:00<08:09,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2157: train loss 0.39279. lr 4.130916e-04:  75%|███████▌  | 2158/2863 [26:00<08:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2158: train loss 0.39228. lr 4.129391e-04:  75%|███████▌  | 2158/2863 [26:00<08:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2158: train loss 0.39228. lr 4.129391e-04:  75%|███████▌  | 2159/2863 [26:00<08:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2159: train loss 0.38489. lr 4.127865e-04:  75%|███████▌  | 2159/2863 [26:01<08:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2159: train loss 0.38489. lr 4.127865e-04:  75%|███████▌  | 2160/2863 [26:01<08:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2160: train loss 0.38969. lr 4.126339e-04:  75%|███████▌  | 2160/2863 [26:02<08:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2160: train loss 0.38969. lr 4.126339e-04:  75%|███████▌  | 2161/2863 [26:02<08:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2161: train loss 0.39575. lr 4.124813e-04:  75%|███████▌  | 2161/2863 [26:02<08:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2161: train loss 0.39575. lr 4.124813e-04:  76%|███████▌  | 2162/2863 [26:02<08:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2162: train loss 0.38264. lr 4.123287e-04:  76%|███████▌  | 2162/2863 [26:03<08:10,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2162: train loss 0.38264. lr 4.123287e-04:  76%|███████▌  | 2163/2863 [26:03<08:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2163: train loss 0.38764. lr 4.121760e-04:  76%|███████▌  | 2163/2863 [26:04<08:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2163: train loss 0.38764. lr 4.121760e-04:  76%|███████▌  | 2164/2863 [26:04<08:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2164: train loss 0.38193. lr 4.120232e-04:  76%|███████▌  | 2164/2863 [26:04<08:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2164: train loss 0.38193. lr 4.120232e-04:  76%|███████▌  | 2165/2863 [26:05<08:02,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2165: train loss 0.38387. lr 4.118705e-04:  76%|███████▌  | 2165/2863 [26:05<08:02,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2165: train loss 0.38387. lr 4.118705e-04:  76%|███████▌  | 2166/2863 [26:05<08:04,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2166: train loss 0.37725. lr 4.117177e-04:  76%|███████▌  | 2166/2863 [26:06<08:04,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2166: train loss 0.37725. lr 4.117177e-04:  76%|███████▌  | 2167/2863 [26:06<08:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2167: train loss 0.39062. lr 4.115649e-04:  76%|███████▌  | 2167/2863 [26:07<08:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2167: train loss 0.39062. lr 4.115649e-04:  76%|███████▌  | 2168/2863 [26:07<08:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2168: train loss 0.38492. lr 4.114120e-04:  76%|███████▌  | 2168/2863 [26:07<08:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2168: train loss 0.38492. lr 4.114120e-04:  76%|███████▌  | 2169/2863 [26:07<08:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2169: train loss 0.38923. lr 4.112591e-04:  76%|███████▌  | 2169/2863 [26:08<08:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2169: train loss 0.38923. lr 4.112591e-04:  76%|███████▌  | 2170/2863 [26:08<08:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2170: train loss 0.38754. lr 4.111062e-04:  76%|███████▌  | 2170/2863 [26:09<08:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2170: train loss 0.38754. lr 4.111062e-04:  76%|███████▌  | 2171/2863 [26:09<08:15,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2171: train loss 0.39029. lr 4.109533e-04:  76%|███████▌  | 2171/2863 [26:09<08:15,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2171: train loss 0.39029. lr 4.109533e-04:  76%|███████▌  | 2172/2863 [26:09<08:09,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2172: train loss 0.37319. lr 4.108003e-04:  76%|███████▌  | 2172/2863 [26:10<08:09,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2172: train loss 0.37319. lr 4.108003e-04:  76%|███████▌  | 2173/2863 [26:10<08:04,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2173: train loss 0.37620. lr 4.106473e-04:  76%|███████▌  | 2173/2863 [26:11<08:04,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2173: train loss 0.37620. lr 4.106473e-04:  76%|███████▌  | 2174/2863 [26:11<08:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2174: train loss 0.38559. lr 4.104942e-04:  76%|███████▌  | 2174/2863 [26:12<08:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2174: train loss 0.38559. lr 4.104942e-04:  76%|███████▌  | 2175/2863 [26:12<07:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2175: train loss 0.38642. lr 4.103411e-04:  76%|███████▌  | 2175/2863 [26:12<07:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2175: train loss 0.38642. lr 4.103411e-04:  76%|███████▌  | 2176/2863 [26:12<08:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2176: train loss 0.37788. lr 4.101880e-04:  76%|███████▌  | 2176/2863 [26:13<08:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2176: train loss 0.37788. lr 4.101880e-04:  76%|███████▌  | 2177/2863 [26:13<08:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2177: train loss 0.38584. lr 4.100348e-04:  76%|███████▌  | 2177/2863 [26:14<08:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2177: train loss 0.38584. lr 4.100348e-04:  76%|███████▌  | 2178/2863 [26:14<08:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2178: train loss 0.38237. lr 4.098816e-04:  76%|███████▌  | 2178/2863 [26:14<08:12,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2178: train loss 0.38237. lr 4.098816e-04:  76%|███████▌  | 2179/2863 [26:14<08:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2179: train loss 0.37725. lr 4.097284e-04:  76%|███████▌  | 2179/2863 [26:15<08:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2179: train loss 0.37725. lr 4.097284e-04:  76%|███████▌  | 2180/2863 [26:15<08:08,  1.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2180: train loss 0.38893. lr 4.095752e-04:  76%|███████▌  | 2180/2863 [26:16<08:08,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2180: train loss 0.38893. lr 4.095752e-04:  76%|███████▌  | 2181/2863 [26:16<08:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2181: train loss 0.37667. lr 4.094219e-04:  76%|███████▌  | 2181/2863 [26:17<08:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2181: train loss 0.37667. lr 4.094219e-04:  76%|███████▌  | 2182/2863 [26:17<08:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2182: train loss 0.38661. lr 4.092686e-04:  76%|███████▌  | 2182/2863 [26:17<08:03,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2182: train loss 0.38661. lr 4.092686e-04:  76%|███████▌  | 2183/2863 [26:17<08:01,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2183: train loss 0.37772. lr 4.091152e-04:  76%|███████▌  | 2183/2863 [26:18<08:01,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2183: train loss 0.37772. lr 4.091152e-04:  76%|███████▋  | 2184/2863 [26:18<07:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2184: train loss 0.38828. lr 4.089618e-04:  76%|███████▋  | 2184/2863 [26:19<07:55,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2184: train loss 0.38828. lr 4.089618e-04:  76%|███████▋  | 2185/2863 [26:19<07:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2185: train loss 0.38062. lr 4.088084e-04:  76%|███████▋  | 2185/2863 [26:19<07:52,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2185: train loss 0.38062. lr 4.088084e-04:  76%|███████▋  | 2186/2863 [26:19<07:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2186: train loss 0.37611. lr 4.086549e-04:  76%|███████▋  | 2186/2863 [26:20<07:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2186: train loss 0.37611. lr 4.086549e-04:  76%|███████▋  | 2187/2863 [26:20<07:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2187: train loss 0.37299. lr 4.085015e-04:  76%|███████▋  | 2187/2863 [26:21<07:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2187: train loss 0.37299. lr 4.085015e-04:  76%|███████▋  | 2188/2863 [26:21<07:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2188: train loss 0.36666. lr 4.083479e-04:  76%|███████▋  | 2188/2863 [26:21<07:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2188: train loss 0.36666. lr 4.083479e-04:  76%|███████▋  | 2189/2863 [26:21<07:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2189: train loss 0.39172. lr 4.081944e-04:  76%|███████▋  | 2189/2863 [26:22<07:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2189: train loss 0.39172. lr 4.081944e-04:  76%|███████▋  | 2190/2863 [26:22<07:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2190: train loss 0.39121. lr 4.080408e-04:  76%|███████▋  | 2190/2863 [26:23<07:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2190: train loss 0.39121. lr 4.080408e-04:  77%|███████▋  | 2191/2863 [26:23<07:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2191: train loss 0.37866. lr 4.078872e-04:  77%|███████▋  | 2191/2863 [26:23<07:43,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2191: train loss 0.37866. lr 4.078872e-04:  77%|███████▋  | 2192/2863 [26:23<07:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2192: train loss 0.37880. lr 4.077336e-04:  77%|███████▋  | 2192/2863 [26:24<07:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2192: train loss 0.37880. lr 4.077336e-04:  77%|███████▋  | 2193/2863 [26:24<07:40,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2193: train loss 0.37654. lr 4.075799e-04:  77%|███████▋  | 2193/2863 [26:25<07:40,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2193: train loss 0.37654. lr 4.075799e-04:  77%|███████▋  | 2194/2863 [26:25<07:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2194: train loss 0.35837. lr 4.074262e-04:  77%|███████▋  | 2194/2863 [26:26<07:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2194: train loss 0.35837. lr 4.074262e-04:  77%|███████▋  | 2195/2863 [26:26<07:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2195: train loss 0.37286. lr 4.072724e-04:  77%|███████▋  | 2195/2863 [26:26<07:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2195: train loss 0.37286. lr 4.072724e-04:  77%|███████▋  | 2196/2863 [26:26<07:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2196: train loss 0.36925. lr 4.071186e-04:  77%|███████▋  | 2196/2863 [26:27<07:42,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2196: train loss 0.36925. lr 4.071186e-04:  77%|███████▋  | 2197/2863 [26:27<07:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2197: train loss 0.39192. lr 4.069648e-04:  77%|███████▋  | 2197/2863 [26:28<07:41,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2197: train loss 0.39192. lr 4.069648e-04:  77%|███████▋  | 2198/2863 [26:28<08:02,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2198: train loss 0.38185. lr 4.068110e-04:  77%|███████▋  | 2198/2863 [26:28<08:02,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2198: train loss 0.38185. lr 4.068110e-04:  77%|███████▋  | 2199/2863 [26:28<07:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2199: train loss 0.39003. lr 4.066571e-04:  77%|███████▋  | 2199/2863 [26:29<07:54,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2199: train loss 0.39003. lr 4.066571e-04:  77%|███████▋  | 2200/2863 [26:29<07:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2200: train loss 0.36884. lr 4.065032e-04:  77%|███████▋  | 2200/2863 [26:30<07:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2200: train loss 0.36884. lr 4.065032e-04:  77%|███████▋  | 2201/2863 [26:30<07:44,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2201: train loss 0.37836. lr 4.063493e-04:  77%|███████▋  | 2201/2863 [26:30<07:44,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2201: train loss 0.37836. lr 4.063493e-04:  77%|███████▋  | 2202/2863 [26:31<07:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2202: train loss 0.38043. lr 4.061953e-04:  77%|███████▋  | 2202/2863 [26:31<07:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2202: train loss 0.38043. lr 4.061953e-04:  77%|███████▋  | 2203/2863 [26:31<07:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2203: train loss 0.38215. lr 4.060413e-04:  77%|███████▋  | 2203/2863 [26:32<07:39,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2203: train loss 0.38215. lr 4.060413e-04:  77%|███████▋  | 2204/2863 [26:32<07:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2204: train loss 0.36721. lr 4.058873e-04:  77%|███████▋  | 2204/2863 [26:33<07:38,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2204: train loss 0.36721. lr 4.058873e-04:  77%|███████▋  | 2205/2863 [26:33<07:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2205: train loss 0.37342. lr 4.057332e-04:  77%|███████▋  | 2205/2863 [26:33<07:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2205: train loss 0.37342. lr 4.057332e-04:  77%|███████▋  | 2206/2863 [26:33<07:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2206: train loss 0.38462. lr 4.055791e-04:  77%|███████▋  | 2206/2863 [26:34<07:37,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2206: train loss 0.38462. lr 4.055791e-04:  77%|███████▋  | 2207/2863 [26:34<07:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2207: train loss 0.37552. lr 4.054250e-04:  77%|███████▋  | 2207/2863 [26:35<07:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2207: train loss 0.37552. lr 4.054250e-04:  77%|███████▋  | 2208/2863 [26:35<07:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2208: train loss 0.37397. lr 4.052708e-04:  77%|███████▋  | 2208/2863 [26:35<07:37,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2208: train loss 0.37397. lr 4.052708e-04:  77%|███████▋  | 2209/2863 [26:35<07:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2209: train loss 0.38910. lr 4.051166e-04:  77%|███████▋  | 2209/2863 [26:36<07:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2209: train loss 0.38910. lr 4.051166e-04:  77%|███████▋  | 2210/2863 [26:36<07:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2210: train loss 0.37407. lr 4.049624e-04:  77%|███████▋  | 2210/2863 [26:37<07:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2210: train loss 0.37407. lr 4.049624e-04:  77%|███████▋  | 2211/2863 [26:37<07:30,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2211: train loss 0.37730. lr 4.048081e-04:  77%|███████▋  | 2211/2863 [26:37<07:30,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2211: train loss 0.37730. lr 4.048081e-04:  77%|███████▋  | 2212/2863 [26:37<07:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2212: train loss 0.36862. lr 4.046538e-04:  77%|███████▋  | 2212/2863 [26:38<07:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2212: train loss 0.36862. lr 4.046538e-04:  77%|███████▋  | 2213/2863 [26:38<07:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2213: train loss 0.38003. lr 4.044995e-04:  77%|███████▋  | 2213/2863 [26:39<07:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2213: train loss 0.38003. lr 4.044995e-04:  77%|███████▋  | 2214/2863 [26:39<07:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2214: train loss 0.36700. lr 4.043452e-04:  77%|███████▋  | 2214/2863 [26:40<07:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2214: train loss 0.36700. lr 4.043452e-04:  77%|███████▋  | 2215/2863 [26:40<07:28,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2215: train loss 0.37864. lr 4.041908e-04:  77%|███████▋  | 2215/2863 [26:40<07:28,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2215: train loss 0.37864. lr 4.041908e-04:  77%|███████▋  | 2216/2863 [26:40<07:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2216: train loss 0.36500. lr 4.040364e-04:  77%|███████▋  | 2216/2863 [26:41<07:29,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2216: train loss 0.36500. lr 4.040364e-04:  77%|███████▋  | 2217/2863 [26:41<07:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2217: train loss 0.37717. lr 4.038819e-04:  77%|███████▋  | 2217/2863 [26:42<07:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2217: train loss 0.37717. lr 4.038819e-04:  77%|███████▋  | 2218/2863 [26:42<07:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2218: train loss 0.37468. lr 4.037275e-04:  77%|███████▋  | 2218/2863 [26:42<07:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2218: train loss 0.37468. lr 4.037275e-04:  78%|███████▊  | 2219/2863 [26:42<07:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2219: train loss 0.36163. lr 4.035730e-04:  78%|███████▊  | 2219/2863 [26:43<07:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2219: train loss 0.36163. lr 4.035730e-04:  78%|███████▊  | 2220/2863 [26:43<07:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2220: train loss 0.37663. lr 4.034184e-04:  78%|███████▊  | 2220/2863 [26:44<07:28,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2220: train loss 0.37663. lr 4.034184e-04:  78%|███████▊  | 2221/2863 [26:44<07:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2221: train loss 0.37668. lr 4.032638e-04:  78%|███████▊  | 2221/2863 [26:44<07:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2221: train loss 0.37668. lr 4.032638e-04:  78%|███████▊  | 2222/2863 [26:44<07:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2222: train loss 0.36802. lr 4.031092e-04:  78%|███████▊  | 2222/2863 [26:45<07:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2222: train loss 0.36802. lr 4.031092e-04:  78%|███████▊  | 2223/2863 [26:45<07:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2223: train loss 0.37834. lr 4.029546e-04:  78%|███████▊  | 2223/2863 [26:46<07:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2223: train loss 0.37834. lr 4.029546e-04:  78%|███████▊  | 2224/2863 [26:46<07:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2224: train loss 0.37704. lr 4.028000e-04:  78%|███████▊  | 2224/2863 [26:46<07:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2224: train loss 0.37704. lr 4.028000e-04:  78%|███████▊  | 2225/2863 [26:46<07:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2225: train loss 0.37310. lr 4.026453e-04:  78%|███████▊  | 2225/2863 [26:47<07:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2225: train loss 0.37310. lr 4.026453e-04:  78%|███████▊  | 2226/2863 [26:47<07:47,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2226: train loss 0.36294. lr 4.024905e-04:  78%|███████▊  | 2226/2863 [26:48<07:47,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2226: train loss 0.36294. lr 4.024905e-04:  78%|███████▊  | 2227/2863 [26:48<07:40,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2227: train loss 0.37519. lr 4.023358e-04:  78%|███████▊  | 2227/2863 [26:49<07:40,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2227: train loss 0.37519. lr 4.023358e-04:  78%|███████▊  | 2228/2863 [26:49<07:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2228: train loss 0.37064. lr 4.021810e-04:  78%|███████▊  | 2228/2863 [26:49<07:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2228: train loss 0.37064. lr 4.021810e-04:  78%|███████▊  | 2229/2863 [26:49<07:28,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2229: train loss 0.36984. lr 4.020262e-04:  78%|███████▊  | 2229/2863 [26:50<07:28,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2229: train loss 0.36984. lr 4.020262e-04:  78%|███████▊  | 2230/2863 [26:50<07:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2230: train loss 0.36963. lr 4.018713e-04:  78%|███████▊  | 2230/2863 [26:51<07:22,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2230: train loss 0.36963. lr 4.018713e-04:  78%|███████▊  | 2231/2863 [26:51<07:32,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2231: train loss 0.35554. lr 4.017164e-04:  78%|███████▊  | 2231/2863 [26:52<07:32,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2231: train loss 0.35554. lr 4.017164e-04:  78%|███████▊  | 2232/2863 [26:52<07:30,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2232: train loss 0.36758. lr 4.015615e-04:  78%|███████▊  | 2232/2863 [26:52<07:30,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2232: train loss 0.36758. lr 4.015615e-04:  78%|███████▊  | 2233/2863 [26:52<07:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2233: train loss 0.38216. lr 4.014066e-04:  78%|███████▊  | 2233/2863 [26:53<07:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2233: train loss 0.38216. lr 4.014066e-04:  78%|███████▊  | 2234/2863 [26:53<07:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2234: train loss 0.37321. lr 4.012516e-04:  78%|███████▊  | 2234/2863 [26:54<07:20,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2234: train loss 0.37321. lr 4.012516e-04:  78%|███████▊  | 2235/2863 [26:54<07:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2235: train loss 0.38019. lr 4.010966e-04:  78%|███████▊  | 2235/2863 [26:54<07:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2235: train loss 0.38019. lr 4.010966e-04:  78%|███████▊  | 2236/2863 [26:54<07:16,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2236: train loss 0.36460. lr 4.009416e-04:  78%|███████▊  | 2236/2863 [26:55<07:16,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2236: train loss 0.36460. lr 4.009416e-04:  78%|███████▊  | 2237/2863 [26:55<07:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2237: train loss 0.37939. lr 4.007865e-04:  78%|███████▊  | 2237/2863 [26:56<07:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2237: train loss 0.37939. lr 4.007865e-04:  78%|███████▊  | 2238/2863 [26:56<07:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2238: train loss 0.36698. lr 4.006314e-04:  78%|███████▊  | 2238/2863 [26:56<07:24,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2238: train loss 0.36698. lr 4.006314e-04:  78%|███████▊  | 2239/2863 [26:56<07:22,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2239: train loss 0.36577. lr 4.004763e-04:  78%|███████▊  | 2239/2863 [26:57<07:22,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2239: train loss 0.36577. lr 4.004763e-04:  78%|███████▊  | 2240/2863 [26:57<07:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2240: train loss 0.36459. lr 4.003212e-04:  78%|███████▊  | 2240/2863 [26:58<07:17,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2240: train loss 0.36459. lr 4.003212e-04:  78%|███████▊  | 2241/2863 [26:58<07:14,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2241: train loss 0.36913. lr 4.001660e-04:  78%|███████▊  | 2241/2863 [26:59<07:14,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2241: train loss 0.36913. lr 4.001660e-04:  78%|███████▊  | 2242/2863 [26:59<07:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2242: train loss 0.35769. lr 4.000108e-04:  78%|███████▊  | 2242/2863 [26:59<07:10,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2242: train loss 0.35769. lr 4.000108e-04:  78%|███████▊  | 2243/2863 [26:59<07:08,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2243: train loss 0.36944. lr 3.998555e-04:  78%|███████▊  | 2243/2863 [27:00<07:08,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2243: train loss 0.36944. lr 3.998555e-04:  78%|███████▊  | 2244/2863 [27:00<07:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2244: train loss 0.36728. lr 3.997003e-04:  78%|███████▊  | 2244/2863 [27:01<07:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2244: train loss 0.36728. lr 3.997003e-04:  78%|███████▊  | 2245/2863 [27:01<07:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2245: train loss 0.37472. lr 3.995450e-04:  78%|███████▊  | 2245/2863 [27:01<07:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2245: train loss 0.37472. lr 3.995450e-04:  78%|███████▊  | 2246/2863 [27:01<07:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2246: train loss 0.37642. lr 3.993896e-04:  78%|███████▊  | 2246/2863 [27:02<07:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2246: train loss 0.37642. lr 3.993896e-04:  78%|███████▊  | 2247/2863 [27:02<07:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2247: train loss 0.37421. lr 3.992343e-04:  78%|███████▊  | 2247/2863 [27:03<07:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2247: train loss 0.37421. lr 3.992343e-04:  79%|███████▊  | 2248/2863 [27:03<07:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2248: train loss 0.36579. lr 3.990789e-04:  79%|███████▊  | 2248/2863 [27:03<07:08,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2248: train loss 0.36579. lr 3.990789e-04:  79%|███████▊  | 2249/2863 [27:03<07:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2249: train loss 0.36439. lr 3.989234e-04:  79%|███████▊  | 2249/2863 [27:04<07:08,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2249: train loss 0.36439. lr 3.989234e-04:  79%|███████▊  | 2250/2863 [27:04<07:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2250: train loss 0.36343. lr 3.987680e-04:  79%|███████▊  | 2250/2863 [27:05<07:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2250: train loss 0.36343. lr 3.987680e-04:  79%|███████▊  | 2251/2863 [27:05<07:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2251: train loss 0.37749. lr 3.986125e-04:  79%|███████▊  | 2251/2863 [27:05<07:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2251: train loss 0.37749. lr 3.986125e-04:  79%|███████▊  | 2252/2863 [27:05<07:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2252: train loss 0.37435. lr 3.984570e-04:  79%|███████▊  | 2252/2863 [27:06<07:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2252: train loss 0.37435. lr 3.984570e-04:  79%|███████▊  | 2253/2863 [27:06<07:02,  1.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2253: train loss 0.36601. lr 3.983014e-04:  79%|███████▊  | 2253/2863 [27:07<07:02,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2253: train loss 0.36601. lr 3.983014e-04:  79%|███████▊  | 2254/2863 [27:07<07:23,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2254: train loss 0.37905. lr 3.981459e-04:  79%|███████▊  | 2254/2863 [27:08<07:23,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2254: train loss 0.37905. lr 3.981459e-04:  79%|███████▉  | 2255/2863 [27:08<07:16,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2255: train loss 0.36726. lr 3.979903e-04:  79%|███████▉  | 2255/2863 [27:08<07:16,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2255: train loss 0.36726. lr 3.979903e-04:  79%|███████▉  | 2256/2863 [27:08<07:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2256: train loss 0.36537. lr 3.978346e-04:  79%|███████▉  | 2256/2863 [27:09<07:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2256: train loss 0.36537. lr 3.978346e-04:  79%|███████▉  | 2257/2863 [27:09<07:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2257: train loss 0.37930. lr 3.976790e-04:  79%|███████▉  | 2257/2863 [27:10<07:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2257: train loss 0.37930. lr 3.976790e-04:  79%|███████▉  | 2258/2863 [27:10<07:03,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2258: train loss 0.35895. lr 3.975233e-04:  79%|███████▉  | 2258/2863 [27:10<07:03,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2258: train loss 0.35895. lr 3.975233e-04:  79%|███████▉  | 2259/2863 [27:10<07:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2259: train loss 0.36169. lr 3.973676e-04:  79%|███████▉  | 2259/2863 [27:11<07:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2259: train loss 0.36169. lr 3.973676e-04:  79%|███████▉  | 2260/2863 [27:11<07:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2260: train loss 0.36356. lr 3.972118e-04:  79%|███████▉  | 2260/2863 [27:12<07:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2260: train loss 0.36356. lr 3.972118e-04:  79%|███████▉  | 2261/2863 [27:12<07:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2261: train loss 0.37690. lr 3.970561e-04:  79%|███████▉  | 2261/2863 [27:13<07:00,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2261: train loss 0.37690. lr 3.970561e-04:  79%|███████▉  | 2262/2863 [27:13<06:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2262: train loss 0.35341. lr 3.969002e-04:  79%|███████▉  | 2262/2863 [27:13<06:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2262: train loss 0.35341. lr 3.969002e-04:  79%|███████▉  | 2263/2863 [27:13<06:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2263: train loss 0.37610. lr 3.967444e-04:  79%|███████▉  | 2263/2863 [27:14<06:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2263: train loss 0.37610. lr 3.967444e-04:  79%|███████▉  | 2264/2863 [27:14<06:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2264: train loss 0.35666. lr 3.965885e-04:  79%|███████▉  | 2264/2863 [27:15<06:58,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2264: train loss 0.35666. lr 3.965885e-04:  79%|███████▉  | 2265/2863 [27:15<06:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2265: train loss 0.36123. lr 3.964327e-04:  79%|███████▉  | 2265/2863 [27:15<06:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2265: train loss 0.36123. lr 3.964327e-04:  79%|███████▉  | 2266/2863 [27:15<06:56,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2266: train loss 0.35741. lr 3.962767e-04:  79%|███████▉  | 2266/2863 [27:16<06:56,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2266: train loss 0.35741. lr 3.962767e-04:  79%|███████▉  | 2267/2863 [27:16<06:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2267: train loss 0.34824. lr 3.961208e-04:  79%|███████▉  | 2267/2863 [27:17<06:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2267: train loss 0.34824. lr 3.961208e-04:  79%|███████▉  | 2268/2863 [27:17<06:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2268: train loss 0.36277. lr 3.959648e-04:  79%|███████▉  | 2268/2863 [27:17<06:54,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2268: train loss 0.36277. lr 3.959648e-04:  79%|███████▉  | 2269/2863 [27:17<06:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2269: train loss 0.37157. lr 3.958088e-04:  79%|███████▉  | 2269/2863 [27:18<06:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2269: train loss 0.37157. lr 3.958088e-04:  79%|███████▉  | 2270/2863 [27:18<06:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2270: train loss 0.37239. lr 3.956527e-04:  79%|███████▉  | 2270/2863 [27:19<06:53,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2270: train loss 0.37239. lr 3.956527e-04:  79%|███████▉  | 2271/2863 [27:19<06:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2271: train loss 0.35866. lr 3.954967e-04:  79%|███████▉  | 2271/2863 [27:19<06:50,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2271: train loss 0.35866. lr 3.954967e-04:  79%|███████▉  | 2272/2863 [27:19<06:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2272: train loss 0.36150. lr 3.953406e-04:  79%|███████▉  | 2272/2863 [27:20<06:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2272: train loss 0.36150. lr 3.953406e-04:  79%|███████▉  | 2273/2863 [27:20<06:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2273: train loss 0.35723. lr 3.951845e-04:  79%|███████▉  | 2273/2863 [27:21<06:49,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2273: train loss 0.35723. lr 3.951845e-04:  79%|███████▉  | 2274/2863 [27:21<06:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2274: train loss 0.36354. lr 3.950283e-04:  79%|███████▉  | 2274/2863 [27:22<06:46,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2274: train loss 0.36354. lr 3.950283e-04:  79%|███████▉  | 2275/2863 [27:22<06:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2275: train loss 0.36071. lr 3.948721e-04:  79%|███████▉  | 2275/2863 [27:22<06:44,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2275: train loss 0.36071. lr 3.948721e-04:  79%|███████▉  | 2276/2863 [27:22<06:50,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2276: train loss 0.36609. lr 3.947159e-04:  79%|███████▉  | 2276/2863 [27:23<06:50,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2276: train loss 0.36609. lr 3.947159e-04:  80%|███████▉  | 2277/2863 [27:23<06:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2277: train loss 0.36814. lr 3.945597e-04:  80%|███████▉  | 2277/2863 [27:24<06:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2277: train loss 0.36814. lr 3.945597e-04:  80%|███████▉  | 2278/2863 [27:24<06:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2278: train loss 0.36026. lr 3.944034e-04:  80%|███████▉  | 2278/2863 [27:24<06:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2278: train loss 0.36026. lr 3.944034e-04:  80%|███████▉  | 2279/2863 [27:24<06:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2279: train loss 0.36611. lr 3.942471e-04:  80%|███████▉  | 2279/2863 [27:25<06:52,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2279: train loss 0.36611. lr 3.942471e-04:  80%|███████▉  | 2280/2863 [27:25<06:50,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2280: train loss 0.36968. lr 3.940908e-04:  80%|███████▉  | 2280/2863 [27:26<06:50,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2280: train loss 0.36968. lr 3.940908e-04:  80%|███████▉  | 2281/2863 [27:26<06:49,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2281: train loss 0.36377. lr 3.939344e-04:  80%|███████▉  | 2281/2863 [27:27<06:49,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2281: train loss 0.36377. lr 3.939344e-04:  80%|███████▉  | 2282/2863 [27:27<07:13,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2282: train loss 0.34885. lr 3.937780e-04:  80%|███████▉  | 2282/2863 [27:27<07:13,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2282: train loss 0.34885. lr 3.937780e-04:  80%|███████▉  | 2283/2863 [27:27<07:05,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2283: train loss 0.36394. lr 3.936216e-04:  80%|███████▉  | 2283/2863 [27:28<07:05,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2283: train loss 0.36394. lr 3.936216e-04:  80%|███████▉  | 2284/2863 [27:28<07:03,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2284: train loss 0.35658. lr 3.934652e-04:  80%|███████▉  | 2284/2863 [27:29<07:03,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2284: train loss 0.35658. lr 3.934652e-04:  80%|███████▉  | 2285/2863 [27:29<07:01,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2285: train loss 0.34771. lr 3.933087e-04:  80%|███████▉  | 2285/2863 [27:29<07:01,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2285: train loss 0.34771. lr 3.933087e-04:  80%|███████▉  | 2286/2863 [27:29<06:54,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2286: train loss 0.35364. lr 3.931522e-04:  80%|███████▉  | 2286/2863 [27:30<06:54,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2286: train loss 0.35364. lr 3.931522e-04:  80%|███████▉  | 2287/2863 [27:30<06:48,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2287: train loss 0.35550. lr 3.929957e-04:  80%|███████▉  | 2287/2863 [27:31<06:48,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2287: train loss 0.35550. lr 3.929957e-04:  80%|███████▉  | 2288/2863 [27:31<06:44,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2288: train loss 0.36061. lr 3.928392e-04:  80%|███████▉  | 2288/2863 [27:32<06:44,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2288: train loss 0.36061. lr 3.928392e-04:  80%|███████▉  | 2289/2863 [27:32<06:42,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2289: train loss 0.36642. lr 3.926826e-04:  80%|███████▉  | 2289/2863 [27:32<06:42,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2289: train loss 0.36642. lr 3.926826e-04:  80%|███████▉  | 2290/2863 [27:32<06:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2290: train loss 0.36288. lr 3.925260e-04:  80%|███████▉  | 2290/2863 [27:33<06:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2290: train loss 0.36288. lr 3.925260e-04:  80%|████████  | 2291/2863 [27:33<06:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2291: train loss 0.35989. lr 3.923693e-04:  80%|████████  | 2291/2863 [27:34<06:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2291: train loss 0.35989. lr 3.923693e-04:  80%|████████  | 2292/2863 [27:34<06:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2292: train loss 0.35417. lr 3.922127e-04:  80%|████████  | 2292/2863 [27:34<06:43,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2292: train loss 0.35417. lr 3.922127e-04:  80%|████████  | 2293/2863 [27:34<06:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2293: train loss 0.35751. lr 3.920560e-04:  80%|████████  | 2293/2863 [27:35<06:39,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2293: train loss 0.35751. lr 3.920560e-04:  80%|████████  | 2294/2863 [27:35<06:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2294: train loss 0.36590. lr 3.918993e-04:  80%|████████  | 2294/2863 [27:36<06:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2294: train loss 0.36590. lr 3.918993e-04:  80%|████████  | 2295/2863 [27:36<06:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2295: train loss 0.34186. lr 3.917425e-04:  80%|████████  | 2295/2863 [27:36<06:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2295: train loss 0.34186. lr 3.917425e-04:  80%|████████  | 2296/2863 [27:36<06:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2296: train loss 0.36257. lr 3.915858e-04:  80%|████████  | 2296/2863 [27:37<06:33,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2296: train loss 0.36257. lr 3.915858e-04:  80%|████████  | 2297/2863 [27:37<06:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2297: train loss 0.35059. lr 3.914290e-04:  80%|████████  | 2297/2863 [27:38<06:31,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2297: train loss 0.35059. lr 3.914290e-04:  80%|████████  | 2298/2863 [27:38<06:30,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2298: train loss 0.35056. lr 3.912721e-04:  80%|████████  | 2298/2863 [27:39<06:30,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2298: train loss 0.35056. lr 3.912721e-04:  80%|████████  | 2299/2863 [27:39<06:42,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2299: train loss 0.36198. lr 3.911153e-04:  80%|████████  | 2299/2863 [27:39<06:42,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2299: train loss 0.36198. lr 3.911153e-04:  80%|████████  | 2300/2863 [27:39<06:40,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2300: train loss 0.36863. lr 3.909584e-04:  80%|████████  | 2300/2863 [27:40<06:40,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2300: train loss 0.36863. lr 3.909584e-04:  80%|████████  | 2301/2863 [27:40<06:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2301: train loss 0.36059. lr 3.908015e-04:  80%|████████  | 2301/2863 [27:41<06:35,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2301: train loss 0.36059. lr 3.908015e-04:  80%|████████  | 2302/2863 [27:41<06:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2302: train loss 0.36107. lr 3.906445e-04:  80%|████████  | 2302/2863 [27:41<06:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2302: train loss 0.36107. lr 3.906445e-04:  80%|████████  | 2303/2863 [27:41<06:39,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2303: train loss 0.36568. lr 3.904876e-04:  80%|████████  | 2303/2863 [27:42<06:39,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2303: train loss 0.36568. lr 3.904876e-04:  80%|████████  | 2304/2863 [27:42<06:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2304: train loss 0.36023. lr 3.903306e-04:  80%|████████  | 2304/2863 [27:43<06:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2304: train loss 0.36023. lr 3.903306e-04:  81%|████████  | 2305/2863 [27:43<06:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2305: train loss 0.35695. lr 3.901736e-04:  81%|████████  | 2305/2863 [27:44<06:46,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2305: train loss 0.35695. lr 3.901736e-04:  81%|████████  | 2306/2863 [27:44<06:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2306: train loss 0.35258. lr 3.900165e-04:  81%|████████  | 2306/2863 [27:44<06:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2306: train loss 0.35258. lr 3.900165e-04:  81%|████████  | 2307/2863 [27:44<06:35,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2307: train loss 0.35047. lr 3.898595e-04:  81%|████████  | 2307/2863 [27:45<06:35,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2307: train loss 0.35047. lr 3.898595e-04:  81%|████████  | 2308/2863 [27:45<06:31,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2308: train loss 0.35780. lr 3.897024e-04:  81%|████████  | 2308/2863 [27:46<06:31,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2308: train loss 0.35780. lr 3.897024e-04:  81%|████████  | 2309/2863 [27:46<06:29,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2309: train loss 0.35854. lr 3.895452e-04:  81%|████████  | 2309/2863 [27:46<06:29,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2309: train loss 0.35854. lr 3.895452e-04:  81%|████████  | 2310/2863 [27:46<06:47,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2310: train loss 0.36612. lr 3.893881e-04:  81%|████████  | 2310/2863 [27:47<06:47,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2310: train loss 0.36612. lr 3.893881e-04:  81%|████████  | 2311/2863 [27:47<06:39,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2311: train loss 0.35155. lr 3.892309e-04:  81%|████████  | 2311/2863 [27:48<06:39,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2311: train loss 0.35155. lr 3.892309e-04:  81%|████████  | 2312/2863 [27:48<06:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2312: train loss 0.35394. lr 3.890737e-04:  81%|████████  | 2312/2863 [27:49<06:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2312: train loss 0.35394. lr 3.890737e-04:  81%|████████  | 2313/2863 [27:49<06:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2313: train loss 0.35807. lr 3.889164e-04:  81%|████████  | 2313/2863 [27:49<06:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2313: train loss 0.35807. lr 3.889164e-04:  81%|████████  | 2314/2863 [27:49<06:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2314: train loss 0.34498. lr 3.887592e-04:  81%|████████  | 2314/2863 [27:50<06:26,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2314: train loss 0.34498. lr 3.887592e-04:  81%|████████  | 2315/2863 [27:50<06:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2315: train loss 0.36249. lr 3.886019e-04:  81%|████████  | 2315/2863 [27:51<06:24,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2315: train loss 0.36249. lr 3.886019e-04:  81%|████████  | 2316/2863 [27:51<06:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2316: train loss 0.33920. lr 3.884446e-04:  81%|████████  | 2316/2863 [27:51<06:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2316: train loss 0.33920. lr 3.884446e-04:  81%|████████  | 2317/2863 [27:51<06:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2317: train loss 0.35989. lr 3.882872e-04:  81%|████████  | 2317/2863 [27:52<06:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2317: train loss 0.35989. lr 3.882872e-04:  81%|████████  | 2318/2863 [27:52<06:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2318: train loss 0.35279. lr 3.881299e-04:  81%|████████  | 2318/2863 [27:53<06:18,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2318: train loss 0.35279. lr 3.881299e-04:  81%|████████  | 2319/2863 [27:53<06:16,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2319: train loss 0.34639. lr 3.879725e-04:  81%|████████  | 2319/2863 [27:53<06:16,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2319: train loss 0.34639. lr 3.879725e-04:  81%|████████  | 2320/2863 [27:53<06:14,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2320: train loss 0.35724. lr 3.878151e-04:  81%|████████  | 2320/2863 [27:54<06:14,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2320: train loss 0.35724. lr 3.878151e-04:  81%|████████  | 2321/2863 [27:54<06:12,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2321: train loss 0.34724. lr 3.876576e-04:  81%|████████  | 2321/2863 [27:55<06:12,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2321: train loss 0.34724. lr 3.876576e-04:  81%|████████  | 2322/2863 [27:55<06:12,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2322: train loss 0.35097. lr 3.875001e-04:  81%|████████  | 2322/2863 [27:55<06:12,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2322: train loss 0.35097. lr 3.875001e-04:  81%|████████  | 2323/2863 [27:55<06:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2323: train loss 0.36699. lr 3.873426e-04:  81%|████████  | 2323/2863 [27:56<06:10,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2323: train loss 0.36699. lr 3.873426e-04:  81%|████████  | 2324/2863 [27:56<06:09,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2324: train loss 0.35405. lr 3.871851e-04:  81%|████████  | 2324/2863 [27:57<06:09,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2324: train loss 0.35405. lr 3.871851e-04:  81%|████████  | 2325/2863 [27:57<06:09,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2325: train loss 0.34111. lr 3.870275e-04:  81%|████████  | 2325/2863 [27:58<06:09,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2325: train loss 0.34111. lr 3.870275e-04:  81%|████████  | 2326/2863 [27:58<06:26,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2326: train loss 0.34986. lr 3.868700e-04:  81%|████████  | 2326/2863 [27:58<06:26,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2326: train loss 0.34986. lr 3.868700e-04:  81%|████████▏ | 2327/2863 [27:58<06:37,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2327: train loss 0.34530. lr 3.867124e-04:  81%|████████▏ | 2327/2863 [27:59<06:37,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2327: train loss 0.34530. lr 3.867124e-04:  81%|████████▏ | 2328/2863 [27:59<06:38,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2328: train loss 0.35869. lr 3.865547e-04:  81%|████████▏ | 2328/2863 [28:00<06:38,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2328: train loss 0.35869. lr 3.865547e-04:  81%|████████▏ | 2329/2863 [28:00<06:36,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2329: train loss 0.35635. lr 3.863971e-04:  81%|████████▏ | 2329/2863 [28:01<06:36,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2329: train loss 0.35635. lr 3.863971e-04:  81%|████████▏ | 2330/2863 [28:01<06:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2330: train loss 0.35551. lr 3.862394e-04:  81%|████████▏ | 2330/2863 [28:01<06:27,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2330: train loss 0.35551. lr 3.862394e-04:  81%|████████▏ | 2331/2863 [28:01<06:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2331: train loss 0.34662. lr 3.860817e-04:  81%|████████▏ | 2331/2863 [28:02<06:20,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2331: train loss 0.34662. lr 3.860817e-04:  81%|████████▏ | 2332/2863 [28:02<06:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2332: train loss 0.34606. lr 3.859239e-04:  81%|████████▏ | 2332/2863 [28:03<06:15,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2332: train loss 0.34606. lr 3.859239e-04:  81%|████████▏ | 2333/2863 [28:03<06:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2333: train loss 0.34975. lr 3.857662e-04:  81%|████████▏ | 2333/2863 [28:03<06:11,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2333: train loss 0.34975. lr 3.857662e-04:  82%|████████▏ | 2334/2863 [28:03<06:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2334: train loss 0.35225. lr 3.856084e-04:  82%|████████▏ | 2334/2863 [28:04<06:09,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2334: train loss 0.35225. lr 3.856084e-04:  82%|████████▏ | 2335/2863 [28:04<06:07,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2335: train loss 0.33763. lr 3.854506e-04:  82%|████████▏ | 2335/2863 [28:05<06:07,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2335: train loss 0.33763. lr 3.854506e-04:  82%|████████▏ | 2336/2863 [28:05<06:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2336: train loss 0.36420. lr 3.852927e-04:  82%|████████▏ | 2336/2863 [28:05<06:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2336: train loss 0.36420. lr 3.852927e-04:  82%|████████▏ | 2337/2863 [28:05<06:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2337: train loss 0.34755. lr 3.851349e-04:  82%|████████▏ | 2337/2863 [28:06<06:05,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2337: train loss 0.34755. lr 3.851349e-04:  82%|████████▏ | 2338/2863 [28:06<06:22,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2338: train loss 0.35929. lr 3.849770e-04:  82%|████████▏ | 2338/2863 [28:07<06:22,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2338: train loss 0.35929. lr 3.849770e-04:  82%|████████▏ | 2339/2863 [28:07<06:15,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2339: train loss 0.34376. lr 3.848191e-04:  82%|████████▏ | 2339/2863 [28:08<06:15,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2339: train loss 0.34376. lr 3.848191e-04:  82%|████████▏ | 2340/2863 [28:08<06:10,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2340: train loss 0.34844. lr 3.846611e-04:  82%|████████▏ | 2340/2863 [28:08<06:10,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2340: train loss 0.34844. lr 3.846611e-04:  82%|████████▏ | 2341/2863 [28:08<06:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2341: train loss 0.35499. lr 3.845032e-04:  82%|████████▏ | 2341/2863 [28:09<06:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2341: train loss 0.35499. lr 3.845032e-04:  82%|████████▏ | 2342/2863 [28:09<06:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2342: train loss 0.34861. lr 3.843452e-04:  82%|████████▏ | 2342/2863 [28:10<06:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2342: train loss 0.34861. lr 3.843452e-04:  82%|████████▏ | 2343/2863 [28:10<06:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2343: train loss 0.35093. lr 3.841872e-04:  82%|████████▏ | 2343/2863 [28:10<06:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2343: train loss 0.35093. lr 3.841872e-04:  82%|████████▏ | 2344/2863 [28:10<06:00,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2344: train loss 0.35055. lr 3.840291e-04:  82%|████████▏ | 2344/2863 [28:11<06:00,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2344: train loss 0.35055. lr 3.840291e-04:  82%|████████▏ | 2345/2863 [28:11<05:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2345: train loss 0.34754. lr 3.838710e-04:  82%|████████▏ | 2345/2863 [28:12<05:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2345: train loss 0.34754. lr 3.838710e-04:  82%|████████▏ | 2346/2863 [28:12<05:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2346: train loss 0.35777. lr 3.837129e-04:  82%|████████▏ | 2346/2863 [28:12<05:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2346: train loss 0.35777. lr 3.837129e-04:  82%|████████▏ | 2347/2863 [28:12<05:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2347: train loss 0.34240. lr 3.835548e-04:  82%|████████▏ | 2347/2863 [28:13<05:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2347: train loss 0.34240. lr 3.835548e-04:  82%|████████▏ | 2348/2863 [28:13<05:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2348: train loss 0.34433. lr 3.833967e-04:  82%|████████▏ | 2348/2863 [28:14<05:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2348: train loss 0.34433. lr 3.833967e-04:  82%|████████▏ | 2349/2863 [28:14<05:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2349: train loss 0.34384. lr 3.832385e-04:  82%|████████▏ | 2349/2863 [28:14<05:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2349: train loss 0.34384. lr 3.832385e-04:  82%|████████▏ | 2350/2863 [28:14<05:51,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2350: train loss 0.34630. lr 3.830803e-04:  82%|████████▏ | 2350/2863 [28:15<05:51,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2350: train loss 0.34630. lr 3.830803e-04:  82%|████████▏ | 2351/2863 [28:15<05:51,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2351: train loss 0.36096. lr 3.829221e-04:  82%|████████▏ | 2351/2863 [28:16<05:51,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2351: train loss 0.36096. lr 3.829221e-04:  82%|████████▏ | 2352/2863 [28:16<05:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2352: train loss 0.34221. lr 3.827639e-04:  82%|████████▏ | 2352/2863 [28:17<05:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2352: train loss 0.34221. lr 3.827639e-04:  82%|████████▏ | 2353/2863 [28:17<05:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2353: train loss 0.35330. lr 3.826056e-04:  82%|████████▏ | 2353/2863 [28:17<05:50,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2353: train loss 0.35330. lr 3.826056e-04:  82%|████████▏ | 2354/2863 [28:17<05:49,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2354: train loss 0.34422. lr 3.824473e-04:  82%|████████▏ | 2354/2863 [28:18<05:49,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2354: train loss 0.34422. lr 3.824473e-04:  82%|████████▏ | 2355/2863 [28:18<05:49,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2355: train loss 0.35157. lr 3.822890e-04:  82%|████████▏ | 2355/2863 [28:19<05:49,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2355: train loss 0.35157. lr 3.822890e-04:  82%|████████▏ | 2356/2863 [28:19<05:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2356: train loss 0.34256. lr 3.821306e-04:  82%|████████▏ | 2356/2863 [28:19<05:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2356: train loss 0.34256. lr 3.821306e-04:  82%|████████▏ | 2357/2863 [28:19<05:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2357: train loss 0.35152. lr 3.819723e-04:  82%|████████▏ | 2357/2863 [28:20<05:47,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2357: train loss 0.35152. lr 3.819723e-04:  82%|████████▏ | 2358/2863 [28:20<05:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2358: train loss 0.34891. lr 3.818139e-04:  82%|████████▏ | 2358/2863 [28:21<05:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2358: train loss 0.34891. lr 3.818139e-04:  82%|████████▏ | 2359/2863 [28:21<05:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2359: train loss 0.35109. lr 3.816554e-04:  82%|████████▏ | 2359/2863 [28:21<05:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2359: train loss 0.35109. lr 3.816554e-04:  82%|████████▏ | 2360/2863 [28:21<05:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2360: train loss 0.33733. lr 3.814970e-04:  82%|████████▏ | 2360/2863 [28:22<05:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2360: train loss 0.33733. lr 3.814970e-04:  82%|████████▏ | 2361/2863 [28:22<05:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2361: train loss 0.34644. lr 3.813385e-04:  82%|████████▏ | 2361/2863 [28:23<05:51,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2361: train loss 0.34644. lr 3.813385e-04:  83%|████████▎ | 2362/2863 [28:23<05:49,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2362: train loss 0.34282. lr 3.811800e-04:  83%|████████▎ | 2362/2863 [28:23<05:49,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2362: train loss 0.34282. lr 3.811800e-04:  83%|████████▎ | 2363/2863 [28:23<05:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2363: train loss 0.34630. lr 3.810215e-04:  83%|████████▎ | 2363/2863 [28:24<05:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2363: train loss 0.34630. lr 3.810215e-04:  83%|████████▎ | 2364/2863 [28:24<05:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2364: train loss 0.35561. lr 3.808630e-04:  83%|████████▎ | 2364/2863 [28:25<05:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2364: train loss 0.35561. lr 3.808630e-04:  83%|████████▎ | 2365/2863 [28:25<05:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2365: train loss 0.35422. lr 3.807044e-04:  83%|████████▎ | 2365/2863 [28:26<05:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2365: train loss 0.35422. lr 3.807044e-04:  83%|████████▎ | 2366/2863 [28:26<06:02,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2366: train loss 0.35452. lr 3.805458e-04:  83%|████████▎ | 2366/2863 [28:26<06:02,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2366: train loss 0.35452. lr 3.805458e-04:  83%|████████▎ | 2367/2863 [28:26<05:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2367: train loss 0.34005. lr 3.803872e-04:  83%|████████▎ | 2367/2863 [28:27<05:55,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2367: train loss 0.34005. lr 3.803872e-04:  83%|████████▎ | 2368/2863 [28:27<05:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2368: train loss 0.34913. lr 3.802286e-04:  83%|████████▎ | 2368/2863 [28:28<05:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2368: train loss 0.34913. lr 3.802286e-04:  83%|████████▎ | 2369/2863 [28:28<05:47,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2369: train loss 0.34384. lr 3.800699e-04:  83%|████████▎ | 2369/2863 [28:28<05:47,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2369: train loss 0.34384. lr 3.800699e-04:  83%|████████▎ | 2370/2863 [28:28<05:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2370: train loss 0.34096. lr 3.799112e-04:  83%|████████▎ | 2370/2863 [28:29<05:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2370: train loss 0.34096. lr 3.799112e-04:  83%|████████▎ | 2371/2863 [28:29<05:54,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2371: train loss 0.34588. lr 3.797525e-04:  83%|████████▎ | 2371/2863 [28:30<05:54,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2371: train loss 0.34588. lr 3.797525e-04:  83%|████████▎ | 2372/2863 [28:30<05:53,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2372: train loss 0.35567. lr 3.795938e-04:  83%|████████▎ | 2372/2863 [28:31<05:53,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2372: train loss 0.35567. lr 3.795938e-04:  83%|████████▎ | 2373/2863 [28:31<05:52,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2373: train loss 0.34448. lr 3.794350e-04:  83%|████████▎ | 2373/2863 [28:31<05:52,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2373: train loss 0.34448. lr 3.794350e-04:  83%|████████▎ | 2374/2863 [28:31<05:49,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2374: train loss 0.35614. lr 3.792763e-04:  83%|████████▎ | 2374/2863 [28:32<05:49,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2374: train loss 0.35614. lr 3.792763e-04:  83%|████████▎ | 2375/2863 [28:32<05:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2375: train loss 0.34550. lr 3.791174e-04:  83%|████████▎ | 2375/2863 [28:33<05:47,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2375: train loss 0.34550. lr 3.791174e-04:  83%|████████▎ | 2376/2863 [28:33<05:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2376: train loss 0.32799. lr 3.789586e-04:  83%|████████▎ | 2376/2863 [28:33<05:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2376: train loss 0.32799. lr 3.789586e-04:  83%|████████▎ | 2377/2863 [28:33<05:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2377: train loss 0.33891. lr 3.787998e-04:  83%|████████▎ | 2377/2863 [28:34<05:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2377: train loss 0.33891. lr 3.787998e-04:  83%|████████▎ | 2378/2863 [28:34<05:45,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2378: train loss 0.34614. lr 3.786409e-04:  83%|████████▎ | 2378/2863 [28:35<05:45,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2378: train loss 0.34614. lr 3.786409e-04:  83%|████████▎ | 2379/2863 [28:35<05:46,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2379: train loss 0.34342. lr 3.784820e-04:  83%|████████▎ | 2379/2863 [28:36<05:46,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2379: train loss 0.34342. lr 3.784820e-04:  83%|████████▎ | 2380/2863 [28:36<05:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2380: train loss 0.33839. lr 3.783231e-04:  83%|████████▎ | 2380/2863 [28:36<05:43,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2380: train loss 0.33839. lr 3.783231e-04:  83%|████████▎ | 2381/2863 [28:36<05:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2381: train loss 0.34410. lr 3.781641e-04:  83%|████████▎ | 2381/2863 [28:37<05:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2381: train loss 0.34410. lr 3.781641e-04:  83%|████████▎ | 2382/2863 [28:37<05:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2382: train loss 0.35226. lr 3.780051e-04:  83%|████████▎ | 2382/2863 [28:38<05:38,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2382: train loss 0.35226. lr 3.780051e-04:  83%|████████▎ | 2383/2863 [28:38<05:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2383: train loss 0.33525. lr 3.778461e-04:  83%|████████▎ | 2383/2863 [28:38<05:35,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2383: train loss 0.33525. lr 3.778461e-04:  83%|████████▎ | 2384/2863 [28:38<05:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2384: train loss 0.33221. lr 3.776871e-04:  83%|████████▎ | 2384/2863 [28:39<05:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2384: train loss 0.33221. lr 3.776871e-04:  83%|████████▎ | 2385/2863 [28:39<05:32,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2385: train loss 0.34218. lr 3.775281e-04:  83%|████████▎ | 2385/2863 [28:40<05:32,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2385: train loss 0.34218. lr 3.775281e-04:  83%|████████▎ | 2386/2863 [28:40<05:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2386: train loss 0.34353. lr 3.773690e-04:  83%|████████▎ | 2386/2863 [28:40<05:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2386: train loss 0.34353. lr 3.773690e-04:  83%|████████▎ | 2387/2863 [28:40<05:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2387: train loss 0.34794. lr 3.772099e-04:  83%|████████▎ | 2387/2863 [28:41<05:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2387: train loss 0.34794. lr 3.772099e-04:  83%|████████▎ | 2388/2863 [28:41<05:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2388: train loss 0.34606. lr 3.770508e-04:  83%|████████▎ | 2388/2863 [28:42<05:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2388: train loss 0.34606. lr 3.770508e-04:  83%|████████▎ | 2389/2863 [28:42<05:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2389: train loss 0.34484. lr 3.768917e-04:  83%|████████▎ | 2389/2863 [28:43<05:31,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2389: train loss 0.34484. lr 3.768917e-04:  83%|████████▎ | 2390/2863 [28:43<05:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2390: train loss 0.35223. lr 3.767325e-04:  83%|████████▎ | 2390/2863 [28:43<05:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2390: train loss 0.35223. lr 3.767325e-04:  84%|████████▎ | 2391/2863 [28:43<05:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2391: train loss 0.33626. lr 3.765733e-04:  84%|████████▎ | 2391/2863 [28:44<05:27,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2391: train loss 0.33626. lr 3.765733e-04:  84%|████████▎ | 2392/2863 [28:44<05:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2392: train loss 0.33825. lr 3.764141e-04:  84%|████████▎ | 2392/2863 [28:45<05:26,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2392: train loss 0.33825. lr 3.764141e-04:  84%|████████▎ | 2393/2863 [28:45<05:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2393: train loss 0.35123. lr 3.762549e-04:  84%|████████▎ | 2393/2863 [28:45<05:25,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2393: train loss 0.35123. lr 3.762549e-04:  84%|████████▎ | 2394/2863 [28:45<05:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2394: train loss 0.33687. lr 3.760957e-04:  84%|████████▎ | 2394/2863 [28:46<05:41,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2394: train loss 0.33687. lr 3.760957e-04:  84%|████████▎ | 2395/2863 [28:46<05:38,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2395: train loss 0.34934. lr 3.759364e-04:  84%|████████▎ | 2395/2863 [28:47<05:38,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2395: train loss 0.34934. lr 3.759364e-04:  84%|████████▎ | 2396/2863 [28:47<05:36,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2396: train loss 0.34176. lr 3.757771e-04:  84%|████████▎ | 2396/2863 [28:48<05:36,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2396: train loss 0.34176. lr 3.757771e-04:  84%|████████▎ | 2397/2863 [28:48<05:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2397: train loss 0.34170. lr 3.756178e-04:  84%|████████▎ | 2397/2863 [28:48<05:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2397: train loss 0.34170. lr 3.756178e-04:  84%|████████▍ | 2398/2863 [28:48<05:29,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2398: train loss 0.35601. lr 3.754584e-04:  84%|████████▍ | 2398/2863 [28:49<05:29,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2398: train loss 0.35601. lr 3.754584e-04:  84%|████████▍ | 2399/2863 [28:49<05:25,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2399: train loss 0.33613. lr 3.752991e-04:  84%|████████▍ | 2399/2863 [28:50<05:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2399: train loss 0.33613. lr 3.752991e-04:  84%|████████▍ | 2400/2863 [28:50<05:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2400: train loss 0.33362. lr 3.751397e-04:  84%|████████▍ | 2400/2863 [28:50<05:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2400: train loss 0.33362. lr 3.751397e-04:  84%|████████▍ | 2401/2863 [28:50<05:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2401: train loss 0.33626. lr 3.749803e-04:  84%|████████▍ | 2401/2863 [28:51<05:21,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2401: train loss 0.33626. lr 3.749803e-04:  84%|████████▍ | 2402/2863 [28:51<05:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2402: train loss 0.34453. lr 3.748208e-04:  84%|████████▍ | 2402/2863 [28:52<05:19,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2402: train loss 0.34453. lr 3.748208e-04:  84%|████████▍ | 2403/2863 [28:52<05:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2403: train loss 0.33634. lr 3.746614e-04:  84%|████████▍ | 2403/2863 [28:52<05:21,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2403: train loss 0.33634. lr 3.746614e-04:  84%|████████▍ | 2404/2863 [28:52<05:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2404: train loss 0.35002. lr 3.745019e-04:  84%|████████▍ | 2404/2863 [28:53<05:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2404: train loss 0.35002. lr 3.745019e-04:  84%|████████▍ | 2405/2863 [28:53<05:23,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2405: train loss 0.33949. lr 3.743424e-04:  84%|████████▍ | 2405/2863 [28:54<05:23,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2405: train loss 0.33949. lr 3.743424e-04:  84%|████████▍ | 2406/2863 [28:54<05:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2406: train loss 0.34447. lr 3.741829e-04:  84%|████████▍ | 2406/2863 [28:55<05:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2406: train loss 0.34447. lr 3.741829e-04:  84%|████████▍ | 2407/2863 [28:55<05:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2407: train loss 0.33474. lr 3.740233e-04:  84%|████████▍ | 2407/2863 [28:55<05:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2407: train loss 0.33474. lr 3.740233e-04:  84%|████████▍ | 2408/2863 [28:55<05:21,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2408: train loss 0.33864. lr 3.738638e-04:  84%|████████▍ | 2408/2863 [28:56<05:21,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2408: train loss 0.33864. lr 3.738638e-04:  84%|████████▍ | 2409/2863 [28:56<05:21,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2409: train loss 0.32939. lr 3.737042e-04:  84%|████████▍ | 2409/2863 [28:57<05:21,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2409: train loss 0.32939. lr 3.737042e-04:  84%|████████▍ | 2410/2863 [28:57<05:21,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2410: train loss 0.34510. lr 3.735446e-04:  84%|████████▍ | 2410/2863 [28:57<05:21,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2410: train loss 0.34510. lr 3.735446e-04:  84%|████████▍ | 2411/2863 [28:57<05:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2411: train loss 0.34353. lr 3.733849e-04:  84%|████████▍ | 2411/2863 [28:58<05:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2411: train loss 0.34353. lr 3.733849e-04:  84%|████████▍ | 2412/2863 [28:58<05:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2412: train loss 0.34853. lr 3.732253e-04:  84%|████████▍ | 2412/2863 [28:59<05:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2412: train loss 0.34853. lr 3.732253e-04:  84%|████████▍ | 2413/2863 [28:59<05:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2413: train loss 0.33543. lr 3.730656e-04:  84%|████████▍ | 2413/2863 [28:59<05:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2413: train loss 0.33543. lr 3.730656e-04:  84%|████████▍ | 2414/2863 [28:59<05:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2414: train loss 0.33921. lr 3.729059e-04:  84%|████████▍ | 2414/2863 [29:00<05:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2414: train loss 0.33921. lr 3.729059e-04:  84%|████████▍ | 2415/2863 [29:00<05:09,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2415: train loss 0.33421. lr 3.727462e-04:  84%|████████▍ | 2415/2863 [29:01<05:09,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2415: train loss 0.33421. lr 3.727462e-04:  84%|████████▍ | 2416/2863 [29:01<05:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2416: train loss 0.33456. lr 3.725864e-04:  84%|████████▍ | 2416/2863 [29:02<05:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2416: train loss 0.33456. lr 3.725864e-04:  84%|████████▍ | 2417/2863 [29:02<05:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2417: train loss 0.33687. lr 3.724267e-04:  84%|████████▍ | 2417/2863 [29:02<05:07,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2417: train loss 0.33687. lr 3.724267e-04:  84%|████████▍ | 2418/2863 [29:02<05:05,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2418: train loss 0.33710. lr 3.722669e-04:  84%|████████▍ | 2418/2863 [29:03<05:05,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2418: train loss 0.33710. lr 3.722669e-04:  84%|████████▍ | 2419/2863 [29:03<05:04,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2419: train loss 0.35080. lr 3.721071e-04:  84%|████████▍ | 2419/2863 [29:04<05:04,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2419: train loss 0.35080. lr 3.721071e-04:  85%|████████▍ | 2420/2863 [29:04<05:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2420: train loss 0.33068. lr 3.719473e-04:  85%|████████▍ | 2420/2863 [29:04<05:06,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2420: train loss 0.33068. lr 3.719473e-04:  85%|████████▍ | 2421/2863 [29:04<05:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2421: train loss 0.33777. lr 3.717874e-04:  85%|████████▍ | 2421/2863 [29:05<05:06,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2421: train loss 0.33777. lr 3.717874e-04:  85%|████████▍ | 2422/2863 [29:05<05:20,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2422: train loss 0.32338. lr 3.716275e-04:  85%|████████▍ | 2422/2863 [29:06<05:20,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2422: train loss 0.32338. lr 3.716275e-04:  85%|████████▍ | 2423/2863 [29:06<05:14,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2423: train loss 0.34045. lr 3.714676e-04:  85%|████████▍ | 2423/2863 [29:06<05:14,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2423: train loss 0.34045. lr 3.714676e-04:  85%|████████▍ | 2424/2863 [29:06<05:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2424: train loss 0.33858. lr 3.713077e-04:  85%|████████▍ | 2424/2863 [29:07<05:11,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2424: train loss 0.33858. lr 3.713077e-04:  85%|████████▍ | 2425/2863 [29:07<05:08,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2425: train loss 0.34558. lr 3.711478e-04:  85%|████████▍ | 2425/2863 [29:08<05:08,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2425: train loss 0.34558. lr 3.711478e-04:  85%|████████▍ | 2426/2863 [29:08<05:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2426: train loss 0.33682. lr 3.709878e-04:  85%|████████▍ | 2426/2863 [29:09<05:06,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2426: train loss 0.33682. lr 3.709878e-04:  85%|████████▍ | 2427/2863 [29:09<05:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2427: train loss 0.34178. lr 3.708278e-04:  85%|████████▍ | 2427/2863 [29:09<05:03,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2427: train loss 0.34178. lr 3.708278e-04:  85%|████████▍ | 2428/2863 [29:09<05:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2428: train loss 0.32406. lr 3.706678e-04:  85%|████████▍ | 2428/2863 [29:10<05:01,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2428: train loss 0.32406. lr 3.706678e-04:  85%|████████▍ | 2429/2863 [29:10<05:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2429: train loss 0.33047. lr 3.705078e-04:  85%|████████▍ | 2429/2863 [29:11<05:00,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2429: train loss 0.33047. lr 3.705078e-04:  85%|████████▍ | 2430/2863 [29:11<04:58,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2430: train loss 0.32859. lr 3.703478e-04:  85%|████████▍ | 2430/2863 [29:11<04:58,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2430: train loss 0.32859. lr 3.703478e-04:  85%|████████▍ | 2431/2863 [29:11<04:57,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2431: train loss 0.33987. lr 3.701877e-04:  85%|████████▍ | 2431/2863 [29:12<04:57,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2431: train loss 0.33987. lr 3.701877e-04:  85%|████████▍ | 2432/2863 [29:12<04:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2432: train loss 0.33837. lr 3.700276e-04:  85%|████████▍ | 2432/2863 [29:13<04:56,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2432: train loss 0.33837. lr 3.700276e-04:  85%|████████▍ | 2433/2863 [29:13<04:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2433: train loss 0.33101. lr 3.698675e-04:  85%|████████▍ | 2433/2863 [29:13<04:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2433: train loss 0.33101. lr 3.698675e-04:  85%|████████▌ | 2434/2863 [29:13<04:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2434: train loss 0.32370. lr 3.697074e-04:  85%|████████▌ | 2434/2863 [29:14<04:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2434: train loss 0.32370. lr 3.697074e-04:  85%|████████▌ | 2435/2863 [29:14<04:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2435: train loss 0.33769. lr 3.695472e-04:  85%|████████▌ | 2435/2863 [29:15<04:55,  1.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2435: train loss 0.33769. lr 3.695472e-04:  85%|████████▌ | 2436/2863 [29:15<04:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2436: train loss 0.33202. lr 3.693870e-04:  85%|████████▌ | 2436/2863 [29:15<04:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2436: train loss 0.33202. lr 3.693870e-04:  85%|████████▌ | 2437/2863 [29:15<04:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2437: train loss 0.33064. lr 3.692269e-04:  85%|████████▌ | 2437/2863 [29:16<04:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2437: train loss 0.33064. lr 3.692269e-04:  85%|████████▌ | 2438/2863 [29:16<04:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2438: train loss 0.32413. lr 3.690666e-04:  85%|████████▌ | 2438/2863 [29:17<04:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2438: train loss 0.32413. lr 3.690666e-04:  85%|████████▌ | 2439/2863 [29:17<04:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2439: train loss 0.34005. lr 3.689064e-04:  85%|████████▌ | 2439/2863 [29:18<04:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2439: train loss 0.34005. lr 3.689064e-04:  85%|████████▌ | 2440/2863 [29:18<04:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2440: train loss 0.33484. lr 3.687461e-04:  85%|████████▌ | 2440/2863 [29:18<04:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2440: train loss 0.33484. lr 3.687461e-04:  85%|████████▌ | 2441/2863 [29:18<04:50,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2441: train loss 0.33395. lr 3.685859e-04:  85%|████████▌ | 2441/2863 [29:19<04:50,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2441: train loss 0.33395. lr 3.685859e-04:  85%|████████▌ | 2442/2863 [29:19<04:49,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2442: train loss 0.32768. lr 3.684256e-04:  85%|████████▌ | 2442/2863 [29:20<04:49,  1.46it/s]\u001b[A\n",
      "epoch 1 iter 2442: train loss 0.32768. lr 3.684256e-04:  85%|████████▌ | 2443/2863 [29:20<04:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2443: train loss 0.33863. lr 3.682653e-04:  85%|████████▌ | 2443/2863 [29:20<04:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2443: train loss 0.33863. lr 3.682653e-04:  85%|████████▌ | 2444/2863 [29:20<04:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2444: train loss 0.32483. lr 3.681049e-04:  85%|████████▌ | 2444/2863 [29:21<04:49,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2444: train loss 0.32483. lr 3.681049e-04:  85%|████████▌ | 2445/2863 [29:21<04:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2445: train loss 0.33304. lr 3.679446e-04:  85%|████████▌ | 2445/2863 [29:22<04:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2445: train loss 0.33304. lr 3.679446e-04:  85%|████████▌ | 2446/2863 [29:22<04:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2446: train loss 0.32295. lr 3.677842e-04:  85%|████████▌ | 2446/2863 [29:22<04:48,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2446: train loss 0.32295. lr 3.677842e-04:  85%|████████▌ | 2447/2863 [29:22<04:48,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2447: train loss 0.33921. lr 3.676238e-04:  85%|████████▌ | 2447/2863 [29:23<04:48,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2447: train loss 0.33921. lr 3.676238e-04:  86%|████████▌ | 2448/2863 [29:23<04:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2448: train loss 0.33241. lr 3.674634e-04:  86%|████████▌ | 2448/2863 [29:24<04:47,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2448: train loss 0.33241. lr 3.674634e-04:  86%|████████▌ | 2449/2863 [29:24<04:45,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2449: train loss 0.33548. lr 3.673029e-04:  86%|████████▌ | 2449/2863 [29:25<04:45,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2449: train loss 0.33548. lr 3.673029e-04:  86%|████████▌ | 2450/2863 [29:25<05:02,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2450: train loss 0.33091. lr 3.671425e-04:  86%|████████▌ | 2450/2863 [29:25<05:02,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2450: train loss 0.33091. lr 3.671425e-04:  86%|████████▌ | 2451/2863 [29:25<04:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2451: train loss 0.33140. lr 3.669820e-04:  86%|████████▌ | 2451/2863 [29:26<04:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2451: train loss 0.33140. lr 3.669820e-04:  86%|████████▌ | 2452/2863 [29:26<04:52,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2452: train loss 0.33521. lr 3.668215e-04:  86%|████████▌ | 2452/2863 [29:27<04:52,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2452: train loss 0.33521. lr 3.668215e-04:  86%|████████▌ | 2453/2863 [29:27<04:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2453: train loss 0.33396. lr 3.666610e-04:  86%|████████▌ | 2453/2863 [29:27<04:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2453: train loss 0.33396. lr 3.666610e-04:  86%|████████▌ | 2454/2863 [29:27<04:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2454: train loss 0.32656. lr 3.665004e-04:  86%|████████▌ | 2454/2863 [29:28<04:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2454: train loss 0.32656. lr 3.665004e-04:  86%|████████▌ | 2455/2863 [29:28<04:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2455: train loss 0.33391. lr 3.663399e-04:  86%|████████▌ | 2455/2863 [29:29<04:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2455: train loss 0.33391. lr 3.663399e-04:  86%|████████▌ | 2456/2863 [29:29<04:54,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2456: train loss 0.33968. lr 3.661793e-04:  86%|████████▌ | 2456/2863 [29:30<04:54,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2456: train loss 0.33968. lr 3.661793e-04:  86%|████████▌ | 2457/2863 [29:30<04:52,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2457: train loss 0.33008. lr 3.660187e-04:  86%|████████▌ | 2457/2863 [29:30<04:52,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2457: train loss 0.33008. lr 3.660187e-04:  86%|████████▌ | 2458/2863 [29:30<04:51,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2458: train loss 0.31585. lr 3.658581e-04:  86%|████████▌ | 2458/2863 [29:31<04:51,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2458: train loss 0.31585. lr 3.658581e-04:  86%|████████▌ | 2459/2863 [29:31<04:49,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2459: train loss 0.32857. lr 3.656974e-04:  86%|████████▌ | 2459/2863 [29:32<04:49,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2459: train loss 0.32857. lr 3.656974e-04:  86%|████████▌ | 2460/2863 [29:32<04:47,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2460: train loss 0.33389. lr 3.655368e-04:  86%|████████▌ | 2460/2863 [29:32<04:47,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2460: train loss 0.33389. lr 3.655368e-04:  86%|████████▌ | 2461/2863 [29:32<04:53,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2461: train loss 0.32554. lr 3.653761e-04:  86%|████████▌ | 2461/2863 [29:33<04:53,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2461: train loss 0.32554. lr 3.653761e-04:  86%|████████▌ | 2462/2863 [29:33<04:49,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2462: train loss 0.32886. lr 3.652154e-04:  86%|████████▌ | 2462/2863 [29:34<04:49,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2462: train loss 0.32886. lr 3.652154e-04:  86%|████████▌ | 2463/2863 [29:34<04:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2463: train loss 0.32633. lr 3.650547e-04:  86%|████████▌ | 2463/2863 [29:35<04:44,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2463: train loss 0.32633. lr 3.650547e-04:  86%|████████▌ | 2464/2863 [29:35<04:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2464: train loss 0.32648. lr 3.648939e-04:  86%|████████▌ | 2464/2863 [29:35<04:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2464: train loss 0.32648. lr 3.648939e-04:  86%|████████▌ | 2465/2863 [29:35<04:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2465: train loss 0.33393. lr 3.647332e-04:  86%|████████▌ | 2465/2863 [29:36<04:38,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2465: train loss 0.33393. lr 3.647332e-04:  86%|████████▌ | 2466/2863 [29:36<04:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2466: train loss 0.33042. lr 3.645724e-04:  86%|████████▌ | 2466/2863 [29:37<04:36,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2466: train loss 0.33042. lr 3.645724e-04:  86%|████████▌ | 2467/2863 [29:37<04:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2467: train loss 0.33731. lr 3.644116e-04:  86%|████████▌ | 2467/2863 [29:37<04:35,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2467: train loss 0.33731. lr 3.644116e-04:  86%|████████▌ | 2468/2863 [29:37<04:43,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2468: train loss 0.32902. lr 3.642508e-04:  86%|████████▌ | 2468/2863 [29:38<04:43,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2468: train loss 0.32902. lr 3.642508e-04:  86%|████████▌ | 2469/2863 [29:38<04:40,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2469: train loss 0.32105. lr 3.640899e-04:  86%|████████▌ | 2469/2863 [29:39<04:40,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2469: train loss 0.32105. lr 3.640899e-04:  86%|████████▋ | 2470/2863 [29:39<04:36,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2470: train loss 0.32606. lr 3.639291e-04:  86%|████████▋ | 2470/2863 [29:39<04:36,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2470: train loss 0.32606. lr 3.639291e-04:  86%|████████▋ | 2471/2863 [29:39<04:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2471: train loss 0.34021. lr 3.637682e-04:  86%|████████▋ | 2471/2863 [29:40<04:34,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2471: train loss 0.34021. lr 3.637682e-04:  86%|████████▋ | 2472/2863 [29:40<04:32,  1.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2472: train loss 0.32308. lr 3.636073e-04:  86%|████████▋ | 2472/2863 [29:41<04:32,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2472: train loss 0.32308. lr 3.636073e-04:  86%|████████▋ | 2473/2863 [29:41<04:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2473: train loss 0.32588. lr 3.634464e-04:  86%|████████▋ | 2473/2863 [29:41<04:30,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2473: train loss 0.32588. lr 3.634464e-04:  86%|████████▋ | 2474/2863 [29:41<04:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2474: train loss 0.32634. lr 3.632855e-04:  86%|████████▋ | 2474/2863 [29:42<04:29,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2474: train loss 0.32634. lr 3.632855e-04:  86%|████████▋ | 2475/2863 [29:42<04:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2475: train loss 0.33144. lr 3.631245e-04:  86%|████████▋ | 2475/2863 [29:43<04:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2475: train loss 0.33144. lr 3.631245e-04:  86%|████████▋ | 2476/2863 [29:43<04:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2476: train loss 0.33241. lr 3.629636e-04:  86%|████████▋ | 2476/2863 [29:44<04:28,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2476: train loss 0.33241. lr 3.629636e-04:  87%|████████▋ | 2477/2863 [29:44<04:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2477: train loss 0.32974. lr 3.628026e-04:  87%|████████▋ | 2477/2863 [29:44<04:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2477: train loss 0.32974. lr 3.628026e-04:  87%|████████▋ | 2478/2863 [29:44<04:43,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2478: train loss 0.31893. lr 3.626416e-04:  87%|████████▋ | 2478/2863 [29:45<04:43,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2478: train loss 0.31893. lr 3.626416e-04:  87%|████████▋ | 2479/2863 [29:45<04:37,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2479: train loss 0.33864. lr 3.624805e-04:  87%|████████▋ | 2479/2863 [29:46<04:37,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2479: train loss 0.33864. lr 3.624805e-04:  87%|████████▋ | 2480/2863 [29:46<04:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2480: train loss 0.32870. lr 3.623195e-04:  87%|████████▋ | 2480/2863 [29:47<04:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2480: train loss 0.32870. lr 3.623195e-04:  87%|████████▋ | 2481/2863 [29:47<04:31,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2481: train loss 0.32175. lr 3.621584e-04:  87%|████████▋ | 2481/2863 [29:47<04:31,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2481: train loss 0.32175. lr 3.621584e-04:  87%|████████▋ | 2482/2863 [29:47<04:29,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2482: train loss 0.33469. lr 3.619973e-04:  87%|████████▋ | 2482/2863 [29:48<04:29,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2482: train loss 0.33469. lr 3.619973e-04:  87%|████████▋ | 2483/2863 [29:48<04:27,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2483: train loss 0.32661. lr 3.618362e-04:  87%|████████▋ | 2483/2863 [29:49<04:27,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2483: train loss 0.32661. lr 3.618362e-04:  87%|████████▋ | 2484/2863 [29:49<04:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2484: train loss 0.32423. lr 3.616751e-04:  87%|████████▋ | 2484/2863 [29:49<04:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2484: train loss 0.32423. lr 3.616751e-04:  87%|████████▋ | 2485/2863 [29:49<04:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2485: train loss 0.32220. lr 3.615140e-04:  87%|████████▋ | 2485/2863 [29:50<04:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2485: train loss 0.32220. lr 3.615140e-04:  87%|████████▋ | 2486/2863 [29:50<04:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2486: train loss 0.32376. lr 3.613528e-04:  87%|████████▋ | 2486/2863 [29:51<04:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2486: train loss 0.32376. lr 3.613528e-04:  87%|████████▋ | 2487/2863 [29:51<04:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2487: train loss 0.33006. lr 3.611916e-04:  87%|████████▋ | 2487/2863 [29:51<04:25,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2487: train loss 0.33006. lr 3.611916e-04:  87%|████████▋ | 2488/2863 [29:51<04:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2488: train loss 0.33305. lr 3.610305e-04:  87%|████████▋ | 2488/2863 [29:52<04:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2488: train loss 0.33305. lr 3.610305e-04:  87%|████████▋ | 2489/2863 [29:52<04:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2489: train loss 0.32493. lr 3.608692e-04:  87%|████████▋ | 2489/2863 [29:53<04:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2489: train loss 0.32493. lr 3.608692e-04:  87%|████████▋ | 2490/2863 [29:53<04:30,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2490: train loss 0.33409. lr 3.607080e-04:  87%|████████▋ | 2490/2863 [29:54<04:30,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2490: train loss 0.33409. lr 3.607080e-04:  87%|████████▋ | 2491/2863 [29:54<04:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2491: train loss 0.33139. lr 3.605468e-04:  87%|████████▋ | 2491/2863 [29:54<04:35,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2491: train loss 0.33139. lr 3.605468e-04:  87%|████████▋ | 2492/2863 [29:54<04:38,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2492: train loss 0.31920. lr 3.603855e-04:  87%|████████▋ | 2492/2863 [29:55<04:38,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2492: train loss 0.31920. lr 3.603855e-04:  87%|████████▋ | 2493/2863 [29:55<04:40,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2493: train loss 0.31716. lr 3.602242e-04:  87%|████████▋ | 2493/2863 [29:56<04:40,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2493: train loss 0.31716. lr 3.602242e-04:  87%|████████▋ | 2494/2863 [29:56<04:42,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2494: train loss 0.31423. lr 3.600629e-04:  87%|████████▋ | 2494/2863 [29:57<04:42,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2494: train loss 0.31423. lr 3.600629e-04:  87%|████████▋ | 2495/2863 [29:57<04:41,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2495: train loss 0.32316. lr 3.599016e-04:  87%|████████▋ | 2495/2863 [29:58<04:41,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2495: train loss 0.32316. lr 3.599016e-04:  87%|████████▋ | 2496/2863 [29:58<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2496: train loss 0.31424. lr 3.597402e-04:  87%|████████▋ | 2496/2863 [29:58<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2496: train loss 0.31424. lr 3.597402e-04:  87%|████████▋ | 2497/2863 [29:58<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2497: train loss 0.34005. lr 3.595789e-04:  87%|████████▋ | 2497/2863 [29:59<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2497: train loss 0.34005. lr 3.595789e-04:  87%|████████▋ | 2498/2863 [29:59<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2498: train loss 0.32079. lr 3.594175e-04:  87%|████████▋ | 2498/2863 [30:00<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2498: train loss 0.32079. lr 3.594175e-04:  87%|████████▋ | 2499/2863 [30:00<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2499: train loss 0.31696. lr 3.592561e-04:  87%|████████▋ | 2499/2863 [30:01<04:41,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2499: train loss 0.31696. lr 3.592561e-04:  87%|████████▋ | 2500/2863 [30:01<04:40,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2500: train loss 0.32367. lr 3.590947e-04:  87%|████████▋ | 2500/2863 [30:01<04:40,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2500: train loss 0.32367. lr 3.590947e-04:  87%|████████▋ | 2501/2863 [30:01<04:38,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2501: train loss 0.32799. lr 3.589333e-04:  87%|████████▋ | 2501/2863 [30:02<04:38,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2501: train loss 0.32799. lr 3.589333e-04:  87%|████████▋ | 2502/2863 [30:02<04:38,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2502: train loss 0.33230. lr 3.587718e-04:  87%|████████▋ | 2502/2863 [30:03<04:38,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2502: train loss 0.33230. lr 3.587718e-04:  87%|████████▋ | 2503/2863 [30:03<04:39,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2503: train loss 0.33610. lr 3.586104e-04:  87%|████████▋ | 2503/2863 [30:04<04:39,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2503: train loss 0.33610. lr 3.586104e-04:  87%|████████▋ | 2504/2863 [30:04<04:38,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2504: train loss 0.32402. lr 3.584489e-04:  87%|████████▋ | 2504/2863 [30:05<04:38,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2504: train loss 0.32402. lr 3.584489e-04:  87%|████████▋ | 2505/2863 [30:05<04:37,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2505: train loss 0.32746. lr 3.582874e-04:  87%|████████▋ | 2505/2863 [30:05<04:37,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2505: train loss 0.32746. lr 3.582874e-04:  88%|████████▊ | 2506/2863 [30:05<04:49,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2506: train loss 0.33429. lr 3.581259e-04:  88%|████████▊ | 2506/2863 [30:06<04:49,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2506: train loss 0.33429. lr 3.581259e-04:  88%|████████▊ | 2507/2863 [30:06<04:44,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2507: train loss 0.32858. lr 3.579643e-04:  88%|████████▊ | 2507/2863 [30:07<04:44,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2507: train loss 0.32858. lr 3.579643e-04:  88%|████████▊ | 2508/2863 [30:07<04:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2508: train loss 0.33082. lr 3.578028e-04:  88%|████████▊ | 2508/2863 [30:08<04:41,  1.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2508: train loss 0.33082. lr 3.578028e-04:  88%|████████▊ | 2509/2863 [30:08<04:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2509: train loss 0.32306. lr 3.576412e-04:  88%|████████▊ | 2509/2863 [30:09<04:39,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2509: train loss 0.32306. lr 3.576412e-04:  88%|████████▊ | 2510/2863 [30:09<04:38,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2510: train loss 0.31217. lr 3.574796e-04:  88%|████████▊ | 2510/2863 [30:09<04:38,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2510: train loss 0.31217. lr 3.574796e-04:  88%|████████▊ | 2511/2863 [30:09<04:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2511: train loss 0.32809. lr 3.573180e-04:  88%|████████▊ | 2511/2863 [30:10<04:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2511: train loss 0.32809. lr 3.573180e-04:  88%|████████▊ | 2512/2863 [30:10<04:34,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2512: train loss 0.31155. lr 3.571564e-04:  88%|████████▊ | 2512/2863 [30:11<04:34,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2512: train loss 0.31155. lr 3.571564e-04:  88%|████████▊ | 2513/2863 [30:11<04:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2513: train loss 0.33008. lr 3.569947e-04:  88%|████████▊ | 2513/2863 [30:12<04:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2513: train loss 0.33008. lr 3.569947e-04:  88%|████████▊ | 2514/2863 [30:12<04:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2514: train loss 0.32353. lr 3.568331e-04:  88%|████████▊ | 2514/2863 [30:12<04:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2514: train loss 0.32353. lr 3.568331e-04:  88%|████████▊ | 2515/2863 [30:12<04:33,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2515: train loss 0.31776. lr 3.566714e-04:  88%|████████▊ | 2515/2863 [30:13<04:33,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2515: train loss 0.31776. lr 3.566714e-04:  88%|████████▊ | 2516/2863 [30:13<04:33,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2516: train loss 0.32096. lr 3.565097e-04:  88%|████████▊ | 2516/2863 [30:14<04:33,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2516: train loss 0.32096. lr 3.565097e-04:  88%|████████▊ | 2517/2863 [30:14<04:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2517: train loss 0.32898. lr 3.563480e-04:  88%|████████▊ | 2517/2863 [30:15<04:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2517: train loss 0.32898. lr 3.563480e-04:  88%|████████▊ | 2518/2863 [30:15<04:29,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2518: train loss 0.32774. lr 3.561863e-04:  88%|████████▊ | 2518/2863 [30:16<04:29,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2518: train loss 0.32774. lr 3.561863e-04:  88%|████████▊ | 2519/2863 [30:16<04:29,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2519: train loss 0.32013. lr 3.560246e-04:  88%|████████▊ | 2519/2863 [30:16<04:29,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2519: train loss 0.32013. lr 3.560246e-04:  88%|████████▊ | 2520/2863 [30:16<04:29,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2520: train loss 0.32817. lr 3.558628e-04:  88%|████████▊ | 2520/2863 [30:17<04:29,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2520: train loss 0.32817. lr 3.558628e-04:  88%|████████▊ | 2521/2863 [30:17<04:29,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2521: train loss 0.32048. lr 3.557010e-04:  88%|████████▊ | 2521/2863 [30:18<04:29,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2521: train loss 0.32048. lr 3.557010e-04:  88%|████████▊ | 2522/2863 [30:18<04:28,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2522: train loss 0.32727. lr 3.555392e-04:  88%|████████▊ | 2522/2863 [30:19<04:28,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2522: train loss 0.32727. lr 3.555392e-04:  88%|████████▊ | 2523/2863 [30:19<04:27,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2523: train loss 0.32055. lr 3.553774e-04:  88%|████████▊ | 2523/2863 [30:20<04:27,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2523: train loss 0.32055. lr 3.553774e-04:  88%|████████▊ | 2524/2863 [30:20<04:26,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2524: train loss 0.32173. lr 3.552156e-04:  88%|████████▊ | 2524/2863 [30:20<04:26,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2524: train loss 0.32173. lr 3.552156e-04:  88%|████████▊ | 2525/2863 [30:20<04:24,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2525: train loss 0.31839. lr 3.550537e-04:  88%|████████▊ | 2525/2863 [30:21<04:24,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2525: train loss 0.31839. lr 3.550537e-04:  88%|████████▊ | 2526/2863 [30:21<04:23,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2526: train loss 0.33357. lr 3.548919e-04:  88%|████████▊ | 2526/2863 [30:22<04:23,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2526: train loss 0.33357. lr 3.548919e-04:  88%|████████▊ | 2527/2863 [30:22<04:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2527: train loss 0.32540. lr 3.547300e-04:  88%|████████▊ | 2527/2863 [30:23<04:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2527: train loss 0.32540. lr 3.547300e-04:  88%|████████▊ | 2528/2863 [30:23<04:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2528: train loss 0.31382. lr 3.545681e-04:  88%|████████▊ | 2528/2863 [30:23<04:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2528: train loss 0.31382. lr 3.545681e-04:  88%|████████▊ | 2529/2863 [30:23<04:22,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2529: train loss 0.32025. lr 3.544062e-04:  88%|████████▊ | 2529/2863 [30:24<04:22,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2529: train loss 0.32025. lr 3.544062e-04:  88%|████████▊ | 2530/2863 [30:24<04:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2530: train loss 0.32868. lr 3.542443e-04:  88%|████████▊ | 2530/2863 [30:25<04:23,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2530: train loss 0.32868. lr 3.542443e-04:  88%|████████▊ | 2531/2863 [30:25<04:21,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2531: train loss 0.31823. lr 3.540824e-04:  88%|████████▊ | 2531/2863 [30:26<04:21,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2531: train loss 0.31823. lr 3.540824e-04:  88%|████████▊ | 2532/2863 [30:26<04:21,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2532: train loss 0.32857. lr 3.539204e-04:  88%|████████▊ | 2532/2863 [30:27<04:21,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2532: train loss 0.32857. lr 3.539204e-04:  88%|████████▊ | 2533/2863 [30:27<04:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2533: train loss 0.32022. lr 3.537584e-04:  88%|████████▊ | 2533/2863 [30:27<04:19,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2533: train loss 0.32022. lr 3.537584e-04:  89%|████████▊ | 2534/2863 [30:27<04:30,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 2534: train loss 0.32110. lr 3.535964e-04:  89%|████████▊ | 2534/2863 [30:28<04:30,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 2534: train loss 0.32110. lr 3.535964e-04:  89%|████████▊ | 2535/2863 [30:28<04:26,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2535: train loss 0.31181. lr 3.534344e-04:  89%|████████▊ | 2535/2863 [30:29<04:26,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2535: train loss 0.31181. lr 3.534344e-04:  89%|████████▊ | 2536/2863 [30:29<04:23,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2536: train loss 0.32269. lr 3.532724e-04:  89%|████████▊ | 2536/2863 [30:30<04:23,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2536: train loss 0.32269. lr 3.532724e-04:  89%|████████▊ | 2537/2863 [30:30<04:21,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2537: train loss 0.32721. lr 3.531104e-04:  89%|████████▊ | 2537/2863 [30:31<04:21,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2537: train loss 0.32721. lr 3.531104e-04:  89%|████████▊ | 2538/2863 [30:31<04:19,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2538: train loss 0.33257. lr 3.529483e-04:  89%|████████▊ | 2538/2863 [30:31<04:19,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2538: train loss 0.33257. lr 3.529483e-04:  89%|████████▊ | 2539/2863 [30:31<04:17,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2539: train loss 0.32656. lr 3.527862e-04:  89%|████████▊ | 2539/2863 [30:32<04:17,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2539: train loss 0.32656. lr 3.527862e-04:  89%|████████▊ | 2540/2863 [30:32<04:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2540: train loss 0.31508. lr 3.526242e-04:  89%|████████▊ | 2540/2863 [30:33<04:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2540: train loss 0.31508. lr 3.526242e-04:  89%|████████▉ | 2541/2863 [30:33<04:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2541: train loss 0.32193. lr 3.524621e-04:  89%|████████▉ | 2541/2863 [30:34<04:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2541: train loss 0.32193. lr 3.524621e-04:  89%|████████▉ | 2542/2863 [30:34<04:14,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2542: train loss 0.31581. lr 3.522999e-04:  89%|████████▉ | 2542/2863 [30:35<04:14,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2542: train loss 0.31581. lr 3.522999e-04:  89%|████████▉ | 2543/2863 [30:35<04:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2543: train loss 0.31225. lr 3.521378e-04:  89%|████████▉ | 2543/2863 [30:35<04:13,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2543: train loss 0.31225. lr 3.521378e-04:  89%|████████▉ | 2544/2863 [30:35<04:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2544: train loss 0.32264. lr 3.519757e-04:  89%|████████▉ | 2544/2863 [30:36<04:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2544: train loss 0.32264. lr 3.519757e-04:  89%|████████▉ | 2545/2863 [30:36<04:12,  1.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2545: train loss 0.31083. lr 3.518135e-04:  89%|████████▉ | 2545/2863 [30:37<04:12,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2545: train loss 0.31083. lr 3.518135e-04:  89%|████████▉ | 2546/2863 [30:37<04:11,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2546: train loss 0.32598. lr 3.516513e-04:  89%|████████▉ | 2546/2863 [30:38<04:11,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2546: train loss 0.32598. lr 3.516513e-04:  89%|████████▉ | 2547/2863 [30:38<04:09,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2547: train loss 0.30646. lr 3.514891e-04:  89%|████████▉ | 2547/2863 [30:39<04:09,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2547: train loss 0.30646. lr 3.514891e-04:  89%|████████▉ | 2548/2863 [30:39<04:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2548: train loss 0.30446. lr 3.513269e-04:  89%|████████▉ | 2548/2863 [30:39<04:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2548: train loss 0.30446. lr 3.513269e-04:  89%|████████▉ | 2549/2863 [30:39<04:05,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2549: train loss 0.31932. lr 3.511647e-04:  89%|████████▉ | 2549/2863 [30:40<04:05,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2549: train loss 0.31932. lr 3.511647e-04:  89%|████████▉ | 2550/2863 [30:40<04:05,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2550: train loss 0.31847. lr 3.510024e-04:  89%|████████▉ | 2550/2863 [30:41<04:05,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2550: train loss 0.31847. lr 3.510024e-04:  89%|████████▉ | 2551/2863 [30:41<04:07,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2551: train loss 0.31479. lr 3.508402e-04:  89%|████████▉ | 2551/2863 [30:42<04:07,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2551: train loss 0.31479. lr 3.508402e-04:  89%|████████▉ | 2552/2863 [30:42<04:06,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2552: train loss 0.31972. lr 3.506779e-04:  89%|████████▉ | 2552/2863 [30:43<04:06,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2552: train loss 0.31972. lr 3.506779e-04:  89%|████████▉ | 2553/2863 [30:43<04:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2553: train loss 0.32100. lr 3.505156e-04:  89%|████████▉ | 2553/2863 [30:43<04:05,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2553: train loss 0.32100. lr 3.505156e-04:  89%|████████▉ | 2554/2863 [30:43<04:04,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2554: train loss 0.32444. lr 3.503533e-04:  89%|████████▉ | 2554/2863 [30:44<04:04,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2554: train loss 0.32444. lr 3.503533e-04:  89%|████████▉ | 2555/2863 [30:44<04:02,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2555: train loss 0.31384. lr 3.501910e-04:  89%|████████▉ | 2555/2863 [30:45<04:02,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2555: train loss 0.31384. lr 3.501910e-04:  89%|████████▉ | 2556/2863 [30:45<04:01,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2556: train loss 0.31214. lr 3.500287e-04:  89%|████████▉ | 2556/2863 [30:46<04:01,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2556: train loss 0.31214. lr 3.500287e-04:  89%|████████▉ | 2557/2863 [30:46<04:00,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2557: train loss 0.31705. lr 3.498663e-04:  89%|████████▉ | 2557/2863 [30:46<04:00,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2557: train loss 0.31705. lr 3.498663e-04:  89%|████████▉ | 2558/2863 [30:46<04:01,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2558: train loss 0.31762. lr 3.497040e-04:  89%|████████▉ | 2558/2863 [30:47<04:01,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2558: train loss 0.31762. lr 3.497040e-04:  89%|████████▉ | 2559/2863 [30:47<04:01,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2559: train loss 0.32714. lr 3.495416e-04:  89%|████████▉ | 2559/2863 [30:48<04:01,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2559: train loss 0.32714. lr 3.495416e-04:  89%|████████▉ | 2560/2863 [30:48<04:00,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2560: train loss 0.31367. lr 3.493792e-04:  89%|████████▉ | 2560/2863 [30:49<04:00,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2560: train loss 0.31367. lr 3.493792e-04:  89%|████████▉ | 2561/2863 [30:49<03:58,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2561: train loss 0.31634. lr 3.492168e-04:  89%|████████▉ | 2561/2863 [30:50<03:58,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2561: train loss 0.31634. lr 3.492168e-04:  89%|████████▉ | 2562/2863 [30:50<04:08,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 2562: train loss 0.31363. lr 3.490543e-04:  89%|████████▉ | 2562/2863 [30:51<04:08,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 2562: train loss 0.31363. lr 3.490543e-04:  90%|████████▉ | 2563/2863 [30:51<04:04,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2563: train loss 0.30703. lr 3.488919e-04:  90%|████████▉ | 2563/2863 [30:51<04:04,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2563: train loss 0.30703. lr 3.488919e-04:  90%|████████▉ | 2564/2863 [30:51<04:01,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2564: train loss 0.30612. lr 3.487295e-04:  90%|████████▉ | 2564/2863 [30:52<04:01,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2564: train loss 0.30612. lr 3.487295e-04:  90%|████████▉ | 2565/2863 [30:52<03:57,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2565: train loss 0.31992. lr 3.485670e-04:  90%|████████▉ | 2565/2863 [30:53<03:57,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2565: train loss 0.31992. lr 3.485670e-04:  90%|████████▉ | 2566/2863 [30:53<03:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2566: train loss 0.32442. lr 3.484045e-04:  90%|████████▉ | 2566/2863 [30:54<03:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2566: train loss 0.32442. lr 3.484045e-04:  90%|████████▉ | 2567/2863 [30:54<03:56,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2567: train loss 0.31189. lr 3.482420e-04:  90%|████████▉ | 2567/2863 [30:54<03:56,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2567: train loss 0.31189. lr 3.482420e-04:  90%|████████▉ | 2568/2863 [30:54<03:55,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2568: train loss 0.31907. lr 3.480795e-04:  90%|████████▉ | 2568/2863 [30:55<03:55,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2568: train loss 0.31907. lr 3.480795e-04:  90%|████████▉ | 2569/2863 [30:55<03:54,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2569: train loss 0.31536. lr 3.479170e-04:  90%|████████▉ | 2569/2863 [30:56<03:54,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2569: train loss 0.31536. lr 3.479170e-04:  90%|████████▉ | 2570/2863 [30:56<03:53,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2570: train loss 0.31000. lr 3.477544e-04:  90%|████████▉ | 2570/2863 [30:57<03:53,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2570: train loss 0.31000. lr 3.477544e-04:  90%|████████▉ | 2571/2863 [30:57<03:52,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2571: train loss 0.31090. lr 3.475919e-04:  90%|████████▉ | 2571/2863 [30:58<03:52,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2571: train loss 0.31090. lr 3.475919e-04:  90%|████████▉ | 2572/2863 [30:58<03:53,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2572: train loss 0.32174. lr 3.474293e-04:  90%|████████▉ | 2572/2863 [30:58<03:53,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2572: train loss 0.32174. lr 3.474293e-04:  90%|████████▉ | 2573/2863 [30:58<03:51,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2573: train loss 0.30637. lr 3.472667e-04:  90%|████████▉ | 2573/2863 [30:59<03:51,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2573: train loss 0.30637. lr 3.472667e-04:  90%|████████▉ | 2574/2863 [30:59<03:50,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2574: train loss 0.31347. lr 3.471041e-04:  90%|████████▉ | 2574/2863 [31:00<03:50,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2574: train loss 0.31347. lr 3.471041e-04:  90%|████████▉ | 2575/2863 [31:00<03:49,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2575: train loss 0.32251. lr 3.469415e-04:  90%|████████▉ | 2575/2863 [31:01<03:49,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2575: train loss 0.32251. lr 3.469415e-04:  90%|████████▉ | 2576/2863 [31:01<03:47,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2576: train loss 0.31385. lr 3.467789e-04:  90%|████████▉ | 2576/2863 [31:02<03:47,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2576: train loss 0.31385. lr 3.467789e-04:  90%|█████████ | 2577/2863 [31:02<03:47,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2577: train loss 0.31644. lr 3.466163e-04:  90%|█████████ | 2577/2863 [31:02<03:47,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2577: train loss 0.31644. lr 3.466163e-04:  90%|█████████ | 2578/2863 [31:02<03:46,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2578: train loss 0.31698. lr 3.464536e-04:  90%|█████████ | 2578/2863 [31:03<03:46,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2578: train loss 0.31698. lr 3.464536e-04:  90%|█████████ | 2579/2863 [31:03<03:46,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2579: train loss 0.31495. lr 3.462909e-04:  90%|█████████ | 2579/2863 [31:04<03:46,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2579: train loss 0.31495. lr 3.462909e-04:  90%|█████████ | 2580/2863 [31:04<03:45,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2580: train loss 0.30596. lr 3.461283e-04:  90%|█████████ | 2580/2863 [31:05<03:45,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2580: train loss 0.30596. lr 3.461283e-04:  90%|█████████ | 2581/2863 [31:05<03:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2581: train loss 0.31857. lr 3.459656e-04:  90%|█████████ | 2581/2863 [31:06<03:44,  1.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2581: train loss 0.31857. lr 3.459656e-04:  90%|█████████ | 2582/2863 [31:06<03:42,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2582: train loss 0.31953. lr 3.458028e-04:  90%|█████████ | 2582/2863 [31:06<03:42,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2582: train loss 0.31953. lr 3.458028e-04:  90%|█████████ | 2583/2863 [31:06<03:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2583: train loss 0.31177. lr 3.456401e-04:  90%|█████████ | 2583/2863 [31:07<03:41,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2583: train loss 0.31177. lr 3.456401e-04:  90%|█████████ | 2584/2863 [31:07<03:40,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2584: train loss 0.32451. lr 3.454774e-04:  90%|█████████ | 2584/2863 [31:08<03:40,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2584: train loss 0.32451. lr 3.454774e-04:  90%|█████████ | 2585/2863 [31:08<03:42,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2585: train loss 0.30785. lr 3.453146e-04:  90%|█████████ | 2585/2863 [31:09<03:42,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2585: train loss 0.30785. lr 3.453146e-04:  90%|█████████ | 2586/2863 [31:09<03:40,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2586: train loss 0.30933. lr 3.451519e-04:  90%|█████████ | 2586/2863 [31:10<03:40,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2586: train loss 0.30933. lr 3.451519e-04:  90%|█████████ | 2587/2863 [31:10<03:39,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2587: train loss 0.31302. lr 3.449891e-04:  90%|█████████ | 2587/2863 [31:10<03:39,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2587: train loss 0.31302. lr 3.449891e-04:  90%|█████████ | 2588/2863 [31:10<03:38,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2588: train loss 0.29820. lr 3.448263e-04:  90%|█████████ | 2588/2863 [31:11<03:38,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2588: train loss 0.29820. lr 3.448263e-04:  90%|█████████ | 2589/2863 [31:11<03:38,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2589: train loss 0.29859. lr 3.446635e-04:  90%|█████████ | 2589/2863 [31:12<03:38,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2589: train loss 0.29859. lr 3.446635e-04:  90%|█████████ | 2590/2863 [31:12<03:45,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 2590: train loss 0.32131. lr 3.445007e-04:  90%|█████████ | 2590/2863 [31:13<03:45,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 2590: train loss 0.32131. lr 3.445007e-04:  90%|█████████ | 2591/2863 [31:13<03:41,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2591: train loss 0.29956. lr 3.443378e-04:  90%|█████████ | 2591/2863 [31:14<03:41,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2591: train loss 0.29956. lr 3.443378e-04:  91%|█████████ | 2592/2863 [31:14<03:38,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2592: train loss 0.30182. lr 3.441750e-04:  91%|█████████ | 2592/2863 [31:14<03:38,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2592: train loss 0.30182. lr 3.441750e-04:  91%|█████████ | 2593/2863 [31:14<03:35,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2593: train loss 0.31168. lr 3.440121e-04:  91%|█████████ | 2593/2863 [31:15<03:35,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2593: train loss 0.31168. lr 3.440121e-04:  91%|█████████ | 2594/2863 [31:15<03:33,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2594: train loss 0.30635. lr 3.438493e-04:  91%|█████████ | 2594/2863 [31:16<03:33,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2594: train loss 0.30635. lr 3.438493e-04:  91%|█████████ | 2595/2863 [31:16<03:32,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2595: train loss 0.31816. lr 3.436864e-04:  91%|█████████ | 2595/2863 [31:17<03:32,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2595: train loss 0.31816. lr 3.436864e-04:  91%|█████████ | 2596/2863 [31:17<03:32,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2596: train loss 0.30186. lr 3.435235e-04:  91%|█████████ | 2596/2863 [31:18<03:32,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2596: train loss 0.30186. lr 3.435235e-04:  91%|█████████ | 2597/2863 [31:18<03:31,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2597: train loss 0.30700. lr 3.433606e-04:  91%|█████████ | 2597/2863 [31:18<03:31,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2597: train loss 0.30700. lr 3.433606e-04:  91%|█████████ | 2598/2863 [31:18<03:25,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2598: train loss 0.31672. lr 3.431977e-04:  91%|█████████ | 2598/2863 [31:19<03:25,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2598: train loss 0.31672. lr 3.431977e-04:  91%|█████████ | 2599/2863 [31:19<03:19,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2599: train loss 0.31798. lr 3.430347e-04:  91%|█████████ | 2599/2863 [31:20<03:19,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2599: train loss 0.31798. lr 3.430347e-04:  91%|█████████ | 2600/2863 [31:20<03:14,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2600: train loss 0.30066. lr 3.428718e-04:  91%|█████████ | 2600/2863 [31:20<03:14,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2600: train loss 0.30066. lr 3.428718e-04:  91%|█████████ | 2601/2863 [31:20<03:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2601: train loss 0.30897. lr 3.427088e-04:  91%|█████████ | 2601/2863 [31:21<03:09,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2601: train loss 0.30897. lr 3.427088e-04:  91%|█████████ | 2602/2863 [31:21<03:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2602: train loss 0.31581. lr 3.425458e-04:  91%|█████████ | 2602/2863 [31:22<03:06,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2602: train loss 0.31581. lr 3.425458e-04:  91%|█████████ | 2603/2863 [31:22<03:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2603: train loss 0.31757. lr 3.423828e-04:  91%|█████████ | 2603/2863 [31:22<03:03,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2603: train loss 0.31757. lr 3.423828e-04:  91%|█████████ | 2604/2863 [31:22<03:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2604: train loss 0.31678. lr 3.422198e-04:  91%|█████████ | 2604/2863 [31:23<03:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2604: train loss 0.31678. lr 3.422198e-04:  91%|█████████ | 2605/2863 [31:23<02:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2605: train loss 0.32536. lr 3.420568e-04:  91%|█████████ | 2605/2863 [31:24<02:59,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2605: train loss 0.32536. lr 3.420568e-04:  91%|█████████ | 2606/2863 [31:24<02:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2606: train loss 0.31377. lr 3.418938e-04:  91%|█████████ | 2606/2863 [31:25<02:58,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2606: train loss 0.31377. lr 3.418938e-04:  91%|█████████ | 2607/2863 [31:25<02:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2607: train loss 0.30675. lr 3.417308e-04:  91%|█████████ | 2607/2863 [31:25<02:57,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2607: train loss 0.30675. lr 3.417308e-04:  91%|█████████ | 2608/2863 [31:25<02:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2608: train loss 0.32258. lr 3.415677e-04:  91%|█████████ | 2608/2863 [31:26<02:56,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2608: train loss 0.32258. lr 3.415677e-04:  91%|█████████ | 2609/2863 [31:26<02:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2609: train loss 0.31701. lr 3.414046e-04:  91%|█████████ | 2609/2863 [31:27<02:55,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2609: train loss 0.31701. lr 3.414046e-04:  91%|█████████ | 2610/2863 [31:27<02:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2610: train loss 0.30798. lr 3.412416e-04:  91%|█████████ | 2610/2863 [31:27<02:54,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2610: train loss 0.30798. lr 3.412416e-04:  91%|█████████ | 2611/2863 [31:27<02:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2611: train loss 0.31410. lr 3.410785e-04:  91%|█████████ | 2611/2863 [31:28<02:53,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2611: train loss 0.31410. lr 3.410785e-04:  91%|█████████ | 2612/2863 [31:28<02:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2612: train loss 0.30986. lr 3.409154e-04:  91%|█████████ | 2612/2863 [31:29<02:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2612: train loss 0.30986. lr 3.409154e-04:  91%|█████████▏| 2613/2863 [31:29<02:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2613: train loss 0.31176. lr 3.407523e-04:  91%|█████████▏| 2613/2863 [31:29<02:52,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2613: train loss 0.31176. lr 3.407523e-04:  91%|█████████▏| 2614/2863 [31:29<02:51,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2614: train loss 0.31009. lr 3.405891e-04:  91%|█████████▏| 2614/2863 [31:30<02:51,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2614: train loss 0.31009. lr 3.405891e-04:  91%|█████████▏| 2615/2863 [31:30<02:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2615: train loss 0.30658. lr 3.404260e-04:  91%|█████████▏| 2615/2863 [31:31<02:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2615: train loss 0.30658. lr 3.404260e-04:  91%|█████████▏| 2616/2863 [31:31<02:56,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2616: train loss 0.31534. lr 3.402628e-04:  91%|█████████▏| 2616/2863 [31:32<02:56,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2616: train loss 0.31534. lr 3.402628e-04:  91%|█████████▏| 2617/2863 [31:32<02:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2617: train loss 0.30346. lr 3.400997e-04:  91%|█████████▏| 2617/2863 [31:32<02:56,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2617: train loss 0.30346. lr 3.400997e-04:  91%|█████████▏| 2618/2863 [31:32<03:07,  1.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2618: train loss 0.31605. lr 3.399365e-04:  91%|█████████▏| 2618/2863 [31:33<03:07,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2618: train loss 0.31605. lr 3.399365e-04:  91%|█████████▏| 2619/2863 [31:33<03:03,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2619: train loss 0.31052. lr 3.397733e-04:  91%|█████████▏| 2619/2863 [31:34<03:03,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2619: train loss 0.31052. lr 3.397733e-04:  92%|█████████▏| 2620/2863 [31:34<02:59,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2620: train loss 0.30297. lr 3.396101e-04:  92%|█████████▏| 2620/2863 [31:35<02:59,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2620: train loss 0.30297. lr 3.396101e-04:  92%|█████████▏| 2621/2863 [31:35<02:55,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2621: train loss 0.30442. lr 3.394469e-04:  92%|█████████▏| 2621/2863 [31:35<02:55,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2621: train loss 0.30442. lr 3.394469e-04:  92%|█████████▏| 2622/2863 [31:35<02:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2622: train loss 0.31159. lr 3.392837e-04:  92%|█████████▏| 2622/2863 [31:36<02:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2622: train loss 0.31159. lr 3.392837e-04:  92%|█████████▏| 2623/2863 [31:36<02:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2623: train loss 0.30923. lr 3.391204e-04:  92%|█████████▏| 2623/2863 [31:37<02:49,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2623: train loss 0.30923. lr 3.391204e-04:  92%|█████████▏| 2624/2863 [31:37<02:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2624: train loss 0.30812. lr 3.389572e-04:  92%|█████████▏| 2624/2863 [31:37<02:48,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2624: train loss 0.30812. lr 3.389572e-04:  92%|█████████▏| 2625/2863 [31:37<02:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2625: train loss 0.29957. lr 3.387939e-04:  92%|█████████▏| 2625/2863 [31:38<02:46,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2625: train loss 0.29957. lr 3.387939e-04:  92%|█████████▏| 2626/2863 [31:38<02:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2626: train loss 0.32025. lr 3.386307e-04:  92%|█████████▏| 2626/2863 [31:39<02:45,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2626: train loss 0.32025. lr 3.386307e-04:  92%|█████████▏| 2627/2863 [31:39<02:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2627: train loss 0.29506. lr 3.384674e-04:  92%|█████████▏| 2627/2863 [31:39<02:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2627: train loss 0.29506. lr 3.384674e-04:  92%|█████████▏| 2628/2863 [31:39<02:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2628: train loss 0.30905. lr 3.383041e-04:  92%|█████████▏| 2628/2863 [31:40<02:43,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2628: train loss 0.30905. lr 3.383041e-04:  92%|█████████▏| 2629/2863 [31:40<02:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2629: train loss 0.30903. lr 3.381408e-04:  92%|█████████▏| 2629/2863 [31:41<02:41,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2629: train loss 0.30903. lr 3.381408e-04:  92%|█████████▏| 2630/2863 [31:41<02:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2630: train loss 0.30636. lr 3.379775e-04:  92%|█████████▏| 2630/2863 [31:41<02:40,  1.45it/s]\u001b[A\n",
      "epoch 1 iter 2630: train loss 0.30636. lr 3.379775e-04:  92%|█████████▏| 2631/2863 [31:41<02:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2631: train loss 0.29898. lr 3.378142e-04:  92%|█████████▏| 2631/2863 [31:42<02:40,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2631: train loss 0.29898. lr 3.378142e-04:  92%|█████████▏| 2632/2863 [31:42<02:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2632: train loss 0.30460. lr 3.376508e-04:  92%|█████████▏| 2632/2863 [31:43<02:41,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2632: train loss 0.30460. lr 3.376508e-04:  92%|█████████▏| 2633/2863 [31:43<02:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2633: train loss 0.30529. lr 3.374875e-04:  92%|█████████▏| 2633/2863 [31:44<02:42,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2633: train loss 0.30529. lr 3.374875e-04:  92%|█████████▏| 2634/2863 [31:44<02:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2634: train loss 0.30579. lr 3.373241e-04:  92%|█████████▏| 2634/2863 [31:44<02:41,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2634: train loss 0.30579. lr 3.373241e-04:  92%|█████████▏| 2635/2863 [31:44<02:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2635: train loss 0.30807. lr 3.371607e-04:  92%|█████████▏| 2635/2863 [31:45<02:41,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2635: train loss 0.30807. lr 3.371607e-04:  92%|█████████▏| 2636/2863 [31:45<02:42,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2636: train loss 0.31370. lr 3.369973e-04:  92%|█████████▏| 2636/2863 [31:46<02:42,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2636: train loss 0.31370. lr 3.369973e-04:  92%|█████████▏| 2637/2863 [31:46<02:43,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2637: train loss 0.30221. lr 3.368339e-04:  92%|█████████▏| 2637/2863 [31:47<02:43,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2637: train loss 0.30221. lr 3.368339e-04:  92%|█████████▏| 2638/2863 [31:47<02:42,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2638: train loss 0.30805. lr 3.366705e-04:  92%|█████████▏| 2638/2863 [31:47<02:42,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2638: train loss 0.30805. lr 3.366705e-04:  92%|█████████▏| 2639/2863 [31:47<02:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2639: train loss 0.29732. lr 3.365071e-04:  92%|█████████▏| 2639/2863 [31:48<02:41,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2639: train loss 0.29732. lr 3.365071e-04:  92%|█████████▏| 2640/2863 [31:48<02:40,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2640: train loss 0.30780. lr 3.363437e-04:  92%|█████████▏| 2640/2863 [31:49<02:40,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2640: train loss 0.30780. lr 3.363437e-04:  92%|█████████▏| 2641/2863 [31:49<02:39,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2641: train loss 0.30746. lr 3.361803e-04:  92%|█████████▏| 2641/2863 [31:49<02:39,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2641: train loss 0.30746. lr 3.361803e-04:  92%|█████████▏| 2642/2863 [31:49<02:37,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2642: train loss 0.30686. lr 3.360168e-04:  92%|█████████▏| 2642/2863 [31:50<02:37,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2642: train loss 0.30686. lr 3.360168e-04:  92%|█████████▏| 2643/2863 [31:50<02:36,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2643: train loss 0.30698. lr 3.358533e-04:  92%|█████████▏| 2643/2863 [31:51<02:36,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2643: train loss 0.30698. lr 3.358533e-04:  92%|█████████▏| 2644/2863 [31:51<02:34,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2644: train loss 0.29913. lr 3.356899e-04:  92%|█████████▏| 2644/2863 [31:51<02:34,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2644: train loss 0.29913. lr 3.356899e-04:  92%|█████████▏| 2645/2863 [31:51<02:33,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2645: train loss 0.30419. lr 3.355264e-04:  92%|█████████▏| 2645/2863 [31:52<02:33,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2645: train loss 0.30419. lr 3.355264e-04:  92%|█████████▏| 2646/2863 [31:52<02:39,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2646: train loss 0.30705. lr 3.353629e-04:  92%|█████████▏| 2646/2863 [31:53<02:39,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2646: train loss 0.30705. lr 3.353629e-04:  92%|█████████▏| 2647/2863 [31:53<02:36,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2647: train loss 0.30126. lr 3.351994e-04:  92%|█████████▏| 2647/2863 [31:54<02:36,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2647: train loss 0.30126. lr 3.351994e-04:  92%|█████████▏| 2648/2863 [31:54<02:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2648: train loss 0.28943. lr 3.350359e-04:  92%|█████████▏| 2648/2863 [31:54<02:33,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2648: train loss 0.28943. lr 3.350359e-04:  93%|█████████▎| 2649/2863 [31:54<02:31,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2649: train loss 0.31692. lr 3.348724e-04:  93%|█████████▎| 2649/2863 [31:55<02:31,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2649: train loss 0.31692. lr 3.348724e-04:  93%|█████████▎| 2650/2863 [31:55<02:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2650: train loss 0.29752. lr 3.347088e-04:  93%|█████████▎| 2650/2863 [31:56<02:29,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2650: train loss 0.29752. lr 3.347088e-04:  93%|█████████▎| 2651/2863 [31:56<02:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2651: train loss 0.31407. lr 3.345453e-04:  93%|█████████▎| 2651/2863 [31:56<02:27,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2651: train loss 0.31407. lr 3.345453e-04:  93%|█████████▎| 2652/2863 [31:56<02:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2652: train loss 0.30301. lr 3.343817e-04:  93%|█████████▎| 2652/2863 [31:57<02:28,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2652: train loss 0.30301. lr 3.343817e-04:  93%|█████████▎| 2653/2863 [31:57<02:31,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2653: train loss 0.29910. lr 3.342181e-04:  93%|█████████▎| 2653/2863 [31:58<02:31,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2653: train loss 0.29910. lr 3.342181e-04:  93%|█████████▎| 2654/2863 [31:58<02:32,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2654: train loss 0.31169. lr 3.340546e-04:  93%|█████████▎| 2654/2863 [31:59<02:32,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2654: train loss 0.31169. lr 3.340546e-04:  93%|█████████▎| 2655/2863 [31:59<02:31,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2655: train loss 0.30183. lr 3.338910e-04:  93%|█████████▎| 2655/2863 [31:59<02:31,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2655: train loss 0.30183. lr 3.338910e-04:  93%|█████████▎| 2656/2863 [31:59<02:30,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2656: train loss 0.30690. lr 3.337274e-04:  93%|█████████▎| 2656/2863 [32:00<02:30,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2656: train loss 0.30690. lr 3.337274e-04:  93%|█████████▎| 2657/2863 [32:00<02:28,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2657: train loss 0.30475. lr 3.335638e-04:  93%|█████████▎| 2657/2863 [32:01<02:28,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2657: train loss 0.30475. lr 3.335638e-04:  93%|█████████▎| 2658/2863 [32:01<02:26,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2658: train loss 0.30689. lr 3.334002e-04:  93%|█████████▎| 2658/2863 [32:02<02:26,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2658: train loss 0.30689. lr 3.334002e-04:  93%|█████████▎| 2659/2863 [32:02<02:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2659: train loss 0.30357. lr 3.332365e-04:  93%|█████████▎| 2659/2863 [32:02<02:25,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2659: train loss 0.30357. lr 3.332365e-04:  93%|█████████▎| 2660/2863 [32:02<02:23,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2660: train loss 0.30303. lr 3.330729e-04:  93%|█████████▎| 2660/2863 [32:03<02:23,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2660: train loss 0.30303. lr 3.330729e-04:  93%|█████████▎| 2661/2863 [32:03<02:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2661: train loss 0.30131. lr 3.329092e-04:  93%|█████████▎| 2661/2863 [32:04<02:22,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2661: train loss 0.30131. lr 3.329092e-04:  93%|█████████▎| 2662/2863 [32:04<02:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2662: train loss 0.29623. lr 3.327456e-04:  93%|█████████▎| 2662/2863 [32:04<02:21,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2662: train loss 0.29623. lr 3.327456e-04:  93%|█████████▎| 2663/2863 [32:04<02:20,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2663: train loss 0.30112. lr 3.325819e-04:  93%|█████████▎| 2663/2863 [32:05<02:20,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2663: train loss 0.30112. lr 3.325819e-04:  93%|█████████▎| 2664/2863 [32:05<02:19,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2664: train loss 0.30286. lr 3.324182e-04:  93%|█████████▎| 2664/2863 [32:06<02:19,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2664: train loss 0.30286. lr 3.324182e-04:  93%|█████████▎| 2665/2863 [32:06<02:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2665: train loss 0.31137. lr 3.322546e-04:  93%|█████████▎| 2665/2863 [32:06<02:18,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2665: train loss 0.31137. lr 3.322546e-04:  93%|█████████▎| 2666/2863 [32:06<02:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2666: train loss 0.30236. lr 3.320909e-04:  93%|█████████▎| 2666/2863 [32:07<02:17,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2666: train loss 0.30236. lr 3.320909e-04:  93%|█████████▎| 2667/2863 [32:07<02:16,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2667: train loss 0.30052. lr 3.319272e-04:  93%|█████████▎| 2667/2863 [32:08<02:16,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2667: train loss 0.30052. lr 3.319272e-04:  93%|█████████▎| 2668/2863 [32:08<02:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2668: train loss 0.29649. lr 3.317634e-04:  93%|█████████▎| 2668/2863 [32:09<02:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2668: train loss 0.29649. lr 3.317634e-04:  93%|█████████▎| 2669/2863 [32:09<02:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2669: train loss 0.30225. lr 3.315997e-04:  93%|█████████▎| 2669/2863 [32:09<02:15,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2669: train loss 0.30225. lr 3.315997e-04:  93%|█████████▎| 2670/2863 [32:09<02:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2670: train loss 0.30320. lr 3.314360e-04:  93%|█████████▎| 2670/2863 [32:10<02:14,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2670: train loss 0.30320. lr 3.314360e-04:  93%|█████████▎| 2671/2863 [32:10<02:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2671: train loss 0.31026. lr 3.312722e-04:  93%|█████████▎| 2671/2863 [32:11<02:13,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2671: train loss 0.31026. lr 3.312722e-04:  93%|█████████▎| 2672/2863 [32:11<02:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2672: train loss 0.30695. lr 3.311085e-04:  93%|█████████▎| 2672/2863 [32:11<02:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2672: train loss 0.30695. lr 3.311085e-04:  93%|█████████▎| 2673/2863 [32:11<02:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2673: train loss 0.30951. lr 3.309447e-04:  93%|█████████▎| 2673/2863 [32:12<02:12,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2673: train loss 0.30951. lr 3.309447e-04:  93%|█████████▎| 2674/2863 [32:12<02:18,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2674: train loss 0.30171. lr 3.307809e-04:  93%|█████████▎| 2674/2863 [32:13<02:18,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2674: train loss 0.30171. lr 3.307809e-04:  93%|█████████▎| 2675/2863 [32:13<02:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2675: train loss 0.30743. lr 3.306172e-04:  93%|█████████▎| 2675/2863 [32:14<02:16,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2675: train loss 0.30743. lr 3.306172e-04:  93%|█████████▎| 2676/2863 [32:14<02:22,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2676: train loss 0.29891. lr 3.304534e-04:  93%|█████████▎| 2676/2863 [32:14<02:22,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2676: train loss 0.29891. lr 3.304534e-04:  94%|█████████▎| 2677/2863 [32:14<02:24,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2677: train loss 0.30552. lr 3.302896e-04:  94%|█████████▎| 2677/2863 [32:15<02:24,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2677: train loss 0.30552. lr 3.302896e-04:  94%|█████████▎| 2678/2863 [32:15<02:22,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2678: train loss 0.29910. lr 3.301258e-04:  94%|█████████▎| 2678/2863 [32:16<02:22,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2678: train loss 0.29910. lr 3.301258e-04:  94%|█████████▎| 2679/2863 [32:16<02:18,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2679: train loss 0.30593. lr 3.299619e-04:  94%|█████████▎| 2679/2863 [32:17<02:18,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2679: train loss 0.30593. lr 3.299619e-04:  94%|█████████▎| 2680/2863 [32:17<02:14,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2680: train loss 0.29279. lr 3.297981e-04:  94%|█████████▎| 2680/2863 [32:17<02:14,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2680: train loss 0.29279. lr 3.297981e-04:  94%|█████████▎| 2681/2863 [32:17<02:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2681: train loss 0.30043. lr 3.296343e-04:  94%|█████████▎| 2681/2863 [32:18<02:11,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2681: train loss 0.30043. lr 3.296343e-04:  94%|█████████▎| 2682/2863 [32:18<02:08,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2682: train loss 0.29434. lr 3.294704e-04:  94%|█████████▎| 2682/2863 [32:19<02:08,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2682: train loss 0.29434. lr 3.294704e-04:  94%|█████████▎| 2683/2863 [32:19<02:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2683: train loss 0.29951. lr 3.293066e-04:  94%|█████████▎| 2683/2863 [32:19<02:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2683: train loss 0.29951. lr 3.293066e-04:  94%|█████████▎| 2684/2863 [32:19<02:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2684: train loss 0.30436. lr 3.291427e-04:  94%|█████████▎| 2684/2863 [32:20<02:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2684: train loss 0.30436. lr 3.291427e-04:  94%|█████████▍| 2685/2863 [32:20<02:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2685: train loss 0.29557. lr 3.289788e-04:  94%|█████████▍| 2685/2863 [32:21<02:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2685: train loss 0.29557. lr 3.289788e-04:  94%|█████████▍| 2686/2863 [32:21<02:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2686: train loss 0.30517. lr 3.288150e-04:  94%|█████████▍| 2686/2863 [32:22<02:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2686: train loss 0.30517. lr 3.288150e-04:  94%|█████████▍| 2687/2863 [32:22<02:05,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2687: train loss 0.30049. lr 3.286511e-04:  94%|█████████▍| 2687/2863 [32:22<02:05,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2687: train loss 0.30049. lr 3.286511e-04:  94%|█████████▍| 2688/2863 [32:22<02:07,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2688: train loss 0.29487. lr 3.284872e-04:  94%|█████████▍| 2688/2863 [32:23<02:07,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2688: train loss 0.29487. lr 3.284872e-04:  94%|█████████▍| 2689/2863 [32:23<02:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2689: train loss 0.30069. lr 3.283233e-04:  94%|█████████▍| 2689/2863 [32:24<02:06,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2689: train loss 0.30069. lr 3.283233e-04:  94%|█████████▍| 2690/2863 [32:24<02:04,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2690: train loss 0.29519. lr 3.281593e-04:  94%|█████████▍| 2690/2863 [32:24<02:04,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2690: train loss 0.29519. lr 3.281593e-04:  94%|█████████▍| 2691/2863 [32:24<02:01,  1.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2691: train loss 0.29213. lr 3.279954e-04:  94%|█████████▍| 2691/2863 [32:25<02:01,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2691: train loss 0.29213. lr 3.279954e-04:  94%|█████████▍| 2692/2863 [32:25<02:00,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2692: train loss 0.30893. lr 3.278315e-04:  94%|█████████▍| 2692/2863 [32:26<02:00,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2692: train loss 0.30893. lr 3.278315e-04:  94%|█████████▍| 2693/2863 [32:26<01:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2693: train loss 0.30142. lr 3.276675e-04:  94%|█████████▍| 2693/2863 [32:26<01:59,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2693: train loss 0.30142. lr 3.276675e-04:  94%|█████████▍| 2694/2863 [32:26<01:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2694: train loss 0.30302. lr 3.275036e-04:  94%|█████████▍| 2694/2863 [32:27<01:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2694: train loss 0.30302. lr 3.275036e-04:  94%|█████████▍| 2695/2863 [32:27<01:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2695: train loss 0.29676. lr 3.273396e-04:  94%|█████████▍| 2695/2863 [32:28<01:57,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2695: train loss 0.29676. lr 3.273396e-04:  94%|█████████▍| 2696/2863 [32:28<01:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2696: train loss 0.29971. lr 3.271757e-04:  94%|█████████▍| 2696/2863 [32:29<01:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2696: train loss 0.29971. lr 3.271757e-04:  94%|█████████▍| 2697/2863 [32:29<01:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2697: train loss 0.29753. lr 3.270117e-04:  94%|█████████▍| 2697/2863 [32:29<01:57,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2697: train loss 0.29753. lr 3.270117e-04:  94%|█████████▍| 2698/2863 [32:29<01:56,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2698: train loss 0.29564. lr 3.268477e-04:  94%|█████████▍| 2698/2863 [32:30<01:56,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2698: train loss 0.29564. lr 3.268477e-04:  94%|█████████▍| 2699/2863 [32:30<01:55,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2699: train loss 0.30418. lr 3.266837e-04:  94%|█████████▍| 2699/2863 [32:31<01:55,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2699: train loss 0.30418. lr 3.266837e-04:  94%|█████████▍| 2700/2863 [32:31<01:55,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2700: train loss 0.30430. lr 3.265197e-04:  94%|█████████▍| 2700/2863 [32:31<01:55,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2700: train loss 0.30430. lr 3.265197e-04:  94%|█████████▍| 2701/2863 [32:31<01:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2701: train loss 0.29653. lr 3.263557e-04:  94%|█████████▍| 2701/2863 [32:32<01:54,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2701: train loss 0.29653. lr 3.263557e-04:  94%|█████████▍| 2702/2863 [32:32<01:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2702: train loss 0.30899. lr 3.261917e-04:  94%|█████████▍| 2702/2863 [32:33<01:58,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2702: train loss 0.30899. lr 3.261917e-04:  94%|█████████▍| 2703/2863 [32:33<01:55,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2703: train loss 0.29388. lr 3.260277e-04:  94%|█████████▍| 2703/2863 [32:34<01:55,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2703: train loss 0.29388. lr 3.260277e-04:  94%|█████████▍| 2704/2863 [32:34<01:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2704: train loss 0.30501. lr 3.258637e-04:  94%|█████████▍| 2704/2863 [32:34<01:53,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2704: train loss 0.30501. lr 3.258637e-04:  94%|█████████▍| 2705/2863 [32:34<01:52,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2705: train loss 0.30695. lr 3.256996e-04:  94%|█████████▍| 2705/2863 [32:35<01:52,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2705: train loss 0.30695. lr 3.256996e-04:  95%|█████████▍| 2706/2863 [32:35<01:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2706: train loss 0.30203. lr 3.255356e-04:  95%|█████████▍| 2706/2863 [32:36<01:51,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2706: train loss 0.30203. lr 3.255356e-04:  95%|█████████▍| 2707/2863 [32:36<01:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2707: train loss 0.29635. lr 3.253715e-04:  95%|█████████▍| 2707/2863 [32:36<01:50,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2707: train loss 0.29635. lr 3.253715e-04:  95%|█████████▍| 2708/2863 [32:36<01:51,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2708: train loss 0.30432. lr 3.252075e-04:  95%|█████████▍| 2708/2863 [32:37<01:51,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2708: train loss 0.30432. lr 3.252075e-04:  95%|█████████▍| 2709/2863 [32:37<01:51,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2709: train loss 0.30189. lr 3.250434e-04:  95%|█████████▍| 2709/2863 [32:38<01:51,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2709: train loss 0.30189. lr 3.250434e-04:  95%|█████████▍| 2710/2863 [32:38<01:52,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2710: train loss 0.29570. lr 3.248793e-04:  95%|█████████▍| 2710/2863 [32:39<01:52,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2710: train loss 0.29570. lr 3.248793e-04:  95%|█████████▍| 2711/2863 [32:39<01:53,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2711: train loss 0.28739. lr 3.247152e-04:  95%|█████████▍| 2711/2863 [32:40<01:53,  1.33it/s]\u001b[A\n",
      "epoch 1 iter 2711: train loss 0.28739. lr 3.247152e-04:  95%|█████████▍| 2712/2863 [32:40<01:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2712: train loss 0.28592. lr 3.245511e-04:  95%|█████████▍| 2712/2863 [32:40<01:54,  1.32it/s]\u001b[A\n",
      "epoch 1 iter 2712: train loss 0.28592. lr 3.245511e-04:  95%|█████████▍| 2713/2863 [32:40<01:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2713: train loss 0.29580. lr 3.243871e-04:  95%|█████████▍| 2713/2863 [32:41<01:54,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2713: train loss 0.29580. lr 3.243871e-04:  95%|█████████▍| 2714/2863 [32:41<01:54,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2714: train loss 0.29218. lr 3.242229e-04:  95%|█████████▍| 2714/2863 [32:42<01:54,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2714: train loss 0.29218. lr 3.242229e-04:  95%|█████████▍| 2715/2863 [32:42<01:53,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2715: train loss 0.28507. lr 3.240588e-04:  95%|█████████▍| 2715/2863 [32:43<01:53,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2715: train loss 0.28507. lr 3.240588e-04:  95%|█████████▍| 2716/2863 [32:43<01:52,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2716: train loss 0.29415. lr 3.238947e-04:  95%|█████████▍| 2716/2863 [32:43<01:52,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2716: train loss 0.29415. lr 3.238947e-04:  95%|█████████▍| 2717/2863 [32:43<01:52,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2717: train loss 0.29061. lr 3.237306e-04:  95%|█████████▍| 2717/2863 [32:44<01:52,  1.30it/s]\u001b[A\n",
      "epoch 1 iter 2717: train loss 0.29061. lr 3.237306e-04:  95%|█████████▍| 2718/2863 [32:44<01:52,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2718: train loss 0.30357. lr 3.235665e-04:  95%|█████████▍| 2718/2863 [32:45<01:52,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2718: train loss 0.30357. lr 3.235665e-04:  95%|█████████▍| 2719/2863 [32:45<01:52,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2719: train loss 0.30081. lr 3.234023e-04:  95%|█████████▍| 2719/2863 [32:46<01:52,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2719: train loss 0.30081. lr 3.234023e-04:  95%|█████████▌| 2720/2863 [32:46<01:51,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2720: train loss 0.29659. lr 3.232382e-04:  95%|█████████▌| 2720/2863 [32:47<01:51,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2720: train loss 0.29659. lr 3.232382e-04:  95%|█████████▌| 2721/2863 [32:47<01:49,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2721: train loss 0.28990. lr 3.230740e-04:  95%|█████████▌| 2721/2863 [32:47<01:49,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2721: train loss 0.28990. lr 3.230740e-04:  95%|█████████▌| 2722/2863 [32:47<01:49,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2722: train loss 0.31102. lr 3.229098e-04:  95%|█████████▌| 2722/2863 [32:48<01:49,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2722: train loss 0.31102. lr 3.229098e-04:  95%|█████████▌| 2723/2863 [32:48<01:48,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2723: train loss 0.29733. lr 3.227457e-04:  95%|█████████▌| 2723/2863 [32:49<01:48,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2723: train loss 0.29733. lr 3.227457e-04:  95%|█████████▌| 2724/2863 [32:49<01:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2724: train loss 0.29446. lr 3.225815e-04:  95%|█████████▌| 2724/2863 [32:50<01:48,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2724: train loss 0.29446. lr 3.225815e-04:  95%|█████████▌| 2725/2863 [32:50<01:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2725: train loss 0.29386. lr 3.224173e-04:  95%|█████████▌| 2725/2863 [32:50<01:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2725: train loss 0.29386. lr 3.224173e-04:  95%|█████████▌| 2726/2863 [32:50<01:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2726: train loss 0.28681. lr 3.222531e-04:  95%|█████████▌| 2726/2863 [32:51<01:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2726: train loss 0.28681. lr 3.222531e-04:  95%|█████████▌| 2727/2863 [32:51<01:45,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2727: train loss 0.29667. lr 3.220889e-04:  95%|█████████▌| 2727/2863 [32:52<01:45,  1.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2727: train loss 0.29667. lr 3.220889e-04:  95%|█████████▌| 2728/2863 [32:52<01:45,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2728: train loss 0.29614. lr 3.219247e-04:  95%|█████████▌| 2728/2863 [32:53<01:45,  1.29it/s]\u001b[A\n",
      "epoch 1 iter 2728: train loss 0.29614. lr 3.219247e-04:  95%|█████████▌| 2729/2863 [32:53<01:44,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2729: train loss 0.30021. lr 3.217605e-04:  95%|█████████▌| 2729/2863 [32:54<01:44,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2729: train loss 0.30021. lr 3.217605e-04:  95%|█████████▌| 2730/2863 [32:54<01:48,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2730: train loss 0.30089. lr 3.215963e-04:  95%|█████████▌| 2730/2863 [32:54<01:48,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2730: train loss 0.30089. lr 3.215963e-04:  95%|█████████▌| 2731/2863 [32:54<01:45,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2731: train loss 0.30665. lr 3.214321e-04:  95%|█████████▌| 2731/2863 [32:55<01:45,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2731: train loss 0.30665. lr 3.214321e-04:  95%|█████████▌| 2732/2863 [32:55<01:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2732: train loss 0.29513. lr 3.212679e-04:  95%|█████████▌| 2732/2863 [32:56<01:44,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2732: train loss 0.29513. lr 3.212679e-04:  95%|█████████▌| 2733/2863 [32:56<01:42,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2733: train loss 0.28539. lr 3.211036e-04:  95%|█████████▌| 2733/2863 [32:57<01:42,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2733: train loss 0.28539. lr 3.211036e-04:  95%|█████████▌| 2734/2863 [32:57<01:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2734: train loss 0.29603. lr 3.209394e-04:  95%|█████████▌| 2734/2863 [32:58<01:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2734: train loss 0.29603. lr 3.209394e-04:  96%|█████████▌| 2735/2863 [32:58<01:40,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2735: train loss 0.29722. lr 3.207751e-04:  96%|█████████▌| 2735/2863 [32:58<01:40,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2735: train loss 0.29722. lr 3.207751e-04:  96%|█████████▌| 2736/2863 [32:58<01:39,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2736: train loss 0.29390. lr 3.206109e-04:  96%|█████████▌| 2736/2863 [32:59<01:39,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2736: train loss 0.29390. lr 3.206109e-04:  96%|█████████▌| 2737/2863 [32:59<01:38,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2737: train loss 0.28558. lr 3.204466e-04:  96%|█████████▌| 2737/2863 [33:00<01:38,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2737: train loss 0.28558. lr 3.204466e-04:  96%|█████████▌| 2738/2863 [33:00<01:37,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2738: train loss 0.28911. lr 3.202823e-04:  96%|█████████▌| 2738/2863 [33:01<01:37,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2738: train loss 0.28911. lr 3.202823e-04:  96%|█████████▌| 2739/2863 [33:01<01:36,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2739: train loss 0.29701. lr 3.201181e-04:  96%|█████████▌| 2739/2863 [33:01<01:36,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2739: train loss 0.29701. lr 3.201181e-04:  96%|█████████▌| 2740/2863 [33:01<01:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2740: train loss 0.29104. lr 3.199538e-04:  96%|█████████▌| 2740/2863 [33:02<01:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2740: train loss 0.29104. lr 3.199538e-04:  96%|█████████▌| 2741/2863 [33:02<01:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2741: train loss 0.29561. lr 3.197895e-04:  96%|█████████▌| 2741/2863 [33:03<01:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2741: train loss 0.29561. lr 3.197895e-04:  96%|█████████▌| 2742/2863 [33:03<01:34,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2742: train loss 0.28824. lr 3.196252e-04:  96%|█████████▌| 2742/2863 [33:04<01:34,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2742: train loss 0.28824. lr 3.196252e-04:  96%|█████████▌| 2743/2863 [33:04<01:34,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2743: train loss 0.29593. lr 3.194609e-04:  96%|█████████▌| 2743/2863 [33:05<01:34,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2743: train loss 0.29593. lr 3.194609e-04:  96%|█████████▌| 2744/2863 [33:05<01:33,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2744: train loss 0.29775. lr 3.192966e-04:  96%|█████████▌| 2744/2863 [33:05<01:33,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2744: train loss 0.29775. lr 3.192966e-04:  96%|█████████▌| 2745/2863 [33:05<01:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2745: train loss 0.29836. lr 3.191323e-04:  96%|█████████▌| 2745/2863 [33:06<01:32,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2745: train loss 0.29836. lr 3.191323e-04:  96%|█████████▌| 2746/2863 [33:06<01:31,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2746: train loss 0.28369. lr 3.189680e-04:  96%|█████████▌| 2746/2863 [33:07<01:31,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2746: train loss 0.28369. lr 3.189680e-04:  96%|█████████▌| 2747/2863 [33:07<01:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2747: train loss 0.30129. lr 3.188037e-04:  96%|█████████▌| 2747/2863 [33:08<01:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2747: train loss 0.30129. lr 3.188037e-04:  96%|█████████▌| 2748/2863 [33:08<01:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2748: train loss 0.29557. lr 3.186393e-04:  96%|█████████▌| 2748/2863 [33:09<01:30,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2748: train loss 0.29557. lr 3.186393e-04:  96%|█████████▌| 2749/2863 [33:09<01:29,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2749: train loss 0.28867. lr 3.184750e-04:  96%|█████████▌| 2749/2863 [33:09<01:29,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2749: train loss 0.28867. lr 3.184750e-04:  96%|█████████▌| 2750/2863 [33:09<01:28,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2750: train loss 0.29680. lr 3.183107e-04:  96%|█████████▌| 2750/2863 [33:10<01:28,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2750: train loss 0.29680. lr 3.183107e-04:  96%|█████████▌| 2751/2863 [33:10<01:27,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2751: train loss 0.28137. lr 3.181463e-04:  96%|█████████▌| 2751/2863 [33:11<01:27,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2751: train loss 0.28137. lr 3.181463e-04:  96%|█████████▌| 2752/2863 [33:11<01:27,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2752: train loss 0.29005. lr 3.179820e-04:  96%|█████████▌| 2752/2863 [33:12<01:27,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2752: train loss 0.29005. lr 3.179820e-04:  96%|█████████▌| 2753/2863 [33:12<01:26,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2753: train loss 0.29004. lr 3.178176e-04:  96%|█████████▌| 2753/2863 [33:12<01:26,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2753: train loss 0.29004. lr 3.178176e-04:  96%|█████████▌| 2754/2863 [33:12<01:25,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2754: train loss 0.29189. lr 3.176533e-04:  96%|█████████▌| 2754/2863 [33:13<01:25,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2754: train loss 0.29189. lr 3.176533e-04:  96%|█████████▌| 2755/2863 [33:13<01:25,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2755: train loss 0.28236. lr 3.174889e-04:  96%|█████████▌| 2755/2863 [33:14<01:25,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2755: train loss 0.28236. lr 3.174889e-04:  96%|█████████▋| 2756/2863 [33:14<01:24,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2756: train loss 0.29550. lr 3.173245e-04:  96%|█████████▋| 2756/2863 [33:15<01:24,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2756: train loss 0.29550. lr 3.173245e-04:  96%|█████████▋| 2757/2863 [33:15<01:23,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2757: train loss 0.29458. lr 3.171602e-04:  96%|█████████▋| 2757/2863 [33:16<01:23,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2757: train loss 0.29458. lr 3.171602e-04:  96%|█████████▋| 2758/2863 [33:16<01:25,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 2758: train loss 0.28704. lr 3.169958e-04:  96%|█████████▋| 2758/2863 [33:16<01:25,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 2758: train loss 0.28704. lr 3.169958e-04:  96%|█████████▋| 2759/2863 [33:16<01:23,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2759: train loss 0.29522. lr 3.168314e-04:  96%|█████████▋| 2759/2863 [33:17<01:23,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2759: train loss 0.29522. lr 3.168314e-04:  96%|█████████▋| 2760/2863 [33:17<01:22,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2760: train loss 0.28943. lr 3.166670e-04:  96%|█████████▋| 2760/2863 [33:18<01:22,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2760: train loss 0.28943. lr 3.166670e-04:  96%|█████████▋| 2761/2863 [33:18<01:20,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2761: train loss 0.28619. lr 3.165026e-04:  96%|█████████▋| 2761/2863 [33:19<01:20,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2761: train loss 0.28619. lr 3.165026e-04:  96%|█████████▋| 2762/2863 [33:19<01:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2762: train loss 0.28841. lr 3.163382e-04:  96%|█████████▋| 2762/2863 [33:20<01:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2762: train loss 0.28841. lr 3.163382e-04:  97%|█████████▋| 2763/2863 [33:20<01:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2763: train loss 0.29081. lr 3.161738e-04:  97%|█████████▋| 2763/2863 [33:20<01:19,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2763: train loss 0.29081. lr 3.161738e-04:  97%|█████████▋| 2764/2863 [33:20<01:18,  1.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2764: train loss 0.28461. lr 3.160094e-04:  97%|█████████▋| 2764/2863 [33:21<01:18,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2764: train loss 0.28461. lr 3.160094e-04:  97%|█████████▋| 2765/2863 [33:21<01:17,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2765: train loss 0.29497. lr 3.158450e-04:  97%|█████████▋| 2765/2863 [33:22<01:17,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2765: train loss 0.29497. lr 3.158450e-04:  97%|█████████▋| 2766/2863 [33:22<01:16,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2766: train loss 0.28862. lr 3.156806e-04:  97%|█████████▋| 2766/2863 [33:23<01:16,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2766: train loss 0.28862. lr 3.156806e-04:  97%|█████████▋| 2767/2863 [33:23<01:15,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2767: train loss 0.28171. lr 3.155162e-04:  97%|█████████▋| 2767/2863 [33:24<01:15,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2767: train loss 0.28171. lr 3.155162e-04:  97%|█████████▋| 2768/2863 [33:24<01:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2768: train loss 0.27717. lr 3.153517e-04:  97%|█████████▋| 2768/2863 [33:24<01:15,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2768: train loss 0.27717. lr 3.153517e-04:  97%|█████████▋| 2769/2863 [33:24<01:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2769: train loss 0.29231. lr 3.151873e-04:  97%|█████████▋| 2769/2863 [33:25<01:14,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2769: train loss 0.29231. lr 3.151873e-04:  97%|█████████▋| 2770/2863 [33:25<01:13,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2770: train loss 0.29972. lr 3.150229e-04:  97%|█████████▋| 2770/2863 [33:26<01:13,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2770: train loss 0.29972. lr 3.150229e-04:  97%|█████████▋| 2771/2863 [33:26<01:12,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2771: train loss 0.28109. lr 3.148584e-04:  97%|█████████▋| 2771/2863 [33:27<01:12,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2771: train loss 0.28109. lr 3.148584e-04:  97%|█████████▋| 2772/2863 [33:27<01:11,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2772: train loss 0.28353. lr 3.146940e-04:  97%|█████████▋| 2772/2863 [33:27<01:11,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2772: train loss 0.28353. lr 3.146940e-04:  97%|█████████▋| 2773/2863 [33:27<01:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2773: train loss 0.29992. lr 3.145295e-04:  97%|█████████▋| 2773/2863 [33:28<01:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2773: train loss 0.29992. lr 3.145295e-04:  97%|█████████▋| 2774/2863 [33:28<01:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2774: train loss 0.28857. lr 3.143651e-04:  97%|█████████▋| 2774/2863 [33:29<01:10,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2774: train loss 0.28857. lr 3.143651e-04:  97%|█████████▋| 2775/2863 [33:29<01:08,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2775: train loss 0.28378. lr 3.142006e-04:  97%|█████████▋| 2775/2863 [33:30<01:08,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2775: train loss 0.28378. lr 3.142006e-04:  97%|█████████▋| 2776/2863 [33:30<01:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2776: train loss 0.29742. lr 3.140361e-04:  97%|█████████▋| 2776/2863 [33:31<01:08,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2776: train loss 0.29742. lr 3.140361e-04:  97%|█████████▋| 2777/2863 [33:31<01:07,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2777: train loss 0.29137. lr 3.138717e-04:  97%|█████████▋| 2777/2863 [33:31<01:07,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2777: train loss 0.29137. lr 3.138717e-04:  97%|█████████▋| 2778/2863 [33:31<01:06,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2778: train loss 0.27978. lr 3.137072e-04:  97%|█████████▋| 2778/2863 [33:32<01:06,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2778: train loss 0.27978. lr 3.137072e-04:  97%|█████████▋| 2779/2863 [33:32<01:05,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2779: train loss 0.29114. lr 3.135427e-04:  97%|█████████▋| 2779/2863 [33:33<01:05,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2779: train loss 0.29114. lr 3.135427e-04:  97%|█████████▋| 2780/2863 [33:33<01:05,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2780: train loss 0.28948. lr 3.133782e-04:  97%|█████████▋| 2780/2863 [33:34<01:05,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2780: train loss 0.28948. lr 3.133782e-04:  97%|█████████▋| 2781/2863 [33:34<01:04,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2781: train loss 0.28680. lr 3.132138e-04:  97%|█████████▋| 2781/2863 [33:35<01:04,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2781: train loss 0.28680. lr 3.132138e-04:  97%|█████████▋| 2782/2863 [33:35<01:03,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2782: train loss 0.28722. lr 3.130493e-04:  97%|█████████▋| 2782/2863 [33:35<01:03,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2782: train loss 0.28722. lr 3.130493e-04:  97%|█████████▋| 2783/2863 [33:35<01:03,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2783: train loss 0.28793. lr 3.128848e-04:  97%|█████████▋| 2783/2863 [33:36<01:03,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2783: train loss 0.28793. lr 3.128848e-04:  97%|█████████▋| 2784/2863 [33:36<01:02,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2784: train loss 0.27924. lr 3.127203e-04:  97%|█████████▋| 2784/2863 [33:37<01:02,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2784: train loss 0.27924. lr 3.127203e-04:  97%|█████████▋| 2785/2863 [33:37<01:01,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2785: train loss 0.28794. lr 3.125558e-04:  97%|█████████▋| 2785/2863 [33:38<01:01,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2785: train loss 0.28794. lr 3.125558e-04:  97%|█████████▋| 2786/2863 [33:38<01:03,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 2786: train loss 0.29302. lr 3.123913e-04:  97%|█████████▋| 2786/2863 [33:39<01:03,  1.21it/s]\u001b[A\n",
      "epoch 1 iter 2786: train loss 0.29302. lr 3.123913e-04:  97%|█████████▋| 2787/2863 [33:39<01:01,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2787: train loss 0.28772. lr 3.122268e-04:  97%|█████████▋| 2787/2863 [33:39<01:01,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2787: train loss 0.28772. lr 3.122268e-04:  97%|█████████▋| 2788/2863 [33:39<01:00,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2788: train loss 0.28641. lr 3.120622e-04:  97%|█████████▋| 2788/2863 [33:40<01:00,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2788: train loss 0.28641. lr 3.120622e-04:  97%|█████████▋| 2789/2863 [33:40<00:59,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2789: train loss 0.29013. lr 3.118977e-04:  97%|█████████▋| 2789/2863 [33:41<00:59,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2789: train loss 0.29013. lr 3.118977e-04:  97%|█████████▋| 2790/2863 [33:41<00:57,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2790: train loss 0.28683. lr 3.117332e-04:  97%|█████████▋| 2790/2863 [33:42<00:57,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2790: train loss 0.28683. lr 3.117332e-04:  97%|█████████▋| 2791/2863 [33:42<00:56,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2791: train loss 0.28109. lr 3.115687e-04:  97%|█████████▋| 2791/2863 [33:43<00:56,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2791: train loss 0.28109. lr 3.115687e-04:  98%|█████████▊| 2792/2863 [33:43<00:56,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2792: train loss 0.28596. lr 3.114042e-04:  98%|█████████▊| 2792/2863 [33:43<00:56,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2792: train loss 0.28596. lr 3.114042e-04:  98%|█████████▊| 2793/2863 [33:43<00:55,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2793: train loss 0.28875. lr 3.112396e-04:  98%|█████████▊| 2793/2863 [33:44<00:55,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2793: train loss 0.28875. lr 3.112396e-04:  98%|█████████▊| 2794/2863 [33:44<00:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2794: train loss 0.27687. lr 3.110751e-04:  98%|█████████▊| 2794/2863 [33:45<00:54,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2794: train loss 0.27687. lr 3.110751e-04:  98%|█████████▊| 2795/2863 [33:45<00:53,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2795: train loss 0.28646. lr 3.109106e-04:  98%|█████████▊| 2795/2863 [33:46<00:53,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2795: train loss 0.28646. lr 3.109106e-04:  98%|█████████▊| 2796/2863 [33:46<00:52,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2796: train loss 0.28535. lr 3.107460e-04:  98%|█████████▊| 2796/2863 [33:46<00:52,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2796: train loss 0.28535. lr 3.107460e-04:  98%|█████████▊| 2797/2863 [33:46<00:51,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2797: train loss 0.28923. lr 3.105815e-04:  98%|█████████▊| 2797/2863 [33:47<00:51,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2797: train loss 0.28923. lr 3.105815e-04:  98%|█████████▊| 2798/2863 [33:47<00:51,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2798: train loss 0.29234. lr 3.104169e-04:  98%|█████████▊| 2798/2863 [33:48<00:51,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2798: train loss 0.29234. lr 3.104169e-04:  98%|█████████▊| 2799/2863 [33:48<00:50,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2799: train loss 0.29370. lr 3.102524e-04:  98%|█████████▊| 2799/2863 [33:49<00:50,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2799: train loss 0.29370. lr 3.102524e-04:  98%|█████████▊| 2800/2863 [33:49<00:49,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2800: train loss 0.27686. lr 3.100878e-04:  98%|█████████▊| 2800/2863 [33:50<00:49,  1.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2800: train loss 0.27686. lr 3.100878e-04:  98%|█████████▊| 2801/2863 [33:50<00:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2801: train loss 0.28917. lr 3.099233e-04:  98%|█████████▊| 2801/2863 [33:50<00:48,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2801: train loss 0.28917. lr 3.099233e-04:  98%|█████████▊| 2802/2863 [33:50<00:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2802: train loss 0.28973. lr 3.097587e-04:  98%|█████████▊| 2802/2863 [33:51<00:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2802: train loss 0.28973. lr 3.097587e-04:  98%|█████████▊| 2803/2863 [33:51<00:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2803: train loss 0.29727. lr 3.095942e-04:  98%|█████████▊| 2803/2863 [33:52<00:47,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2803: train loss 0.29727. lr 3.095942e-04:  98%|█████████▊| 2804/2863 [33:52<00:46,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2804: train loss 0.27966. lr 3.094296e-04:  98%|█████████▊| 2804/2863 [33:53<00:46,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2804: train loss 0.27966. lr 3.094296e-04:  98%|█████████▊| 2805/2863 [33:53<00:45,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2805: train loss 0.28335. lr 3.092650e-04:  98%|█████████▊| 2805/2863 [33:54<00:45,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2805: train loss 0.28335. lr 3.092650e-04:  98%|█████████▊| 2806/2863 [33:54<00:44,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2806: train loss 0.28816. lr 3.091005e-04:  98%|█████████▊| 2806/2863 [33:54<00:44,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2806: train loss 0.28816. lr 3.091005e-04:  98%|█████████▊| 2807/2863 [33:54<00:44,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2807: train loss 0.29171. lr 3.089359e-04:  98%|█████████▊| 2807/2863 [33:55<00:44,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2807: train loss 0.29171. lr 3.089359e-04:  98%|█████████▊| 2808/2863 [33:55<00:43,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2808: train loss 0.28035. lr 3.087713e-04:  98%|█████████▊| 2808/2863 [33:56<00:43,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2808: train loss 0.28035. lr 3.087713e-04:  98%|█████████▊| 2809/2863 [33:56<00:42,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2809: train loss 0.28448. lr 3.086067e-04:  98%|█████████▊| 2809/2863 [33:57<00:42,  1.26it/s]\u001b[A\n",
      "epoch 1 iter 2809: train loss 0.28448. lr 3.086067e-04:  98%|█████████▊| 2810/2863 [33:57<00:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2810: train loss 0.28414. lr 3.084422e-04:  98%|█████████▊| 2810/2863 [33:57<00:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2810: train loss 0.28414. lr 3.084422e-04:  98%|█████████▊| 2811/2863 [33:58<00:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2811: train loss 0.28832. lr 3.082776e-04:  98%|█████████▊| 2811/2863 [33:58<00:41,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2811: train loss 0.28832. lr 3.082776e-04:  98%|█████████▊| 2812/2863 [33:58<00:40,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2812: train loss 0.29019. lr 3.081130e-04:  98%|█████████▊| 2812/2863 [33:59<00:40,  1.27it/s]\u001b[A\n",
      "epoch 1 iter 2812: train loss 0.29019. lr 3.081130e-04:  98%|█████████▊| 2813/2863 [33:59<00:39,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2813: train loss 0.28581. lr 3.079484e-04:  98%|█████████▊| 2813/2863 [34:00<00:39,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2813: train loss 0.28581. lr 3.079484e-04:  98%|█████████▊| 2814/2863 [34:00<00:40,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 2814: train loss 0.28663. lr 3.077838e-04:  98%|█████████▊| 2814/2863 [34:01<00:40,  1.22it/s]\u001b[A\n",
      "epoch 1 iter 2814: train loss 0.28663. lr 3.077838e-04:  98%|█████████▊| 2815/2863 [34:01<00:39,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2815: train loss 0.28211. lr 3.076192e-04:  98%|█████████▊| 2815/2863 [34:02<00:39,  1.23it/s]\u001b[A\n",
      "epoch 1 iter 2815: train loss 0.28211. lr 3.076192e-04:  98%|█████████▊| 2816/2863 [34:02<00:37,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2816: train loss 0.28270. lr 3.074546e-04:  98%|█████████▊| 2816/2863 [34:02<00:37,  1.24it/s]\u001b[A\n",
      "epoch 1 iter 2816: train loss 0.28270. lr 3.074546e-04:  98%|█████████▊| 2817/2863 [34:02<00:36,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2817: train loss 0.28674. lr 3.072900e-04:  98%|█████████▊| 2817/2863 [34:03<00:36,  1.25it/s]\u001b[A\n",
      "epoch 1 iter 2817: train loss 0.28674. lr 3.072900e-04:  98%|█████████▊| 2818/2863 [34:03<00:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2818: train loss 0.29495. lr 3.071254e-04:  98%|█████████▊| 2818/2863 [34:04<00:35,  1.28it/s]\u001b[A\n",
      "epoch 1 iter 2818: train loss 0.29495. lr 3.071254e-04:  98%|█████████▊| 2819/2863 [34:04<00:33,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2819: train loss 0.28523. lr 3.069608e-04:  98%|█████████▊| 2819/2863 [34:04<00:33,  1.31it/s]\u001b[A\n",
      "epoch 1 iter 2819: train loss 0.28523. lr 3.069608e-04:  98%|█████████▊| 2820/2863 [34:04<00:31,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2820: train loss 0.28307. lr 3.067962e-04:  98%|█████████▊| 2820/2863 [34:05<00:31,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2820: train loss 0.28307. lr 3.067962e-04:  99%|█████████▊| 2821/2863 [34:05<00:30,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2821: train loss 0.28904. lr 3.066316e-04:  99%|█████████▊| 2821/2863 [34:06<00:30,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2821: train loss 0.28904. lr 3.066316e-04:  99%|█████████▊| 2822/2863 [34:06<00:29,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2822: train loss 0.27247. lr 3.064670e-04:  99%|█████████▊| 2822/2863 [34:07<00:29,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2822: train loss 0.27247. lr 3.064670e-04:  99%|█████████▊| 2823/2863 [34:07<00:28,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2823: train loss 0.28510. lr 3.063024e-04:  99%|█████████▊| 2823/2863 [34:07<00:28,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2823: train loss 0.28510. lr 3.063024e-04:  99%|█████████▊| 2824/2863 [34:07<00:28,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2824: train loss 0.28174. lr 3.061378e-04:  99%|█████████▊| 2824/2863 [34:08<00:28,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2824: train loss 0.28174. lr 3.061378e-04:  99%|█████████▊| 2825/2863 [34:08<00:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2825: train loss 0.28574. lr 3.059732e-04:  99%|█████████▊| 2825/2863 [34:09<00:27,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2825: train loss 0.28574. lr 3.059732e-04:  99%|█████████▊| 2826/2863 [34:09<00:26,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2826: train loss 0.28474. lr 3.058086e-04:  99%|█████████▊| 2826/2863 [34:09<00:26,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2826: train loss 0.28474. lr 3.058086e-04:  99%|█████████▊| 2827/2863 [34:09<00:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2827: train loss 0.28675. lr 3.056440e-04:  99%|█████████▊| 2827/2863 [34:10<00:25,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2827: train loss 0.28675. lr 3.056440e-04:  99%|█████████▉| 2828/2863 [34:10<00:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2828: train loss 0.28674. lr 3.054793e-04:  99%|█████████▉| 2828/2863 [34:11<00:24,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2828: train loss 0.28674. lr 3.054793e-04:  99%|█████████▉| 2829/2863 [34:11<00:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2829: train loss 0.29022. lr 3.053147e-04:  99%|█████████▉| 2829/2863 [34:12<00:23,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2829: train loss 0.29022. lr 3.053147e-04:  99%|█████████▉| 2830/2863 [34:12<00:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2830: train loss 0.28644. lr 3.051501e-04:  99%|█████████▉| 2830/2863 [34:12<00:23,  1.38it/s]\u001b[A\n",
      "epoch 1 iter 2830: train loss 0.28644. lr 3.051501e-04:  99%|█████████▉| 2831/2863 [34:12<00:23,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2831: train loss 0.29146. lr 3.049855e-04:  99%|█████████▉| 2831/2863 [34:13<00:23,  1.35it/s]\u001b[A\n",
      "epoch 1 iter 2831: train loss 0.29146. lr 3.049855e-04:  99%|█████████▉| 2832/2863 [34:13<00:23,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2832: train loss 0.28275. lr 3.048208e-04:  99%|█████████▉| 2832/2863 [34:14<00:23,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2832: train loss 0.28275. lr 3.048208e-04:  99%|█████████▉| 2833/2863 [34:14<00:22,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2833: train loss 0.28312. lr 3.046562e-04:  99%|█████████▉| 2833/2863 [34:15<00:22,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2833: train loss 0.28312. lr 3.046562e-04:  99%|█████████▉| 2834/2863 [34:15<00:21,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2834: train loss 0.28494. lr 3.044916e-04:  99%|█████████▉| 2834/2863 [34:15<00:21,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2834: train loss 0.28494. lr 3.044916e-04:  99%|█████████▉| 2835/2863 [34:15<00:20,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2835: train loss 0.28671. lr 3.043270e-04:  99%|█████████▉| 2835/2863 [34:16<00:20,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2835: train loss 0.28671. lr 3.043270e-04:  99%|█████████▉| 2836/2863 [34:16<00:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2836: train loss 0.28420. lr 3.041623e-04:  99%|█████████▉| 2836/2863 [34:17<00:19,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2836: train loss 0.28420. lr 3.041623e-04:  99%|█████████▉| 2837/2863 [34:17<00:18,  1.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 2837: train loss 0.28168. lr 3.039977e-04:  99%|█████████▉| 2837/2863 [34:17<00:18,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2837: train loss 0.28168. lr 3.039977e-04:  99%|█████████▉| 2838/2863 [34:17<00:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2838: train loss 0.28607. lr 3.038331e-04:  99%|█████████▉| 2838/2863 [34:18<00:17,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2838: train loss 0.28607. lr 3.038331e-04:  99%|█████████▉| 2839/2863 [34:18<00:16,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2839: train loss 0.26548. lr 3.036684e-04:  99%|█████████▉| 2839/2863 [34:19<00:16,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2839: train loss 0.26548. lr 3.036684e-04:  99%|█████████▉| 2840/2863 [34:19<00:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2840: train loss 0.26813. lr 3.035038e-04:  99%|█████████▉| 2840/2863 [34:19<00:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2840: train loss 0.26813. lr 3.035038e-04:  99%|█████████▉| 2841/2863 [34:19<00:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2841: train loss 0.28392. lr 3.033392e-04:  99%|█████████▉| 2841/2863 [34:20<00:15,  1.44it/s]\u001b[A\n",
      "epoch 1 iter 2841: train loss 0.28392. lr 3.033392e-04:  99%|█████████▉| 2842/2863 [34:20<00:15,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2842: train loss 0.28353. lr 3.031745e-04:  99%|█████████▉| 2842/2863 [34:21<00:15,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2842: train loss 0.28353. lr 3.031745e-04:  99%|█████████▉| 2843/2863 [34:21<00:14,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2843: train loss 0.28303. lr 3.030099e-04:  99%|█████████▉| 2843/2863 [34:22<00:14,  1.34it/s]\u001b[A\n",
      "epoch 1 iter 2843: train loss 0.28303. lr 3.030099e-04:  99%|█████████▉| 2844/2863 [34:22<00:13,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2844: train loss 0.27178. lr 3.028453e-04:  99%|█████████▉| 2844/2863 [34:22<00:13,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2844: train loss 0.27178. lr 3.028453e-04:  99%|█████████▉| 2845/2863 [34:22<00:12,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2845: train loss 0.27822. lr 3.026806e-04:  99%|█████████▉| 2845/2863 [34:23<00:12,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2845: train loss 0.27822. lr 3.026806e-04:  99%|█████████▉| 2846/2863 [34:23<00:12,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2846: train loss 0.28340. lr 3.025160e-04:  99%|█████████▉| 2846/2863 [34:24<00:12,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2846: train loss 0.28340. lr 3.025160e-04:  99%|█████████▉| 2847/2863 [34:24<00:11,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2847: train loss 0.28648. lr 3.023513e-04:  99%|█████████▉| 2847/2863 [34:25<00:11,  1.36it/s]\u001b[A\n",
      "epoch 1 iter 2847: train loss 0.28648. lr 3.023513e-04:  99%|█████████▉| 2848/2863 [34:25<00:10,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2848: train loss 0.28358. lr 3.021867e-04:  99%|█████████▉| 2848/2863 [34:25<00:10,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2848: train loss 0.28358. lr 3.021867e-04: 100%|█████████▉| 2849/2863 [34:25<00:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2849: train loss 0.28445. lr 3.020220e-04: 100%|█████████▉| 2849/2863 [34:26<00:10,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2849: train loss 0.28445. lr 3.020220e-04: 100%|█████████▉| 2850/2863 [34:26<00:09,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2850: train loss 0.27530. lr 3.018574e-04: 100%|█████████▉| 2850/2863 [34:27<00:09,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2850: train loss 0.27530. lr 3.018574e-04: 100%|█████████▉| 2851/2863 [34:27<00:08,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2851: train loss 0.27228. lr 3.016928e-04: 100%|█████████▉| 2851/2863 [34:27<00:08,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2851: train loss 0.27228. lr 3.016928e-04: 100%|█████████▉| 2852/2863 [34:27<00:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2852: train loss 0.29202. lr 3.015281e-04: 100%|█████████▉| 2852/2863 [34:28<00:07,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2852: train loss 0.29202. lr 3.015281e-04: 100%|█████████▉| 2853/2863 [34:28<00:07,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2853: train loss 0.27897. lr 3.013635e-04: 100%|█████████▉| 2853/2863 [34:29<00:07,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2853: train loss 0.27897. lr 3.013635e-04: 100%|█████████▉| 2854/2863 [34:29<00:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2854: train loss 0.27100. lr 3.011988e-04: 100%|█████████▉| 2854/2863 [34:29<00:06,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2854: train loss 0.27100. lr 3.011988e-04: 100%|█████████▉| 2855/2863 [34:29<00:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2855: train loss 0.28692. lr 3.010342e-04: 100%|█████████▉| 2855/2863 [34:30<00:05,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2855: train loss 0.28692. lr 3.010342e-04: 100%|█████████▉| 2856/2863 [34:30<00:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2856: train loss 0.28367. lr 3.008695e-04: 100%|█████████▉| 2856/2863 [34:31<00:04,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2856: train loss 0.28367. lr 3.008695e-04: 100%|█████████▉| 2857/2863 [34:31<00:04,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2857: train loss 0.28902. lr 3.007049e-04: 100%|█████████▉| 2857/2863 [34:32<00:04,  1.41it/s]\u001b[A\n",
      "epoch 1 iter 2857: train loss 0.28902. lr 3.007049e-04: 100%|█████████▉| 2858/2863 [34:32<00:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2858: train loss 0.28269. lr 3.005402e-04: 100%|█████████▉| 2858/2863 [34:32<00:03,  1.39it/s]\u001b[A\n",
      "epoch 1 iter 2858: train loss 0.28269. lr 3.005402e-04: 100%|█████████▉| 2859/2863 [34:32<00:02,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2859: train loss 0.27689. lr 3.003756e-04: 100%|█████████▉| 2859/2863 [34:33<00:02,  1.40it/s]\u001b[A\n",
      "epoch 1 iter 2859: train loss 0.27689. lr 3.003756e-04: 100%|█████████▉| 2860/2863 [34:33<00:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2860: train loss 0.28555. lr 3.002110e-04: 100%|█████████▉| 2860/2863 [34:34<00:02,  1.42it/s]\u001b[A\n",
      "epoch 1 iter 2860: train loss 0.28555. lr 3.002110e-04: 100%|█████████▉| 2861/2863 [34:34<00:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2861: train loss 0.28791. lr 3.000463e-04: 100%|█████████▉| 2861/2863 [34:35<00:01,  1.43it/s]\u001b[A\n",
      "epoch 1 iter 2861: train loss 0.28791. lr 3.000463e-04: 100%|█████████▉| 2862/2863 [34:35<00:00,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2862: train loss 0.28978. lr 3.000129e-04: 100%|█████████▉| 2862/2863 [34:35<00:00,  1.37it/s]\u001b[A\n",
      "epoch 1 iter 2862: train loss 0.28978. lr 3.000129e-04: 100%|██████████| 2863/2863 [34:35<00:00,  1.38it/s]\u001b[A\n",
      " 10%|█         | 1/10 [35:08<5:16:15, 2108.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1895152 characters, 44695 unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7403 [00:01<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [36:24<5:27:43, 2184.87s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.37 GiB (GPU 3; 23.65 GiB total capacity; 7.18 GiB already allocated; 180.12 MiB free; 8.32 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7fbfe9ccd536 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1cf1e (0x7fbfe9f16f1e in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1df9e (0x7fbfe9f17f9e in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7fbfecaa59e5 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf688bb (0x7fbfeb0918bb in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xfb21a7 (0x7fbfeb0db1a7 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0x1073c49 (0x7fc0279aec49 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x1073f87 (0x7fc0279aef87 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xe1ff1e (0x7fc02775af1e in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x9e0 (0x7fc027761810 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1132be1 (0x7fc027a6dbe1 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1185ee3 (0x7fc027ac0ee3 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x28aa4c2 (0x7fbfec9d34c2 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #13: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xb9 (0x7fbfec9e7ed9 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #14: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x99 (0x7fbfec9d3c59 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #15: <unknown function> + 0xf73540 (0x7fbfeb09c540 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #16: <unknown function> + 0x10c4396 (0x7fc0279ff396 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: <unknown function> + 0x2ca977c (0x7fc0295e477c in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #18: <unknown function> + 0x10c4396 (0x7fc0279ff396 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1c9 (0x7fc0291e0859 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x2d89705 (0x7fc0296c4705 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7fc0296c1a03 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7fc0296c27e2 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7fc0296bae59 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7fc035ffe5f8 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #25: <unknown function> + 0xc819d (0x7fc0686bc19d in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #26: <unknown function> + 0x9669 (0x7fc06ad99669 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #27: clone + 0x43 (0x7fc06acc1323 in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a8222d1bad24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_text_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGENRE_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLANG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_text_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     train_gpt_generator(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpathjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGENRE_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLANG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_text_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpathjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPT_MODELS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLANG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ff52f9789da3>\u001b[0m in \u001b[0;36mtrain_gpt_generator\u001b[0;34m(train_text_file, state_dict_file, n_layer, n_head, n_embd, max_epochs, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Non-thematic-Text-Classification/code/minGPT/mingpt/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Non-thematic-Text-Classification/code/minGPT/mingpt/trainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;31m# backprop and update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_norm_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.37 GiB (GPU 3; 23.65 GiB total capacity; 7.18 GiB already allocated; 180.12 MiB free; 8.32 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7fbfe9ccd536 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1cf1e (0x7fbfe9f16f1e in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1df9e (0x7fbfe9f17f9e in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7fbfecaa59e5 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf688bb (0x7fbfeb0918bb in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xfb21a7 (0x7fbfeb0db1a7 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0x1073c49 (0x7fc0279aec49 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x1073f87 (0x7fc0279aef87 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xe1ff1e (0x7fc02775af1e in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x9e0 (0x7fc027761810 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1132be1 (0x7fc027a6dbe1 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1185ee3 (0x7fc027ac0ee3 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x28aa4c2 (0x7fbfec9d34c2 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #13: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xb9 (0x7fbfec9e7ed9 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #14: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x99 (0x7fbfec9d3c59 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #15: <unknown function> + 0xf73540 (0x7fbfeb09c540 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)\nframe #16: <unknown function> + 0x10c4396 (0x7fc0279ff396 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #17: <unknown function> + 0x2ca977c (0x7fc0295e477c in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #18: <unknown function> + 0x10c4396 (0x7fc0279ff396 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1c9 (0x7fc0291e0859 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x2d89705 (0x7fc0296c4705 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7fc0296c1a03 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7fc0296c27e2 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7fc0296bae59 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7fc035ffe5f8 in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #25: <unknown function> + 0xc819d (0x7fc0686bc19d in /home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #26: <unknown function> + 0x9669 (0x7fc06ad99669 in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #27: clone + 0x43 (0x7fc06acc1323 in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "for train_text_file in tqdm.tqdm(listdir(pathjoin(GENRE_DATA_DIR, LANG))):\n",
    "    label = train_text_file[:-4]\n",
    "    train_gpt_generator(\n",
    "        pathjoin(GENRE_DATA_DIR, LANG, train_text_file),\n",
    "        pathjoin(GPT_MODELS_DIR, LANG, label)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
