{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "\n",
    "import allennlp\n",
    "import torch\n",
    "from allennlp.data import DataLoader, DatasetReader, Instance, Vocabulary\n",
    "from allennlp.data.fields import LabelField, TextField\n",
    "from allennlp.data.token_indexers import TokenIndexer, PretrainedTransformerIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules import TextFieldEmbedder, Seq2VecEncoder\n",
    "from allennlp.modules.token_embedders import PretrainedTransformerEmbedder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.seq2vec_encoders import BertPooler\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.trainer import GradientDescentTrainer, Trainer\n",
    "from allennlp.training.optimizers import AdamOptimizer\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "\n",
    "from os.path import join as pathjoin\n",
    "import pandas as pd\n",
    "from allennlp.predictors import TextClassifierPredictor\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "MODEL_ID = 'allennlp_bert_base_cased'\n",
    "transformer_model = 'bert-base-cased'\n",
    "MAX_TOKENS = 510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -100 '/home/mlepekhin/data/multi_train' > '{DATA_DIR}/multi_train'\n",
    "#!head -10 '/home/mlepekhin/data/multi_test' > '{DATA_DIR}/multi_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_indexer = PretrainedTransformerIndexer(model_name=transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDatasetReader(DatasetReader):\n",
    "    def __init__(self,\n",
    "                 lazy: bool = False,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_tokens: int = None):\n",
    "        super().__init__(lazy)\n",
    "        self.tokenizer = tokenizer or PretrainedTransformerTokenizer(transformer_model, max_length=MAX_TOKENS)\n",
    "        self.token_indexers = token_indexers or {'bert_tokens': PretrainedTransformerIndexer(transformer_model)}\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "    def text_to_instance(self, string: str, label: str = None) -> Instance:\n",
    "        tokens = self.tokenizer.tokenize(string)\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"text\": sentence_field}\n",
    "        if label is not None:\n",
    "            fields[\"label\"] = LabelField(label)\n",
    "        return Instance(fields)\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        dataset_df = pd.read_csv(file_path)\n",
    "        for text, label in zip(dataset_df['text'], dataset_df['target']):\n",
    "            yield self.text_to_instance(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(Model):\n",
    "    def __init__(self,\n",
    "                 vocab: Vocabulary,\n",
    "                 embedder: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder):\n",
    "        super().__init__(vocab)\n",
    "        self.embedder = embedder \n",
    "        num_labels = vocab.get_vocab_size(\"labels\")\n",
    "        self.encoder = encoder\n",
    "        self.classifier = torch.nn.Linear(encoder.get_output_dim(), num_labels)\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                text: Dict[str, torch.Tensor],\n",
    "                label: torch.Tensor=None) -> Dict[str, torch.Tensor]:\n",
    "        # Shape: (batch_size, num_tokens, embedding_dim)\n",
    "        embedded_text = self.embedder(text)\n",
    "        #print(\"embed shape\", embedded_text.shape)\n",
    "        # Shape: (batch_size, num_tokens)\n",
    "        mask = util.get_text_field_mask(text)\n",
    "        #print(\"mask shape\", mask.shape)\n",
    "        # Shape: (batch_size, encoding_dim)\n",
    "        encoded_text = self.encoder(embedded_text, mask)\n",
    "        # Shape: (batch_size, num_labels)\n",
    "        logits = self.classifier(encoded_text)\n",
    "        # Shape: (batch_size, num_labels)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        if label is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, label)\n",
    "            self.accuracy(logits, label)\n",
    "            return {'loss': loss, 'probs': probs}\n",
    "        else:\n",
    "            return {'probs': probs}\n",
    "    \n",
    "    def get_metrics(self, reset: bool = True) -> Dict[str, float]:\n",
    "        return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "\n",
    "\n",
    "def read_data(reader: DatasetReader, train_path: str, val_path: str) -> Tuple[Iterable[Instance], Iterable[Instance]]:\n",
    "    print(\"Reading data\")\n",
    "    training_data = reader.read(train_path)\n",
    "    validation_data = reader.read(val_path)\n",
    "    return training_data, validation_data\n",
    "\n",
    "\n",
    "def build_vocab(instances: Iterable[Instance]) -> Vocabulary:\n",
    "    print(\"Building the vocabulary\")\n",
    "    return Vocabulary.from_instances(instances)\n",
    "\n",
    "\n",
    "def build_model(vocab: Vocabulary) -> Model:\n",
    "    print(\"Building the model\")\n",
    "    vocab_size = vocab.get_vocab_size(\"tokens\")\n",
    "    #embedder = BasicTextFieldEmbedder(\n",
    "    #    {\"tokens\": Embedding(embedding_dim=10, num_embeddings=vocab_size)})\n",
    "    embedding = PretrainedTransformerEmbedder(model_name=transformer_model)\n",
    "    embedder = BasicTextFieldEmbedder(token_embedders={'bert_tokens': embedding})\n",
    "    encoder = BertPooler(transformer_model)\n",
    "    return SimpleClassifier(vocab, embedder, encoder)\n",
    "\n",
    "def build_dataset_reader() -> DatasetReader:\n",
    "    return ClassificationDatasetReader()\n",
    "\n",
    "def run_training_loop():\n",
    "    dataset_reader = build_dataset_reader()\n",
    "\n",
    "    # These are a subclass of pytorch Datasets, with some allennlp-specific\n",
    "    # functionality added.\n",
    "    train_data, dev_data = read_data(dataset_reader)\n",
    "\n",
    "    vocab = build_vocab(train_data + dev_data)\n",
    "    model = build_model(vocab)\n",
    "\n",
    "    # This is the allennlp-specific functionality in the Dataset object;\n",
    "    # we need to be able convert strings in the data to integers, and this\n",
    "    # is how we do it.\n",
    "    train_data.index_with(vocab)\n",
    "    dev_data.index_with(vocab)\n",
    "\n",
    "    # These are again a subclass of pytorch DataLoaders, with an\n",
    "    # allennlp-specific collate function, that runs our indexing and\n",
    "    # batching code.\n",
    "    train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "    # You obviously won't want to create a temporary file for your training\n",
    "    # results, but for execution in binder for this course, we need to do this.\n",
    "    with tempfile.TemporaryDirectory() as serialization_dir:\n",
    "        trainer = build_trainer(\n",
    "            model,\n",
    "            serialization_dir,\n",
    "            train_loader,\n",
    "            dev_loader\n",
    "        )\n",
    "        print(\"Starting training\")\n",
    "        trainer.train()\n",
    "        print(\"Finished training\")\n",
    "    return trainer\n",
    "\n",
    "\n",
    "# The other `build_*` methods are things we've seen before, so they are\n",
    "# in the setup section above.\n",
    "def build_data_loaders(\n",
    "    train_data: torch.utils.data.Dataset,\n",
    "    dev_data: torch.utils.data.Dataset,\n",
    ") -> Tuple[allennlp.data.DataLoader, allennlp.data.DataLoader]:\n",
    "    # Note that DataLoader is imported from allennlp above, *not* torch.\n",
    "    # We need to get the allennlp-specific collate function, which is\n",
    "    # what actually does indexing and batching.\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    dev_loader = DataLoader(dev_data, batch_size=16, shuffle=False)\n",
    "    return train_loader, dev_loader\n",
    "\n",
    "\n",
    "def build_trainer(\n",
    "    model: Model,\n",
    "    serialization_dir: str,\n",
    "    train_loader: DataLoader,\n",
    "    dev_loader: DataLoader,\n",
    "    num_epochs: int = 1,\n",
    "    cuda_device: int = -1\n",
    ") -> Trainer:\n",
    "    parameters = [\n",
    "        [n, p]\n",
    "        for n, p in model.named_parameters() if p.requires_grad\n",
    "    ]\n",
    "    optimizer = AdamOptimizer(parameters, lr=0.000025)\n",
    "    trainer = GradientDescentTrainer(\n",
    "        model=model,\n",
    "        serialization_dir=serialization_dir,\n",
    "        data_loader=train_loader,\n",
    "        validation_data_loader=dev_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        optimizer=optimizer,\n",
    "        cuda_device=cuda_device,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f2d4db7a674cb9ad52c695d0a82ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08001bd5eeb7434b93037cbf90607a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8839e985290440e9b2d4b3d7dbd62dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1686.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#trainer = run_training_loop()\n",
    "\n",
    "dataset_reader = build_dataset_reader()\n",
    "\n",
    "train_data, dev_data = read_data(\n",
    "    dataset_reader, \n",
    "    pathjoin(DATA_DIR, \"en_train\"), \n",
    "    pathjoin(DATA_DIR, \"en_test\")\n",
    ")\n",
    "\n",
    "vocab = build_vocab(train_data + dev_data)\n",
    "\n",
    "train_data.index_with(vocab)\n",
    "dev_data.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokenizer = PretrainedTransformerTokenizer(model_name=transformer_model, max_length=MAX_TOKENS)\\ntoken_indexer = PretrainedTransformerIndexer(model_name=transformer_model)\\n#text = \"Здравствуй, дорогой друг! Я очень рад тебя видеть. Что нового?\"\\ntext = \\'Привет! \\' * 150\\ntokens = tokenizer.tokenize(text)\\nprint(len(tokens))\\n#print(\"Transformer tokens:\", tokens)\\n#print(type(tokens))\\n\\ntext_field = TextField(tokens, {\\'bert_tokens\\': token_indexer})\\ntext_field.index(vocab)\\ntoken_tensor = text_field.as_tensor(text_field.get_padding_lengths())\\nprint(\"Transformer tensors:\", token_tensor)\\n\\nembedding = PretrainedTransformerEmbedder(model_name=transformer_model)\\n\\nembedder = BasicTextFieldEmbedder(token_embedders={\\'bert_tokens\\': embedding})\\n\\ntensor_dict = text_field.batch_tensors([token_tensor])\\nprint(\\'tensor_dict\\', tensor_dict)\\nembedded_tokens = embedder(tensor_dict)\\nprint(\"Transformer embedded tokens:\", embedded_tokens)\\n\\nembedded_tokens.shape\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tokenizer = PretrainedTransformerTokenizer(model_name=transformer_model, max_length=MAX_TOKENS)\n",
    "token_indexer = PretrainedTransformerIndexer(model_name=transformer_model)\n",
    "#text = \"Здравствуй, дорогой друг! Я очень рад тебя видеть. Что нового?\"\n",
    "text = 'Привет! ' * 150\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(len(tokens))\n",
    "#print(\"Transformer tokens:\", tokens)\n",
    "#print(type(tokens))\n",
    "\n",
    "text_field = TextField(tokens, {'bert_tokens': token_indexer})\n",
    "text_field.index(vocab)\n",
    "token_tensor = text_field.as_tensor(text_field.get_padding_lengths())\n",
    "print(\"Transformer tensors:\", token_tensor)\n",
    "\n",
    "embedding = PretrainedTransformerEmbedder(model_name=transformer_model)\n",
    "\n",
    "embedder = BasicTextFieldEmbedder(token_embedders={'bert_tokens': embedding})\n",
    "\n",
    "tensor_dict = text_field.batch_tensors([token_tensor])\n",
    "print('tensor_dict', tensor_dict)\n",
    "embedded_tokens = embedder(tensor_dict)\n",
    "print(\"Transformer embedded tokens:\", embedded_tokens)\n",
    "\n",
    "embedded_tokens.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_device = 0\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1\n",
    "print(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c440184666a64732b0bb1047d4af08f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e8c0ccc688491d8187cdb53292c687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d44124352c4b28a6c0f0dab824d83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52374c62e0a44ff2b397e1931d5178a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d016d2c9ef4a40e285745f991833f305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61d6f822136437ea83d7b616137c6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3c8cc6e14749678f5c8bc30b8c1147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f28e993e61548d0af5c8c94f36df1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6991c4841ab24f69a919b8329661d818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391d02fa931b44ada7cf0d56c1e91383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e7df56c6746fd8cc596019e18d6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc47e5a071704737a0197d7a12472587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917c6852776e4e4191b52db681cfb4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d4ae0352b7420a824fa85df22d7235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522d1dcfb2b441a98dc7a6b490c384d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5916cfbed65b45bd8a5253546f52cb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc477f182c494030b3f4c2f453455132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2be740447644d3e9f4fc6cad8ecd786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8adfee97e5465da06332d9305d6c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb369cb77f074c3c9f71a228998095c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "# You obviously won't want to create a temporary file for your training\n",
    "# results, but for execution in binder for this course, we need to do this.\n",
    "with tempfile.TemporaryDirectory() as serialization_dir:\n",
    "    trainer = build_trainer(\n",
    "        model,\n",
    "        serialization_dir,\n",
    "        train_loader,\n",
    "        dev_loader,\n",
    "        10,\n",
    "        cuda_device=cuda_device\n",
    "    )\n",
    "    print(\"Starting training\")\n",
    "    trainer.train()\n",
    "    print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlepekhin/anaconda3/envs/mlepekhin_research/lib/python3.8/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type SimpleClassifier. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(model.state_dict, pathjoin(MODELS_DIR, MODEL_ID, 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:vocabulary serialization directory /home/mlepekhin/models/allennlp_bert_base_cased/vocab is not empty\n"
     ]
    }
   ],
   "source": [
    "vocab.save_to_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'A12', 'A7', 'A16', 'A8', 'A22', 'A4', 'A11', 'A14', 'A9', 'A17']\n"
     ]
    }
   ],
   "source": [
    "id_to_label = []\n",
    "with open(pathjoin(MODELS_DIR, MODEL_ID, 'vocab', 'labels.txt')) as vocab_in:\n",
    "    for line in vocab_in:\n",
    "        id_to_label.append(line.strip())\n",
    "print(id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(sentence_list):\n",
    "    predictor = TextClassifierPredictor(model, dataset_reader=build_dataset_reader())\n",
    "    result = [id_to_label[np.argmax(predictor.predict(sentence)[\"probs\"])]\\\n",
    "              for sentence in sentence_list]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A16', 'A16', 'A1', 'A22']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_classes(['Здесь должно быть ваше сообщение',\n",
    "                 'Коты - лучшие домашние животные. К такому выводу пришли эксперты из издания New York Times',\n",
    "                 'It is no more than what it is.',\n",
    "                 'Жила я как-то с парнем. Я только вот на днях уволилась с работы, так как мне тяжело было работать сутки через сутки, должна была выходить на другую работу. И именно в этот период, мне сильно поплохело, начались жуткие головные боли, слабость, обмороки. Парень настоял, что нужно срочно вызывать врача. Приехала скорая, фельдшер мужик лет 50 весь седой. Позадавал вопросы мне, где болит, как болит, и зачем болит? Кто такая вообще по жизни, и чем занимаюсь? Смерил давление, температуру, написал что-то в своих бумагах, и дав лишь рекомендацию: \"больше отдыхайте, пейте воду, гуляйте на свежем воздухе\" пошёл на выход.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the time to interpret our simple classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.interpret.saliency_interpreters import SmoothGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TextClassifierPredictor(model, dataset_reader=build_dataset_reader())\n",
    "smooth_grad_interpr = SmoothGradient(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance_1': {'grad_input_1': [0.012206169837410004,\n",
       "   0.0015257712296762504,\n",
       "   0.003242263863062032,\n",
       "   0.003051542459352501,\n",
       "   0.003051542459352501,\n",
       "   0.004577313689028751,\n",
       "   0.003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.007628856148381252,\n",
       "   0.001907214037095313,\n",
       "   0.004958756496447814,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0026700996519334382,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.003051542459352501,\n",
       "   0.004577313689028751,\n",
       "   0.018309254756115004,\n",
       "   0.007628856148381252,\n",
       "   0.0026700996519334382,\n",
       "   0.004195870881609689,\n",
       "   0.0015257712296762504,\n",
       "   0.003814428074190626,\n",
       "   0.0,\n",
       "   0.0022886568445143756,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.001907214037095313,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0011443284222571878,\n",
       "   0.0015257712296762504,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0022886568445143756,\n",
       "   0.0001907214037095313,\n",
       "   0.0022886568445143756,\n",
       "   0.0015257712296762504,\n",
       "   0.003051542459352501,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0026700996519334382,\n",
       "   0.0001907214037095313,\n",
       "   0.0011443284222571878,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0026700996519334382,\n",
       "   0.0015257712296762504,\n",
       "   0.0014304105278214847,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0017164926333857818,\n",
       "   0.0015257712296762504,\n",
       "   0.001907214037095313,\n",
       "   0.0017164926333857818,\n",
       "   0.0013350498259667191,\n",
       "   0.004195870881609689,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0011443284222571878,\n",
       "   0.0003814428074190626,\n",
       "   0.0001907214037095313,\n",
       "   0.0011443284222571878,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.009154627378057502,\n",
       "   0.0015257712296762504,\n",
       "   0.0011443284222571878,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0022886568445143756,\n",
       "   0.0022886568445143756,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.0017164926333857818,\n",
       "   0.0,\n",
       "   0.0022886568445143756,\n",
       "   0.003051542459352501,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.001907214037095313,\n",
       "   0.0015257712296762504,\n",
       "   0.003051542459352501,\n",
       "   0.004577313689028751,\n",
       "   0.0022886568445143756,\n",
       "   0.0013350498259667191,\n",
       "   0.0,\n",
       "   0.001907214037095313,\n",
       "   0.003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0007628856148381252,\n",
       "   0.0001907214037095313,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.003051542459352501,\n",
       "   0.0003814428074190626,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.009154627378057502,\n",
       "   0.0036237066704810947,\n",
       "   0.0003814428074190626,\n",
       "   0.0026700996519334382,\n",
       "   0.0015257712296762504,\n",
       "   0.003051542459352501,\n",
       "   0.0022886568445143756,\n",
       "   0.0,\n",
       "   0.006103084918705002,\n",
       "   0.003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.003814428074190626,\n",
       "   0.0011443284222571878,\n",
       "   0.0013350498259667191,\n",
       "   0.0003814428074190626,\n",
       "   0.0007628856148381252,\n",
       "   0.004577313689028751,\n",
       "   0.0003814428074190626,\n",
       "   0.0022886568445143756,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0022886568445143756,\n",
       "   0.0026700996519334382,\n",
       "   0.0022886568445143756,\n",
       "   0.003814428074190626,\n",
       "   0.004577313689028751,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0053401993038668764,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.001907214037095313,\n",
       "   0.0007628856148381252,\n",
       "   0.0011443284222571878,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.004577313689028751,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.0003814428074190626,\n",
       "   0.0011443284222571878,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.004577313689028751,\n",
       "   0.0,\n",
       "   0.0034329852667715635,\n",
       "   0.00028608210556429694,\n",
       "   0.0003814428074190626,\n",
       "   0.003814428074190626,\n",
       "   0.0001907214037095313,\n",
       "   0.008391741763219378,\n",
       "   0.006103084918705002,\n",
       "   0.0007628856148381252,\n",
       "   0.0003814428074190626,\n",
       "   0.0011443284222571878,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0011443284222571878,\n",
       "   0.0015257712296762504,\n",
       "   0.0026700996519334382,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0009536070185476566,\n",
       "   0.0007628856148381252,\n",
       "   0.001907214037095313,\n",
       "   0.0013350498259667191,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.003051542459352501,\n",
       "   0.0022886568445143756,\n",
       "   0.0007628856148381252,\n",
       "   0.0011443284222571878,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.004005149477900157,\n",
       "   0.0015257712296762504,\n",
       "   0.0022886568445143756,\n",
       "   0.0,\n",
       "   0.0022886568445143756,\n",
       "   0.0017164926333857818,\n",
       "   0.0022886568445143756,\n",
       "   0.004195870881609689,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.003051542459352501,\n",
       "   0.003051542459352501,\n",
       "   0.004577313689028751,\n",
       "   0.0015257712296762504,\n",
       "   0.0011443284222571878,\n",
       "   0.006484527726124064,\n",
       "   0.0015257712296762504,\n",
       "   0.009154627378057502,\n",
       "   0.0009536070185476566,\n",
       "   0.003051542459352501,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.003051542459352501,\n",
       "   0.0,\n",
       "   0.003051542459352501,\n",
       "   0.0026700996519334382,\n",
       "   0.0005721642111285939,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0011443284222571878,\n",
       "   0.0003814428074190626,\n",
       "   0.0005721642111285939,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.001907214037095313,\n",
       "   0.0022886568445143756,\n",
       "   0.003051542459352501,\n",
       "   0.0022886568445143756,\n",
       "   0.0007628856148381252,\n",
       "   0.0034329852667715635,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.006103084918705002,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0009536070185476566,\n",
       "   0.0020979354408048444,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0011443284222571878,\n",
       "   0.002479378248223907,\n",
       "   0.006103084918705002,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0005721642111285939,\n",
       "   0.0011443284222571878,\n",
       "   0.0005721642111285939,\n",
       "   0.0003814428074190626,\n",
       "   0.0022886568445143756,\n",
       "   0.0003814428074190626,\n",
       "   0.001907214037095313,\n",
       "   0.0007628856148381252,\n",
       "   0.0022886568445143756,\n",
       "   0.0,\n",
       "   0.001907214037095313,\n",
       "   0.0,\n",
       "   0.0022886568445143756,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.003051542459352501,\n",
       "   0.0011443284222571878,\n",
       "   0.0022886568445143756,\n",
       "   0.003051542459352501,\n",
       "   0.003051542459352501,\n",
       "   0.0,\n",
       "   0.0001907214037095313,\n",
       "   0.001907214037095313,\n",
       "   0.0022886568445143756,\n",
       "   0.006103084918705002,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0005721642111285939,\n",
       "   9.536070185476565e-05,\n",
       "   0.001907214037095313,\n",
       "   0.0015257712296762504,\n",
       "   0.001907214037095313,\n",
       "   0.003051542459352501,\n",
       "   0.0012873694750393362,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.001907214037095313,\n",
       "   0.0005721642111285939,\n",
       "   0.006103084918705002,\n",
       "   0.0026700996519334382,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.006103084918705002,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.0053401993038668764,\n",
       "   0.0,\n",
       "   0.002479378248223907,\n",
       "   0.0001907214037095313,\n",
       "   0.0015257712296762504,\n",
       "   0.0026700996519334382,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.0011443284222571878,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0003814428074190626,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.01602059791160063,\n",
       "   0.004958756496447814,\n",
       "   0.001907214037095313,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0022886568445143756,\n",
       "   0.007056691937252658,\n",
       "   0.0,\n",
       "   0.0003814428074190626,\n",
       "   0.0011443284222571878,\n",
       "   0.004577313689028751,\n",
       "   0.007628856148381252,\n",
       "   0.012206169837410004,\n",
       "   0.0001907214037095313,\n",
       "   0.0,\n",
       "   0.006103084918705002,\n",
       "   0.0017164926333857818,\n",
       "   0.0001907214037095313,\n",
       "   0.0022886568445143756,\n",
       "   0.0,\n",
       "   0.0026700996519334382,\n",
       "   0.0007628856148381252,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0007628856148381252,\n",
       "   0.003814428074190626,\n",
       "   0.0,\n",
       "   0.0011443284222571878,\n",
       "   0.010680398607733753,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.011443284222571877,\n",
       "   0.0,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0022886568445143756,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0053401993038668764,\n",
       "   0.001907214037095313,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0011443284222571878,\n",
       "   0.0007628856148381252,\n",
       "   0.0017164926333857818,\n",
       "   0.003051542459352501,\n",
       "   0.0022886568445143756,\n",
       "   0.0015257712296762504,\n",
       "   0.0001907214037095313,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.0011443284222571878,\n",
       "   0.0007628856148381252,\n",
       "   0.001907214037095313,\n",
       "   0.004577313689028751,\n",
       "   0.006103084918705002,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0022886568445143756,\n",
       "   0.0026700996519334382,\n",
       "   0.0001907214037095313,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.0026700996519334382,\n",
       "   0.0021932961426596098,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.004577313689028751,\n",
       "   0.0026700996519334382,\n",
       "   0.0015257712296762504,\n",
       "   0.0005721642111285939,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0003814428074190626,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0011443284222571878,\n",
       "   0.001907214037095313,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0009536070185476566,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.003051542459352501,\n",
       "   0.009154627378057502,\n",
       "   0.006103084918705002,\n",
       "   0.001907214037095313,\n",
       "   0.0020979354408048444,\n",
       "   0.0,\n",
       "   0.003051542459352501,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0022886568445143756,\n",
       "   0.0011443284222571878,\n",
       "   0.0003814428074190626,\n",
       "   0.0003814428074190626,\n",
       "   0.0011443284222571878,\n",
       "   0.0,\n",
       "   0.0017164926333857818,\n",
       "   0.001907214037095313,\n",
       "   0.0,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.010680398607733753,\n",
       "   0.018309254756115004,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0007628856148381252,\n",
       "   0.0001907214037095313,\n",
       "   0.001907214037095313,\n",
       "   0.0001907214037095313,\n",
       "   0.0003814428074190626,\n",
       "   0.0015257712296762504,\n",
       "   0.0007628856148381252,\n",
       "   0.0022886568445143756,\n",
       "   0.0011443284222571878,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.009154627378057502,\n",
       "   0.0015257712296762504,\n",
       "   0.0003814428074190626,\n",
       "   0.0007628856148381252,\n",
       "   0.0022886568445143756,\n",
       "   0.0020979354408048444,\n",
       "   0.003051542459352501,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.001907214037095313,\n",
       "   0.006103084918705002,\n",
       "   0.001907214037095313,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0015257712296762504,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0015257712296762504,\n",
       "   0.0013350498259667191,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0011443284222571878,\n",
       "   0.004577313689028751,\n",
       "   0.0003814428074190626,\n",
       "   0.0026700996519334382,\n",
       "   0.0,\n",
       "   0.0007628856148381252,\n",
       "   0.0,\n",
       "   0.001907214037095313,\n",
       "   0.0,\n",
       "   0.001907214037095313,\n",
       "   0.0,\n",
       "   0.018309254756115004,\n",
       "   0.0015257712296762504,\n",
       "   0.0015257712296762504,\n",
       "   0.002956181757497735,\n",
       "   0.0017164926333857818,\n",
       "   0.0,\n",
       "   0.0026700996519334382,\n",
       "   0.024412339674820007]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_grad_interpr.saliency_interpret_from_json({'sentence': 'Жила я как-то с парнем. Я только вот на днях уволилась с работы, так как мне тяжело было работать сутки через сутки, должна была выходить на другую работу. И именно в этот период, мне сильно поплохело, начались жуткие головные боли, слабость, обмороки. Парень настоял, что нужно срочно вызывать врача. Приехала скорая, фельдшер мужик лет 50 весь седой. Позадавал вопросы мне, где болит, как болит, и зачем болит? Кто такая вообще по жизни, и чем занимаюсь? Смерил давление, температуру, написал что-то в своих бумагах, и дав лишь рекомендацию: \"больше отдыхайте, пейте воду, гуляйте на свежем воздухе\" пошёл на выход.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
