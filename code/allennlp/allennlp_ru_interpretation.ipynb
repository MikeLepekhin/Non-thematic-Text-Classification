{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "\n",
    "import allennlp\n",
    "import torch\n",
    "from allennlp.data import DataLoader, DatasetReader, Instance, Vocabulary\n",
    "from allennlp.data.fields import LabelField, TextField\n",
    "from allennlp.data.token_indexers import TokenIndexer, PretrainedTransformerIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules import TextFieldEmbedder, Seq2VecEncoder\n",
    "from allennlp.modules.token_embedders import PretrainedTransformerEmbedder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.seq2vec_encoders import BertPooler\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.trainer import GradientDescentTrainer, Trainer\n",
    "from allennlp.training.optimizers import AdamOptimizer\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "\n",
    "from os.path import join as pathjoin\n",
    "import pandas as pd\n",
    "from allennlp.predictors import TextClassifierPredictor\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "MODEL_ID = 'allennlp_rubert'\n",
    "CHECKPOINTS_DIR = pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints')\n",
    "BEST_MODEL = pathjoin(CHECKPOINTS_DIR, 'best.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = 'DeepPavlov/rubert-base-cased'\n",
    "MAX_TOKENS = 510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(Model):\n",
    "    def __init__(self,\n",
    "                 vocab: Vocabulary,\n",
    "                 embedder: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder):\n",
    "        super().__init__(vocab)\n",
    "        self.embedder = embedder \n",
    "        num_labels = vocab.get_vocab_size(\"labels\")\n",
    "        self.encoder = encoder\n",
    "        self.classifier = torch.nn.Linear(encoder.get_output_dim(), num_labels)\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                text: Dict[str, torch.Tensor],\n",
    "                label: torch.Tensor=None) -> Dict[str, torch.Tensor]:\n",
    "        # Shape: (batch_size, num_tokens, embedding_dim)\n",
    "        embedded_text = self.embedder(text)\n",
    "        #print(\"embed shape\", embedded_text.shape)\n",
    "        # Shape: (batch_size, num_tokens)\n",
    "        mask = util.get_text_field_mask(text)\n",
    "        #print(\"mask shape\", mask.shape)\n",
    "        # Shape: (batch_size, encoding_dim)\n",
    "        encoded_text = self.encoder(embedded_text, mask)\n",
    "        # Shape: (batch_size, num_labels)\n",
    "        logits = self.classifier(encoded_text)\n",
    "        # Shape: (batch_size, num_labels)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        if label is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, label)\n",
    "            self.accuracy(logits, label)\n",
    "            return {'loss': loss, 'probs': probs}\n",
    "        else:\n",
    "            return {'probs': probs}\n",
    "    \n",
    "    def get_metrics(self, reset: bool = True) -> Dict[str, float]:\n",
    "        return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "\n",
    "def read_data(reader: DatasetReader, train_path: str, val_path: str) -> Tuple[Iterable[Instance], Iterable[Instance]]:\n",
    "    print(\"Reading data\")\n",
    "    training_data = reader.read(train_path)\n",
    "    validation_data = reader.read(val_path)\n",
    "    return training_data, validation_data\n",
    "\n",
    "\n",
    "def build_vocab(instances: Iterable[Instance]) -> Vocabulary:\n",
    "    print(\"Building the vocabulary\")\n",
    "    return Vocabulary.from_instances(instances)\n",
    "\n",
    "\n",
    "def build_model(vocab: Vocabulary) -> Model:\n",
    "    print(\"Building the model\")\n",
    "    vocab_size = vocab.get_vocab_size(\"tokens\")\n",
    "    #embedder = BasicTextFieldEmbedder(\n",
    "    #    {\"tokens\": Embedding(embedding_dim=10, num_embeddings=vocab_size)})\n",
    "    embedding = PretrainedTransformerEmbedder(model_name=transformer_model)\n",
    "    embedder = BasicTextFieldEmbedder(token_embedders={'bert_tokens': embedding})\n",
    "    encoder = BertPooler(transformer_model)\n",
    "    return SimpleClassifier(vocab, embedder, encoder)\n",
    "\n",
    "def build_dataset_reader() -> DatasetReader:\n",
    "    return ClassificationDatasetReader()\n",
    "\n",
    "def run_training_loop():\n",
    "    dataset_reader = build_dataset_reader()\n",
    "\n",
    "    # These are a subclass of pytorch Datasets, with some allennlp-specific\n",
    "    # functionality added.\n",
    "    train_data, dev_data = read_data(dataset_reader)\n",
    "\n",
    "    vocab = build_vocab(train_data + dev_data)\n",
    "    model = build_model(vocab)\n",
    "\n",
    "    # This is the allennlp-specific functionality in the Dataset object;\n",
    "    # we need to be able convert strings in the data to integers, and this\n",
    "    # is how we do it.\n",
    "    train_data.index_with(vocab)\n",
    "    dev_data.index_with(vocab)\n",
    "\n",
    "    # These are again a subclass of pytorch DataLoaders, with an\n",
    "    # allennlp-specific collate function, that runs our indexing and\n",
    "    # batching code.\n",
    "    train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "    # You obviously won't want to create a temporary file for your training\n",
    "    # results, but for execution in binder for this course, we need to do this.\n",
    "    with tempfile.TemporaryDirectory() as serialization_dir:\n",
    "        trainer = build_trainer(\n",
    "            model,\n",
    "            serialization_dir,\n",
    "            train_loader,\n",
    "            dev_loader\n",
    "        )\n",
    "        print(\"Starting training\")\n",
    "        trainer.train()\n",
    "        print(\"Finished training\")\n",
    "    return trainer\n",
    "\n",
    "\n",
    "# The other `build_*` methods are things we've seen before, so they are\n",
    "# in the setup section above.\n",
    "def build_data_loaders(\n",
    "    train_data: torch.utils.data.Dataset,\n",
    "    dev_data: torch.utils.data.Dataset,\n",
    ") -> Tuple[allennlp.data.DataLoader, allennlp.data.DataLoader]:\n",
    "    # Note that DataLoader is imported from allennlp above, *not* torch.\n",
    "    # We need to get the allennlp-specific collate function, which is\n",
    "    # what actually does indexing and batching.\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    dev_loader = DataLoader(dev_data, batch_size=16, shuffle=False)\n",
    "    return train_loader, dev_loader\n",
    "\n",
    "\n",
    "def build_trainer(\n",
    "    model: Model,\n",
    "    serialization_dir: str,\n",
    "    train_loader: DataLoader,\n",
    "    dev_loader: DataLoader,\n",
    "    num_epochs: int = 1,\n",
    "    cuda_device: int = -1\n",
    ") -> Trainer:\n",
    "    parameters = [\n",
    "        [n, p]\n",
    "        for n, p in model.named_parameters() if p.requires_grad\n",
    "    ]\n",
    "    optimizer = AdamOptimizer(parameters, lr=0.000025)\n",
    "    trainer = GradientDescentTrainer(\n",
    "        model=model,\n",
    "        serialization_dir=serialization_dir,\n",
    "        data_loader=train_loader,\n",
    "        validation_data_loader=dev_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        optimizer=optimizer,\n",
    "        cuda_device=cuda_device,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer tokens: [[CLS], hel, ##lo, !, i, ', s, no, more, than, just, my, op, ##ini, ##on, ., but, i, want, ##ed, to, say, you, that, i, don, ', t, car, ##e, [SEP]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PretrainedTransformerTokenizer(model_name=transformer_model)\n",
    "token_indexer = PretrainedTransformerIndexer(model_name=transformer_model)\n",
    "text = \"Hello! I's no more than just my opinion. But I wanted to say you that I don't care\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"Transformer tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.interpret.saliency_interpreters import SmoothGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDatasetReader(DatasetReader):\n",
    "    def __init__(self,\n",
    "                 lazy: bool = False,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_tokens: int = None):\n",
    "        super().__init__(lazy)\n",
    "        self.tokenizer = tokenizer or PretrainedTransformerTokenizer(transformer_model, max_length=MAX_TOKENS)\n",
    "        self.token_indexers = token_indexers or {'bert_tokens': PretrainedTransformerIndexer(transformer_model)}\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "    def text_to_instance(self, string: str, label: str = None) -> Instance:\n",
    "        tokens = self.tokenizer.tokenize(string)\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"text\": sentence_field}\n",
    "        if label is not None:\n",
    "            fields[\"label\"] = LabelField(label)\n",
    "        return Instance(fields)\n",
    "\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        dataset_df = pd.read_csv(file_path)\n",
    "        for text, label in zip(dataset_df['text'], dataset_df['target']):\n",
    "            yield self.text_to_instance(text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary().from_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A8': 0, 'A12': 1, 'A1': 2, 'A14': 3, 'A11': 4, 'A17': 5, 'A16': 6, 'A4': 7, 'A9': 8, 'A7': 9}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.get_token_to_index_vocabulary('labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(BEST_MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A8', 1: 'A12', 2: 'A1', 3: 'A14', 4: 'A11', 5: 'A17', 6: 'A16', 7: 'A4', 8: 'A9', 9: 'A7'}\n",
      "dict_values(['A8', 'A12', 'A1', 'A14', 'A11', 'A17', 'A16', 'A4', 'A9', 'A7'])\n"
     ]
    }
   ],
   "source": [
    "id_to_label = vocab.get_index_to_token_vocabulary('labels')\n",
    "print(id_to_label)\n",
    "print(id_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>726</td>\n",
       "      <td>A7</td>\n",
       "      <td>Глава 1 Приступая к работе 1.1 Знакомство с те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1871</td>\n",
       "      <td>A17</td>\n",
       "      <td>Kawasaki D-Tracker С недавних пор Kawasaki d-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1265</td>\n",
       "      <td>A17</td>\n",
       "      <td>По моему , вполне достойные книги , может и не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205</td>\n",
       "      <td>A11</td>\n",
       "      <td>Тест-драйв Lada Granta : новая надежда автогра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>A8</td>\n",
       "      <td>среда , 2 декабря 2009 года , 12.33 Бумага всё...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 target                                               text\n",
       "0         726     A7  Глава 1 Приступая к работе 1.1 Знакомство с те...\n",
       "1        1871    A17  Kawasaki D-Tracker С недавних пор Kawasaki d-t...\n",
       "2        1265    A17  По моему , вполне достойные книги , может и не...\n",
       "3         205    A11  Тест-драйв Lada Granta : новая надежда автогра...\n",
       "4         141     A8  среда , 2 декабря 2009 года , 12.33 Бумага всё..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_test_df = pd.read_csv(pathjoin(DATA_DIR, 'ru_test'))\n",
    "ru_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = ru_test_df.target.values\n",
    "sentences = ru_test_df.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_description = {\n",
    "    'A1': 'argum',\n",
    "    'A3': 'emotive',\n",
    "    'A4': 'fictive',\n",
    "    'A5': 'flippant',\n",
    "    'A6': 'informal',\n",
    "    'A7': 'instruct',\n",
    "    'A8': 'reporting',\n",
    "    'A9': 'legal',\n",
    "    'A11': 'personal',\n",
    "    'A12': 'commercial',\n",
    "    'A13': 'propaganda',\n",
    "    'A14': 'research',\n",
    "    'A15': 'specialist',\n",
    "    'A16': 'info',\n",
    "    'A17': 'eval',\n",
    "    'A19': 'poetic',\n",
    "    'A20': 'appeal',\n",
    "    'A22': 'stuff'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TextClassifierPredictor(model, dataset_reader=build_dataset_reader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(sentence_list):\n",
    "    return [id_to_label[np.argmax(predictor.predict(sentence)['probs'])] for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.array(predict_classes(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label (argum) f1_score 0.7080745341614907 precision 0.7402597402597403 recall 0.6785714285714286\n",
      "label (fictive) f1_score 0.7999999999999999 precision 0.8695652173913043 recall 0.7407407407407407\n",
      "label (instruct) f1_score 0.8275862068965517 precision 0.7058823529411765 recall 1.0\n",
      "label (reporting) f1_score 0.9483568075117371 precision 0.9805825242718447 recall 0.9181818181818182\n",
      "label (legal) f1_score 0.8148148148148148 precision 0.8461538461538461 recall 0.7857142857142857\n",
      "label (personal) f1_score 0.6516853932584269 precision 0.5918367346938775 recall 0.725\n",
      "label (commercial) f1_score 0.9467455621301775 precision 0.9411764705882353 recall 0.9523809523809523\n",
      "label (research) f1_score 0.8627450980392157 precision 0.8979591836734694 recall 0.8301886792452831\n",
      "label (info) f1_score 0.4680851063829786 precision 0.3333333333333333 recall 0.7857142857142857\n",
      "label (eval) f1_score 0.6582278481012658 precision 0.7647058823529411 recall 0.5777777777777777\n",
      "accuracy 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "for label, description in label_description.items():\n",
    "    true_binary = true_classes == label\n",
    "    if np.sum(true_binary) == 0:\n",
    "        continue\n",
    "    predicted_binary = predicted_classes == label\n",
    "    print(\n",
    "        f\"label ({description})\", \n",
    "        f\"f1_score {f1_score(predicted_binary, true_binary)}\", \n",
    "        f\"precision {precision_score(predicted_binary, true_binary)}\", \n",
    "        f\"recall {recall_score(predicted_binary, true_binary)}\", \n",
    "    )\n",
    "print(f\"accuracy\", accuracy_score(predicted_classes, true_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_model, y_true):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    labels_list = list(id_to_label.values())\n",
    "    cm = confusion_matrix(y_model, y_true, labels=labels_list)\n",
    "    sums = np.sum(cm, axis=1)\n",
    "    normed_cm = (cm.T / sums).T\n",
    "    sns.heatmap(normed_cm)\n",
    "    labels_descr = [label_description[label] for label in id_to_label.values()]\n",
    "    plt.xticks(0.5 + np.arange(len(labels_list)), labels=labels_descr, fontsize=12)\n",
    "    plt.yticks(0.5 + np.arange(len(labels_list)), labels=labels_descr, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(predicted_classes, true_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency Gradient Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.interpret.saliency_interpreters import SmoothGradient, SimpleGradient, IntegratedGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_grad = SmoothGradient(predictor)\n",
    "simple_grad = SimpleGradient(predictor)\n",
    "integrated_grad = IntegratedGradient(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interpreter(sentence, tokens, k, interpreter):\n",
    "    vec = np.array(interpreter.saliency_interpret_from_json({\"sentence\": sentence})['instance_1']['grad_input_1'])\n",
    "    important_indices = set(vec.argsort()[-k:])\n",
    "    \n",
    "    print(type(interpreter), \"TEXT:\")\n",
    "    for token_id, token in enumerate(tokens):\n",
    "        if token_id in important_indices:\n",
    "            print(colored(token , \"red\"), end=' ')\n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "def interpret_sentence(sentence, k, interpreters=[], true_label=None, label=None):\n",
    "    if true_label is not None:\n",
    "        print(\"TRUE LABEL:\", true_label)\n",
    "    if label is not None:\n",
    "        print(\"LABEL:\", label)\n",
    "    \n",
    "    tokens = tokenizer.tokenize(sentence)[1:511]\n",
    "    k = min(k, len(tokens))\n",
    "    for interpreter in interpreters:\n",
    "        run_interpreter(sentence, tokens, k, interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_ids = []\n",
    "\n",
    "for sent_id in range(len(true_classes)):\n",
    "    if true_classes[sent_id] != predicted_classes[sent_id]:\n",
    "        mistake_ids.append(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABEL: personal\n",
      "LABEL: eval\n",
      "<class 'allennlp.interpret.saliency_interpreters.smooth_gradient.SmoothGradient'> TEXT:\n",
      "тест - дра ##ив \u001b[31mla\u001b[0m ##da gran ##ta : новая надежда авто ##града фактически \u001b[31m,\u001b[0m новая la ##da gran ##ta - это старая \u001b[31mla\u001b[0m ##da ka ##lin ##a плюс 400 новых дет ##але ##и . но назвать грант ##у всего лишь рест ##аи ##лингом калин ##ы язык не поверн ##ется . автомобиль \u001b[31mдеи\u001b[0m ##ств ##ительно изменился и на самом деле стал лучше прежних продуктов автов ##аза . но поч ##ивать на лав ##рах тольят ##тин ##цам еще рано . ko ##les ##a . r u выяснили \u001b[31m,\u001b[0m почему . сюрприз ##ы поджид ##али еще до проб ##но ##и поездки на la ##da gran ##ta . \u001b[31mпровод\u001b[0m ##ив меня к машине , сотрудник \u001b[31mавтос\u001b[0m ##алона объяснил \u001b[31mмне\u001b[0m \u001b[31mкак\u001b[0m пользоваться бр ##ел ##ком дополнительно ##и сигнализации : \" если нажать на эту кнопку и немного подерж ##ать , двигатель завед ##ется ! \" нажим \u001b[31m##ает\u001b[0m . держит . не заводит ##ся . \" наверное это из - за вашего коллеги , котор ##ы ##и открыл заднюю дверь , пока я жал на кнопку \u001b[31m\"\u001b[0m . \u001b[31mдверь\u001b[0m закрыли , еще пару раз поставили - сняли с охраны . снова \u001b[31mне\u001b[0m заводит ##ся . \" ы специально для вас машину \u001b[31mвчера\u001b[0m пом ##ыли , а ночью \u001b[31mмороз\u001b[0m \u001b[31mударил\u001b[0m \u001b[31m;\u001b[0m наверное \u001b[31mзамерз\u001b[0m ##ла \u001b[31m\"\u001b[0m . \u001b[31mменеджер\u001b[0m был явно \u001b[31mвстревож\u001b[0m ##ен , но держался \u001b[31mмолод\u001b[0m ##цом , и я на самом деле поверил \u001b[31mего\u001b[0m удивлению неожиданно ##и наклад ##ке . на трети ##и раз gran ##ta завела ##сь ! для убедительно ##сти заглуш ##или мотор и повторили \u001b[31mпроцедуру\u001b[0m : двигатель ново ##и лад ##а без проблем запустил \u001b[31m##ся\u001b[0m одним наж ##атием кнопки . впрочем \u001b[31m,\u001b[0m даже если бы трюк с бр ##елок ##ом не удался , претензии были бы не к автов ##азу , а к установ ##щикам доп ##оборуд ##ования , ведь сигнализация с дистанц ##ионным запуском идет как опция , причем не завод ##ская . я \u001b[31mзабрал\u001b[0m ключи и попробовал устроиться \u001b[31mза\u001b[0m рулем gran ##ta . автомобиль цвета \" порт ##ве ##ин \" был в комплектации норма за 260 000 рубл ##еи . поэтому в машине было все , чем на дан ##ны ##и момент ( максимальная комплекта ##ция люкс вы ##идет летом 2012 года ) богата лад ##а гранта . например , кожан ##ы ##и салон \u001b[31m,\u001b[0m фирмен ##ны ##и сенс ##орн ##ы ##и дисп ##леи с навиг \u001b[31m##аци\u001b[0m ##еи , люк на всю крышу \u001b[31m.\u001b[0m . . шу ##чу , конечно . если серьезно , то салон может порад \u001b[31m##овать\u001b[0m мягким \u001b[31m,\u001b[0m \u001b[31mно\u001b[0m не \u001b[31mочень\u001b[0m \u001b[31mудобным\u001b[0m \u001b[31mкресло\u001b[0m ##м , регулируем \u001b[31m##ым\u001b[0m только по углу наклона спин ##ки и в продольно \u001b[31m##м\u001b[0m направлении . был \u001b[31mдаже\u001b[0m бортов ##ои компьютер \u001b[31m,\u001b[0m почему - то утвержд ##авш \u001b[31m##ии\u001b[0m , что \u001b[31mсред\u001b[0m ##нии расход топлива 16 литров . дополнительная магнито ##ла избав ##ила от необходимости видеть пуст ##ую полку в центрально ##и консоли \u001b[31m.\u001b[0m выж ##ал сцепление и прид ##вину ##лся на оптим \u001b[31m##альное\u001b[0m расстояние \" по ногам \" , после чего понял \u001b[31m,\u001b[0m что к рул ##ю придется \u001b[31mтянут\u001b[0m ##ься . регулиров \u001b[31m##ка\u001b[0m руля есть только по высоте , поэтому пришлось \u001b[31mпод\u001b[0m ##од ##вига ##ть \n",
      "\n",
      "<class 'allennlp.interpret.saliency_interpreters.simple_gradient.SimpleGradient'> TEXT:\n",
      "\u001b[31mтест\u001b[0m - дра ##ив la ##da gran ##ta : новая надежда авто \u001b[31m##града\u001b[0m \u001b[31mфактически\u001b[0m , новая \u001b[31mla\u001b[0m \u001b[31m##da\u001b[0m gran ##ta - \u001b[31mэто\u001b[0m \u001b[31mстарая\u001b[0m \u001b[31mla\u001b[0m \u001b[31m##da\u001b[0m \u001b[31mka\u001b[0m \u001b[31m##lin\u001b[0m ##a плюс 400 новых дет ##але ##и . но назвать грант ##у всего лишь рест ##аи ##лингом калин ##ы язык не поверн ##ется . автомобиль деи ##ств ##ительно изменился и на самом деле стал лучше прежних продуктов автов ##аза . но \u001b[31mпоч\u001b[0m ##ивать на лав ##рах тольят ##тин ##цам еще рано . ko ##les ##a . \u001b[31mr\u001b[0m \u001b[31mu\u001b[0m выяснили , почему \u001b[31m.\u001b[0m сюрприз ##ы поджид \u001b[31m##али\u001b[0m еще до проб ##но ##и поездки на la ##da gran ##ta . провод ##ив меня \u001b[31mк\u001b[0m машине , сотрудник автос ##алона \u001b[31mобъяснил\u001b[0m \u001b[31mмне\u001b[0m как пользоваться бр ##ел ##ком дополнительно ##и сигнализации : \u001b[31m\"\u001b[0m если нажать на эту кнопку и немного подерж ##ать , двигатель завед ##ется ! \" нажим ##ает . держит . не заводит ##ся . \" наверное это из - за вашего коллеги , котор ##ы ##и открыл заднюю дверь , пока я жал на кнопку \" . дверь закрыли , еще пару \u001b[31mраз\u001b[0m поставили - сняли с охраны . снова не \u001b[31mзаводит\u001b[0m ##ся . \" ы специально для вас \u001b[31mмашину\u001b[0m вчера пом ##ыли , а ночью мороз ударил ; \u001b[31mнаверное\u001b[0m \u001b[31mзамерз\u001b[0m ##ла \" \u001b[31m.\u001b[0m \u001b[31mменеджер\u001b[0m \u001b[31mбыл\u001b[0m явно встревож \u001b[31m##ен\u001b[0m , но \u001b[31mдержался\u001b[0m \u001b[31mмолод\u001b[0m \u001b[31m##цом\u001b[0m , и я на самом деле поверил его удивлению неожиданно ##и наклад ##ке . на трети ##и раз gran \u001b[31m##ta\u001b[0m завела ##сь ! для убедительно ##сти заглуш ##или мотор и повторили процедуру : двигатель ново ##и лад ##а без проблем запустил ##ся одним наж ##атием кнопки . впрочем , даже если бы трюк с бр ##елок ##ом не удался , претензии были бы не к автов ##азу , а к установ ##щикам доп ##оборуд ##ования , ведь сигнализация с дистанц ##ионным запуском идет как опция , причем не завод ##ская . я забрал ключи и попробовал устроиться за рулем gran ##ta . автомобиль цвета \" порт ##ве ##ин \" был в комплектации норма за 260 000 рубл ##еи . поэтому в машине было все , чем на дан ##ны ##и момент ( максимальная комплекта ##ция люкс вы ##идет летом 2012 года ) богата лад ##а гранта . например , кожан ##ы ##и салон , фирмен ##ны ##и сенс \u001b[31m##орн\u001b[0m ##ы ##и дисп ##леи с навиг ##аци ##еи , люк на всю крышу . . . шу ##чу \u001b[31m,\u001b[0m конечно . если серьезно , то салон может \u001b[31mпорад\u001b[0m ##овать \u001b[31mмягким\u001b[0m , но не очень удобным кресло \u001b[31m##м\u001b[0m , регулируем \u001b[31m##ым\u001b[0m только по углу наклона спин ##ки и в продольно ##м направлении . был даже бортов ##ои компьютер , почему - то утвержд \u001b[31m##авш\u001b[0m \u001b[31m##ии\u001b[0m , что сред ##нии расход топлива \u001b[31m16\u001b[0m литров . \u001b[31mдополнительная\u001b[0m \u001b[31mмагнито\u001b[0m \u001b[31m##ла\u001b[0m избав \u001b[31m##ила\u001b[0m от необходимости видеть пуст \u001b[31m##ую\u001b[0m полку в центрально ##и консоли \u001b[31m.\u001b[0m выж ##ал сцепление и прид ##вину ##лся на оптим ##альное расстояние \" по ногам \" , после чего понял \u001b[31m,\u001b[0m что к рул ##ю придется тянут ##ься . регулиров ##ка руля есть только по высоте , поэтому пришлось под ##од ##вига ##ть \n",
      "\n",
      "<class 'allennlp.interpret.saliency_interpreters.integrated_gradient.IntegratedGradient'> TEXT:\n",
      "\u001b[31mтест\u001b[0m - дра ##ив la ##da gran ##ta : новая надежда авто \u001b[31m##града\u001b[0m фактически , новая la \u001b[31m##da\u001b[0m gran ##ta - это \u001b[31mстарая\u001b[0m la ##da ka ##lin ##a плюс 400 новых дет ##але ##и . но назвать грант ##у всего \u001b[31mлишь\u001b[0m \u001b[31mрест\u001b[0m ##аи ##лингом калин ##ы язык не поверн ##ется . автомобиль деи ##ств ##ительно изменился и на самом деле \u001b[31mстал\u001b[0m \u001b[31mлучше\u001b[0m \u001b[31mпрежних\u001b[0m продуктов автов ##аза . \u001b[31mно\u001b[0m \u001b[31mпоч\u001b[0m ##ивать на лав ##рах тольят ##тин ##цам еще \u001b[31mрано\u001b[0m . ko ##les ##a . r u выяснили , почему \u001b[31m.\u001b[0m сюрприз ##ы \u001b[31mподжид\u001b[0m ##али еще до проб ##но ##и поездки на la ##da gran ##ta . провод ##ив меня к машине , сотрудник автос ##алона объяснил мне как пользоваться бр ##ел ##ком дополнительно ##и сигнализации : \" если нажать на эту кнопку и немного подерж ##ать , \u001b[31mдвигатель\u001b[0m завед ##ется ! \" нажим ##ает . держит . не заводит ##ся . \" наверное это из - за вашего коллеги , котор ##ы ##и открыл заднюю дверь , \u001b[31mпока\u001b[0m я жал на кнопку \" \u001b[31m.\u001b[0m дверь \u001b[31mзакрыли\u001b[0m \u001b[31m,\u001b[0m \u001b[31mеще\u001b[0m пару раз поставили - сняли \u001b[31mс\u001b[0m охраны \u001b[31m.\u001b[0m \u001b[31mснова\u001b[0m не заводит \u001b[31m##ся\u001b[0m \u001b[31m.\u001b[0m \u001b[31m\"\u001b[0m \u001b[31mы\u001b[0m специально для вас \u001b[31mмашину\u001b[0m вчера пом ##ыли , \u001b[31mа\u001b[0m ночью мороз ударил ; наверное замерз ##ла \" . \u001b[31mменеджер\u001b[0m \u001b[31mбыл\u001b[0m явно встревож ##ен , но держался молод ##цом , и я на самом деле поверил его удивлению неожиданно ##и наклад ##ке . на трети ##и раз gran ##ta завела ##сь ! для убедительно ##сти заглуш ##или мотор и повторили процедуру : двигатель ново ##и лад ##а без проблем запустил ##ся одним наж ##атием кнопки . впрочем , даже если бы трюк с бр ##елок ##ом не удался , претензии были бы не к автов ##азу , а к установ ##щикам доп ##оборуд ##ования , ведь сигнализация с дистанц ##ионным запуском идет как опция , причем не завод ##ская . я забрал ключи и попробовал устроиться за рулем gran ##ta . автомобиль цвета \" порт ##ве ##ин \" был в комплектации \u001b[31mнорма\u001b[0m за 260 000 рубл ##еи . поэтому в машине было все , чем на дан ##ны ##и момент ( максимальная комплекта ##ция люкс вы ##идет летом 2012 \u001b[31mгода\u001b[0m ) богата лад ##а гранта . например , кожан \u001b[31m##ы\u001b[0m ##и салон , фирмен ##ны ##и \u001b[31mсенс\u001b[0m ##орн ##ы ##и дисп ##леи с навиг ##аци ##еи , люк на всю крышу . . . шу ##чу , конечно \u001b[31m.\u001b[0m \u001b[31mесли\u001b[0m серьезно \u001b[31m,\u001b[0m то салон может \u001b[31mпорад\u001b[0m ##овать мягким \u001b[31m,\u001b[0m \u001b[31mно\u001b[0m не \u001b[31mочень\u001b[0m \u001b[31mудобным\u001b[0m кресло ##м , регулируем ##ым только \u001b[31mпо\u001b[0m \u001b[31mуглу\u001b[0m наклона спин ##ки и в продольно ##м направлении . был даже бортов ##ои компьютер , почему - то утвержд ##авш ##ии , что сред ##нии расход топлива 16 литров . дополнительная магнито ##ла избав ##ила от необходимости видеть пуст ##ую полку в центрально ##и консоли . выж ##ал сцепление и прид ##вину ##лся на оптим ##альное расстояние \" по ногам \" , после чего понял , что к рул ##ю придется тянут ##ься . регулиров ##ка руля есть \u001b[31mтолько\u001b[0m по высоте \u001b[31m,\u001b[0m поэтому \u001b[31mпришлось\u001b[0m \u001b[31mпод\u001b[0m ##од ##вига ##ть \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_sentence(\n",
    "    sentences[mistake_ids[0]], 50, \n",
    "    [smooth_grad, simple_grad, integrated_grad],\n",
    "    label_description[true_classes[mistake_ids[0]]],\n",
    "    label_description[predicted_classes[mistake_ids[0]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABEL: personal\n",
      "LABEL: eval\n",
      "<class 'allennlp.interpret.saliency_interpreters.smooth_gradient.SmoothGradient'> TEXT:\n",
      "я хотел бы рассказать немного о том , что мне нравится \u001b[31mписать\u001b[0m \u001b[31m.\u001b[0m я люблю \u001b[31mпогруж\u001b[0m ##аться в тему , о котор ##ои пишу \u001b[31m.\u001b[0m мне нравится окун ##уться в тему с голово ##и и почувствовать себя таким подоп ##ыт ##ным кролик ##ом . я рассматрив ##аю свою жизнь как ряд экспериментов . ит \u001b[31m##ак\u001b[0m , я работа ##ю в журнале \u001b[31mes\u001b[0m \u001b[31m##quir\u001b[0m \u001b[31m##e\u001b[0m , и пару лет назад я написал статью под названием \" аутсор ##синг в мое ##и жизни \" ; я нанял группу люд ##еи в банг \u001b[31m##ало\u001b[0m ##ре , инди ##я , чтобы они прожили \u001b[31mмою\u001b[0m жизнь за меня . и они просматр \u001b[31m##ивали\u001b[0m за меня мою электронную почту и отвечали на письма . они отвечали на мои телефонные \u001b[31mзвонки\u001b[0m \u001b[31m.\u001b[0m они спор ##или вместо меня \u001b[31mс\u001b[0m мое ##и жен ##ои и читали моему \u001b[31mсыну\u001b[0m сказки на ночь . это был луч \u001b[31m##ши\u001b[0m ##и месяц мое ##и жизни , потому что я просто сидел , читал книги \u001b[31mи\u001b[0m смотрел фильмы . это был чудес ##ны ##и опыт \u001b[31m.\u001b[0m \u001b[31mпозже\u001b[0m , я написал \u001b[31mдля\u001b[0m es \u001b[31m##quir\u001b[0m ##e статью - - о радикально ##и честности . это \u001b[31mдвижение\u001b[0m , \u001b[31mбыло\u001b[0m начато психологом из вир \u001b[31m##джин\u001b[0m \u001b[31m##ии\u001b[0m , котор ##ы ##и утверждал , что никогда , ни при каких обстоятельствах не следует л ##гать , разве что во время игры \u001b[31mв\u001b[0m покер \u001b[31mи\u001b[0m гольф - только это исключение он сделал . и , более того , вообще все то , что у тебя \u001b[31mна\u001b[0m уме , должно быть и на языке . я решил не л ##гать в течение месяца . это был худ ##ши ##и месяц мое ##и жизни . ( смех ) я никому не совету ##ю это повторять . чтобы вы поняли , что это за жизнь , скажу , что статья \u001b[31mназывалась\u001b[0m \u001b[31m\"\u001b[0m по - моему , ты толстая \" . ( смех ) это было тяжело . моя последняя \u001b[31mкнига\u001b[0m \u001b[31m—\u001b[0m до нее была книга под названием \" хочу все знать \" , она о год ##е , котор ##ы ##и я провел , читая \u001b[31mбританскую\u001b[0m \u001b[31mэнциклопедию\u001b[0m от a до z , чтобы узнать все обо всем во всем мире , или , если быть точнее , от a - ak , вида восточно ##азиат \u001b[31m##ско\u001b[0m ##и музыки \u001b[31m,\u001b[0m и до z ##w ##yi ##ec — не скажу что это , не буду \u001b[31mпорт\u001b[0m ##ить сюрприз . ( смех \u001b[31m)\u001b[0m там очень \u001b[31mувлек\u001b[0m \u001b[31m##ательная\u001b[0m \u001b[31mвит\u001b[0m ##иева \u001b[31m##тая\u001b[0m концовка , прямо как в произведениях о ' ген ##ри , и поэтому не хочется \u001b[31mее\u001b[0m порт ##ить . \u001b[31mно\u001b[0m мне этот эксперимент \u001b[31mпонравился\u001b[0m \u001b[31m,\u001b[0m потому что он показывал , как много информации может воб ##рать в себя один человеческ ##ии мозг , несмотря на то , что к ##еви ##н кел ##ли рекомендует \u001b[31mнам\u001b[0m ничего не запомина \u001b[31m##ть\u001b[0m вообще . вы можете просто \" прог ##угли ##ть \" этот вопрос . поэтому я потратил немного времени на это . мне нравятся эти эксперименты \u001b[31m,\u001b[0m но я считаю самым важным и даже поворотным в жизни мои сам ##ы ##и послед \u001b[31m##нии\u001b[0m эксперимент , во время которого я \n",
      "\n",
      "<class 'allennlp.interpret.saliency_interpreters.simple_gradient.SimpleGradient'> TEXT:\n",
      "\u001b[31mя\u001b[0m хотел бы рассказать немного о том , что мне нравится \u001b[31mписать\u001b[0m . я люблю погруж ##аться в тему , о котор ##ои пишу . мне нравится \u001b[31mокун\u001b[0m ##уться в тему с голово ##и и почувствовать себя таким подоп ##ыт ##ным кролик ##ом . я рассматрив ##аю свою жизнь как ряд экспериментов . ит ##ак , я работа ##ю в журнале es \u001b[31m##quir\u001b[0m \u001b[31m##e\u001b[0m , и пару лет назад я написал статью под названием \" аутсор ##синг в мое ##и жизни \" ; я нанял группу люд ##еи в банг ##ало ##ре , инди ##я , чтобы они прожили мою \u001b[31mжизнь\u001b[0m за меня . \u001b[31mи\u001b[0m они просматр ##ивали за меня мою электронную \u001b[31mпочту\u001b[0m и отвечали на письма . \u001b[31mони\u001b[0m отвечали на мои телефонные звонки \u001b[31m.\u001b[0m они спор ##или вместо меня с мое ##и жен ##ои и читали моему сыну сказки на ночь . это был луч ##ши ##и месяц мое ##и жизни , потому что я просто сидел , читал книги и смотрел фильмы \u001b[31m.\u001b[0m это был чудес ##ны ##и опыт . позже \u001b[31m,\u001b[0m я написал \u001b[31mдля\u001b[0m es \u001b[31m##quir\u001b[0m \u001b[31m##e\u001b[0m статью - - о радикально ##и честности . \u001b[31mэто\u001b[0m \u001b[31mдвижение\u001b[0m , было начато психологом из вир ##джин ##ии , \u001b[31mкотор\u001b[0m \u001b[31m##ы\u001b[0m ##и утверждал , \u001b[31mчто\u001b[0m никогда , \u001b[31mни\u001b[0m при каких обстоятельствах не следует л ##гать , разве \u001b[31mчто\u001b[0m во время игры в покер и гольф - только это исключение он сделал . и , более того , вообще все то , что у тебя на уме , должно быть и на языке . я решил не л ##гать в течение месяца . это был худ ##ши ##и месяц мое ##и жизни . ( смех ) \u001b[31mя\u001b[0m никому не совету ##ю это повторять . чтобы вы поняли , что это за жизнь , скажу , что статья называлась \" по - моему , ты толстая \" . ( смех ) это было тяжело . моя последняя \u001b[31mкнига\u001b[0m — \u001b[31mдо\u001b[0m нее была книга под названием \" хочу все знать \" , она о год ##е , котор ##ы ##и я провел , читая британскую энциклопедию от a до z , чтобы узнать все обо всем во всем мире , или , если быть точнее , от a \u001b[31m-\u001b[0m ak , вида восточно ##азиат \u001b[31m##ско\u001b[0m ##и музыки , и до z ##w ##yi ##ec \u001b[31m—\u001b[0m не скажу что это , не буду порт ##ить сюрприз . \u001b[31m(\u001b[0m смех ) там очень \u001b[31mувлек\u001b[0m \u001b[31m##ательная\u001b[0m вит ##иева \u001b[31m##тая\u001b[0m концовка \u001b[31m,\u001b[0m прямо \u001b[31mкак\u001b[0m в \u001b[31mпроизведениях\u001b[0m \u001b[31mо\u001b[0m \u001b[31m'\u001b[0m ген \u001b[31m##ри\u001b[0m , и поэтому не хочется ее порт \u001b[31m##ить\u001b[0m . но \u001b[31mмне\u001b[0m \u001b[31mэтот\u001b[0m \u001b[31mэксперимент\u001b[0m \u001b[31mпонравился\u001b[0m \u001b[31m,\u001b[0m \u001b[31mпотому\u001b[0m что он \u001b[31mпоказывал\u001b[0m , как много информации может воб ##рать в себя один человеческ ##ии мозг , несмотря на то , что \u001b[31mк\u001b[0m ##еви ##н кел ##ли рекомендует \u001b[31mнам\u001b[0m ничего не запомина ##ть вообще . вы можете просто \" прог ##угли ##ть \" этот вопрос . поэтому я потратил немного времени на это . мне нравятся \u001b[31mэти\u001b[0m эксперименты , но я считаю самым важным и даже поворотным в жизни мои сам ##ы ##и послед ##нии эксперимент , во время которого я \n",
      "\n",
      "<class 'allennlp.interpret.saliency_interpreters.integrated_gradient.IntegratedGradient'> TEXT:\n",
      "\u001b[31mя\u001b[0m хотел бы рассказать немного \u001b[31mо\u001b[0m том , что мне нравится \u001b[31mписать\u001b[0m . я люблю погруж ##аться в тему , о котор ##ои пишу . мне нравится \u001b[31mокун\u001b[0m ##уться в тему с голово ##и и почувствовать себя таким подоп ##ыт ##ным кролик ##ом . я рассматрив ##аю свою жизнь как ряд экспериментов . ит ##ак , я работа \u001b[31m##ю\u001b[0m в журнале \u001b[31mes\u001b[0m ##quir ##e , и пару \u001b[31mлет\u001b[0m назад я написал статью под названием \" аутсор ##синг в мое ##и жизни \" ; я нанял \u001b[31mгруппу\u001b[0m люд ##еи в банг ##ало ##ре , инди ##я , чтобы они прожили мою жизнь за меня . и они просматр \u001b[31m##ивали\u001b[0m за меня мою электронную \u001b[31mпочту\u001b[0m и отвечали на письма . \u001b[31mони\u001b[0m отвечали на мои телефонные звонки . \u001b[31mони\u001b[0m спор ##или вместо меня с мое ##и жен ##ои \u001b[31mи\u001b[0m читали \u001b[31mмоему\u001b[0m сыну сказки на ночь . это \u001b[31mбыл\u001b[0m луч ##ши ##и месяц мое ##и жизни , потому что я просто сидел , читал книги и смотрел фильмы \u001b[31m.\u001b[0m это был чудес ##ны ##и опыт . \u001b[31mпозже\u001b[0m , я \u001b[31mнаписал\u001b[0m для es \u001b[31m##quir\u001b[0m \u001b[31m##e\u001b[0m \u001b[31mстатью\u001b[0m - \u001b[31m-\u001b[0m о \u001b[31mрадикально\u001b[0m \u001b[31m##и\u001b[0m \u001b[31mчестности\u001b[0m . это \u001b[31mдвижение\u001b[0m \u001b[31m,\u001b[0m было начато психологом из вир ##джин ##ии , котор \u001b[31m##ы\u001b[0m ##и утверждал , что никогда , ни при каких обстоятельствах не следует л ##гать , разве что во время игры \u001b[31mв\u001b[0m покер \u001b[31mи\u001b[0m гольф - только это исключение он сделал . и , более того , вообще все то , что у тебя на уме , должно быть и на языке . я решил не л ##гать в течение месяца . это был худ ##ши ##и месяц мое ##и жизни . \u001b[31m(\u001b[0m смех ) я никому не совету ##ю это повторять . чтобы вы поняли , что это за жизнь , скажу , что статья называлась \" по - моему , ты толстая \" . ( смех ) это было тяжело . моя последняя книга — до нее была книга под названием \" хочу все знать \" , она о год ##е , котор ##ы ##и я провел , читая британскую энциклопедию от a до z , чтобы узнать все обо всем во всем мире , или , \u001b[31mесли\u001b[0m быть точнее , от a - ak , вида \u001b[31mвосточно\u001b[0m \u001b[31m##азиат\u001b[0m \u001b[31m##ско\u001b[0m ##и музыки \u001b[31m,\u001b[0m \u001b[31mи\u001b[0m до \u001b[31mz\u001b[0m ##w ##yi ##ec — не скажу что это , не буду порт ##ить сюрприз . ( смех \u001b[31m)\u001b[0m там очень \u001b[31mувлек\u001b[0m ##ательная вит ##иева ##тая \u001b[31mконцовка\u001b[0m , прямо как в произведениях \u001b[31mо\u001b[0m ' \u001b[31mген\u001b[0m ##ри , и поэтому не хочется ее порт ##ить \u001b[31m.\u001b[0m но мне этот эксперимент \u001b[31mпонравился\u001b[0m \u001b[31m,\u001b[0m потому что он показывал , как много информации может воб ##рать в себя один человеческ ##ии мозг , несмотря на то , что \u001b[31mк\u001b[0m ##еви ##н кел ##ли рекомендует нам ничего не запомина ##ть вообще . вы можете \u001b[31mпросто\u001b[0m \" прог ##угли ##ть \" этот вопрос . поэтому я потратил немного времени на это . мне нравятся \u001b[31mэти\u001b[0m эксперименты , но я считаю самым важным и даже поворотным в жизни мои сам ##ы ##и послед ##нии эксперимент , во время которого я \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_sentence(\n",
    "    sentences[mistake_ids[1]], 50, \n",
    "    [smooth_grad, simple_grad, integrated_grad],\n",
    "    label_description[true_classes[mistake_ids[1]]],\n",
    "    label_description[predicted_classes[mistake_ids[1]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABEL: research\n",
      "LABEL: argum\n",
      "<class 'allennlp.interpret.saliency_interpreters.smooth_gradient.SmoothGradient'> TEXT:\n",
      "когда мы смотри ##м новости \u001b[31m,\u001b[0m мы видим сообщения из ирак \u001b[31m##а\u001b[0m , афган ##истана , с ##ьерра - ле ##оне , и кажется , что эти конфликты \u001b[31mневозможно\u001b[0m \u001b[31mпонять\u001b[0m . именно так я и думал , когда начинал этот проект . но я физик \u001b[31m,\u001b[0m и поэтому решил на ##ити данные и попробовать разобраться . просто попробовать . ну и как на ##ив ##ны ##и новозеланд ##ец \u001b[31mя\u001b[0m подумал , что по ##иду в пента \u001b[31m##гон\u001b[0m . не могли бы вы поделиться со мн ##ои информ ##аци ##еи ? ( смех ) нет . поэтому пришлось задуматься пос ##ерьез ##нее . и вот однажды вечером в оксфорд \u001b[31m##е\u001b[0m я смотрел новости . и обратил \u001b[31mвнимание\u001b[0m на экран под говоря ##щи ##ми головами \u001b[31m.\u001b[0m и обнаружил там информацию . там были данные , в ль ##ющихся на нас потока ##х новост ##еи . весь шум вокруг нас деи ##ств ##ительно содержит информацию . и мне пришла в голову мысль организовать нечто вроде разведки \u001b[31mпо\u001b[0m открытым источникам . если ском ##бин ##ировать данные изо всех этих потоков \u001b[31m,\u001b[0m возможно , мы сможем понять воин ##у . именно так я и поступил \u001b[31m.\u001b[0m мы начали собирать команду , междисциплин ##арную команду ученых , экономистов \u001b[31m,\u001b[0m математиков . мы собрали \u001b[31mэтих\u001b[0m \u001b[31mребят\u001b[0m \u001b[31m,\u001b[0m и начали работу над проблем \u001b[31m##ои\u001b[0m . в работе было три этапа . перв ##ы ##и — собрать данные . мы обработал ##и 130 источников информации : от отчетов ng ##o до газет и теленов ##ост ##еи . мы собрали эти данные и от ##филь ##тр ##овали их . достал ##и из них важные для наше ##и базы данных кусочки . в это ##и базе было время атак \u001b[31m,\u001b[0m координаты , масштаб и тип использован ##ного оружия . все это есть в ежедневных новостях , нужно просто уметь извлекать это . ну а когда мы накоп ##или базу , мы занялись класс ##ными штук ##ами . что если изучить распределение масштабов атак ? что мы там обнаруж ##им ? этим мы и занялись \u001b[31m.\u001b[0m тут вы можете видеть , что по горизонтально ##и оси \u001b[31mотложено\u001b[0m количество жертв атаки \u001b[31m—\u001b[0m масштаб атаки . а по вертикально ##и оси — количество атак \u001b[31m.\u001b[0m мы построили \u001b[31mграфик\u001b[0m масштабов атак . вы видит ##е как будто бы случаи ##ное распределение \u001b[31m:\u001b[0m например , в 67 атаках было убито по одному человеку , а в 47 — по семеро . вот так ##ои график мы построили \u001b[31mдля\u001b[0m ирак \u001b[31m##а\u001b[0m . тогда мы еще не знали \u001b[31m,\u001b[0m что мы \u001b[31mобнаруж\u001b[0m \u001b[31m##им\u001b[0m \u001b[31m.\u001b[0m \u001b[31mнаша\u001b[0m \u001b[31mнаходка\u001b[0m \u001b[31mочень\u001b[0m \u001b[31mвпечатл\u001b[0m \u001b[31m##яет\u001b[0m . казалось \u001b[31mбы\u001b[0m , конфликт \u001b[31m,\u001b[0m весь этот хаос \u001b[31m,\u001b[0m весь этот шум , и из этого появляется точное математическое \u001b[31mраспределение\u001b[0m атак этого \u001b[31mконфликта\u001b[0m \u001b[31m.\u001b[0m это взрыва ##ет мозг . откуда в конфликте типа \u001b[31mиракского\u001b[0m такая вот математика \u001b[31m?\u001b[0m откуда в воин \u001b[31m##е\u001b[0m взяться порядку ? мы этого не понимали . мы думали \u001b[31m,\u001b[0m что может быть в ирак \u001b[31m##е\u001b[0m есть что - то особенное \u001b[31m.\u001b[0m и мы изучили еще несколько конфликтов . мы прис ##мотре ##лись к колумб ##ии , афган \u001b[31m##истан\u001b[0m ##у и сенег ##алу . в \n",
      "\n",
      "<class 'allennlp.interpret.saliency_interpreters.simple_gradient.SimpleGradient'> TEXT:\n",
      "\u001b[31mкогда\u001b[0m мы смотри ##м новости , мы видим сообщения из ирак ##а , афган ##истана , с ##ьерра \u001b[31m-\u001b[0m ле ##оне , и кажется \u001b[31m,\u001b[0m что эти конфликты \u001b[31mневозможно\u001b[0m понять . именно так я и думал , когда начинал этот проект . но я физик \u001b[31m,\u001b[0m и поэтому решил на ##ити данные и попробовать разобраться . просто попробовать . ну и как на ##ив ##ны ##и новозеланд ##ец я подумал , что по ##иду в пента ##гон . не могли бы вы поделиться со мн ##ои информ ##аци ##еи ? ( смех ) \u001b[31mнет\u001b[0m . поэтому пришлось задуматься пос ##ерьез ##нее . и вот однажды вечером в оксфорд \u001b[31m##е\u001b[0m я смотрел новости . и обратил внимание на экран под говоря ##щи ##ми головами . и обнаружил там информацию . там были данные , в ль ##ющихся на нас потока ##х новост ##еи . весь шум вокруг нас деи ##ств ##ительно содержит информацию . и мне пришла в голову мысль организовать нечто вроде разведки по открытым источникам . если ском ##бин ##ировать данные изо всех этих потоков , возможно \u001b[31m,\u001b[0m мы сможем понять воин \u001b[31m##у\u001b[0m \u001b[31m.\u001b[0m именно так я и поступил . мы начали собирать команду , междисциплин ##арную \u001b[31mкоманду\u001b[0m ученых \u001b[31m,\u001b[0m экономистов \u001b[31m,\u001b[0m математиков . мы собрали этих ребят , и начали работу над проблем ##ои . \u001b[31mв\u001b[0m работе было три \u001b[31mэтапа\u001b[0m . перв ##ы ##и — собрать данные . мы обработал ##и 130 источников информации : от отчетов ng ##o до газет и теленов ##ост ##еи . мы собрали эти данные и от ##филь ##тр ##овали их . достал \u001b[31m##и\u001b[0m из них важные для наше ##и базы данных кусочки . в это ##и базе было время атак , координаты , масштаб и тип использован ##ного оружия . все это есть в ежедневных новостях , нужно просто уметь извлекать это . ну а когда мы накоп ##или базу , мы занялись класс ##ными штук ##ами . что если изучить распределение масштабов атак ? что мы там обнаруж ##им ? этим мы и занялись . тут вы можете видеть , что по горизонтально ##и оси отложено количество жертв атаки — масштаб атаки . а по вертикально ##и оси — количество атак . мы построили график масштабов атак . вы видит ##е как будто бы случаи ##ное распределение : например , в 67 атаках \u001b[31mбыло\u001b[0m \u001b[31mубито\u001b[0m по одному человеку , а в 47 \u001b[31m—\u001b[0m по семеро . вот так ##ои график мы \u001b[31mпостроили\u001b[0m \u001b[31mдля\u001b[0m \u001b[31mирак\u001b[0m \u001b[31m##а\u001b[0m . \u001b[31mтогда\u001b[0m мы еще \u001b[31mне\u001b[0m знали , что мы \u001b[31mобнаруж\u001b[0m ##им . наша \u001b[31mнаходка\u001b[0m очень \u001b[31mвпечатл\u001b[0m \u001b[31m##яет\u001b[0m \u001b[31m.\u001b[0m казалось бы , конфликт \u001b[31m,\u001b[0m весь этот хаос , весь этот шум , и из этого появляется точное математическое распределение \u001b[31mатак\u001b[0m \u001b[31mэтого\u001b[0m конфликта \u001b[31m.\u001b[0m это взрыва ##ет мозг \u001b[31m.\u001b[0m \u001b[31mоткуда\u001b[0m в \u001b[31mконфликте\u001b[0m \u001b[31mтипа\u001b[0m \u001b[31mиракского\u001b[0m \u001b[31mтакая\u001b[0m вот математика ? откуда в воин ##е взяться порядку ? мы этого не понимали \u001b[31m.\u001b[0m мы думали , что может быть в ирак \u001b[31m##е\u001b[0m есть что - то особенное . и мы изучили еще несколько конфликтов . мы прис ##мотре \u001b[31m##лись\u001b[0m к колумб \u001b[31m##ии\u001b[0m , афган \u001b[31m##истан\u001b[0m \u001b[31m##у\u001b[0m и сенег \u001b[31m##алу\u001b[0m . \u001b[31mв\u001b[0m \n",
      "\n",
      "<class 'allennlp.interpret.saliency_interpreters.integrated_gradient.IntegratedGradient'> TEXT:\n",
      "\u001b[31mкогда\u001b[0m \u001b[31mмы\u001b[0m \u001b[31mсмотри\u001b[0m ##м новости , мы видим сообщения из ирак \u001b[31m##а\u001b[0m , афган ##истана , с ##ьерра \u001b[31m-\u001b[0m ле ##оне , и кажется , что эти конфликты \u001b[31mневозможно\u001b[0m понять . именно так я и думал , когда начинал этот проект \u001b[31m.\u001b[0m но \u001b[31mя\u001b[0m физик \u001b[31m,\u001b[0m и поэтому решил на ##ити данные \u001b[31mи\u001b[0m попробовать \u001b[31mразобраться\u001b[0m . просто попробовать \u001b[31m.\u001b[0m ну и как на ##ив ##ны ##и новозеланд ##ец я \u001b[31mподумал\u001b[0m , что по ##иду в пента ##гон . \u001b[31mне\u001b[0m \u001b[31mмогли\u001b[0m бы вы поделиться со мн ##ои информ ##аци ##еи ? ( смех ) нет . поэтому пришлось задуматься пос ##ерьез ##нее . и вот однажды вечером в оксфорд \u001b[31m##е\u001b[0m я смотрел новости \u001b[31m.\u001b[0m \u001b[31mи\u001b[0m обратил \u001b[31mвнимание\u001b[0m \u001b[31mна\u001b[0m экран под говоря ##щи ##ми головами . и обнаружил там информацию . там были данные \u001b[31m,\u001b[0m в ль ##ющихся на нас потока ##х \u001b[31mновост\u001b[0m ##еи . весь шум вокруг нас деи ##ств ##ительно содержит информацию . и мне пришла в голову мысль организовать нечто вроде разведки по открытым источникам . если ском ##бин ##ировать \u001b[31mданные\u001b[0m изо \u001b[31mвсех\u001b[0m этих потоков \u001b[31m,\u001b[0m возможно , мы сможем понять \u001b[31mвоин\u001b[0m ##у . именно так я \u001b[31mи\u001b[0m \u001b[31mпоступил\u001b[0m \u001b[31m.\u001b[0m мы начали \u001b[31mсобирать\u001b[0m \u001b[31mкоманду\u001b[0m \u001b[31m,\u001b[0m \u001b[31mмеждисциплин\u001b[0m \u001b[31m##арную\u001b[0m команду \u001b[31mученых\u001b[0m , экономистов , математиков . мы собрали этих \u001b[31mребят\u001b[0m , и начали работу \u001b[31mнад\u001b[0m проблем ##ои . в работе было три этапа . перв ##ы ##и — собрать данные . мы обработал ##и 130 источников информации : от отчетов ng ##o до газет и теленов ##ост ##еи . мы собрали эти данные и от ##филь ##тр ##овали их . достал ##и из них важные для наше ##и базы данных кусочки . в это ##и базе было время атак , координаты , масштаб и тип использован ##ного оружия . все это есть в ежедневных новостях , нужно просто уметь извлекать это . ну а когда мы накоп ##или базу , мы занялись класс ##ными штук ##ами . что если изучить распределение масштабов атак ? что мы там обнаруж ##им ? этим мы и занялись . тут вы можете видеть , что по горизонтально ##и оси отложено количество жертв атаки — масштаб атаки . а по вертикально ##и оси — количество атак . мы построили график масштабов атак . \u001b[31mвы\u001b[0m видит ##е как \u001b[31mбудто\u001b[0m \u001b[31mбы\u001b[0m \u001b[31mслучаи\u001b[0m ##ное распределение : \u001b[31mнапример\u001b[0m , \u001b[31mв\u001b[0m 67 атаках было убито \u001b[31mпо\u001b[0m одному человеку , а в 47 \u001b[31m—\u001b[0m по семеро . вот так ##ои график мы построили для ирак ##а . \u001b[31mтогда\u001b[0m мы еще не знали , что мы \u001b[31mобнаруж\u001b[0m ##им . наша находка очень впечатл ##яет . казалось бы , конфликт , весь этот хаос , весь этот шум , и из этого появляется точное математическое распределение атак этого конфликта . это взрыва ##ет мозг . откуда в конфликте типа иракского такая вот математика ? откуда в воин \u001b[31m##е\u001b[0m взяться порядку ? мы этого не понимали . мы думали , что может быть в ирак ##е есть что - то особенное . и мы изучили еще несколько конфликтов . \u001b[31mмы\u001b[0m прис ##мотре ##лись к колумб ##ии , афган ##истан ##у и сенег ##алу . в \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_sentence(\n",
    "    sentences[mistake_ids[2]], 50, \n",
    "    [smooth_grad, simple_grad, integrated_grad],\n",
    "    label_description[true_classes[mistake_ids[2]]],\n",
    "    label_description[predicted_classes[mistake_ids[2]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
